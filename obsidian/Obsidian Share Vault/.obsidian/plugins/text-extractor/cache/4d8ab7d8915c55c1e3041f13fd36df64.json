{"path":"lit/lit_sources/Rahman24TrackComputeIntensiveAI.pdf","text":"4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 /3 2ArticlesTracking Compute-Intensive AI ModelsWe present a dataset of 81 compute-intensive models, from AlphaGo toGemini, developed across 18 countries, at the leading edge of scale andcapabilities.Tracking Compute-Intensive AI ModelsReportEPOCH 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 2 /3 2PublishedApr 05, 2024AuthorsRobi RahmanDavid OwenJosh You 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 3 /3 2ResourcesCiteContentsResultsThere are few models at the leading edge, but the frontier advances rapidlyMost compute-intensive models are language modelsMost compute-intensive models are developed by US companiesDownloadable models are common, but have lower training computeMethods for finding compute-intensive modelsBenchmarks and RepositoriesNon-English news and websitesOther sourcesUnconfirmed compute-intensive modelsOutcomes and limitationsConclusionAppendixDatasetGrowth of the compute frontierCreditsNotes 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 4 /3 2We present a new dataset tracking compute-intensive AI models, with training compute over 10floating point operations (FLOP). This corresponds to training costs of hundreds of thousands of dollarsor more. We have identified 81 such models, and another 86 models that may exceed the 10 FLOPthreshold but don’t have confirmed training details.Compute-intensive models are key to research and policymaking. Our previous work has examined thecrucial role of training compute in the development of modern AI, and how it drives model capabilities.Existing AI regulation explicitly acknowledges the importance of training compute: both the recent USExecutive Order on AI development and the EU AI Act establish reporting requirements based oncompute thresholds. Motivated by these developments, we plan to track compute-intensive AI modelsby updating this dataset on an ongoing basis.The dataset offers insight into several recent trends in AI development. We share our findings in moredetail below, including these:23123The pace of compute-intensive model releases is accelerating. Only 11 models exceeded 10 FLOP in2020. By 2024, this grew to 81 models in our dataset, and the trend shows no sign of slowing. More.The large majority of compute-intensive models are language models, but many others aremultimodal or process images. Despite early breakthroughs in game-playing, language and imagegeneration have dominated since 2021. More.Over half of known compute-intensive models were developed in the United States. A quarter weredeveloped in China, with this proportion growing in recent years. More.Almost half of the compute-intensive models in our dataset had published, downloadable weights,mostly with training compute between 10 and 10 FLOP. Publicly released model weights arecommon, but are trained with less compute than the very largest proprietary models. More.•23•••2324 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 5 /3 2Figure 1: Interactive plot showing the 81 models in our dataset with estimated training compute above 10 FLOP.While compiling this dataset, we have conducted an exhaustive search process relying on existingbenchmarks and repositories, an automated search for non-English model announcements, and otherCompute-intensive modelsEPOCHTraining compute (FLOP)102310241025AlphaGo ZeroGPT-3GPT-4Gemini UltraPaLMAlphaGo MasterPublication date2017201820192020202120222023202423 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 6 /3 2sources. We explain our methods in depth later in the article. To download the data, see the Appendix orvisit our online database.ResultsThere are few models at the leading edge, but the frontier advances rapidlyNumber of models larger than 10 FLOP released by yearEPOCHNumber of models23 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 7 /3 23540Model count by training computeEPOCHNumber of models050100150200GeminiGPT-4Falcon 180BLlama 2 70BGPT-3Turing-NLGAlphaZeroWhisper v2Training compute (FLOP)1022102310241025 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 8 /3 2Figure 2: a) Number of models with training compute of at least 10 FLOP published in each year, 2017 through 2024.b) Number of models with training compute over different thresholds as of 2024 March 31. Supplemental data on models below 10 FLOP istaken from our broader database of AI models.Figure 2b shows how there are few models at the frontier of training compute, currently 10 FLOP ormore. However, as shown in Figure 2a, the frontier advances rapidly over time. In 2020, only two modelswere trained with more than 10 FLOP. This increased exponentially over the subsequent three years,and over 40 models trained at this scale were released in 2023.The rapid advance of the frontier is consistent with exponential increases in ML R&D investment andhardware performance. If training compute continues to increase 4x per year, the top models willsurpass 10 FLOP in 2024, and models at the 10 scale will be over 1000x smaller than the top modelsby 2026. Meanwhile, the number of models above smaller thresholds is also quickly expanding, socompute thresholds for monitoring models may need to rise correspondingly over time, if they are toremain focused on models at the cutting edge of capabilities.Most compute-intensive models are language models232325232624Compute-intensive models by domainEPOCHCompute-intensiveUnconfirmed compute-intensive 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 9 /3 2Figure 3: Compute-intensive models categorized by domains of machine learning. Language models trained for both general-purposelanguage tasks and biology tasks, such as Galactica, are counted within both language and biology.Figure 3 shows how a large majority (69 out of 81, or 85%) of compute-intensive models in our datasetare language models, and a few more (5 out of 81, about 6%) are vision-language models. Commonapplications for these models include general language modeling, chat, and code generation. Amonglanguage models, the majority are used for natural-language tasks, like chatting with users andfollowing text-based instructions, and some are trained for tasks such as code generation and protein-11122226667516216955124MedicineRoboticsVisionAudioGamesBiologySpeechVideo generationImage generationVision-languageLanguageNumber of models020406080100120140 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 0 /3 2sequence prediction. Only a small minority of compute-intensive models (7 out of 81, about 9%) are nottrained on language or text data, instead using audio, image, or game data.To gain a fuller picture of domains for compute-intensive models, Figure 3 also shows domains formodels with unconfirmed training compute. These models lack public information about their trainingprocess, but may be trained with over 10 FLOP, based on what we know about them (see Unconfirmedcompute-intensive models). The domain breakdown is broadly similar, but a higher proportion of themdeal with other applications such as image generation, video generation, and robotics.Proprietary models, such as Runway’s Gen-2 video generator, typically don’t disclose details of theirtraining datasets and hardware. Robotics systems, such as Nvidia’s CALM, typically require the authorsto gather custom, proprietary datasets rather than using open-source datasets which are publiclyavailable and well-documented.23Compute-intensive models by domain and publication dateEPOCHTraining compute (FLOP)LanguageMultimodalSpeechGamesDrawingBiologyVision 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 1 /3 2Figure 4: Compute-intensive models by year, separated by domain. Game-playing models such as AlphaGo Master were the first to exceedthe 10²³ FLOP threshold, and it took two years for language models to catch up. After 2021, the number of LLMs rapidly increased, whilethere were no more game-playing models at this scale of compute.Although language models have been the dominant category of large models from 2020 onward, thefirst two compute-intensive models were both game-playing models. The first models trained on over10 FLOP, AlphaGo Master and AlphaGo Zero, were developed by DeepMind and published in 2017.These models were trained with an unprecedented amount of compute, over an order of magnitude102310241025AlphaGo ZeroGPT-3GPT-4Gemini UltraPaLMAlphaGo MasterMeenaPublication date2017201820192020202120222023202423 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 2 /3 2more than any preceding model. There are no game-playing models in the dataset after these. Figure 4shows how the next model trained at a similar scale, Google’s GPT-inspired Meena, was not publisheduntil 2020. GPT and GPT-2 were below 10 FLOP, but GPT-3 arrived later the same year, followed byother GPT-inspired language models such as Jurassic-1.Computer vision is a prominent area of research, but only one non-generative vision model (ViT-22B,current SOTA for ObjectNet) is near today’s frontier of compute. The most compute-intensive models inour database, GPT-4 and Gemini Ultra, are both multimodal models that accept non-text inputs —since multimodal models are more useful than pure language models, this may become a trend amonglarge models. Many of these models have been used in commercial products, such as GPT-4 in ChatGPT,Gemini, and ERNIE in Ernie Bot.Diffusion models have also been used in many image- and video-generation products, like DALL-E andMidjourney. Several of these may be near the compute frontier, but their developers have typically notpublished training details.Most compute-intensive models are developed by US companies43 out of 81 compute-intensive models were developed by organizations based in the United States,followed by 19 in China and 6 in the UK. 10 models were developed in other countries outside the US,China, and the UK, and three were developed by collaborations involving researchers and organizationsfrom multiple countries. DeepMind is responsible for every compute-intensive model developedexclusively in the UK; since merging with the AI teams at Google, it has produced two more asmultinational collaborations.232 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 3 /3 2Figure 5: Number of compute-intensive models developed by selected countries, over time. Multinational refers to models developed bycollaborators in multiple countries. DeepMind is considered to be within the United Kingdom prior to April 2023; following its merger withGoogle Brain, models developed by Google DeepMind are considered multinational. Other refers to models developed within any singlecountry not listed in the legend.Compute-intensive models by countryEPOCHCumulative number of modelsUnited StatesChinaOtherUnited KingdomMultinational01020304050607080Year201720182019202020212022202320243 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 4 /3 2The leading organizations in number of confirmed compute-intensive models are Google, Meta,DeepMind, Hugging Face, and OpenAI. Other developers include corporations, universities, andgovernments. Findings are broadly similar when including unconfirmed models, although organizationssuch as Anthropic and Alibaba move further up the ranking. The vast majority of compute-intensivemodels are developed by industry (71) rather than academia (2), with a few industry-academiacollaborations (6), and a couple developed by government institutions (2). Slightly over half (53) havebeen documented in an academic format, although only 17 of these have been published in a peer-reviewed journal or conference, with the remaining 36 published as arXiv preprints or similar.45Compute-intensive models by organizationEPOCHCompute-intensiveUnconfirmed compute-intensive 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 5 /3 2Figure 6: Number of compute-intensive models by organization, for organizations involved in at least 4 such models. Some models aredeveloped by multiple organizations and therefore appear in each of their tallies.Downloadable models are common, but have lower training compute38 out of 81 compute-intensive models are downloadable, with their model weights available to thepublic. The downloadable model trained with the most compute to date is Falcon-180B, which wastrained using 3.8 * 10 FLOP, or roughly ⅕ as much compute as GPT-4. Most (86%) of thesedownloadable models were trained on between 10 and 10 FLOP. Meta’s OPT-175B, released in May44224134415633618955101221414418Hugging FaceBAAITsinghuaMistral AINVIDIADeepMindAlibabaAnthropicOpenAIMetaGoogleNumber of models0510156242324 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 6 /3 22022, was the first downloadable model to reach the 10 level. To date, Meta has now released a dozendownloadable models at this scale and has committed to continuing this approach in the future,suggesting that open-access ML will continue to grow with the investments of one of the largest techcompanies.Chinese labs are well-represented among compute-intensive downloadable models — 12 weredeveloped by organizations based in China. Alibaba’s Qwen is one notable example, achieving state-of-the-art performance on several Chinese benchmarks. All compute-intensive downloadable models fromChina are large language models trained on datasets containing trillions of tokens of English andChinese text. Most of them primarily function as chatbots, but several are also trained for codegeneration. The organizations developing these large models include established companies from theChinese technology industry like Alibaba, Baidu, Huawei, and research institutions such as TsinghuaUniversity. There are also several new AI startups, including DeepSeek and Baichuan.Methods for finding compute-intensive modelsWe used a variety of resources to find candidate models that were plausibly trained using more than 10FLOP. We then estimated how much compute was used to train these models when it is not directlyreported by the developers. The models were added to our database, along with estimates of theirtraining compute, number of parameters, and amount of training data whenever this information wasavailable. Models trained with over 10 FLOP were tallied and the results presented in this article.Benchmarks and RepositoriesBenchmark leaderboards are an important tool for identifying frontier models because researchersevaluate their models against benchmarks as part of standard practice and models trained on the most232323 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 7 /3 2compute tend to perform the best. We have searched a variety of benchmarks in depth, selected toprovide coverage of many different domains of machine learning.Papers With Code (PWC) maintains a collection of machine learning research papers that have beenpublished along with their repositories, allowing other researchers to replicate their work. It also has acollection of benchmarks, each with a leaderboard tracking the state-of-the-art level of benchmarkperformance over time. For every benchmark with over 100 model evaluations submitted, we examinedthe top-performing model. Additionally, we examined every model in the PWC dataset that had at least 1billion parameters, estimating their training compute based on their associated papers, and added themto our database.The Center for Research on Foundation Models (CRFM) at Stanford University also works on trackinglarge models, especially foundation models used in downstream applications after fine-tuning, and hassome resources showing a number of compute-intensive systems. Their Holistic Evaluation of LanguageModels project has a live leaderboard ranking many large models on a variety of metrics and scenarios.CRFM also graphically tracks the ecosystem of foundation models, child models, and datasets, andprovides a table of information on these components. We’ve checked their sources for informationrelevant for estimating compute and collected candidate models from the models table.Hugging Face is a company that maintains a large online repository of open-source model weights. Weused their API to search for models with over 100 downloads and at least 1 billion parameters. HuggingFace also operates Chatbot Arena, a crowdsourced comparison platform where users chat with twoLMs at once and choose the one whose responses they like better, which adjusts the models’ Elo ratingsaccordingly. Chatbot Arena’s leaderboard then ranks all the competing models by Elo rating. We’vecollected all of the models from the leaderboard with training runs likely to have used at least 10 FLOP.Non-English news and websites723 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 8 /3 2As the fields of AI and ML grow, development of compute-intensive models is spreading around theworld, and systems developed in regions where languages other than English are predominant may notreceive enough coverage in English-language media to come to our attention unless we seek them out.Considering the most commonly spoken languages around the world and in areas with activetechnology industries, we selected the following languages and did searches using the most popularsearch engines for each language: Chinese, Hindi, Spanish, French, Arabic, Bengali, Portuguese,Russian, Urdu, German, Japanese, Turkish, Korean, Persian, and Hebrew. We looked at the top 100results for each of the 3-6 most relevant AI keywords in each language, filtered to 2020-present,encompassing the time period when models began to regularly exceed 10 FLOP.One of the most fruitful search avenues has been Chinese-language media, which has extensivelycovered recent AI developments. We found a large number of previously unfamiliar compute-intensivemodels through Baidu searches for terms such as “chatbot”, “trillion parameter”, and “large AI model”.For each keyword, we translated the term into Chinese using Google Translate, searched for thetranslated term on Baidu, and recorded any AI models mentioned in the first 100 search results. Thesewere then researched to determine whether they were trained using at least 10 floating-pointoperations.We also looked at two leaderboards, SuperCLUE (Chinese Language Understanding Evaluation) andOpenCompass, that rank many LLMs by their performance on Chinese-language benchmarks. Most ofthese LLMs were developed in China. These leaderboards were checked for models previously missingfrom Epoch’s database.Other sourcesSeveral other sources were used to identify models for the database, though these were not checkedexhaustively. We reviewed blog posts and press releases from the major frontier labs (Anthropic,Google, DeepMind, Microsoft, OpenAI) from the past few years to identify research and products82323 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 1 9 /3 2involving large models. Epoch staff also follow machine learning research and announcements onvarious platforms and newsletters. We collect new model releases and then add them to the database.We periodically conduct literature searches of machine learning topics in order to find highly influentialresearch. Compute-intensive systems are frequently (but not always) highly cited, which is to beexpected because well-funded research has more potential to achieve breakthroughs and attentionwithin the field. However, during this focused effort to find compute-intensive models, no models wereidentified in scholarly searches or bibliographies that were not already identified by the other methodsabove.Unconfirmed compute-intensive modelsA challenge in this work is that many models do not report enough details to estimate training compute.Our dataset focuses on models with known training compute, but this precludes many notable modelssuch as Claude 3 or Sora. To mitigate this, we collected a separate table of unconfirmed compute-intensive models, where compute is unknown but available information suggests their training computecould exceed 10 FLOP. This data is also downloadable in the Appendix.We selected models in our database published in 2022 or later, with unknown training compute. Weexcluded models with fewer than 3 billion parameters or 10 billion training data points. These thresholdswere based on parameter counts and dataset sizes in models with confirmed compute. We alsoexcluded models fine-tuned from other models. We then manually inspected candidates to rule outmodels likely to fall below 10 FLOP, for example based on training hardware or model capabilities.Although some of these models may nevertheless have been trained with less than 10 FLOP, this dataprovides more context about compute-intensive models, for example in Figures 3 and 6.Outcomes and limitationsThere are limits to our search methods, and some models within the scope of our search may not bepossible to find by these or other methods. Commercial products are often proprietary and their232323 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 2 0 /3 2technical details not divulged, especially in the cybersecurity and B2B service industries. Thecybersecurity suite Darktrace and anti-malware software McAfee are typical examples of this, as is thecustom chatbot service Dante.Sometimes, there are publicly announced AI products which may or may not have important modelsbehind them. Microsoft Azure offers chatbots which may have been developed within Microsoft or maybe using GPT-4. Salesforce’s competing service EinsteinGPT is similar and may be using an OpenAImodel on the backend or may involve a custom, fine-tuned model. ByteDance’s Tako chatbot (used inTikTok) is almost certainly not based on GPT-4, but it is unclear how much compute or data was usedwhen creating it. The image generation service Craiyon may involve a large model, possibly based onStable Diffusion. The chat and writing services YouChat and rytr, on the other hand, definitively do notcontain bespoke models, instead relying on the GPT API.In other cases, labs may develop large models but forgo announcing them in order to maintain secrecy.We don’t know how many such models have flown under the radar. Determining the number or identityof organizations capable of creating these models would be a useful endeavor, but was beyond thescope of this process.ConclusionCompute-intensive AI models are of particular interest for policymakers and researchers. We havecollected a dataset covering 81 highly compute-intensive models. Analyzing this dataset confirmsseveral key insights. First, language modeling is by far the most common domain. This trend seems likelyto continue, with language prioritized in development of the next generation of frontier models, even asthey become multimodal. Second, compute-intensive models are primarily developed by US companies,but a quarter come from Chinese labs, and this proportion has grown in recent years. Finally, almost half 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 2 1 /3 2of highly compute-intensive models are downloadable, a trend suggesting that new cutting-edgecapabilities become widely available soon after they are developed in proprietary models.Ultimately, we can never find every machine learning model in existence, so our search continues. A keychallenge in this work has been the large number of models without known training compute. We urgemachine learning developers to report your compute so that the policy and research communities canmaintain a well-informed view of the frontier of the field.To keep our database up-to-date, 15 foreign languages have been incorporated into an automatedpipeline that searches 5 languages per month for AI news articles published since the previous search,to find any model within three months of its release in any language. As machine learning companies,talent, and infrastructure spread around the world, these search results will reveal more and more largemodels.We’ll continue tracking new leading models on previously searched benchmarks, models leading onbenchmarks newly exceeding 100 evaluated systems, and models with over 1 billion parameterssubmitted to Papers With Code and Hugging Face. Suggestions for large ML systems not featured in ourdatabase can be submitted using this form. If this data has been useful to you, we’d love to hear fromyou at data@epochai.org.AppendixDatasetCompute-intensive models These models were trained with over 10^23 FLOP, based on our estimates oftraining compute.9 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 2 2 /3 2Unconfirmed and known compute-intensive models This dataset includes both models that weretrained with over 10 FLOP as well as models which have unknown training compute but may have beentrained on over 10 FLOP. Further details are described in Unconfirmed compute-intensive models.Table of known and unconfirmed compute-intensive models:Show:2323 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 2 3 /3 2Confirmed compute-intensive modelsThe data can be downloaded using the dropdown menu at the top of the embedded table. We also offera downloadable compute-intensive model dataset, updated daily, on our database portal and at thisCSV link.Growth of the compute frontierModel count by training compute at different yearsEPOCHNumber of models20202021202220232024 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 2 4 /3 2Figure 7: number of models (y-axis) above different compute thresholds (x-axis) in different years (legend). In any year, the figure illustrateshow many models had been published after being trained on a given amount of compute. The annual counts are spaced one year apart,with numbers as of March 31 in each year.The compute frontier of large models advanced rapidly after 2021. Most existing highly compute-intensive models were published in the last two years: 21 during 2022, and 42 in 2023. A similar patternholds across all compute thresholds between 10 and 10 FLOP. At any given time, there were a smallnumber of models at the leading edge of training compute. However, once the first model was trained at050100150200GeminiGPT-4Falcon 180BLlama 2 70BGPT-3Turing-NLGAlphaZeroWhisper v2Training compute (FLOP)102210231024102510262224 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 2 5 /3 2a given compute scale, subsequent models followed at an increasing rate. The frontier has grownrapidly: in 2020 a handful of models were above 10 FLOP, but by 2024 there were hundreds, asillustrated in Figure 7.CreditsThis article was written by Robi Rahman, David Owen, and Josh You.The frontier model search was conducted by Robi Rahman, Josh You, David Owen, and Ben Cottier. Thetraining compute of models identified during the search was estimated by Josh You, BartoszPodkanowicz, and Robi Rahman.We thank Anson Ho, Jaime Sevilla, Robert Sandler, Tamay Besiroglu, Ben Cottier, and Markus Anderljungfor review and feedback on the drafts, and Edu Roldan and Robert Sandler for formatting the article foronline publication.Notes\u0000. Based on December 2023 cloud compute cost rates to train a model with 10 FLOPs at 30-50%model FLOPs utilization. For detailed training cost estimates, see our forthcoming study in the 2024Stanford AI Index Report. ↩\u0000. Gemini 1.5 Pro and Claude 3 are two recently announced models that are also multimodal. They arelikely among the largest models trained to date, though we do not have compute estimates forthem yet. ↩2223 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 2 6 /3 2\u0000. Countries included in the category Other include: the United Arab Emirates (2 models), France (2),Israel (1), South Korea (1), Russia (1), Germany (1), Japan (1), and Finland (1). ↩\u0000. Google’s AI division merged with DeepMind in 2023, forming an AI lab called Google DeepMind.Models created by Google DeepMind are counted as “Google” in this graph, while DeepMindmodels from before this merger are counted separately. ↩\u0000. TII, or Technology Innovation Institute, is a government research institute in the United ArabEmirates. ↩\u0000. Includes fully open-source models (weights, code, data), and models with weights released underpermissive or open-source licenses. ↩\u0000. paper, repository ↩\u0000. The most popular search engine is Google in every language except the following: Baidu is the topsearch engine for Chinese, Yandex for Russian, and Naver for Korean. ↩\u0000. Some models that were in fact trained on >10 FLOP may be missing from our list of compute-intensive models because we don’t have enough information on how much compute was used totrain them, not because we don’t know about them. See the appendix for a list of models wesuspect may have been trained on over 10 FLOP, but for which we do not have compute counts orcompute estimates. ↩About the authors2323 4 /1 1 /2 4 , 1 0 :3 1 P M T r a c k in g C o m p u te - In te n s iv e A I M o d e ls – E p o c h c h r o m e - e x te n s io n ://m p io d ijh o k g o d h h o fb c jd e c p ffjip k le /s r c /u i/p a g e s /e d ito r.h tm l 2 7 /3 2Robi Rahman manages the databases for Epoch’s hardware and machine learning datasets, and collectsdata on new AI systems. Robi is also a contributor to the Stanford AI Index Report and a volunteer for hislocal effective altruism chapter. Before joining Epoch, Robi received a master’s degree in data science fromHarvard University.David Owen is a researcher with a background in computer vision and machine learning. He is interestedin analysing and predicting model capabilities, and using empirical data to explore AI deployment in thereal world. Before joining Epoch, David worked in an industrial research lab developing AI models forsurgical video.Josh You is a data analyst who collects and analyzes data on AI systems. Before Epoch, he worked as asoftware engineer and a content writer, and graduated from Carleton College with a degree in ComputerScience and Mathematics.ShareTwitterLinkedInTagsDataMethodologyCompute-intensive modelsRelated posts","libVersion":"0.3.1","langs":""}