{"path":"lit/lit_sources/Donadee15operBattUncertPhD.pdf","text":"Operation and Valuation of Multi-Function Battery Energy Storage under Uncertainty Submitted in partial fulﬁllment of the requirements for the degree of Doctor of Philosophy in Electrical and Computer Engineering Jonathan R. Donadee B.S.E., Mechanical Engineering, Minor Economics, University of Michigan, Ann Arbor M.S., Management Science and Engineering, Stanford University Carnegie Mellon University Pittsburgh, PA May 2015 Abstract Electrical energy storage resources (ESRs) oﬀer a promising solution to many of the issues facing the electric grid. In order for this promise to be fully real- ized, new intelligent decision-making technologies are required. This dissertation studies the operation and valuation of ESRs in an uncertain electric grid en- vironment. ESRs can include both stationary battery energy storage systems (BESSs) and distributed deferrable loads such as plug-in electric vehicles (EVs). An ESR can be operated to provide multiple services simultaneously, maximiz- ing its value. An EV can provide transportation services as well as participate in electric grid frequency regulation. A BESS can also provide frequency reg- ulation while providing load peak shifting. In this thesis, we propose new and innovative solutions that enable optimal operation and accurate valuation of multi-function ESRs under uncertainty. New Markov decision problems (MDPs) for smart charging of EVs are developed for cases of price, ancillary services, and driver behavior uncertainty. In order to compare the proposed MDP approaches with deterministic optimization approaches, a Dynamic Monitoring and Decision Systems (DYMONDS) energy market simulation is developed. We also propose an inﬁnite horizon MDP approach to estimating the net present value of a BESS that degrades over time. In order to optimize the economic scheduling of an ESR that provides frequency regulation service, one needs a predictive model of the automatic generation control (AGC) signal. We investigate timeseries and other statistical models for the prediction of an AGC signal and its cumulative eﬀect on the state of charge of an ESR. iii Acknowledgments This dissertation was advised and supported by Professor Marija Ili´c. I am sincerely thankful for the opportunity to work with her and her stellar research group. Marija’s pride in her students and excitement for her work has been a con- stant inspiration. I would also like to recognize Prof. Orkun Karabasoglu, Prof. Soummya Kar, and Dr. Jianhui Wang for their active collaboration throughout my PhD. studies and their participation in the thesis committee. I would also like to thank Claire Bauerle and Samantha Goldstein for administrative support within the Department of Electrical and Computer Engineering. The work in this thesis was ﬁnancially supported by Funda¸c˜ao para a Ciˆencia e a Tecnologia (Portuguese Foundation for Science and Technology) through the Carnegie Mel- lon Portugal Program, the Carnegie Mellon University - Sun Yat Sen University Collaborative Innovation Research Center, and ﬁnally the National Institute of Standards. It has been a pleasure to study in the Porter Hall B level oﬃces where so many friends were made over the last 4 and a half years. Through coursework, Ph.D. requirements, and happy hours, so many colleagues and friends have been there to share in commiserating and celebrating. Thank you to Javad Mohammadi, Kyri Baker, Milos Cvetkovi´c, Sanja Cviji´c, Dan McAdams, Stefanos Baros, Xia Miao, Kevin Bachovchin, Maxim Buevich, Malika Sinha, Joya Deri, Matthias Althoﬀ, Jovan Ili´c, Rohan Chabukswar, Nikos Arechiga, Andrew Hsu, Nipun Popli, Anit Sahu, Chin Yen Tee, S´ergio Pequito, Amin Kargarian, Hadi Amini, Mohsen Rahmani, Evgeny Toropov, Pui Siripha Junlakarn, Jose Prada, Caroline Van den Hauwe, and Martin Wagner for your support and friendship. Also, I iv would like to thank the CMU Roller Hockey team for being a great excuse to stop working for a few hours each week. I would like to thank my family for their support during the Ph.D. and for making me the person I am today. My father, Jack, who has always pushed his children to succeed and to be their own person. My mother Janey who is always there to listen without judging. My sister Chenell, who has always inspired me to expand my horizons and has been a lifesaver since I moved to Pittsburgh. And Jacob, my cooler older brother, who has kept me from becoming too nerdy (maybe?). Finally, I’d like to thank Jhi-Young Joo, without whom this thesis would probably have never been written. In addition to being a loving companion, J.Y. has been my biggest fan and best friend. vvi Contents 1 Introduction 1 1.1 Background and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2 Stochastic Optimization of Grid to Vehicle (G2V) Frequency Regulation Capacity 7 2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.2 Problem Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.2.1 Decision Making Scenario . . . . . . . . . . . . . . . . . . . . . . . . 11 2.2.2 Decision Epochs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.2.3 System State . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.2.4 State Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.2.5 Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.2.6 Cost Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.2.7 Markov Decision Problem . . . . . . . . . . . . . . . . . . . . . . . . 15 2.3 Possible Solution Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.4 Proposed Stochastic Dynamic Programming Solution Heuristic . . . . . . . . 18 2.4.1 Discrete MDP Approximation and SDP . . . . . . . . . . . . . . . . . 18 2.4.2 Approximate SDP with a Continuous Space of Actions . . . . . . . . 19 2.4.3 Derivation of Value Function Inequality Coeﬃcients . . . . . . . . . . 20 vii 2.4.4 Reduction of Problem Size . . . . . . . . . . . . . . . . . . . . . . . . 21 2.4.5 Proposed SDP Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 22 2.5 Stochastic Process Models for Simulation . . . . . . . . . . . . . . . . . . . . 23 2.5.1 Estimating Continuous Stochastic Process Models . . . . . . . . . . . 23 2.5.2 Simulation Input Data . . . . . . . . . . . . . . . . . . . . . . . . . . 25 2.6 Simulation Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 2.6.1 Simulation Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 2.6.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3 Electric Vehicles in the Adaptive Load Management Framework 33 3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 3.2 Deterministic MPC based Real-Time ALM . . . . . . . . . . . . . . . . . . . 35 3.3 MDP based ALM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 3.3.1 Energy Price Markov Model . . . . . . . . . . . . . . . . . . . . . . . 39 3.3.2 MDP Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 4 Optimal Autonomous EV Charging with Stochastic Driver Behavior 45 4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 4.2 Markov Decision Problem Formulation . . . . . . . . . . . . . . . . . . . . . 48 4.2.1 Decision Epochs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 4.2.2 State Vector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 4.2.3 State Transitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 4.2.4 Feasible Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 4.2.5 Cost function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 4.2.6 Optimization Problem . . . . . . . . . . . . . . . . . . . . . . . . . . 55 4.3 Numerical Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 4.3.1 Input Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 4.3.2 Results and Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 viii 5 Evaluation of the System Wide Impacts of Smart EVS Using the Smart Grid in a Room Simulator Architecture 63 5.1 SGRS Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 5.2 Implementation of the Real-Time DYMONDS Energy Market Simulation . . 67 5.3 Mathematical Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 5.3.1 Inﬂexible Load . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 5.3.2 Generator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 5.3.3 EV Driver . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 5.3.4 Price Forecaster . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 5.4 Simulation Input Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 5.5 Experiment Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 5.6 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 5.6.1 Fast Charging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86 5.6.2 MPC Based TOU Charging . . . . . . . . . . . . . . . . . . . . . . . 90 5.6.3 MPC Based Price-Taker Charging . . . . . . . . . . . . . . . . . . . . 93 5.6.4 MPC Based ALM Charging . . . . . . . . . . . . . . . . . . . . . . . 97 5.6.5 MDP Based ALM Charging . . . . . . . . . . . . . . . . . . . . . . . 100 5.6.6 Cost Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 5.6.7 Real-Time Responsiveness . . . . . . . . . . . . . . . . . . . . . . . . 106 5.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109 6 An MDP Approach to Valuation of Multi-Function Battery Energy Stor- age under Uncertainty 111 6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 6.1.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 6.1.2 Proposed Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 6.2 MDP for BESS Operations under Uncertainty . . . . . . . . . . . . . . . . . 115 ix 6.2.1 BESS MDP Formulation . . . . . . . . . . . . . . . . . . . . . . . . . 115 6.2.2 Optimal Operating Policy . . . . . . . . . . . . . . . . . . . . . . . . 118 6.3 Estimating the Rate of Battery Capacity Degradation under a Markov Oper- ating Policy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 6.3.1 Degradation Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 6.3.2 Estimation of Capacity Degradation Rate . . . . . . . . . . . . . . . 123 6.4 Penalizing Battery Degradation Cost in the BESS MDP . . . . . . . . . . . 124 6.5 Estimation and Maximization of NPV . . . . . . . . . . . . . . . . . . . . . 127 6.5.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128 7 AGC Modeling for Energy Storage Operations 131 7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131 7.2 Hourly AGC Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 7.3 Forecasting the Next SOC . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 8 Conclusions and Future Work 139 8.1 Conculsions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139 8.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 x List of Figures 2.1 Example EV charging simulation trial results . . . . . . . . . . . . . . . . . . 28 2.2 Example energy price simulation . . . . . . . . . . . . . . . . . . . . . . . . . 29 2.3 Example regulation service price simulation . . . . . . . . . . . . . . . . . . 29 4.1 Proposed system architecture for optimizing autonomous charging policies . 48 4.2 Static circuit equivalent model of the vehicle battery . . . . . . . . . . . . . 52 4.3 Energy market prices on a weekday and a weekend day at 5 diﬀerent CDF points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 4.4 Open circuit voltage curve of the EV battery pack . . . . . . . . . . . . . . . 58 4.5 Probability of unplugging at diﬀerent times of day on weekdays (a) and on weekends (b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 5.1 SGRS simulation architecture . . . . . . . . . . . . . . . . . . . . . . . . . . 66 5.2 Screen capture of the web interface plotting live simulation results . . . . . . 66 5.3 Schematic of modules and communications implemented in the SGRS simu- lation architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 5.4 Weekday EV connection proﬁle . . . . . . . . . . . . . . . . . . . . . . . . . 75 5.5 Weekend EV connection proﬁle . . . . . . . . . . . . . . . . . . . . . . . . . 75 5.6 PJM system price as a function of load . . . . . . . . . . . . . . . . . . . . . 77 5.7 Power system network used for simulations . . . . . . . . . . . . . . . . . . . 78 5.8 Weekday seasonal load proﬁle at each bus . . . . . . . . . . . . . . . . . . . 79 xi 5.9 Weekend seasonal load proﬁle at each bus . . . . . . . . . . . . . . . . . . . 80 5.10 Example of forecast load and actual simulation load at Bus 2 . . . . . . . . . 81 5.11 The deterministic relationship between energy price and system load in the simulated system . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 5.12 Average weekday energy price proﬁle without EVs . . . . . . . . . . . . . . . 85 5.13 Average weekend energy price proﬁle without EVs . . . . . . . . . . . . . . . 86 5.14 Mean EV ﬂeet load proﬁle for weekdays under the Fast Charging strategy . . 87 5.15 Mean EV ﬂeet load proﬁle for a weekend under the Fast Charging strategy . 87 5.16 EV ﬂeet load proﬁle for a single weekday under the Fast Charging strategy . 88 5.17 Average system price proﬁle for weekdays under the Fast Charging strategy . 89 5.18 Average system price proﬁle for a weekend under the Fast Charging strategy 89 5.19 Mean EV ﬂeet load proﬁle for weekdays under the TOU charging strategy . 91 5.20 Mean EV ﬂeet load proﬁle for weekends under the TOU charging strategy . 91 5.21 EV ﬂeet load proﬁle for a single weekday under the TOU charging strategy . 92 5.22 Average system price proﬁle for weekdays under the TOU charging strategy 92 5.23 Average system price proﬁle for weekends under the TOU charging strategy 93 5.24 Mean EV ﬂeet load proﬁle for weekdays under the Price-Taker charging strategy 94 5.25 Mean EV ﬂeet load proﬁle for weekends under the Price-Taker charging strategy 94 5.26 EV ﬂeet load proﬁle for a single weekday under the Price-Taker charging strategy 95 5.27 Average system price proﬁle for weekdays under the Price-Taker charging strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 5.28 Average system price proﬁle for weekends under the Price-Taker charging strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 5.29 Mean EV ﬂeet load proﬁle for weekdays under the MPC-ALM charging strategy 98 5.30 Mean EV ﬂeet load proﬁle for weekends under the MPC-ALM charging strategy 98 5.31 EV ﬂeet load proﬁle for a single weekday under the MPC-ALM charging strategy 99 xii 5.32 Average system price proﬁle for weekdays under the MPC-ALM charging strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99 5.33 Average system price proﬁle for weekends under the MPC-ALM charging strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 5.34 Mean EV ﬂeet load proﬁle for weekdays under the MDP-ALM charging strat- egy, assuming that price forecast errors are strongly correlated . . . . . . . . 101 5.35 Mean EV ﬂeet load proﬁle for weekdays under the MDP-ALM charging strat- egy, assuming that price forecast errors are weakly correlated . . . . . . . . . 102 5.36 Mean EV ﬂeet load proﬁle for weekends under the MDP-ALM charging strat- egy, assuming that price forecast errors are highly correlated . . . . . . . . . 102 5.37 Mean EV ﬂeet load proﬁle for weekends under the MDP-ALM charging strat- egy, assuming that price forecast errors are weakly correlated . . . . . . . . . 103 5.38 EV ﬂeet load proﬁle for a single weekday under the MDP-ALM charging strategy, assuming that price forecast errors are strongly correlated . . . . . 103 5.39 EV ﬂeet load proﬁle for a single weekday under the MDP-ALM charging strategy, assuming that price forecast errors are weakly correlated . . . . . . 104 5.40 Average system price proﬁle for weekdays under the MDP-ALM charging strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 5.41 Average system price proﬁle for weekdays under the MDP-ALM charging strategy, assuming that price forecast errors are weakly correlated . . . . . . 105 5.42 Total power system load proﬁle without EVs and with a load spike . . . . . 107 5.43 Market clearing energy prices for the day of the load spike . . . . . . . . . . 107 5.44 EV ﬂeet charging proﬁles for all charging strategies during a load spike . . . 108 5.45 System price proﬁle for all charging strategies during a load spike . . . . . . 108 6.1 Hourly energy prices used for the BESS MDP . . . . . . . . . . . . . . . . . 119 6.2 Optimal BESS policy for baseline charge rate P . . . . . . . . . . . . . . . . 119 xiii 6.3 Optimal BESS policy for regulation capacity B . . . . . . . . . . . . . . . . 120 6.4 The expected eﬀective-Ah throughput for each state, Ah ef f (s, π∗(s)) under the policy of section 6.2.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124 6.5 Optimal policy for baseline charge rate P with degradation cost and ξ = 1 . 125 6.6 Optimal policy for regulation capacity B with degradation cost and ξ = 1 . . 126 6.7 The expected eﬀective-Ah-throughput for each state, Ah ef f (s, π∗(s)), under the policy of section 6.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127 6.8 Expected BESS Energy Storage Capacity . . . . . . . . . . . . . . . . . . . . 129 6.9 Expected BESS Annual Revenues . . . . . . . . . . . . . . . . . . . . . . . . 130 7.1 Distribution of imbalance generation dispatched in BPA . . . . . . . . . . . . 133 7.2 Scatter plot of hourly AGC energy with the previous hour’s AGC energy (a) and the last observed AGC signal (b) . . . . . . . . . . . . . . . . . . . . . . 134 7.3 A non-linear relationship between the hourly AGC energy and the energy out (a) or energy in (b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 xiv List of Tables 2.1 Proposed SDP Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.2 G2V Simulation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 4.1 Summary of Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 5.1 Generator Parameter Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 5.2 Network Line Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.3 EV Parameter Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.4 Distribution of load across buses . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.5 TOU Energy Pricing Tariﬀ . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 5.6 Summary of SGRS simulation results . . . . . . . . . . . . . . . . . . . . . . 106 6.1 Proposed Procedure for Estimating NPV . . . . . . . . . . . . . . . . . . . . 128 6.2 Estimated NPV for all Cases . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 7.1 Fitted Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 xvxvi Chapter 1 Introduction 1.1 Background and Motivation In order to reduce harmful emissions from electric power generation, signiﬁcant amounts of wind and solar power are being installed in many countries. The power supplied by these renewable energy resources is intermittent and cannot be predicted perfectly, creating new challenges in safely and eﬃciently operating electric power grids. Electric power grids must become more robust, ﬂexible, and responsive to integrate a high percentage of intermittent renewable power generation. Electric grids are typically operated using a hierarchical control strategy. Economic scheduling of supply and demand happens on the minutes to hours timescale through market mechanisms. On the seconds to minutes timescale, the system AC frequency is maintained by a centralized controller which broadcasts an automatic generation control (AGC) signal to ﬂexible producers or consumers who have committed to providing frequency regulation ca- pacity over a time period. Decentralized droop control and inertial response halts frequency deviations on faster timescales. Many balancing areas have exhibited a trend of decreas- ing system intertia, resulting in larger frequency deviations from imbalances of supply and demand [1], leaving more frequency regulation to be done by AGC. 1 [2] shows that Independent System Operators (ISO) must procure additional capacity for ancillary services, such as frequency regulation, to compensate for production forecast errors for intermittent generation resources. Additional ancillary services can be provided by keeping more generation capacity online and idling. Alternatively, adjustment of ﬂexible power consumption could provide ancillary services without fuel costs or emissions. [2] also shows that the main mechanism through which wind power would eﬀect an electric grid is through hourly timescale ramping events. During such events, more ﬂexibility during economic dispatch could reduce the burden on AGC. Internet enabled two-way communications enable more demand side resources to interact with the electric grid at value and respond to electric grid conditions. The framework for value based participation of resources in the economic and stable operation of the electric grid is commonly referred to as transactive energy [3]. The GridWise Architecture Council deﬁnes transactive energy as such : “... techniques for managing the generation, consumption or ﬂow of electric power within an electric power system through the use of economic or market- based constructs while considering grid reliability constraints. The term trans- active comes from considering that decisions are made based on a value. These decisions may be analogous to or literally economic transactions.” Speciﬁc methods and algorithms for implementing transactive energy are actively being researched. One such method is Adaptive Load Management (ALM) and the Dynamic Monitoring and Decision Systems (DYMONDS) framework[4, 5]. In the ALM approach to transactive energy for distributed loads, load serving entities (LSEs) create price-sensitive energy bid functions based on physical modeling of appliances and the preferences of end- users. Plug-in battery powered electric vehicles (EVs) have become a mainstream reality in recent years, with U.S. sales topping 120,000 in 2014 [6]. However, EVs remain prohibitively expensive for most people. EVs also represent a new signiﬁcant load on the electric grid. If 2 EVs are not charged in an intelligent way, power system peak demands will grow, resulting in higher energy costs for all energy consumers [7]. EV owners only care that their battery has suﬃcient charge to support transportation, leaving signiﬁcant ﬂexibility for an intelligent EV to choose when and how much energy to charge. This gives EVs the potential to participate in transactive energy systems such as ALM, reduce their energy costs, and add ﬂexibility to the electric grid. Price responsive EVs in the ALM system could respond to hourly ramping events mentioned in [2]. [8] describes EVs as an ideal resource for providing frequency regulation service. If an EV commits to providing regulation capacity and varies its charge rate according to the AGC signal, an EV can actually earn revenue, greatly reducing the cost of ownership. Intelligent EVs have the potential to become a multi-functional energy storage resource for the electric grid. An EV is ﬁrstly a transportation resource, but can function as a price-sensitive, dispatchable, demand-response resource, or a frequency regulation resource for the electric grid. Another option for managing the balance of supply and demand in the electric grid is battery energy storage systems (BESS). BESSs have been deployed in the PJM ISO and in microgrid demonstration projects [9, 10]. The California Public Utilities Commission (CPUC) recently approved a mandate for utilities to procure 1.3 GW of energy storage resources by 2020 [11]. Also, the EV manufacturer Tesla Motors has begun sales of BESSs suitable for home or oﬃce behind-the-meter applications [12]. In order to extract maximum value from a BESS it must perform multiple functions for the electric grid. BESSs can charge at night and discharge during the day to perform what is called peak-shifting. A BESS proﬁts from peak-shifting by arbitraging the cycle of energy market prices. Peak- shifting will ultimately lower the high peak time energy prices for consumers. BESSs can simultaneously provide frequency regulation service to the grid. These two services conﬂict and so operations for multiple functions must be optimized considering the trade-oﬀ. Policy makers and investors must appropriately estimate the value of BESSs that perform multiple functions and degrade over time. 3 FERC Order 755 [13] requires ISOs to pay for ancillary services based on the accuracy of a providers response to the AGC signal. Fast responding resources such as EVs or BESSs can follow an AGC signal accurately, increasing their incentive to provide regulation capac- ity. When a multi-functional resource optimizes the tradeoﬀ between providing regulation service and providing transportation or peak-shifting, it must understand how providing frequency regulation will aﬀect its battery state of charge (SOC). Stochastic models of the AGC signal must be developed in order for multi-functional devices to properly optimize frequency regulation decisions. 1.2 Contributions In this section we summarize the contributions made in this dissertation. In chapter 2 we analyze the decision making problem of an EV that must fulﬁll a battery charging requirement by a deadline, but can also earn revenues by selling frequency regulation capacity. We formulate the decision making problem as a ﬁnite horizon model predictive control (MPC) problem and also as a Markov decision problem (MDP). These problem formulations assume that the EV decides on a ﬁxed quantity of energy to charge before market clearing prices are known. This approach assumes that the EV does not aﬀect energy prices and so the EV acts as a price-taker. The MDP approach directly considers uncertainty and autocorrelation in prices as well as the random eﬀect of the AGC signal on battery SOC. We also introduce a stochastic dynamic programming heuristic which allows for approximate optimization over a continuous space of charging decisions. Using stochastic process models of energy prices, regulation service prices, and the AGC signal, we simulate an EV being charged under the MPC and MDP approaches. Simulation results show that the MDP based decision making approach results in lower expected costs to the EV owner. This work resulted in two publications [14, 15]. As large numbers of EVs begin to charge from the electric grid, their aggregate charging 4 behavior will have an inﬂuence on energy prices. In chapter 3 we analyze the decision making problem of an EV that must fulﬁll a battery charging requirement by a deadline, but we relax the price taker assumption of chapter 2. We present two approaches that enable EVs to act as price-sensitive bidders in energy markets using the ALM framework. An MPC based approach to EV decision making is developed using the existing ideas of the ALM framework. Also, a new MDP based approach for EV decision making and aggregation in the ALM framework is developed. The MDP approach allows price sensitive bidding assuming correlation in price forecasting errors. In order to evaluate these two approaches to EV charging, we will develop a multi-agent DYMONDS energy market simulation in chapter 5. The EV charging methods described in chapters 2 and 3 assume that each time a driver ﬁnishes a trip, he knows when and where his next trip will be with certainty. This is not a common behavior today and may be a mental burden on EV owners. Therefore, in chapter 4, we develop a new approach to optimal EV charging that does not require drivers to input a transportation schedule. This optimal autonomous charging problem is formulated as an inﬁnite horizon average reward MDP. In this problem, we assume a Markov model of transportation behaviors and energy prices. Charging problems are formulated for plug-in hybrid electric vehicles (PHEVs) as well as battery only EVs. We analyze the resulting optimal charging policy for EVs, which is quite conservative. This work has been published in [16] In order to evaluate decision making methods for intelligent EVs and their eﬀect on energy markets, we develop a multi-agent DYMONDS energy market simulation in chapter 5. The simulation is developed using the Smart Grid in a Room Simultator (SGRS) distributed simulation architecture. The structure of the simulation as well as DYMONDS market agent models are presented in detail. We then use the simulation to evaluate the performance of various EV charging strategies when EV charging can signiﬁcantly eﬀect market prices. The MDP based ALM approach developed in chapter 3 is shown to charge with the lowest average 5 cost per energy charged of the tested strategies. In chapter 6 we propose leveraging the inﬁnite horizon MDP framework to estimate and Maximize the NPV of a grid-scale BESS that performs multiple grid functions and degrades with use. An MDP is formulated for maximizing BESS revenues by performing peak shifting and providing frequency regulation service. We demonstrate how this detailed model of short term operations can be used to estimate the long run rate at which revenues are earned without conducting simulations. We then develop a Markov reward process (MRP) model of battery degradation. This model is then used to estimate the long run rate of degradation under an operating policy. We also show how the MRP of degradation can be used to design an optimal operating policy that considers long run degradation costs. Finally, we present a new method for estimating and maximizing the net present value (NPV) of a BESS using the tools developed in this chapter.Some of the work presented in chapter 6 was published in [17], which won the best student paper and presentation award at the North American Power Symposium 2013, and in [18]. In this thesis, we investigate methods for the operation and valuation of multi-functional energy storage resources while considering uncertainty. One of the functions that we focus on is electric grid frequency regulation. In many of the methods presented in this thesis, we assume that models of the ISO’s AGC signal are available. To date, very little work has focused on analyzing the AGC signal as an exogenous input to be forecast. Therefore, in chapter 7 we investigate the application of statistical timeseries methods to predicting the AGC signal’s energy, which will aﬀect battery SOC. We also present nonparametric approaches to forecasting the AGC signal’s eﬀect on energy storage without perfect energy conversion eﬃciency. This work resulted in the publishing of [19]. 6 Chapter 2 Stochastic Optimization of Grid to Vehicle (G2V) Frequency Regulation Capacity This chapter investigates stochastic optimization methods for the optimal scheduling of charging and frequency regulation capacity by an electric vehicle (EV) in a smart electric grid environment. We formulate a Markov decision problem (MDP) to minimize an EVs expected cost over a ﬁxed charging horizon. We account for both Markov random prices and a Markov random eﬀect from the automatic generation control (AGC) signal. We also propose a heuristic enhancement to the classical discrete stochastic dynamic programming method for the solution of the MDP. This heuristic allows optimization over a continuous space of decision variables via linear programming at each state. Simple stochastic process models are built from real data and used to simulate the implementation of the proposed method. The proposed method is shown to outperform deterministic model predictive control in terms of average EV charging cost. Work shown in this chapter was ﬁrst published in [14] and [15]. 7 2.1 Introduction EVs are a ﬂexible load that could be controlled in order to provide ancillary services to the electric grid. EV drivers want to drive when and where they desire without waiting for the battery to charge, but would also like to charge their batteries for minimum cost. Cost is a major barrier to EV adoption, so reducing the cost of EV ownership is a high research priority. In liberalized electric power systems, such as PJM, ancillary services are procured through a market. If an EV provides ancillary services to the electric grid, the EV owner would earn revenue at the market price, oﬀsetting the cost of charging. One ancillary service that EVs are well suited to provide is secondary frequency reg- ulation, also simply referred to as regulation. An EV could eﬀectively provide regulation service without discharging into the electric grid by committing to a baseline charge rate and a capacity for regulation before the start of a regulation service period, usually lasting one hour. For the duration of the contracted period, the EV would receive an automatic generation control (AGC) signal, which is broadcast by the ISO. The EV would then vary its charging power according to the AGC signal and its commitments. This scheme is known as grid to vehicle (G2V) regulation. If the EV also discharges into the grid, the scheme would be called vehicle to grid (V2G) regulation. Recent literature has investigated the potential for V2G in a assisting integration of variable renewable resources in the electric grid [20], [8]. The feasibility of the concept has also been demonstrated in hardware [21]. Other work has focused on implementable methods for optimizing EV charging and regulation capacity decisions. [22] develops a deterministic model predictive control (MPC) problem for V2G charging of a single EV. Some research has focused on the charging and regulation capacity bids of an EV aggregator. [23] investigates various optimization models to be used by an EV aggregator. The models are formulated as deterministic MPC problems and are solved using linear programming. The problems incorporate constraints that might be imposed on the aggregate consumption of a ﬂeet of 8 EVs. [24] also takes a deterministic MPC approach to the V2G EV aggregator problem. An EV providing ancillary services in a deregulated market environment faces many forms of uncertainty. Market prices for energy and regulation service as well as the AGC signal are unknown before an EV would commit to providing regulation for some contract period. Providing regulation service would make the battery’s future state of charge (SOC) uncertain. This motivates the use of stochastic optimization methods when determining an EV’s baseline charge rate and capacity for regulation. Stochastic optimization, which directly considers parameter uncertainty, results in lower expected realized costs than deterministic methods, which simply optimize using the expected values of parameters [25]. Optimization and control under uncertainty is a mature ﬁeld with rich theory and various applications as introduced in [26, 25, 27] as well as many other references. Recently, attempts have been made to apply stochastic optimization methods to V2G and G2V charging problems for single EVs. [28] describes the V2G problem as a Markov decision problem (MDP) with uncertain energy prices and a small set of available control actions. Q-learning is used to create a control policy in an online and model-free way. It is not clear if this method would outperform other methods in the literature or how long it would take to train good control policies in the real world. [14] formulates a G2V MDP for a single EV, and also provides an approximate solution method based on mixed integer linear programming and stochastic dynamic programming (SDP) backwards recursion. The MDP model presented in [14] directly considers that the integrated energy of the AGC signal will have a random eﬀect on battery SOC. Some advantages of a stochastic approach over a deterministic dynamic programming approach are demonstrated in [14] . This chapter extends the existing literature by formulating the G2V charging problem for a single EV as an MDP with multiple sources of uncertainty. The work presented here could easily be modiﬁed for the V2G situation. We optimize EV charging and regulation capacity decisions assuming that the hourly price of energy, the hourly price of regulation service, and the integrated hourly energy of the AGC signal follow Markov random processes. Addi- 9 tionally, we introduce an intuitive approximate SDP method which allows for optimization over a continuous space of charging and regulation capacity bids. This approximate SDP recursion is applicable to any convex sequential decision making problem under uncertainty. A parallelized implementation of the proposed method is described. Finally, we demonstrate that the proposed method results in lower expected charging costs than the deterministic MPC method. Although the proposed method is more computationally demanding than the deterministic MPC method, we show that it could still be practical to use for hourly decision making. In this paragraph we present an outline of the remainder of the chapter. In the next section we formulate the G2V problem as an MDP with multiple sources of uncertainty. In section 2.3, we brieﬂy review the available approaches for solving multi-stage stochastic optimization problems. This is followed by the development of the proposed approximate SDP approach in section 2.4. In order to simulate the implementation of the proposed method, we analyze real data and construct models of the random processes of the prices and AGC signal in section 2.5. In section 2.6 we describe our simulation experiments and interpret our results. 2.2 Problem Formulation In this section, we formulate the EV’s G2V decision making problem as an MDP. First, however, we describe the convention for notation used throughout this thesis. Random variables are noted by bold font while a speciﬁc realization will be the same variable without bolding. Time indexing is done with brackets such as in P [h], function arguments are inside of parentheses as in f (x), varible naming is done in superscripts such as in P min, and indexing of set elements is done with subscripts such as ei. 10 2.2.1 Decision Making Scenario In liberalized energy markets, generators and loads determine the amount of regulation ca- pacity which they are willing to provide. It is the responsibility of the local electrical grid ISO to ensure that an adequate amount of regulation capacity has been procured. The ISO must also determine an AGC signal which maintains the systems alternating current frequency. The resources that have committed to providing regulation capacity are then obligated to respond to the ISOs AGC signal. In this chapter we analyze a decision optimization problem from the perspective of an EV that is a direct market participant. Although, we assume that the EV charges with perfect eﬃciency in this chapter, the approaches presented here could easily be modiﬁed for case of lossy charging. Our goal is to minimize the charging costs for a single EV owner who is able to provide G2V service. In this chapter, we assume that an EV bids ﬁxed quantities as a price-taker in both the energy and ancillary services markets. We assume that individual EVs are either operating in a smart electric grid where they can bid directly into markets, or that they communicate their bids to a 3rd party aggregator, who then bids the sum of many EVs decisions into the markets. This aggregation step would be necessary to provide G2V service in todays markets because an individual EV does not consume enough power to participate. The focus of the work in this chapter is a decision making method for a single EV, and not on aggregation or system level eﬀects. We assume that EVs make decisions without coordination. There are situations that would warrant the coordination of charging and regulation capacity bids, such as low voltage in distribution networks or market power. We assume that the ISO knows the total capacity for regulation in the system and computes an AGC signal for restoring the electric grids AC frequency to nominal on a 5 minute basis. The AGC signal can then be normalized to the total regulation capacity and broadcast to all participating generators or ﬂexible loads. When a generator or load speciﬁes a regulation capacity, it speciﬁes how much it is willing to vary its power generation 11 or consumption. A generator would then change its power output by the normalized AGC signal multiplied by its agreed upon regulation capacity. Loads would respond to the negative of the normalized AGC signal, which is intended for generators. We assume that when an EV is plugged in at the driver’s home or workplace, the EV driver communicates a planned unplugging time to a smart EV charger. We assume that the EV driver agrees to not unplug the EV before this scheduled time, or else he might face some ﬁnancial penalty. At the beginning of each hour, h, while the EV is plugged in, the smart charger decides on and commits to a baseline charge rate, P [h] (kW), and capacity for regulation, B[h] (kW), before knowing the true hourly energy price, regulation service price, or AGC signal. The smart EV charger should choose P [h] and B[h] in such a way that it minimizes the total expected cost to charge the EV to maximum SOC, e max, by the known unplugging time. In the following subsections we will develop the ﬁnite horizon MDP that a smart charger must solve in order to determine the best bids, P [h] and B[h], to commit to at each hourly decision epoch. The theory of ﬁnite horizon MDPs is developed in [27]. 2.2.2 Decision Epochs Charging and regulation capacity decisions are made at each hourly decision epoch h of the ﬁnite decision-making horizon h ∈ {1, . . . , H}, where H is the number of hours the EV will be plugged in. 2.2.3 System State The system state vector s[h] = (e[h], y[h − 1], ρ r[h − 1], ρ e[h − 1]) ∈ S[h] includes the EV battery state of charge e[h] (kWh), the last observed hourly time integral of the normalized AGC signal y[h − 1] (hr), the last observed hourly price of regulation capacity ρ r[h − 1] ($/kW), and the last observed hourly price of energy ρe[h − 1] ($/kWh). The battery SOC has a feasible range of [0, e max]. The optimal charging and regulation decisions will depend 12 on the values of each dimension of the state vector. for simplicity of notation, we will often refer to the component dimensions of s without the timestep indexing [h] and [h − 1] as s = (e, y, ρr, ρ e). 2.2.4 State Dynamics Given the hourly baseline charge rate P [h] and the hourly regulation capacity B[h] decisions, the random charge rate at any time within the hour is given by P[t] as determined in (2.1), where x[t] (unitless) is the random normalized AGC signal broadcast by the ISO. x[t] is assumed to be normalized so that it takes on values between −1 and 1. P[t] = P [h] − x[t]B[h] (2.1) On an hourly basis, the battery SOC evolves according to (2.2), which is referred to as a state transition function. y[h] (h) is the hourly time integral of the normalized AGC signal, x[t], and is uncertain when the decisions are made. Realizations of y[h] can take on any value between −1 and 1 with some probability distribution. This makes the next battery SOC, e[h + 1] , uncertain with a distribution that depends on our decisions as well as the probability distribution of the AGC signal. e[h + 1] = e[h] + ∆hP [h] − y[h]B[h] (2.2) If we separate out the exogenous components of the state vector, the full state vector can be written as s[h] = (e[h], s x[h]) where the exogenous state vector is given by sx[h] = (y[h − 1], ρ r[h − 1], ρ e[h − 1]). Future values of sx are modeled as a vector of random variables sx which has statistical dependence on its previous value as in (2.3). f is a continuous probability density function. We refer to the random variables in s x as state variables because the last observed values give information that is useful for optimal decision making. These are modeled as exogenous random variables which our decisions do not eﬀect. s x[h + 1] ∼ f (sx[h]) (2.3) 13 Hourly electric energy prices, ancillary service prices are known to have a statistical depen- dence on recently observed values [29]. Our own analysis of the hourly dependence for an AGC signal was shown in chapter 7 and [19]. Markovian dependence is a simple approxima- tion of the real behavior of these random variables. In reality, electric energy prices depend on a variety of seasonal and exogenous factors not included in our state vector. Our problem has a ﬁnite horizon on the scale of half a day, so the state distributions can be estimated conditionally given the state of other factors known at time h = 1. We assume that the state and time of day captures the majority of the information that would be useful in predicting the next hourly prices and AGC signal. 2.2.5 Actions P [h] and B[h] can be referred to together as the decision or action vector a = (P, B). The constraints (2.4)-(2.9) describe the set of feasible action vectors given the system state at decision epoch h, A[h](s). Over the course of the hour, the instantaneous charge rate may take any value between (P [h] − B[h]) and (P [h] + B[h]). Since we are analyzing a G2V scenario where the EV does not discharge into the grid, the chosen action vector should not allow the possibility of a negative charge rate, giving constraints (2.4)-(2.6). The choice of P [h] and B[h] is also constrained by the maximum charge rate of the EV and smart charger, P max (kW) as in (2.7). If the battery SOC, e[h], were to reach maximum SOC, e max (kWh), before the end of the hour, the EV would stop charging and would not be able to modify its charge rate in a way that eﬀectively provides regulation service to the grid. This would violate the contract to provide regulation service for the whole hour. We add constraint (2.8) to avoid violation of the regulation service contract. ∆ h (h) is the time-step length of 1 hour. We assume that the EV driver requires the battery SOC to be e max by the scheduled unplugging time h = H + 1. In order to guarantee that the EV will be fully charged by the known unplugging time, we add decision constraint (2.9). In this constraint, emin[h + 1] 14 (kWh) is the minimum SOC needed at the start of the next hour to ensure that the EV SOC will be able to reach emax before unplugging. e min[h + 1] can be calculated for each hour based on and the number of hours remaining until the EV unplugs and P max. 0 ≤ B[h] (2.4) 0 ≤ P [h] (2.5) B[h] ≤ P [h] (2.6) B[h] + P [h] ≤ P max (2.7) e[h] + ∆hP [h] + ∆hB[h] ≤ emax (2.8) e[h] + ∆hP [h] − ∆ hB[h] ≥ emin[h + 1] (2.9) 2.2.6 Cost Function Given that the EV was in some state s[h] at decision epoch h and an action vector a was chosen, the EV will incur random cost or reward r[h](s, a) as shown in (2.10). This represents the total cost incurred during the period between decision epoch h and h + 1. The expected value of r[h](s, a) is ¯r[h](s, a). If we assume that the random variables are conditionally independent given sx[h − 1], then the expectation of (2.10) is given by (2.11). r[h](s, a) = ρ e[h](∆ hP [h] − y[h]B[h]) − ρ r[h]B[h] (2.10) ¯r[h](s, a) = ¯ρe[h](∆ hP [h] − ¯y[h]B[h]) − ¯ρr[h]B[h] (2.11) 2.2.7 Markov Decision Problem J[h](s), commonly called the cost to go, is the expected total future cost of having some state s at decision epoch h and making optimal decisions for the remainder of the problem horizon. The cost to go for when the EV ﬁrst plugs in is the result of solving the ﬁnite horizon MDP given in (2.12). Solving the MDP also results in an optimal decision-making 15 policy π∗. For ﬁnite horizon MDPs, a decision-making policy π is a collection of decision- making rules π = {d[h](s), . . . , d[H](s)} that take in the current state and return a decision or action vector. A decision-making policy must be in the set of feasible decision-making policies Π, ensuring that d[h](s) = a ∈ A[h](s), ∀s ∈ S[h], ∀h. J[1](s) = min π∈Π E π [ H∑ h=1 ¯r[h] (s, d (s)) \f \f \f \f \f s[1] ] (2.12) 2.3 Possible Solution Approaches In reality, the problem in 2.12 involves continuous states, random variables, and space of available decisions given by (2.4)–(2.9). Such problems are very diﬃcult to solve or even approximate. Existing solution approaches are examined in this section. Ultimately, each examined method leaves something to be desired, so we develop a new heuristic approach in the next section. A simple sub-optimal approach to decision making is to approximate the problem in (2.12) with a deterministic MPC problem, (2.13), where uncertain parameters are replaced by their joint expected values given s[1]. The state transition equation (2.2) is simply replaced by the deterministic state transition equation in (2.14). This method was used in [23] and [24] for the V2G aggregator problem. The method is simple and fast, but it results in sub-optimal control decisions. In fact, the optimal decisions for a deterministic optimization problem are not guaranteed to be anywhere near the optimal decisions for the true stochastic problem [25]. J M P C[1](s) = min P [h], B[h], e[h+1] ∀h H∑ h=1 ¯ρe[h](∆ hP [h] − ¯y[h]B[h]) − ¯ρr[h]B[h] (2.13) s.t. (2.4)–(2.9), (2.14) e[h + 1] = e[h] + ∆hP [h] − ¯y[h]B[h] (2.14) The problem in (2.12) also ﬁts into the framework of stochastic linear programming 16 (SLP). The SLP framework is most powerful when there are many state and decision vari- ables, but only a few decision stages. When uncertain data have correlation over time, solving multi-stage SLP problems is impractical. This is because SLP problems grow exponentially in the number of decision stages. They become very diﬃcult to even approximately solve by using scenario reduction [30] or nested Benders decomposition [25, 31]. It is common practice to approximate an MDP that has continuous states and decision variables with a discrete MDP, having only discrete sets of possible states and decisions. This approach is used in [32] for an inﬁnite horizon MDP. [32] also demonstrates that it is often necessary to develop approximation schemes when applying SDP to real problems. This reference cannot apply the discrete methods of [27] directly because the state transition equations do not necessarily lead to states that have been evaluated. Instead they rely on linear interpolation for approximating the cost to go at the next state. This encourages us to ﬁnd an SDP approximation scheme which enables us to optimize over a continuous space of actions. The management of hydropower reservoirs has motivated practical solution methods for solving multistage stochastic optimization problems with continuous control variables. These solution methods have been developed by recognizing the shared theory of the MDP and SLP frameworks. [33] describes how hydropower management problems can be decomposed by decision stages in a fashion similar to discrete MDPs. It also shows that continuous cost to go functions can be created and updated using SLP theory. The stochastic dual dynamic programming (SDDP) method of [33] can be thought of as a speciﬁc implementation of nested Benders decomposition, which avoids the discretization of controlled endogenous state variables. [34] extends [33] and propose solution methods which consider uncertain and Markovian energy prices. These solution methods approximate the exogenous random process for price with a ﬁnite set of states and transition probabilities, and are described as a combination of SDP and SDDP. However, the methods proposed in [33] and [34] cannot be directly applied to the G2V 17 problem. These methods do not allow uncertain decision variable coeﬃcients in the state transition equation. For the G2V problem, equation 2.2 shows a random variable, y[h], multiplying a decision variable, B[h], in the state transition equation. Therefore, we develop an approximate SDP scheme which is inspired by the hydropower operations literature to leverage SLP theory. 2.4 Proposed Stochastic Dynamic Programming Solu- tion Heuristic We propose an SDP algorithm for minimizing an approximation of the expected future costs given by Problem 1. The proposed algorithm consists of a single backwards recursion over a discrete set of possible states. We propose an intuitive way to optimize over a continuous space of decisions given each state. We begin by approximating (2.12) with a discrete MDP and then extending it. 2.4.1 Discrete MDP Approximation and SDP Since our random variables are truly continuous we ﬁrst assume that the stochastic processes for the energy price, regulation service price, and AGC signal are well approximated as discrete and Markovian. This allows us to discretize the random exogenous state vector into a discrete set of possible values, sx[h] ∈ ˜S x[h]. To create a discrete MDP, the range of possible values for the SOC, must also be discretized into a set of values e[h] ∈ ˜E[h] from which we can guarantee e[H +1] = e max when the vehicle unplugs. A discrete MDP optimizes over a discrete set of decisions, a ∈ ˜A[h](s). A discrete MDP also requires state transition probabilities of the form Pr[h] (sj | si, ak), the probability of transitioning from state si at time h to state sj at time h + 1 when action ak was chosen. This discrete MDP can then be decomposed into hourly decision problems by the principle of optimality, yielding the 18 recursive equation in (2.15). The SDP backwards recursion solves the MDP by recursively solving (2.15). The procedure begins at the ﬁnal decision epoch H and evaluates (2.15) for J disc[H](si) for all states i in ˜S[H]. The timestep is decremented to H − 1 and the evaluation is repeated. The decrementing and evaluating repeats until the current decision time, h = 1 is reached. Since the state is known for h = 1, only one state must be evaluated. J disc[h](si) = min k ¯r[h](si, ak) + ∑ j Pr[h] (sj | si, ak) J disc[h + 1](sj) (2.15) 2.4.2 Approximate SDP with a Continuous Space of Actions We now turn our attention to the case where decisions can take any value in the feasible region of (2.4)-(2.9). In this case e[h + 1] is not necessarily an element of ˜E[h + 1], the discrete set of SOCs that were evaluated in the previous step of the backwards recursion. We propose using a piecewise linear convex function of the SOC as an approximation of the cost to go. This approach will allow the approximation of expected future costs for any action in the feasible space and will allow the use of linear programming methods to ﬁnd the best action given some state. This approximation method can be used more generally to create an approximate cost to go function of controlled endogenous states, such as e[h], whenever the recursive equation of an MDP is a convex optimization problem. The recursion shown in (2.16) is linear programming problem based on (2.15) which enables optimization over a continuous space of actions. ˆJ[h](si) is the approximate cost to go which approximates expected future costs given some state. In order to solve (2.16) given some state si at decision epoch h, one must know the inequality constraint coeﬃcients of (2.18), αk,j[h + 1] and βk,j[h + 1], the expected values of random variables for immediate cost function ¯r[h](si, a), and the state transition probabilities Pr[h](sx j | sx i ) from exogenous state sx i at decision epoch h to exogenous state sx j at epoch h+1. For some decision P [h] and B[h], the next SOC when the exogenous state transitions to sx j would be ˜ej as given in (2.17). ˜ej is not necessarily one of the states that was previously evaluated in the backwards recursion, 19 so we use the variable ˜Jj to approximate the cost to go at that SOC. For each outcome j of the exogenous state, the constraints in (2.18) form a piecewise-linear convex function in the dimension of SOC. ˜Jj is minimized subject to (2.18), so ˜Jj will take the value of the largest constraint corresponding to outcome j. An instance of the recursive equation in (2.16) can be solved over a continuous space of decisions using linear programming methods. ˆJ[h](si) = min P [h], B[h], ˜ej , ˜Jj ¯r[h](si, a) + ∑ j Pr[h](sx j | sx i ) ˜Jj (2.16) s.t. 2.4–2.9, 2.17, 2.18 ˜ej = ei[h] + ∆hP [h] − yj[h]B[h], ∀j ∈ ˜S x[h + 1] (2.17) ˜Jj ≥ αk,j[h + 1] − βk,j[h + 1]˜ej, ∀j ∈ ˜S x[h + 1], ∀k ∈ ˜E[h + 1] (2.18) At each decision epoch of the proposed SDP backwards recursion, one solves for ˆJ[h](si), ∀i ∈ ˜S[h]. This also yields the inequality coeﬃcients, αi[h] and βi[h] as will be explained next. The inequality coeﬃcients are then used in the next earlier timestep of the backwards recursion to represent a piecewise linear convex approximation of the cost to go in the dimension of SOC for each exogenous state. 2.4.3 Derivation of Value Function Inequality Coeﬃcients An instance of the linear programming problem in (2.16) can be rewritten in the general form (2.19) with parameter matrices W and A, vector T , and price vector q. The current stage decision vector is shown as x, and the given SOC, e[h], is represented as z. Solution of (2.19) given some z0 results in cost Q(z0) and the optimal dual variable vector λ0. Q(z0) = min x {qT x | Ax = W − T z0 : λ0} (2.19) 20 A lower bound for the primal function Q(z) for all z can be constructed from the optimal dual variables of (2.19). Construction of this lower bound is shown in (2.20)-(2.22) [25]. β0 = λT 0 T (2.20) α0 = λ T 0 W (2.21) Q(z) ≥ α0 − β0z (2.22) We can calculate the coeﬃcients αj,k[h] and βj,k[h] for each of the constraints in (2.18) after solving (2.16) given state sj,k = (ek, s x j ). The constraints in (2.18) form a piecewise linear convex function of battery SOC for each possible outcome of sx. Because the constraints in (2.18) are an under approximation of ˆJ[h + 1](s), ˜Jj will be less than or equal to ˆJ[h + 1](s) with the same SOC as ˜ej. The transition probability weighted sum of ˜Jj calculates the expectation of approximate future costs with a continuous space of decisions. In order to solve for the initial decision when h = 1, approximate cost to go functions must be constructed recursively for h = H, . . . , 2. 2.4.4 Reduction of Problem Size The problem in (2.16) can grow in size very quickly with the reﬁnement of the discretization of states. If each exogenous state dimension is discretized into K values, then the number of possible next states is | ˜S x[h]| = K 3. Constraint set (2.18) consists of | ˜S x[h]| × | ˜E[h]| constraints. This motivates ﬁnding some way to reduce the size of (2.16) . In order to reduce the size of (2.16) at decision epoch h and state si,j,k,l[h] = (ei[h], yj[h − 1], ρ r k[h − 1], ρ e l [h − 1]), we propose taking the expectation of the approximate cost to go function coeﬃcients with respect to ρ r and ρe, reducing the dimensionality of the ap- proximate cost to go function from four to two. Here, we index the inequality coeﬃ- cients as αm,n,o,p[h + 1] and βm,n,o,p[h + 1] resulting from the solution of (2.16) given state sm,n,o,p[h + 1] = (em[h + 1], yn[h], ρ r o[h], ρ e p[h]). We use the state transition probabilities of the Markov random processes to compute the expectation of the inequality constraint coeﬃcients 21 as shown in (2.23) and (2.24), assuming that the random variables are independent. αm,n[h + 1] = ∑ o ∑ p Pr[h] (ρr o | ρr k) Pr[h] ( ρe p | ρ e l ) αm,n,o,p[h + 1] (2.23) βm,n[h + 1] = ∑ o ∑ p Pr[h] (ρr o | ρr k) Pr[h] ( ρe p | ρ e l ) βm,n,o,p[h + 1] (2.24) Using the reduced number of inequality constraints in (2.23) and (2.24), we formulate the new approximate SDP recursive equation shown in (2.25). (2.25) is a linear programming problem for each state s[h]. ˆJ[h](si,j,k,l) = min P [h], B[h], ˜en, ˜Jn ¯r[h](si,j,k,l, a) + ∑ n Pr[h](yn | yj) ˜Jn (2.25) s.t. 2.4–2.9, 2.26, 2.27 ˜en = ei[h] + ∆hP [h] − yn[h]B[h], ∀n (2.26) ˜Jn ≥ αm,n[h + 1] − βm,n[h + 1]˜en, ∀m, ∀n (2.27) 2.4.5 Proposed SDP Algorithm Assuming that each exogenous state is discretized into K values and the SOC is discretized into I values the proposed SDP algorithm is a backwards recursion that successively solves I × K 3 instances of the linear programming problem (2.25) for each decision epoch. Using a modern multi-core desktop computer, we can solve the batch of problems for each decision epoch in a parallel fashion. The approximate cost to go constraint coeﬃcients of 2.27 are then calculated and incorporated into the next batch of earlier decision problems, back propagating expected future costs. This is repeated until the recursive procedure reaches the ﬁrst decision epoch. At the ﬁrst decision epoch, only one instance of (2.25) must be solved, as the current SOC and previously observed exogenous states are known. This decision can then be submitted to an aggregator or ISO. 22 I.) For h = H, . . . , 2 1.) Parallel For si,j,k,l[h] ∈ ˜S[h] 1) If h ̸= H calculate αm,n[h + 1], and βm,n[h + 1] as in (2.23) and (2.24) 2) Solve the linear program (2.25) 3) Calculate αi,j,k,l[h], βi,j,k,l[h] End Parallel For End For II.) Solve (2.25) for ˆJ[1](s) Table 2.1: Proposed SDP Algorithm 2.5 Stochastic Process Models for Simulation In order to simulate an EV charging by our proposed method, we construct models of the stochastic processes of the exogenous data. These models will allow us to generate random realizations from continuous distributions and evaluate EV charging methods by simulation. Given these continuous stochastic process models, we must estimate discrete Markov models of the random variables to solve the MDP by the proposed dynamic programming recursions in (2.16) or (2.25). Also, we will use the continuous stochastic process models to estimate expected values for input into the MPC charge optimization method. 2.5.1 Estimating Continuous Stochastic Process Models Models for energy price and regulation service price were built from PJM ISO market data from the year 2011 [35]. 5 weeks of AGC signal data was also gathered from PJM ISO [35]. We made slightly diﬀerent assumptions in modeling each stochastic process. The random variables are assumed to be independent of each other. In our simulation experiments, we assume that the EV pays the real-time hourly energy market price for energy consumed. In order to model real-time energy market prices, we ﬁrst assume that day-ahead energy markets 23 are the best predictors of real-time prices available a day in advance. This motivates building a model of the diﬀerences between real-time and day-ahead prices, which can then be added back to the known day-ahead prices. Real-time energy prices are known to exhibit higher variance during peak load hours, when it is more likely that the electric grid is bound by capacity constraints, than during low load hours. And so, we modeled the energy price diﬀerences using a unique marginal distribution for each hour of the day. We use empirical cumulative density functions (CDFs) to model each marginal distribution [36]. In order to model Markovian dependence in the price diﬀerences, a Gaussian copula model was ﬁt to each pair of distributions for adjacent hours of the day. The Gaussian copula uses rank correlation to model the dependence between random variables of arbitrary marginal distributions [36]. By ﬁtting a diﬀerent copula to each pair of distributions, we model the dependence as varying with hour of the day. This model allows us to simulate realizations of the next price diﬀerence given the diﬀerence of the current hour. We can then add this diﬀerence to the day-ahead price and call it a realization from the real-time price distribution. The hourly regulation service price appears to exhibit cyclical daily patterns. This moti- vates modeling the regulation service price with a unique marginal probability distribution for each hour of the day. An empirical CDF was used to estimate the unique marginal distri- butions in each hour of the day. A Gaussian copula model was ﬁt to each pair of distributions for adjacent hours of the day. Due to the limited amount of data available, we modeled the AGC signals normalized energy, y[h], with the same marginal probability distribution in all hours. The distribution used is the empirical CDF of the collected data. y[h] is restricted to take values between -1 and 1. A single Gaussian copula was ﬁt to model the dependence between y[h] and its last observed value. 24 2.5.2 Simulation Input Data The proposed SDP recursions in (2.16) or (2.25) require a discrete Markov model for each exogenous random state. In order to create a discrete Markov model, we ﬁrst estimate the states of the model by discretizing each random variables distribution in each hour. This is done by evaluating each distributions inverse CDF at kequally spaced values between 0 and 1, exclusive. For the Markov model of energy price diﬀerences, we simply add the error state values to the day-ahead prices to get real-time price states. We must also estimate state transition probabilities, Pr[h] (sx j | sx i ), for each state of the discrete Markov process. In order to estimate transition probabilities, we used a Monte Carlo and maximum likelihood estimation approach. Given each possible state of the dis- crete random processes, we generate 500,000 conditional realizations of the next hours data with the continuous distribution stochastic process models of section 2.5.1. The generated realizations are binned according to which discretized state has the closest CDF value. Bin counts are divided by the total number of generated realizations to yield estimated state transition probabilities [37]. For each state of the Markov models, we must estimate conditionally expected next values of random variables. these expected values are then used in the cost function of the SDP recursions, ¯r[h](s, a). The same generated realizations used to estimate state transition probabilities are used to estimate expected values. The conditionally expected values can be estimated by simply taking the mean of the generated values. During the simulation of EV charging, realizations of random variables will be generated from the continuous stochastic process models after each charging decision is made. The EV will then make a charging decision given the new state sx[h]. If an EV is charging using the proposed SDP algorithms, new conditionally expected values of random variables and transition probabilities must be estimated for only this new state at time h. The EV can then solve one instance of the recursive problem in (2.16) or (2.25) using previously computed 25 value function inequality constraint coeﬃcients. If the EV is making charging decisions with the MPC approach, then a new forecast of random variables must be made for the remaining planning horizon from h to H. These forecasts are made using a Monte Carlo approach. 500,000 traces are generated for each random variable over the remaining planning horizon. The mean value of each random variable at each time is used as its forecast value for that time period. 2.6 Simulation Experiments We investigated the value of using the proposed SDP approach for determining G2V charg- ing and regulation bids as opposed to using a deterministic MPC approach. Using both approaches, we simulated 20,000 trials of an EV charging overnight given the same vehicle parameters, initial state, and day-ahead energy prices. The mean charging costs and dis- tributions of charging costs are compared for the diﬀerent methods. We also compared the SDP algorithm solution times when using the dynamic programming heuristic in (2.16) or (2.25). The simulation procedure and results are described below. 2.6.1 Simulation Procedure After the initial input data is calculated, we use the procedure presented in this subsection to simulate each of the 20,000 EV charging trials. For the proposed SDP recursions in (2.16) or (2.25), a single backwards recursion computes all of the approximate cost to go inequality coeﬃcients needed to solve for any charging or regulation bid of the ﬁxed charging horizon. Given the known current state, we then solve an instance of (2.16) or (2.25) for the ﬁrst SDP based charging and regulation capacity decisions. For the ﬁrst MPC based charging and regulation capacity decisions, an instance of (2.13), which does not require a backwards recursion to be completed, is solved. After the bids are submitted, the continuous distribution stochastic process models of section 2.5 are used to generate the next realization 26 of each random state variable. Then running total incurred costs and current states are updated. Given the new state, data for the next decision epochs instance of (2.13), (2.16), or (2.25) must be created. For the SDP method, new state transition probabilities and expected exogenous state values are estimated for only the current decision epoch using as described in subsection 2.5.2. Using these new state transition probabilities, the weighted average constraint coeﬃcients must be recalculated by (2.23) and (2.24). For the MPC method, expected values of the exogenous states are estimated for the remainder of the charging horizon given the current state as was described in subsection 2.5.2. Given the new state and data, (2.13), (2.16), or (2.25) is solved for new bids. This ﬁxed horizon simulation procedure continues in each simulation trial until either the EV reaches maximum SOC or the unplugging time is reached. All experiments were conducted on a desktop PC with an Intel 3930k 6 core processor and 12GB of RAM. Simulations were implemented in MATLAB, and CPLEX was used to solve linear programs. During each decision stage of the SDP algorithms backwards recursions, the many instances of linear program (2.16) or (2.25) were solved in parallel. This is done using MATLABs Parallel Computing Toolbox. All other steps of the SDP algorithms are run in serial. In our experiments, we solve an example problem consisting of 12 hourly decision stages, with H=12. Our EV plugs in at 8 p.m. and unplugs at 8 a.m.. The EVs initial SOC is 8 kWh and must charge to emax= 24 kWh. The maximum charge rate is P max=7 kW. These values are typical of EVs currently on the market [38]. Typical January Day-ahead energy prices are used in simulating energy prices. The SDP based methods were implemented with the SOC discretized into |I| = 7 states and each exogneous random variable discretized into K = 12 states. Due to memory lim- itations, this is the ﬁnest discretization we successfully implemented for the SDP routine using (2.16) . During the backwards recursion, 12 processing threads are used to solve linear 27 Figure 2.1: Example EV charging simulation trial results programs based on (2.25) in parallel. Again, due to memory limitations, the number of processing threads was limited to 4 when executing the backwards recursion with (2.16) . We suspect that the memory limitations are partially due to the amount of simulation data we saved for analysis and partially due to how the Parallel Computing Toolbox clones data for parallel processing. 2.6.2 Results Fig. 2.1 shows the battery SOC trajectory resulting from a single simulation trial of an EV charging and providing frequency regulation service. The solid black line shows how the SOC would evolve if the battery charged at a rate of P [h] in each hour. The solid red lines show the actual SOC trajectory including the eﬀect of following the AGC signal. The random eﬀect of following the AGC signal is most noticeable following 11 p.m. and 4 a.m. The blue lines show the maximum and minimum trajectories that the SOC could take over the hours when the EV provides frequency regulation. The dashed red line at 24 kWh shows e max. Figs. 2.2 and 2.3 show the evolution of prices during this simulation trial. Day-ahead energy prices are shown as red circles in ﬁg. 2.2, while the hourly means of the regulation service price distributions are shown as red circles in ﬁg. 2.3. The actual prices observed are shown with blue cross marks while the expected price, given the last hour’s value, is shown with a 28 Figure 2.2: Example energy price simulation Figure 2.3: Example regulation service price simulation 29 black square. Table 2.2 summarizes the results of the three sets of simulation trials. Because the costs are the result of a stochastic simulation, the mean cost varies with each batch of simulations. In order to make a stronger statement about the relative performance of the evaluated methods, we used basic statistics to estimate a 95% conﬁdence interval for the true mean cost of using each method. The upper and lower bounds of this conﬁdence interval are given in Table 2.2 in the rows labeled C.I. upper bound and C.I. lower bound. For this example problem, the mean EV charging cost when using the proposed SDP method with (2.25) is 22% lower than the mean cost incurred when using MPC. The 95% conﬁdence interval for the mean cost when using SDP is completely below the conﬁdence interval for the mean cost when using MPC. Performing the SDP routine with the recurision in (2.25) instead of that Method Used SDP SDP MPC Problem (2.16) (2.25) (2.13) Expected Cost ($) 0.056 0.057 0.072 C.I. Upper Bound 0.060 0.061 0.077 C.I. Lower Bound 0.052 0.052 0.067 Recursion Time (s) 15,590 212 N/A Average Instance Solution Time (ms) 750 33 3 Table 2.2: G2V Simulation Results in (2.16) results in a negligible diﬀerence in mean cost as is expected. However, using (2.25) results in a signiﬁcant reduction in computation time as shown in the rows of Table 2.2 labeled “Recursion time” and “Average instance solution time”. The recursion time refers to the time required to execute the entire proposed SDP backwards recursion from H to 1, while the Average instance solution time refers to the average amount of time required to solve for hourly charging and regulation bids after the backwards recursion has completed. 30 This highlights the importance of reducing the problem size as done in section 2.4.4. Our results show that the proposed approximate SDP method could be a practical hourly decision making strategy for EVs. An EV smart charger would need to perform the proposed SDP backwards recursion once each time the EV plugs in for the night. The required recursion time is less than four minutes in our implementation. At the beginning of each hour while the EV is charging, the smart charger would optimize its bids by solving a single linear program, requiring 33ms on average. The proposed method requires much more computation than the MPC method, but it is still well within the abilities of todays multi-core personal computers. 3132 Chapter 3 Electric Vehicles in the Adaptive Load Management Framework In chapter 2, we proposed an MDP for optimal decision making by an EV that partici- pates in energy markets as a price taker. In this chapter, we move beyond the price taker assumption and develop methods by which EVs can communicate the price sensitivity of their demand to the market, enabling ﬂexibility in the dispatch of generators and loads. We propose integrating EVs into the Adaptive Load Management (ALM) framework for aggregating distributed heterogeneous loads [4]. The existing ALM approach to aggrega- tion relies on intelligent loads, such as EVs, to solve their own deterministic MPC problems for optimal energy consumption. We extend the ALM framework to incorporate intelligent demands that optimize consumption decisions under uncertainty using an MDP approach. Two problem formulations are presented for EVs that participate in the ALM framework, one is a deterministic MPC problem and the other is an MDP with Markov random energy prices. 33 3.1 Introduction If EVs gain mass adoption, their load could add to system load peaks and increase electricity prices for all consumers without intelligent control of charging [7, 39, 40]. Many approaches have been investigated for optimal charging of a large EV ﬂeet. [23, 41] propose centralized approaches where an aggregator uses forecasts of EV energy needs and market prices to optimize a charging schedule for a ﬂeet of EVs. These aggregators purchase ﬁxed quantities from energy markets and pay whatever the market clearing price is. [39] shows that such an aggregator approach can result in new load and price spikes during the overnight hours. And so, new approaches have tried to address optimal charging when the EV load can signiﬁcantly eﬀect energy prices. [42] proposes a similar aggregation approach to the others, but optimizes charging schedules with an objective function that models the market power eﬀect of EV energy consumption on prices. The aggregator then submits a ﬁxed quantity bid into the energy market on behalf of the EV owners. [39] compares the performance of an EV aggregator, which charges as a price taker based on a day ahead forecast, against a fully centralized approach where generation dispatch and EV consumption are optimized in a single problem. It is shown that the fully centralized approach will achieve lower system costs. Iterative decentralized approaches have also been suggested to optimize the charging of EVs who communicate with a system operator in [43, 44, 45, 46]. [43, 44, 45] propose methods for optimizing EVs for “valley ﬁlling”, which minimizes variation in the total system load proﬁle during overnight hours. In these papers, total system load acts as a proxy for energy price. [43] also demonstrates the application of an iterative decentralized optimization to online control of charging for valley ﬁlling. [46] presents a Lagrangian relaxation and heuristic approach to coordinating load and generation to minimize system cost with non-convexities. [47] describes how Lagrangian relaxation can be used to coordinate supply and demand and also respect power system thermal line limits. 34 Iterative approaches can take a large number of iterations to converge when power net- work constraints are considered, making them feasible for day ahead scheduling but challeng- ing to implement in real-time energy markets. [4, 48, 49] introduce the real-time Adaptive Load Management (ALM) framework for integrating price-sensitive demand into real-time energy markets, which clear on sub-hourly timesteps and without the need for iterations. This framework readily lends itself to the integration of EVs, as well as other heterogeneous loads. In this chapter we propose two methods for integrating EVs in the ALM framework. The ﬁrst method is that which is described in [4, 48, 49]. In this approach an aggregate demand bid function is created based on the price sensitivity of intelligent loads. The aggregate price sensitivity is determined by a procedure where each load solves a deterministic MPC optimization problem for energy consumption under forecast energy prices and with pertur- bations to the forecast price of the next market period. The perturbations do not propagate through the entire forecast as would be expected when prices exhibit autocorrelation, which is typically seen in electric power markets. Therefore, we propose a new approach to de- veloping an aggregate demand bid function based on intelligent loads that optimize energy consumption considering uncertainty and autocorrelation in energy prices. This new ap- proach will model price forecast errors using a Markov chain model, and decisions will be optimized by solving an MDP. The new procedure should result in better decision making and lower energy costs. 3.2 Deterministic MPC based Real-Time ALM In this section, we describe a possible approach to integrating EVs into the real-time ALM framework. Below, we describe the procedure of the real-time ALM framework in math- ematical detail. We also present a deterministic MPC problem formulation for EVs that participate in the ALM framework. 35 1. Given historical market data up to the current moment, the LSE creates a forecast of energy prices over a planning horizon ˆρ e = [ˆρe[1], ˆρe[2], . . . , ˆρe[T ]] T ($/MWh) and broadcasts it to its N L intelligent loads. 2. Each load solves three optimization problems for energy consumption over the planning horizon based on the end-user’s preferences and the appliance’s physics. For an EV that only charges electric energy from the grid, the MPC problem is shown in 3.1. In this optimization problem, the EV battery is modeled as having linear dynamics and a constant eﬃciency η. Constraint (3.2) enforces that the EV must charge enough energy to support the transportation needs of the driver. (3.3) and (3.4) limit the choice of battery charge rate to be positive and less than the maximum power P max. We assume that the driver communicates an unplugging time, T , and travel plans to the EV charger, which can estimate a required SOC for the trip ereq (kWh). All of the parameters and variables of 3.1 can vary from EV to EV, but the subscript l is omitted. min P [t] T∑ t=1 ˆρe[t]P [t]∆t (3.1) s.t. (3.2) − (3.4) e[1] + η T∑ t=1 ∆tP [t] = ereq (3.2) 0 ≤ P [t], ∀t (3.3) P [t] ≤ P max, ∀t (3.4) This optimization problem will be solved three times. Once given the forecast energy prices, ˆρe, once given a positive perturbation to the next forecast price, ρe+ = [ˆρ e[1](1+ δ), ˆρe[2], . . . , ˆρe[T ]] T , and once given a negative perturbation to the next forecast price ρe− = [ˆρ e[1](1 − δ), ˆρe[2], . . . , ˆρ e[T ]]T . The resulting optimal charging powers for the immediate market period will be noted as P ∗[1], P +[1], and P −[1] Additionally, the EV should calculate a lower limit, ∆tP min[t], and upper limit ∆tP max[t], for energy 36 consumption during the next market period t. P min[t] will be the smallest charge rate such that the EV will still be able to meet its energy requirement by the unplugging time and P max[t] will respect the maximum charging power and the maximum SOC of the EV battery. Finally, the three price, quantity demand points and demand limits are transmitted to the LSE. 3. Once the LSE has collected the optimization results from all N l of the intelligent loads, it sums the total energy given each price, resulting in the three price quantity points of (3.5). The total energy consumed, E is given by (3.6), where l indexes the individual EVs. ( E+, ρe+[1]) , (E∗, ˆρe[1]) , ( E−, ρe−[1] ) (3.5) E = ∆t N l ∑ l=1 Pl[1] (3.6) Using these three points, the LSE uses linear regression to estimate the slope and intercept of the marginal beneﬁt function M B of consuming energy as in (3.7). M B(E) = β0 + β1E (3.7) The marginal beneﬁt function is integrated to form the beneﬁt function B(E) shown in (3.8). B(E) = β0E + β1 2 E2 (3.8) The aggregate minimum and maximum energy demand for the market period are also calculated by (3.9) and (3.10) respectively. Emin = ∆ t N l ∑ l=1 P min l [t] (3.9) Emax = ∆ t N l ∑ l=1 P max l [t] (3.10) The LSE then transmits the beneﬁt function and dispatch limits to the ISO 37 4. Given quadratic cost and beneﬁt functions from generators and LSEs, the ISO solves the DYMONDS dispatch problem proposed in [5, 50]. In the DYMONDS framework, generators and LSEs create cost and beneﬁt functions in a look-ahead fashion as de- scribed in steps 1 through 3. This method for creating bid functions is said to “in- ternalize dynamics”, creating an economic dispatch problem for a single period. This approach to economic dispatch requires much less computational eﬀort than solving a centralized look-ahead economic dispatch MPC problem for the whole system, sub- jected to simpliﬁed ramp rate constraints. The DYMONDS economic dispatch problem is shown in (3.11). This problem is in terms of energy as opposed to power because we assume a timestep that is not 1hr. The optimization variables are the energy dispatch of each generator EG i (MWh) and the energy dispatch of each aggregated LSE load EL j (MWh). N L is the number of LSEs while N G is the number of generators. Constraint (3.12) enforces the supply demand balance for energy, where EIFk (MWh) is the total uncontrollable load at bus k. Constraint (3.13) ensures that absolute value of the real power ﬂows on each transmission line are less than the line’s thermal limit, given by the vector F max. In (3.13), DF is the power transfer distribution factor matrix and (E′G − E′L − E′IF )/∆ t gives the net power injection at all buses other than the slack bus. The ′ symbol denotes that the slack bus element of the vector is omitted. min EG i , EL j N G ∑ i=1 Ci(EG i ) − N L ∑ j=1 Bj(EL j ) (3.11) s.t. (3.12), (3.15) N G ∑ i=1 EG i = N IF ∑ k=1 EIF k + N L ∑ j=1 EL j (3.12) \f \fDF × (E′G − E′L − E′IF )/∆ t\f \f ≤ F max (3.13) EL,min j ≤ EL j ≤ EL,max j (3.14) EG,min i ≤ EG i ≤ EG,max i (3.15) 38 5. Given the results of the dispatch, LSE j must divide EL j ∗ MW amongst the EVs. To do this, the LSE calculates a dispatch percentage ,θj, of the distance that EL j ∗ lies between EL,min j and EL,max j as shown in (3.16). θj is then broadcast to all of the individual loads. θj = EL j ∗ − EL,min j EL,max j − EL,min j (3.16) 6. Given θj, all individual loads of LSE j consume power Pl according to the equation in (3.17). In simulation, the loads will then update their states using Pl and the timestep length ∆t, before the procedure goes back to step 1. Pl[t] = P min l [t] + θj(P max l [t] − P min l [t]) (3.17) 3.3 MDP based ALM The diﬀerence between the given ALM framework and the proposed framework lies in the intelligent load’s internal decision making method and models. In the proposed framework, an intelligent load determines its optimal energy consumption by the solution of an MDP that includes a Markov model of the energy price. An MDP based approach will enable an intelligent demand to better consider uncertainty in energy prices as well as the evolution of future prices given a deviation from the forecast. This approach will require more information about the prices than just a point forecast and could be estimated based on historical data gathered by an EV or EV LSE. 3.3.1 Energy Price Markov Model The energy price Markov model used in the EV’s MDP for ALM will be created from the superposition of the latest energy price forecast and a ﬁnite horizon Markov model of forecast errors. This will allow the Markov model to accurately represent time of day and day of week seasonality, which is not accounted for in the Markov models described in [78]. The prices 39 used in the MDP can be constructed by addition of the latest forecast ˆρe to the state values of the forecast error Markov model. The LSE will store price forecasts as well as actual market clearing prices and ﬁt the Markov model to this data. If an intelligent load’s MDP is composed of N ρ price states for each decision epoch, the LSE will create bid functions using N ρ price, demand points. For now, we assume a simple Markov model for price forecast errors built by discretizing a multivariate Gaussian distribution. We assume that the marginal distribution for each forecast horizon from 1 to T time steps ahead has the same standard deviation σ and mean 0. The marginal distribution at each forecast horizon is then discretized into a set of N ρ error states of evenly spaced cumulative density function (CDF) values. For example, if we are constructing a Markov chain with 5 states, then the set of error states at all forecast horizons S ϵ will be as given by (3.18), where Φ−1 is the inverse CDF of a normal distribution with standard deviation σ. S ϵ = {Φ −1(0.1), Φ −1(0.3), Φ −1(0.5), Φ −1(0.7), Φ−1(0.9)} (3.18) We assume that each pair of neighboring error distributions has the same coeﬃcient of correlation βr. Transition probabilities between the states can be determined analytically using the bivariate normal distribution function. Given an error state ϵi ∈ S ϵ the next error ϵj ∈ S ϵ will be distributed according to (3.19) with a continuous model. We refer to the CDF of the distribution in (3.19) as Φj|i. ϵj ∼ N (βrϵi, σ2(1 − βr2)) (3.19) State transition probabilities are then calculated by (3.20). b+ j and b− j are the cell boundaries of state j in terms of CDF value. For example, if there are 5 error states and the CDF value of ϵj is 0.5 then b+ j = 0.6 and b− j = 0.4. If state j is the largest state, then b+ j = 1 and if state j is the smallest state, then b− j = 0. Pr (ϵj | ϵi) = Φj|i ( Φ −1 ( b+ j )) − Φj|i (Φ −1 (b− j )) (3.20) 40 3.3.2 MDP Formulation In this section we develop a ﬁnite horizon Markov decision problem (MDP) for an EV that must ﬁll its battery by a known deadline and faces Markovian random prices . Unlike the MDP formulated in chapter 2, we formulate the problem as if the EV knows the energy price in the current period with certainty, but future prices are uncertain. This way, the result of the MDP tells us what the optimal charge rate would be given each price state. We then use these price, quantity points to construct a price sensitive demand-side bid function that approximates how much power the EV would optimally consume across a range of prices. • Decision Epochs Charging decisions are made at each decision epoch t of the ﬁnite decision-making horizon t ∈ [1, . . . , T ], where T is the number of market periods the EV will be plugged in. The length of time between market periods is ∆t (h). • System State The system state vector s[t] = (e[t], ρ e[t]) ∈ S[t] includes the EV battery state of charge e[t] (kWh) and the price of energy ρ e[t]($/kWh). In order to solve an MDP using the discrete SDP backwards recursion, we model the space of states as being a discrete set. The optimal charging and regulation decisions will depend on the values of each dimension of the state vector. • Actions The action vector a only consists of the charging power P . The constraints (3.21)-(3.24) describe the space of feasible actions given the system state at decision epoch t, A[t](s). We assume that the EV does not discharge into the grid, giving constraint (3.21). The choice of P [t] is constrained by the maximum charge rate of the EV and smart charger, P max (kW) by (3.22). The charge rate is also limited according depending on its SOC and by the battery’s maximum SOC, emax (kWh), such that it does not over charge the battery in (3.23). We assume that the EV driver requires the battery SOC to have 41 suﬃcient charge for the next trip, e req (kWh), by the scheduled unplugging time T + 1. In order to guarantee that the EV will be suﬃciently charged by the known unplugging time, we observe constraint (3.24), where e min[T + 1] = ereq and e min[t] ∀t < T + 1 is the minimum SOC at time t such that the EV SOC can still reach e req by time T + 1. The value of e min[t] is determined by the maximum charging rate, charging eﬃciency η, the ﬁnal SOC required for transportation e req, and the number of market periods remaining until the vehicle unplugs. 0 ≤ P [t] (3.21) P [t] ≤ P max (3.22) e[t] + η∆ tP [t] ≤ e max (3.23) e[t] + η∆ tP [t] ≥ e min[t + 1] (3.24) For each state and time of the decision making horizon, we discretize the space of possible actions into the discrete set of possible charge rates. • State Dynamics Given the charge rate P [t], the next SOC is determined according to (3.25). e[t + 1] = e[t] + η∆ tP [t] (3.25) Since the SOC state transition equation (3.25) doesn’t always lead to a SOC in the set of states S[t + 1], we represent state transitions in the MDP using transition probabilities calculated as shown in (3.26) and (3.26). e +[t + 1] represents the SOC in S[t + 1] which is the closest SOC greater than or equal to e[t + 1] as calculated by (3.25), and e −[t + 1] is the closest SOC less than e[t + 1]. For SOCs other than e −[t + 1] and e +[t + 1], the 42 state transition probability is set to 0. Pr (e[t + 1] | e[t], P [t]) =  ||||| ||||| (e[t]+η∆tP [t])−e−[t+1] e+[t+1]−e−[t+1] , e[t + 1] = e +[t + 1] 1 − (e[t]+η∆tP [t])−e−[t+1] e+[t+1]−e−[t+1] , e[t + 1] = e −[t + 1] 0, otherwise (3.26) Energy prices are modeled as following a discrete Markov process over the ﬁnite plan- ning horizon as in (3.27). Calculation of price state transition probabilities is described in 3.3.1. Pr (ρe[t + 1] | ρe[t]) , ∀ρ e[t] ∈ S[t], ∀ρe[t + 1] ∈ S[t + 1] (3.27) The total state transition probability is then written as in (3.28) Pr (s[t + 1] | s[t], a[t]) = Pr (e[t + 1] | e[t], P [t]) Pr (ρe[t + 1] | ρe[t]) (3.28) • Cost Function Given that the EV was in some state s[t] at decision epoch t and an action vector a[t] was chosen, the EV will incur cost r[t](s, a) as shown in (3.29). This represents the total cost incurred during the period between decision epoch t and t + 1. r[t](s, a) = ρe[t]∆ tP [t] (3.29) • Markov Decision Problem J[t](s), commonly called the cost to go, is the expected total future cost of having some state s at decision epoch t and making optimal decisions for the remainder of the problem horizon. The cost to go at the current decision epoch is the result of solving the ﬁnite horizon MDP given in (3.30). Solving the MDP also results in an optimal decision-making policy π∗. A decision-making policy π is a collection of decision- making rules π = {d[1](s), . . . , d[T ](s)} that take in the current state and return a decision or action vector. A decision-making policy must be in the set of feasible 43 decision-making policies Π, ensuring that d[t](s) = a ∈ A[t](s), ∀s ∈ S[t], ∀t. J[1](s) = min π∈Π E π [ T∑ t=1 r[t] (s, d (s)) | s[1] ] (3.30) This ﬁnite horizon MDP can be solved by the SDP backwards recursion procedure as described in [27] and 2.3. 44 Chapter 4 Optimal Autonomous EV Charging with Stochastic Driver Behavior This chapter proposes the application of the Markov decision problem (MDP) framework for optimizing the autonomous charging of individual plug-in electric vehicles (EVs). Two inﬁnite horizon average cost MDP formulations are described, one for plug-in hybrid electric vehicles (PHEVs) and one for battery only electric vehicles (BEVs). In both formulations, we assume no direct input from the driver to the smart charger about the driver’s travel schedule. Instead, we use stochastic models of plug-in and unplug behaviors as well as energy required for transportation to represent a driver’s charging requirements. We also assume that electric energy prices follow a Markov random process. These stochastic models can be built from historical data on vehicle usage. The objective of the MDPs is to minimize the sum of electric energy charging costs, driving costs, and the cost of any driver inconvenience. We demonstrate the solution of the MDP for a BEV and analyze the results. This chapter presents a new approach to minimizing long-run EV charging costs while reducing the need for trip planning by a driver. 45 4.1 Introduction In order to make EVs more attractive to consumers, recent research has focused on ways to minimize EV charging costs. Chapters 2 and 3 of this dissertation present approaches to optimizing EV decisions as price-taker and as a price-sensitive bidder respectively. Chapters 2 and 3 both assume known unplugging times and energy requirements and plan for only the next driving trip. [45] and [43] propose decentralized approaches to coordinating vehicles for overnight “valley ﬁlling”, which should minimize the total charging cost for a ﬂeet of vehicles that can inﬂuence wholesale market prices. These approaches are proposed for day-ahead scheduling of vehicle charging given deterministic driving schedules. [23] proposes methods for an EV aggregator which optimally charges a ﬂeet of EVs which also sell ancillary services to the electric grid. This centralized approach assumes that EV drivers communicate their driving schedules to an aggregator. The proposed aggregator uses a derating constant to protect against randomness in driver behaviors. [51] proposes scheduling the charge rates of an aggregation of EVs by chance constrained convex optimization. The method proposed in [51] assumes that drivers communicate a driving schedule a day in advance and complete trips in the planned order. However, the durations of sojourns or stops are modeled as random, motivating the use of chance constraints. The methods proposed in the literature all optimize over a ﬁnite planning horizon and assume that a driver communicates his driving schedule to a smart EV charger hours in advance. The work presented in this chapter seeks to address two challenges to minimizing the energy cost of charging an electric vehicle. First, scheduling future driving trips is a men- tal burden that could dissuade consumers from purchasing an EV or participating in an optimized charging program. We propose an approach to minimizing EV charging costs that does not require drivers to communicate a driving schedule. Instead, we use Markov chain models of plug-in and unplug behaviors as well as energy required for transportation to represent a driver’s charging requirements. A second challenge is to minimize charging 46 costs over a longer planning horizon than just one day. The average daily driving distance for american drivers is 33 mi per day, while EVs such as the Nissan Leaf provide an average drving range of 84 mi [38]. It is very possible that an EV would not need to be charged for every trip or even every day. The approach proposed in this chapter minimizes costs in the long-run over an inﬁnite planning horizon based on patterns in driving behavior as modeled by Markov chains. Additionally, we aim to optimize charging in such a way that it results in a price sensitive energy demand bid for use in the ALM framework as was done in chapter 3. We assume that an EV or smart EV charging device can record data on plug-in and unplug times, battery state of charge (SOC), and fuel consumption on each trip. Given this data, an EV or smart charger can construct Markov chain models of EV connection patterns and energy needs. Alternatively, if many EVs periodically connect to the Internet and share their data, an individual’s Markov chain models can be constructed using the data of many vehicles, helping to alleviate data sparsity issues. Given the appropriate Markov models, we propose formulating the optimization problem for minimizing long-run EV charging costs in the absence of a predetermined driving schedule as an inﬁnite horizon average cost MDP, also known as an average reward MDP. The inﬁnite horizon MDP approach has been applied to many energy storage management problems such as supervisory control of hybrid electric vehicle batteries [52]. The inﬁnite horizon MDP approach is a natural ﬁt for optimizing autonomous charging of EVs with stochastic driver behavior. Solving an MDP results in an optimal operating policy, which is simply a look-up table. Once the MDP has been solved, the optimal look-up table of charging actions could be downloaded to the EV or smart charger. An Internet based architecture for gathering data, ﬁtting Markovian driver behavior models, solving the MDP, and downloading the optimal policies is shown in Figure 4.1. In order to make optimal charging decisions in real-time, the smart charger would need minimal computing power. The smart charger would only need to sense the relevant system state information and perhaps interpolate between the actions in 47 Driving data Database Driver behavior model construction Individual policy optimizer Optimized policies Driving trips Vehicle 1 … Vehicle N Grid data Figure 4.1: Proposed system architecture for optimizing autonomous charging policies the look-up table. By including a price state in the MDP, a smart EV charger could translate the price sensitivity of the optimal charging policy into a price sensitive demand bid as was shown in chapter 3. The optimal policy could even be updated seasonally if driver behaviors changed with the seasons of the year. 4.2 Markov Decision Problem Formulation In this section, we describe the inﬁnite horizon average cost MDP for optimal autonomous charging of EVs in detail. We describe how each component of the MDP represents or approximates the true vehicle charging problem. The MDP framework is developed in detail in [27]. 48 4.2.1 Decision Epochs At each decision epoch t the smart vehicle charger decides on a charging rate P [t] (kW). While plugged-in, we assume that decisions are made every 15 minutes. Charging decisions are only made while the vehicle is plugged-in. If the vehicle unplugs, the length of time until the next decision epoch is random and depends on when the vehicle plugs back into the electric gid. We assume that there are an inﬁnite number of decision epochs such that t ∈ T = {1, 2, . . . ∞}. 4.2.2 State Vector The system state vector of the MDP is s = (e, w, ρe) ∈ S. e is the vehicle state of charge (SOC) which is in units of fraction of maximum storage capacity. e can take on values in the range [0, 1]. The maximum charge storage capacity is emax (Ah). In order to solve a discrete MDP, we must discretize e into a ﬁnite set of states E. w is time of the week on a 15 minute basis and can take discrete values such that w ∈ W = {1, . . . , 672}. By including time of the week in our MDP, we are able to account for time of day seasonality as well as weekday versus weekend seasonal eﬀects on parameter values. ρ e is the electric grid energy price ($/kWh), which we will model as being part of a two-dimensional discrete Markov random process along with w. We assume that there is a ﬁnite set of possible values that ρe can take for each w such that ρe ∈ R e(w), ∀w ∈ W. 4.2.3 State Transitions In this section, we describe the MDP system state dynamics for each state dimension. The dynamics for time of the week are described by the four possible cases in (4.1), which 49 holds for all decision epochs t. w[t + 1] =  ||||||||||||||||||||| ||||||||||||||||||||| w[t + 1]; I plug,[t] = 1, w[t] ∈ {1, . . . , 671} 1; I plug[t] = 1, w[t] = 672 w[t] + L[t]; I plug[t] = 0, L[t] = L[t], w[t] + L[t] ∈ {2, . . . , 672} w[t] + L[t] − 672; I plug[t] = 0, L[t] = L[t], w[t] + L[t] > 672 (4.1) When the vehicle remains plugged-in, the time of the week w is assumed to follow the natural progression of time as shown in the ﬁrst two cases of (4.1). Given that the vehicle is plugged-in at some decision epoch, it is not known if the vehicle will remain plugged-in for the entirety of the 15 minute period. We represent random unplugging behavior with the {0, 1} indicator random variable I plug. If the vehicle remains plugged-in for the entire 15 minute period, then I plug = 1. If the vehicle unplugs at some point before the end of the 15 minute period, then I plug = 0. One can imagine that travel patterns have strong seasonality due to work or recreation schedules, so we model the probability of unplugging as depending on the time of week state, w. If a vehicle unplugs, the length of time that the vehicle is unplugged for is represented by L. The outcome of L will determine the time of the week at the next decision epoch as shown in the ﬁnal two cases of (4.1). L is modeled as a discrete random variable in units of 15 minute periods. When I plug = 0, L takes a positive value in the set L = {1, 2, . . . , Lmax}. The maximum number of periods elapsed over a driving trip, Lmax, is likely to be less than 12 hours. We hypothesize that L will depend on the time of the week w. This dependence could be due to traﬃc patterns or the driver’s regular schedule. After estimating the probability mass functions (PMFs) Pr (I plug | w) and Pr ( L | I plug, w) we can use the cases in (4.1) to 50 estimate the state transition probabilities Pr (w[t + 1] | w[t]). The possible state transitions for battery SOC are described in (4.2), which holds for all decision epochs t. e[t + 1] =  || || e[t] + ∆e(e[t], P [t]); I plug[t] = 1 e[t] − G[t] emax ; I plug[t] = 0, G[t] = G[t] (4.2) The change in battery state of charge between decision epochs depends on whether or not the vehicle remains plugged in until the next decision epoch, the choice of battery charge rate P (kW), and the driving behavior of the vehicle owner. The ﬁrst case of (4.2) describes the state transition when the vehicle stays plugged-in while the second case of (4.2) describes the state transition when the vehicle unplugs and goes driving. When the vehicle remains plugged-in and is charged with power P , the rate of change of the battery SOC is ˙e as shown in (4.3). ˙e is the rate of change in SOC according to the static circuit equivalent model of the vehicle battery pack shown in Figure 4.2. V oc(e) is the open circuit voltage (V) of the battery and Rint(e) is the internal resistance (Ohms). Both the internal resistance and open-circuit voltage of the battery can depend on the battery SOC. (4.3) can be derived by writing the equation for conservation of power in the circuit and applying the quadratic equation to solve for current as a function of power. The total change in SOC between decision epochs when the vehicle remains plugged-in will be the integral of ˙e over the 15 minute time period ∆t (hrs) as shown in (4.4). ˙e = −V oc(e) + √ V oc2(e) + 4000Rint(e)P 2emaxRint(e) (4.3) ∆e(e, P ) = ∫ ∆t 0 ˙e dt (4.4) G (Ah) is the battery charge consumed for driving between when the vehicle unplugs and when the vehicle plugs back in. We model the charge consumption of PHEVs and BEVs separately as G P HEV and GBEV respectively. These random variables depend on I plug as there is no driving if the vehicle does not unplug. Because the battery SOC cannot be 51 Figure 4.2: Static circuit equivalent model of the vehicle battery negative or exceed 1, the distribution of GP HEV or G BEV will depend on the SOC when the vehicle unplugs, e. For PHEVs, GP HEV may take negative values depending on how the hybrid power split between the combustion engine and electric motor is managed while driving. The support of GP HEV could be [e max(e − 1), e maxe] given I plug = 0. BEVs cannot charge the battery while driving, so GBEV can only take on positive values. The support of G BEV is [0, e maxe]. Also, it is natural to assume that the charge consumed is related to the length of time the vehicle is unplugged L, as driving longer distances requires more time and more battery charge. Charge consumption could additionally depend on w as traﬃc can be seasonal and trip time is a function of both distance and traﬃc conditions. We want to model the distribution of BEV battery charge consumption in a way that respects the preferences of the driver. We assume that at any time, the driver may want to take a trip that could be accomplished with a full SOC. If the driver attempts to take a trip and the battery SOC is inadequate for the driver’s trip, we assume that the driver manually changes the charging power to P max and waits for the battery to charge to an adequate level. When the driver returns from the trip and plugs back in, we assume that the trip will have consumed all of the battery’s charge. We model the PMF of change in BEV charge consumption under these assumptions as in (4.5), where Gmax is the charge consumed by a 52 BEV that has a full SOC when it unplugs. Pr (G BEV | e) = Pr ( min (Gmax, e maxe) = G BEV ) (4.5) Due to the dependence of G on L the outcome of e[t+1] will be dependent on w[t+1]. Using the estimated PMFs Pr ( I plug | w) , Pr ( L | I plug, w) , and Pr (G | L, I plug, w, e) along with the state transition equations (4.1) and (4.2), we can calculate the PMF Pr (e[t + 1] | w[t], w[t + 1], e[t], P [t]) The electric grid energy market price ρe[t] is assumed to be known at the start of each decision epoch, but future values are uncertain. Energy market prices are known to exhibit seasonal patterns and so we model ρe[t] as a discrete Markov random process that depends on w[t] but not on the decision epoch t. The energy market price transitions randomly according to the PMF Pr (ρe[t + 1] | ρ e[t], w[t], w[t + 1]). Given the PMFs described earlier in this section we can calculate the full state transition probability as in (4.6). Pr (s[t + 1] | s[t], P [t]) = Pr (w[t + 1] | w[t]) × Pr (e[t + 1] | e[t], w[t], w[t + 1]) × Pr (ρ e[t + 1] | w[t], w[t + 1], ρ e[t], P [t]) (4.6) 4.2.4 Feasible Actions At each decision epoch t, the smart vehicle charger must choose an action a ∈ A(s). In the MDP presented here, the action a is simply the choice of charging power P . A(s) is the set of feasible actions given the current state s as deﬁned by constraints (4.7)-(4.9). In this work, we do not consider discharging of the vehicle into the grid, so P must be positive as shown in constraint (4.7). We assume that there is a maximum rated charging power P max of the vehicle or charger that limits the choice of P as in constraint (4.8). Also, the choice of P must respect the maximum charge capacity of the battery. Constraint (4.9) ensures that 53 the battery is not charged above its maximum capacity. P ≥ 0 (4.7) P ≤ P max (4.8) e + ∆e(e, P ) ≤ 1 (4.9) 4.2.5 Cost function At each decision epoch, the vehicle will pay a random cost, r(s, a) ($), for taking action a while in state s. The cost function for PHEVs is shown in (4.10). If the vehicle stays plugged-in, then the driver must pay to withdraw energy from the electric grid at a price of ρe ($/kWh), giving the ﬁrst term. If the vehicle unplugs and goes driving, then a random amount of gasoline, g (l) is consumed at a cost of ρg ($/l). g could be dependent on w as the distribution of traﬃc and therefore driving time could be dependent w. Since the vehicle must either be powered by charge from the battery or fuel, we assume that the distribution of fuel consumption is also dependent on the SOC when the vehicle unplugs, e. r P HEV (s, a) = P ∆t ρ e I plug + g ρg (4.10) The cost function for BEVs is shown in (4.11). The ﬁrst term of (4.11) is charging costs, while the second term is an inconvenience cost to the driver. If the driver attempts to take a trip and the battery SOC is inadequate for that trip, we assume the driver will manually command the vehicle to charge at maximum power and wait until the battery is charged to a suﬃcient level. This inconveniences the driver and so we model the driver’s displeasure with an inconvenience cost. The inconvenience cost is deﬁned by the driver’s inconvenience price, ρwait ($/h), multiplied by the amount of time the vehicle must spend charging at P max to cover the next trip’s charge deﬁcit Gdef (Ah). The driver would need to communicate ρ wait to the smart charging device at least once for the proposed approach to accurately account 54 for driver preferences. rBEV (s, a) = P ∆t e I plug + G def 4emax∆e(e, P max) ρwait (4.11) The PMF of Gdef is deﬁned in (4.12). Pr ( G def | e ) = Pr (max (G max − e maxe, 0) = G def ) (4.12) 4.2.6 Optimization Problem The inﬁnite horizon average cost MDP for the system we have described is shown in (4.13). (4.13) can be solved for γ∗(s) for each state s. γ∗(s) is composed of a bias for starting in some initial state, b∗(s), and the gain or stationary cost, γ∗, as shown in (4.14). The optimal gain can be interpreted as the minimum per-period average expected cost. γ∗(s) = min π∈Π lim N →∞ 1 N E π s [ N∑ t=1 r(s[t], π(s[t])) | s[1] = s ] (4.13) γ∗(s) = b∗(s) + γ∗ ∀s ∈ S (4.14) A decision making policy π must be in the set of feasible decision making policies Π, ensuring a ∈ A(s)∀s. π ∈ Π is a stationary policy which takes the form of a look-up table, listing a feasible action to take given the current state of the system, regardless of the decision epoch. (4.13) can be solved using algorithms such as value iteration, policy iteration, or modiﬁed policy iteration as detailed in [27]. Solving (4.13) for the optimal gain and biases also results in the optimal policy π∗. To use the optimal policy in online operations for charging, where the states are truly continuous, one can use interpolation or a nearest-neighbor rule to determine the correct action to take. In the smart charging architecture shown in Figure 4.1, this optimization problem is solved oﬄine by a remote service provider. The service provider may solve the autonomous charging MDP seasonally for each EV, or more frequently to incorporate new driver behavior or energy price data. 55 4.3 Numerical Example In this section, we develop, solve, and analyze results realistic examples of the proposed au- tonomous charging MDP for a BEV. First, we will describe parameter data and distributions of random variables. Some parameter values are based on real data, while some information was assumed based on intuition. Then we describe the computational eﬀort required to solve the problem under diﬀerent levels of discretization. The eﬀect of discretization reﬁne- ment on solution time and quality is investigated. Finally, we analyze how important driver inconvenience price may be to the usefulness of the proposed autonomous charging system. 4.3.1 Input Data Although the focus of this chapter is the proposed MDP formulation and general appraoch, an eﬀort was made to build a realistic example problem. This is done so that we might develop some intuition about the real world performance and usefulness of the autonomous charging system proposed here. We attempted to model the decision making problem for a small commuter BEV such as a Nissan Leaf. Energy Prices Wholesale energy market price data was collected for the year 2011 in the PJM ISO [35]. The entire year’s worth of data was used to ﬁt a Markov model where the next energy price depends on the time of day, whether it is a weekday or weekend, and the last observed energy price. On both weekdays and weekends, a distribution of energy prices was estimated for each hour of the day by kernel smoothing density estimation [53]. The distributions were then discretized into states using equally spaced values of their estimated cumulative distribution functions (CDFs). Energy price transition probabilities were estimated for each pair of states in consecutive hours with a Gaussian Copula model [36]. A Copula model uses rank correlation to model the dependency between random variables of arbitrary marginal 56 1 5 9 13 17 21 1 5 9 13 17 21 20 40 60 80 100 Hour of the DayEnergy Price ($/MWh) 0.9 0.7 0.5 0.3 0.1 Figure 4.3: Energy market prices on a weekday and a weekend day at 5 diﬀerent CDF points distributions. Figure 4.3 shows the energy prices for each hour of a weekday and a weekend day at 5 equally spaced values of each hour’s CDF. The legend in Figure 4.3 lists the CDF value corresponding to each price. The daily pattern of prices has diﬀerent characteristics at diﬀerent CDF levels. At the lowest CDF level the energy price has two nearly equal high price periods around the start and end of the work day with smooth transitions. This contrasts with the price pattern at the highest CDF level, which has one dominant price peak around hour 15. Battery Model We constructed a 65 Ah battery pack model based on the pack used in the Nissan Leaf EV [54]. Using the generic Li-Ion battery model in the MATLAB SimPowerSystems Simulink package, we calculated typical values for open-circuit voltage of the pack at various SOCs [55]. We the internal resistance of the battery pack is calculated to be 0.0554 Ohms. Figure 4.4 shows how open circuit voltage changes as a function of state of charge. In our imple- mentation, we assume that the battery must always be kept above 10 % state of charge. We assume that the BEV has a level-2 charger, giving a maximum charging power of 6.6 57 Figure 4.4: Open circuit voltage curve of the EV battery pack kW. We assume that the BEV charger can vary the charging power and so we discretize the charge rate into 5 possible values for each SOC. The state transition equation for SOC (4.2) will not necessarily lead to the discretized levels of SOC of the MDP. We overcome this challenge by adjusting the state transition probabilities. We split each possible outcome of e[t + 1], e[t + 1], into two outcomes and assign them the values of the two nearest discrete states. We then calculate transition probabilities to the two new outcomes such that their probability weighted sum is e[t + 1]. Driver Behaviors In the proposed MDP, driving behaviors are modeled by the probability of unplugging Pr (I plug | w), the PMF of duration of driving trips Pr (L | I plug, w), and the PMF of bat- tery charge consumed during a driving trip Pr (G | L, I plug, w, e). Probabilities are assumed based on typical driver behavior. The probability of unplugging is plotted for each 15 minute period of a weekday and weekend in 4.5(a) and 4.5(b) respectively. On weekdays, we as- sume the vehicle is used for commuting to work and back, with some small probability of 58 1 5 9 13 17 21 0 0.5 1Probability Hour of the Day 1 5 9 13 17 21 0 0.05 0.1Probability Hour of the Day (a) (b) Figure 4.5: Probability of unplugging at diﬀerent times of day on weekdays (a) and on weekends (b) non-commuting trips throughout the day. On weekends, we assume it is likely to take a mid-day or evening trip. In this ﬁrst implementation, we assume that battery charge use while driving, G, is a deterministic function of the length of time unplugged. When the EV battery has a full SOC, we assume that charge use follows an exponential function that approaches the capacity of the battery. This is a reasonable assumption as we do not expect that the vehicle is driving for the entire time that it is unplugged. An alternative approach for estimating the distribution of G in the absence of real charge consumption data would be to gather transportation survey data and simulate energy consumption with a dynamic vehicle model as done in [56]. We also assume that the vehicle is unplugged for a maximum of 4 hours at a time. 4.3.2 Results and Analysis We have implemented the value iteration algorithm for the solution of the inﬁnite horizon average cost MDP. The algorithm was implemented in Matlab in such a way that does not require storing a full system state transition probability matrix, which would be a square matrix of size |S|. The value iteration algorithm is used to ﬁnd an ϵ-optimal policy for the 59 Table 4.1: Summary of Results P max (kW) |R e| |E| gain time (min.) #it 6.6 5 5 0.397 158 3987 6.6 5 10 0.251 250 3086 6.6 10 5 0.397 317 3987 6.6 10 10 0.253 511 3086 20 5 10 0.044 10 134 average cost MDP. For some tolerance ϵ, we can guarantee that we ﬁnd a policy with a gain that is within ϵ 2 of the gain of the true optimal solution. In our experiments, we use a value of ϵ = 0.15. In order to achieve convergence, we also applied an aperiodicity transformation to the cost function and transition probabilities. The value iteration algorithm for average cost MDPs is developed in detail in [27]. In order to analyze the computational eﬀort required to solve the MDP, we solved MDPs with diﬀerent granularities of discretization. Table 4.1 shows a summary of results from solving the BEV MDP. Each row of table 4.1 represents a diﬀerent case that was solved. The columns labeled |R e| and |E| give the discretization size for the energy price and state of charge state dimensions respectively. The gain column shows the estimated value of the long-run per-period average expected cost under the resulting policy. We also list the total computation time in minutes and number of iterations required to solve the MDP in the ﬁnal two columns respectively. All cases in table 4.1 assume a driver inconvenience cost of 20$/hr. The last row of the table shows results for a case when P max is set to 20 kW, as opposed to the value of 6.6 kW used in the other cases. Increasing the number of energy price states increases computation time more than increasing the number of state of charge states. This is due to our implementation’s frequent recalculation of energy price transition probabilities 60 during a single iteration of the value iteration algorithm. Discretizing SOC more ﬁnely and increasing the maximum charging power appear to lower the gain. We also investigated the impact of the driver’s inconvenience price, ρ wait, and the max- imum charging power, P max, on the usefulness of the proposed MDP. 3 cases were solved, all having |R e|=5 and |E|=10. In the two cases with P max =6.6 kW, the optimized policies charge at maximum power in 92.4% of all states when ρwait is set to 5 $/hr and 96.5% of all states when ρwait is set to 50$/hr. However, when given P max =20 kW and ρwait set to 20 $/hr, the optimal policy charged at maximum power in only 78.8% of states. A higher maximum charge rate gives more ﬂexibility and makes an optimized charging policy more valuable. Although we describe the policy in terms of percentage of all states, this does not mean the optimal policy will charge at P max for the same percentage of time, since states will be visited with diﬀerent frequencies. The tolerance for optimality, ϵ=0.15, seems large compared to the size of the gains resulting from solving the BEV charging MDPs. Yet, satis- fying this tolerance already requires signiﬁcant computation time. A more eﬃcient solution method is needed. If sparse matrices can be used to store entire system state transition probability matrices in computer memory, the policy iteration algorithm could be used to solve the MDPs. Policy iteration requires fewer and more computationally intensive itera- tions than value iteration, but many of the intensive matrix operations required for policy iteration are eﬃciently implemented in Matlab. The formulation presented in this chapter models energy prices as being random and Markovian. This enables the construction price sensitive demand functions as was done in chapter 3. The formulation studied in this chapter appears to be too computationally challenging to be of practical use in the ALM system. However, If the EV driver pays for energy under a deterministic retail tariﬀ, then the energy price would not be needed as a state in the MDPs. This would greatly reduce the computational burden of the proposed approach to optimal autonomous charging with stochastic driver behavior. The methods shown in this chapter would likely be more practical in the case of deterministic retail energy tariﬀs. 6162 Chapter 5 Evaluation of the System Wide Impacts of Smart EVS Using the Smart Grid in a Room Simulator Architecture In this chapter, we introduce our approach to evaluating the interaction between a ﬂeet of EVs and electric energy markets. In particular, we develop a simulation of the real- time DYMONDS energy market proposed in [48]. The simulation is implemented using the Smart Grid in a Room Simulator (SGRS) distributed simulation architecture. Agent models are developed for many of the components of a real-time electric energy market, including stochastic inﬂexible load, a price forecaster, EVs, EV drivers, and Generators. We describe a simulation experiment to evaluate and compare the performance of diﬀerent decision making methods for the charging of EVs. Simulation results are then analyzed in detail. Five diﬀerent EV decision making methods are evaluated using the simulation developed in this chapter. The ﬁrst method is uncontrolled charging, where EVs begin charging at maximum power as soon as they plug-in, and charge until their batteries are full. The 63 second approach is time of use (TOU) pricing, where EVs optimize charging given a ﬁxed TOU energy price tariﬀ. In the third approach, EVs optimize charging under real-time energy prices and bid into energy markets as price-takers. The next method we evaluate is deterministic MPC based price-sensitive bidding as developed previously in section 3.2, which we refer to as MPC-ALM. The ﬁnal method we evaluate is the MDP based price- sensitive bidding strategy that was developed in section 3.3, referred to here as MDP-ALM. The various EV charging methods have their own advantages and disadvantages. In this chapter, we use the SGRS based simulation to evaluate the ability of the diﬀerent methods to minimize EV charging costs by responding to seasonal patterns, short-term ﬂuctuations, and unexpected emergency conditions. 5.1 SGRS Overview The SGRS distributed simulation architecture enables distributed software modules to co- ordinate with each other and conduct a simulation. Each software module is executed by a separate computing process. The SGRS architecture provides 3 interfaces for use by modules, enabling distributed simulation without a centralized process scheduler. The three interfaces are the broker interface, the communication interface, and the data logging interface. Users must deﬁne a simulation in terms of what the software modules are, the directories where they are located, and what communication links need to be established between modules. Currently, this deﬁnition is stored in a database. Using this simulation deﬁnition, a central broker module starts the execution of the user’s software modules. The broker interface then provides each of the user’s modules with communication channels to its neighbors, as deﬁned in the simulation deﬁnition. The broker interface also provides database credentials to modules. These database credentials are used to read from an initialization parameter database and write simulation results to a results database. Module initialization data can also be stored in local ﬁles. If the user’s software 64 modules are distributed across diﬀerent computers, a broker web application must be running on each computer. This local broker web application executes broker functions on the local machine and passes information about the status of local modules to the central broker. The communication interface allows user modules to communicate with each other over the Internet. The communicated information is encoded using the JSON format. The com- munication interface is implemented as an object with methods enabling a user module to read messages from or write messages to other user modules. The communicator converts Matlab structs to JSON strings and vice versa. We have adopted the convention of writing structures containing ﬁelds for a message type, a timestamp, and the actual message pay- load, which can be a structure itself. User modules that communicate with each other must agree on the information protocol for the message payload. In other words, the user must ensure that a transmitting module sends the information payload that a receiving module is expecting. It is also up to the user to ensure that modules are using the communication in- terface to properly execute the intended sequence of events for the simulation. If one module executes a blocking read with the communication interface, that module will wait until the transmitting module has sent its message. If the simulation sequence of communications is not properly implemented by the modules, a module could wait indeﬁnitely for a message, resulting in a stalled simulation. The ﬁnal interface is the data logging interface. The data logging interface allows modules to write simulation results to a central results database. It also provides functionality for retrieving results for analysis. Fig. 5.1 shows the SGRS architecture. A disk icon represents a database and a globe icon represents a broker web application. A useful web interface also allows users to designing simulation instances, launch simulations, and plot results in real time as they are logged to the results database. Fig. 5.2 shows an example web page for plotting from a live simulation in real time. 65 Figure 5.1: SGRS simulation architecture Figure 5.2: Screen capture of the web interface plotting live simulation results 66 5.2 Implementation of the Real-Time DYMONDS En- ergy Market Simulation In this section, we describe the simulation of the real-time DYMONDS energy market as implemented using the SGRS simulation architecture. The simulation we have implemented can be described generally as a stochastic, discrete time simulation. This stochastic sim- ulation is driven by randomly generated values of inﬂexible load, randomly generated EV transportation behavior, and the logic in the EV LSE and generator modules. Fig. 5.3 shows the modules involved in the simulation and the communication channels between the modules. In the SGRS architecture, an independent computing process executes each module. The modules that compose the simulation of the real-time DYMONDS energy market are the Inﬂexible Load, Price Forecaster, Generator, EV LSE, and the ISO modules. In a simulation with multiple generators or LSEs, each generator or LSE is simulated by an independent module. The modules are implemented based on object oriented design, allowing us to intuitively model the multi-layered ALM system for EVs. EV decision making, charging, and transportation is simulated within the process of the EV LSE module. EVs are implemented as individual objects with unique parameters for transportation behavior and energy consumption. The ISO module contains logic for communication with other modules and organizing market bids, but encapsulates the power system object, which models the electric power grid and computes optimal market dispatches. The overall simulation sequence of events is shown below. Detailed descriptions of the mathematical models and methods implemented within each module are described in section 5.3. The simulation is based on a 10 minute timestep. 1. The Inﬂexible Load module forecasts the inﬂexible load for each bus for the current simulation timestep and the next 8 hours. This forecast is transmitted to the Price Forecaster module. 67 Figure 5.3: Schematic of modules and communications implemented in the SGRS simulation ar- chitecture 68 2. The Inﬂexible Load generates a value of the inﬂexible load at each bus for the current simulation timestep and transmits the new load values to the ISO. 3. The Price Forecaster creates a price forecast for the current market period and the following 8 hours. The price forecasts are transmitted to the Generator and EV LSE modules. 4. Generators and EV LSEs create supply and demand bid functions and transmit them to the ISO. 5. The ISO updates the power system object with new inﬂexible load, supply bid, and demand bid data. 6. The Power System object solves the DYMONDS linearized optimal power ﬂow (DCOPF) problem for optimal supply and demand dispatch. 7. The ISO sends optimal dispatch quantities to Generator and EV LSE modules. 8. After receiving the optimal dispatch quantities, Generator and EV LSE modules ad- vance their internal clocks and wait for the next price forecast. 9. The ISO sends the market clearing price and total system load to the Price Forecaster 10. The Price Forecaster adds the new market data to its internal data record, and may re-ﬁt its price forecasting model to the stored data. 11. The Price Forecaster updates its internal clock and waits for the next load forecast. 12. The ISO sends a notiﬁcation to the inﬂexible load that the market period has ended, updates its internal clock, and waits for the next periods power system data. 13. The Inﬂexible Load reads the ISO’s notiﬁcation, updates its internal clock, and returns to step 1. 69 5.3 Mathematical Modeling In this section, we detail the mathematical models and methods embedded within the indi- vidual modules. Modeling and methods for the EV LSE module was previously described in section 3. The DYMONDS DCOPF problem used by the ISO was shown in (3.11). 5.3.1 Inﬂexible Load The uncontrollable inﬂexible load is modeled using a statistical time series approach. Time series approaches are popular for modeling power system load and stochastic renewable power output [57, 58]. This model is used for both generating new load values and forecasting future load values. We model the time varying, seasonal mean of total power system load µ[h] as being a linear regression function of factors such as time of day and whether or not it is a workday. The model for the seasonal mean system load is given in (5.1). Ii[h] is an indicator variable that has a value of 1 when the hour of timestep h is i and a value of 0 otherwise. Iw[h] is an indicator variable that has a value of 1 when timestep h is during a workday and a value of 0 otherwise. The parameters β are coeﬃcients that need to be ﬁt to data. For sub-hourly timesteps t, we model the seasonal mean µ[t] by linear interpolation of µ[h] from the two nearest hours to timestep t. µ[h] = β0 + βwIw[h] + 24∑ i=2 βiIi[h] + 24∑ i=2 βw,iIw[h]Ii[h] (5.1) The total load at bus j, Lj is given by (5.2). The total load at each bus is modeled as the sum of the scaled seasonal mean plus a stochastic process of correlated noise for bus j, xj[t]. The seasonal mean load for each bus is the seasonal system mean times a scaling factor, sj. The scaling factors must be in the range [0, 1] and sum to 1. The stochastic process of xj[t] is modeled in (5.3) using the seasonal autoregressive moving average modeling approach (SARMA) [59, 36]. xj[t] is correlated with its previous value and the process innovation 24 hours ago. In (5.3), K would be the number of smaller timesteps t in an hour h. In order 70 for xj[t] to be stationary with ﬁnite variance both ϕ and Φ must be positive and less than 1. Lj[t] = sjµ[t] + xj[t] (5.2) xj[t] = ϕxj[t − 1] + Φ (xj[t − 24K] − ϕxj[t − 24K − 1]) + ϵj[t] (5.3) The stochastic process errors ϵj[t] are drawn from a multivariate normal distribution with covariance matrix Σ as shown in (5.4). This approach models spatial correlation in the load across the power system buses. The covariance matrix is assumed to be time-invariant. ϵ ∼ N (0, Σ) (5.4) Load forecasts are created for each bus by the sum of the deterministic seasonal mean and a forecast the stochastic process ˆxj[t] as shown in (5.5). Given the realizations of the stochastic process up to time t The stochastic process is forecast for time t + τ by recursively using (5.6) for τ = 1, . . . , T , where T is the forecast horizon. When the time indices on the right hand side of (5.6) are in the future, forecast values are used in place of measured values. ˆLj[t + τ ] = sjµ[t + τ ] + ˆxj[t + τ ] (5.5) ˆxj[t + τ ] = ϕxj[t + τ − 1] + Φ (xj[t + τ − 24K] − ϕxj[t + τ − 24K − 1]) (5.6) 5.3.2 Generator In this subsection, we describe the models used to simulate generators that participate in a DYMONDS framework for economic dispatch. Models and methods for electric power generators that participate in the DYMONDS economic dispatch were introduced in [5, 50]. The generator’s decison making problem is shown in (5.7). Given a forecast of electric energy prices ˆρe = [ˆρe[1], ˆρe[2], . . . , ˆρ e[T ]]T , a generator optimizes a power generation schedule, P (MW), seeking to maximize its proﬁts subject to its internal dynamics. The proﬁt is the market energy price minus the power generation cost function C(P ). We assume that the cost function of the generator follows a quadratic function such as that shown in (5.10). The 71 internal dynamics are modeled by a static ramp rate constraint (5.8) with maximum ramp rate R (MW) and the maximum and minimum generation limits (5.9). max P [t] T∑ t=1 ˆρe[t]P [t]∆ t − C(P [t]) (5.7) s.t. (5.8), (5.9) |P [t] − P [t − 1]| ≤ R, ∀t (5.8) P min ≤ P [t] ≤ P max, ∀t (5.9) C(P ) = β1P + β2P 2 (5.10) This optimization problem will be solved three times. Once given the forecast energy prices, ˆρe, once given a positive perturbation to the next forecast price, ρe+ = [ˆρe[1](1 + δ), ˆρe[2], . . . , ˆρe[T ]] T , and once given a negative perturbation to the next forecast price ρe− = [ˆρe[1](1 − δ), ˆρe[2], . . . , ˆρ e[T ]]T . The resulting optimal generation powers for the immediate market period will be noted as P ∗[1], P +[1], and P −[1]. Using the three price, energy points in (5.11), the generator applies linear regression to estimate the slope and intercept of the DYMONDS marginal cost function of energy M C(E) shown in (5.12), where E = P ∆ t. (∆ tP +[1], ρe+[1]) , (∆ tP ∗[1], ˆρe[1] ) , ( ∆ tP −[1], ρe−[1] ) (5.11) M C(E) = β0 + β1E (5.12) The marginal cost function is integrated to form the cost function of dispatched energy C dym(E) shown in (5.13). Creating a cost function in this way is said to “internalize dynam- ics” of the generator [5]. C dym(E) = β0E + β1 2 E2 (5.13) The minimum and maximum power generation limits for the current market period are also calculated by (5.14) and (5.15) respectively. Here, P [0] is the current power generation 72 setpoint, resulting from the previous market period. The minimum and maximum dispatch in terms of energy are then shown in (5.16) and (5.17). P min[t] = max (P min, P [0] − ∆ tR) (5.14) P max[t] = min ( P max, P [0] + ∆tR) (5.15) Emin[t] = ∆ tP min[t] (5.16) Emax[t] = ∆ tP max[t] (5.17) The generator then transmits its cost function and dispatch limits to the ISO. 5.3.3 EV Driver In this subsection, we describe the probabilistic model of the EV driver’s tranportation be- havior. Each time an EV ﬁnishes a trip and plugs in, this model is used to randomly generate the next trip’s start time, end time, and energy requirement. The energy requirement is the minimum battery SOC needed to complete the trip. The generated trips depend on the time of day and day of the week when the EV ﬁnishes the trip and plugs in. The generated trip can also depend on the EVs SOC when it plugs in. Three types of trips can be generated: a trip to work, a trip home from work, and a weekend trip. A “to work” trip is generated whenever the EV arrives at home from work between Monday and Thursday inclusive. Additionally, a “to work” trip is generated for Monday morning when an EV ﬁnishes its last trip on Sunday. A “to work” trip starts between 6:50 am and 7:50 am with uniform probability.The average American commuting trip by car takes 25 min and travels a distance of 20 mi [60]. Because our simulation is run on ten minute timesteps, we model the trip to work as taking either 10, 20, or 30 minutes with uniform probability. The Nissan Leaf EV has a 24 kWh battery and a range of 84 mi[38]. Using data for the Nissan Leaf and the average commute, we estimate that an EV will use 2.3 kWh per ten minutes of driving. 73 A “to home” trip is generated whenever the EV arrives at work. The starting time of the “to home” trip is assumed to be between 7 and 9 hours after the EV’s arrival time at work, with uniform probability. The length of time spent driving is again either 10, 20, or 30 minutes with uniform probability. A weekend trip is generated whenever an EV arrives home from work on a Friday and whenever an EV ﬁnishes a trip and plugs in on a weekend. When an EV arrives home from work on a Friday or ﬁnishes its last trip on a Saturday, the earliest possible start time for the next trip 8:50 am the next day. Otherwise, if the EV plugs in during the weekend earlier than 7:30 pm, the earliest start time of the next trip is ten minutes later. The latest possible start time of the next trip is 7:40 pm. The start time is then determined by generating binomial random variables for each time period between the earliest and latest start time. The probability of each variable taking a value of 1 is set to 2%. The earliest of these binomials to take a value of 1 is chosen as the trip start time. If none of these variables take a value of 1, then the EV’s next trip will be on the next day, and the appropriate trip is generated. The time spent driving is between 1 and 10 time periods, with an additional restriction that the EV must ﬁnish driving by 7:50 pm. A check is also performed to make sure the trip is feasible given the parameters and SOC of the EV and the trip start time. If the generated trip is not feasible, then the length of time spent driving is shortened to be feasible. To illustrate the resulting transportation behavior of the above model, we simulated 10,000 EVs on a workday and weekend day. Figs. 5.4 and 5.5 show the percentage of EVs connected to the grid at each time over the course of a weekday and a weekend day respectively. 74 Figure 5.4: Weekday EV connection proﬁle Figure 5.5: Weekend EV connection proﬁle 75 5.3.4 Price Forecaster Electric energy prices are known to be highly correlated with the system load. [61] developed stochastic volatility models of energy prices in power systems as a function of load and supply curve. Fig. 5.6 shows one week of real system price data for the PJM system [35]. This data shows that the system energy price can modeled very well with a cubic function of the system load, with a coeﬃcient of determination R2 = 0.97. This relationship has also motivated research on coordinating EV charging to perform “valley ﬁlling” where EVs charge overnight in a way that smooths the total system load as much as possible [45, 43]. We seek to develop a price forecaster that will help EVs plan their charging to minimize the cost of charging as well as smooth the total system load. The prices are forecast according to (5.18). This linear regression model of price is ﬁt to the total system load, but forecast energy prices ˆρe are created as a function of forecast inﬂexible load ˆL, which doesn’t include EV load. This model may not forecast the actual market clearing prices accurately, but it will allow the EV LSE to determine which times are more preferable for charging, where periods having lower inﬂexible load are more preferable for charging. ˆρe[t] = β0 + β1 ˆL[t] (5.18) 5.4 Simulation Input Data In this section, we provide speciﬁcs on the data used for our simulation experiments. Fig. 5.7 shows the power system network used in our simulations. The four buses are labeled with their respective numbers. Generators 1 and 2 are connected to buses 1 and 2 respectively. All buses have some uncontrollable inﬂexible load, shown by red arrows. EVs will be connected to bus 4, shown with a green arrow. Generator parameters are shown in table 5.1 and line parameters are shown in table 5.2. Line parameters are taken from an example system in [62]. The line power ﬂow limits are assumed to be much larger than the ﬂows such that line 76 Figure 5.6: PJM system price as a function of load congestion does not occur. Table 5.3 gives parameter data related to EVs. We assume Level 1 charging and the same size battery pack as a Nissan Leaf EV [38]. In order to simulate the system in a reasonable amount of time, 20 EVs are simulated. If all EVs charge at their maximum charging power, the load from EVs would be approximately 24% of the mean total system uncontrollable load. The inﬂexible load model described in 5.3.1 was ﬁt to hourly load data for the DUQ node of the PJM power system [35]. The seasonal mean model in (5.1) is ﬁt by ordinary least squares regression. The parameters of (5.1) are then scaled so that the mean of the total system load is ¯µ = 280 kW. This small load value was chosen so that we could simulate EVs as a large percentage of the system load in a reasonable amount of time. The total system load is then distributed to the four buses according to the values in table 5.4. Figs. 5.8 and 5.9 show the seasonal mean load for the four buses on weekdays and weekends respectively. The SARMA stochastic process model described in (5.3) is ﬁt to the hourly data with K = 1. These same parameter values are then used to simulate the stochastic process on 77 Figure 5.7: Power system network used for simulations Generator 1 P max 2 MW P min 0 MW R 0.5 MW β1 20 β2 100 Generator 2 P max 2 MW P min 0 MW R 2 MW β1 30 β2 120 Table 5.1: Generator Parameter Data 78 line impedance (P.U.) 1-2 0.010+j0.050 1-3 0.007+j0.037 2-4 0.007+j0.037 3-4 0.013+j0.064 Table 5.2: Network Line Parameters Emax (kWh) P max(kW ) η 24 3.3 0.95 Table 5.3: EV Parameter Data Bus 1 Bus 2 Bus 3 Bus 4 0.1 0.34 0.4 0.16 Table 5.4: Distribution of load across buses Figure 5.8: Weekday seasonal load proﬁle at each bus 79 Figure 5.9: Weekend seasonal load proﬁle at each bus a ten minute timestep with K = 6. The stochastic process model with K = 6 will not accurately model the real DUQ load data, but it gives us a reasonable, stationary model of load data to use for simulation purposes. To ﬁt the model, we estimate parameters for ϕ, Φ simultaneously via linear regression, ignoring the term with their product. The resulting stochastic process model is shown in (5.19). xj[t] = 0.98xj[t − 1] + 0.18xj[t − 24K] − 0.176xj[t − 24K − 1] + ϵj[t] (5.19) In order to simulate load that is correlated across the diﬀerent buses, the stochastic process errors are drawn from a multivariate normal distribution. The covariance matrix Σ0 is used to generate correlated errors ϵ0. The matrix Σ0 is given below in (5.20). The correlated errors are then scaled to have a standard deviation proportional to mean load of the bus by (5.21). ¯µ is the total system mean load. diag(s) is a matrix with the bus scaling factors sj on the diagonal and zeros on the oﬀ diagonals . 80 Figure 5.10: Example of forecast load and actual simulation load at Bus 2 Σ0 =          0.98 0.51 0.36 0.29 0.51 0.98 0.51 0.36 0.36 0.51 0.98 0.51 0.29 0.36 0.51 0.98          (5.20) ϵ = 0.02¯µdiag(s)ϵ0 (5.21) The inﬂexible load is forecast using the same models that are used to simulate the in- ﬂexible load, as described in section 5.3.1. Before each market period, the Inﬂexible Load module forecasts the inﬂexible load for the market period and the 8 hrs following it. Fig. 5.10 shows an example trace of a load forecast and the actual simulation load at Bus 2. Because the load model has high autocorrelation, we see that deviations from the forecast persist for hours. The price forecasting model is ﬁt to the results of simulating the power system over one week. Because the generator ramp rates are relatively fast and line limits are not binding, the market clearing energy price is a deterministic linear function of the total system load. Fig. 5.11 shows a scatter plot of price and system load. The resulting price model parameters 81 Figure 5.11: The deterministic relationship between energy price and system load in the simulated system for (5.18) are β0 = 147.27 and β1 = 654.55. 5.5 Experiment Design In this section, we describe the experiments and analysis conducted using the SGRS based simulation of intelligent EVs in the DYMONDS energy market. The main objective of the experiments is to compare the EV charging costs when diﬀerent EV charging strategies are used. An EV will need to intelligently respond to both seasonal patterns in prices and short term randomness in order to minimize their charging costs. We also investigate the ability of the EVs to respond to unforeseen disturbances in the power system. Six diﬀerent approaches to EV charging are tested. Under any MPC or MDP based approach, EVs optimize charging based on a look-ahead horizon that includes the current market period and the following 8 hours. 1. Fast Charging: Under this strategy, EVs simply charge at full power whenever they are plugged in. Each EV charges until its battery is full. 82 Time Period Pricing Tier Price ($/kWh) 7:00 A.M. to 2:00 P.M. Shoulder 0.23 2:00 P.M. to 9:00 P.M. Peak 0.43 9:00 P.M. to 11:00 P.M. Shoulder 0.23 11:00 P.M. to 7:00 A.M. Oﬀ-Peak 0.10 Table 5.5: TOU Energy Pricing Tariﬀ 2. MPC Based TOU Charging (TOU): For this method, we assume that EVs pay for energy under a time of use (TOU) retail pricing scheme. We assume the TOU prices are the weekday summer rates of the Paciﬁc Gas and Electric EV-A tariﬀ, which is speciﬁcally oﬀered for EV owners [63]. Table 5.5 shows the tariﬀ. Given this tariﬀ, EVs optimize their charging schedule by solving the deterministic MPC problem shown in 3.1, but using the energy prices of table 5.5 in place of forecast energy prices. Under this approach, no information about the current state of the power system is used to optimize charging decisions. 3. MPC Based Price-Taker Charging (Price-Taker): In this appraoch to EV charg- ing, EVs optimize their charging schedule by solving the deterministic MPC problem shown in (3.1). At the start of each time period while the EV is plugged in, a new forecast of energy prices is obtained from the price forecaster module. The optimal charging powers for the next market period, resulting from solution of (3.1) by all EVs, are then aggregated by the EV LSE. The EV LSE then purchases a ﬁxed quantity of energy as a price taker in the DYMONDS energy market. 4. MPC Based ALM Charging (MPC-ALM): This approach to EV charging is detailed in section 3.2. 5. MDP Based ALM Charging (MDP-ALM): This approach to EV charging is detailed in section 3.3. This approach is simulated twice to test the dependence of the 83 charging strategy on the assumed Markov model of energy price forecast errors. In the ﬁrst simulation, we assume the forecast errors are highly correlated with a correlation coeﬃcient of βcorr = 0.95. In the second simulation, we assume a correlation coeﬃcient of βcorr = 0.2. In both simulations, we assume the distribution of price forecast errors is constant for all prediction horizons with a mean of 0 and a standard deviation of 4. In order to compare charging costs, a simulation is run with each EV charging method. Each simulation is run for 4 weeks and one day. The extra one day is used to compare the ability of the EV charging methods to respond to unpredictable disturbances in the power system. On this last simulation day, a spike of 0.1 MW is added to the inﬂexible load between 8 a.m. and 9:50 a.m.. This spike is not reﬂected in the price forecasts, but eﬀects the market clearing. This experiment simulates a situation similar to what would happen if a large generator malfunctions and disconnects from the electric grid. The simulation time begins at Jan. 1, 2008, which is a Tuesday. 5.6 Results In this section we report the results of the simulation experiments developed in this chapter. To analyze the charging behavior on weekdays, we have plot the EV ﬂeet average total load proﬁle for weekdays for each charging strategy. The mean EV ﬂeet load proﬁle for weekdays shows the average of the daily EV load proﬁle over all Mondays, Tuesdays, Wednesdays, and Thursdays, totaling 14 days. Fridays are left out because charging for Saturday driving may occur on Friday night. To analyze the charging behavior on weekends, we plot the mean EV ﬂeet load proﬁle for weekends for each charging strategy. The mean EV ﬂeet load proﬁle for weekends shows the average of the total EV load proﬁle spanning Friday, Saturday, and Sunday. Friday is included in this proﬁle because of its unique charging pattern. The mean weekend proﬁle averages 4 weekends. We also analyze charging behavior on particular traces. Because the simulations are random and the amount of energy consumed by EVs varies from 84 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 290 300 310 320 330 340 350 360 370 380 Time of DayMean System Price ($/MWh) Figure 5.12: Average weekday energy price proﬁle without EVs simulation to simulation, the EV charging approaches are compared in terms of average cost per MWh charged. In order to better understand the eﬀect of EV charging on energy market prices, we ﬁrst show results from a simulation of the power system with no EVs. Fig. 5.12 shows the resulting average of system price proﬁle for weekdays and ﬁg. 5.13 shows the mean price proﬁle for weekends. On weekdays, the prices peak around 4 p.m. at 372 $/MWh and reach a minimum of 295 $/MWh between 2 and 4 a.m. . On Saturday and Sunday, the maximum price is around 350 $/MWh near 6 p.m. and the minimum price is around 280 $/MWh near 6 a.m.. In each subsection below, one can compare the resulting prices against these plots, making the price eﬀects of EVs more obvious. 85 Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 260 280 300 320 340 360 380 Time of DayMean System Price ($/MWh) Figure 5.13: Average weekend energy price proﬁle without EVs 5.6.1 Fast Charging Under the Fast Charging strategy, EVs will charge at full power whenever they ﬁnish a trip, charging until the battery is full. The aggregate EV load will depend on the transportation behaviors of the EV drivers. Fig. 5.14 shows the mean EV ﬂeet total load proﬁle for weekdays and ﬁg. 5.15 shows the mean charging proﬁle for weekends. Fig. 5.16 shows an example charging proﬁle. looking at ﬁgs. 5.4 and 5.5, we can see that charging occurs slightly later than when EVs begin traveling. EV trips may be as short as one simulation period and charging will begin as soon as an EV’s trip ends. One can also notice that the mean charging proﬁle is smoother than the single day’s proﬁle. Figs. 5.17 and 5.18 show the resulting average of system price proﬁles for weekdays and weekends respectively when using the Fast Charging strategy. EV charging has a large inﬂuence on the market clearing prices, causing two large price spikes on weekdays. On Friday Evening, energy prices are pushed up to 400 $/MWh. The impact is less obvious on Saturday and Sunday when charging is spread out across the day, but price peaks are still increased by 15 to 25 $/MWh compared with when 86 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0 0.01 0.02 0.03 0.04 0.05 0.06 Time of DayMean Total EV Charging Power (MW) Figure 5.14: Mean EV ﬂeet load proﬁle for weekdays under the Fast Charging strategy Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 Time of DayMean Total EV Charging Power (MW) Figure 5.15: Mean EV ﬂeet load proﬁle for a weekend under the Fast Charging strategy 87 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0 0.01 0.02 0.03 0.04 0.05 0.06 Time of DayTotal EV Charging Power (MW) Figure 5.16: EV ﬂeet load proﬁle for a single weekday under the Fast Charging strategy there are no EVs. 88 12AM 6AM 12PM 6PM 12AM 280 300 320 340 360 380 400 Time of DayMean Energy Price ($/MWh) Figure 5.17: Average system price proﬁle for weekdays under the Fast Charging strategy Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 260 280 300 320 340 360 380 400 420 Time of DayMean Energy Price ($/MWh) Figure 5.18: Average system price proﬁle for a weekend under the Fast Charging strategy 89 5.6.2 MPC Based TOU Charging Fig. 5.19 shows the mean EV ﬂeet load proﬁle for weekdays and ﬁg. 5.20 shows the mean charging proﬁle for weekends under the TOU charging strategy. The charging behavior clearly depends on the transportation patterns as well as the TOU tariﬀ in table 5.5. Under the TOU charging strategy on weekdays, EVs charge for their drive to work during the oﬀ- peak hours of the TOU tariﬀ, which spans from 11 p.m. to 7 a.m.. The ﬂeet charges at a constant power during this period. When charging for the trip home from work, EVs ﬁnish charging before the peak period starts at 2 p.m. There is a very small amount of charging that takes place near 3 p.m. . This is likely because the planning horizon of the EVs, 8 hours, is too short in the case of EVs that leave work early and arrive home to see peak period prices during their entire charge planning horizon. When we look at the weekend charging proﬁle, we see this same eﬀect on Friday afternoon, when EVs plan their charging for much longer weekend trips on Saturday. On weekends, we see that EVs charge all of the energy for their ﬁrst trip of Saturday or Sunday before 7 a.m. of that day. On Saturdays and Sundays, we see a spike in charging as EVs try to charge before the peak pricing period starts at 2 p.m.. In ﬁg. 5.21 we see ﬂat charging proﬁles before leaving for work in the morning and after arriving at work. The charging power in ﬁg. 5.21 is not the same as in 5.19 due to variation in energy needed for driving. Figs. 5.22 and 5.23 show the resulting average of system price proﬁles for weekdays and weekends respectively when using the TOU charging strategy. This charging strategy raises the minimum price on weekdays and also creates a new peak in energy prices before 2 p.m.. Each weekday, a sharp drop in prices occurs at 2 p.m. when the EVs face peak prices. A jump in prices can also be seen each day at 11 p.m., followed by a price drop at 7 a.m.. Price peaks that were seen under the Fast Charging method are reduced signiﬁcantly. 90 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0.002 0.004 0.006 0.008 0.01 0.012 0.014 0.016 Time of DayMean Total EV Charging Power (MW) Figure 5.19: Mean EV ﬂeet load proﬁle for weekdays under the TOU charging strategy Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 0.005 0.01 0.015 0.02 0.025 0.03 Time of DayMean Total EV Charging Power (MW) Figure 5.20: Mean EV ﬂeet load proﬁle for weekends under the TOU charging strategy 91 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0 0.002 0.004 0.006 0.008 0.01 0.012 0.014 0.016 0.018 Time of DayTotal EV Charging Power (MW) Figure 5.21: EV ﬂeet load proﬁle for a single weekday under the TOU charging strategy 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 300 310 320 330 340 350 360 370 380 390 Time of DayMean Energy Price ($/MWh) Figure 5.22: Average system price proﬁle for weekdays under the TOU charging strategy 92 Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 270 290 310 330 350 370 Time of DayMean Energy Price ($/MWh) Figure 5.23: Average system price proﬁle for weekends under the TOU charging strategy 5.6.3 MPC Based Price-Taker Charging Fig. 5.24 shows the mean EV ﬂeet load proﬁle for weekdays and ﬁg. 5.25 shows the mean charging proﬁle for weekends under the Price-Taker charging method. The charging behavior clearly depends on the transportation patterns as well as the price pattern generated in the absence of EVs. On weekdays, EVs charge all of the energy needed to drive to work when the lowest prices would occur without EVs. EVs charge the energy they need for the drive home from work as soon as they arrive at work. On weekends, EVs charge mainly between midnight and 8 a.m.. EVs then have a second, smaller charging peak between 1 and 3 p.m.. Fig. 5.26 shows that actual charging peaks are less smooth and higher than the mean proﬁle. Figs. 5.27 and 5.28 show the resulting average of system price proﬁles for weekdays and weekends respectively when using the Price-Taker charging strategy. On both weekdays and weekends, nighttime charging creates a new signiﬁcant price peak. On weekdays, we see a new price peak around 9 a.m. when EVs arrive at work. However this new morning peak 93 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0 0.01 0.02 0.03 0.04 0.05 0.06 Time of DayMean Total EV Charging Power (MW) Figure 5.24: Mean EV ﬂeet load proﬁle for weekdays under the Price-Taker charging strategy Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 Time of DayMean Total EV Charging Power (MW) Figure 5.25: Mean EV ﬂeet load proﬁle for weekends under the Price-Taker charging strategy 94 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 Time of DayTotal EV Charging Power (MW) Figure 5.26: EV ﬂeet load proﬁle for a single weekday under the Price-Taker charging strategy does not push prices far above the existing system price peak in the early evening. 95 12AM 6AM 12PM 6PM 12AM 300 310 320 330 340 350 360 370 380 Time of DayMean Energy Price ($/MWh) Figure 5.27: Average system price proﬁle for weekdays under the Price-Taker charging strategy Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 280 290 300 310 320 330 340 350 360 370 380 Time of DayMean Energy Price ($/MWh) Figure 5.28: Average system price proﬁle for weekends under the Price-Taker charging strategy 96 5.6.4 MPC Based ALM Charging Fig. 5.29 shows the mean EV ﬂeet load proﬁle for weekdays and ﬁg. 5.30 shows the mean charging proﬁle for weekends under the MPC-ALM charging method. The charging behavior depends on the transportation patterns as well as the price pattern generated in the absence of EVs, but to a lesser degree than the Price-Taker approach. EV charging for the trip to work is spread over the entire time period from 6 p.m. to before 6 a.m. and some is charged around 4 p.m. . On weekdays, EVs charge the energy they need for the drive home over a wider range of time than for the Price-Taker charging approach. On weekends, there appear to be morning and afternoon peaks in charging. The charging is spread out over much more time than with the Price-Taker approach, leading to much smaller peaks in the average charging proﬁle. Because EVs demand bids are price sensitive, they might charge whenever the market clearing price is lower than forecast and not necessarily when the lowest prices are on average. Under the MPC-ALM strategy, charging peaks are much less than under the Price-Taker approach. Fig. 5.31 shows that a single day’s charging proﬁle appears to be much noisier than the mean proﬁle in 5.29. Figs. 5.32 and 5.33 show the resulting average of system price proﬁles for weekdays and weekends respectively when using the MPC-ALM charging strategy. The MPC-ALM strategy does not create signiﬁcant new price spikes on weekdays as happened with Price- Taker charging. 97 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0 0.005 0.01 0.015 0.02 0.025 0.03 Time of DayMean Total EV Charging Power (MW) Figure 5.29: Mean EV ﬂeet load proﬁle for weekdays under the MPC-ALM charging strategy Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 0 0.005 0.01 0.015 0.02 0.025 Time of DayMean Total EV Charging Power (MW) Figure 5.30: Mean EV ﬂeet load proﬁle for weekends under the MPC-ALM charging strategy 98 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0 0.005 0.01 0.015 0.02 0.025 0.03 Time of DayTotal EV Charging Power (MW) Figure 5.31: EV ﬂeet load proﬁle for a single weekday under the MPC-ALM charging strategy 12AM 6AM 12PM 6PM 12AM 300 310 320 330 340 350 360 370 380 390 Time of DayMean Energy Price ($/MWh) Figure 5.32: Average system price proﬁle for weekdays under the MPC-ALM charging strategy 99 Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 280 290 300 310 320 330 340 350 360 370 380 Time of DayMean Energy Price ($/MWh) Figure 5.33: Average system price proﬁle for weekends under the MPC-ALM charging strategy 5.6.5 MDP Based ALM Charging Figs. 5.34 and 5.35 show the mean EV ﬂeet load proﬁle for weekdays under the MDP-ALM charging strategy with the assumptions that price forecast errors are strongly or weakly correlated respectively. Figs. 5.36 and 5.37 show the mean charging proﬁle for weekends under the MDP-ALM charging strategy with the assumptions that price forecast errors are strongly or weakly correlated respectively. On weekdays when strong correlation is assumed, there is a bi-modal charging proﬁle with a high charge rate between 3 and 6 a.m. and again between 8 and 10 a.m.. The charging proﬁle with low correlation is much more spread out, with signiﬁcantly more energy being charged in the afternoon. On weekends, MDP-ALM charging occurs mainly in the early morning for the ﬁrst trip and in the afternoon for other trips. The weekend charging peaks are much larger with the assumption of stronger correlation than under the assumption of weaker correlation. The charging proﬁle is more spread out under the weak correlation assumption, with charging power not reaching zero Friday or Saturday nights. There is also a large diﬀerence between 100 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0 0.005 0.01 0.015 0.02 0.025 Time of DayMean Total EV Charging Power (MW) Figure 5.34: Mean EV ﬂeet load proﬁle for weekdays under the MDP-ALM charging strategy, assuming that price forecast errors are strongly correlated the charging proﬁles near noon, depending on what is assumed about price forecast errors. Figs. 5.38 and 5.39 show charging proﬁles from single days assuming strong and weak correlation for price forecast errors respectively. These plots show rougher proﬁles than the mean charging proﬁles. Fig. 5.40 shows the resulting average of system price proﬁles for weekdays when using the MDP-ALM charging strategy and assuming strong and weak correlation for price forecast errors. There is interesting behavior in the results on either side of 6 a.m. and either side of noon. At both times of day, the EVs charge energy earlier and at a lower price in the high correlation case than in the low correlation case. Fig. 5.41 shows the resulting average of system price proﬁles for weekends when using the MDP-ALM charging strategy and assuming strong or weak correlation for price forecast errors. We can see that around 9 a.m. Saturday and Sunday, there are higher prices from more charging in the high correlation case than in the low correlation case. In the low 101 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0 0.002 0.004 0.006 0.008 0.01 0.012 0.014 0.016 0.018 Time of DayMean Total EV Charging Power (MW) Figure 5.35: Mean EV ﬂeet load proﬁle for weekdays under the MDP-ALM charging strategy, assuming that price forecast errors are weakly correlated Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 Time of DayMean Total EV Charging Power (MW) Figure 5.36: Mean EV ﬂeet load proﬁle for weekends under the MDP-ALM charging strategy, assuming that price forecast errors are highly correlated 102 Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 0 0.005 0.01 0.015 0.02 0.025 0.03 Time of DayMean Total EV Charging Power (MW) Figure 5.37: Mean EV ﬂeet load proﬁle for weekends under the MDP-ALM charging strategy, assuming that price forecast errors are weakly correlated Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 Time of DayMean Total EV Charging Power (MW) Figure 5.38: EV ﬂeet load proﬁle for a single weekday under the MDP-ALM charging strategy, assuming that price forecast errors are strongly correlated 103 Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 0 0.005 0.01 0.015 0.02 0.025 0.03 Time of DayMean Total EV Charging Power (MW) Figure 5.39: EV ﬂeet load proﬁle for a single weekday under the MDP-ALM charging strategy, assuming that price forecast errors are weakly correlated 12AM 6AM 12PM 6PM 12AM 300 310 320 330 340 350 360 370 380 390 Time of DayMean Energy Price ($/MWh) Low Correlation High Correlation Figure 5.40: Average system price proﬁle for weekdays under the MDP-ALM charging strategy 104 Fri 12PM Sat 12AM Sat 12PM Sun 12AM Sun 12PM Mon 12AM 280 290 300 310 320 330 340 350 360 370 380 Time of DayMean Energy Price ($/MWh) Low Correlation High Correlation Figure 5.41: Average system price proﬁle for weekdays under the MDP-ALM charging strategy, assuming that price forecast errors are weakly correlated correlation case, there is more charging later in the day, around noon, resulting in higher prices during those times. 5.6.6 Cost Comparison In order to compare the overall performance of the various EV charging methods discussed in this chapter we must ﬁrst decide on a metric for comparison. Because the simulations conducted in this chapter are stochastic, the total amount of energy consumed by EVs and the inﬂexible load will vary from simulation to simulation. If EVs consume less energy in a simulation trial, the total cost to the EVs is expected to be lower, holding all else is equal. Therefore, we compare the charging methods on the basis of weighted average price per MWh charged by EVs, W ($/MWh). The formula for this metric is given in (5.22). Because price is also a function of the inﬂexible load, which will vary from simulation to simulation, we analyzed the total energy consumed in each simulation. However, the total energy does 105 EV Charging Method Fast TOU Price-Taker MPC-ALM MDP-ALM hi MDP-ALM lo EV Energy (MWh) 6.95 5.95 6.28 6.26 6.5 6.60 EV Cost ($) 2,540 1,973 2,117 2,111 2,149 2,202 W ($/MWh) 365.4 331.6 337.1 337.2 330.6 333.6 Total Energy (MWh) 182.70 183.00 183.34 183.52 183.56 183.66 Table 5.6: Summary of SGRS simulation results not vary more than half a percent across simulations. W = ∑ t ρe[t]E[t] ∑ t E[t] (5.22) Table 5.6 shows the weighted average price paid per MWh charged by EVs under each method. The table also lists the total energy consumed by EVs in the row labeled EV Energy and total cost of charging EVs in the row labeled EV Cost for each simulation. The Fast Charging method is the worst performing approach with W = 365.4 $/MWh. The Price-Taker and MPC-ALM approaches performed similar to each other. The three best approaches are MDP-ALM assuming low error correlation, TOU charging, and MDP- ALM assuming high error correlation, which performed best. We also list the total energy consumed in each simulation in the last row of table 5.6. The inﬂexible load might also inﬂuence the energy prices, but we can see that the relative variation of the total energy consumed across simulations is much lower than that of the EV energy consumption. 5.6.7 Real-Time Responsiveness In this section, we investigate the ability of EV charging strategies to respond to unpre- dictable conditions in the power system. Fig. 5.42 shows a spike in load of 0.01 MW that begins at 8 a.m. on the 29th day of the simulation and ends at 9:50 a.m. on the same day. This spike in load is not accounted for in any of the price forecasts received by EVs 106 under any of the charging strategies, but will only eﬀect charging through the clearing of the energy market. Fig. 5.43 shows the eﬀect of the spike on market prices when there are no EVs present. 12AM 3AM 6AM 9AM 12PM 3PM 6PM 9PM 12AM 0.2 0.25 0.3 0.35 0.4 0.45 Time of DayTotal System Load (MW) Figure 5.42: Total power system load proﬁle without EVs and with a load spike 12AM 6AM 12PM 6PM 12AM 280 300 320 340 360 380 400 420 Time of DaySystem Energy Prices($/MWh) Figure 5.43: Market clearing energy prices for the day of the load spike Fig. 5.44 shows the charging proﬁle of each charging strategy during the load spike. The Fast, TOU, and Price-Taker charging strategies do not respond to the spike in energy prices. The MPC-ALM approach completely stops charging during the load spike. The MDP-ALM method with the assumption of low price forecast error correlation, labeled as MDP-ALM Low, also completely ceases charging during the price spike. However, the MDP-ALM method with the assumption of high price forecast error correlation, labeled as MDP-ALM High, does not completely stop charging during the ﬁrst few timesteps of the spike. Fig. 5.45 shows the energy price proﬁle under each charging strategy during the load spike. Higher prices are observed during the spike under the Fast, TOU, and Price-Taker charging strategies, which do not respond to the spike in energy prices. The MPC-ALM, and MDP-ALM approaches result in lower energy prices than the unresponsive charging methods. In the case using the MDP-ALM High strategy, the price is higher in the ﬁrst few timesteps, but then matches the prices in the MDP-ALM Low case once charging stops. 107 7AM 8AM 9AM 10AM 11AM 0 0.01 0.02 0.03 0.04 0.05 0.06 Time of DayEV Fleet Charging Power (MW) Fast TOU Price−Taker MPC−ALM MDP−ALM High MDP−ALM Low Figure 5.44: EV ﬂeet charging proﬁles for all charging strategies during a load spike 7AM 8AM 9AM 10AM 11AM 300 320 340 360 380 400 420 440 Time of DayEnergy Price ($/MWh) Fast TOU Price−Taker MPC−ALM MDP−ALM High MDP−ALM Low Figure 5.45: System price proﬁle for all charging strategies during a load spike 108 5.7 Discussion Many observations can be made based on the simulation experiments conducted in this chapter. All of the controlled charging approaches lowered charging costs by at least 7% versus uncontrolled Fast Charging on the basis of average price paid per MWh charged. The Price-Taker approach is able to lower EV charging costs by moving consumption to periods of low uncontrolled load. However, this approach concentrates EV charging in a few hours and causes new price spikes, increasing costs. The TOU approach performed surprisingly well for such a simple approach and considering that the tariﬀ was not designed for this simulation. The TOU approach encourages EVs to spread out their charging, avoiding the creation of new price spikes, but also allows for targeting of time periods with low seasonal costs for charging. The MPC-ALM approach to EV charging seemed have the noisiest charging proﬁle and spread charging over many hours. The MPC-ALM approach may be overly inﬂuenced by short-term ﬂuctuations in prices, since it does not model price forecast errors at future timesteps or their correlation over time. The MDP-ALM approach assuming low correlation between price forecast errors did better than the MPC-ALM approach at charging when the inﬂexible load is lowest, but was also noisy and quite spread out. The MDP-ALM approach assuming high correlation between price forecast errors per- formed the best in terms of average price paid per MWh charged. This approach reduced the average price paid per MWh by 9.5% versus uncontrolled Fast Charging. Since the in- ﬂexible load is driven by a high autocorrelation stochastic process, one would expect highly correlated price forecast errors as the load drifts signiﬁcantly. The MDP-ALM approach assuming high correlation models changes in the expected future prices and is less inﬂuenced by short-term noise. Looking at the results of section 5.6.7 we see that the MDP-ALM high case does not react to the price spike as severely as the MPC-ALM or MDP-ALM low cases. The MDP-ALM high case models movements in prices as highly correlated across time, so when the price in the current market period moves, this approach assumes future prices will 109 deviate similarly. This results in the MDP-ALM high case optimizing charging for seasonal price patterns more closely than in the MPC-ALM or MDP-ALM low cases. 110 Chapter 6 An MDP Approach to Valuation of Multi-Function Battery Energy Storage under Uncertainty In this chapter, we propose using the modeling and computational techniques of the average reward, inﬁnite horizon, Markov decision problem (MDP) to estimate the net present value (NPV) of a grid-scale battery energy storage system (BESS) that participates in energy and ancillary services markets. First, we propose an MDP to optimize hourly operational decisions under uncertainty. The solution of this MDP is then used to estimate the rate at which the BESS earns proﬁts and the rate at which the maximum energy storage capacity of the BESS degrades. Finally, we utilize the methods developed in this chapter to estimate and maximize the NPV of a BESS. 6.1 Introduction Before constructing a BESS, investors must estimate its net present value (NPV). The NPV of the BESS depends on its earnings and degradation. Both earnings and degradation depend 111 on how the BESS is operated. Therefore an optimal operating policy must be designed to maximize the NPV of the BESS by considering the interplay of operating strategy, earnings, and degradation over time. In order to maximize NPV, BESS operations should be optimized to consider multiple sources of revenue simultaneously. Electric energy market prices exhibit a daily cycle, creat- ing an opportunity for energy price arbitrage. A BESS can charge when prices are low and discharge when prices are high, arbitraging prices and earning a proﬁt. A BESS can also provide ancillary services such as frequency regulation by varying its charge rate according to the automatic generation control (AGC) signal of an electric grid’s Independent System Operator (ISO). Providing regulation service makes a BESSs future charge rate uncertain, but a BESS also needs control of its charge rate to arbitrage energy prices. Charging and regulation service decisions conﬂict, and so the decisions must be co-optimized. It has been suggested that BESSs could be constructed using degraded Li-ion electric vehicle batteries that are no longer useful for transportation [64]. To date, multiple BESS projects have been based on the same Li-ion technology as electric vehicle batteries [65]. The energy storage capacity of Li-ion batteries is known to decrease as a function of usage. When optimizing the operating policy of a Li-ion BESS, degradation and its eﬀect on future earnings should be accounted for. 6.1.1 Background In this subsection we review the existing work on assessing the value of an energy storage resource (ESR) which participates in both energy and ancillary services markets. [66] asseses the NPV of NaS batteries performing only energy price arbitrage and ﬂywheels performing only regulation service in NYISO. This assessment ﬁxes an ESRs operating schedule and then uses historical price data to calculate revenues that would have been earned. [67, 68, 69] perform deterministic optimal scheduling of energy storage resources over 112 weekly or monthly periods using historical market price data. In this way they are able to estimate the maximum potential earnings of an ESR performing arbitrage or a combination of ancillary services and arbitrage. [67, 68] also analyze cases where the operating sched- ule is optimized according to the previous optimization periods prices, simulating predictive scheduling. These papers ﬁnd that this simple backcasting and scheduling approach captures approximately 85% of the value captured with perfect foresight. [69] proposes estimating the expected proﬁts per period and per MW of power of various small ESRs. The approach in [69] is to optimize an ESRs schedule over a 24 hr period, simulate price forecasting er- rors, and estimate the expected proﬁts of an ESR. [68, 69, 70] assume deterministic eﬀects of providing ancillary services on the ESRs state of charge (SOC), making their optimized schedules not implementable in reality and overestimating the value of the ESR. [71] sim- ulates electric vehicles as ancillary service providers. A single moving horizon stochastic simulation simulates 3 months of operations, accounting for the eﬀect of ancillary services on a 5 minute basis, using historical data. [72]computes the annual value of energy storage in a vertically integrated utility by per- forming deterministic Unit Commitment and Economic Dispatch optimizations with ESRs in a large power system. However, the stochastic eﬀects of providing ancillary services on ESR SOC are not simulated, making the ESRs scheduling not implementable. This approach is able to capture the beneﬁts of an ESR to a power system that cannot be captured by modeling an ESR as a market participant. In [66, 70, 71] degradation of the ESR is accounted for as a continuously incurred cost, but the degradation does not aﬀect the capacity of the storage used in the simulations. 6.1.2 Proposed Approach To date, the engineering literature suggests that running numerous stochastic simulations of ESR operations is the only way to realistically estimate the expected revenues of an 113 ESR that participates in energy or ancillary service markets. In this chapter we propose a markedly diﬀerent approach for estimating and maximizing the NPV of a BESS that participates in energy and ancillary service markets. Our proposed approach is based on the MDP framework. The MDP framework allows us to model and optimize the operations of an ESR whose SOC evolves stochastically due to providing ancillary services. The long-run expected rate at which revenues are earned can then be determined from the solution of an MDP, which models short term operations in detail. This approach could also be extended to include uncertain and Markovian energy and ancillary service prices or a Markovian AGC signal. BESS energy storage capacity degrades with usage. This degradation depends on how the BESS is used and cannot be accurately modeled using simpliﬁed manufacturers ratings in terms of cycles as done in the literature. We propose an approach to modeling incremental degradation as a Markov reward process(MRP). The MDP framework can then be used to estimate the expected rate of degradation while using a given operating policy. We then demonstrate how to penalize degradation causing actions when optimizing the BESS’s operating policy. Finally, we propose a method for estimating and maximizing the NPV of a BESS using the MDP based tools we have developed. Estimating the BESSs NPV involves solving an MDP for an optimal operating policy, estimating the expected rate of degradation, and estimating the expected rate of earnings. This leads to estimates for total annual degradation and earnings. Each year of the planning horizon, an MDP is solved given a new storage capacity, modeling degradation from use. Annual earnings can then be used in a standard NPV formula. NPV can then be maximized by tuning the degradation penalty used use during policy optimization. 114 6.2 MDP for BESS Operations under Uncertainty In this section, we develop the inﬁnite horizon average reward MDP to be solved by a BESS that performs both arbitrage and provides regulation capacity under uncertainty. We present a simpliﬁed model where the ISO’s AGC signal is the only random variable. In this chapter, we assume that the BESS has perfect eﬃciency, and ignore possible correlation in the AGC signal across time periods. We assume a ﬁxed, deterministic pattern of energy prices that repeats every 24 hours. We also assume that the price of regulation service capacity is ﬁxed at all times. This problem formulation ﬁts the decision making problem for a business or residence that may own a BESS and makes a service contract with the local utility. This type of service contract may become common with the adoption of small BESSs such as those recently announced by Tesla Motors [12]. 6.2.1 BESS MDP Formulation We now formulate the decision making problem for the BESS as an inﬁnite horizon average reward MDP. All sets of states and actions, as well as random variables, are discrete, ﬁnite, and countable. • Decision Epochs We assume that the BESS submits its charging and frequency regulation decisions to the ISO at the start of each hourly decision epoch t ∈ T = {1, 2, . . . , ∞} . • System State The MDP has the system state vector s = (e, h) ∈ S. e (MWh) is the BESS SOC, while h is the hour of the day. The BESS SOC is discretized into a set of states E = {0, ∆ e, . . . , emax} and the set of hours is H = {1, 2, . . . , 24} so that the total set of states is S = E × H. The set of possible system states does not depend on the decision epoch t other than through the hour of the day state dimension h. • Actions 115 Given the state of the system at each decision epoch t, the BESS must decide on a baseline charge rate P [t] (MW) and capacity for regulation B[t] (MW). The broadest set of possible baseline charge rates is P = {−P max, −P max + 1, . . . , P max − 1, P max} and the broadest set of possible regulation capacities is B = {0, 1, . . . , 2 ∗ P max}, both with values in units of MW. Together, these form the action vector a[t] = (P [t], B[t]). Actions must be chosen such that a[t] ∈ A(s) , ∀s , ∀t. The discrete and ﬁnite set of feasible actions available at any time, A(s), will depend on the BESS SOC, and will be the largest subset of P × B with each action vector satisfying the constraints (6.1)- (6.5). Constraint (6.1) restricts us to positive amounts of regulation capacity. (6.2) restricts the combination of baseline charge rate and regulation capacity so that the instantaneous charge rate commanded for regulation service will always be possible given the maximum charge rate of the BESS P max. (6.3) restricts the combination of baseline charge rate and regulation capacity so that the instantaneous charge rate commanded for regulation service will always be possible given the maximum discharge rate of the BESS, which we assume is −P max. (6.4) guarantees that we do not over charge the battery in the worst case. (6.5) guarantees that we do not over discharge the battery in the worst case. 0 ≤ B[t] (6.1) P [t] + B[t] ≤ P max (6.2) P [t] − B[t] ≥ −P max (6.3) e[t] + ∆tP [t] + ∆tB[t] ≤ emax (6.4) e[t] + ∆tP [t] − ∆ tB[t] ≥ 0 (6.5) • State Dynamics Given an action vector, the BESS SOC at the next decision epoch, e[t + 1], will be random due to the eﬀects of providing frequency regulation. The BESS SOC transitions 116 according to (6.6), where z[t] is the hourly time integral of the AGC signal. e[t + 1] = e[t] + P [t] − z[t]B[t] (6.6) We approximate the random state transition given s[t] and a[t] with the uniform proba- bility distribution given by (6.7). This distribution could be adjusted to model battery eﬃciency and the distribution of a real AGC signal. Pr (e[t + 1] | s[t], a[t]) =  ||| ||| 1 2|B[t]|+1, when e[t] + P [t] − B[t] ≤ e[t + 1] and e[t] + P [t] + B[t] ≥ e[t + 1] 0, otherwise (6.7) The hour of the day advances according to the deterministic daily cycle shown in (6.8). h[t + 1] =  || || h[t] + 1, h[t] ≤ 24 1, h[t] = 24 (6.8) • Reward Function Given that the BESS system was in some state s and an action vector a was chosen, the BESS will earn random reward r(s, a) as shown in (6.9). r(s, a) represents the total reward earned during the period between decision epochs. The reward function does not have a subscript t, as the reward does not depend on the decision epoch. The reward function does, however, depend on the hour of the day h, which is included in the state of the system s, and the action a. In this problem formulation we assume that energy prices, ρ e h ($/MWh), follow a deterministic daily pattern and that the price of regulation service capacity, ρr ($/MW) is known and constant. The expected value of r(s, a) is written as ¯r(s, a). r(s, a) = ρrB − ρe h(e[t + 1] − e[t]) (6.9) 117 • Markov Decision Problem The inﬁnite horizon average reward MDP for the system we have described is shown in (6.10). (6.10) can be solved for γ∗(s), the maximum per-period average expected reward over an inﬁnite horizon when starting in state s, for each state s ∈ S. γ∗(s) is composed of a bias for starting in some initial state, b∗(s), and the gain or stationary reward, γ∗, as shown in (6.11). γ∗(s) = max π∈Π lim N →∞ 1 N E π [ N∑ t=1 ¯r(s[t], π(s[t])) | s[1] = s ] ∀s ∈ S (6.10) γ∗(s) = b∗(s) + γ∗ ∀s ∈ S (6.11) A stationary decision-making policy π(s) = a lists an action for each state. The policy π must be in the set of feasible decision-making policies Π ensuring that π(s) = a ∈ A(s), ∀s, ∀t. Solving (6.10) for the optimal gain and biases also yields the optimal stationary decision-making policy π∗. 6.2.2 Optimal Operating Policy An example BESS MDP was analyzed for a BESS with a maximum energy storage capacity of emax = 20 MWh and a maximum charge or discharge rate of P max = 10 MW. Energy market prices from PJM ISO on 8/1/10, shown in ﬁg. 6.1, are used as deterministic hourly energy prices. We assumed a regulation capacity price of ρ r = $20/M W . The BESS SOC was discretized with 11 possible SOCs, giving 264 possible states. The MDP is solved using the policy iteration algorithm, resulting in the optimal stationary Markov operating policy [27]. 118 Figure 6.1: Hourly energy prices used for the BESS MDP 4 8 12 16 20 24 0 4 8 12 16 20 HourSOC (MWh) P(MW) Figure 6.2: Optimal BESS policy for baseline charge rate P 119 4 8 12 16 20 24 0 4 8 12 16 20 HourSOC (MWh) B (MW) Figure 6.3: Optimal BESS policy for regulation capacity B 120 In Figs. 6.2 and 6.3, the vertical axis gives the BESS SOC in MWh and the horizontal axis lists the hour of the day. The color of each grid square shows the optimal charging or regulation capacity action to take when the system state matches the coordinates of the square’s lower left vertex. The optimal policy is to arbitrage the price spikes in the middle of the day and provide more regulation capacity at night when prices are relatively constant. By solving the BESS MDP, we obtain the optimal stationary gain γ∗. For this problem instance, the optimal gain is $261.7/hr. The optimal gain can be thought of as the expected rate at which revenues are earned. 6.3 Estimating the Rate of Battery Capacity Degrada- tion under a Markov Operating Policy In the design, operation, and valuation of Li-Ion battery based systems, such as BESSs or EVs, it is important to understand how a battery’s maximum energy storage capacity will degrade over time. Typically, battery manufacturers provide degradation information assuming simple charge and discharge cycles [73]. [74] models degradation based on the number of ﬁxed charging cycles expected from providing regulation service. In real world applications, however, the power demands placed on a battery will vary with the users needs and can be of arbitrary complexity, making the manufacturers information insuﬃcient when optimizing an operating policy.[75] presents a ﬂexible approach to modeling degradation in Li-Ion batteries based on a severity factor map. [73] integrates the severity factor map approach into a Monte Carlo simulation of EV operations and estimates short run battery degradation. We propose a new method for estimating long run Li-Ion battery degradation without using Monte Carlo simulation of long run operations. We propose a new method for estimating the rate of battery degradation under a Markov operating policy, such as that shown in ﬁgs. 6.2 and 6.3. The ideas presented in this section were ﬁrst developed and 121 demonstrated in [18]. The approach that we propose is applicable to any battery chemistry for which a severity factor map model of degradation, as described in [75], is appropriate. 6.3.1 Degradation Model The severity factor map approach relates the state of the battery and charging current to an amount of degradation per Ah-throughput at the given state. The battery state may include temperature Θ, the battery SOC e, and charging current I batt. The severity factor map is a function such as σ(Θ, e, I batt), which yields the rate of capacity degradation relative to the average rate of degradation under a standard charging cycle. The total lifetime Ah- throughput of a battery, Ahtot, is deﬁned in (6.12) as the total charge into or out of a battery under some standard charging and discharging cycle before the battery has reached its end of life (EoL) degradation level. EoL is typically deﬁned as the point where the maximum charge capacity of the battery is 80% of its original value. Ah tot = ∫ tEoL 0 |I batt,standard(t)| dt (6.12) The amount of degradation accumulated over time and under arbitrary usage is the eﬀective Ah-throughput, Ah ef f , as shown in (6.13). The function σ should be determined such that whenever Ah ef f = Ah tot the battery has reached EoL. Ah ef f (t) = ∫ t 0 σ(Θ, e, I batt)|I batt(τ )| dτ (6.13) If at any decision epoch, the system is in state s and action a is taken, then the expected eﬀective Ah-throughput incurred before the next decision epoch is Ah ef f (s, a). If we assume that the current is constant for a given state transition from s[t] to s′[t + 1] with action a[t], which is shown as ¯I batt(s, a, s′), then Ah ef f (s, a) can be approximated by (6.14). ¯σ(s, a, s′) is the average value of the severity factor map over the state transition, which can be found by integrating σ and using the average value theorem of calculus. Ah ef f (s, a) = ∑ s′ Pr(s′ | s, a)¯σ(s, a, s′)| ¯I batt(s, a, s′)| (6.14) 122 6.3.2 Estimation of Capacity Degradation Rate Given an MDP for operating a BESS, a stationary Markov operating policy, π, and the relevant battery parameters, one can calculate Ah ef f (s, π(s)), ∀s ∈ S. To estimate the expected long run rate at which eﬀective-Ah are accumulated under a policy π, we replace the reward function of the MDP in (6.10) with Ah ef f (s, π(s)) and execute the policy evaluation step of the policy iteration algorithm. The policy evaluation step results in the gains and biases for the MDP. The resulting gain would represent expected eﬀective-Ah accumulated per period under policy π, Ah ef f (π). Given the appropriate battery data, Ah ef f (π) can be converted to MWh of capacity lost. We now illustrate the proposed method for estimating the capacity degradation rate with a numerical example. First, we assume that the severity factor map follows the function in (6.15), where DOD is the depth of discharge as deﬁned in (6.16). σ(DOD) = 1 + 2(DOD) 2 (6.15) DOD[t] = 1 − e[t] emax (6.16) Assuming, a constant terminal voltage for the BESS of 1kV, we calculate a constant current for each possible state transition, ¯I batt(s, a, s′). Ah ef f (s, π∗(s)) was then calculated using for the optimal policy shown in ﬁgs. 6.2 and 6.3. The expected eﬀective-Ah-throughput is shown for each state under this policy in ﬁg. 6.4. We can see in ﬁg. 6.4 that more degradation is caused in states where the optimal policy is a high charge or discharge rate or in states with a low SOC. Using the policy evaluation step of the policy iteration algorithm, we calculate the long run rate at which eﬀective-Ah accumulates to be Ah ef f (π) = 9, 017 (eﬀective-Ah/h). One can interpret the policy evaluation step as calculating a probability weighted sum of Ah ef f (s, π∗(s)), using the long run fractions of time spent in each state as the probability weights. Given a value of Ah tot, the lifetime Ah-throughput under a standard test charging cycle, 123 4 8 12 16 20 24 0 4 8 12 16 20 HourSOC (MWh) Effective Ah−Throughput Figure 6.4: The expected eﬀective-Ah throughput for each state, Ah ef f (s, π∗(s)) under the policy of section 6.2.2 the battery capacity degrades at a rate of Φ MWh of lost capacity per eﬀective Ah-throughput as given by 6.17. Φ = 0.2e max Ahtot (6.17) The expected long run rate of capacity loss in MWh is then ΦAh ef f (π). Assuming a value of Ah tot = 87.6 MAh, the BESS capacity would fade at a rate of 4.12E−4 MWh/h under the operating policy of section 6.2.2. 6.4 Penalizing Battery Degradation Cost in the BESS MDP In this section, we will extend the MDP for optimal BESS operations described in section 6.2 to include battery degradation costs. Given a capital cost C ($/MWh capacity) for the BESS, the expected battery degradation cost of being in state s and taking action a is δ(s, a) deﬁned in (6.18). 124 δ(s, a) = ξAh ef f (s, a)ΦC (6.18) Depending on the relative importance of battery degradation, the degradation cost can be scaled by a weighting factor ξ. The expected degradation cost can be subtracted from the MDP reward function (6.9) of Section 6.2 in order to penalize actions that cause battery degradation. We refer to the BESS MDP which uses this degradation penalizing reward function as the BESS MDP with degradation cost. Figs. 6.5 and 6.5 show the resulting optimal policy for the example BESS when C = $1MM/MWh and ξ = 1. By comparing ﬁgs. 6.5 and 6.2 we see that charging starts earlier in the morning and at lower rates than when it is not considered. In ﬁg. 6.6 we can see that the maximum amount of regulation capacity provided when battery degradation is considered is only 8 MW. The maximum amount of regulation capacity is provided in fewer states when battery degradation costs are considered. Figs. 6.5 and 6.5 show that in many states it is optimal for the battery to take no action. All of these changes in the optimal operating policy result from penalizing degradation causing actions. Fig. 6.7 shows the expected eﬀective 4 8 12 16 20 24 0 4 8 12 16 20 HourSOC (MWh) P(MW) Figure 6.5: Optimal policy for baseline charge rate P with degradation cost and ξ = 1 Ah-throughput for each state under the policy optimized while considering degradation. By comparing ﬁgs. 6.7 and 6.4, one can notice that many states have lower values of expected 125 4 8 12 16 20 24 0 4 8 12 16 20 HourSOC (MWh) B (MW) Figure 6.6: Optimal policy for regulation capacity B with degradation cost and ξ = 1 eﬀective Ah-throughput when battery degradation is considered. Under the policy optimized while penalizing degradation, the long run rate of battery capacity fade is estimated to be 8.6E−5 MWh/h. This is one ﬁfth the rate of degradation of the policy that did not consider degradation. For the BESS MDP when considering degradation, we compute the expected revenue rate by ﬁnding the stationary gain γ′ of the optimal policy, but with the reward function that does not include a degradation cost. This is because we assume that no maintenance actions are taken during operations, and so the BESS does not actually pay a degradation cost as it operates. The degradation cost is simply a penalty added to the reward function when optimizing the operating policy. The stationary gain is computed by the policy evaluation step of the policy iteration algorithm. For this problem instance, the expected revenue rate is $150.25/hr. Using the stationary gain to compute the expected earnings over a long period of time ignores the fact that energy storage capacity degrades over time, which we address in section 6.5. 126 4 8 12 16 20 24 0 4 8 12 16 20 HourSOC (MWh) Effective Ah−Throughput Figure 6.7: The expected eﬀective-Ah-throughput for each state, Ah ef f (s, π∗(s)), under the policy of section 6.4 6.5 Estimation and Maximization of NPV The proposed method for estimating the NPV of a degrading BESS is given Table 6.1. This method estimates the NPV with a planning horizon of ymax years, and a discount rate of m. In each year, we solve the BESS MDP with degradation cost for an optimal policy for year y, π∗ y. We then estimate the rate at which revenues are earned for this policy, γ′ y, by executing the policy evaluation step for policy π∗ y and the reward function of (6.9). The annual earnings are calculated assuming the expected revenues are earned every hour of the year. The expected rate of accumulation of eﬀective-Ah under policy π∗ y is then calculated as described in section 6.3.2. We assume that the expected rate of degradation occurs each hour of the year and calculate the new maximum energy storage capacity for the next year, e max y+1 .. This process repeats for each year of the planning horizon before calculating NPV. 127 I.) For y = 1 . . . , ymax 1.) Solve the BESS MDP with degradation cost for π∗ y 2.) Execute the policy evaluation step using reward function (6.9) and π∗ y 3.) Set γy equal to the stationary gain from step 2.) 4.) Calculate expected annual earnings, Earningsy = 8760 ∗ γy 5.) Calculate Ah ef f (π∗ y) as described in section 6.3.2 6.) Set emax y+1 = e max y − 8760 ϕ Ah ef f (π∗ y) End For II.) Calculate NPV N P V = ymax∑ y=1 Earningsy (1 + m)y Table 6.1: Proposed Procedure for Estimating NPV BESS owners want to operate the BESS in such a way that the NPV of the BESS is maximized. The NPV depends heavily on how the battery is used and the degradation caused by usage. To maximize the NPV of the BESS, one can tune the degradation cost weight ξ in (6.18). This tuning must be done without having any explicit derivatives of NPV available. Therefore, line search methods such as golden section search can be used to optimize the NPV of a BESS. 6.5.1 Results The proposed procedure for estimating NPV was executed for various values of ξ. Figure 6.8 shows how the battery capacity is expected to degrade over time when diﬀerent weights are placed on degradation cost. Figure 6.9 shows expected annual revenues for each year of the planning horizon. When ξ is small, revenues are large in early years, but the battery capacity quickly fades. When ξ is large, revenues are relatively smaller in the early years, but larger in later years because the capacity has not degraded as much. However, larger 128 values of ξ do not necessarily increase NPV as revenue in later years is discounted. The expected NPV is given for diﬀerent degradation cost weights in Table 6.2. Of the values tested, ξ = 0.5 yielded the largest expected NPV. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 5 10 15 20 Yearemax (MWh) ξ=0 ξ=0.1 ξ=0.5 ξ=1 Figure 6.8: Expected BESS Energy Storage Capacity Case ξ = 0 ξ = 0.1 ξ = 0.5 ξ = 1 NPV ($MM) 8.575 9.644 12.659 11.101 Table 6.2: Estimated NPV for all Cases 129 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 0.5 1 1.5 2 2.5 x 10 6 YearUndiscounted Revenue ($) ξ=0 ξ=0.1 ξ=0.5 ξ=1 Figure 6.9: Expected BESS Annual Revenues 130 Chapter 7 AGC Modeling for Energy Storage Operations Energy storage resources (ESRs) are being used for secondary frequency regulation in the bulk electric power grid. In order to optimize the economic scheduling of an ESR using look- ahead model predictive control, predictive models of the automatic generation control (AGC) signal and its eﬀect on an ESRs state of charge are needed. In this chapter we investigate predictive methods that would be useful to an ESR that provides regulation service in a liberalized market setting. 7.1 Introduction ESRs, such as electrochemical batteries or ﬂywheels, can rapidly change power output and are well suited for providing secondary frequency regulation service in bulk electric power systems. In this chapter, we investigate forecasting tools that can be used by an ESR participating in both liberalized electric energy markets and frequency regulation capacity markets. These markets are typically cleared on an hourly basis. At the start of each hour, we assume that an ESR would submit a baseline charge or discharge rate and a capacity 131 for frequency regulation to the system operator or balancing authority. Between the hourly decision epochs, the ESRs instantaneous power demand or supply is dictated by the ESRs hourly decisions and the balancing authority’s AGC signal. Responding to the AGC signal over an hour can have a signiﬁcant cumulative eﬀect on the amount of energy stored in the ESR, known as the state of charge (SOC). An ESR can use model predictive control (MPC)[76] to optimize its hourly decisions and maximize proﬁts. An MPC approach requires a forecast of the AGC signal and the AGC signals cumulative eﬀect on the ESR SOC on an hourly basis. Some previous work has analyzed real-world AGC signals. Frequency domain and seasonal analyses of an AGC signal on sub-hourly timescales are demonstrated in [77]. However, little work has focused on the prediction of the AGC signal or forecasting the SOC of an ESR that provides frequency regulation. Timeseries models have been popular in power systems for forecasting price or wind power[29, 78]. 7.2 Hourly AGC Modeling In this section we explore statistical models for predicting the hourly integral of a capacity normalized AGC signal, which we refer to as the hourly AGC energy. In the Bonneville Power Administration (BPA), imbalance generation is dispatched every 5 minutes and is analogous to an AGC signal. Fig. 7.1 shows a histogram of the hourly AGC energy from BPA in 2012 [79]. Normalizing the dispatched power with respect to imbalance generation capacity gives unitless values between -1 and 1. Integrating these values with respect to time gives units of hours. A value of 1 corresponds to the imbalance generation being dispatched to maximum output for an entire hour, a value of -1 corresponds to dispatch to minimum output for an entire hour, and a value of zero indicates dispatch for equal amounts of energy up and down over an hour. As can be seen in Fig. 7.1, the distribution of AGC energy is centered near zero with signiﬁcant positive and negative values occurring frequently. This suggests that it would be prudent for an ESR to consider the eﬀect of an AGC signal on 132 −1 −0.8 −0.6 −0.4 −0.2 0 0.2 0.4 0.6 0.8 1 0 500 1000 1500 Integrated Normalized Imbalance Generation (hrs)Counts Figure 7.1: Distribution of imbalance generation dispatched in BPA SOC when scheduling over a planning horizon of more than one hour. Fig. 7.2 (a) is a scatter plot with the vertical axis measuring an hours AGC energy and the horizontal axis measuring the previous hours AGC energy. Fig. 7.2 (b) plots each hours AGC energy on the vertical axis and the normalized AGC signal broadcast 5 minutes prior to the start of each hour on the horizontal axis. Various Table 7.1 shows three possible time series models for forecasting hourly AGC energy. We analyzed the last 2763 hours of the BPA dataset since it was not missing any data. In all models, the predicted value is y[h], the hourly AGC energy in hour h. Model 1) is a linear regression model using the last observed AGC signal (on a 5-minute basis), x[t − 1], as the predictor. This type of purely stationary prediction is applied in [78] for wind power. Model 2) also incorporates daily seasonal terms where hour[h] is the time of day for data h. The seasonal terms S and C are deﬁned in (7.1) and (7.2) . ST [h] = sin ( 2π hour[h] T ) (7.1) CT [h] = cos ( 2π hour[h] T ) (7.2) Model 3) is an autoregressive, moving average, lag 2 model, or ARMA(2,2), which uses the last two previous prediction errors, , and the last two previously observed values of the 133 −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 Previous Hour's AGC Energy (hrs)AGC Energy (hrs) −1 −0.5 0 0.5 1 −1 −0.5 0 0.5 1 Last Observed Normalized AGC SignalAGC Energy (hrs) (a) (b) Figure 7.2: Scatter plot of hourly AGC energy with the previous hour’s AGC energy (a) and the last observed AGC signal (b) Model Fit MSE 1 y[h] = 0.010 + 0.532x[t − 1] 0.023 2 y[h] = 0.01 + 0.73x[t − 1] − 0.30y[h − 1] + 0.06C12(hour[h]) − 0.03S12(hour[h]) + 0.02C24(hour[h]) − 0.05S24(hour[h]) 0.020 3 y[h] = 0.02 + 0.31y[h − 1] + 0.12y[h − 2] − 0.11ϵ[h − 1] + 0.11ϵ[h − 2] 0.032 Table 7.1: Fitted Models hourly AGC energy as predictors [59]. Models 1) and 2) are ﬁt by least squares and model 3) was ﬁt using the armax function available in the Matlab System Identiﬁcation Toolbox. All of the model parameters in table 7.1 are statistically signiﬁcant. These results tell us that useful predictive models of AGC energy can be built from historical AGC data. 7.3 Forecasting the Next SOC In this section, we propose a method for forecasting an ESRs next SOC given the ESRs operational decisions and a forecast value of the hourly AGC energy. This method does not require building or simulating from a sub-hourly timescale model of the AGC signal. First, 134 however, we must explain in detail how providing regulation service aﬀects the ESRs SOC. In order to provide regulation service for the duration of hour h, an ESR must commit to a baseline charge rate, P [h] (MW), and a regulation capacity, B[h] (MW). The balancing authority then broadcasts a capacity normalized AGC signal, x[t], during time-step t of hour h. This signal is broadcast every 5 minutes in BPA. The ESR then responds to the AGC signal by supplying power Pout[t] (MW) to the grid or drawing power Pin[t] (MW) from the grid as determined by (7.3) and (7.4). Pout[t] = max (0, −P [h] + B[h]x[t]) (7.3) Pout[t] = max (0, −P [h] + B[h]x[t]) (7.4) In economic scheduling of ESRs, it is common to model the evolution of an ESRs SOC with a discrete time linear dynamic equation such as 7.5 [71]. e[t] is the ESR state of charge (MWh) at time t, α is the energy conversion eﬃciency (unitless), and the length of the time-step is ∆t (hrs). α has a value between 0 and 1. e[t + 1] = e[t] + αPin[t]∆t − 1 α Pout[t]∆t (7.5) Due to the energy conversion eﬃciency of an ESR, discharging and charging have diﬀerent eﬀects on the ESRs SOC. This means that a forecast of the AGC energy is not suﬃcient to determine the next ESR SOC. Given the operational decisions P [h] and B[h], the SOC at the start of hour h, e[h], and a value of the hourly AGC energy, y[h], the expected value of the ESRs SOC at the end of the hour is given by 7.6. E [e[h + 1] | e[h], P [h], B[h], y[h]] =e[h] + αE [t=12∑ t=1 Pin[t]∆t | e[h], P [h], B[h], y[h] ] − 1 α E [t=12∑ t=1 Pout[t]∆t | e[h], P [h], B[h], y[h] ] (7.6) We refer to the ﬁrst expectation on the right side of (7.6) as the expected energy in and the second expectation on the right as the expected energy out. If these two expectations can be 135 −1 −0.5 0 0.5 1 0 0.2 0.4 0.6 0.8 1 Hourly AGC Energy (hrs)Energy Out (MWh) −1 −0.5 0 0.5 1 0 0.2 0.4 0.6 0.8 1 Hourly AGC Energy (hrs)Energy In (MWh) (b)(a) Figure 7.3: A non-linear relationship between the hourly AGC energy and the energy out (a) or energy in (b) estimated, then we can estimate e[h+1]. Therefore, we suggest a method for determining the expected energy in or out. The decisions P [h] and B[h] aﬀect the energy in and out through equations (7.3) and (7.4), so as an example we will estimate the expected energy in and out with P [h] and B[h] set to 0 and 1 MW respectively. These decisions correspond to an ESR that provides frequency regulation without a biased charge rate. Figs. 7.3 (a) and (b) show the relationship between the energy out or in and the hourly AGC energy. These plots are based on the same BPA dataset used in section 7.2. Given some value of y[h], we propose estimating the expected energy in or out by using local linear regression with a Gaussian weighting kernel [53]. We choose this approach because it does not require specifying or ﬁtting a complex function to the data, which appears to have diﬀerent behavioral regimes. Local linear regression solves the optimization problem in (7.7) for a given value of, X0, using the whole data set of N points (X[i], Y [i]), and a bandwidth parameter H. In our problem, the Xs are the hourly AGC energy and the Y s are the energy in or out. min a0, b0 N∑ i=1 1 √2π exp ( −(X[i] − X0) 2 2H 2 ) (Y [i] − a0 − b0X[i]) 2 (7.7) The predicted value ˆY0, which corresponds to X0, is then given by (7.8), where a∗ 0 and b∗ 0 are 136 the solutions to (7.7). ˆY0 = a∗ 0 + b∗ 0X0 (7.8) Fig. 7.3 shows the estimated expected values of energy in or out in black. These values are calculated using a bandwidth of 0.1. When the hourly AGC energy is positive, the expected energy out (in) is nearly equal to the AGC energy (nearly zero). When the AGC energy is negative, the expected energy out (in) is nearly zero (equal to the opposite of the AGC energy). When forecasting the next ESR SOC e[h + 1] at time h, y[h] is not known with certainty. Therefore, a useful forecast of e[h + 1] would be as in (7.9) without conditioning on y[h]. E [e[h + 1] | e[h], P [h], B[h], y[h]] =e[h] + αE [t=12∑ t=1 Pin[t]∆t | e[h], P [h], B[h] ] − 1 α E [t=12∑ t=1 Pout[t]∆t | e[h], P [h], B[h] ] (7.9) As shown in section 7.2, a forecast ˆy[h] can be made using information available at time h. Because the relationship between y[h] and energy in or out is apparently a convex function, simply performing the local linear regression procedure described above for X0 = ˆy[h] would underestimate the expected values of energy in or out without conditioning on y[h]. If the error distribution for the forecast ˆy[h] is known, then an unbiased estimate of energy in or out can be obtained by simulation. For example, if the random variable y[h] has a distribution as in (7.10), values of y[h] can be sampled from the distribution. The local linear regression approach can be applied to each sample to obtain corresponding samples of energy in and out. The mean of the energy in or energy out samples can then be used as unbiased estimates of the expected energy in or expected energy out. Given these estimates, a forecast of e[h+1] can be computed by (7.9). y[h] ∼ N (ˆy[h], σy) (7.10) 137138 Chapter 8 Conclusions and Future Work 8.1 Conculsions One of the ways that the cost of EV ownership can be reduced is if they are made available to provide frequency regulation service, earning revenues. In this thesis, we presented new MDP problem formulation to optimize an individual EV’s decision making given knowledge of the driver’s transportation schedule. This MDP has three sources of uncertainty and optimizes charging and regulation capacity decisions as a price-taker. An approximate SDP algorithm is presented for the optimization of an EVs charging and frequency regulation bids over a continuous space of decisions. The proposed MDP formulation and SDP solution method result in lower average EV charging costs than deterministic MPC charge optimization. Although the improvement in mean charging cost is large in relative terms, it is still very small in absolute terms. We also demonstrate that the proposed method can be solved in a practical amount of time on a personal computer. In reality, if large numbers of EVs are present in the electric grid, their charging decisions would inﬂuence energy markets, so we investigate the integration of EVs into the real-time ALM approach to Transactive Energy and the DYMONDS energy market. We developed an extension to the real-time ALM framework to incorporate decision making that considers 139 uncertainty and autocorrelation in energy prices. An MDP was formulated for EVs that participate in the ALM framework and purchase energy as price sensitive bidders. A large majority of the approaches for optimal charging of EVs in a power system de- scribed in the research literature require EV drivers to communicate their transportation schedule to a smart charging device up to a day in advance. Drivers are not used to planning their transportation so far in advance, and would be overly burdened by such approaches. Therefore, we developed an inﬁnite horizon average reward MDP for optimal autonomous EV charging with stochastic driver behavior. MDPs were described for PHEVs and EVs and the MDP for EVs was solved. Solution of the MDP within a tight optimality tolerence is diﬃcult due to the problem’s size. The optimal policy for EVs is quite conservative since the cost of inconveniencing the driver is very high relative to energy costs. This approach to smart EV charging may be more practical under deterministic retail energy pricing than under stochastic market pricing. In order to compare the performance various EV charging approaches in a market setting, and evaluate their system level impacts, we developed a stochastic, discrete-time, simulation of a small electric power system using the SGRS distributed simulation architecture. Using the simulation, we demonstrated that our proposed MDP based ALM approach outperforms the existing MPC based ALM approach to aggregating loads and bidding in energy markets. The MDP based ALM approach with the assumption of high correlation between price forecast errors performed best in terms of average price paid per MWh. All of the ALM approaches demonstrated the ability to respond to an unexpected price spike. The MDP based ALM approach while assuming high correlation between price forecast errors responded to the spike less so than when assuming low correlation. When the MDP assumes high correlation in price forecast errors, it assumes that the relative attractiveness of charging at one time or another does not change much, making it less responsive spikes. Surprisingly, optimizing charging under TOU retail prices is also shown to have very good performance in minimizing charging costs in the market setting. 140 Before investing in a BESS, investors must estimate the NPV of such a system. The BESS must optimize its operations under uncertainty to maximize NPV while considering battery degradation. Revenues can be maximized by providing multiple electric grid functions si- multaneously. We present a markedly diﬀerent approach to estimating and maximizing the NPV of a BESS when compared to the literature. Instead of relying on exhaustive Monte Carlo simulation, we propose leveraging the analytical tools of the inﬁnite horizon average reward MDP. We demonstrate how to use these tools to estimate the long run rate at which revenues are earned or degradation is incurred. We also demonstrate how considering degra- dation can eﬀect the optimal operations policy and NPV of a BESS. We show that the a degradation penalty can be tuned in order to maximize the NPV of the BESS. As energy storage resources such as EVs and BESSs provide more ancillary services, it is important to develop predictive models of how providing ancillary services will aﬀect SOC. We apply timeseries statistical methods to the analysis of the integrated AGC energy in the BPA balancing authority. These models are shown to be statistically signiﬁcant and useful for predicting integrated AGC energy. We then develop a nonparametric approach to estimating the net eﬀect of AGC energy on energy storage SOC. Our work shows that useful predictive models can be made for real world AGC signals. These predictive models will be useful whenever an energy storage resource optimizes its operating schedule in a look-ahead way. 8.2 Future Work In this thesis, we have developed a new MDP based method for EVs to participate in energy markets as price-sensitive bidders and demonstrated its advantages. The methods in chapter 2 investigate the tradeoﬀ between providing ancillary services and energy consumption of an EV that acts as a price-taker. In today’s electric power grid, economic dispatch of generators for energy and ancillary services is co-optimized. A DYMONDS market that 141 co-optimizes energy and ancillary services should be developed in order to make the best use of ﬂexible generation and demand resources. This would require participants to submit a bidding function of both energy and ancillary service capacity. Methods must be developed for estimating such a multi-dimensional bidding function. In chapter 4, an inﬁnite horizon MDP for optimal autonomous charging with stochastic driver behavior was presented. This problem was computationally diﬃcult to solve, and was not solved to within a tight tolerance. The policy iteration algorithm could not be used for the solution of this MDP because of the large transition probability matrix size. However, this matrix is very sparse. It may be possible to implement the policy iteration algorithm using sparse matrix packages of Matlab. Otherwise, this autonomous approach to smart charging of an EV may be better suited to applications where there are ﬁxed retail electricity tariﬀs. This approach to charging of EVs should also be validated using real driving data. It would be interesting to compare the actual long-run rate of costs versus those predicted by the MDP. This will require large datasets, tracking individual drivers over extended periods of time. In chapter 5, we presented a simulation study of EVs in a DYMONDS energy market. The simulation study was very small, with only 20 EVs on a 4 bus network. Simulating a large ﬂeet of intelligent EVs in a reasonable amount of time will require splitting the ﬂeet into multiple EV LSE modules, and distributing these modules on multiple computers. This simulation testbed should also be used to test the performance of other EV charging methods from literature. The methods presented in chapter 6 for estimating and maximizing a BESS’s NPV should be further developed and validated. If the BESS operates in energy and ancillary services markets, Markov models of energy prices, and regulation service prices could be added. After showing in chapter 7 that an AGC signal exhibits autocorrelation over time, we might also want to include a Markov model of AGC and its eﬀect on SOC. The inﬁnite horizon MDP approach proposed in this thesis assumes that any random variables are well approximated by 142 a stationary Markov chain model. However, seasonal eﬀects can still be modeled using a time inhomogeneous Markov chain model. For example, A stationary but time inhomogeneous Markov chain model of energy prices can be created by modeling price states and state transition probabilities as depending on an hour of the day state h, but not decision epoch t. This approach was used to model energy prices in chapter 4. Energy prices also exhibit season of the year seasonal eﬀects. Modeling season of the year patterns within an hourly decision MDP would require an extremely large state space and might not be practical to solve. In order to model this season of the year variation, we could to solve 4 separate seasonal MDPs and estimate earnings and degradation on a season by season basis. The assumptions made while modeling degradation from providing frequency regulation must also be revisited. In this thesis, we assumed that the current would be constant over the hour. If the AGC signal is a mainly higher frequency signal, then the degradation caused by providing ancillary services will need to be estimated in a more sophisticated way, possibly by Monte Carlo simulation. In order to understand the accuracy of the approach to modeling BESS online operations proposed in chapter 6, the performance of the stationary MDP operating policy should be compared against operations using ﬁnite horizon MPC or MDP methods. The stationary policy would likely earn less revenue as it can’t make use of new forecast information. Finally, the estimated revenues earned under the optimal stationary operating policy and Markov models of random prices should be compared against the revenues earned by the stationary policy when facing the actual prices. This will require running extensive simulations. ISOs have recently been deploying new frequency control strategies to make better use of fast responding energy storage resources. PJM ISO now broadcasts a separate AGC signal, called RegD, for fast responding resources. It would be interesting to apply the methods of chapter 7 to analyze the consequences of responding to RegD instead of the old AGC signal. 143144 Bibliography [1] J. Ingleson and E. Allen, “Tracking the eastern interconnection frequency governing characteristic,” in Power and Energy Society General Meeting, 2010 IEEE, July 2010, pp. 1–6. [2] R. Walling, L. Freeman, and W. Lasher, “Regulation requirements with high wind generation penetration in the ERCOT market,” in Power Systems Conference and Ex- position, 2009. PSCE ’09. IEEE/PES, March 2009, pp. 1–7. [3] “Gridwise transactive energy framework version 1.0,” The GridWise Architecture Coun- cil, Tech. Rep., 2015. [4] J. Joo and M. Ilic, “A multi-layered adaptive load management (ALM) system: Infor- mation exchange between market participants for eﬃcient and reliable energy use,” in Transmission and Distribution Conference and Exposition, 2010 IEEE PES. IEEE, 2010, pp. 1–7. [5] M. Ilic, L. Xie, and J.-Y. Joo, “Eﬃcient coordination of wind power and price-responsive demand; Part I: Theoretical foundations,” Power Systems, IEEE Transactions on, vol. 26, no. 4, pp. 1875 –1884, nov. 2011. [6] “Monthly plug-in sales scorecard,” InsideEVs.com. [Online]. Available: http://insideevs.com/monthly-plug-in-sales-scorecard/ [7] S. Schneider, R. Bearman, H. McDermott, X. Xu, S. Benner, and K. Huber, “An assessment of the price impacts of electric vehicles on the pjm market,” 145 PJM, Tech. Rep., May 2011. [Online]. Available: http://www.pjm.com/markets-and- operations/advanced-tech-pilots/research-and-studies.aspx [8] W. Kempton and J. Tomi´c, “Vehicle-to-grid power implementation: From stabilizing the grid to supporting large-scale renewable energy,” Journal of Power Sources, vol. 144, no. 1, pp. 280–294, 2005. [9] “Deployments,” NEC Energy Solutions, May 2015. [Online]. Available: http://www.aesenergystorage.com/deployments/ [10] C. Marnay, N. DeForest, M. Stadler, and J. Donadee, “A green prison: Santa rita jail creeps towards zero net energy,” in Summer Study, 2011 ECEEE, 2011. [11] “California passes huge grid energy storage mandate,” Greentech Media, Inc., July 2011. [Online]. Available: http://www.greentechmedia.com/articles/read/california- passes-huge-grid-energy-storage-mandate [12] “Powerwall—Tesla Home Battery,” Tesla Motors, May 2015. [Online]. Available: http://www.teslamotors.com/powerwall [13] “Frequency regulation compensation in organized wholesale power markets (ﬁnal rule), order no. 755,” FERC, October 2011. [Online]. Available: http://www.ferc.gov/whatsnew/comm-meet/2011/102011/E-28.pdf [14] J. Donadee and M. Ilic, “Stochastic co-optimization of charging and frequency regulation by electric vehicles,” in North American Power Symposium (NAPS), 2012. IEEE, 2012, pp. 1–6. [15] ——, “Stochastic optimization of grid to vehicle frequency regulation capacity bids,” Smart Grid, IEEE Transactions on, vol. 5, no. 2, pp. 1061–1069, March 2014. [16] J. Donadee, M. Ilic, and O. Karabasoglu, “Optimal autonomous charging of electric vehicles with stochastic driver behavior,” in Vehicle Power and Propulsion Conference (VPPC), 2014 IEEE. IEEE, 2014, pp. 1–6. 146 [17] J. Donadee, “Optimal operation of energy storage for arbitrage and ancillary service ca- pacity: The inﬁnite horizon approach,” in North American Power Symposium (NAPS), 2013, Sept 2013, pp. 1–6. [18] J. Donadee and M. Ilic, “Estimating the rate of battery degradation under a stationary markov operating policy,” in Power and Energy Society General Meeting, 2014 IEEE, July 2014, pp. 1–5. [19] J. Donadee and J. Wang, “AGC signal modeling for energy storage operations,” Power Systems, IEEE Transactions on, vol. PP, no. 99, pp. 1–2, 2014. [20] F. K. Tuﬀner and M. C. Kintner-Meyer, “Using electric vehicles to meet balancing re- quirements associated with wind power,” Paciﬁc Northwest National Laboratory, Tech. Rep., 2011. [21] A. N. Brooks, “Vehicle-to-grid demonstration project: Grid regulation ancillary service with a battery electric vehicle,” 2002. [22] N. Rotering and M. Ilic, “Optimal charge control of plug-in hybrid electric vehicles in deregulated electricity markets,” Power Systems, IEEE Transactions on, vol. 26, no. 3, pp. 1021–1029, 2011. [23] E. Sortomme and M. A. El-Sharkawi, “Optimal charging strategies for unidirectional vehicle-to-grid,” Smart Grid, IEEE Transactions on, vol. 2, no. 1, pp. 131–138, 2011. [24] S. Han, S. Han, and K. Sezaki, “Optimal control of the plug-in electric vehicles for v2g frequency regulation using quadratic programming,” in Innovative Smart Grid Tech- nologies (ISGT), 2011 IEEE PES. IEEE, 2011, pp. 1–6. [25] J. R. Birge and F. Louveaux, Introduction to stochastic programming. Springer Science & Business Media, 2011. [26] D. P. Bertsekas, Dynamic programming and optimal control. Athena Scientiﬁc Belmont, Massachusetts, 1996. 147 [27] M. L. Puterman, Markov decision processes: discrete stochastic dynamic programming. John Wiley & Sons, 2009. [28] W. Shi and V. W. Wong, “Real-time vehicle-to-grid control algorithm under price uncer- tainty,” in Smart Grid Communications (SmartGridComm), 2011 IEEE International Conference on. IEEE, 2011, pp. 261–266. [29] F. J. Nogales, J. Contreras, A. J. Conejo, and R. Esp´ınola, “Forecasting next-day elec- tricity prices by time series models,” Power Systems, IEEE Transactions on, vol. 17, no. 2, pp. 342–348, 2002. [30] H. Heitsch and W. R¨omisch, “Scenario reduction algorithms in stochastic program- ming,” Computational optimization and applications, vol. 24, no. 2-3, pp. 187–206, 2003. [31] G. Infanger, Planning under uncertainty: solving large-scale stochastic linear programs. Boyd & Fraser Publishing Company, 1994. [32] C.-C. Lin, H. Peng, and J. Grizzle, “A stochastic control strategy for hybrid electric vehicles,” in American Control Conference, 2004. Proceedings of the 2004, vol. 5. IEEE, 2004, pp. 4710–4715. [33] M. Pereira, “Optimal stochastic operations scheduling of large hydroelectric systems,” International Journal of Electrical Power & Energy Systems, vol. 11, no. 3, pp. 161–169, 1989. [34] A. Gjelsvik, M. M. Belsnes, and A. Haugstad, “An algorithm for stochastic medium- term hydrothermal scheduling under spot price uncertainty,” in Proceedings of 13th Power Systems Computation Conference, 1999. [35] “PJM markets and operations,” PJM. [Online]. Available: http://www.pjm.com/markets-and-operations [36] D. Ruppert, Statistics and data analysis for ﬁnancial engineering. Springer, 2010. [37] “Lecture 6: Statistical inference for discrete stochastic processes,” Carnegie 148 Mellon University, 2009. [Online]. Available: http://www.stat.cmu.edu/ cshal- izi/462/lectures/06/06.pdf [38] “Nissan leaf electric car, charging and range,” Nissan North America, Inc. [Online]. Available: http://www.nissanusa.com/electric-cars/leaf/charging-range/ [39] M. Gonz´alez Vay´a and G. Andersson, “Centralized and decentralized approaches to smart charging of plug-in vehicles,” in Power and Energy Society General Meeting, 2012 IEEE. IEEE, 2012, pp. 1–8. [40] S. W. Hadley and A. A. Tsvetkova, “Potential impacts of plug-in hybrid electric vehicles on regional power generation,” The Electricity Journal, vol. 22, no. 10, pp. 56–68, 2009. [41] R. J. Bessa, M. A. Matos, F. J. Soares, and J. A. P. Lopes, “Optimized bidding of a ev aggregation agent in the electricity market,” Smart Grid, IEEE Transactions on, vol. 3, no. 1, pp. 443–452, 2012. [42] P. Balram, T. Le Anh, and L. Bertling Tjernberg, “Eﬀects of plug-in electric vehi- cle charge scheduling on the day-ahead electricity market price,” in Innovative Smart Grid Technologies (ISGT Europe), 2012 3rd IEEE PES International Conference and Exhibition on. IEEE, 2012, pp. 1–8. [43] L. Gan, U. Topcu, and S. Low, “Optimal decentralized protocol for electric vehicle charging,” in Decision and Control and European Control Conference (CDC-ECC), 2011 50th IEEE Conference on. IEEE, 2011, pp. 5798–5804. [44] L. Gan, U. Topcu, and S. H. Low, “Stochastic distributed protocol for electric vehicle charging with discrete charging rate,” in Power and Energy Society General Meeting, 2012 IEEE. IEEE, 2012, pp. 1–8. [45] Z. Ma, D. S. Callaway, and I. A. Hiskens, “Decentralized charging control of large pop- ulations of plug-in electric vehicles,” Control Systems Technology, IEEE Transactions on, vol. 21, no. 1, pp. 67–78, 2013. 149 [46] D. Papadaskalopoulos, G. Strbac, P. Mancarella, M. Aunedi, and V. Stanojevic, “De- centralized participation of ﬂexible demand in electricity marketspart ii: Application with electric vehicles and heat pump systems,” Power Systems, IEEE Transactions on, vol. 28, no. 4, pp. 3667–3674, 2013. [47] J.-Y. Joo and M. Ilic, “Distributed scheduling of demand resources in a congested network,” in PES General Meeting— Conference & Exposition, 2014 IEEE. IEEE, 2014, pp. 1–5. [48] ——, “Multi-temporal risk minimization of adaptive load management in electricity spot markets,” in Innovative Smart Grid Technologies (ISGT Europe), 2011 2nd IEEE PES International Conference and Exhibition on. IEEE, 2011, pp. 1–7. [49] ——, “Multi-layered optimization of demand resources using lagrange dual decomposi- tion,” Smart Grid, IEEE Transactions on, vol. 4, no. 4, pp. 2081–2088, Dec 2013. [50] M. Ilic, L. Xie, and J.-Y. Joo, “Eﬃcient coordination of wind power and price-responsive demand; Part II: Case studies,” Power Systems, IEEE Transactions on, vol. 26, no. 4, pp. 1885 –1893, nov. 2011. [51] M. G. Vay´a and G. Andersson, “Smart charging of plug-in vehicles under driving be- haviour uncertainty,” in 12th International Conference on Probabilistic Methods Applied to Power Systems (PMAPS), 2012, pp. 10–14. [52] J. Liu and H. Peng, “Modeling and control of a power-split hybrid vehicle,” Control Systems Technology, IEEE Transactions on, vol. 16, no. 6, pp. 1242–1251, Nov 2008. [53] A. W. Bowman and A. Azzalini, Applied Smoothing Techniques for Data Analysis. Oxford University Press, 1997. [54] “AESC high energy battery pack,” Automotive Energy Supply Corporation. [Online]. Available: http://www.eco-aesc-lb.com/en/product/ [55] “Simpowersystems battery help,” The MathWorks, Inc. [Online]. Available: 150 http://www.mathworks.com/help/physmod/sps/powersys/ref/battery.html [56] O. Karabasoglu and J. Michalek, “Inﬂuence of driving patterns on life cycle cost and emissions of hybrid and plug-in electric vehicle powertrains,” Energy Policy, vol. 60, pp. 445–461, 2013. [57] M. T. Hagan and S. M. Behr, “The time series approach to short term load forecasting,” Power Systems, IEEE Transactions on, vol. 2, no. 3, pp. 785–791, 1987. [58] A. Conejo, M. Carri´on, and J. Morales, Decision making under uncertainty in electricity markets. Springer Verlag, 2010, vol. 153. [59] R. H. Shumway and D. S. Stoﬀer, Time series analysis and its applications, 3rd ed. New York: Springer, 2011. [60] “Commuting in the united states: 2009,” United States Census Bureau, 2011. [Online]. Available: https://www.census.gov/prod/2011pubs/acs-15.pdf [61] P. Skantze, M. Ilic, and J. Chapman, “Stochastic modeling of electric power prices in a multi-market environment,” in Power Engineering Society Winter Meeting, 2000. IEEE, vol. 2. IEEE, 2000, pp. 1109–1114. [62] J. J. Grainger and W. D. Stevenson, Power system analysis. McGraw-Hill New York, 1994, vol. 31. [63] “Electric schedule ev,” Paciﬁc Gas and Electric, March 2015. [Online]. Available: http://www.pge.com/tariﬀs/tm2/pdf/ELEC SCHEDS EV.pdf [64] “Used electric car batteries may get second life,” The New York Times, July 2011. [Online]. Available: http://www.nytimes.com/gwire/2011/07/21/21greenwire- used-electric-car-batteries-may-get-second-life-8495.html [65] “Smart grid storage,” A123 Systems, January 2013. [Online]. Available: http://www.a123systems.com/smart-grid-storage.htm [66] R. Walawalkar, J. Apt, and R. Mancini, “Economics of electric energy storage for energy 151 arbitrage and regulation in new york,” Energy Policy, vol. 35, no. 4, pp. 2558–2568, 2007. [67] R. Sioshansi, P. Denholm, T. Jenkin, and J. Weiss, “Estimating the value of electricity storage in pjm: Arbitrage and some welfare eﬀects,” Energy economics, vol. 31, no. 2, pp. 269–277, 2009. [68] R. H. Byrne and C. A. Silva-Monroy, “Estimating the maximum potential revenue for grid connected electricity storage: Arbitrage and regulation,” Sandia Natl Labs Publications Available Online: http://www. sandia. gov/ess/publications/SAND2012- 3863. pdf, 2012. [69] A. A. Thatte and L. Xie, “Towards a uniﬁed operational value index of energy storage in smart grid environment,” Smart Grid, IEEE Transactions on, vol. 3, no. 3, pp. 1418–1426, 2012. [70] S. J. Kazempour and M. P. Moghaddam, “Economic viability of NaS battery plant in a competitive electricity market,” in Clean Electrical Power, 2009 International Confer- ence on. IEEE, 2009, pp. 453–459. [71] E. Sortomme and M. A. El-Sharkawi, “Optimal scheduling of vehicle-to-grid energy and ancillary services,” Smart Grid, IEEE Transactions on, vol. 3, no. 1, pp. 351–359, 2012. [72] P. Denholm, J. Jorgenson, M. Hummon, T. Jenkin, D. Palchak, B. Kirby, O. Ma, and M. OMalley, “The value of energy storage for grid applications,” NREL Tech. Rep., 2013. [73] A. Di Filippi, S. Stockar, S. Onori, M. Canova, and Y. Guezennec, “Model-based life estimation of li-ion batteries in phevs using large scale vehicle simulations: An introduc- tory study,” in Vehicle Power and Propulsion Conference (VPPC), 2010 IEEE. IEEE, 2010, pp. 1–6. [74] V. Viswanathan and M. Kintner-Meyer, “Second use of transportation batteries: Maxi- mizing the value of batteries for transportation and grid services,” Vehicular Technology, 152 IEEE Transactions on, vol. 60, no. 7, pp. 2963–2970, Sept 2011. [75] S. Onori, P. Spagnol, V. Marano, Y. Guezennec, and G. Rizzoni, “A new life estima- tion method for lithium–ion batteries in plug–in hybrid electric vehicles applications,” International Journal of Power Electronics, vol. 4, no. 3, pp. 302–319, 2012. [76] K. Baker, G. Hug, and X. Li, “Optimal integration of intermittent energy sources using distributed multi-step optimization,” in Power and Energy Society General Meeting, 2012 IEEE. IEEE, 2012, pp. 1–8. [77] R. P. Hafen, K. Subbarao, V. V. Viswanathan, and M. C. Kintner-Meyer, “Requirements for deﬁning utility drive cycles: An exploratory analysis of grid frequency regulation data for establishing battery performance testing standards,” Paciﬁc Northwest National Laboratory, Tech. Rep., 2011. [78] N. Abdel-Karim, M. Ilic, and M. Small, Modeling wind speed for power system applica- tions. INTECH Open Access Publisher, 2011. [79] “Data for balancing reserves deployed,” Bonneville Power Administration, July 2013. [Online]. Available: http://transmission.bpa.gov/Business/Operations/Wind/ReservesDeployedYTD 2012.xls 153","libVersion":"0.3.1","langs":""}