{"path":"lit/lit_notes_OLD_PARTIAL/Passalis20adaptInNormLoadFrcst.pdf","text":"Global Adaptive Input Normalization for Short-Term Electric Load Forecasting Nikolaos Passalis Computational Intelligence and Deep Learning Group AIIA Lab., Dept. of Informatics Aristotle University of Thessaloniki Thessaloniki, Greece passalis@csd.auth.gr Anastasios Tefas Computational Intelligence and Deep Learning Group AIIA Lab., Dept. of Informatics Aristotle University of Thessaloniki Thessaloniki, Greece tefas@csd.auth.gr Abstract—Recent advances in Deep Learning (DL) provided immensely powerful tools for various time series forecasting tasks. However, DL models are often quite sensitive to the used input normalization method, requiring extensive experimentation and ﬁne-tuning to identify and apply the most appropriate method for different tasks. Even though trainable adaptive normalization methods have been recently proposed to overcome this to a certain extend, these methods also tend to remove useful information from the data, ignoring the global statistics of the input time series. To overcome this limitation, in this paper we propose a trainable adaptive normalization approach that is capable of both maintaining important mode information, since global statistics are employed for the normalization, as well as taking into account the current behavior of the time series and adjusting the normalization scheme to this. The effectiveness of the proposed method over baseline and state-of- the-art normalization methods is demonstrated using extensive experiments on two different electric load forecasting datasets. Index Terms—Deep Learning, Adaptive Normalization, Train- able Normalization, Load Forecasting I. INTRODUCTION Deep Learning (DL) provided powerful tools for various time series forecasting tasks, ranging from ﬁnancial time series forecasting [1] to energy production [2] and consumption fore- casting [3], [4]. Despite the ability of DL to extract meaningful high-level features from raw time series data, DL models are often quite sensitive to the used input normalization method. As a result, selecting the most appropriate input normalization scheme is often critical [5], [6]. It is worth noting that in some cases, specialized feature engineering approaches are required just to be able to successfully train the employed DL models, e.g., constructing stationary features for volatile non-stationary ﬁnancial time series [7]. These ﬁndings motivated the development of trainable and adaptive input normalization layers that can learn the most appropriate normalization scheme, for a given data distribution and task, without requiring to design and tune handcrafted normalization methods. Indeed, it was recently demonstrated that developing a trainable adaptive normalization method can lead to signiﬁcantly performance beneﬁts [8]. In some cases, this approach even allowed simpler models, such as MultiLayer Perceptrons (MLPs), to outperform more powerful ones, such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). This method, called Deep Adaptive Input Normalization (DAIN) [8], consist of three separate layers, each of which is responsible for performing a different task (shifting, scaling and gating). Therefore, DAIN works by employing a set of trainable parameters that allows for learning how to shift, scale and perform gating to the input of a DL model, given the current window of observations. In this way, DAIN is capable of not only learning some trivial constant normalization parameters, but to also take into account the distribution from which the current time series observations have been drawn and appropriately alter the applied normalization scheme. As a result, DAIN is able to dynamically alter on-the-ﬂy the applied normalization scheme, overcoming signiﬁcant non-stationarity issues that often arise, e.g., for volatile cryptocurrencies [9]. It is worth noting that the normalization performed by DAIN is mainly based on local information, i.e., information that can be inferred from the current input window instead of the whole training dataset. This results to discarding mode information and leading to a more stationary data distribution. Indeed, this is among the main reasons that enabled DAIN to perform so well on ﬁnancial tasks [8]. However, at the same time, this behavior can be a limiting factor for other tasks, such as load forecasting, where the actual magnitude of the input values are as important as the dynamics/behavior of the input time series. This can be better understood by the following example. First, consider the case of a ﬁnancial forecasting problem, where we want to predict whether the price of an asset will go up or down. The actual price at which the price movements happen typically have limited effect on the prediction accuracy, since many phenomena that can affect a ﬁnancial asset are not directly related to its price. Actually, discarding this information typically allows DL models to generalize better, especially for assets, such as cryptocurrencies, where it is expected that models might operate on regions outside the training ones (e.g., when the price rises above the levels observed in the training set). Now, consider the case of a load forecasting problem where we want to predict the exact value of the load the next day. For this problem the exact value of a measurement, e.g., temperature, often matters as978-1-7281-2547-3/20/$31.00 ©2020 IEEE 1 2020 IEEE Symposium Series on Computational Intelligence (SSCI) December 1-4, 2020, Canberra, Australia Authorized licensed use limited to: BOURNEMOUTH UNIVERSITY. Downloaded on June 25,2021 at 18:18:04 UTC from IEEE Xplore. Restrictions apply. much as its behavior/trend. For example, a dropping trend for the temperature (e.g., a drop of 5◦C over one day) is expected to reduce the energy consumption in the summer (e.g., due to reduced use of air-conditioning units). However, the same drop is expected to increase the expected load in the winter (due to increased needs for heating). Therefore, just observing the trend of the observations is not enough, since the same trend can lead to vastly different outcomes. It becomes apparent that for such tasks we should avoid discarding information that is related to the absolute magnitude of the data. Indeed, using global normalization approaches, that normalize the data according to the global training set statistics, instead of just the local ones that often lead to discarding crucial information about the mode of the data, can improve the forecasting accuracy, as it is also experimentally demonstrated in Section III. Note that in this work we use the term global statistics to refer to the statistics calculated using the whole training set and local statistics to refer to statistics calculated using a small window near the current input to a model. Motivated by these observation we propose a global normal- ization approach, called Global Adaptive Input Normalization (GAIN), that is capable of adaptively ﬁne-tuning the applied normalization scheme to the current window of observations. In this way, the proposed method is capable of both main- taining important mode information, since global statistics are employed for the normalization, as well as taking into account the current behavior of the time series and adjusting the normalization scheme to this. The proposed method employs two trainable neural layers that operate on various statistics extracted from the input time series (e.g., global and local average and standard deviation per feature) and learns how to perform normalization to accommodate the task at hand in an end-to-end fashion. It is worth noting that, to the best of our knowledge, this is the ﬁrst work that proposes a trainable adaptive input normalization approach that can take into account both global and local time series statistics and can be effectively combined with any DL architecture. The ef- fectiveness of the proposed method over baseline and state-of- the-art normalization methods is demonstrated using extensive experiments on two different electric load forecasting datasets. The rest of the paper is structured as follows. First, the proposed method is analytically derived and discussed in Section II. Then, extensive experiments are provided and the proposed method is compared to several other normalization methods in Section III. Finally, conclusions are drawn in Section IV. II. PROPOSED METHOD First, the necessary notation is brieﬂy introduced in this Section and then the proposed method is analytically derived. Let Xt =[x1; x2; x3; ... ; xL]T ∈ RL×d denote a window of a time series that is composed of Ld-dimensional measurement vectors. Also, let X ∈ RN ×L×d denote a collection of N time series windows, which can be used for calculating the statistics for global normalization methods. Global normaliza- tion approaches, such as z-score normalization and min-max scaling, normalize the data according to these statistics, i.e., [x′ti]l = [xti]l − [c1]l [c2]l , (1) where the notation [xti]l is used to refer to the l-th element of a measurement vector xti and c1 and c2 are the vectors used for the normalization process. By setting c1 =min(X) ∈ Rd and c2 = max(X) − min(X) ∈ Rd, then the plain min- max normalization is obtained. Note that the notation min(X) and max(X) is used to refer to the vectors that contain the minimum and maximum values per feature dimension according to the dataset X. Similarly, the global z-score normalization can be obtained by setting c1 = avg(X) and c2 = std(X), where again the notation avg(X)/std(X) is used to denote the vector that contains the average/standard deviation per feature dimension of the dataset X. The pipeline of the proposed method is summarized in Fig. 1. The proposed method works by learning how to adapt the global normalization scheme provided in (1) according to the current input window Xt as follows: [x′ti]l = [xti]l − [c1]l − [s1(Xt)]l [c1]l +[s2(Xt)]l , (2) where s1(Xt) and s2(Xt) are the normalization vectors used to adapt the normalization scheme to the current input Xt, i.e., to the local statistics. The ﬁrst one, s1(Xt), corresponds to the adaptive shifting layer and its response is calculated as: s1(Xt)= g(Xt)W1 + b1 ∈ Rd, (3) where W1 are the weights of the shifting layer, b1 denotes the bias vector of the layer and g(Xt) is a function that is responsible for extracting some (local) statistics for the current input window. In this work, g(Xt) extracts the average, minimum, maximum and standard deviation per input feature dimension for the current input window. Therefore, g(·) is deﬁned as: g(Xt)=[avg(Xt), max(Xt), min(Xt), std(Xt)]T ∈ R4d, (4) while W1 ∈ R4d×d. In this way, the input measurement vector xti is ﬁrst shifted by c1 using the global statistics and, if needed, the proposed layer further adapts it according to the local behavior (current window) by further shifting it by s1(Xt). The next layer, the adaptive scaling layer, is again respon- sible for adjusting the scaling process according to the current window statistics. This layer is similarly deﬁned as: s2(Xt)= g(Xt)W1 + b2 ∈ Rd, (5) where W2 and b2 are the weights and biases of the scaling layer. Again, the function g(·) extracts the aforementioned statistics. This process again allows to perform global scaling according to the global statistics and, if needed, further reﬁne the scaling process using the local statistics of the current 2 Authorized licensed use limited to: BOURNEMOUTH UNIVERSITY. Downloaded on June 25,2021 at 18:18:04 UTC from IEEE Xplore. Restrictions apply. Input Timeseries Local Statistics Extractor Adaptive Shift Layer Adaptive Scale Layer DL Model Global Statistics Extractor Normalization Scheme Normalized Timeseries Fig. 1: Overview of the proposed method. Global Adaptive Input Normalization (GAIN) builds upon global statistics to perform the normalization process, after appropriately ﬁne-tuning them according to the recent (local) observations. input window Xt. This allows to maintain the beneﬁts of global normalization methods, i.e., keep the mode information in the normalized data, while also increasing the invariance of the normalized features, since the effect of distribution shifts can be more easily mitigated using the proposed layers. Also, note that in this work we used simple linear layers both for the shifting and scaling processes. However, more powerful combinations of non-linear layers could be also used to capture more complex phenomena that could affect the normalization process. After the normalization process is completed, the normal- ized output is fed into a DL model fW(·), where W denotes the parameters of the model. The weights of both layers can be trained along with the rest of the parameters of the model in an end-to-end fashion using plain gradient descent as: (6)ΔW = −η ∂L ∂W , ΔW1 = −η ∂L ∂W1 , ΔW2 = −η ∂L ∂W2 , where η is the employed learning rate. Also, note that the implementation of the proposed method can be simpliﬁed by ﬁrst performing global normalization (either min-max scaling or z-score normalization) and then applying (2) with c1 = 0 and c2 = 1. This process has been employed for all the experiments conducted in this paper. III. EXPERIMENTAL EVALUATION The experimental evaluation is provided in this Section. First, the datasets and setups used for the evaluation are provided in Section III-A. Then, the experimental results are presented and discussed in detail in Section III-B. A. Datasets and Experimental Setup Two different datasets were used for all the experiments conducted in this paper. The ﬁrst dataset, abbreviated as “Spain-Load” in this paper, contains data collected over a period of four years from the Spanish Transmission Service operator (TSO) [10], leading to a total of 35,065 collected data points. The data collection period starts on 1 January 2015 and ends on 31 December 2018. The sampling frequency was set to 1 hour, while several features were collected (energy generation from various sources, total load, generation waste, etc.). The dataset is also accompanied by weather data for the corresponding collection period. The weather data concern four different cities: Valencia, Madrid, Barcelona and Seville. All data used for the conducted experiments are publicly available [10]. The second dataset was collected from the Toronto Hydro Corporation and contains hourly electricity load from 1 January 2016 to 31 December 2016 [11], [12], leading to a total of 5,112 collected data points. This dataset is called “Toronto-Load” in this paper. The Spain-Load dataset already contains various forecasts as features, e.g., wind generation forecast, solar generation forecast, etc. These features were discarded to avoid relying on existing prediction models and evaluate the ability of the trained models to extract useful higher level features from raw data. Therefore, only features related to energy generation and consumption were used for the conducted experiments. Furthermore, since date cannot be directly fed to the models, three additional features were constructed to enrich the dataset: a) a hour feature (encoding the current hour of the day, which ranges from 0 to 23), b) a weekday feature (ranging from 0 to 6, one for each day of the week), c) a month feature (ranging from 0 to 11, one for each month of the year) and d) a weekend feature (which denotes whether the current day is a working day or not). The data were also joined with weather data. Weather measurements for all the four Spanish cities were included in 3 Authorized licensed use limited to: BOURNEMOUTH UNIVERSITY. Downloaded on June 25,2021 at 18:18:04 UTC from IEEE Xplore. Restrictions apply. Input Features (24 hours) Forecasting Model 1h Prediction (next 1 hour) F1 Task Input Features (48 hours) Forecasting Model 6h Prediction (average of next 6 hours) F2 Task Fig. 2: Two different load forecasting tasks were used in the experiments conducted in this paper. the dataset as additional features. The used weather features were: a) maximum and minimum temperature for 1h intervals, b) average pressure, c) humidity, d) wind speed and direction, e) cloud coverage, f) rain levels for the last 1 hour and 3 hours, along with g) snow level for the last 3 hours. Linear interpolation was used to ﬁll any missing or corrupted values. The ﬁrst 90% of the data, i.e., 31,557 data samples, were used for training the models, while the remaining 10% was used for testing the developed models. Also, three different versions of the Spain-Load dataset were used: a) the “weather” feature split, where only weather-related features were used for forecasting, b) the “energy” feature split, where only energy related features were used and c) the “combined” feature split, where all the available features were used. This allows for evaluating the effect of using different features on the forecasting precision, along with the behavior of the proposed method on different feature sets. For the Toronto-Load dataset a similar pre-processing pipeline was used. The Toronto-Load dataset contains only load related features, so the dataset was also enriched with the aforementioned day and hour features. Since the dataset spans only one year, month features were not included. Again, the ﬁrst 90% of the dataset was used for training the models and the remaining 10% was employed for the evaluation. Two different forecasting tasks were used for the conducted evaluation experiments, as also shown in Figure 2. For the ﬁrst one the forecasting target was set to the next hour. Therefore, models were trained to predict the load during the next hour, while hourly features during the previous 24 hours were fed to the models. This setup is called “F1 task” (forecasting task 1). Furthermore, to evaluate the developed models under a more challenging setup an additional forecasting task was also employed. Instead of predicting the load during the next hour, the models were trained to forecast the average load during the next 6 hours. This setup is called forecasting task 2 (“F2 Task”). For the F2 task the models were trained using features collected from the previous 48 hours (i.e., they operate on an input window twice as large as the one used for the F1 task). Finally, two different neural network architectures were Input Flatten Fully Connected Layer (512 neurons) Fully Connected Layer (1 neuron) (Optional) Normalization Layer Input Flatten Fully Connected Layer (512 neurons) Fully Connected Layer \u0002\u0002 (1 neuron) (Optional) Normalization Layer 1D Convolutional Layer (kernel 5, stride 1) MLP Model CNN Model Fig. 3: Two different neural network architectures were used for the conducted experiments in this paper. used for the conducted experiments to evaluate the behavior of the proposed method under a wider range of settings: a) a simple Multi-Layer Perceptron (MLP) model and b) a Convolutional Neural Network (CNN) model. The architecture of both models is depicted in Fig. 3. Both models were trained for 10 epochs using a learning rate of 10−3, followed by additional 10 epochs using a lowered learning rate of 10−4 for the Spain-Load dataset. The number of epochs were raised to 50 (100 for the CNN) for the Toronto-Load dataset, since this dataset was smaller. The Adam optimization algorithm, using the default hyper-parameters, was used for the optimization for all the conducted experiments [13]. The ReLU activation function was used for all the layers [14], while the forecasting target was normalized to the 0 ... 1 interval using the training set statistics. B. Load Forecasting Experiments First, the proposed method was evaluated using the Spain- Load dataset for the ﬁrst forecasting task (F1). The results are reported in Table I. An MLP model has been used for all the results reported in Table I. The proposed method was also compared to four other methods: • Global Standardization, where the dataset was nor- malized using z-score normalization (i.e., to have unit variance and zero mean) using the training set statistics, • Global Scaling, where the dataset was scaled to the 0 ... 1 interval according to the minimum and maximum values of the training set, • Local Standardization, where each input window was locally normalized to have zero mean and unit variance (z-score normalization) using the statistics of the current window, and • DAIN, where the Deep Adaptive Input Normalization (DAIN) [8] method was applied (after appropriately tun- ing its hyper-parameters). 4 Authorized licensed use limited to: BOURNEMOUTH UNIVERSITY. Downloaded on June 25,2021 at 18:18:04 UTC from IEEE Xplore. Restrictions apply. TABLE I: Spain-Load Dataset: Evaluation using an MLP model for the F1 task. Normalization Method Feature Split RMSE MAPE R2 Global Standardization Energy 523.7 ± 7.31.333 ± 0.029 0.987 ± 0.000 Global Scaling Energy 578.4 ± 15.41.494 ± 0.042 0.984 ± 0.001 Local Standardization Energy 1808.3 ± 30.25.019 ± 0.109 0.844 ± 0.005 DAIN Energy 757.1 ± 59.42.036 ± 0.178 0.973 ± 0.004 Proposed Energy 432.9 ± 8.21.032 ± 0.029 0.991 ± 0.000 Global Standardization Weather 937.7 ± 96.52.613 ± 0.350 0.958 ± 0.009 Global Scaling Weather 805.6 ± 16.32.138 ± 0.056 0.969 ± 0.001 Local Standardization Weather 2489.7 ± 13.26.995 ± 0.068 0.705 ± 0.003 DAIN Weather 583.3 ± 10.01.509 ± 0.027 0.984 ± 0.001 Proposed Weather 566.9 ± 8.91.458 ± 0.022 0.985 ± 0.000 Global Standardization Combined 816.6 ± 37.62.259 ± 0.124 0.968 ± 0.003 Global Scaling Combined 731.8 ± 18.81.965 ± 0.044 0.974 ± 0.001 Local Standardization Combined 2078.2 ± 20.95.855 ± 0.084 0.794 ± 0.004 DAIN Combined 614.7 ± 27.81.631 ± 0.078 0.982 ± 0.002 Proposed Combined 532.4 ± 19.61.371 ± 0.070 0.986 ± 0.001 TABLE II: Spain-Load Dataset: Evaluation using a CNN model for the F1 task. Normalization Method Feature Split RMSE MAPE R2 Global Standardization Energy 406.4 ± 8.40.931 ± 0.026 0.992 ± 0.000 Global Scaling Energy 427.1 ± 5.31.007 ± 0.027 0.991 ± 0.000 Local Standardization Energy 1426.2 ± 34.73.853 ± 0.111 0.903 ± 0.005 DAIN Energy 504.1 ± 15.21.285 ± 0.059 0.988 ± 0.001 Proposed Energy 393.1 ± 8.30.888 ± 0.022 0.993 ± 0.000 Global Standardization Weather 490.7 ± 36.71.205 ± 0.113 0.988 ± 0.002 Global Scaling Weather 493.8 ± 7.21.207 ± 0.027 0.988 ± 0.000 Local Standardization Weather 1683.0 ± 23.24.587 ± 0.047 0.865 ± 0.004 DAIN Weather 488.4 ± 15.71.220 ± 0.062 0.989 ± 0.001 Proposed Weather 456.3 ± 10.31.106 ± 0.036 0.990 ± 0.000 Global Standardization Combined 466.0 ± 29.31.148 ± 0.101 0.990 ± 0.001 Global Scaling Combined 444.5 ± 7.51.076 ± 0.014 0.991 ± 0.000 Local Standardization Combined 1629.7 ± 51.14.417 ± 0.147 0.873 ± 0.008 DAIN Combined 532.0 ± 162.51.399 ± 0.543 0.985 ± 0.010 Proposed Combined 414.7 ± 6.00.976 ± 0.026 0.992 ± 0.000 TABLE III: Spain-Load Dataset: Evaluation using an MLP model for the F2 task. Normalization Method Feature Split RMSE MAPE R2 Global Standardization Energy 1148.207 ± 25.601 2.948 ± 0.104 0.922 ± 0.004 Global Scaling Energy 1037.290 ± 7.833 2.701 ± 0.020 0.936 ± 0.001 Local Standardization Energy 1887.469 ± 8.211 5.239 ± 0.039 0.789 ± 0.002 DAIN Energy 1444.880 ± 44.806 3.867 ± 0.143 0.876 ± 0.008 Proposed Energy 997.839 ± 22.216 2.497 ± 0.058 0.941 ± 0.003 Global Standardization Weather 1482.220 ± 34.333 4.127 ± 0.128 0.870 ± 0.006 Global Scaling Weather 1326.361 ± 32.854 3.640 ± 0.086 0.896 ± 0.005 Local Standardization Weather 2289.253 ± 32.120 6.430 ± 0.134 0.690 ± 0.009 DAIN Weather 1255.094 ± 49.093 3.291 ± 0.127 0.907 ± 0.007 Proposed Weather 1172.236 ± 27.059 3.147 ± 0.076 0.919 ± 0.004 Global Standardization Combined 1431.119 ± 49.568 3.916 ± 0.193 0.879 ± 0.008 Global Scaling Combined 1157.395 ± 24.078 3.091 ± 0.104 0.921 ± 0.003 Local Standardization Combined 1972.100 ± 27.250 5.480 ± 0.062 0.770 ± 0.006 DAIN Combined 1220.471 ± 47.748 3.158 ± 0.158 0.912 ± 0.007 Proposed Combined 1144.755 ± 26.675 2.970 ± 0.090 0.922 ± 0.004 5 Authorized licensed use limited to: BOURNEMOUTH UNIVERSITY. Downloaded on June 25,2021 at 18:18:04 UTC from IEEE Xplore. Restrictions apply. TABLE IV: Spain-Load Dataset: Evaluation using a CNN model for the F2 task. Normalization Method Feature Split RMSE MAPE R2 Global Standardization Energy 863.962 ± 13.215 2.155 ± 0.041 0.956 ± 0.001 Global Scaling Energy 941.216 ± 40.189 2.364 ± 0.103 0.948 ± 0.004 Local Standardization Energy 1707.210 ± 37.478 4.623 ± 0.091 0.828 ± 0.008 DAIN Energy 1166.946 ± 61.011 3.069 ± 0.180 0.919 ± 0.009 Proposed Energy 848.582 ± 36.808 2.106 ± 0.066 0.957 ± 0.004 Global Standardization Weather 926.484 ± 17.251 2.443 ± 0.065 0.949 ± 0.002 Global Scaling Weather 953.769 ± 26.438 2.485 ± 0.068 0.946 ± 0.003 Local Standardization Weather 2148.147 ± 29.343 5.883 ± 0.090 0.727 ± 0.007 DAIN Weather 923.223 ± 29.383 2.432 ± 0.077 0.950 ± 0.003 Proposed Weather 792.468 ± 4.404 2.104 ± 0.011 0.963 ± 0.000 Global Standardization Combined 1048.783 ± 46.653 2.781 ± 0.164 0.935 ± 0.006 Global Scaling Combined 967.083 ± 41.369 2.451 ± 0.122 0.945 ± 0.005 Local Standardization Combined 1908.356 ± 36.175 5.244 ± 0.021 0.785 ± 0.008 DAIN Combined 1001.138 ± 34.700 2.559 ± 0.071 0.941 ± 0.004 Proposed Combined 883.535 ± 22.545 2.221 ± 0.033 0.954 ± 0.002 Note that, as discussed in Section I, DAIN works with local statistics, discarding information about the mode/distribution from which the data were sampled, similarly to the local standardization approach. On the other hand, global stan- dardization and global scaling methods maintain such in- formation. All methods were applied feature-wise, i.e., each feature dimension was separately normalized. Furthermore, three different evaluation metrics were used for measuring the performance of the methods: a) Root Mean Square Error (RMSE), b) Mean Average Precision Error (MAPE) and c) R2 score [15]. Finally, note that min-max statistics are used for global normalization when the proposed method is used, unless otherwise stated. Several conclusions can be drawn from the results reported in Table I. First, global standardization and global scaling methods work equally well, with global standardization lead- ing to better results for the energy feature split and global scal- ing leading to better results for the “weather” and “combined” feature splits. On the other hand, local standardization leads to signiﬁcantly worse results, e.g., RMSE increases by over two times. The aforementioned behavior can be explained if we consider the nature of the forecasting task, where the employed models were trained to directly predict the load during the next hour. However, this is strongly correlated to the magnitude of the previous load values (for the Energy split) and/or to the magnitude of the temperatures (for the “weather” and “combined” splits), instead of just their relative movements. Local standardization provides more invariant features, which, however, discard the absolute scale of the measurements and make the forecasting task signiﬁcantly harder, as was also explained in Section I. DAIN, despite being based on local standardization, managed in many cases (“weather” and “combined” splits) to achieve better performance than global normalization methods, due to its ability to learn constant parameters that can behave similarly to the global standard- ization methods. On the other hand, the proposed method directly builds upon global standardization methods, allow- ing for learning how to ﬁne-tune the applied normalization scheme according to the local (window) statistics. Indeed, this approach can lead to signiﬁcantly better performance across all the evaluated metrics, as reported in Table I. Another interesting observation is that the “energy” feature split leads to better results compared to the “weather” feature split. Therefore, despite weather being a valid predictor of the future load, the previous load trends allow for more accurate predictions. Quite interestingly, combining the energy and weather features (“combined” feature split) does not increase the forecasting accuracy over the plain “energy” split, possibly due to over ﬁtting phenomena. The proposed method was also evaluated on the same task and dataset using a CNN model. The experiments results are reported in Table II. It is worth noting that all the evaluated methods perform better using the CNN model compared to MLP. The effectiveness of the proposed method under a wide range of settings is again veriﬁed, since using the proposed method leads to the overall best results regardless the used model and feature split. This is further validated in the results reported in Tables III and IV, where the same evaluation is provided for the second forecasting task (F2). To demonstrate and validate the improved learning capacity of the models when the proposed method is employed, we monitored the learning curves during the training process and compared the proposed method to the plain static global scaling approach. The results are plotted in Figure 4 (for the MLP model) and Figure 5 (for the CNN model). Indeed, in both cases the proposed method allows for signiﬁcantly faster convergence, regardless the learning capacity of the employed model. Note that the steep drop in the loss during epoch 10 is due to reducing the learning rate from 10−3 to 10−4. Next, the proposed method was evaluated on the Toronto- Load dataset. The experimental evaluation is provided in Table V for both the MLP and CNN models. Both models were evaluated for the F1 task. Global normalization methods, i.e., global standardization and global scaling, also seem to perform better than local standardization, similarly to the Spain-Load dataset. However, note that global standardization 6 Authorized licensed use limited to: BOURNEMOUTH UNIVERSITY. Downloaded on June 25,2021 at 18:18:04 UTC from IEEE Xplore. Restrictions apply. (a) Energy feature split (b) Weather feature split (c) Combined feature split Fig. 4: Learning curves for the MLP model comparing the proposed method to the global scaling normalization method. (a) Energy feature split (b) Weather feature split (c) Combined feature split Fig. 5: Learning curves for the CNN model comparing the proposed method to the global scaling normalization method. seems to perform signiﬁcantly better when used together with the MLP model. Motivated by this observation, we evaluated the proposed method both with global standard- ization (“Proposed (S)”) and with global scaling (“Proposed (M)”) for this dataset, as it was described in Section II. The experimental results suggest that a) using the proposed method outperforms the corresponding static normalization scheme in all the evaluated cases, b) the proposed method again performs better than DAIN, while c) combining the proposed method with the most appropriate global scaling approach for each dataset/model/task leads to the best results. An additional set of experiments was conducted using the Spain-Load dataset (F1 split, MLP model) to evaluate the impact of each of the four features used for the dynamic local normalization (Section II). The heatmap of the W1 and W2 matrices (after the training process is completed) is shown in Fig. 6. Each column in the heatmap corresponds to each input feature dimension, while each row to each output dimension of the weight matrices. The average and standard deviation features seem to have the greatest impact on the normalization process, compared to the minimum and maximum features. However, all features seem to have a signiﬁcant impact on the adaptive normalization process, given that the initial norm of the weights is about 10−5, which, after the training process is completed, raises over 1. Finally, the sensitivity of the proposed method on the initial- ization of the adaptive shifting and gating layers was evaluated, since another adaptive normalization method, DAIN, requires a (a) Weight matrices used for adaptive shifting (b) Weight matrices used for adaptive scaling Fig. 6: Weight matrices, along with the Frobenius norm of the weights (in parentheses) for the adaptive shifting and scaling layers. “AVG”/“MIN”/“MAX”/“STD” refers to the weights used for the average/minimum/maximum/standard deviation features. The heatmap of the weight matrices has been split according to the four different inputs. very speciﬁc form of initialization in order to ensure that it will work correctly [8]. Therefore, we varied the variance of the Gaussian distribution used for the initialization of the shifting and scaling layers. As shown in Table VI, the proposed method 7 Authorized licensed use limited to: BOURNEMOUTH UNIVERSITY. Downloaded on June 25,2021 at 18:18:04 UTC from IEEE Xplore. Restrictions apply. TABLE V: Toronto-Load Dataset Evaluation Normalization Method Model RMSE MAPE R2 Global Standardization MLP 27.3 ± 0.71.260 ± 0.035 0.995 ± 0.000 Global Scaling MLP 39.0 ± 5.81.820 ± 0.408 0.990 ± 0.003 Local Standardization MLP 240.2 ± 5.710.908 ± 0.165 0.619 ± 0.018 DAIN MLP 34.8 ± 1.31.657 ± 0.057 0.992 ± 0.001 Proposed (M) MLP 29.0 ± 1.11.310 ± 0.063 0.994 ± 0.000 Proposed (S) MLP 25.9 ± 0.51.182 ± 0.017 0.996 ± 0.000 Global Standardization CNN 27.8 ± 1.01.270 ± 0.037 0.995 ± 0.000 Global Scaling CNN 27.6 ± 0.71.255 ± 0.041 0.995 ± 0.000 Local Standardization CNN 163.7 ± 4.07.306 ± 0.169 0.823 ± 0.009 DAIN CNN 35.2 ± 0.81.617 ± 0.050 0.992 ± 0.000 Proposed (M) CNN 26.4 ± 1.01.194 ± 0.042 0.995 ± 0.000 Proposed (S) CNN 25.5 ± 0.51.177 ± 0.038 0.996 ± 0.000 TABLE VI: Effect of altering the initialization variance for the weights of the adaptive shifting and scaling layers (10 training epochs were used for the conducted experiments on the F1 split of the Spain-Load dataset). Model Initial Variance RMSE MLP 10−7 572.9 ± 12.2 MLP 10−6 560.9 ± 18.1 MLP 10−5 567.4 ± 16.0 MLP 10−4 568.3 ± 20.9 CNN 10−7 497.6 ± 29.6 CNN 10−6 474.1 ± 13.3 CNN 10−5 495.0 ± 27.4 CNN 10−4 482.2 ± 10.0 performs quite well for initialization variances up to 10−4, demonstrating that the proposed method can indeed work with generic initialization methods, without requiring any kind of method-speciﬁc initialization. IV. CONCLUSIONS In this paper we proposed a trainable adaptive input normalization approach that works by combining both global and local statistics. To this end, the proposed method uses two trainable neural layers that receive different statistics extracted from the input time series and appropriately learns how to perform normalization adapted to the task at hand in an end-to-end fashion. Experiments conducted on two load forecasting datasets indeed conﬁrm the effectiveness of the proposed method on such tasks, where additional information, apart from the trends of the data, are needed to correctly forecast the behavior of a time series. This paper highlighted the potential of global adaptive input normalization approaches for load forecasting tasks paving the way for developing even more advanced methods, that are capable of separately encoding information regarding the mode of the data, e.g., using the Bag-of-Features mode [16], as well as applying the proposed approach on tasks that go beyond load forecasting, e.g., forecasting the energy that will be generated by renewable energy sources or the price trends in electricity markets. Acknowledgment: This work has been co-ﬁnanced by the European Union and Greek national funds through the Op- erational Program Competitiveness, Entrepreneurship and In- novation, under the call RESEARCH - CREATE - INNOVATE (project code: T2EDK-03048). REFERENCES [1] O. B. Sezer, M. U. Gudelek, and A. M. Ozbayoglu, “Financial time series forecasting with deep learning: A systematic literature review: 2005–2019,” Applied Soft Computing, vol. 90, p. 106181, 2020. [2] H. Wang, Z. Lei, X. Zhang, B. Zhou, and J. Peng, “A review of deep learning for renewable energy forecasting,” Energy Conversion and Management, vol. 198, p. 111799, 2019. [3] H. Shi, M. Xu, and R. Li, “Deep learning for household load fore- casting—a novel pooling deep rnn,” IEEE Transactions on Smart Grid, vol. 9, no. 5, pp. 5271–5280, 2017. [4] W. Kong, Z. Y. Dong, D. J. Hill, F. Luo, and Y. Xu, “Short-term residential load forecasting based on resident behaviour learning,” IEEE Transactions on Power Systems, vol. 33, no. 1, pp. 1087–1088, 2017. [5] P. Nousi, A. Tsantekidis, N. Passalis, A. Ntakaris, J. Kanniainen, A. Tefas, M. Gabbouj, and A. Iosiﬁdis, “Machine learning for forecast- ing mid-price movements using limit order book data,” IEEE Access, vol. 7, pp. 64 722–64 736, 2019. [6] S. Bhanja and A. Das, “Impact of data normalization on deep neural network for time series forecasting,” arXiv preprint arXiv:1812.05519, 2018. [7] A. Tsantekidis, N. Passalis, A. Tefas, J. Kanniainen, M. Gabbouj, and A. Iosiﬁdis, “Using deep learning for price prediction by exploiting stationary limit order book features,” Applied Soft Computing, p. 106401, 2020. [8] N. Passalis, A. Tefas, J. Kanniainen, M. Gabbouj, and A. Iosiﬁdis, “Deep adaptive input normalization for time series forecasting,” IEEE Transactions on Neural Networks and Learning Systems, 2019. [9] S. Lahmiri and S. Bekiros, “Cryptocurrency forecasting with deep learning chaotic neural networks,” Chaos, Solitons & Fractals, vol. 118, pp. 35–40, 2019. [10] “Hourly energy demand generation and weather dataset,” https://www.kaggle.com/nicholasjhana/ energy-consumption-generation-prices-and-weather, accessed: 2020- 08-1. [11] “Toronto hydro,” https://www.torontohydro.com, accessed: 2020-08-1. [12] “Electric-power-hourly-load-forecasting-using-recurrent- neural-networks,” https://github.com/Yifeng-He/ Electric-Power-Hourly-Load-Forecasting-using-Recurrent-Neural-Networks, accessed: 2020-08-1. [13] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” in Proceedings of the International Conference on Learning Represen- tations. [14] X. Glorot, A. Bordes, and Y. Bengio, “Deep sparse rectiﬁer neural networks,” in Proceedings of the International Conference on Artiﬁcial Intelligence and Statistics, 2011, pp. 315–323. [15] N. J. Nagelkerke et al., “A note on a general deﬁnition of the coefﬁcient of determination,” Biometrika, vol. 78, no. 3, pp. 691–692, 1991. [16] N. Passalis, A. Tsantekidis, A. Tefas, J. Kanniainen, M. Gabbouj, and A. Iosiﬁdis, “Time-series classiﬁcation using neural bag-of-features,” in Proceedings of the European Signal Processing Conference, pp. 301– 305. 8 Authorized licensed use limited to: BOURNEMOUTH UNIVERSITY. Downloaded on June 25,2021 at 18:18:04 UTC from IEEE Xplore. Restrictions apply.","libVersion":"0.3.2","langs":""}