{"path":"lit/lit_sources/Zecchin24ForkingUncertaintiesReliable.pdf","text":"1 Forking Uncertainties: Reliable Prediction and Model Predictive Control with Sequence Models via Conformal Risk Control Matteo Zecchin, Sangwoo Park, and Osvaldo Simeone Abstract In many real-world problems, predictions are leveraged to monitor and control cyber-physical systems, demanding guarantees on the satisfaction of reliability and safety requirements. However, predictions are inherently uncertain, and managing prediction uncertainty presents significant challenges in environments characterized by complex dynamics and forking trajectories. In this work, we assume access to a pre-designed probabilistic implicit or explicit sequence model, which may have been obtained using model-based or model-free methods. We introduce probabilistic time series-conformal risk prediction (PTS-CRC), a novel post-hoc calibration procedure that operates on the predictions produced by any pre-designed probabilistic forecaster to yield reliable error bars. In contrast to existing art, PTS-CRC produces predictive sets based on an ensemble of multiple prototype trajectories sampled from the sequence model, supporting the efficient representation of forking uncertainties. Furthermore, unlike the state of the art, PTS-CRC can satisfy reliability definitions beyond coverage. This property is leveraged to devise a novel model predictive control (MPC) framework that addresses open-loop and closed-loop control problems under general average constraints on the quality or safety of the control policy. We experimentally validate the performance of PTS-CRC prediction and control by studying a number of use cases in the context of wireless networking. Across all the considered tasks, PTS-CRC Matteo Zecchin, Sangwoo Park, and Osvaldo Simeone are with the King’s Communications, Learning & Information Processing (KCLIP) lab within the Centre for Intelligent Information Processing Systems (CIIPS), Department of Engi- neering, King’s College London, London WC2R 2LS, U.K. (e-mail: matteo.1.zecchin@kcl.ac.uk; sangwoo.park@kcl.ac.uk; osvaldo.simeone@kcl.ac.uk). (sho The work of M. Zecchin and O. Simeone was supported by the European Union’s Horizon Europe project CENTRIC (101096379). The work of O. Simeone was also supported by the Open Fellowships of the EPSRC (EP/W024101/1) by the EPSRC project (EP/X011852/1), and by Project REASON, a UK Government funded project under the Future Open Networks Research Challenge (FONRC) sponsored by the Department of Science Innovation and Technology (DSIT).arXiv:2310.10299v1 [cs.IT] 16 Oct 2023 2 predictors are shown to provide more informative predictive sets, as well as safe control policies with larger returns. I. INTRODUCTION A. Motivation and Overview In many real-world problems, predictions are leveraged to monitor and control cyber-physical systems. For instance, when planning the path of a robot on the floor of a factory, one may leverage predictions of the other robots’ or agents’ movements [1], [2]. As another example, designing the trajectory of a drone for the purpose of data collection, tracking, or providing wireless connectivity may benefit from access to predictions regarding future data generation, target movements, or wireless traffic levels [3]–[5]. And, as illustrated in Fig. 1, in wireless networks, in order to point a transmission or reception beam towards a user at high carrier frequencies, a base station can make use of the predicted angle of departure or arrival of the wireless signal [6], [7]. Predictions are inherently uncertain, and yet the monitoring and operation of cyber-physical systems typically demand guarantees on the satisfaction of reliability and safety requirements. With reference to the examples above, in the context of path planning of autonomous agents, robots should be able to operate while avoiding collision and respecting satisfy safety margins [8]. Drones have to ensure a minimal level of coverage in mission critical scenarios such as natural disasters, e.g., for surveillance or aid delivery [9], [10]. In 5G wireless systems, base stations have to reliably forecast traffic demands and channel state evolutions to support ultra-reliable low latency communications (URLLC) applications [11]. While essential for the reliable monitoring and safe control of cyber-physical systems, man- aging prediction uncertainty presents significant challenges in environments characterized by complex dynamics. For instance, in the setting illustrated in Fig. 1, a vehicle may exit a roundabout at several intersections, creating forks in the possible future trajectories, with each possible trajectory having error bars of its own, accounting, e.g., for variable accelerations or decelerations. Existing approaches for the design of predictors and of model predictive control (MPC) systems encompass model-based and model-free methods. In the former case, domain knowledge is leveraged to define a physically motivated model of the environment, from which predictions and optimal policies are constructed. Any reliability or safety guarantee provided by this class 3 (a) Scenario −20 −10 0 10 0.0 0.5 1.0 1.5AoA TS-CP −20 −10 0 10 t 0.0 0.5 1.0 1.5AoA PTS-CRC m=16 (this work) (b) Prediction example 0.70 0.75 0.80 0.85 0.90 0.95 1 − α 0.7 0.8 0.9Coverage Coverage < 1 − α 0.70 0.75 0.80 0.85 0.90 0.95 1 − α 10 20 30IneﬃciencyTS-CP PTS-CRC m=4 (this work) PTS-CRC m=16 (this work) (c) Performance Fig. 1: Illustration of an exemplifying application of the proposed method: (a) The base station wishes to predict the evolution of the angle of arrival yt for the line-of-sight radio propagation path from a vehicle moving in a roundabout. (b) Given knowledge of the sequence yt from at times t = −20, . . . , −1, the goal is to produce prediction intervals for the future evolution of the sequence yt at times t = 0, ..., 19. The true trajectory is shown as a dashed black line, with the predictive intervals (blue shaded areas) produced by the state-of-the-art TS-CP [16] provided in the upper part, while the proposed set-predictor (PTS-CRC) with m = 4 and m = 16 prototypes (see Fig. 2) are plotted in the lower part. (c) Both TS-CP and PTS-CRC are guaranteed to cover the true trajectory with probability at least 1 − α (top), but PTS-CRC significantly reduces the inefficiency, i.e., the average predicted set size (bottom). of techniques is valid only as long as the underlying system’s model is accurate [12], [13]. Model-free solutions offer an alternative approach, whereby environment dynamics are captured by using general-purpose models – such as autoregressive models or transfomer-based solutions like large language models (LLMs) – that are optimized based on data. The higher versatility of model-free methods comes at the cost of weaker guarantees and costly data collection procedures [14], [15]. In this work, we assume access to a pre-designed probabilistic sequence model, which may have been obtained by using model-based or model-free methods. As an example, one may have trained a transformer-based sequence model such as an LLM or a decision-based transformer [17]–[19], or one may have optimized a Kalman predictor, or variants thereof, based on a dynamic model [20]. As such, the proposed approach takes an agnostic stance toward modeling 4 assumptions, only positing the availability of any implicit or explicit probabilistic model. An implicit model can only generate predictive samples, as is the case for models based on complex physics simulations [21] and for neural flow algorithms [22]; while an explicit model can also assign probabilities to the possible predictive outputs, as for Kalman filters or language models. We propose a novel general framework, grounded in conformal risk control (CRC) [23], that enables (i) efficient and provably reliable predictive uncertainty quantification even in situations with forking paths (see Fig. 1); and (ii) MPC with guarantees on general average constraints with respect to the future behavior of the system. To validate the theoretical properties of the proposed methodology, we showcase several applications related to the monitoring and control of modern wireless systems. B. Related Work Quantifying uncertainty in the prediction of time series and ensuring the safe operation of complex systems are fundamental problems in statistics and control theory, respectively. Traditional model-based approaches are based on autoregressive modeling assumptions, including Kalman filters, and on frameworks such as control Lyapunov theory, control barrier functions, and robust MPC [24]–[26]. All these strategies offer theoretical guarantees under the assump- tions that the postulated models are valid [27] and that the computational complexity of the optimized strategies, particularly in the case of non-linear system dynamics, affords an efficient implementation [28]. Data-driven control approaches, including recurrent neural networks (RNNs) [29], long short- term memory networks (LSTMs) [30] and LLMs [31], learning-based MPC [32], and model- free reinforcement learning (RL) [14], [15], [33], can potentially address these shortcomings and have gained significant attention over the past decades. Learning-based methods exhibit remarkable versatility, but they provide looser guarantees as compared to their model-based counterparts, being ultimately limited by the availability of relevant data. A particular concern in this regard is that machine learning models may excel at accurate prediction of complex dynamics under best-case conditions, but they typically lack reliable uncertainty quantification capabilities [34], [35]. Bayesian variants of these forecasting models offer a principled approach to account for uncertainty. However, they are limited by the approximations required for efficient implementations [36] and they are susceptible to model misspecification and outliers [37]–[39]. 5 In this context, conformal prediction (CP) has recently emerged as a prominent post-hoc calibration technique. CP can be applied to the output of any pre-designed model to yield reliable error bars with (frequentist) finite-sample coverage guarantees [40]–[42]. In its most practical incarnation, CP requires the use of a separate calibration data set [23], and it may leverage probabilistic predictors [43]. CP has been recently applied to the problem of quantifying predictive uncertainty for time series in various domains. These include the monitoring of LLM- based planning routines [44], [45], the estimate of the returns of policies for Markov decision processes [46], and the run-time verification of dynamic systems [47], [48]. The error bars produced by CP have also been leveraged for MPC targeting the safe planning of agents in shared environments [49], [50]. C. Contributions In this work, we address the problems of reliable prediction and safe MPC by leveraging pre- designed implicit or explicit probabilistic sequence models and calibration data in the form of sample time series for the quantities being predicted. Reliable prediction requires the evaluation of error bars satisfying average accuracy constraints, while safe MPC entails the satisfaction of average risk constraints. As summarized in the previous subsection, existing art proposed the application of CP to tackle these challenges, resulting in the following two limitations that we aim to address in this work. • Unimodal vs. forking uncertainties: In the example in Fig. 1, the base station wishes to predict the evolution of the angle of arrival for the line-of-sight radio propagation path between a moving vehicle in a roundabout and the base station. Given that the vehicle can exit the roundabout at any of the four side streets, the future evolution of the angle of arrival has multiple possible forking trajectories. State-of-the-art time series-CP (TS-CP) [16] builds a unimodal error bar around a single trajectory (Fig. 1(b), upper part), and it hence cannot capture the forking uncertainties caused by the multiple possible future evolutions of the target process. This causes the predictive interval to be inefficient, i.e., excessively large, in order to provide coverage guarantees (Fig. 1(c)). • Coverage vs. risk: CP targets reliability guarantees in terms of coverage probability, i.e., of the probability that the error bars include the true future trajectory. In control applications, one may need to address more general average risk constraints that cannot be expressed in terms of coverage probability. For instance, one may wish to impose that the average quality 6 of a predicted text crosses a user-defined threshold or that the average quality of service provided by the base station in Fig. 1 be sufficiently large. Existing methods cannot address such constraints. Targeting these two limitations of the state of the art, the contributions of this work are as follows. • Probabilistic time series conformal risk control (PTS-CRC): We introduce PTS-CRC, a post- hoc calibration procedure that operates on the predictions produced by any pre-designed sequence model to yield reliable error bars. In contrast to existing art, PTS-CRC produces predictive sets based on an ensemble of multiple prototype trajectories sampled from the sequence model (Fig. 1(b), lower part, and Fig. 2). This way, PTS-CRC can efficiently account for forking uncertainties. Furthermore, building on CRC [23], PTS-CRC can satisfy reliability definitions beyond coverage. • PTS-CRC-based safe MPC: We introduce a novel MPC framework that addresses open-loop and closed-loop control problems under general average constraints on the quality or safety of the control policy. The approach builds on the set predictors produced by PTS-CRC. • Use cases: We experimentally validate the performance of PTS-CRC prediction and MPC by studying a number of use cases in the context of wireless networking. First, we consider the problem of reliably monitoring the evolution of the channel gain between a base station and a moving user in an urban microcell scenario. Second, we leverage the proposed PTS-CRC- based control framework to design power control policies that satisfy reliability requirements, namely maximum interference constraints and minimal decoding packet probability guarantees. Across all the considered tasks, PTS-CRC predictors are shown to provide more informative predictive sets and safe control policies with larger returns. The rest of the paper is organized as follows. In Section II, we formally describe the prediction and MPC settings under study. In Section III, we review TS-CP [16]. In Section IV, we introduce and analyze PTS-CRC for both implicit and explicit sequence models. In Section V, we present novel control algorithms that leverage PTS-CRC for MCP. In Section VI, we elucidate the relations between the proposed PTS-CRC and the frameworks of probabilistic CP [43] and CRC [23]. Section VII experimentally validates the proposed framework and the paper is concluded in Sec. VIII. 7 II. PROBLEM DEFINITION In this section, we describe first the setting and performance criteria for the problem of reliable prediction, and then we detail the class of MPC problems under study. A. Prediction Given the first T samples of a time series y−T , ..., y−1, we are interested in predicting the next τ samples y0, ..., yτ −1 by providing sets, i.e., “error bars”, that satisfy reliability guarantees with respect to the correct trajectory (see Fig. 1). The overall trajectory y−T :τ −1 = [y−T , . . . , yτ −1] ∈ Y T +τ is a time series in which each sample yt takes values in a set Y. Set Y may be discrete and finite or a subset of a real-valued vector space. Its distribution p(y−T :τ −1) is unknown, and it can be generally written using the chain rule as p(y−T :τ −1) = p(y−T ) τ −1∏ t=−T +1 p(yt|y−T :t−1), (1) where p(yt|y−T :t−1) is the conditional distribution of sample yt given the past samples y−T :t−1. We assume access to a sequence model in the form of a probabilistic predictor described by a conditional distribution ˆp(y0:τ −1|y−T :−1) over the future samples y0:τ −1 given the past samples y−T :−1. The predictor ˆp(y0:τ −1|y−T :−1) is an approximation of the true conditional distribution p(y0:τ −1|y−T :−1) obtained from the joint distribution in (1). As mentioned in Section I, the conditional distribution ˆp(y0:τ −1|y−T :−1) may, e.g., take the form of a pre-trained machine learning model or of a model-based predictor based on a physics-driven simulator (see, e.g., [51]– [53]). Furthermore, as detailed next, while prior work [16], [46], [47], [49], [54], [55] focused on deterministic predictors, here we assume either implicit or explicit probabilistic models. • Deterministic predictors: Prior work [16], [46], [47], [49], [54], [55] assumed that the pre- dictor ˆp(y0:τ −1|y−T :−1) is concentrated at a single predicted trajectory ˆy0:τ −1 ∈ Y τ , which is thus a deterministic function of the past samples y−T :−1. That is, we have the equality ˆp(y0:τ −1|y−T :−1) = δ (y0:τ −1 − ˆy0:τ −1), where δ(·) is the Kronecker or Dirac delta function depending on whether the domain Y is discrete or continuous, respectively. • Implicit, or generative-only, probabilistic predictors: Implicit probabilistic predictors can gen- erate predicted trajectories ˆy0:τ −1 ∼ ˆp(y0:τ −1|y−T :−1), (2) which are conditionally independent given the input y−T :−1. Such models do not provide an explicit value for the conditional distribution ˆp(ˆy0:τ −1|y−T :−1) for the generated samples 8 ˆy0:τ −1. Examples include time-GANs [56], diffusion models [57], and probabilistic spiking neural networks [58], [59]. • Explicit, or likelihood-based, probabilistic predictors: Explicit probabilistic predictors can gen- erate samples (2) like implicit models, but they also provide as output the value ˆp(ˆy0:τ −1|y−T :−1) assigned by the model to the generated sample ˆy0:τ −1. B. Set Prediction The goal of this work is to leverage the available, implicit or explicit, probabilistic predictor ˆp(y0:τ −1|y−T :−1) to produce a prediction set over the space of future sequences. We focus on the special class of set predictors that depend on the past evolution y−T :−1 through a set P m(y−T :−1) = {yi 0:τ −1} m i=1 of m prototypical sequences, where yi 0:τ −1 is the i-th prototype. While more general forms of the predictors are possible, we will consider set predictors that include all future sequences y0:τ −1 that are sufficiently close to any of the prototypes with respect to a given distance measure d(·, ·), i.e., Γ(y−T :−1) = {y0:τ −1 ∈ Y τ : min ˆy0:τ −1∈P m(y−T :−1) d(y0:τ −1, ˆy0:τ −1) ≤ λ } (3a) = ⋃ ˆy0:τ −1∈P m(y−T :−1) {y0:τ −1 ∈ Y τ : d(y0:τ −1, ˆy0:τ −1) ≤ λ} , (3b) where λ > 0 is a design parameter. The equality between (3a) and (3b) follows from the fact that, if a sequence y0:τ −1 is in the set defined by (3a), there exists a prototype ˆy0:τ −1 ∈ P m(y−T :−1) satisfying the inequality d(y0:τ −1, ˆy0:τ −1) ≤ λ, ensuring that the sequence is also in set (3b), and vice versa. As we will discuss in Section IV, existing works [16], [46], [47], [49], [54], [55] only consider the case m = 1, while this paper leverages the use of probabilistic predictors to allow for m > 1 prototypes. In Fig. 2 we provide an illustration of a prototype-based set predictor Γ(y−T :−1) of the form (3) obtained from a set of m = 3 prototypical sequences. The set predictor expresses the predictor’s expectation that the future sequence y0:τ −1 is in set Γ(y−T :−1) given the available information y−T :−1 as input. As per (3), the set predictor Γ(y−T :−1) can be obtained by including all sequences y0:τ −1 whose distance from any prototype ˆy0:τ −1 is no larger than λ. Given a set predictor Γ(y−T :−1) we define the per-time step predicted set at time t as including all values of Y that are assumed by some trajectory ˆy0:τ −1 in set Γ(y−T :−1) at time t, i.e., Γt(y−T :−1) = {y ∈ Y : ∃ ˆy0:τ −1 ∈ Γ(y−T :−1) with ˆyt = y} . (4) 9 Fig. 2: A prototype-based set predictor: Given the past evolution of time series y−T :−1 (solid black curve), the prototype-based set predictor Γ(y−T :−1) in (3) is constructed based on the set P m(y−T :−1) containing m prototypical sequences (here m = 3) by including all sequences ˆy0:τ −1 whose maximum distance to one of the prototypes is bounded by λ (here λ = 0.05). The prototype-based set predictor Γ(y−T :−1), reported on the right, includes all the sequences that are either in the red, green, or blue-shaded areas. While prior work is limited to the case of a single prototype (m = 1), this paper leverages the use of probabilistic sequence models to allow for m > 1 prototypes. C. Reliability We are interested in producing interval predictors Γ(y−T :−1) that are reliable and efficient. To define reliability, let us fix a loss function L (Γ, y0:τ −1) that measures the discrepancy between the predicted set Γ and the actual trajectory realization y0:τ −1. We impose some mild assumptions on the loss function in a manner similar to [23]. Assumption 1 (Bounded and monotonic loss function). The loss function L (·, ·) satisfies the inequality L (Γ, y0:τ −1) ≤ B (5) for all pairs (Γ, y0:τ −1), where B ≤ ∞ is a constant, and it is monotonic in the size of the predicted set, i.e., we have the inequality L (Γ, y) ≤ L (Γ ′, y) for any pair of sets satisfying the inclusion relation Γ ′ ⊆ Γ. 10 We say that the set predictor Γ(·) is α-reliable with respect to the loss L(·, ·) if the expected value of the loss, R(Γ), is bounded by a target maximum unreliability level α. Accordingly, the predictor Γ(y−T :−1) is α-reliable if it satisfies inequality R(Γ) := E[L (Γ(y−T :−1), y0:τ −1)] ≤ α, (6) where the expectation is over the unknown distribution p(y−T :τ −1) in (1) of the time series y−T :τ −1. The definition of reliability (6) specializes to distinct requirements depending on the choice of the loss functions. Some important examples, satisfying Assumption 1, are as follows. • Sequence coverage probability: The miscoverage loss function L (Γ(y−T :−1), y0:τ −1) = 1 {y0:τ −1 /∈ Γ(y−T :−1)} (7) returns 1 if the actual sequence y0:τ −1 of future samples is not included in the predicted set Γ(y−T :−1). With this loss function, characterized by B = 1 in (5), the reliability requirement (6) corresponds to the sequence coverage probability guarantee [16], [46], [47], [49], [54], [55] Pr[y0:τ −1 /∈ Γ(y−T :−1)] ≤ α. (8) • Sample coverage rate: The per-sample miscoverage rate loss function L (Γ(y−T :−1), y0:τ −1) = 1 τ τ −1∑ t=0 1 {yt /∈ Γt(y−T :−1)} (9) calculates the fraction of future samples {yt}τ −1 t=0 that are not included in the corresponding per-time step predicted subsets {Γt(y−T :−1)}τ −1 t=0 in (4). With loss (9), also characterized by B = 1 in (5), the reliability condition (6) reduces to the constraint 1 τ τ −1∑ t=0 Pr [yt /∈ Γt(y−T :−1)] ≤ α (10) that, on average, the prediction sets contain the future trajectory for at least a fraction 1 − α of the future time steps. Note that the requirement (10) is less strict than (8). D. Efficiency Efficiency refers to the informativeness of the interval prediction Γ(·, ·) which is generally measured by its size [60], [61]. To appreciate the tension between reliability and efficiency, 11 note that the coverage guarantee (8) can be satisfied for any value of α ∈ [0, 1] by the trivial interval predictor that always outputs the entire space Γ(y−T :−1) = Y τ of possible trajectories. This prediction is clearly not informative, but it is perfectly reliable. To formalize the notion of inefficiency, we fix a measure µ(·) over the space Y τ of trajectories. For instance, if set Y is discrete, measure µ(Γ) may count the number of trajectories in subset Γ ⊆ Y τ ; or if Y τ = Rτ , function µ(Γ) may be the Lebesgue measure or the time-averaged measure (1/τ ) ∑τ −1 t=0 µ(Γt) evaluated using the per-time step predictions (4). The inefficiency of a set predictor Γ(·) is then defined as the average size I(Γ) := E[µ (Γ(y−T :−1))], (11) where the average is again over the unknown distribution p(y−T :τ −1) in (1). E. Model Predictive Control Reliable and efficient set predictors can support decision making processes that are subject to reliability or safety requirements. In this work, we specifically focus on the general problem of controlling a dynamical system whose state is described by a state variable st ∈ S via the selection of a sequence of actions ut ∈ U over time t. For instance, the state st may represent the trajectory of a drone or robot, or the occupancy of queues in a telecommunications network; while action ut may describe a steering decision or the allocation of some resources. The evolution of the state st depends on the action ut for time step t = 0, 1, . . . through the system equation st = f (st−1, ut) (12) for some known function f (·, ·) and known initial state s−1. The reliability, or safety, of the sequence of states st is measured in relation to another process yt for t = 0, 1, ..., τ −1, which we refer to as the target process. To this end, we define a constraint function c(s0:τ −1, y0:τ −1), which measures the extent to which the sequence of states s0:τ −1 fails to meet a reliability requirement with respect to sequence y0:τ −1. For instance, for any time t, the value yt may represent the current distribution of data to be collected, the position of targets to be tracked, the distribution of wireless traffic levels, or the positions of other robots or agents in a shared environment. In these examples, the constraint function c(s0:τ −1, y0:τ −1) can measure the extent to which the current position st of a drone fails 12 to cover the areas of high data availability or wireless traffic, as described by the sample yt; or the distance between a robot’s position st and the positions yt of the other robots or agents. The target process y0:τ −1 has an unknown distribution (1). Furthermore, at any time t, con- ditioned on all past actions u0:t−1, states s0:t−1 and samples y0:t−1, the next sample yt depends only on the past target samples y0:t−1. That is, we have the conditional distribution p(yt|y0:t−1, u0:t−1, s0:t−1) = p(yt|y0:t−1). (13) By (13), as also assumed in [49], the target process yt is not affected by the actions ut, and it is generally subject to the randomness modeled by the distribution p(yt|y−T :−t). The target process y0:τ −1 is not available to the decision maker, which has access to a sequence of past samples y−T :−1 and to a probabilistic predictor ˆp(y0:τ −1|y−T :−1), and it is aware of the initial state s0. As we detail below, for closed-loop control, we also assume that, at time t, the controller has access to the past samples y−T :τ −1. Finally, note that, due to the deterministic dynamic described by (12), the controller can perfectly predict the impact of its actions ut on the evolution of the state st. On the basis of the available information about the past samples y−T :−1, about the initial value s0, and, possibly, also about the past values y0:t−1, the decision maker chooses each action ut for t = 0, 1, . . . , τ − 1 with the goal of minimizing the cumulative value of a cost function J(st, ut) over the future τ steps, while satisfying an average reliability constraint. Specifically, the decision maker addresses the problem minimize u0...,uτ −1 τ −1∑ t=0 J(st, ut) (14a) s.t. st = f (st−1, ut) for t = 0, 1, . . . , τ − 1 (14b) E[c(s0:τ −1, y0:τ −1)] ≤ δ, (14c) where parameters δ > 0 define the maximum control unreliability level. The constraint (14c) requires that the average value of the constraint function c(s0:τ −1, y0:τ −1) to be no larger than level δ, where the expectation is taken over the unknown distribution p(y−T :τ −1) of the target process in (1). Based on the fact that the value δ can be included in the constraint function c(s0:τ −1, y0:τ −1), in the following we set δ = 0 without loss of generality. Problem (14) is addressed via MPC by choosing control actions ut that depend on predictions obtained based on the sequence model ˆp(y0:τ −1|y−T :−1). Specifically, we consider both open-loop 13 and closed-loop control formulations of problem (14). The open-loop formulation corresponds to the scenario in which the control sequence u0:τ −1 is designed entirely based on the information available at time t = 0. That is, the control sequence is evaluated by tackling problem (14) based on the initial state s0, the past samples y−T :−1 and the probabilistic predictor ˆp(y0:τ −1|y−T :−1). In the closed-loop formulation, after every time step t, the controller observes the realization of yt, and it can use this additional information to refine its prediction about the future evolution of the target process yt:τ −1. Formally, the action ut at time t is given by addressing (14) based on the observed state and target process evolutions up to time t, i.e. s0, . . . , st−1 and y−T , . . . , yt−1 and the predictive distribution ˆp(yt:τ −1|y−T :t−1). Importantly, for both the open-loop and closed-loop formulations, predictions must be used to ensure that constraint (14c) is satisfied with respect to the unknown target process distribution, and not with respect to the predictive distribution. III. BACKGROUND: TIME SERIES CONFORMAL PREDICTION In this section, we review TS-CP [16], [46], [47], [49], [55]. TS-CP applies CP to turn a deterministic time series forecaster into a set predictor (3) that includes the future evolution of the system with a user-specified coverage level 1 − α as per the sequence coverage probability guarantee (8) [16]. Given a predicted sequence ˆy0:τ −1, TS-CP adopts the set predictor (3) with m = 1, where the set P 1 of prototypes includes only the prediction ˆy0:τ −1 as P 1 = {ˆy0:τ −1}. Furthermore, the distance measure in (3) is set as d(y0:τ −1, ˆy0:τ −1) = max t=0,...,τ −1 wt|yt − ˆyt|, (15) where {wt}τ −1 t=0 are pre-determined positive coefficients. The weights can be chosen to be equal [16], [46], [47], [49], or they may be decreasing over time to compensate for the fact that the prediction error is typically increasing in t [55]. The threshold λ in (3) is selected based on a calibration data set Dcal = {yi −T :τ −1} n i=1 of trajectories drawn from the true distribution (1). To this end, TS-CP evaluates the distance between the deterministic prediction ˆyi 0:τ −1 and the corresponding i-th calibration data point yi 0:τ −1 as di = d(yi 0:τ −1, ˆyi 0:τ −1) (16) 14 for all i = 1, . . . , n. Then, following the general CP methodology [40], it evaluates the threshold λ in (3) to equal the ⌈(n + 1)(1 − α)⌉-th smallest value of the calibration errors {di} n i=1 , i.e., λT S−CP = Q1−α(Dcal) = max { d : n∑ i=1 1{di ≤ d} ≤ ⌈(n + 1)(1 − α)⌉ } . (17) Accordingly, the TS-CP set predictor is given as Γ T S−CP (y−T :−1) = {y0:τ −1 ∈ Y τ : d(y0:τ −1, ˆy0:τ −1) ≤ Q1−α(Dcal)} . (18) Note that, by the choice of the distance in (15), the per-time step predictor (4), given by Γ T S−CP t (y−T :−1) = { y ∈ Y : |ˆyt − yt| ≤ Q1−α(Dcal) wt } , (19) is centered on the predicted sample ˆyt with an error interval proportional to the empirical quantile Q1−α(Dcal). Furthermore, the set predictor ΓT S−CP (y−T :−1) can be expressed as the Cartesian product of the per-time step intervals (19). Assume that the calibration sequences in Dcal and the test sequence y−T :τ −1 are drawn i.i.d. from the distribution (1). Then, by the general properties of CP, the calibrated predictor (18) is guaranteed to include the true realization of the time series y0:τ −1 with a probability that is no smaller than 1 − α [16], [46], [47], [49], [55]. That is, TS-CP satisfies the coverage guarantee (8), where the probability is evaluated with respect to the calibration and test sequences. IV. PROBABILISTIC TIME SERIES CONFORMAL PREDICTION The TS-CP set predictor Γ T S−CP t (y−T :−1) in (19) can only produce sets in the form of single real-valued intervals. As such, TS-CP can become highly inefficient when the true distribution of the future evolution of the system, p(y0:τ −1|y−T :−1), is multimodal (see Fig. 1), and it does not apply to discrete-valued time series. To address these limitations, in this section, we introduce PTS-CRC. Following Section II-A, we differentiate between set predictors based on implicit and explicit probabilistic forecasters. As we will see, explicit probabilistic predictors enable the definition of more general prediction schemes that may provide more informative set predictors. A. PTS-CRC via Implicit Sequence Models Given past samples y−T :−1, an implicit probabilistic predictor produces samples of predicted trajectories ˆy0:τ −1 from the predictive distribution ˆp(y0:τ −1|y−T :−1), while not explicitly providing the value of the distribution ˆp(ˆy0:τ −1|y−T :−1) for the generated sequences ˆy0:τ −1. Unlike TS-CP, 15 Algorithm 1 Probabilistic Time Series Conformal Risk Control (PTS-CRC) Input: Time series predictor ˆp(y0:τ −1|y−T :−1), test input y−T :−1, calibration data set Dcal = {yi −T :τ −1} n i=1, maximum unreliability level α > 0, loss function L, and integer m > 0 Output: α-reliable set predictor Γ P T S−CRC (y−T :−1) //Offline Calibration Phase for all yi −T :τ −1 ∈ Dcal do sample predictions P m i = {ˆyj 0:τ −1} m j=1 i.i.d. from the sequence model ˆp(y0:τ −1|yi −T :−1) end for compute threshold λ P T S−CRC ← inf { λ : ∑n i=1 L (Γλ(P m i , yi 0:τ −1) ) + B ≤ α(n + 1)} . // Testing Phase sample predictions P m = {ˆyj 0:τ −1}m j=1 from the sequence model ˆp(y0:τ −1|y−T :−1) obtain Γ P T S−CRC (y−T :−1) = ⋃ ˆy0:τ −1∈P m { y0:τ −1 ∈ Y τ : d(ˆy0:τ −1, y0:τ −1) ≤ λ P T S−CRC} which relies on a single predicted sequence ˆy0:τ −1, TS-CP leverages the capacity of a probabilistic sequence model to generate m ≥ 1 trajectories P m = {ˆyj 0:τ −1}m j=1 sampled i.i.d. from the model ˆp(y0:τ −1|y−T :−1). Based on the predicted trajectories P m, PTS-CRC applies the prototype-based set prediction (3) for a suitably designed threshold λ P T S−CRC. Specifically, given a loss function L (Γ, y0:τ −1) and calibration data set Dcal = {yi −T :τ −1}n i=1 generated i.i.d. from the unknown distribution (1), the threshold λ P T S−CRC is chosen so as to guarantee the reliability constraint (6) for the target maximum unreliability level α under any loss function satisfying Assumption 1. The reliability requirement (6) depends on the unknown joint distribution (1), and it can be estimated using the calibration data Dcal. To this end, we evaluate the loss L ( Γλ ( yi −T :−1) , yi 0:τ −1) for each i-th calibration data point by computing the set predictor Γλ (yi −T :−1) in (3) based on prototype predictions P m i = {ˆyj 0:τ −1,i} m j=1 drawn from the sequence model. Note that we have made explicit the dependence of the set predictor (3) on the threshold λ. Then, we evaluate the empirical average 1/n ∑n i=1 L ( Γλ ( yi −T :−1) , yi 0:τ −1) by averaging over the calibration data set. Intuitively, PST-CRC chooses the threshold λ P T S−CRC in such a way that this empirical estimate is no larger than α. More precisely, we have λ P T S−CRC := inf { λ : 1 n + 1 ( n∑ i=1 L ( Γλ ( yi −T :−1) , yi 0:τ −1) + B ) ≤ α } , (20) 16 where the empirical estimate of constraint (6) is corrected by adding a fictitious (n + 1)-th data point with maximal loss value B (see Assumption 1). As explained in Section VI, this correction follows the CRC framework. The PTS-CRC procedure, producing PTS-CRC predicted set Γ P T S−CRC (y−T :−1) = ⋃ ˆy0:τ −1∈P m {y0:τ −1 ∈ Y τ : d(ˆy0:τ −1, y0:τ −1) ≤ λP T S−CRC} , (21) is summarized in Algorithm 1. PTS-CRC satisfies the following reliability guarantee. Theorem 1. Assuming that the samples in the calibration data set Dcal and the test sample y−T :τ −1 are i.i.d. from distribution (1), and that the loss function L (Γ, y0:τ −1) satisfies Assumption 1, the PTS-CRC set predictor Γ P T S−CRC (y−T :−1) in (21) satisfies the α-reliability guarantee (6), where the expectation is taken with respect to the calibration data set Dcal, the test data point y−T :τ −1 and the prototypes {P m, {P m i } n i=1}, with the latter drawn i.i.d. form the respective predictive distributions {ˆp(y0:τ −1|y−T :−1), {ˆp(y0:τ −1|yi −T :−1) }n i=1}. The properties of PTS-CRC stated in Theorem 1 can be proved by leveraging tools from the theory of CRC [23] and probabilistic CP [43]. This is discussed in Section VI. B. PTS-CRC via Explicit Sequence Models In this subsection, we propose E-PTS-CRC, a variant of PTS-CRC that leverages explicit probabilistic predictors. As detailed in Section II-A, explicit forecasters not only allow a trajectory ˆy0:τ −1 to be sampled from the model distribution ˆp(y0:τ −1|y−T :−1), but they also provide the value of the distribution ˆp(ˆy0:τ −1|y−T :−1) for the synthesized sample. We take inspiration from the literature on language models [62], with the aim of generating sets of predicted trajectories that are better representatives of the plausible evolutions of the input sequence y0:τ −1. This objective is accomplished via a biased sampling procedure that generates samples ˆy0:τ −1 from a distribution ˆq(y0:τ −1|y−T :−1) that is generally distinct from the sequence model ˆp(y0:τ −1|y−T :−1), satisfying additional desirable properties. For instance, in the context of text generation, which corresponds to a time series forecasting problem over a sequence of words, trajectories with the largest likelihood are often nonsensical [63], and hence one may wish to filter out sequences by typicality rather than likelihood [64]. Furthermore, it may be desirable to explicitly avoid the generation of sequences that are too unlikely. As exemplary strategies, we elaborate here on sequence-level filtering [43] and autoregressive filtering [62]–[64]. 17 1) Sequence-level filtering: Sequence-level filtering aims at obtaining samples from high- density regions of the predictive distribution, while reducing the occurrence of unlikely tra- jectories. This is done by filtering out samples with low likelihood from a set of trajectories sampled from the predictive distribution ˆp(y0:τ −1|y−T :−1) [43]. Specifically, given an explicit model ˆp(y0:τ −1|y−T :−1), one samples a set P ⌈m(1+κ)⌉ of ⌈m(1 + κ)⌉ trajectories obtained i.i.d. from ˆp(y0:τ −1|y−T :−1) given some κ > 0, and then obtains a subset P m ⊂ P ⌈m(1+κ)⌉ by selecting the m trajectories with the largest distribution value from set P ⌈m(1+κ)⌉. 2) Autoregressive filtering: In autoregressive filtering, sample selection is done on a per- time step basis. For example, in top-k sampling [62], which applies to discrete sets Y, the next sample ˆyt is constrained to lie within the set Sk of samples yt with the top-k largest distribution value ˆp(yt|ˆy0:t−1, y−T :−1). Sampling is hence done from a truncated probability ˆq(yt|ˆy0:t−1, y−T :−1) ∝ ˆp(yt|ˆy0:t−1, y−T :−1)1(y ∈ Sk). Other examples include p-nucleus sampling [63] and locally typically sampling [64], which respectively apply to continuous and discrete sets Y. V. PTS-CRC MODEL PREDICTIVE CONTROL In this section, we introduce open-loop and closed-loop policies for the MPC problem (14) by leveraging PTS-CRC to predict the target process trajectories. Control policies based on TS-CP, which was reviewed in Section III, were presented in [49], and they will be obtained as a special case of the more general framework put forth here. A. Open-Loop MPC We first consider the open-loop MPC control problem (14), whereby the action ut is allowed to depend only on the initial state s0, the past samples y−T :−1, and the (implicit or explicit) probabilistic predictor ˆp(y0:τ −1|y−T :−1). As discussed in Section II-E, meeting the average cost constraint (14c) is made complicated by the fact that the distribution p(y0:τ −1|y−T :−1) of the target process y0:τ −1 is unknown. In order to gauge the impact of the prediction errors on the performance of a control policy in terms of the constraint (14c), we introduce the following assumption, which limits the sensitivity of the constraint to changes in the target process. 18 Assumption 2 (Constraint Sensitivity). For some L > 0, the constraint function c(s0:τ −1, y0:τ −1) is L-Lipschitz in the second argument y0:τ −1 ∈ Y τ with respect to some metric m : Y τ ×Y τ → R in the space of trajectories. That is, we have the inequality |c(s0:τ −1, y′ 0:τ −1) − c(s0:τ −1, y′′ 0:τ −1)| ≤ Lm(y′ 0:τ −1, y′′ 0:τ −1) (22) for all sequences s0:τ −1 and all pairs of target process trajectories y′ 0:τ −1 and y′′ 0:τ −1. Assumption 2 states that we can identify a function m(·, ·) with the property that switching between any two target sequences y′ 0:τ −1 and y′′ 0:τ −1 cannot change the constraint c(·, ·) by more than Lm(y′ 0:τ −1, y′′ 0:τ −1) for some constant L > 0. For example, the constraint function c(s0:τ −1, y′ 0:τ −1) = ( τ −1∑ t=0 |st − y′ t| p)1/p (23) for p ≥ 1, which evaluates the ℓp distance between the state sequence s0:τ −1 and the target process y′ 0:τ −1, satisfies Assumption 2 with L = 1 for the function m(·, ·) = c(·, ·). Another constraint function is c(s0:τ −1, y′ 0:τ −1) = τ −1∑ t=0 log(1 + sty′ t), (24) which will be seen in Section VII to be relevant for the control of wireless systems. This constraint function can be shown to satisfy Assumption 2 with L = maxs∈S |s| and function m(y′ 0:τ −1, y′′ 0:τ −1) = ∑τ −1 t=0 |y′ t − y′′ t |, assuming that the inequality styt ≥ 0 holds for any state st and target sample yt. Under Assumption 2, we now derive a surrogate MPC problem whose feasibility set is guaranteed to be a subset of the feasibility set of the original control problem (14). In other words, a solution to the surrogate problem is also guaranteed to be feasible for the original problem, and hence the surrogate problem imposes more conservative constraints. As we will discuss, the key advantage of the surrogate MPC problem is that it can be addressed by using the available predictor, while the original problem (14) is not accessible given the dependence of the constraint (14c) on the unknown target process distribution. 19 Theorem 2 (PTS-CRC-based surrogate open-loop MPC problem). Consider the PTS-CRC pre- dictor Γ P T S−CRC (y−T :−1) in (20)-(21) obtained with distance measure d(·, ·) = m(·, ·) for some target reliability level α > 0 and with the loss L(Γ, y0:τ −1) = min ˜y0:τ −1∈Γ m(y0:τ −1, ˜y0:τ −1). (25) Any solution to the problem minimize u0...,uτ −1 τ −1∑ t=0 J(st, ut) (26a) s.t. st = f (st−1, ut), for t = 0, . . . , τ − 1 (26b) c(s0:τ −1, ˆy0:τ −1) ≤ −Lα for all ˆy0:τ −1 ∈ Γ P T S−CRC (y−T :−1) (26c) yields feasible solutions also for the original MPC problem (14) in which the average reliability constraint (14c) is evaluated on average with respect to the evolution y0:τ −1, the calibration se- quences Dcal, and the prototypes {P m, {P m i } n i=1}, with the latter drawn i.i.d. form the respective predictive distributions {ˆp(y0:τ −1|y−T :−1), {ˆp(y0:τ −1|yi −T :−1) }n i=1} . Theorem 2 justifies the adoption of the surrogate problem (26) in lieu of the problem (14). In problem (26), constraint (14c) is relaxed by taking the expectation not only with respect to target process y0:τ −1, but also over the prediction Γ P T S−CRC (y−T :−1). The relaxed constraint (26c) becomes more stringent as the Lipschitz constant L increases, indicating, by (22), that the constraint becomes more sensitive to changes in the target process. Since (26c) is a more stringent requirement as compared to (14c), there exists scenarios in which the original MPC problem (14) is feasible but the surrogate problem (26) is not. The reliability threshold α in constraint (26c), which may be freely chosen, dictates the trade-off between the size of the search space Γ P T S−CRC (y−T :−1) and the strictness of the inequality. The MPC controller based on TS-CP proposed in [49] can be recovered as a special case of the PTS-CRC-based control policy of Theorem 2. In particular, given a reliability level δ > 0, the controller in [49] addresses constraints (14c) of the form E [1 {c(s0:τ −1, y0:τ −1) > 0}] ≤ δ, (27) by leveraging the TS-CP predictor (18). 20 B. Closed-Loop MPC In the closed-loop setting, at every time step t, as detailed in Section II-E, the controller receives a feedback signal providing the current value of the state of the target process yt. As such, the control ut at time t is allowed to depend on the observed sequence y−T :t−1, the sequence of state s0:t−1, and the probabilistic predictor ˆp(yt:τ −1|y−T :t−1). In this setting, the control sequence u0, ..., uτ −1 is designed by following a receding horizon strategy. Accordingly, at every time step t > 0, the control action ut is obtained by optimizing the future control sequence ut, ..., uτ −1 and then retaining only the first action. As we describe next, this optimization leverages leverages the output of the PTS-CRC predictor Γ P T S−CRC(y−T :t−1) and the feedback sequence y0:t−1 in a manner similar to Theorem 1. Under Assumption 2, at each time step t = 0, . . . , τ − 1, based on the observed sequence y−T :t−1 we define a surrogate MPC problem whose feasibility set is guaranteed to be a subset of the feasibility set of the control problem (14) for the time interval t, . . . , τ − 1. The surrogate problem imposes more conservative constraints, which be addressed using the available predictor Γ P T S−CRC(y−T :t−1). Theorem 3 (PTS-CRC-based closed-loop MPC). For each time step t = 0, . . . , τ − 1, consider the PTS-CRC predictor Γ P T S−CRC(y−T :t−1) obtained with the distance measure d(·, ·) = m(·, ·) for some target reliability level α > 0 and calibrated via (20) on the loss L(Γ, y0:τ −1) = min ˜y0:τ −1∈Γ m(y0:τ −1, ˜y0:τ −1). (28) Then, the sequence of actions u0, . . . , uτ −1, in which ut is obtained as a solution of minimize ut...,uτ −1 τ −1∑ k=t J(sk, uk) (29a) s.t. sk = f (sk−1, uk), for k = 0, . . . , τ − 1 (29b) c(s0:τ −1, ˆy0:τ −1) ≤ −Lα, for all ˆy0:τ −1 ∈ Γ P T S−CRC (y−T :t−1) , (29c) yields feasible solutions also for the original MPC problem (14) in which the average reliability constraint is evaluated on average with respect to prediction {Γ P T S−CRC (y−T :t−1)} τ −1 t=0 and the evolution y0:τ −1. In a manner similar to the open-loop control case studied in the previous subsection, the closed-loop control policy based on TS-CP [49] can be recovered as a special instantiation of the PTS-CRC policy of Theorem 3. 21 VI. CONNECTING PTS-CRC WITH CP, PROBABILISTIC CP, AND CRC In this section, we first briefly review CP, probabilistic CP (PCP), and CRC, and then we describe PTS-CRC as a novel application of the principles underlying PCP and CRC to time series data. A. Conformal Prediction CP, PCP, and CRC apply to a general supervised learning setting in which data points take the form of pairs (x, y) with input x and output y ∈ Y. These schemes assume the availability of a calibration data set Dcal = {(x, y)i}n i=1 ∈ (X × Y) n of input-output pairs (x, y), which are assumed to be jointly distributed with the test pair in an i.i.d. manner. The theory also generalizes directly to exchangeable data points [40]. CP transforms a pre-designed predictor ˆy = f (x) into a set predictor Γ CP (x) ⊆ Y that contains the true output y with any target probability 1 − α, with probability evaluated with respect to calibration and test data. The CP set predictors Γ CP (x) depends on the choice of a non-conformity (NC) scoring function d(·) : Y × Y → R that measures the extent to which model’s prediction conforms with the ground truth y. Specifically, for each data point (x, y), the NC score is evaluated as d(f (x), y), and we denote as di = d(f (xi), yi) the NC score for the i-th calibration data point. Then, the CP set predictor is defined as ΓCP (x) = {y : d(f (x), y) ≤ Q1−α(Dcal)}, (30) where Q1−α(Dcal) is the ⌈(n + 1)(1 − α)⌉-th smallest value of the set {di}n i=1 of calibration NC scores. It can be shown that (30) satisfies the coverage guarantee [40]. Pr [ y /∈ Γ CP (x) ] ≤ α. (31) The TS-CP set predictor (18) can be obtained as an application of the CP set predictor by considering x to be the past samples y−T :−1 and the target y the future samples y0:τ −1, while using as the NC scoring function the maximum per-sample weighted error (15). B. Probabilistic Conformal Prediction PCP is a variant of CP that aims at producing discontinuous prediction sets based on samples obtained from probabilistic predictors. Specifically, given a probabilistic predictor ˆp(y|x) and 22 an input x, PCP generates m i.i.d. predictions P m(x) = {ˆyi}m i=1. Then, given an NC scoring function d(·) : Y × Y → R, it produces the predictive set Γ P CP (x) = ⋃ ˆy∈P m(x) {y : d(y, ˆy) ≤ λ} , (32) where the threshold λ > 0 is selected as the ⌈(n + 1)(1 − α)⌉-th smallest value of the set {di} n i=1 of calibration NC scores di = minˆy∈P m(x) d(yi, ˆy). PCP can be shown to also satisfy the coverage condition (31). In the special case of a the miscoverage loss (7) and assuming implicit probabilistic predictors, in a manner similar to TS-CP, PTS-CRC can be thought of as an application of PCP to time series prediction. C. Conformal Risk Control CRC is a generalization of CP that addresses more general reliability requirements, beyond the the coverage guarantee (31) [23]. Given a deterministic predictor ˆy = f (x), calibration data Dcal, and test input x, CRC produces a set predictor Γ CRC(x) that satisfies the average constraint E[L(ΓCRC(x), y)] ≤ α (33) for a bounded loss L (Γ, y). To this end, the CRC set predictors is given by Γ CRC(x) = {y : d(f (x), y) ≤ λCRC}, (34) where the threshold λCRC is chosen so as to ensure the inequality 1/(n+1)(∑n i=1 L(Γλ(xi, yi)+ B) ≤ α, where B is a bound on the loss function and we have defined Γλ(x) = {y : d(f (x), y) ≤ λ}. In the special case of deterministic predictors (m = 1), PTS-CRC can be seen as an application of CRC to time series prediction. Overall, in order to capture forking uncertainties in time series prediction while accounting for general loss functions, PTS-CRC borrows from PCP the idea of relying on multiple stochastic predictions, and for CRC the idea of calibrating a set prediction on the basis of an empirical estimate of the loss function. Furthermore, in order to enhance the predictive efficiency, PTS-CRC integrates the use of explicit probabilistic predictors, leveraging recent work on sequence modeling. 23 (a) Deployment Area 80 100 120 140 160 0.0 0.5 1.0ChannelGain ×10−7 80 100 120 140 160 Time [s] 0.0 0.5 1.0ChannelGain ×10−7 (b) Channel gain evolutions Fig. 3: (a) Top-view of the simulation scenario: The base station (BS), represented by a red circle, serves a user equipment (UE), blue circle, that moves along one of the possible 30 paths in green. The scenario includes static obstacles such as buildings, represented as dark grey blocks, as well as dynamic obstacles that may or may not be present, in yellow. (b) Two possible channel gain sequence realizations for a UE moving along the blue path shown in Fig.3(a). The red-shaded areas correspond to random blockage events during which the line-of-sight (LoS) component is blocked due to the presence of dynamic obstacles. VII. EXPERIMENTS In this section, we explore the application of PTS-CRC set predictors in the context of wireless networking. To begin, we address the challenge of reliably forecasting the evolution of the channel gain between a base station and users moving in an urban cell scenario. Subsequently, we harness the predicted channel behavior to develop model predictive power control policies subject to interference and energy efficiency requirements. A. Simulation Scenario We consider the urban microcell deployment depicted in Fig. 3(a). In Marienhof square, located in Munich, a base station (BS) is located at the top of a building facing the square. The BS serves users that move across the square with a fixed constant speed of 1.5 m/s following one of 30 possible trajectories. All trajectories are equally likely. As illustrated in Fig. 3(a), obstacles in the scene can obstruct the line of sight (LoS) component between the BS and the 24 user equipment (UE). Each obstacle, shown in Fig. 3(a), can be present or not, independently from the other obstacles, with Pb, which we set as Pb = 0.5 (see, e.g. [65]). The BS and the UE communicate using a single receiving and transmitting antenna system operating at a center frequency fc = 2.14 GHz with a bandwidth B = 120 KHz. The wireless channel is simulated using the ray-tracing simulator Sionna RT [66]. Accordingly, the baseband channel impulse response is obtained by simulating the wave propagation of the transmitted signal, and it is described by the superposition of NR rays as h(τ ) = NR∑ i=1 aie −j2fcπτiδ(τ − τi), (35) where ai ∈ C and τi ∈ R are the channel complex coefficients and the delay associated with the i-th simulated ray. Assuming that the delay spread ∆τ = maxi,j |τi − τi| is small compared to the symbol time 1/B, the channel gain is evaluated as g = ∣ ∣ ∣ ∣ ∣ Nrays∑ i=1 aie −j2fcπτi∣ ∣ ∣ ∣ ∣ 2 . (36) We assume that the BS has a maximum transmit power of Pmax = 1 W and that the communica- tion link is affected by additive white Gaussian noise with a noise spectral density N0 = 10 −15 W/Hz. For every user in the cell, the value of the channel gain (36) is estimated at the UE based on a reference signal that is periodically transmitted by the BS with a periodicity Ts = 80 ms. The UE evaluates an average over 10 measurements of the channel gain, and the average is sent back to the BS [67]. Accordingly, the BS receives a channel gain estimate gt every 800 ms. As exemplified in Fig. 3(b), the evolution of the time series gt depends on the path followed by the UE as well as on the random blockage events. B. Reliable Channel Gain Prediction As a first task, we address the problem of reliably forecasting the future evolution of the channel gain at the BS based on past feedback messages received from a UE in the cell. Specifically, given the past T channel gain estimates g−T :−1, our objective is to generate a set predictor that includes the true future evolution g0:τ −1 with a probability no smaller than 1 − α. 25 0.70 0.75 0.80 0.85 0.90 0.95 1 − α 0.70 0.75 0.80 0.85 0.90 0.95Coverage Coverage < 1 − α 0.70 0.75 0.80 0.85 0.90 0.95 1 − α 0.4 0.6 0.8 1.0Ineﬃciency ×10−7 TS-CP PTS-CRC m=16 (this work) E-PTS-CRC m=10 (this work) (a) Coverage and Inefficiency -30 -25 -20 -15 -10 -5 0 5 0.0 0.5 1.0ChannelGain ×10−7 TS-CP -30 -25 -20 -15 -10 -5 0 5 t 0.0 0.5 1.0ChannelGain ×10−7 PTS-CRC m=4 (this work) (b) Prediction Examples Fig. 4: (a) Test coverage probability 8 and inefficiency 11 of TS-CP [16], PTS-CRC with m = 16 prediction samples and E-PTS-CRC. (b) Example of set predictions produced by TS-CP and PTS- CRC based on m = 4 prototypes. To achieve this goal, we train a DeepAR probabilistic forecaster ˆp(g0:τ −1|g−T :−1) [68] using a training dataset comprising 73k channel gain sequences recorded from UEs moving within the deployment area as explained in the previous subsection. We explore different calibration strategies to transform the trained forecaster into a reliable set predictor. Our options include TS-CP [16], which involves applying CP to the average prediction obtained from the predictive distribution of the DeepAR model, i.e., f (g−T :−1) = E [ˆp(g0:τ −1|g−T :−1)]. Additionally, we consider the proposed PTS-CRC (Sec. IV-A), obtained by directly sampling m = 16 prototypes from the probabilistic predictor ˆp(g0:τ −1|g−T :−1), and the proposed E-PTS-CRC (Sec. IV-B) based on sequence-level filtering, constructed on the subset of m = 10 prototypes with highest likelihood from the original set of 16 prototypes. Calibration uses a data set of Ncal = 1000 time series, and Fig. 4(a) presents the test coverage levels and test efficiency of the set predictors averaged over Nte = 1000 independently generated test time series. As depicted in the top panel of Fig. 4(a), all calibration methods produce set predictors that meet the desired target coverage levels 1 − α. The coverage probability, defined in (8), evaluates the fraction of test trajectories that lie within the predicted set. As seen as in the bottom panel 26 0.0 0.1 0.2 0.3 0.4 0.5TransmitPowerPTS-CRC Rate = 4.31 Mbit/s TS-CRC Rate = 3.18 Mbit/s TS-CRC Power Allocation PTS-CRC Power Allocation -30 -20 -10 0 5 t 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5ChannelGain ×10−8 Channel Gain Fig. 5: Power allocation example obtained solving the model predictive power control problem based on the TS-CRC [23] and the proposed PTS-CRC predictor. The true channel realization (unknown) is shown as a dashed black line. Both the TS-CRC (in grey) and the PTS-CRC (in blue) power allocations ensure that the maximum cumulative interference over k = 3 slots does not exceed the safety threshold γ. However, the larger efficiency of the PTS-CRC predictor translates into a rate that is 33% larger than the one obtained using the TS-CRC predictor. of Fig. 4(a), as the coverage requirement 1 − α increases, CP yields sets with lower efficiency compared to the proposed the proposed PTS-CRC and E-PTS-CRC. The inefficiency is measured by the average size of the predicted set per time instant. As illustrated with two examples of predictions in Fig. 4(b), the higher efficiency of the proposed probabilistic set predictors can be attributed to their ability to output disjoint sets that better capture the multimodal residual uncertainty associated with unknown mobility patterns and blockage events. C. Open-Loop Model Predictive Power Control for Interference Mitigation In this subsection we leverage the reliable channel gain set predictors evaluated above to derive model predictive power control policies that satisfy interference constraints. More specifically, we consider the scenario in which licensed users (LU) and unlicensed users (UU) coexist within the cell, and the BS is tasked with the problem of modulating its transmit power P0, . . . , Pτ −1 over the next τ communication slots in order to maximize the sum-rate of the UU, while controlling the interference experienced by the LU. This formulation is motivated by the fact that UUs are typically served in a best-effort fashion whereas higher priority LUs have strict reliability requirements (see, e.g., [69], [70]). The BS observes the past evolution of the channel gain gLU −T :−1 of the LU, as well as the past evolution of the channel gain gU U −T :−1 of the UU. The future sum-rate of the UU is estimated 27 based on a forecast ˆgU U 0:τ −1 of the evolution of the UU channel gain as RU U (P0:τ −1, ˆgU U 0:τ −1) = 1 τ τ −1∑ t=0 B log2 ( 1 + ˆgU U t Pt N0B ) , (37) where we recall that Pt is the power allocated by the BS at time t. The interference constraint for the LU is formulated as an upper bound on the expected maximum cumulative interference over k subsequent communication slots. For a power allocation P0, . . . , Pτ −1, the maximum k-step cumulative interference at the LU over the future time horizon 0, 1, . . . , τ , is measured as ϕ (gLU 0:τ −1, P0:τ −1) = max t′∈{0,...,τ −k−1} 1 k t′+k∑ t=t′ gLU t Pt, (38) where the maximization ranges over all possible periods of k times slots. Therefore, for a safety threshold γ, the LU interference constraint amounts to the inequality E [ ϕ (gLU 0:τ −1, P0:τ −1)] ≤ γ, (39) where the expectation is over the unknown LU channel evolution gLU 0:τ −1. We note that the constraint (39) can be also expressed in the language of robust signal temporal logic (STL) [71]. The interference threshold γ in (39) is determined based on the observed past LU channel evolution gLU −T :−1. Accordingly, it is set to a fraction β ∈ [0, 1] of the maximum k-step cumulative interference over the past T communication slots, i.e., γ = β ( max t′∈{−T,...,−1−k} Pmax k t′+k∑ t=t′ gLU t ) . (40) By (40), a smaller value of β imposes a stricter interference constraint. The power control problem can then be formalized as the following open-loop problem maximize P0...,Pτ −1 1 τ τ −1∑ t=0 B log2 ( 1 + ˆgU U t Pt N0B ) (41a) s.t. 0 ≤ Pt ≤ Pmax, ∀t ∈ {0, . . . , τ − 1} (41b) E [ϕ (gLU 0:τ −1, P0:τ −1)] ≤ γ. (41c) 28 0.0 2.5 5.0 7.5 10.0 Rate [Mbit/s] 0.00 0.25 0.50 0.75 1.00InverseC.D.F. β =0.25 TS-CRC PTS-CRC m = 4 PTS-CRC m = 8 0 5 10 Rate [Mbit/s] β =1.0 (a) k = 1 0.0 2.5 5.0 7.5 10.0 Rate [Mbit/s] 0.00 0.25 0.50 0.75 1.00InverseC.D.F. β =0.25 TS-CRC PTS-CRC m = 4 PTS-CRC m = 8 0 5 10 Rate [Mbit/s] β =1.0 (b) k = 3 Fig. 6: Inverse empirical cumulative distribution function (C.D.F.) of the rate obtained by the different model predictive power control policies as a function of the maximum LU interference level β. For interference windows of size (a) k = 1 and (b) k = 3. The constraint (41c) is not directly tractable due to the expectation over the unknown distribution of the future evolution of the LU channel gain gLU 0:τ −1. However, the constraint function satisfies Assumption 2 in Sec. V by virtue of the inequality ∣ ∣ϕ (gLU 0:τ −1, P0:τ −1) − ϕ (˜gLU 0:τ −1, P0:τ −1)∣ ∣ ≤ Pmax k max t′∈{0,τ −1−k} t′+k∑ t=t′ ∣ ∣gLU t − ˜gLU t ∣ ∣ . (42) As stated in Theorem 2, it is then possible to replace constraint (41c) with a stricter constraint that depends on the output of a reliable set predictor. Accordingly, the solution of the resulting MPC problem yields a communication rate that lower bounds the optimal rate of the original problem (41), which is not attainable due to the lack of knowledge of future channel realizations. We benchmark the performance of different set predictors by addressing the associated MPC control problem. In Fig. 5, we illustrate the power control solutions obtained by the proposed PST-CRC predictor with m = 8 prototypes, and by a TS-CRC predictor, which is obtained by applying the same steps as PTS-CRC with m = 1 to the predictive mean of the DeepAR model. This approach is adopted here as a benchmark since TS-CP [16] cannot address the average constraint in (41). We set T = 30 and τ = 6. While both power allocations meet the interference requirement, the PTS-CRC power control policy has larger transmit power, and therefore it attains a higher communication rate. This improvement is attributed to the higher efficiency of the PTS-CRC predictor, which leads to surrogate constraints that are less conservative compared to those given by TS-CRC. 29 The performance gain of PTS-CRC is further validated in Fig. 6, in which we provide the inverse empirical cumulative distribution function (C.D.F) of the communication rate obtained by solving 1000 instances of the surrogate control problem for β ∈ {0.25, 1} and k ∈ {1, 3}. As β and k increase, the interference constraint (41c) is relaxed, and all power control policies yield larger communication rates. However, for fixed values of β and k, the empirical C.D.F. of the PST-CRC power control policy has a heavier tail and a larger mean, indicating that these power allocations are able to serve the UU with larger rates. The performance gain becomes more evident for larger values of the number of predictor’s samples m. For example, for k = 3 and β = 1, the 50th percentile of the PTS-CRC-based power control policy with m = 8 prototypes is 80% larger as compared to TS-CRC. 0.25 0.50 0.75 1.00 β 4.0 4.5 5.0 5.5AverageDelay[slot] TS-CP PTS-CRC m = 4 PTS-CRC m = 8 (a) Average Delay 0.25 0.50 0.75 1.00 β 0.2 0.3 0.4 0.5 0.6 0.7DecodingSuccessProbabilityTS-CP PTS-CRC m = 4 PTS-CRC m = 8 (b) Decoding Probability 0.25 0.50 0.75 1.00 β 0.6 0.8 1.0 1.2 1.4 1.6 1.8Throughput[Mbit/s] TS-CP PTS-CRC m = 4 PTS-CRC m = 8 (c) Throughput 0.25 0.50 0.75 1.00 β 2.00 2.25 2.50 2.75 3.00 3.25Eﬃciency[bit/J] ×106 TS-CP PTS-CRC m = 4 PTS-CRC m = 8 (d) Energy Efficiency Fig. 7: (a) Average delay, (b) decoding probability, (c) throughput and (c) energy efficiency of HARQ-IR schemes based on the TS-CP predictor [16] and the proposed PTS-CRC predictor for m = 4 and m = 8 prototypes. D. Energy Efficient HARQ-IR via Closed-Loop Model Predictive Power Control In this subsection, we address the problem of designing energy-efficient hybrid automatic repeat request with incremental redundancy (HARQ-IR) protocols [72] by leveraging reliable channel state information forecasting. As a brief review, given a sequence of random channel gains gt:τ −1 and transmit powers Pt:τ −1, τ − 1 − t retransmissions of a packet encoded with rate R [bit/s/Hz] yields successful decoding at the receiver with probability [73] Pdec(Pt:τ −1, R) = Pr [ τ −1∑ t′=t log2 ( 1 + Pt′gt′ BN0 ) > R ] , (43) 30 where the probability is over the future evolution of the channel gain gt:τ −1. At each time t, the base station (BS) has access to the feedback sequence g−T :t−1 of past channel gains fed back by a user equipment and it must modulate the transmit power Pt for the current time slot. The goal is to minimize energy expenditure while ensuring a minimum HARQ-IR decoding probability. The target communication rate R in constraint (43) is set to the rate achieved during the τ communication slots −τ − 1, . . . , −1 prior to their start of the HARQ process for a transmit power βPmax with β ∈ {0, 1}, i.e., R = −1∑ t=−τ −1 log2 ( 1 + βPmaxgt BN0 ) . (44) By (44), a larger value of β indicates a more stringent constraint (43). Overall, at every time step t = 0, 1, . . . , τ − 1 the BS optimizes the transmit power level Pt by addressing the closed-loop MPC problem minimize Pt...,Pτ −1 τ −1∑ k=t Pk (45a) s.t. t ≤ Pk ≤ Pmax, ∀k ∈ {t, . . . , τ − 1} (45b) Pdec(Pt:τ −1, R − Rt) > δ. (45c) where 0 < δ < 1 is the target decoding probability and Rt = t−1∑ t′=0 log2 (1 + Pt′gt′ BN0 ) (46) is the achieved rate decodable based on the past t − 1 retransmissions. If the problem (45) is not feasible, the BS does not transmit, while if it is feasible the power Pt is used for transmission. If R − Rt < 0 the HARQ-IR message is successfully decoded, and hence the transmission process stops. The protocol also stops at the maximum number of retransmissions τ irrespective of whether the decoding was successful or not. Constraint (45c) cannot be evaluated, since the distribution of the future channel gain sequence gt:τ −1 is unknown. However, the constraint function satisfies Assumption 2 in Section V, since the inequality ∣ ∣ ∣ ∣ ∣ 1 τ τ −1∑ t=0 log2 ( 1 + Ptgt BN0 ) − 1 τ τ −1∑ t=0 log2 ( 1 + Pt˜gt BN0 ) ∣ ∣ ∣ ∣ ∣ ≤ Pmax BN0 1 τ τ −1∑ t=0 |gt − ˜gt|. (47) 31 Thus, by Theorem 3, it is possible to replace the original constraint (45c) with a stricter constraint based on the output of reliable set predictors. By solving the resulting optimization problem, we can obtain a power control policy that satisfies the reliability constraint. For a numerical example, we set the observed feedback sequence of length T = 30 and a maximum number of retransmissions τ = 6 steps using the TS-CP and the proposed TS-CRC set predictor with m = 4 and m = 8 prototypes. In Fig. 7, we present key performance indicators of the resulting HARQ-IR transmission protocol for different values of β. Specifically, we solve 1000 problem instances and compute the average number of retransmissions, the probability of decoding the HARQ packet, the average throughput, and the average energy efficiency expressed as the number of decoded bits per Joule of transmit energy. As the value of β increases, the target information rate becomes larger, resulting in an increase in average delay and a decrease in decoding success probability for all schemes. However, when the PTS-CRC predictor is employed to predict the evolution of the future channel gain, the resulting HARQ-IR protocol can decode a larger fraction of information packets with shorter delays as compared to the TS-CP-based HARQ-IR scheme. Consequently, the PTS-CRC-based HARQ-IR scheme achieves an average throughput and average energy efficiency up to 25% higher than that of the TS-CP-based scheme. VIII. CONCLUSIONS In this work, we have addressed the problem of monitoring and controlling cyber-physical systems based on set predictors that provide reliable uncertainty estimates. To this end, we have proposed PTS-CRC, a novel post-hoc calibration technique that leverages pre-trained probabilistic sequence models, like language models, to obtain predictive intervals with finite-sample reliability guarantees. PTS-CRC leverages an ensemble of prototype trajectories sampled from the sequence model to effectively capture forking uncertainties, while satisfying reliability guarantees beyond the conventional coverage criterion. Furthermore, we have demonstrated an application of PTS- CRC to open-loop and closed-loop model predictive control problems under general average constraints on the quality or safety of the control policy. This paper has focused on settings in which the predictor or controller has access to calibration data in the form of sample sequences for the quantity to be predicted or for the target process. In an alternative setting, the predictor or controller may receive feedback on its predictions or actions in an online fashion without having offline access to calibration data. This setup was 32 studied in [74], [75] for prediction and [76] for control. Integrating the methods proposed in this paper, which can address forking uncertainties, within the online setting is an interesting direction for future work. REFERENCES [1] J. Ji, A. Khajepour, W. W. Melek, and Y. Huang, “Path planning and tracking for vehicle collision avoidance based on model predictive control with multiconstraints,” IEEE Transactions on Vehicular Technology, vol. 66, no. 2, pp. 952–964, 2016. [2] H. Wang, B. Lu, J. Li, T. Liu, Y. Xing, C. Lv, D. Cao, J. Li, J. Zhang, and E. Hashemi, “Risk assessment and mitigation in local path planning for autonomous vehicles with LSTM based predictive model,” IEEE Transactions on Automation Science and Engineering, vol. 19, no. 4, pp. 2738–2749, 2021. [3] J. Lee, R. Huang, A. Vaughn, X. Xiao, J. K. Hedrick, M. Zennaro, and R. Sengupta, “Strategies of path-planning for a UAV to track a ground vehicle,” in Proceedings of the 2nd annual Autonomous Intelligent Networks and Systems Conference, Menlo Park, CA, 2003. [4] F. Vanegas, D. Campbell, N. Roy, K. J. Gaston, and F. Gonzalez, “UAV tracking and following a ground target under motion and localisation uncertainty,” in 2017 IEEE Aerospace Conference, pp. 1–10, IEEE, 2017. [5] B. Li and Y. Wu, “Path planning for UAV ground target tracking via deep reinforcement learning,” IEEE access, vol. 8, pp. 29064–29074, 2020. [6] S. Moon, H. Kim, and I. Hwang, “Deep learning-based channel estimation and tracking for millimeter-wave vehicular communications,” Journal of Communications and Networks, vol. 22, no. 3, pp. 177–184, 2020. [7] S. H. Lim, S. Kim, B. Shim, and J. W. Choi, “Deep learning-based beam tracking for millimeter-wave communications under mobility,” IEEE Transactions on Communications, vol. 69, no. 11, pp. 7458–7469, 2021. [8] V. Kunchev, L. Jain, V. Ivancevic, and A. Finn, “Path planning and obstacle avoidance for autonomous mobile robots: A review,” in Knowledge-Based Intelligent Information and Engineering Systems: 10th International Conference, KES 2006, Bournemouth, UK, October 9-11, 2006. Proceedings, Part II 10, pp. 537–544, Springer, 2006. [9] T. Patterson, S. McClean, P. Morrow, G. Parr, and C. Luo, “Timely autonomous identification of UAV safe landing zones,” Image and Vision Computing, vol. 32, no. 9, pp. 568–578, 2014. [10] Y. Zeng, R. Zhang, and T. J. Lim, “Wireless communications with unmanned aerial vehicles: Opportunities and challenges,” IEEE Communications magazine, vol. 54, no. 5, pp. 36–42, 2016. [11] H. Chen, R. Abbas, P. Cheng, M. Shirvanimoghaddam, W. Hardjawana, W. Bao, Y. Li, and B. Vucetic, “Ultra-reliable low latency cellular networks: Use cases, challenges and approaches,” IEEE Communications Magazine, vol. 56, no. 12, pp. 119–125, 2018. [12] C. Brosilow and B. Joseph, Techniques of model-based control. Prentice Hall Professional, 2002. [13] J. A. Rossiter, Model-based predictive control: a practical approach. CRC press, 2017. [14] J. Garcıa and F. Fern´andez, “A comprehensive survey on safe reinforcement learning,” Journal of Machine Learning Research, vol. 16, no. 1, pp. 1437–1480, 2015. [15] M. Hasanbeig, D. Kroening, and A. Abate, “Towards verifiable and safe model-free reinforcement learning,” CEUR Workshop Proceedings, 2020. [16] K. Stankeviciute, A. M Alaa, and M. van der Schaar, “Conformal time-series forecasting,” Advances in neural information processing systems, vol. 34, pp. 6216–6228, 2021. 33 [17] B. Lim, S. ¨O. Arık, N. Loeff, and T. Pfister, “Temporal fusion transformers for interpretable multi-horizon time series forecasting,” International Journal of Forecasting, vol. 37, no. 4, pp. 1748–1764, 2021. [18] B. Tang and D. S. Matteson, “Probabilistic transformer for time series analysis,” Advances in Neural Information Processing Systems, vol. 34, pp. 23592–23608, 2021. [19] L. Chen, K. Lu, A. Rajeswaran, K. Lee, A. Grover, M. Laskin, P. Abbeel, A. Srinivas, and I. Mordatch, “Decision transformer: Reinforcement learning via sequence modeling,” Advances in neural information processing systems, vol. 34, pp. 15084–15097, 2021. [20] B. Ristic, S. Arulampalam, and N. Gordon, Beyond the Kalman filter: Particle filters for tracking applications. Artech house, 2003. [21] K. Cranmer, J. Brehmer, and G. Louppe, “The frontier of simulation-based inference,” Proceedings of the National Academy of Sciences, vol. 117, no. 48, pp. 30055–30062, 2020. [22] D. P. Kingma, T. Salimans, R. Jozefowicz, X. Chen, I. Sutskever, and M. Welling, “Improved variational inference with inverse autoregressive flow,” Advances in neural information processing systems, vol. 29, 2016. [23] A. N. Angelopoulos, S. Bates, A. Fisch, L. Lei, and T. Schuster, “Conformal risk control,” arXiv preprint arXiv:2208.02814, 2022. [24] M. Z. Romdlony and B. Jayawardhana, “Stabilization with guaranteed safety using control lyapunov–barrier function,” Automatica, vol. 66, pp. 39–47, 2016. [25] A. Anand, K. Seel, V. Gjærum, A. H˚akansson, H. Robinson, and A. Saad, “Safe learning for control using control lyapunov functions and control barrier functions: A review,” Procedia Computer Science, vol. 192, pp. 3987–3997, 2021. [26] M. B. Saltık, L. ¨Ozkan, J. H. Ludlage, S. Weiland, and P. M. Van den Hof, “An outlook on robust model predictive control algorithms: Reflections on performance and computational aspects,” Journal of Process Control, vol. 61, pp. 77–102, 2018. [27] A. Bemporad and M. Morari, “Robust model predictive control: A survey,” in Robustness in identification and control, pp. 207–226, Springer, 2007. [28] I. R. Manchester and J.-J. E. Slotine, “Robust control contraction metrics: A convex approach to nonlinear state-feedback H ∞ control,” IEEE Control Systems Letters, vol. 2, no. 3, pp. 333–338, 2018. [29] D. E. Rumelhart, G. E. Hinton, R. J. Williams, et al., “Learning internal representations by error propagation,” 1985. [30] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural computation, vol. 9, no. 8, pp. 1735–1780, 1997. [31] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in neural information processing systems, vol. 30, 2017. [32] L. Hewing, K. P. Wabersich, M. Menner, and M. N. Zeilinger, “Learning-based model predictive control: Toward safe learning in control,” Annual Review of Control, Robotics, and Autonomous Systems, vol. 3, pp. 269–296, 2020. [33] W. Chen, D. Subramanian, and S. Paternain, “Probabilistic constraint for safety-critical reinforcement learning,” arXiv preprint arXiv:2306.17279, 2023. [34] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger, “On calibration of modern neural networks,” in International conference on machine learning, pp. 1321–1330, PMLR, 2017. [35] L. Tao, Y. Zhu, H. Guo, M. Dong, and C. Xu, “A benchmark study on calibration,” arXiv preprint arXiv:2308.11838, 2023. [36] O. Simeone, Machine learning for engineers. Cambridge University Press, 2022. [37] S. G. Walker, “Bayesian inference with misspecified models,” Journal of statistical planning and inference, vol. 143, no. 10, pp. 1621–1633, 2013. [38] R. Martinez-Cantin, K. Tee, and M. McCourt, “Practical Bayesian optimization in the presence of outliers,” in International conference on artificial intelligence and statistics, pp. 1722–1731, PMLR, 2018. 34 [39] M. Zecchin, S. Park, O. Simeone, M. Kountouris, and D. Gesbert, “Robust PACm: Training ensemble models under misspecification and outliers,” IEEE Transactions on Neural Networks and Learning Systems, 2023. [40] V. Vovk, A. Gammerman, and G. Shafer, Algorithmic learning in a random world, vol. 29. Springer, 2005. [41] V. Quach, A. Fisch, T. Schuster, A. Yala, J. H. Sohn, T. S. Jaakkola, and R. Barzilay, “Conformal language modeling,” arXiv preprint arXiv:2306.10193, 2023. [42] N. Deutschmann, M. Alberts, and M. R. Mart´ınez, “Conformal autoregressive generation: Beam search with coverage guarantees,” arXiv preprint arXiv:2309.03797, 2023. [43] Z. Wang, R. Gao, M. Yin, M. Zhou, and D. M. Blei, “Probabilistic conformal prediction using conditional random samples,” arXiv preprint arXiv:2206.06584, 2022. [44] J. Wang, J. Tong, K. Tan, Y. Vorobeychik, and Y. Kantaros, “Conformal temporal logic planning using large language models: Knowing when to do what and when to ask for help,” arXiv preprint arXiv:2309.10092, 2023. [45] A. Z. Ren, A. Dixit, A. Bodrova, S. Singh, S. Tu, N. Brown, P. Xu, L. Takayama, F. Xia, J. Varley, et al., “Robots that ask for help: Uncertainty alignment for large language model planners,” arXiv preprint arXiv:2307.01928, 2023. [46] T. G. Dietterich and J. Hostetler, “Conformal prediction intervals for markov decision process trajectories,” arXiv preprint arXiv:2206.04860, 2022. [47] L. Lindemann, X. Qin, J. V. Deshmukh, and G. J. Pappas, “Conformal prediction for STL runtime verification,” in Proceedings of the ACM/IEEE 14th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2023), pp. 142–153, 2023. [48] F. Cairoli, N. Paoletti, and L. Bortolussi, “Conformal quantitative predictive monitoring of STL requirements for stochastic processes,” in Proceedings of the 26th ACM International Conference on Hybrid Systems: Computation and Control, pp. 1–11, 2023. [49] L. Lindemann, M. Cleaveland, G. Shim, and G. J. Pappas, “Safe planning in dynamic environments using conformal prediction,” arXiv preprint arXiv:2210.10254, 2022. [50] A. Dixit, L. Lindemann, S. X. Wei, M. Cleaveland, G. J. Pappas, and J. W. Burdick, “Adaptive conformal prediction for motion planning among dynamic agents,” in Learning for Dynamics and Control Conference, pp. 300–314, PMLR, 2023. [51] S. T. Jose and O. Simeone, “Address-event variable-length compression for time-encoded data,” in 2020 International Symposium on Information Theory and Its Applications (ISITA), pp. 71–75, IEEE, 2020. [52] G. Revach, N. Shlezinger, X. Ni, A. L. Escoriza, R. J. Van Sloun, and Y. C. Eldar, “KalmanNet: Neural network aided kalman filtering for partially known dynamics,” IEEE Transactions on Signal Processing, vol. 70, pp. 1532–1547, 2022. [53] K. Pratik, R. A. Amjad, A. Behboodi, J. B. Soriaga, and M. Welling, “Neural augmentation of kalman filter with hypernetwork for channel tracking,” in 2021 IEEE Global Communications Conference (GLOBECOM), pp. 1–6, IEEE, 2021. [54] S. Sun and R. Yu, “Copula conformal prediction for multi-step time series forecasting,” arXiv preprint arXiv:2212.03281, 2022. [55] M. Cleaveland, I. Lee, G. J. Pappas, and L. Lindemann, “Conformal prediction regions for time series using linear complementarity programming,” arXiv preprint arXiv:2304.01075, 2023. [56] J. Yoon, D. Jarrett, and M. Van der Schaar, “Time-series generative adversarial networks,” Advances in neural information processing systems, vol. 32, 2019. [57] K. Rasul, C. Seward, I. Schuster, and R. Vollgraf, “Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting,” in International Conference on Machine Learning, pp. 8857–8868, PMLR, 2021. [58] H. Jang, O. Simeone, B. Gardner, and A. Gruning, “An introduction to probabilistic spiking neural networks: Probabilistic models, learning rules, and applications,” IEEE Signal Processing Magazine, vol. 36, no. 6, pp. 64–77, 2019. 35 [59] B. Rosenfeld, O. Simeone, and B. Rajendran, “Spiking generative adversarial networks with a neural network discriminator: Local training, Bayesian models, and continual meta-learning,” IEEE Transactions on Computers, vol. 71, no. 11, pp. 2778– 2791, 2022. [60] D. Stutz, A. T. Cemgil, A. Doucet, et al., “Learning optimal conformal classifiers,” arXiv preprint arXiv:2110.09192, 2021. [61] G. S. Dhillon, G. Deligiannidis, and T. Rainforth, “On the expected size of conformal prediction sets,” arXiv preprint arXiv:2306.07254, 2023. [62] A. Fan, M. Lewis, and Y. Dauphin, “Hierarchical neural story generation,” in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Association for Computational Linguistics, 2018. [63] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi, “The curious case of neural text degeneration,” arXiv preprint arXiv:1904.09751, 2019. [64] C. Meister, T. Pimentel, G. Wiher, and R. Cotterell, “Locally typical sampling,” Transactions of the Association for Computational Linguistics, vol. 11, pp. 102–121, 2023. [65] K. Haneda, J. Zhang, L. Tan, G. Liu, Y. Zheng, H. Asplund, J. Li, Y. Wang, D. Steer, C. Li, et al., “5G 3GPP-like channel models for outdoor urban microcellular and macrocellular environments,” in 2016 IEEE 83rd vehicular technology conference (VTC spring), pp. 1–7, IEEE, 2016. [66] J. Hoydis, S. Cammerer, F. Ait Aoudia, A. Vem, N. Binder, G. Marcus, and A. Keller, “Sionna: An open-source library for next-generation physical layer research,” arXiv preprint, Mar. 2022. [67] E. Dahlman, S. Parkvall, and J. Skold, 4G, LTE-advanced Pro and the Road to 5G. Academic Press, 2016. [68] D. Salinas, V. Flunkert, J. Gasthaus, and T. Januschowski, “DeepAR: Probabilistic forecasting with autoregressive recurrent networks,” International Journal of Forecasting, vol. 36, no. 3, pp. 1181–1191, 2020. [69] N. Hoven and A. Sahai, “Power scaling for cognitive radio,” in 2005 International Conference on Wireless Networks, Communications and Mobile Computing, vol. 1, pp. 250–255, IEEE, 2005. [70] A. Sahai, N. Hoven, S. M. Mishra, and R. Tandra, “Fundamental tradeoffs in robust spectrum sensing for opportunistic frequency reuse,” in Proc First Intl Workshop on Tech. and Policy for Accessing Spectrum, 2006. [71] J. V. Deshmukh, A. Donz´e, S. Ghosh, X. Jin, G. Juniwal, and S. A. Seshia, “Robust online monitoring of signal temporal logic,” Formal Methods in System Design, vol. 51, pp. 5–30, 2017. [72] S. Lin and D. J. Costello, Error control coding: fundamentals and applications. Upper Saddle River, NJ: Pearson/Prentice Hall, 2004. [73] W. Lee, O. Simeone, J. Kang, S. Rangan, and P. Popovski, “HARQ buffer management: An information-theoretic view,” IEEE Transactions on Communications, vol. 63, no. 11, pp. 4539–4550, 2015. [74] I. Gibbs and E. Candes, “Adaptive conformal inference under distribution shift,” Advances in Neural Information Processing Systems, vol. 34, pp. 1660–1672, 2021. [75] M. Zaffran, O. F´eron, Y. Goude, J. Josse, and A. Dieuleveut, “Adaptive conformal predictions for time series,” in International Conference on Machine Learning, pp. 25834–25866, PMLR, 2022. [76] J. Lekeufack, A. A. Angelopoulos, A. Bajcsy, M. I. Jordan, and J. Malik, “Conformal decision theory: Safe autonomous decisions from imperfect predictions,” 2023. 1 APPENDIX A PROOFS A. Proof of Theorem 1 The proof of Theorem 1 relies on an integration of techniques introduced for the analysis of PCP [43] and CRC [23] (see Section VI). The key idea is to treat the pair (y−T :τ −1, P m) of true sequence y−T :τ −1 and prototype set P m, as a data point. The corresponding n augmented calibra- tion data points and the augmented test data point remain i.i.d., or more generally exchangeable, since the predicted sequences are conditionally independent given the respective past samples {yi −T :τ −1} n i=1 and y−T :τ −1. To elaborate, we simplify the notation by denoting the loss L(Γλ(yi 0:τ −1)) of i-th calibration data point as li λ, the test point as yn+1 −T :τ −1, as the test data, and the corresponding test loss as ln+1 λ . We can then rewrite the expected test reliability requirement of PTS-CRC as E [ln+1 λP T S−CRC ] ≤ α, where the expectation is taken as explained in Theorem 1 . We now introduce a genie-aided threshold λ∗ that is based on an empirical estimate of the average loss (6) using a data set that incorporates both calibration and test data as λ∗ := inf { λ : 1 n + 1 n+1∑ i=1 li λ ≤ α } . (48) Given Assumption 1, we have the inequality λ P T S−CRC ≥ λ ∗, for the threshold (20) selected by PTS-CRC. since λP T S−CRC. Denote the (unordered) set of data points as Hy1 −T :τ −1, ..., yn+1 −T :τ −1I. Using the law of total expectation, and given the monotonicity of the loss (Assumption 1), the average loss (6) can be bounded as E[ln+1 λP T S−CRC ] ≤ E[ln+1 λ∗ ] (49) = E[ E [ ln+1 λ∗ |Hl1 λ∗, ..., ln+1 λ∗ I]] = E[∑n+1 i=1 li λ∗ n + 1 ] ≤ α, (50) where the second equality follows from the exchangeability of the losses {l1 λ∗, . . . , ln+1 λ∗ }. This concludes the proof. 2 B. Proof of Theorem 2 By Assumption 1, from Theorem 1, the calibrated set predictor Γ P T S−CRC satisfies the inequality E [ L (Γ P T S−CRC(y−T :−1), y0:τ −1)] = E [ min ˜y0:τ −1∈ΓP T S−CRC (y−T :−1) m(y0:τ −1, ˜y0:τ −1)] ≤ α. (51) From Assumption 2, for any pair (y0:τ −1, s0:τ −1) ∈ Y τ × S τ and for any sequence ˜y0:τ −1 ∈ Γ P T S−CRC(y−T :−1), we have the inequality c(s0:τ −1, y0:τ −1) ≤ c(s0:τ −1, ˜y0:τ −1) + Lm(y0:τ −1, ˜y0:τ −1). (52) Minimizing the right-hand size of (52) over ˜y0:τ −1, we get c(s0:τ −1, y0:τ −1) ≤ min ˜y0:τ −1∈ΓP T S−CRC (y−T :−1) [c(s0:τ −1, ˜y0:τ −1) + Lm(y0:τ −1, ˜y0:τ −1)] (53) ≤ max ˜y0:τ −1∈ΓP T S−CRC (y−T :−1) c(s0:τ −1, ˜y0:τ −1) + L min ˜y0:τ −1∈ΓP T S−CRC (y−T :−1) m(y0:τ −1, ˜y0:τ −1). (54) Taking the expectation with respect to the test sequence y0:τ −1 ∼ p(y0:τ −1|y−T :−1), we obtain E [c(s0:τ −1, y0:τ −1)] ≤ max ˜y0:τ −1∈ΓP T S−CRC (y−T :−1) c(s0:τ −1, ˜y0:τ −1) + Lα, (55) where the inequality follows from (51). We conclude that if there exists a sequence uT +1 . . . , uT +τ such that associated state sequence sT +1 . . . , sT +τ satisfies (26c), then uT +1 . . . , uT +τ is in the feasible set of (14) and it satisfies the desired inequality E [c(s0:τ −1, y0:τ −1)] ≤ 0. C. Proof of Theorem 3 Following the proof for the open-loop case (Theorem 2), if for every time step t = 0, . . . , τ −1 there exists a control sequence ut:τ −1 for which the control problem is feasible, then the reliability guarantee E [c(st:τ −1, yt:τ −1)|s0:t−1, y0:t−1] ≤ 0 is satisfied for all t ∈ [0, τ − 1] and, therefore the original guarantee (14c) is satisfied.","libVersion":"0.3.2","langs":""}