{"path":"lit/lit_sources.backup/Genet24kolmogArnoldFrcstTKAN.pdf","text":"TKAN: Temporal Kolmogorov-Arnold Networks Rémi Genet & Hugo Inzirillo May 2024 Abstract Recurrent Neural Networks (RNNs) have revolutionized many areas of machine learning, particularly in natural language and data sequence processing. Long Short-Term Memory (LSTM) has demonstrated its ability to capture long-term dependencies in sequential data. Inspired by the Kolmogorov-Arnold Networks (KANs) a promising alternatives to Multi- Layer Perceptrons (MLPs), we proposed a new neural networks architecture inspired by KAN and the LSTM, the Temporal Kolomogorov-Arnold Networks (TKANs). TKANs combined the strenght of both networks, it is composed of Recurring Kolmogorov-Arnold Networks (RKANs) Layers embedding memory management. This innovation enables us to perform multi-step time series forecasting with enhanced accuracy and efficiency. By addressing the limitations of traditional models in handling complex sequential patterns, the TKAN architecture offers significant potential for advancements in fields requiring more than one step ahead forecasting. Figure 1: Temporal Kolmogorov-Arnold Networks (TKAN) 1arXiv:2405.07344v1 [cs.LG] 12 May 2024 1 Introduction Time series forecasting is an important branch of statistical analysis and machine learning. The development of machine learning models has accelerated rapidly in the past few years. Time series, which can be defined as sequences of data indexed in time, are essential in finance, meteorology and even in the field of healthcare. The ability to accurately predict the future evolution of this data has become a strategic issue for these different industries constantly seeking for innovation. In recent years, the growing interest in this area of research is mainly due to the massive increase in the availability of data and the increased computer processing capacity now make possible to process large datasets. The second driver is that innovation, particularly in terms of statistical methods, deep learning techniques [SGO20] and hybrid models have offered new opportunities to improve the accuracy and efficiency of forecasts. Econometric models (ARIMA[MH97; MSG14]) and other extensions, Recurrent Neural Networks (RNNs) [MJ+01] are families of models that have been recognized for their proven effectiveness in many forecasting scenarios[HBB21]. RNNs have been proposed to address the \"persistence problem\", i.e. the potentially dependencies between the successive observations of some time series. Therefore, RNNs most often outperform \"static\" networks as MLPs [LJH15]. Traditional methods of gradient descent may not be sufficiently effective for training Recurrent Neural Networks (RNNs), particularly in capturing long- term dependencies [BSF94]. Meanwhile, [Chu+14] conducted an empirical study revealing the effectiveness of gated mechanisms in enhancing the learning capabilities of RNNs. Actually, RNNs have proved to be one of the most powerful tools for processing sequential data and solving a wide range of difficult problems in the fields of automatic natural language processing, translation, image processing and time series analysis where MLPs [HSW89; Hay98; Cyb89] cannot perform well. When it comes to sequential data management, MLPs face limitation. Unlike RNNs, MLPs, are not design to manage sequential data, information only flows in one direction, from input to output (feedforward connection). This specification make them not suitable for modeling temporal sequences where sequence structure is essential for prediction. Another weakness of MLPs is that these networks have no embeded macanism for cell memory state management. Recurrent Neural Networks (RNNs) [Wer90; Wil89] have provided an answer to these problems. However, standard RNNs have solved one problem, but created another: \"vanishing\" or \"exploding gradient problem\" [Hoc98]. Traditional methods of gradient descent may not be sufficiently effective for training RNNs, particularly in capturing long-term dependencies [BSF94]. Meanwhile, [Chu+14] conducted an empirical study revealing the effectiveness of gated mechanisms in enhancing the learning capabilities of RNNs. Actually, RNNs have proved to be one of the most powerful tools for processing sequential data and solving a wide range of difficult problems in the fields of automatic natural language processing, translation and time series analysis. Recently, Liu et al. [Liu+24] proposed Kolmogorov-Arnold Networks (KANs) as an alternative 2 to MLPs. The Kolmogorov-Arnold Network (KAN) is a powerful new neural network architecture known for its improved performance and interpretability. Unlike traditional models, KANs apply activation functions on the connections between nodes, and these functions can even learn and adapt during training. The Temporal Kolmogorov-Arnold Networks (TKANs) in addition to use KAN Layer manage temporality within a data sequence. The idea is to design a new familiy of neural networks capable to catch long term dependency. Our primarly idea is to introduce a an external memory modules which can be attached to KAN Layer. This \"memory\" can store information relevant to the temporal context and be accessed by the network during processing. This allows the network to explicitly learn and utilize past information. Codes are available at https://github.com/remigenet/TKAN and can be installed using the following command: pip install tkan. The data are accessible if you wish to reproduce the experiments inside the github provided above. 2 Kolmogorov-Arnold Networks (KAN) Multi-Layer Perceptrons (MLPs) [HSW89] extension of original percetron pro- posed by [Ros58], are inspired by the universal approximation theorem [Cyb89] which states that a feed-forward network (FFN) with single hidden layer contain- ing a finite number of neurons can approximate continuous functions on compact subsets of Rn. Kolmogorov-Arnold Network (KAN) focus on the Kolmogorov- Arnold representation theorem [Kol61]. The Kolmogorov-Arnold representation theorem states that any multivariate continuous function can be represented as a composition of univariate functions and the addition operation, f (x1, . . . , xn) = 2n+1∑ q=1 Φq ( n∑ p=1 ϕq,p(xp) ) (1) where ϕq,p are univariates functions that map each input variable (xp) such ϕq,p : [0, 1] → R and ϕq : R → R. Since all functions to be learned are univariate functions, we can parametrize each 1D function as a B-spline curve, with learnable coefficients of local B-spline basis functions. The key insight comes when we see the similarities between MLPs and KAN. In MLPs, a layer includes a linear transformation followed by nonlinear operations, and you can make the network deeper by adding more layers. Let us define what a KAN layer is Φ = {ϕq,p}, p = 1, 2, · · · , nin, q = 1, 2 · · · , nout, (2) where ϕq,p are parametrized function of learnable parameters. In the Kolmogov- Arnold theorem, the inner functions form a KAN layer with nin = n and nout = 2n + 1, and the outer functions form a KAN layer with nin = 2n + 1 and nout = 1. So the Kolmogorov-Arnold representations in eq. (1) are simply compositions of two KAN layers. Now it becomes clear what it means to have Deep Kolmogorov-Arnold representation. Taking the notation from [Liu+24] let 3 us define a shape of KAN [n0, n1, · · · , nL], where ni is the number of nodes in the i th layer of the computational graph. We denote the i th neuron in the lth layer by (l, i), and the activation value of the (l, i)-neuron by xl,i. Between layer l and layer l + 1, there are nlnl+1 activation functions: the activation function that connects (l, i) and (l + 1, j) is denoted by ϕl,j,i, l = 0, · · · , L − 1, i = 1, · · · , nl, j = 1, · · · , nl+1. (3) The pre-activation of ϕl,j,i is simply xl,i; the post-activation of ϕl,j,i is denoted by ˜xl,j,i ≡ ϕl,j,i(xl,i). The activation value of the (l + 1, j) neuron is simply the sum of all incoming post-activations: xl+1,j = nl∑ i=1 ˜xl,j,i = nl∑ i=1 ϕl,j,i(xl,i), j = 1, · · · , nl+1. (4) Rewriting it under the matrix form will give, xl+1 =      ϕl,1,1(·) ϕl,1,2(·) · · · ϕl,1,nl (·) ϕl,2,1(·) ϕl,2,2(·) · · · ϕl,2,nl (·) ... ... ... ϕl,nl+1,1(·) ϕl,nl+1,2(·) · · · ϕl,nl+1,nl (·)      ︸ ︷︷ ︸ Φl xl, (5) where Φl is the function matrix corresponding to the lth KAN layer. A general KAN network is a composition of L layers: given an input vector x0 ∈ Rn0 , the output of KAN is KAN(x) = (ΦL−1 ◦ ΦL−2 ◦ · · · ◦ Φ1 ◦ Φ0)x. (6) We can also rewrite the above equation to make it more analogous to eq. (1), assuming output dimension nL = 1, and define f (x) ≡ KAN(x): f (x) = nL−1∑ iL−1=1 ϕL−1,iL,iL−1   nL−2∑ iL−2=1 · · · ( n2∑ i2=1 ϕ2,i3,i2 ( n1∑ i1=1 ϕ1,i2,i1 ( n0∑ i0=1 ϕ0,i1,i0(xi0 ) ))) · · ·   , (7) 3 Temporal Kolmogorov-Arnold Networks (TKAN) After proposing the RKAN (Recurrent Kolmogorov-Arnold Network), which integrates temporality management by adapting the concept of Kolmogorov- Arnold networks to temporal sequences, we developed an additional innovation to build our neural network: the TKAN (Temporal Kolmogorov-Arnold Networks) layer. This TKAN layer combines the RKAN architecture with a slightly modified LSTM (Long Short-Term Memory) cell. The idea is to propose an extension of the model proposed by [Liu+24] to manage sequential data and temporality 4 during the learning task. The objective is to provide a framework for time series forecasting on multiple steps ahead. As discussed previously, RNNs’ weakness lies in the persistence of the information when the input sequence is quite long, resulting in a significant loss of information in some tasks. LSTMs address this problem through the use of a gating mechanism. LSTMs can be computationally more expensive than standard RNNs; however, this extra complexity is often justified by better performance on complex learning tasks. The integration of an LSTM cell combined with the RKAN enables the capture of complex nonlinearities with learnable activation functions of RKAN, but also the maintenance of a memory of past events over long periods with the LSTM cell architecture. This combination offers superior modeling power for tasks involving complex sequential data. The major components of the TKAN are: • RKAN Layers: RKAN layers enable the retention of short term memory from previous states within the network. Each RKAN layer manages this short term memory throughout the processing in each layer. • Gating Mecanism: these mechanisms help to manage the information flow. The model decides which information should be retained or forgotten over time. 3.1 Recurring Kolmogorov-Arnold Networks (RKAN) In neural networks, particularly in the context of recurrent neural networks (RNN), a recurrent kernel refers to the set of weights that are applied to the hidden state from the previous timestep during the network’s operation. This kernel plays a crucial role in how an RNN processes sequential data over time. Let us denote τ = 1, 2, ... a discrete time steps. Each step has a forward pass and backward pass. During the forward pass the ouput or activation of units are computed. during the backward pass the computation of the error for all weights is computed. During each timestep, an RNN receives an input vector and the hidden state from the previous timestep ht−1 . The recurrent kernel is a matrix of weights that transforms this previous hidden state. This operation is usually followed by an addition, the result of this transformation is passed through a non-linear function, an activation function f (.) we can take many forms tanh, ReLU etc. The update could be formulated as such ht = f (Whhht−1 + Whxxt + bh), (8) where ht is the hidden state at time t ∈ τ and Wh and Wx are the recurrent kernel a weight matrix that transforms the previous hidden states ht−1 and the input kernel, a weight matrix transforming the current input denoted xt, respectively. In the latter sections we propose a new kind of update for KAN. We propose a process to maintain the memory of past inputs by incoporating previous hidden state into the current states enabling the network to exhibit dynamic temporal behavior. 5 Recurrent Kernel is the key for RKAN layers learn from sequence where context and order of data matters. We design the TKAN to leverage the power of Kolmogorov-Anrold Network while offering memory management to handle time dependency. To introduce time dependency we modify each transformation function ϕl,j,i to be time dependent. Let us denote hl,i(t) a memory function capturing the history of node i in l-th layer; xl+1,j(t) = nl∑ i=1 ˜xl,j,i(t) = nl∑ i=1 ϕl,j,i,t(xl,i(t), hl,i(t)), j = 1, · · · , nl+1. (9) The \"memory\" step hl,i(t) is defined as a combination of past hidden states, such: hl,i(t) = Whhhl,i(t − 1) + Whzxl,i(t), (10) where W is a vector of weights. W weights the importance of past values relative to the most recent input. Rewriting under the matrix form, we redefine the function matrix Φl,t to consider current and past states: xl+1(t) =      ϕl,1,1(·, ·) ϕl,1,2(·, ·) · · · ϕl,1,nl(·, ·) ϕl,2,1(·, ·) ϕl,2,2(·, ·) · · · ϕl,2,nl (·, ·) ... ... ... ϕl,nl+1,1(·, ·) ϕl,nl+1,2(·, ·) · · · ϕl,nl+1,nl (·, ·)      (xl(t), hl(t)) (11) About the Recurring KAN Layer, the network now embbeds memory man- agement at each layer: KAN(x, t) = (ΦL−1,t ◦ ΦL−2,t ◦ · · · ◦ Φ1,t ◦ Φ0,t)(x, t). (12) Finally, we update the function ξ(x, t) to incorporate memory: ξ(x, t) = nL−1∑ iL−1=1 ϕL−1,iL,iL−1   nL−2∑ iL−2=1 · · · ( n2∑ i2=1 ϕ2,i3,i2 ( n1∑ i1=1 ϕ1,i2,i1 ( n0∑ i0=1 ϕ0,i1,i0(xi0(t), h0,i0(t)) ))) · · ·   . (13) 6 3.2 TKAN Architecture Figure 2: A two layers Temporal Kolmogorov-Arnold Networks (TKAN) Block For the next step, towards to maintain the memory, we took inspiration from the LSTM [HS97; SM19]. We denote the input vector of dimension d denoted by xt. This unit uses several internal vectors and gates to manage information flow. The forget gate, with activation vector ft, ft = σ(Wf xt + Uf ht−1 + bf ), (14) decides what information to forget from the previous state. The input gate, with activation vector denoted it, it = σ(Wixt + Uiht−1 + bi), (15) controls which new information to include. The output gate, with activation vector ot, ot = σ(ξ(⃗x, t)), (16) 7 determines what information from the current state to output given ξ(⃗x, t) from eq. (13) . The hidden state, ht, captures the unit’s output, while the cell state, ct is updated such ct = ft ⊙ ct−1 + it ⊙ ˜ct, (17) where ˜ct = σ(Wcxt + Ucht−1 + bc) represents its internal memory. All these internal states have a dimensionality of h. The ouput denoted ht is given by ht = ot ⊙ tanh(ct). (18) Finally, the unit relies on parameter matrices W and U , and a bias vector b. Hence, the predicted ouput will be given by ˆyt = Whyht + by. (19) In the latter section we will describe the learning task and the several tests proceeded. We started to test the power of prediction of our model for one steap ahead forecasting and in the second time for multi-step ahead [Fan+19; Lim+21]. 4 Learning Task In this study, we evaluate the predictive capabilities of our model on real-world data, specifically to avoid biases inherent in synthetic datasets. The primary goal is to assess the model’s performance in leveraging historical data to forecast future values across multiple time steps. 4.1 Task Definition and Dataset The objective of this task is to predict future market traded notional values of Bitcoin (BTC) across several time steps. For this purpose, data were sourced from Binance Exchange, the largest market player, focusing on currency pairs quoted in USDT (Tether). The dataset comprises hourly notional values spanning multiple assets, including BTC, ETH, ADA, XMR, EOS, MATIC, TRX, FTM, BNB, XLM, ENJ, CHZ, BUSD, ATOM, LINK, ETC, XRP, BCH, and LTC. These assets were selected based on their liquidity over a three-year period from January 1, 2020, to December 31, 2022. Although the dataset encompasses a variety of assets, the predictive analysis is confined to the BTC-USDT trading pair in order to not have scaling effects between the pairs that is even harder to tackle in the objectives than in the inputs, that would overcomplicate the test example. 4.2 Data Preparation Data preparation plays a critical role in the performance of both economet- ric and deep learning models. This is particularly crucial when employing a 8 Kolmogorov-Arnold Network(KAN) model, which incorporates exponential acti- vation functions that are sensitive to the scale of input data. Moreover, financial series such as market volumes or notional values often exhibit significant variabil- ity in magnitude across different assets and time periods, necessitating careful scaling and normalization to ensure model stability and performance. To address these challenges, we applied two standard preprocessing steps to our dataset. First, each time series was normalized by dividing by its rolling median over a 14-day period (336 observations). This normalization, applied with a lag equal to the forecast horizon, mitigates the influence of outliers and reduces forward-looking bias, essential for creating a reliable predictive model. Second, we implemented MinMax scaling for each series. This scaling tech- nique adjusts the data to fall within a [0,1] range, which is particularly beneficial for neural network models that are sensitive to input magnitude. Unlike stan- dard normalization that centers data around zero, MinMax scaling preserves the natural zero point of the series (which is typically the initial serie minimum on hourly klines), typically by dividing each observation by the maximum value observed in the training set. This approach ensures that the scale of the inputs remains consistent, avoiding issues related to activation function saturation and numerical overflow. For the partitioning of the dataset, we allocated 80% of the data for training and 20% for testing. This split provides over 21,000 observations for training, ensuring ample data for the model to learn, and approximately 5,000 for testing to evaluate model performance. 4.3 Loss Function for Model Training To evaluate the predictive accuracy of our model, we employ the Mean Squared Error (MSE) as the loss function. MSE is a widely recognized performance metric in both statistical forecasting and machine learning, offering a clear quantification of the prediction error by measuring the average squared difference between the predicted and actual values. Formally, the MSE is computed as follows: MSE = 1 N N∑ i=1 ( ˆX(i) t+1 − X(i) t+1)2 , where N represents the number of samples in the dataset, ˆX(i) t+1 denotes the predicted notional values of Bitcoin at time t + 1 for the i-th sample, and X (i) t+1 are the corresponding true values. This loss function is particularly effective for regression problems where the goal is to minimize the errors in predictions. By squaring the errors, the MSE gives a higher weight to larger errors, making it sensitive to outliers and ensuring that the model accurately captures significant deviations from the actual values. 9 4.4 Temporal Kolmogorov-Arnold Networks Evaluation and Benchmarking In this section, we evaluate the efficacy of the TKAN by benchmarking it against conventional recurrent neural networks, Gated Recurrent Units (GRU) and Long Short-Term Memory (LSTM) networks. These models are well-established in the field of time-series forecasting and are known for their robust capability to capture complex temporal dependencies. 4.4.1 Model Architectures To ensure comparability, each model was constructed with a standardized ar- chitecture, facilitating a direct assessment of their predictive performance. The LSTM and GRU models were configured with their default activation function, tanh, as provided by TensorFlow, which serves as the standard nonlinearity for processing temporal sequences. The common architecture framework for each model includes: 1. An initial recurrent layer with 100 units that returns full sequences, cap- turing a broad temporal context. 2. A middle recurrent layer with 100 units, designed not to return sequences, focusing the model’s output on specific predictive targets. 3. A final Dense layer with linear activation, projecting the recurrent layer’s output into the forecast horizon, producing the predicted values for each time step. For the TKAN model, we used as sub-layers activations 5 B-Spline activation of order ranging from 0 to 4. Finally, we also compared the three model with the most naïve benchmark, which consists on using the last value as a predictor of the futures one, the value being repeated when using multiple steps-ahead predictions. 4.4.2 Metrics and Comparative Framework The performance of each model was quantitatively assessed using the R-squared (R2) metric, which is commonly utilized in financial and economic modeling due to its interpretability. R2 provides an indication of the proportion of variance in the dependent variable that is predictable from the independent variables, offering a normalized measure of predictive accuracy: R2 = 1 − ∑N i=1( ˆX(i) t+1 − X(i) t+1) 2 ∑N i=1(X(i) t+1 − ¯Xt+1)2 , where ˆX(i) t+1 and X (i) t+1 are the predicted and actual values respectively, and ¯Xt+1 is the mean of the actual values. 10 4.5 Training Methodology and Implementation Details Our model training employs a thorough scaling and normalization approach to address the dynamic nature of financial time series data. During training, we compute the loss function on data that has undergone scaling. However, when calculating the R-squared (R2) performance metric, we only reverse the Min-Max scaling, not the median division normalization. Since the original minimum value of the series is zero, this partial re-scaling doesn’t affect the results. We avoid reversing the median division normalization because doing so would disproportionately weight certain parts of the dataset, leading to a loss of meaning in our metrics. This strategy helps maintain the relevance and accuracy of the performance assessments over time. 4.5.1 Optimization and Training Callbacks The Adam optimizer, a popular choice for its efficiency in handling sparse gradients on noisy problems, was utilized for training all models. To enhance the training process, two specific callbacks were implemented: 1. Early Stopping: This callback halts training if there is no improvement in the loss metric over six consecutive epochs, thereby preventing overfitting and reducing unnecessary computational effort. The best weights are restored at the end. 2. Learning Rate Reduction on Plateau: This callback reduces the learning rate by half whenever there is no decrease in loss over three consecutive epochs. This strategy helps to fine-tune the models by making smaller adjustments in weights, potentially leading to better convergence in later stages of training. Both callbacks use a validation set, which constitutes 20% of the training data, randomly selected to ensure the independence of the test dataset. The validation set provides a robust measure for model adjustment and performance tuning. Importantly, the test dataset is carefully separated from the final portion of the data series to avoid any overlap, thereby preserving the integrity and independence of the test data used for final model evaluation. 4.6 Results This section presents a comprehensive analysis of the model performance evalua- tions. To ensure robustness and reproducibility of our results, each model was trained five times using the same dataset. The ensuing analysis is based on the average performance metrics and the observed deviations between each training session, thus providing insight into both the effectiveness and consistency of each model. 11 4.6.1 Performance Metrics Summary The performance of the models was quantified using the R-squared (R2) metric, calculated for predictions that were scaled using only Min-Max scaling and then rescaled back to the original values. The following tables summarize these metrics: Table 1: Average (R2) obtained over 5 run Time TKAN:5 B-Spline GRU:default LSTM:default Last Value 1 0.350845 0.365136 0.355532 0.292171 3 0.198842 0.200674 0.061220 -0.062813 6 0.140543 0.082504 -0.225838 -0.331346 9 0.117477 0.087164 -0.290584 -0.457718 12 0.105111 0.017864 -0.473220 -0.518252 15 0.086077 0.033423 -0.404432 -0.555633 Table 2: Standard Deviation of the (R2) obtained over 5 run Time TKAN:5 B-Spline GRU:default LSTM:default 1 0.014208 0.008336 0.011163 3 0.007385 0.004848 0.080200 6 0.007238 0.023637 0.062710 9 0.014551 0.014833 0.052729 12 0.003919 0.086386 0.085746 15 0.024656 0.024078 0.092729 The results of the model evaluations reveal significant insights into the per- formance of each model over different forecast horizons. The following discussion delves into the details of the performances and interprets the implications of these results. Performance Analysis From the data in the previous tables, we observe a clear trend across all models where the R2 scores generally decrease as the prediction horizon increases. This trend is typical in time series forecasting due to the increasing uncertainty and difficulty in making accurate long-term predictions. • Short-term Predictions: At a 1-time step ahead prediction, the GRU [Cho+14] performs slightly better than the LSTM and TKAN models, with an R2 score of 0.365136. This suggests that GRU’s simpler architecture might be capturing the necessary information more effectively at shorter horizons. 12 • Mid-term Predictions: At 3 and 6 time steps ahead, we notice that the R2 scores for all models, especially LSTM, begin to significantly deterio- rate. The LSTM model shows a notable decline to -0.225838 at a 6-time step, indicating poor performance in capturing longer-term dependencies compared to the other models. • Long-term Predictions: By the 12 and 15-time steps, all models show negative R2 values, except for the TKAN model, which still maintains positive values albeit low (0.105111 and 0.086077 respectively). This suggests that the TKAN model, with its 5 B-Spline activations, is somewhat more robust in handling the increasing unpredictability at longer horizons. Model Stability The standard deviation of the R2 scores, as listed in the second table, provides insights into the stability of the models across multiple runs. A lower standard deviation indicates a more reliable model in terms of performance consistency. • The TKAN model shows relatively low standard deviations across all time steps, highlighting its consistency despite varying conditions. However, an increase is noted at the 15-time step, aligning with the general trend of decreasing performance reliability over longer horizons. • The LSTM model exhibits high standard deviations, especially from 3-time steps onwards, peaking at 12 and 15-time steps (0.085746 and 0.092729 respectively). This indicates significant variability in performance, which could be attributed to its sensitivity to initial conditions and the stochastic nature of the training process. • The GRU model, while generally consistent at shorter horizons, shows a sudden increase in variability at the 12-time step (0.086386), suggesting challenges in model performance under extended prediction intervals. Comparative Insights All tested models consistently outperform the naive benchmark across all prediction horizons. This superior performance highlights the advantages of sophisticated modeling techniques over a simplistic approach, such as relying on the last observed value for predictions. Despite the natural decrease in R2 scores with longer forecast horizons, each model maintains a higher accuracy level compared to the naive benchmark, demonstrating that they are able to capture at least some informations to give a prediction. This consistent outperformance suggests that even as forecasts become more challenging at longer horizons, the structured learning and temporal dynamics captured by models like the TKAN, GRU, and LSTM offer significant improvements over basic heuristic methods. 4.6.2 Training Dynamics and Model Stability To further elucidate the performance differences between the models, we visu- alized the training and validation loss over multiple training sessions for each 13 model. These graphs offer a dynamic view of each model’s learning process and its ability to generalize beyond the training data, shedding light on their stability and efficiency during training. Figure 3: TKAN training and validation loss over epochs Figure 4: GRU training and validation loss over epochs 14 Figure 5: LSTM training and validation loss over epochs The visual representations clearly corroborate the statistical findings pre- sented earlier. The GRU and LSTM models exhibit significant divergence between their training and validation loss trajectories, particularly as the num- ber of epochs increases. This divergence suggests potential overfitting where the model learns the idiosyncrasies of the training data rather than generalizing from it. In contrast, the TKAN model demonstrates a much more stable convergence between training and validation losses, indicating better generalization and robustness across different training sessions.This stability in the TKAN model’s training process, evident from the closer alignment of its training and validation loss curves, implies a consistent learning pattern that effectively captures the underlying patterns in the data without overfitting. 5 Conclusion We proposed in this paper an adaptation of the Kolmogorov-Arnold Network architecture for time series that incorporates both recurring and gating mecha- nisms. The architecture, while not so complicated, enables improving multiple steps performances and stability compared to traditional methods and seems to be promising. The temporal Kolmogorov-Arnold networks (TKANs) combine the best features of recurrent neural networks (RNNs) and Kolmogorov-Arnold Networks (KANs). This new architecture tackles the usual problems of RNNs (long-term dependency). TKANs embed Recurrent Kolmogorov-Arnold Net- works (RKAN). These layers help the system to memorize and use new and old information efficiently. Compared with traditional models such as LSTM and GRU, TKAN particularly stands out when it comes to making longer-term predictions, showing that it is capable of handling different situations and longer periods of time. Our experiments show that it is usable and more stable than GRU and LSTM on real historical market data. While not specifically interesting for short-term predictions, it especially demonstrates an ability to largely out- 15 perform other models when it comes to multi-step predictions.This also confirms that the idea developed in the original KAN paper works well on real use cases and is totally relevant for time series analysis. This paper opens interesting new ways to improve our capacities to calibrate accurate time-series models over multiple steps, which is of the hardest tasks in temporal analysis. References [BSF94] Y. Bengio, P. Simard, and P. Frasconi. “Learning long-term depen- dencies with gradient descent is difficult”. In: IEEE Transactions on Neural Networks 5.2 (1994), pp. 157–166. doi: 10.1109/72.279181. [Cho+14] Kyunghyun Cho et al. “Learning phrase representations using RNN encoder-decoder for statistical machine translation”. In: arXiv preprint arXiv:1406.1078 (2014). [Chu+14] Junyoung Chung et al. “Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling”. In: CoRR abs/1412.3555 (2014). [Cyb89] George Cybenko. “Approximation by superpositions of a sigmoidal function”. In: Mathematics of control, signals and systems 2.4 (1989), pp. 303–314. [Fan+19] Chenyou Fan et al. “Multi-horizon time series forecasting with tem- poral attention learning”. In: Proceedings of the 25th ACM SIGKDD International conference on knowledge discovery & data mining. 2019, pp. 2527–2535. [Hay98] Simon Haykin. Neural networks: a comprehensive foundation. Pren- tice Hall PTR, 1998. [HBB21] Hansika Hewamalage, Christoph Bergmeir, and Kasun Bandara. “Recurrent neural networks for time series forecasting: Current status and future directions”. In: International Journal of Forecasting 37.1 (2021), pp. 388–427. [Hoc98] Sepp Hochreiter. “The vanishing gradient problem during learning recurrent neural nets and problem solutions”. In: International Jour- nal of Uncertainty, Fuzziness and Knowledge-Based Systems 6.02 (1998), pp. 107–116. [HS97] Sepp Hochreiter and Jürgen Schmidhuber. “Long short-term memory”. In: Neural computation 9.8 (1997), pp. 1735–1780. [HSW89] Kurt Hornik, Maxwell Stinchcombe, and Halbert White. “Multi- layer feedforward networks are universal approximators”. In: Neural networks 2.5 (1989), pp. 359–366. 16 [Kol61] Andrei Nikolaevich Kolmogorov. On the representation of contin- uous functions of several variables by superpositions of continuous functions of a smaller number of variables. American Mathematical Society, 1961. [Lim+21] Bryan Lim et al. “Temporal fusion transformers for interpretable multi-horizon time series forecasting”. In: International Journal of Forecasting 37.4 (2021), pp. 1748–1764. [Liu+24] Ziming Liu et al. “KAN: Kolmogorov-Arnold Networks”. In: arXiv preprint arXiv:2404.19756 (2024). [LJH15] Quoc V Le, Navdeep Jaitly, and Geoffrey E Hinton. “A simple way to initialize recurrent networks of rectified linear units”. In: arXiv preprint arXiv:1504.00941 (2015). [MH97] Spyros Makridakis and Michele Hibon. “ARMA models and the Box–Jenkins methodology”. In: Journal of forecasting 16.3 (1997), pp. 147–163. [MJ+01] Larry R Medsker, Lakhmi Jain, et al. “Recurrent neural networks”. In: Design and Applications 5.64-67 (2001), p. 2. [MSG14] Prapanna Mondal, Labani Shit, and Saptarsi Goswami. “Study of effectiveness of time series modeling (ARIMA) in forecasting stock prices”. In: International Journal of Computer Science, Engineering and Applications 4.2 (2014), p. 13. [Ros58] F. Rosenblatt. “The perceptron: A probabilistic model for information storage and organization in the brain.” In: Psychological Review 65 (1958), pp. 386–408. issn: 0033-295X. [SGO20] Omer Berat Sezer, Mehmet Ugur Gudelek, and Ahmet Murat Ozbayo- glu. “Financial time series forecasting with deep learning: A system- atic literature review: 2005–2019”. In: Applied soft computing 90 (2020), p. 106181. [SM19] Ralf C Staudemeyer and Eric Rothstein Morris. “Understanding LSTM–a tutorial into long short-term memory recurrent neural networks”. In: arXiv preprint arXiv:1909.09586 (2019). [Wer90] Paul J Werbos. “Backpropagation through time: what it does and how to do it”. In: Proceedings of the IEEE 78.10 (1990), pp. 1550– 1560. [Wil89] Ronald J Williams. “A learning algorithm for continually running fully recurrent neural netwokrs”. In: Neural Computation 1 (1989), pp. 256–263. 17","libVersion":"0.3.2","langs":""}