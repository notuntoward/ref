{"path":"lit/lit_sources/Gordon83CumulativeDistributionFunction.pdf","text":"This article was downloaded by: [University of Chicago Library] On: 02 June 2013, At: 22:23 Publisher: Taylor & Francis Informa Ltd Registered in England and Wales Registered Number: 1072954 Registered office: Mortimer House, 37-41 Mortimer Street, London W1T 3JH, UK Journal of Statistical Computation and Simulation Publication details, including instructions for authors and subscription information: http://www.tandfonline.com/loi/gscs20 Cumulative distribution function of the sum of correlated chi— squared random variables N. H. Gordon a & P. F. Ramig b a Assistant Professor, Department of Mathematics and Statistics, Case Western Reserve University, Cleveland, Ohio, 44106, U.S.A b Standard Oil of Ohio, Cleveland, Ohio, U.S.A Published online: 20 Mar 2007. To cite this article: N. H. Gordon & P. F. Ramig (1983): Cumulative distribution function of the sum of correlated chi— squared random variables, Journal of Statistical Computation and Simulation, 17:1, 1-9 To link to this article: http://dx.doi.org/10.1080/00949658308810633 PLEASE SCROLL DOWN FOR ARTICLE Full terms and conditions of use: http://www.tandfonline.com/page/terms-and-conditions This article may be used for research, teaching, and private study purposes. Any substantial or systematic reproduction, redistribution, reselling, loan, sub-licensing, systematic supply, or distribution in any form to anyone is expressly forbidden. The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date. The accuracy of any instructions, formulae, and drug doses should be independently verified with primary sources. The publisher shall not be liable for any loss, actions, claims, proceedings, demand, or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material. J S!utrxr Compu!. Srmu!., !9E?, Vo!. !?, pp. 1-9 0094-4655,'85:173i-O~i $16 5043 IB Gordon and Brcach Sc~ence Publishers Inc.. 1983 Prinied in Grear Briiala (Received January 11, 1982) The cumulative distribution function of the sum, S, of correlated XZ[n] random variables can be obtained by considering a multivariate generalization of a gamma distribution which occurs naturally within the context of a general multivariate normal model. By application of 4,. ' r:le !urc:s;u~~ f~rmda to ihe characierisiic function of S, an accurate method for calcuiating the dkiiibiiiioii of S was obtained. An expiicii expression for this distribution is presented for certain parameter va!i;es in thi case where ihe underiying muiiivariare normai model has the moving averages correiation structure. Agreement between the two methods was excellent. KEY WORDS: Correlated chi-squmb distribution; moving averages; variance. 1. INTRODUCTION The need for the cumulative distribution of the sum of correlated X2[n] variables arises in the construction of confidence intervals for the common variance, a2, of multivariate normal populations with correlation structure having unknown correlation parameters. Determination of these confidence intervals has been largely restricted to the case where szmples are assumed to be independent. However, within the context of a general .-.--^- 2-? I ---- 2 ----- ii;isli ;i;i;i;;;;, ucp,--;;cc:i~~ amcng the componeii& of the error vector can be incorporated into the model. Examples of such modeling of dependesce (Box, et ill., 1978) have often led to a variance-covariance structure of the form a2y where I/ is the correlation matrix. intervai estimators for the common variance, a', have been obtained by Ramig and Zacks (1980) for the intraclass correlation structure and by ?Present address: Department of Surgery, C. W.R.U. Downloaded by [University of Chicago Library] at 22:23 02 June 2013 3 - N H GORDON ,4ND P. F. RAMIG The distribution of the sum of correlated x2[n] variables can be obtained by considering a multivariate generaiizarion of a gamna disiribu:ion which occurs naturally within the context of a multivariate normal model. For this generalization, let (Zil,. . ., Z,,), i= 1,. . ., n, be a sample of n indcpendeni random vectors of dimension mj where each vector has a joint muitivariate normai distribution with zero mean vector and variance-covariance matrix, L! Tnis matrix consisis of 1's e:: its diagona! and i-nji.n- l)/2 corre!atim parameters on its off diagonal eiements. T'ne joint distribution of S,,. ..,S,, whzre Sj=xl=, Z;, j= !,.. .,nz is then one such multivariate gamiria distri\"vu:in. Each one of the statistics, Sj, has a marginal X2[n] distribution. The join: bistributior, of Si,. . ., S, has been called the \"muitivariate chi-square7' (Krishnaiah, ei d., 1963) and the \"generalized Rayleight distribution\" (Miller, 1954). An explicit form of the density function for m=2 is given by Jehnson and Kotz (1 972). Lukacs and Laha (1964) have given the joint characteristic fsnction of Si, ..., S, as where D, is a diagonal matrix with diagonai eiements t,, . . ., i,, and I is the identity iriatfix of A' uimbAulx ---.A- K. Let S= xjm= Sj: Thus defined, S has a characteristic function (Gnedenko, 196bj Downloaded by [University of Chicago Library] at 22:23 02 June 2013 Further, let k=[m/2], where [x] is the greatest integer less than or equal to x. Then and, if m is even, If E is odd, the !as? term in b(t) is Downloaded by [University of Chicago Library] at 22:23 02 June 2013 It is straightforward to show that the integrand of (2.3) is continuous e. aria bounded fCr $1 of L ia ( .zFu,, y) iill;i;-iding t &. &,Iorco~;cr; as ,i-0, the integrand has the value (, - tl. The integral (2.3) was evaluated numerically after simplification of the integrand. For this simplification, note that exp(- it, t) - exp( - i5,tj can be expressed as A(t) + iB(t), where A(t) = cos((,t) - cos(t2t) and B(t) = sin(t2t) - ~i~((,~j. Ajf) is an eve11 fzilciiori of i, .-.I------ D'+l ;.- -AA l?, ,-thPrmnrp w1:c:caa D\\L~ 13 VUU. I JL II~~~~~~.~~~~ A(t) + iB(t) can be expressed as r,(t) expji&, jt)), where r,ji) = [A2(ij L E?2jt)]1i2 and 4: (t) is an angle between O and 271.. 4:jtj is determined by its angle of reference, u,(t)=a tanlE(t)/~(t)l. x,(tf satisfies the condition, Osal(t)snj2. The quadrant in which 4,jtj iies is the same as that in which the point (~(t), B(tj) iies. Thus, A (1) = r ,(i) cos & ,(ij aiid bjij = rl(t) sin 41(t). Using Eq. (24, $,(t) car, be expressed as ([a(tj + ib(t)]'12)-n. The two square roots of the function a(t)+ibjt) can be expressed as [a2(t) + b2(t)]lI4exp t(Q(t)/2 + kn), with k =O or I. To define O(t), let a,(t) =a tanlb(t)/a(tfl where c,(t) is between 1) and 1112. An angle Qf(t), between O and 27r, is then defined using a,(tj as its angle of reference. The quadrant in which d'(t) lies is the same as that in which the point (a(t), b(t)) lies. Further as t+O, a(t) and b(t) change sign; thus, Q1(t) oscillates through the va!ues from 271 to O beginning at 271 when t=O and decreasing as i increases. in order for $,ji) to be a cu~iiiiiuoii~ fiiiiction of t, 8::) must be coterminai with Q'jij and itself IiiiiSi b2 a con tin^^::^ fumtior. of t. Consequentiy, Q(t) is defined as B1(t)-2jn, where j is aii integer equal to the number of times a'jt) has gone through a ci;rnp!ete period of its va!ues. $,(t) then becomes r2(t) exp(i4,(t)), where Downloaded by [University of Chicago Library] at 22:23 02 June 2013 Obaelvation of tile equations for iijt) and bjtj rebeak that as t-+O+. n(t)-t 1 and hit )+0 causlng 8(t)+27[-. and rzlt)+ 1 Therefore, 3. NUMERICAL EVALUATION 'To evaluate the integrai (2.4j, the trapezoidai ruie was used on the interval from 0 to T whic!? was partitioned as fo!!ows: nt=0.0i, to=O, tj=to +jAt for j=O,. . ., k. Equation (2.4) then becomes cos nn . rl(tj)r2(tj) sin[dl(tj) -nQ(tj)/2] At Fs(t2)-zFs(t1) =- llm C (3.1) n k+mj=o tj The infinite sum was terminated as soon as 10 consecutive values of the suinmand were 5 IQ-'. Computations were carried out using single . . y-ec!s!on (8 decimal places) on a Digital DEC 2060 computer. TL- ---. I UG au,LiriiCj; of the numerical integration in Eq. (3.1) was ascertained by comparing the results of this integration with those from an explicit form of F,(x), (Tables 1 and Il), for the case when the underlying normal mdel has the moving averages xiariance-celiariance structure, i.e., !/=I +{pfi(ii-ji-l)j, where 6(x) equais 1 if x=0 but otherwise equais 0, and 1 gi, jgm. This explicit form can be obtained for even values of 11 and has the added restriction that the underlying multivariate normal mode! must have non-singular variance-covariance structure (see Appendix B). In Downloaded by [University of Chicago Library] at 22:23 02 June 2013 required !he use of double precision (at least 16 decimal places) especially at lavier l,rajues of I. This &fficill;;; jncrcases 2s x dccrezss and tn t? increase. From a practical point of view, caiculation of Eqs. (5.2) and (5.3) are not to be recommended. They serve though as good ihecks on the accuracy of the fiumericz! rr,ethod using the inversion formula. The i~uersion method is easily evaluated for both odd and even values of r! as weii as for all values of p E(- 1. i). This is true even when the variance-covariance structure of the uiideiiqliig muitivariate normal ;;.,ode! is singu!ar. Fer cxampk, in the case of the moving averages model. the characteristic roots, ,?j, arc quai to 1-2p co~Gn,'j;ii + I jj f~i j = !, . . ., m. -. . 3 . . ! fi~_~~fcr~, :gajh~~~: p w;i_;~ii yield negaiii..i: cnarac:er;s;;c ;sots prod-ee singular rnulrlvariate nnrma! models. Further~nore, as can be seen from - @ abiPs I and the jnVersioii iriei;iod _- 2-- -- -..- - L - VLSV~UL~ dbiuiiitc rzsults. The TASLE ; P[Ssxl Using Eq. (3.1) for the Inversion Method (IM) and Eq (5.2) for the Expllclt Method (EM! -, -hen rn 2. n = 2 0.28495696 0.60736505 0.79974401 0 90044677 0.95097696 0.97594696 0.99861618 nnn u.779770~7 OOOLA 0.99999941 ,=4 0.02357604 0.16130391 0.37373213 0.57721477 0.73380219 0.84005599 0.9833l791 0.99997385 1.0000000 'p IS the correlat~on parameter for the moving averages model Downloaded by [University of Chicago Library] at 22:23 02 June 2013 -. . .F.Y r 77 1 ,\\DL& 11 P[Ssx] Using Eq. (3.1) for the inversion Method iIM1 and Eq. i5.3~ for the Explicit Method (F,;\";,; -+; -,cT, iizL 6. 0.00000 184 0.00009 11 7 0.0Oi 1 i 528 0.00637634 - m\"m,,n.- U.ULL00Y I,! 0.31171966 0.97489727 0.99987166 \"p IS the correlat~on parameter lor the rnovlng averages model. \"Explic~t Method nor appl~cable lor p values which produce negative characteristic roots difference between ihe i~o methods is at most of the order of 1 x IF6 and generally decreases as m and n increase. In conclusion, the inversion method for obtaining the cumulative distribution function of S is an accurate as well as 2 convenient methd. References sox, G. E. P., Hunter W. G. and Hunter J. S. (1Y78). St~tl~tics j>r Experimenters. john Wiiey & Sons, Inc., New York. Gnedenko, B. V. (1968). 7% Theory oJf ?Cpmbahi!i!y. Chelsea Publishing Co,, New York Graybill, F. A. (1976). Theory and Applicution of the Linear Model. Duxbury Press, North Scituate. Johnson, N. L. and Kotz, S. (1972). Distributions in Statistics: Continuous Multivariate Distributions. John Wiley & Sons, Inc., New York. Downloaded by [University of Chicago Library] at 22:23 02 June 2013 Kr.rh;?.~i&\".. P I? H:?~iq P :id sic in her^. L (1963; 4 K!>ic cii: he Ri~ariate Ch,. Distribution. Sf.4.M Re~mt, 5. 140-~!41. - < iiris:lnamoorth,, A. 5 ~nii Fxthziarathy, M (1951). .A. M/lu!!i\\ahte Gam:m-Tlpe D:stribu!ion. .-Innii!? 01\" .Ma~hema:icai Sruiicrir,y 31, 329-557 iukacs. E. and Laha. R. G. (1964). Applicaimns qj Ctzuiiicierzsrrc L'incrlo?;~. Grifiin's Statistical Monographs No. 14. Cjr~ffin, London. Mi!!er, K. E (1964). Multidimensionnl Gaussian Distribution.r. John Wiley & Sons, Inc., New York. . . Rarnig, P. F. and Zacks, S. Confidence Intervals Ibr the Common Variance or' Equlcorreiated Nomai Random Variahies, 111 prcpitiaiion for piibkhtisn. = - r,jtj sin(nQ(tjl2) cos nn. Note that C(t) is even in t. D(t) can be easily shown to be odd. With this simplification, the numerator of the integrand of (2.3) can be expressed as [Ajt) + iB(t)] [C(t) i iD(t)] which yields The real part of (4.1) is an even function of t, whereas the imaginary part . . is \"b& Using symme~ry of (4.2 j, -\" - ----. --G.; .. \" -----,.- 4,-\" LiiG iiiic&i a~i~a 1 G~LG~GLI LG; by Eq. (2.3) is equivalent to The integrand of Eq. (4.2) can now be expressed in terms of the original variables as in Eq. (2.4). Downloaded by [University of Chicago Library] at 22:23 02 June 2013 where J = 1.. . .j mi are the characteristic roots of E.' Furfhe~ where cj, j= I,. . ., m, can be found by Heaviside expansion and have the values For even vaiues of ii, Fs,,jx) is a mixture of gamma distributions. Ai a vaiue of n = 2, For n=4, Equations (5.2) and (5.3) yield meaningful results only if the characteristic roots are all positive, i.e., the underlying multivariate normal model has a non-singular variance-covariance structure. Downloaded by [University of Chicago Library] at 22:23 02 June 2013","libVersion":"0.3.1","langs":""}