{"path":"lit/lit_sources/Plassier24ConditionallyValidProbabilistic.pdf","text":"Conditionally valid Probabilistic Conformal Prediction Vincent Plassier 1 Alexander Fishkov 2,4 Maxim Panov 2 Eric Moulines 2,3 1 Lagrange Mathematics and Computing Research Center 2 Mohamed bin Zayed University of Artificial Intelligence 3 CMAP, Ecole Polytechnique 4 Skolkovo Institute of Science and Technology vincent.plassier@ens-paris-saclay.fr Abstract We develop a new method for creating prediction sets that combines the flexibility of conformal methods with an estimate of the conditional distribution PY |X . Most existing methods, such as conformalized quantile regression and probabilistic conformal prediction, only offer marginal coverage guarantees. Our approach extends these methods to achieve conditional coverage, which is essential for many practical applications. While exact conditional guarantees are impossible without assumptions about the data distribution, we provide non-asymptotic bounds that explicitly depend on the quality of the available estimate of the conditional distribution. Our confidence sets are highly adaptive to the local structure of the data, making them particularly useful in high heteroskedasticity situations. We demonstrate the effectiveness of our approach through extensive simulations, showing that it outperforms existing methods in terms of conditional coverage and improves the reliability of statistical inference in a wide range of applications. 1 Introduction Conformal predictions are commonly used to construct prediction sets. Under minimal assump- tions, they offer finite-sample validity [40, 36]. However, significant challenges arise with high heteroskedasticity, often leading to incorrect inferences [11]. The split-conformal approach uses a set of n calibration data points {(Xk, Yk)}k∈[n] with Xk ∈ Rd and Yk ∈ Y to create a prediction set Cα(x) where α ∈ (0, 1). For each x ∈ Rd, the prediction set based on a conformity score function V : Rd × Y → R, is given by Cα(x) = {y ∈ Y : V (x, y) ≤ Q1−α ( 1 n + 1 ∑n k=1 δV (Xk,Yk) + 1 n + 1 δ∞ )} , where Q1−α represents (1 − α)-quantile of the adjusted empirical score distribution 1 n+1 ∑n k=1 δV (Xk,Yk) + 1 n+1 δ∞. If the calibrations data {(Xk, Yk)}k∈[n] are drawn i.i.d. from a population distribution PX,Y , then for any new data point (Xn+1, Yn+1) ∼ PX,Y sampled inde- pendently of the calibration data, the conformal theory ensures the marginal validity of Cα(Xn+1), meaning that P (Yn+1 ∈ Cα(Xn+1)) ≥ 1 − α. Initially, most of the conformal methods focused on estimating a mean regression function for Y | X, to then construct a fixed-width band around it; see [39, 40]. However, as pointed out by [21], this marginal guarantee can hide significant discrepancies in the coverage of different regions of the input space Rd. In particular, certain regions may be over-covered while others are under-covered. To solve this problem, it is necessary to construct adaptive prediction sets. Conditional conformal predictionarXiv:2407.01794v1 [stat.ML] 1 Jul 2024 methods allow the generation of confidence intervals that adapt to the test point under consideration Xn+1. For example, if a patient has certain characteristics, the goal is to guarantee that their treatment will be successful with a confidence of 1 − α. Therefore, we want to adapt the guarantees to the profile of the individual instead of giving guarantees that only apply to the population as a whole. In particular, for any point x ∈ Rd, the set Cα(x) is described as conditional valid if P (Yn+1 ∈ Cα(Xn+1) | Xn+1 = x) ≥ 1 − α. Although conditional validity is a more desirable guarantee than marginal validity, it is difficult to achieve in practice without further assumptions about the data distribution. Indeed, it has been shown to be incompatible with the distribution-free setting [38, 25]. For practical purposes, however, an approximate conditional validity may be sufficient. In regions with high heteroskedasticity, additional flexibility in the construction of prediction sets is useful. Methods based on quantile regression approaches were investigated in [30, 22]. These algorithms estimate the lower and upper conditional quantile regression functions ˆqα/2 and ˆq1−α/2; see e.g. [23, 2]. In [30], conditional confidence sets for Yn+1 | Xn+1 are constructed on the basis of the conformity assessment, which is determined by V (x, y) = max {ˆqα/2(x) − y, y − ˆq1−α/2(x)} . Then, denoting by µ = 1 n ∑n k=1 δV (Xk,Yk); the prediction set is defined as Cα(x) = [ˆqα/2(X) − Q(1−α)(1+n−1)(µ), ˆq1−α/2(X) + Q(1−α)(1+n−1)(µ)] , where Q(1−α)(1+n−1)(µ) is the (1 − α)(1 + n−1) quantile of the distribution of µ. Possible im- provements of this conformity score are also investigated in [22, 34]. In particular, [34] has shown that the constructed interval converges to the narrowest possible bands that achieve conditional coverage under mild assumptions. However, when the conditional distribution of the response has widely separated high-density regions, the ideal prediction set is not necessarily an interval. In such cases, a conformal method should be able to generate disjoint regions instead of being restricted to intervals; see Figure 1 for a simple illustration and [41] for a discussion and examples. Training data Prediction set Figure 1: Bimodal example. This paper is concerned with improving the construc- tion of prediction sets, especially when an estimate of the conditional distribution PY |X is available. The approach we propose utilizes the flexibility of con- formal prediction methods to generate confidence sets that better capture the structure of the predictive distribution. This leads to improved conditional cov- erage and efficiency, especially in situations with high heteroskedasticity where the width of the confidence interval can vary significantly between regions. In order to achieve this, we pursue the fundamental question of how conditionally valid prediction sets can be derived. There are many, mostly negative, results on conditional validity, which can only be achieved under strong assumptions on the joint distribution of (X, Y ), which often fail to be satisfied [13]. One possible solution is to divide the space Rd into several regions and learn a specific quantile for each of these regions [15, 16, 1]. However, this approach has significant drawbacks, especially since splitting the space Rd into multiple regions for a given calibration set typically leads to an increase in the length of the prediction set [29, 27]. As shown in [3, 28], the conditional coverage follows a beta distribution. The error deviation is therefore of the order of 1/√nx, where nx is the number of calibration data contained in the bin associated with x. Thus, an accuracy of 0.01 would require almost 104 data points in each bin, which limits the feasibility of binning methods. Our proposed method aims to overcome these limitations and provide a more feasible and efficient solution for marginally valid prediction sets equipped with some conditional guarantees. In particular, our work addresses these challenges through the following main contributions: • We propose a new method for constructing conditional confidence intervals that adapts to the local structure of the data distribution and allows the generation of confidence intervals that are more informative; see Section 2. 2 • We develop a theoretical framework to analyze the properties of the proposed method, establishing its approximate conditional validity; see Section 3. • We demonstrate the effectiveness of the proposed method through a series of experiments on synthetic and real-world datasets; see Section 4. The results show that it outperforms existing methods in terms of conditional coverage. 2 Conditionally valid Probabilistic Conformal Prediction Figure 2: Schematic representation of CP 2. Problem Setup and Sketch of the Method. Suppose we are given n samples {(Xk, Yk)} n k=1 and we must now predict the unknown value of Yn+1 at a test point Xn+1. We assume that all samples {(Xk, Yk)} n+1 k=1 are i.i.d. from an arbi- trary joint distribution PX,Y over the feature vec- tors X ∈ Rd and response variables Y ∈ Y. The target set Y can be either finite or continuous. Our goal is to construct a prediction set Cα(Xn+1) that contains the unobserved output Yn+1 with probability close to 1 − α, where α ∈ (0, 1) is the user-specified confidence level. We aim to develop a flexible plug-and-play method that combines existing conformal meth- ods with conditional distribution estimation PY |X . We want to construct marginally valid predictive sets with approximate conditional validity. There are three main ingredients for our approach: 1. We specify a family of confidence sets R(x; t) parameterized by t ∈ R. For instance, t can be chosen as the radius of a ball centered around an estimate of conditional mean PY |X . 2. We split the available data into the training and calibration ones. An estimator ΠY |X of the conditional probability PY |X is learnt using the training data; see Remark 2.2. Given x ∈ Rd, if ΠY |X=x closely approximates the true conditional probability PY |X=x, then for any τx ∈ R such that ΠY |X=x(R(x; τx)) ≥ 1 − α, it follows that R(x; τx) is an approximately valid prediction set; see Theorem 3.2 for more details. 3. We introduce λx,y = inf {t ∈ R : y ∈ R(x; t)}, which can be considered as a conformity score for the input x and the observation y. On the calibration dataset, we determine τx using the model ΠY |X ; see details later in (3). We also introduce an increasing function fτ (λ) parameterized by τ > 0. An example of such a function is fτ (λ) = τ λ. We then calculate the empirical measure µ of the transformed conformity values f −1 τXk (λXk,Yk ). Finally, we determine the quantile Q1−α(µ) and construct the prediction set as follows Cα(Xn+1) = R (Xn+1; fτXn+1 (Q1−α(µ) )) , (1) which achieves marginal validity P (Yn+1 ∈ Cα(Xn+1)) ≥ 1 − α, see Theorem 3.1. Remark 2.1. Conformal prediction methods are based on a conformity score V (x, y), which evaluates how well the model prediction matches y. Given V , one can construct a family of confidence intervals R(x, t) = {y ∈ Y : V (x, y) ≤ t}. With this definition, λx,y = V (x, y); therefore, λx,y plays the role of conformity measure. In (1), if we take fτ (λ) = λ, the standard conformal method is used. On the other hand, if we set fτ (λ) = τ , then the confidence set is completely determined by the conditional generative model (we trust our conditional distribution but lose conformal guarantees). Taking fτn+1(Q1−α(µ)) provides a compromise between the “simple” conformal method Q1−α(µ) and the confidence set derived from the conditional distribution, expressed by τx. In this context, ˜V (x, y) = f −1 τx (λx,y) can be viewed as an “adjusted” conformity measure. Consequently, (1) represents the conformal prediction set derived from the conformity score function ˜V . This relationship directly establishes the finite sample marginal validity. 3 Remark 2.2. If the predictive distribution has multiple modes, a single interval centered around the predictive mean often fails to provide an informative prediction set. Ideally, R(x; t) should correspond to the intervals with the highest probability density (HPD) of PY |X ; HPD regions are difficult to determine in practice, even when the conditional predictive density is available. [41] proposes a way to approximate HPD domains by using implicit conditional generative models. In this case, the prediction sets Rz(x; t) can depend on an exogenous variables z ∈ Z, such as a union of balls with radius t centered at points sampled from ΠY |X . 2.1 The CP 2 framework We will now present our method for constructing adaptive prediction sets defined in (1). These sets are based on confidence set Rz(x; t) satisfying the following assumption. H 1. For all (x, z) ∈ Rd × Z, the confidence sets {Rz(x; t)}t∈R are non-decreasing, and ∩t∈RRz(x; t) = ∅, ∪t∈RRz(x; t) = Y, ∩t′>tRz(x; t′) = Rz(x; t). In simpler terms, the size of Rz(x; t) grows with t. If we select a large enough value for t, we can cover the entire output space Y. Let’s introduce the parameter λx,y,z which corresponds to the minimal radius needed to guarantee that the confidence set contains the output value y λx,y,z = inf {t ∈ R : y ∈ Rz(x; t)} . (2) Lemma 2.3. Assume H1 holds. For any (x, y, z) ∈ Rd × Y × Z, λx,y,z ∈ (−∞, +∞) and y ∈ Rz(x; λx,y,z). Our method relies on a family of transformations, denoted as {λ ↦→ fτ (λ)}τ ∈R, which balance the following two factors: • The optimal parameter λx,y,z that ensures y is included in the confidence set Rz(x; λx,y,z). • The parameter τx,z obtained from the probabilistic model ΠY |X=x. H2. There exists φ ∈ R such that τ ∈ R ↦→ fτ (φ) is increasing and bijective. Additionally, the function λ ∈ R ∪ {∞} ↦→ fτx,z (λ) is increasing for any x ∈ Rd, z ∈ Z, where τx,z is defined in (3). Given the significance level α ∈ [0, 1], consider τx,z = inf { τ ∈ R : ΠY |X=x(Rz(x; fτ (φ))) ≥ 1 − α} (3) where by convention, we set inf ∅ = −∞. Lemma 2.4. Assume H1-H2 hold, and let α ∈ (0, 1), x ∈ Rd, z ∈ Z. If ΠY |X=x is a probability measure, then τx,z ∈ (−∞, ∞) and ΠY |X=x(Rz(x; fτx,z (φ))) ≥ 1 − α. In words, τx,z ensures that the confidence set Rz(x; fτx,z (φ)) is approximately conditionally valid when the distribution of Y given X = x is well approximated by the probabilistic model ΠY |X=x. For notational simplicity, set ¯τk := τXk,Zk and ¯λk := λXk,Yk,Zk . Given Xn+1 ∈ Rd, we sample Zn+1 ∼ ΠZ|X=Xn+1 and construct the resulting CP 2 prediction set as Cα(Xn+1) = RZn+1 (Xn+1; f¯τn+1(Q1−α(µ))) , (4) where Q1−α(µ) is the 1 − α quantile of the distribution µ is given by µ = 1 n + 1 ∑n k=1 δf −1 ¯τk (¯λk) + 1 n + 1 δ∞. (5) Now, let’s explore two examples of the CP 2 framework. 4 2.2 CP 2 with Explicit Conditional Generative Model: CP 2-HPD We illustrate a specific instance of our framework, called CP 2-HPD. We suggest using this approach when an approximate of the density function is known, denoted by γY |X=x. The confidence set is defined as R(x; t) = {y ∈ Y : γY |X=x(y) ≥ t}. We omit the variable z from the notation, as we do not consider exogenous randomization in this case. The parameter τx is obtained by solving ΠY |X=x(R(x; fτ (φ))) = 1 − α. We then compute λx,y = γY |X=x(y) and derive the prediction set as Cα(x) = {y ∈ Y : γY |X=x(y) ≥ fτx (Q1−α (µ))} . If we take fτ (λ) = λ and φ = 1, the method shares similarity with the CD-split method, proposed in [20]. While CD-split uses λx,y = γY |X=x(y) as the conformity score, our method uses f −1 τx (λx,y), which incorporates the information from τx to modify γY |X=x(y). Additionally, CP 2-HPD does not rely on binning, unlike the CD-split approach. 2.3 CP 2 with Implicit Conditional Generative Model: CP 2-PCP We also develop a second instance of the CP 2 algorithm, which is inspired by [41]. Unlike CP 2-HPD, this approach does not require the conditional density. Instead, it is designed for cases where the conditional generative model (CGM) ΠY |X is implicit, meaning we cannot evaluate it pointwise while being able to sample from it. For each calibration point Xk, we draw M random variables { ˆYk,i} M i=1 from ΠY |X=Xk . We denote Zk = ( ˆYk,1, · · · , ˆYk,M ) and consider the confidence sets as the union of spheres centered around the sample points: RZk (Xk; t) = ∪ M i=1B( ˆYk,i, t). With such choice, we get ¯λk = min M i=1 ∥Yk − ˆYk,i∥. We then draw a second sample { ˜Yk,j} ˜M j=1, and compute ¯τk = {τ ∈ R+ : ∑ ˜M j=1 1 ˜Yk,j ∈RZk (Xk;fτ (φ)) ≥ 1 − α}. It can be verified that ¯τk = (τ ↦→ fτ (φ))−1 { Q1−α ( 1 ˜M ∑ ˜M j=1 δminM i=1 ∥ ˜Yj,k− ˆYk,i∥)} . Given a new input Xn+1 ∈ Rd, we sample Zn+1 = ( ˆYn+1,1, . . . , ˆYn+1,M ) and obtain prediction set as follows Cα(Xn+1) = { y ∈ Y : min M i=1 ∥y − ˆYn+1,i∥ ≤ f¯τn+1 (Q1−α (µ))} , where µ is given in (5). The CP2-PCP method employs the same confidence set Rz(x; t) as the one used by PCP. This method effectively captures multimodalities using balls centered at likely outputs ˆYn+1,i. Furthermore, the conformity scores used by PCP correspond to our λx,y,z. However, the key distinction between the two algorithms lies in the additional parameter τx,z for CP 2-PCP, which requires the generation of a second random sample from ΠY |X=x. 2.4 Asymptotic Validity of CP 2 To gain insights, we informally discuss the asymptotic conditional validity of CP 2. We assume for simplicity that PY |X = ΠY |X , i.e., the predictive distribution is known. If H1 and H2 hold, then Lemma 2.3 shows that P (λX,Y,Z ≤ fτX,Z (t) | X = x, Z = z) = P (Y ∈ Rz(x; fτx,z (t)) | X = x, Z = z) = ΠY |X=x (Rz(x; fτx,z (t)) ) . Note that ΠY |X=x(Rz(x; fτx,z (t))) ≥ 1 − α if and only if t ≥ φ, which implies that P(f −1 τx,z (λx,Y,z) ≤ t | X = x, Z = z) ≥ 1 − α if and only if t ≥ φ. (6) From (6) we deduce that the (1 − α)-quantile of f −1 τX,Z (λX,Y,Z) is φ. The Glivenko–Cantelli Theorem [37, Theorem 19.1] demonstrates that supt∈R |µ(−∞, t] − P(f −1 τX,Z (λX,Y,Z) ≤ t)| → 0 5 Y|X = Xk Yk Zk(Xk; k) Zk(Xk; f k( )) Y|X = Xk Zk(Xk; k) Zk(Xk; f k( )) Yk Figure 3: Examples of ¯τk and ¯λk for two different scenarios. In both cases, ¯τk is selected such that the probability of the corresponding confidence set RZk (Xk; f¯τk (φ)) under the distribution ΠY |X=Xk is equal to 1 − α. On the other hand, ¯λk is chosen as the smallest real number such that the true label Yk belongs to the confidence set RZk (Xk; ¯λk). Table 1: Confidence sets R(x; t) found in the literature and also discussed in [18, Table 1]. [24] [24] [22] [pred(x) − t, pred(x) + t] [pred(x) − tσ(x), pred(x) + tσ(x)] (1 + t)[qα/2(x), q1−α/2(x)] − tq1/2(x) [9] [30] [34] [qt(x), q1−t(x)] [qα/2(x) − t, q1−α/2(x) + t] [qα/2(x), q1−α/2(x)] ± t(q1−α/2(x) − qα/2(x)) almost surely as n → ∞, where µ is defined in (5). Applying [37, Lemma 21.2], under weak conditions we deduce that Q1−α(µ) → φ as n → ∞. If the quantile Q1−α(µ) is greater than φ, it indicates that there are insufficient calibration data points Yk ∈ RZk (Xk; f¯τk (φ)). Conversely, if Q1−α(µ) is less than φ, it means that an excessive percentage of calibration data falls within the confidence set RZk (Xk; f¯τk (φ)). In this situation, the radius of the confidence set is increased to ensure the correct proportion of observations Yk covered. 2.5 Related Work Approximating the conditional distribution of Y | X to construct prediction sets has been exten- sively studied. Methods based on density estimation, such as [6, 25], achieve asymptotic validity under appropriate conditions. [19] uses kernel density estimation to construct asymmetric prediction bands. However, this method cannot handle bimodality as it generates a single interval. On the other hand, [35] partitions the domain of Y into bins to create a histogram approximation of PY |X . The authors showed that their method satisfies the marginal validity while achieving the asymptotic conditional coverage. This property has also been derived in the context of regression [24]. Asymp- totic conditional coverage is also obtained in [34, 8] using quantile regression-based methods, or using cumulative distribution function estimators [20, 9]. Conditionally valid prediction sets have been shown to improve the robustness to perturbations [14]. [41] introduced a method adapted to distributions with separated high-density regions and with implicit CGM. Recently, [17] converted regression problems into classification problems by binning the range space and discretizing the labels. They learn an approximation of the conditional density to generate prediction sets that match the HPD regions. Similarly, [12] proposed a method that estimates the conditional density using neural network parameterized splines. The concept of nested sets was investigated in the work of [18]. Additionally, [32] proposed an approach leading to a confidence set R(x; τ ) = [ˆqlo(x, τ ), ˆqhi(x, τ )], where ˆqlo(x, τ ) and ˆqhi(x, τ ) are quantile regressors for the conditional distribution Y | X. Moreover, τ is set such that at least 100(1 − α)% of the calibration data fall within the prediction set. 6 3 Theoretical guarantees In this section, we provide both marginal and conditional guarantees for the prediction set Cα(x) given in (4). The validity of these guarantees is ensured by the exchangeability of the calibration data, with the exception of Corollary 3.3 which relies on a concentration inequality and thus requires that the calibration data are i.i.d. The following theorem establishes marginal validity of the predictive set defined by CP 2. Theorem 3.1. Assume H1-H2. Then, for any α ∈ (0, 1), it holds 1 − α ≤ P (Yn+1 ∈ Cα(Xn+1)) . Moreover, if the conformity scores {f −1 ¯τk (¯λk)}n+1 k=1 are almost surely distinct, then it also holds that P (Yn+1 ∈ Cα(Xn+1)) < 1 − α + 1 n + 1 . The proof is postponed to Appendix A.1. Moreover, the upper bound on the coverage always holds when the distribution of f −1 ¯τk (¯λk) is continuous. Now, we will investigate the conditional validity of Cα(x). Denote by dTV the total variation distance. Theorem 3.2. Assume H1-H2, and let α ∈ (0, 1). For any x ∈ Rd and z ∈ Z, it holds P (Yn+1 ∈ Cα(x) | Xn+1 = x, Zn+1 = z) ≥ 1 − α − dTV(PY |X=x; ΠY |X=x) − p(x,z) n+1 , where p(x,z) n+1 = P (Q1−α(µ) < f −1 ¯τn+1(¯λn+1) ≤ φ | Xn+1 = x, Zn+1 = z). The proof is postponed to Appendix A.1. The better the estimator ΠY |X=x is, the closer the result is to 1 − α. Achieving accurate conditional coverage at x does not require knowledge of the entire conditional distribution PY |X . Instead, only a reliable approximation for the specific point x is required. dThe second term in the lower bound is p (x,z) n+1 . Its expected value is upper bounded by E[p(x,z) n+1 ] ≤ α, but analyzing this term is difficult. We address this problem in the following corollary, whose proof is postponed to Appendix A.2. Denote by F and ˆF the cumulative distribution functions of the random variables f −1 τX,Z (λX,Y,Z) and f −1 τX,Z (λX, ˆY ,Z), where (X, Y, Z) ∼ PX ⊗ PY |X ⊗ ΠZ|X and (X, ˆY , Z) ∼ PX ⊗ ΠY |X ⊗ ΠZ|X , respectively. Corollary 3.3. Assume H1-H2, and suppose the distribution of f −1 τX,Z (λX,Y,Z) is continuous. For any x ∈ Rd, z ∈ Z and ϵ ∈ [0, 1 − α), it holds that p (x,z) n+1 ≤ exp (−nΦ(ϵ)) + P (F −1(1 − α − ϵ) < f −1 ¯τn+1(¯λn+1) ≤ ˆF −1(1 − α) ∣ ∣ Xn+1 = x, Zn+1 = z) where Φ(ϵ) = ϵ[(u−1 ϵ − 1) log(1 + uϵ) − 1] and uϵ = ϵ(α + ϵ)−1(1 − α − ϵ)−1. Setting ϵ = √ 8α(1 − α)n−1 log n ensures that exp(−nΦ(ϵ)) ≤ n−1. When F −1 is continuous, F −1(1 − α) is approximately equal to F −1(1 − α − ϵ) for small ϵ. Therefore, if ˆF −1(1 − α) closely approximates F −1(1 − α), then Corollary 3.3 demonstrates that p(x,z) n+1 is always small. The prediction set, defined in (4), is derived from the (1 − α)-quantile of the conformity scores {f −1 ¯τk (¯λk)}n k=1 ∪ {∞}. However, {∞} can be removed from these conformity scores. Inspired by [30, 34], the Corollary 3.4 ensures the marginal validity of ¯Cα(x) = Rz (x; fτx,z (Q(1−α)(1+n−1)( 1 n ∑n k=1 δf −1 ¯τk (¯λk)))) . Corollary 3.4. Under the same assumptions as in Theorem 3.1, for any α ∈ [1/(n + 1), 1], we have 1 − α ≤ P (Yn+1 ∈ ¯Cα(Xn+1) ) < 1 − α + 1 n + 1 , where the upper bound only holds if the conformity scores {f −1 ¯τk (¯λk)}n+1 k=1 are almost surely distinct. The proof of Corollary 3.4 is along the same lines as [41, Corollary 1]; see Appendix A.3. 7 XY 0 10 20 30 40 50 (a) Data and MDN estimate −4 −2 0 2 4 X 0.800 0.825 0.850 0.875 0.900 0.925 0.950 0.975 1.000Conditionalcoverage CP2-HPD CQR PCP CP (b) Conditional coverage −4 −2 0 2 4 X 2 4 6 8 10 12LengthofthePredictionSet CP2-HPD CQR PCP CP (c) Length of the prediction set Figure 4: Mixture Density Network: the multimodal case. bike bio blog fb1 fb2 meps19 meps20 meps21 temp 0.75 0.80 0.85 0.90 0.95 1.00Worst-slabcoverage,1−δ=0.1CP PCP ΓY |X CP2-PCP-L CP2-PCP-D CHR CQR CQR2 Figure 5: Worst-slab coverage on real data. Results averaged over 50 random splits of each dataset. Calibration and test set sizes set to 2000, 50 conditional samples for PCP, CP2 and ΠY |X . Worst-slab coverage parameter (1 − δ) = 0.1. Nominal coverage level is (1 − α) = 0.9 and is shown in dashed black. Methods with conditional coverage below 0.75 shown as cross-hatched on horizontal axis. 4 Numerical experiments In this section, we conduct a comprehensive analysis demonstrating the advantage of CP 2 compared to standard and adaptive split conformal algorithms. Specifically, we benchmark our algorithm against two state-of-the-art methods: Conformalized Quantile Regression (CQR; [30]) and Probabilistic Conformal Prediction (PCP; [41]). We aim to answer these specific questions: how does CP 2 performs in terms of coverage, conditional coverage and predictive set volume when compared to state-of-the- art methods on synthetic and real data. 4.1 Synthetic data experiments In this example, (Xk, Yk) is sampled from a mixture of P = 4 Gaussians; see Figure 4a. The results for other classical 2-d datasets lead to similar conclusions. The number of training and calibration samples is T = 10 4 and n = 10 3, respectively. We fit a Mixture Density Network (MDN) as an explicit generative model, γY |X=x(y) = ∑P ℓ=1 πℓ(x)N (y; µℓ(x), σ2 ℓ (x)), where µℓ(·), σℓ(·) and πℓ(·) are all modeled by fully connected 2-layers neural networks (the condition ∑P ℓ=1 πℓ(x) = 1 is ensured by using softmax activation functions). We use CP2-HPD (the calculation of the HPD rates as well as τx and λx,y is explicit in this case). The parameters of the MDN are trained by maximizing the likelihood on the training set. We compare the plain CP 2-HPD, PCP (with the same MDN as CP2-HPD and M = 50 draws) and CQR. All methods achieve the desired nominal coverage 1 − α = 0.9. We illustrate the conditional coverage in Figure 4b and the lengths of the predictive sets in Figure 4c. CP 2-HPD with a fixed-width predictive set performs poorly in this multimodal example, both in terms of the size of the confidence set and the conditional coverage. CP 2-HPD and CQR perform similarly in terms of conditional coverage (which remains close to 1 − α = 0.9). The conditional coverage of PCP varies between 0.85 and 0.95. CP 2 produces shorter prediction sets compared to CQR and PCP. This is because CP2 uses an HPD confidence set that is more suitable for multimodal applications than the confidence set used by CQR. 8 bike bio blog fb1 fb2 meps19 meps20 meps21 temp 0.0 0.5 1.0 1.5 2.0 2.5wsd CP PCP ΓY |X CP2-PCP-L CP2-PCP-D CHR CQR CQR2 Figure 6: Sizes of the prediction sets on real data. We divide the size of the set by the standard deviation of response to present the results on the same scale. 4.2 Real data experiments In this section, we study the performance of CP 2-PCP on several real world regression datasets. Datasets. We use publicly available regression datasets, which are also considered in [30, 41]. Some of them come from the UCI repository: bike sharing (bike), protein structure (bio), blog feedback (blog), Facebook comments (fb1 and fb2). Other datasets come from US Department of Health surveys (meps19, meps20 and meps21), and from weather forecasts (temp) [10]. Methods. We compare the proposed CP 2-PCP method with Probabilistic Conformal Prediction (PCP; [41]), Conformalized Quantile Regression (CQR; [30]) and Conformalized Histogram Regression (CHR; [35]). We also consider CQR2 which is a modification of CQR that uses inverse quantile nonconformity score. For our method and PCP we use a Mixture Density Network [4] to estimate the conditional distribution PY |X , since it was chosen in [41] as best-performing. We also consider different choices of fτ for our method: CP 2-PCP-L stands for CP 2-PCP with fτ (λ) = λτ and CP 2-PCP-D stands for CP 2-PCP with fτ (λ) = λ + τ . Our implementation of CP 2-PCP is summarized in Algorithms 1 and 2. They use Brent’s method to find the optimal τx; see (3). Additionally, we consider ΠY |X which is a special case of CP 2-PCP with fτ (λ) = τ . Metrics. Empirical coverage (marginal and conditional) is the main quantity of interest for pre- diction sets. We evaluate worst-slab conditional coverage [8, 31] in our experiments, see details in Appendix B.3. We also measure the total size of the predicted sets, scaled by the standard deviation of the response Y . Experimental setup. Our experimental setup closely follows [41]. We split each dataset into train, calibration and test portions and train a Mixture Density Network with 10 components to approximate PY |X . For each calibration and test point we first obtain the Gaussian Mixture parameters (this becomes ΠY |X ) and then sample M = 5, 20, 50 samples from these distributions (gives us Rz(x, τ )). We replicate this experiment on 50 different splits of each dataset. Results of the experiments for M = 50 samples are presented in Figures 5 and 6, additional results are available in Appendix B. In terms of marginal coverage, all methods achieve the target 1 − α value, except for ΠY |X . Standard conformal prediction fails to maintain the conditional coverage as expected. We can also observe that PCP consistently struggles with conditional coverage. On all the datasets CP 2-PCP provides valid conditional coverage, while CQR fails on blog and temp. CHR method shows unstable performance not achieving conditional coverage more often than other methods but sometimes providing narrower predictions sets. Additionally, CP 2-PCP significantly outperforms quantile regression-based methods in terms of size of the prediction sets on bike, bio and temp datasets. Additionally, we assess conditional coverage with the help of clustering. We apply HDBSCAN [7, 26] method to cluster the test set and then compute coverage within clusters. Results for fb1 dataset are presented in Figure 7. We again observe that CP and PCP do not achieve conditional coverage and CHR and CQR performance is unstable. CP 2-PCP on the other hand maintains valid conditional coverage on all clusters and even on outliers (cluster label -1). Not that these are all outliers combined and they may not lie in the same region of the input space. 9 -1 0 1 2 Cluster 0.75 0.80 0.85 0.90 0.95 1.00Coverage CP PCP ΓY |X CP2-PCP-L CP2-PCP-D CHR CQR CQR2 Figure 7: Conditional coverage for different clusters, fb1 dataset. We have used HDBSCAN algorithm with minimum cluster size of 100, min_samples hyper-parameter of 20 and l2 metric. Cluster label -1 corresponds to the outliers. Sample size for sampling-based methods was set to 50. Nominal coverage equals (1 − α) = 0.9 and is shown in dashed blacks. 5 Conclusion We address the challenge of conditional coverage in conformal predictions, and overcome previous negative results by assuming the knowledge of a good estimator of PY |X . We develop a general framework for constructing prediction sets, which encompasses many existing conformal methods and refine their confidence sets using a probabilistic estimator of Y | X. Our key contributions include theoretical studies of the conditional validity, holding significant implications for the development of future methods. Acknowledgments and Disclosure of Funding Part of this work has been carried out under the auspice of the Lagrange Mathematics and Computing Research Center. E.M. is Funded by the European Union (ERC, Ocean, 101071601). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. References [1] A. M. Alaa, Z. Hussain, and D. Sontag. Conformalized unconditional quantile regression. In International Conference on Artificial Intelligence and Statistics, pages 10690–10702. PMLR, 2023. [2] A. Beyerlein. Quantile regression—opportunities and challenges from a user’s perspective. American journal of epidemiology, 180(3):330–331, 2014. [3] M. Bian and R. F. Barber. Training-conditional coverage for distribution-free predictive infer- ence. Electronic Journal of Statistics, 17(2):2044–2066, 2023. [4] C. M. Bishop. Mixture density networks. 1994. [5] S. Boucheron, G. Lugosi, and O. Bousquet. Concentration inequalities. In Summer school on machine learning, pages 208–240. Springer, 2003. [6] T. T. Cai, M. Low, and Z. Ma. Adaptive confidence bands for nonparametric regression functions. Journal of the American Statistical Association, 109(507):1054–1070, 2014. [7] R. J. G. B. Campello, D. Moulavi, and J. Sander. Density-based clustering based on hierarchical density estimates. In Pacific-Asia Conference on Knowledge Discovery and Data Mining, 2013. [8] M. Cauchois, S. Gupta, and J. C. Duchi. Knowing what you know: valid and validated confidence sets in multiclass and multilabel prediction. J. Mach. Learn. Res., 22:81:1–81:42, 2020. 10 [9] V. Chernozhukov, K. Wüthrich, and Y. Zhu. Distributional conformal prediction. Proceedings of the National Academy of Sciences, 118(48):e2107794118, 2021. [10] D. Cho, C. Yoo, J. Im, and D.-H. Cha. Comparative assessment of various machine learning- based bias correction methods for numerical weather prediction model forecasts of extreme air temperatures in urban areas. Earth and Space Science, 7(4):e2019EA000740, 2020. [11] N. Dewolf, B. De Baets, and W. Waegeman. Heteroskedastic conformal regression. arXiv preprint arXiv:2309.08313, 2023. [12] N. Diamant, E. Hajiramezanali, T. Biancalani, and G. Scalia. Conformalized deep splines for optimal and efficient prediction sets. In International Conference on Artificial Intelligence and Statistics, pages 1657–1665. PMLR, 2024. [13] R. Foygel Barber, E. J. Candes, A. Ramdas, and R. J. Tibshirani. The limits of distribution-free conditional predictive inference. Information and Inference: A Journal of the IMA, 10(2):455– 482, 2021. [14] A. Gendler, T.-W. Weng, L. Daniel, and Y. Romano. Adversarially robust conformal prediction. In International Conference on Learning Representations, 2021. [15] L. Guan. Conformal prediction with localization. arXiv preprint arXiv:1908.08558, 2019. [16] L. Guan. Localized conformal prediction: A generalized inference framework for conformal prediction. Biometrika, 110(1):33–50, 2023. [17] E. K. Guha, S. Natarajan, T. Möllenhoff, M. E. Khan, and E. Ndiaye. Conformal predic- tion via regression-as-classification. In The Twelfth International Conference on Learning Representations, 2024. [18] C. Gupta, A. K. Kuchibhotla, and A. Ramdas. Nested conformal prediction and quantile out-of-bag ensemble methods. Pattern Recognition, 127:108496, 2022. [19] X. Han, Z. Tang, J. Ghosh, and Q. Liu. Split localized conformal prediction. arXiv preprint arXiv:2206.13092, 2022. [20] R. Izbicki, G. Shimizu, and R. Stern. Flexible distribution-free conditional predictive bands using density estimators. In International Conference on Artificial Intelligence and Statistics, pages 3068–3077. PMLR, 2020. [21] R. Izbicki, G. Shimizu, and R. B. Stern. Cd-split and hpd-split: Efficient conformal regions in high dimensions. The Journal of Machine Learning Research, 23(1):3772–3803, 2022. [22] D. Kivaranovic, K. D. Johnson, and H. Leeb. Adaptive, distribution-free prediction intervals for deep networks. In International Conference on Artificial Intelligence and Statistics, pages 4346–4356. PMLR, 2020. [23] R. Koenker and K. F. Hallock. Quantile regression. Journal of economic perspectives, 15(4):143– 156, 2001. [24] J. Lei, M. G’Sell, A. Rinaldo, R. J. Tibshirani, and L. Wasserman. Distribution-free predictive inference for regression. Journal of the American Statistical Association, 113(523):1094–1111, 2018. [25] J. Lei and L. Wasserman. Distribution-free prediction bands for non-parametric regression. Journal of the Royal Statistical Society Series B: Statistical Methodology, 76(1):71–96, 2014. [26] L. McInnes and J. Healy. Accelerated hierarchical density based clustering. 2017 IEEE International Conference on Data Mining Workshops (ICDMW), pages 33–42, 2017. [27] P. Melki, L. Bombrun, B. Diallo, J. Dias, and J.-P. Da Costa. Group-conditional conformal prediction via quantile regression calibration for crop and weed classification. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 614–623, 2023. [28] V. Plassier, N. Kotelevskii, A. Rubashevskii, F. Noskov, M. Velikanov, A. Fishkov, S. Horvath, M. Takac, E. Moulines, and M. Panov. Efficient conformal prediction under data heterogeneity. In International Conference on Artificial Intelligence and Statistics, pages 4879–4887. PMLR, 2024. [29] Y. Romano, R. F. Barber, C. Sabatti, and E. Candès. With malice toward none: Assessing uncertainty via equalized coverage. Harvard Data Science Review, 2(2):4, 2020. 11 [30] Y. Romano, E. Patterson, and E. Candes. Conformalized quantile regression. Advances in neural information processing systems, 32, 2019. [31] Y. Romano, M. Sesia, and E. Candes. Classification with valid and adaptive coverage. Advances in Neural Information Processing Systems, 33:3581–3591, 2020. [32] R. Rossellini, R. F. Barber, and R. Willett. Integrating uncertainty awareness into conformalized quantile regression. In International Conference on Artificial Intelligence and Statistics, pages 1540–1548. PMLR, 2024. [33] J. Rothfuss, F. Ferreira, S. Walther, and M. Ulrich. Conditional density estimation with neural networks: Best practices and benchmarks. arXiv:1903.00954, 2019. [34] M. Sesia and E. J. Candès. A comparison of some conformal quantile regression methods. Stat, 9(1):e261, 2020. [35] M. Sesia and Y. Romano. Conformal prediction using conditional histograms. Advances in Neural Information Processing Systems, 34:6304–6315, 2021. [36] G. Shafer and V. Vovk. A tutorial on conformal prediction. Journal of Machine Learning Research, 9(3), 2008. [37] A. W. Van der Vaart. Asymptotic statistics, volume 3. Cambridge university press, 2000. [38] V. Vovk. Conditional validity of inductive conformal predictors. In Asian conference on machine learning, pages 475–490. PMLR, 2012. [39] V. Vovk, A. Gammerman, and C. Saunders. Machine-learning applications of algorithmic randomness. In Proceedings of the Sixteenth International Conference on Machine Learning, pages 444–453, 1999. [40] V. Vovk, A. Gammerman, and G. Shafer. Algorithmic learning in a random world, volume 29. Springer, 2005. [41] Z. Wang, R. Gao, M. Yin, M. Zhou, and D. Blei. Probabilistic conformal prediction using conditional random samples. In International Conference on Artificial Intelligence and Statistics, pages 8814–8836. PMLR, 2023. A Additional results and calculations In this section, we analyze the theoretical results of Section 3. First, let’s recall the definition of the quantile function for any distribution µ living in R. For any α ∈ (0, 1), the quantile Q1−α(µ) is defined by Q1−α(µ) = inf {t ∈ R : µ((−∞, t]) ≥ 1 − α} . Given a measure ΠY |X=x defined on σ(Y), we consider for all x ∈ Rd, z ∈ Z, the parameters τx,z and λx,y,z given by τx,z = inf { τ ∈ R : ΠY |X=x(Rz(x; fτ (φ))) ≥ 1 − α} , λx,y,z = inf {λ ∈ R : y ∈ Rz(x; λ)} , (7) where φ is chosen as in H2, and by convention we set inf ∅ = ∞. We denote by δv the Dirac measure at v ∈ R, and write ¯τk = τXk,Zk and ¯λk = λXk,Yk,Zk . In this Appendix, we study the coverage of the prediction set given ∀(x, z) ∈ R × Z by Cα(x) = Rz (x; fτx,z (Q1−α(µ) )) , where the distribution µ is defined as µ = 1 n + 1 n∑ k=1 δf −1 ¯τk (¯λk) + 1 n + 1 δ∞. The key idea behind the choice of ¯τk is to ensure that the conditional coverage of the prediction set Cα(Xk) is approximately 1 − α when the empirical distribution ΠY |X=Xk is close to PY |X=Xk . In other words, ¯τk is chosen such that the probability of the observed value Yk given Xk falling inside the prediction set Cα(Xk) is close to 1 − α. On the other hand, the parameter ¯λk is used to ensure that the prediction set RZk (Xk; ¯λk) contains the observed value Yk. Moreover, note that ¯τk only depends on the input data (Xk, Zk), while ¯λk depends on (Xk, Yk, Zk). Thus, the i.i.d. property of {(Xk, Yk, Zk) : k ∈ [n + 1]} ensures that the {(¯τk, ¯λk)} n+1 k=1 are also i.i.d. 12 A.1 Proof of Theorems 3.1 and 3.2 Lemma A.1. Assume H1 hold. For any (x, y, z) ∈ Rd × Y × Z, λx,y,z exists in R, and we have y ∈ Rz(x; λx,y,z). Proof. Let (x, y, z) ∈ Rd × Y × Z be fixed. Since ∩t∈RRz(x; t) = ∅ and ∪t∈RRz(x; t) = Y, we deduce the existence of t0 and t1 such that y /∈ Rz(x; t0) and y ∈ Rz(x; t1). Therefore, {t ∈ R : y ∈ Rz(x; t)} is non-empty and lower-bounded by t0. Thus, the infimum λx,y,z exists. Now, let’s prove that y ∈ Rz(x; λx,y,z). Since λx,y,z = inf{t ∈ R : y ∈ Rz(x; t)}, we deduce the existence of a decreasing sequence {λn}n∈N such that y ∈ Rz(x; λn) and limn→∞ λn = λx,y,z. By definition of {λn}n∈N, we have y ∈ ∩n∈NRz(x; λn). However, using H1, remark that ∩n∈NRz(x; λn) = ∩n∈N ∩t>λn Rz(x; t) = ∩t> lim n→∞ λn Rz(x; t) = ∩t>λx,y,z Rz(x; t) = Rz(x; λx,y,z). Since y ∈ ∩n∈NRz(x; λn), it implies that y ∈ Rz(x; λx,y,z). We will now present the proof for Theorem 3.1, which establishes the marginal validity of our proposed method. Theorem A.2. Assume H1-H2 hold, if {f −1 ¯τk (¯λk)}n+1 k=1 are almost surely distinct, then it follows 1 − α ≤ P (Yn+1 ∈ Cα(Xn+1)) < 1 − α + 1 n + 1 . (8) Proof. By definition, we have P (Yn+1 ∈ Cα(Xn+1)) = P (Yn+1 ∈ RZn+1 (Xn+1, f¯τn+1(Q1−α(µ)))) = P (λn+1 ≤ f¯τn+1 (Q1−α(µ)) ) . Since λ ↦→ f¯τn+1 (λ) is increasing by H2, we deduce that P (λn+1 ≤ f¯τn+1(Q1−α(µ))) = P (f −1 ¯τn+1(λn+1) ≤ Q1−α(µ) ) . Denote by Vk = f −1 ¯τk (¯λk), the exchangeability of the data {(Xk, Yk, Zk) : k ∈ [n + 1]} implies that P ( Vn+1 ≤ Q1−α ( n∑ k=1 δVk n + 1 + δ∞ n + 1 )) = P ( Vn+1 ≤ Q1−α ( n+1∑ k=1 δVk n + 1 )) = 1 n + 1 n+1∑ k=1 E [ 1Vk ≤ Q1−α ( 1 n + 1 n+1∑ k=1 δVk )] = E [ E [ 1VI ≤ Q1−α ( 1 n + 1 n+1∑ k=1 δVk ) ∣ ∣ ∣ ∣ V1, . . . , Vn+1 ]] , where I ∼ Unif (1, . . . , n + 1). Therefore, the definition of the quantile function implies the lower bound in (8). Moreover, if there are no ties between the {Vk} n+1 k=1 , then P (f −1 ¯τn+1 (λn+1) ≤ Q1−α(µ)) < 1 − α + 1 n + 1 . The following lemma provides conditions under which ΠY |X=x(Rz(x; fτx,z (φ))) ≥ 1 − α. Lemma A.3. Assume H1-H2 hold, and let α ∈ (0, 1), x ∈ Rd, z ∈ Z. If ΠY |X=x is a probability measure, then τx,z is defined in R and ΠY |X=x(Rz(x; fτx,z (φ))) ≥ 1 − α. 13 Proof. Let x ∈ Rd be such that ΠY |X=x is a probability measure, and fix z ∈ Z. Since τ ↦→ fτ (φ) is increasing and bijective by H2, we have lim τ →+∞ ΠY |X=x(Rz(x; fτ (φ))) = ΠY |X=x (∪τ ∈RRz(x; fτ (φ))) = ΠY |X=x (∪t∈RRz(x; t)) = 1. The previous equality shows the existence of τ ∈ R such that ΠY |X=x(Rz(x; fτ (φ))) ≥ 1 − α. Therefore {τ ∈ R : ΠY |X=x(Rz(x; fτ (φ))) ≥ 1 − α} is non-empty. This proves the existence of τx,z = inf{τ ∈ R : ΠY |X=x(Rz(x; fτ (φ))) ≥ 1 − α} in R ∪ {−∞}. However, τx,z > −∞, otherwise we would have 1 − α ≤ lim τ →−∞ ΠY |X=x(Rz(x; fτ (φ))) = ΠY |X=x (∩t∈RRz(x; t)) = ΠY |X=x(∅) = 0. Therefore, we deduce that τx,z ∈ R. Lastly, remark that ΠY |X=x(Rz(x; fτx,z (φ))) = ΠY |X=x(∩τ >τx,z Rz(x; fτ (φ))) = inf τ >τx,z ΠY |X=x(Rz(x; fτ (φ))) ≥ 1 − α. Now, we prove Theorem 3.2. This result guarantees that the conditional confidence intervals constructed by our method approximately satisfy the desired coverage of 1 − α. Theorem A.4. Assume H1-H2 hold, let x ∈ Rd be such that ΠY |X=x is a probability measure. For any z ∈ Z, it follows that P (Yn+1 ∈ Cα(Xn+1) | Xn+1 = x, Zn+1 = z) ≥ 1 − α − dTV(PY |X=x; ΠY |X=x) − P (Q1−α(µ) < f −1 τx,z (λx,Yn+1,z) ≤ φ | Xn+1 = x, Zn+1 = z) . Proof. First, recall that Cα(x) is given in (4), and λx,Yn+1,z is defined in (7). Applying Lemma A.1, we know that λx,Yn+1,z is defined in R, and also that Yn+1 ∈ Rz(x; λx,Yn+1,z). Hence, it holds P (Yn+1 ∈ Cα(Xn+1) | Xn+1 = x, Zn+1 = z) = P (Yn+1 ∈ Rz (x; fτx,z (Q1−α(µ))) | Xn+1 = x, Zn+1 = z) = P (λx,Yn+1,z ≤ fτx,z (Q1−α(µ)) | Xn+1 = x, Zn+1 = z) . Let’s introduce the term P(λx,Yn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) as follows: P (λx,Yn+1,z ≤ fτx,z (Q1−α(µ)) | Xn+1 = x, Zn+1 = z) = P (λx,Yn+1,z ≤ fτx,z (Q1−α(µ)) | Xn+1 = x, Zn+1 = z) ± P (λx,Yn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) . (9) Now, we will control the difference between the two terms of the previous equation. Let A and B be defined as A = P (f −1 τx,z (λx,Yn+1,z) ≤ Q1−α(µ) < φ | Xn+1 = x, Zn+1 = z) , B = P (f −1 τx,z (λx,Yn+1,z) ≤ φ ≤ Q1−α(µ) | Xn+1 = x, Zn+1 = z) . We have P (λx,Yn+1,z ≤ fτx,z (Q1−α(µ)) | Xn+1 = x, Zn+1 = z) = A + B + P (φ < f −1 τx,z (λx,Yn+1,z) ≤ Q1−α(µ) | Xn+1 = x, Zn+1 = z) , and also P (λx,Yn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) = A + B + P (Q1−α(µ) < f −1 τx,z (λx,Yn+1,z) ≤ φ | Xn+1 = x, Zn+1 = z) . 14 Therefore, the difference between the terms introduced in (9) can be rewritten as P (λx,Yn+1,z ≤ fτx,z (Q1−α(µ)) | Xn+1 = x, Zn+1 = z) − P (λx,Yn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) = P (φ < f −1 τx,z (λx,Yn+1,z) ≤ Q1−α(µ) | Xn+1 = x, Zn+1 = z) − P (Q1−α(µ) < f −1 τx,z (λx,Yn+1,z) ≤ φ | Xn+1 = x, Zn+1 = z) . (10) By definition of the total variation distance, we have P (λx,Yn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) ≥ P (λx, ˆYn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) − dTV(PY |X=x; ΠY |X=x). Moreover, Lemma A.3 implies that P (λx, ˆYn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) = P ( ˆYn+1 ∈ { y ∈ Y : λx,y,z ≤ fτx,z (φ) } | Xn+1 = x, Zn+1 = z) = P ( ˆYn+1 ∈ Rz(x; fτx,z (φ)) | Xn+1 = x, Zn+1 = z) = ΠY |X=x(Rz(x; fτx,z (φ))) ≥ 1 − α. Therefore, we deduce that P (λx,Yn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) ≥ 1 − α − dTV(PY |X=x; ΠY |X=x). Finally, combining the previous result with (9) and (10) shows that P (λx,Yn+1,z ≤ fτx,z (Q1−α(µ)) | Xn+1 = x, Zn+1 = z) ≥ 1 − α − dTV(PY |X=x; ΠY |X=x) + P (φ < f −1 τx,z (λx,Yn+1,z) ≤ Q1−α(µ) | Xn+1 = x, Zn+1 = z) − P ( Q1−α(µ) < f −1 τx,z (λx,Yn+1,z) ≤ φ | Xn+1 = x, Zn+1 = z) . A.2 Proof of Corollary 3.3 The objective of this section is to study the conditional guarantee obtained in Theorem A.4. Under some assumptions, we have demonstrated that the conditional coverage is controlled as follows: P (Yn+1 ∈ Cα(Xn+1) | Xn+1 = x, Zn+1 = z) ≥ 1 − α − dTV(PY |X=x; ΠY |X=x) − p(x,z) n+1 , p (x,z) n+1 = P (Q1−α(µ) < f −1 τx,z (λx,Yn+1,z) ≤ φ | Xn+1 = x, Zn+1 = z) , where µ = 1 n+1 ∑n k=1 δf −1 ¯τXk (¯λk) + 1 n+1 δ∞. While E[p(Xn+1,Zn+1) n+1 ] ≤ α, studying p(x,z) n+1 is chal- lenging. However, we control this term in Corollary A.5. Remark, the quantile Q1−α(µ) is an order statistic with a known distribution that rapidly converges to the true quantile q0, which is defined for any ϵ ∈ [0, 1 − α) by qϵ = inf{t ∈ R : P(f −1 τX,Z (λX,Y,Z) ≤ t) ≥ 1 − α − ϵ}. (11) Moreover, we define the cumulative density functions F : t ↦→ P(f −1 τX,Z (λX,Y,Z) ≤ t) and ˆF : t ↦→ P(f −1 τX,Z (λX, ˆY ,Z) ≤ t), where (X, Y, Z) ∼ PX ⊗PY |X ⊗ΠZ|X and (X, ˆY , Z) ∼ PX ⊗ΠY |X ⊗ΠZ|X . 15 Corollary A.5. Assume H1-H2 hold, and let x ∈ Rd be such that ΠY |X=x is a probability measure. For any ϵ ∈ [0, 1 − α), if pϵ = P(f −1 τX,Z (λX,Y,Z) < qϵ) ≤ 1 − α, then it follows that p (x,z) n+1 ≤ P (F −1(1 − α − ϵ) < f −1 τx,y (λx,Yn+1,z) ≤ ˆF −1(1 − α) | Xn+1 = x, Zn+1 = z) + exp ( −npϵ(1 − pϵ)h ( 1 − α − pϵ pϵ(1 − pϵ) )) , where h : u ↦→ (1 + u) log(1 + u) − u. Proof. Let ϵ ∈ [0, 1 − α), x ∈ Rd, and consider A = {Q1−α(µ) < qϵ} , Bx,z = { y ∈ Y : fτx,z (qϵ) < λx,y,z ≤ fτx,z (φ)} . We have P (fτx,z (Q1−α(µ)) < λx,Yn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) ≤ P (A | Xn+1 = x, Zn+1 = z) + P (Yn+1 ∈ Bx,z | Xn+1 = x, Zn+1 = z) . Now, let’s upper bound the first term of the right-hand side equation. First, remark that {Q1−α(µ) < qϵ} ⇔ { 1 n + 1 n∑ k=1 1f −1 ¯τk (¯λk)<qϵ ≥ 1 − α } . Thus, we deduce that P (A | Xn+1 = x, Zn+1 = z) ≤ P ( n∑ k=1 1f −1 ¯τk (¯λk)<qϵ ≥ (n + 1)(1 − α) ) . Recall that pϵ = P(f −1 τX,Z (λX,Y,Z) < qϵ), and also that we assume pϵ ≤ 1 − α. Therefore, the Bennett’s inequality [5, Theorem 2] implies that P (A | Xn+1 = x, Zn+1 = z) ≤ exp ( −npϵ(1 − pϵ) h ( (n + 1)(1 − α) − npϵ npϵ(1 − pϵ) )) , (12) where h : u ↦→ (1 + u) log(1 + u) − u. Moreover, define uϵ = 1 − α − pϵ pϵ(1 − pϵ) , ˜uϵ = (n + 1)(1 − α) − npϵ npϵ(1 − pϵ) . We have ˜uϵ ≤ uϵ, from the increasing property of h it follows that P (A | Xn+1 = x, Zn+1 = z) ≤ exp (−npϵ(1 − pϵ)h(uϵ)) . Furthermore, the definition of the cumulative distribution function: P (Yn+1 ∈ Bx,z | Xn+1 = x, Zn+1 = z) = P (fτx,z (qϵ) < λx,Yn+1,z ≤ fτx,z (φ) | Xn+1 = x, Zn+1 = z) . By definition of qϵ provided in (11), we have qϵ = F −1(1 − α − ϵ). Moreover, for any t ∈ (−∞, φ), we have ˆF (t) = P (f −1 τX,Z (λX, ˆY ,Z) ≤ t ) = ∫ P (f −1 τX,Z (λX, ˆY ,Z) ≤ t ∣ ∣ ∣ X = x, Z = z) ΠZ|X=x(dz) PX (dx) = ∫ P ( ˆY ∈ R (x, fτz,z (t) ) ∣ ∣ ∣ X = x, Z = z) ΠZ|X=x(dz) PX (dx). Using H2, the bijective property of τ ↦→ fτ (φ) implies the existence of ν ∈ R, such that fν(φ) = fτz,z (t). Note that, ν < τx,z otherwise it would lead to fν(φ) ≥ fτx,z (φ) > fτx,z (t). The definition of τx,z shows that P ( ˆY ∈ R (x, fν(φ)) ∣ ∣ ∣ X = x, Z = z) < 1 − α. 16 Therefore, we deduce that ˆF −1(1 − α) ≥ φ, and we can conclude that P (Yn+1 ∈ Bx,z | Xn+1 = x, Zn+1 = z) ≤ P (F −1(1 − α − ϵ) < f −1 τx,y (λx,Yn+1,z) ≤ ˆF −1(1 − α) | Xn+1 = x, Zn+1 = z) . (13) Finally, combining (12) and (13) concludes the proof. Given α ∈ (0, 1), define the threshold ϵn = √ 8α(1 − α) log n n . Lemma A.6. If the distribution of f −1 τX,Z (λX,Y,Z) is continuous, then for all ϵ ∈ [0, 1 − α), we have pϵ = P(f −1 τX,Z (λX,Y,Z) < qϵ) = 1 − α − ϵ. Moreover, if ϵn ≤ α(1−α) 8 , then it follows exp (−npϵn (1 − pϵn )h ( 1 − α − pϵn pϵn (1 − pϵn ) )) ≤ 1 n , where h : u ↦→ (1 + u) log(1 + u) − u. Proof. First, recall that qϵ is defined in (11). If the distribution of f −1 τX,Z (λX,Y,Z) is continuous, then we have 1 − α − ϵ ≤ F (qϵ) = sup δ>0 F (qϵ − δ) ≤ P (f −1 τX,Z (λX,Y,Z) < qϵ) = pϵ ≤ 1 − α − ϵ. Therefore, we deduce that pϵ = 1 − α − ϵ. Let’s denote δn = (n + 1)(1 − α) − npϵn , un = (n + 1)(1 − α) − npϵn npϵn (1 − pϵn ) . For any u ≥ 0, remark that log(1 + u) ≥ u − u 2/2. Thus, we deduce npϵn (1 − pϵn ) h (un) ≥ δn (1 + un) log(1 + un) − un un ≥ δn un(1 − un) 2 . (14) Now, let’s show that un ≤ 1/4. We have un = (n + 1)(1 − α) − npϵn npϵn (1 − pϵn ) = 1 − α npϵn (1 − pϵn ) + 1 − α − pϵn pϵn (1 − pϵn ) = 1 − α n(α + ϵn)(1 − α − ϵn) + ϵn (α + ϵn)(1 − α − ϵn) . Therefore, un ≤ 1/4 if and only if 1 − α n + ϵn ≤ (α + ϵn)(1 − α − ϵn) 4 . The function ϵ ∈ [0, 1/2 − α] ↦→ (α + ϵ)(1 − α − ϵ) is increasing. Since ϵn ≤ α(1 − α)/8 ≤ 1/2 − α, it is sufficient to prove that 1 − α n + ϵn ≤ α(1 − α) 4 . Since ϵn ≤ α(1 − α)/8, we just need to show that 1 − α n ≤ α(1 − α) 8 , i.e., 8α(1 − α) n ≤ α2(1 − α). (15) 17 Again, using the fact that ϵn ≤ α(1 − α)/8, we deduce that 8α(1 − α) n = ϵ2 n log n ≤ α2(1 − α)2 8 log n = α2(1 − α) × (1 − α) 8 log n . Since (1−α) 8 log n ≤ 1, we deduce that (15) holds. This concludes that un ≤ 1/4. Moreover, for any u ∈ [0, 0.25], we have δn u(1 − u) 2 ≥ uδn 4 . Plugging the previous line in (14) implies that exp (−npϵn (1 − pϵn ) h (un)) ≤ exp ( − [(n + 1)(1 − α) − npϵn]2 4npϵn (1 − pϵn ) ) ≤ exp ( − (1 − α + nϵn)2 4n(α + ϵn)(1 − α − ϵn) ) ≤ exp (− nϵ 2 n 4(α + ϵn)(1 − α − ϵn) ) . (16) Lastly, since ϵn ≤ α, it follows that nϵ 2 n 4(α + ϵn)(1 − α − ϵn) = 2α(1 − α) log n (α + ϵn)(1 − α − ϵn) ≥ log n. Combining the previous line with (16) completes the proof. A.3 Proof of Corollary 3.4 In this last part of Appendix A, we prove a corollary of Theorem 3.1. Its result demonstrates the marginal validity of the prediction set defined as ¯Cα(x) = Rz (x; fτx,z (Q(1−α)(1+n−1)( 1 n ∑n k=1 δf −1 ¯τk (¯λk)))) . (17) The prediction set ¯Cα(x) relies on the quantile of the distribution 1 n ∑n k=1 δf −1 ¯τk (¯λk). However, the proof reveals that this prediction set is equivalent to Cα(x). Corollary A.7. Under the same assumptions as in Theorem 3.1, for any α ∈ [1/(n + 1), 1], we have 1 − α ≤ P (Yn+1 ∈ ¯Cα(Xn+1) ) < 1 − α + 1 n + 1 , where the upper bound only holds if {f −1 ¯τk (¯λk)} n+1 k=1 are almost surely distinct. Proof. Let α ∈ R such that (n + 1)−1 ≤ α ≤ 1, and recall that µ = 1 n + 1 n∑ k=1 δf −1 ¯τk (¯λk) + 1 n + 1 δ∞. Since α ≥ (n + 1)−1, the quantile Q1−α(µ) is the kαth order statistic of V1, . . . , Vn, where Vk = f −1 ¯τk (¯λk), and kα = ⌈(1 − α)(n + 1)⌉. However, ∀β ∈ ( kα−1 n , kα n ], we have Qβ ( 1 n ∑n k=1 δVk ) = V(kα). Since Cα(Xn+1) = RZn+1(Xn+1; f¯τn+1 (V(kα))), Theorem 3.1 implies that 1 − α ≤ P (Yn+1 ∈ RZn+1 (Xn+1; f¯τn+1 (Qβ ( 1 n ∑n k=1 δVk )))) < 1 − α + 1 n + 1 . Setting β = (1 − α)(1 + n−1) in the previous inequality and using the definition of ¯Cα(Xn+1) given in (17) concludes the proof. 18 ADJUSTMENT Trivial Linear Exp Tanh Sigmoid fτ (λ) λ τ λ exp(τ λ) tan(τ λ) (1 + exp(−λτ ))−1 f −1 τ (λ) λ τ −1λ τ −1 log λ τ −1arctan λ τ −1 log((1 − λ) −1λ) Table 2: Adjustment Functions fτ and their inverses f −1 τ . B Experimental setup and results This section aims to provide a comprehensive understanding of the CP2 algorithm. We want to further explore the CP 2 approach and to better explain the key concepts. B.1 Algorithm structure and features We detail the construction of the prediction sets given by CP 2. The algorithm is divided into two parts: the first part computes the quantile Q1−α(µ) (Algorithm 1), and the second part constructs the prediction set Cα(x) (Algorithm 2). Algorithm 1 Quantile Computation Input: dataset {(Xk, Yk)}k∈[n], significance level α, confidence set R, conditional distributions ΠY |X and ΠZ|X , function fτ . for k = 0 to n do Sample Zk ∼ ΠZ|X=Xk (¯τk, ¯λk) ← Equations (2) and (3) Compute Vk = f −1 ¯τk (¯λk) Set kα = ⌈(1 − α)(n + 1)⌉ V(kα) ← kα-th smallest value in {Vk}k∈[n] ∪ {∞} Output: V(kα). Algorithm 2 Prediction Set Computation Input: new data x, dataset {(Xk, Yk)}k∈[n], significance level α, confidence set R, conditional dis- tributions ΠY |X and ΠZ|X , function fτ . Q1−α(µ) ← Algorithm 1 Sample z ∼ ΠZ|X=x τx,z ← Equations (2) and (3) Output: Rz(x; fτx,z (Q1−α(µ))). Choice of fτ . We present examples of mappings fτ and their inverses f −1 τ in Table 2. The choice of the mapping fτ is crucial for the performance of the method, and we investigate their impact in Section 4. For instance, choosing fτ (λ) = τ λ results in conditionally valid prediction sets, as long as ΠY |X=x accurately estimates the conditional distribution PY |X=x; see Corollary 3.3. B.2 Details of the experimental setup We use the Mixture Density Network [4] implementation from CDE [33] Python package 1 as a base model for CP, PCP and CP 2. The underlying neural network contains two hidden layers of 100 neurons each and was trained for 1000 epochs for each split of the data. Number of components of the Gaussian Mixture was set to 10 for all datasets. For the CQR [30] and CHR [35] we use the original authors’ implementation 2. The underlying neural network that outputs conditional quantiles consists of two hidden layers with 64 neurons each. Training was performed for 200 epochs for batch size 250. We replicate the experiments for 50 random splits of all nine datasets. To lower noise in calculated performance metrics we reuse trained networks and samples across different top-level algorithms for each replication. 1https://github.com/freelunchtheorem/Conditional_Density_Estimation 2https://github.com/msesia/chr 19 bike bio blog fb1 fb2 meps19 meps20 meps21 temp 0.75 0.80 0.85 0.90 0.95 1.00Worst-slabcoverage,1−δ=0.4CP PCP ΓY |X CP2-PCP-L CP2-PCP-D CHR CQR CQR2 Figure 8: Worst-slab coverage on real data, (1 − δ) = 0.4. B.3 Worst-slab coverage Here we present some additional experiments related to conditional coverage achieved by different methods. We have used Worst Slab Coverage metric, which is sensitive to the set of labs considered during the search. Following [8, 31], recall that a slab is defined as Sv,a,b = {x ∈ Rp : a < vT x < b } , where v ∈ Rp and a, b ∈ R, such that a < b. Now, given the prediction set C(x) and δ ∈ [0, 1], the worst-slab coverage is defined as: WSC(C, δ) = inf v∈Rp,a<b∈R P (Y ∈ C(X)|X ∈ Sv,a,b) s.t. P(X ∈ Sv,a,b) ≥ 1 − δ. In Section 4, we presented the results obtained for (1 − δ) = 0.1. In this case, the considered slabs must contain at least 10% of the data. In Figure 8 we report results obtained for (1−δ) = 0.4. We can see that performance improves a lot compared to δ = 0.1, and most results become indistinguishable. B.4 Extended results of real data experiments Table 3 we summarize all metrics from our real-world data experiments. For conditional coverage we report worst-slab coverage with (1 − δ) = 0.1. On six out of nine datasets CP 2 method achieves the best result in conditional coverage. B.5 Other perspective on conditional coverage The worst-slab coverage metric used in the previous section is not always helpful: (1) it provides a single number for each method, and (2) the selected slab is different for each algorithm. In practice we might be interested in how sharp the coverage is along the portion of the input space spanned by the test data. To explore this, we used two approaches: dimensionality reduction and clustering. Results for clustering with HDBSCAN are presented in the main part in Figure 7, here turn to dimensionality reduction. First we apply UMAP algorithm to project data to two dimensions and then construct a heatmap plot to show coverage in each bin of the histogram. Results for meps_19 dataset are presented in Figure 9. Nominal coverage is set to (1 − α) = 0.9 and corresponds to gray part of the color scale. We can see that our method and baseline ΠY |X perform better than CP and PCP across the space. C Further discussion on the method In this section, we address the limitations of CP 2. This general framework was designed to combine the advantages of both frequentist and Bayesian methods. The CP2 method can create a broad range of methods by combining fτ and Πx alongside existing conformal techniques. 20 Table 3: Real data experiments: M. Cov. stands for marginal coverage, C. Cov. is worst-slab coverage (here (1−δ) = 0.4) and wsd is average total length of the prediction sets, scaled by standard deviation of Y . Nominal coverage level is set to (1 − α) = 0.9. For ΠY |X , PCP, CP 2-PCP we use the same underlying mixture density network model with 50 samples. CHR and CQR(2) also share the same base neural network model. We average results of 50 random data splits. For each dataset, we highlighted the algorithm achieving the closest conditional coverage. Dataset Metric CP PCP ΠY |X CP 2-PCP-L CP 2-PCP-D CHR CQR CQR2 bike M. Cov. 0.90 0.90 0.93 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.79 0.85 0.92 0.90 0.90 0.88 0.89 0.88 wsd 0.71 0.71 0.83 0.77 0.81 1.93 2.21 2.27 bio M. Cov. 0.90 0.90 0.91 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.88 0.89 0.91 0.90 0.90 0.90 0.88 0.89 wsd 2.34 1.89 1.95 1.89 1.91 1.92 2.13 2.10 blog M. Cov. 0.90 0.90 0.91 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.60 0.74 0.91 0.89 0.90 0.88 0.88 0.87 wsd 0.60 0.30 0.72 0.60 0.71 0.31 0.42 0.39 fb1 M. Cov. 0.90 0.90 0.93 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.49 0.64 0.92 0.88 0.89 0.86 0.89 0.88 wsd 0.47 0.28 0.58 0.49 0.58 0.28 0.39 0.35 fb2 M. Cov. 0.90 0.90 0.93 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.50 0.61 0.91 0.87 0.88 0.87 0.89 0.88 wsd 0.53 0.32 0.65 0.53 0.65 0.32 0.41 0.36 meps19 M. Cov. 0.90 0.90 0.89 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.54 0.78 0.89 0.90 0.90 0.90 0.89 0.89 wsd 1.05 0.73 1.02 1.06 1.04 0.76 1.09 1.17 meps20 M. Cov. 0.90 0.90 0.89 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.58 0.80 0.89 0.89 0.89 0.90 0.89 0.90 wsd 1.06 0.75 0.98 1.02 1.00 0.76 1.08 1.16 meps21 M. Cov. 0.90 0.90 0.89 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.54 0.81 0.89 0.90 0.90 0.90 0.89 0.89 wsd 1.04 0.72 0.99 1.04 1.01 0.76 1.13 1.20 temp M. Cov. 0.90 0.90 0.82 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.87 0.89 0.81 0.89 0.88 0.87 0.86 0.87 wsd 0.87 0.92 0.78 0.94 0.93 1.32 1.48 1.30 However, it is important to recognize that our method has its own challenges. Specifically, it relies on an estimator for the conditional distribution PY |X , which may be difficult to obtain in certain real-world situations. Additionally, our approach might not be compatible with all conformal methods, like with binning procedures. Our theoretical analysis of the conditional validity illustrates the benefit of more adaptive strategies. These findings may prove helpful to improve the empirical performance of conformal prediction in various problems. We are excited about the potential of our work to contribute to the development of new uncertainty management techniques. Specifically, when it comes to refining confidence regions obtained via Bayesian methods. In summary, our results showcase the promise of CP 2 in improving the reliability of machine learning models. We hope that our research will motivate further progress in this field and inspire researchers to explore the vast possibilities of this approach. 21 Data CP PCP ΓY |X CP2-PCP-L CHR CQR CQR2 CP2-PCP-D 0.0 0.2 0.4 0.6 0.8 1.0Conditionalcoverage Figure 9: Conditional coverage after dimensionality reduction, meps_21 dataset. Data projected to two dimensions using UMAP algorithm with Canberra metric, with the n_neighbors hyperparameter set to 2. Nominal coverage is set to (1 − α) = 0.1, it corresponds to gray on the color scale. 22 Table 4: Summary results of experiments on real data: New version. M. Cov. stands for marginal coverage, C. Cov. is worst-slab coverage (here (1 − δ) = 0.1) and wsd is average total length of the prediction sets, scaled by standard deviation of Y . Nominal coverage level is set to (1 − α) = 0.9. For ΠY |X , PCP, CP 2-PCP we use the same underlying mixture density network model with 50 samples. CHR and CQR(2) also share the same base neural network model. We average results of 50 random data splits. For each dataset, we highlighted the algorithm achieving the closest conditional coverage. CP 2 Dataset Metric ΠY |X HYB-D HYB-L PCP-D PCP-L CHR CP CQR CQR2 PCP bike M. Cov. 0.93 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.92 0.90 0.90 0.89 0.89 0.88 0.79 0.90 0.87 0.85 wsd 0.83 0.81 0.77 0.80 0.79 1.94 0.71 2.25 2.31 0.71 bio M. Cov. 0.91 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.91 0.90 0.90 0.90 0.90 0.90 0.88 0.89 0.89 0.89 wsd 1.95 1.91 1.89 1.95 1.97 1.92 2.34 2.13 2.10 1.89 blog M. Cov. 0.91 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.91 0.90 0.89 0.90 0.89 0.87 0.60 0.87 0.86 0.74 wsd 0.72 0.71 0.60 0.71 0.72 0.31 0.60 0.44 0.39 0.30 fb1 M. Cov. 0.93 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.92 0.89 0.88 0.89 0.88 0.87 0.49 0.90 0.87 0.64 wsd 0.58 0.58 0.49 0.59 0.56 0.26 0.47 0.37 0.33 0.28 fb2 M. Cov. 0.93 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.91 0.88 0.87 0.88 0.88 0.88 0.50 0.89 0.89 0.61 wsd 0.65 0.65 0.53 0.65 0.62 0.33 0.53 0.43 0.37 0.32 meps19 M. Cov. 0.89 0.90 0.90 0.90 0.90 0.90 0.90 0.89 0.90 0.90 C. Cov. 0.89 0.90 0.90 0.89 0.90 0.90 0.54 0.88 0.89 0.78 wsd 1.02 1.04 1.06 1.07 1.19 0.76 1.05 1.14 1.19 0.73 meps20 M. Cov. 0.89 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.89 0.89 0.89 0.90 0.90 0.91 0.58 0.88 0.89 0.80 wsd 0.98 1.00 1.02 1.04 1.15 0.77 1.06 1.09 1.17 0.75 meps21 M. Cov. 0.89 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.89 0.90 0.90 0.89 0.89 0.90 0.54 0.89 0.88 0.81 wsd 0.99 1.01 1.04 1.04 1.16 0.79 1.04 1.13 1.21 0.72 temp M. Cov. 0.82 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 0.90 C. Cov. 0.81 0.88 0.89 0.89 0.88 0.86 0.87 0.85 0.86 0.89 wsd 0.78 0.93 0.94 0.93 0.96 1.31 0.87 1.48 1.30 0.92 23","libVersion":"0.3.2","langs":""}