{"path":"lit/lit_notes_OLD_PARTIAL/Berghout23battSOHcollabNN.pdf","text":"Lithium-ion Battery State of Health Prediction with a Robust Collaborative Augmented Hidden Layer Feedforward Neural Network Approach Tarek Berghout, Mohamed Benbouzid, Fellow, IEEE, Yassine Amirat, IEEE Senior Member, and Gang Yao Abstract—Lithium-ion (Li-ion) batteries play an important role in providing necessary energy when acting as a main or backup source of electricity. Indeed, the unavailability of battery aging discharge data in most real-world applications makes the State of Health (SoH) assessment very challenging. Alternatively, accelerated aging is therefore adopted to emulate the degradation process and to achieve an SoH estimate. However, accelerated aging generates limited deterioration patterns suffering from a higher level of complexity due to the non-linearity and non-stationarity imposed by harsh conditions. In this context, this paper aims to provide a predictive model capable of solving incomplete data problems by providing two main solutions for each of the problems of complexity and missing patterns, respectively. First, to overcome the problem of lack of patterns, a robust collaborative feature extractor (RCFE) is designed by collaborating between a set of improved restricted Boltzmann machines (I-RBMs) to be able to share learning knowledge among different locally trained I-RBMs to create a more generalized global extraction model. Second, a set of RCFEs is then evolved through a neural network with an augmented hidden layer (NAHL) to enhance the predictive ability by further exploring representation learning to overcome pattern complexity issues. The designed RCFE-NAHL is trained to predict SoH using constant current (CC) discharge characteristics by implying multiple characteristics recorded through the constant voltage (CV) charging process as indicators of health. The proposed SoH prediction approach performances are evaluated on a set of battery life cycles from the well-known NASA database. In this context, the achieved results clearly highlight the higher accuracy and robustness of the proposed learning model. Index Terms—Accelerated aging; collaborative training; Lithium batteries; NAHL; neural networks; remaining useful life; restricted Boltzmann machine; state of health. I. INTRODCUTION The eco-friendly and energy storage features of Li-ion batteries make them the leading power source storage systems for renewables [1]. Li-ion batteries cover a wide range of applications in many fields, including mobile devices, electric vehicles, aerospace, etc. [2]. In this context, it is mandatory to design an accurate SoH monitoring system to ensure healthy and efficient operation and ensure the replacement of aged batteries at the appropriate time by avoiding or minimizing system shutdowns [3]. Tarek Berghout is with the University of Batna 2, Laboratory of Automation and Manufacturing Engineering, 05000 Batna, Algeria (e-mail: t.berghout@univ-batna2.dz). Mohamed Benbouzid is with the University of Brest, UMR CNRS 6027 IRDL, 29238 Brest, France (email: Mohamed.Benbouzid@univ-brest.fr). He is also with Shanghai Maritime University, Shanghai, 201306 China. Yassine Amirat is with ISEN Yncréa Ouest, L@bISEN, 29200 Brest, France (email: yassine.amirat@isen-ouest.yncrea.fr). Gang Yao is with the Shanghai Maritime University, Shanghai, 201306 China (e-mail: gangyao@shmtu.edu.cn.) In such a situation, the SoH indicates the level of battery aging and also reflects the total amount of usable capacity reduction and resistance increment [4]. To achieve this goal, it is important to construct a digital twin from real batteries behavior so that any deviations from the standard operating conditions can be observed [5]. There are two main approaches to obtain modeling of Li-ion battery health degradation, namely, model-based and data-driven methods [6], [7]. Model-based approaches entail modeling of battery aging through either electrical equivalent circuit network models, mathematical models, or electrochemical models [8]. A model-based approach is an authentic way to design reliable monitoring as it is based on system knowledge. However, it is difficult to derive these models accurately due to the complexity of modeling as aging and other performance degradation phenomena are still not enough understood [9]. A popular widely studied alternative to model-based approaches is data-driven methods where machine learning (ML) dominates [10], [11]. One of the main advantages of ML models is that they do not require any prior knowledge of batteries in terms of electrochemical reactions. In fact, a well- executed degradation model built upon external analysis will suffice to estimate the SoH under different conditions. In this context, two main ML categories can be distinguished, namely, small-scale ML (SML) and deep learning (DL). This classification is tightly related to data complexity where more complex prediction generally requires DL models. According to recorded data of charging and discharging cycles conditions such as ambient temperature, load current and voltage, charging current and voltage, besides the physical characteristics of the battery itself, data complexity can be primarily assessed and model categories will therefore be appropriately selected. In our study, degradation process modeling focuses on the study of accelerated aging where battery life cycles are subject to lack of both degradation patterns and labels. In this context, some important recent works using the well-known NASA battery dataset have been reviewed. In this context, it was found that SML methods as linear regressing models [12], support vector machine (SVM) [13], Gaussian process regression (GPR) [1], [14], [15], extreme learning machine (ELM) [16], and artificial neural networks (ANN) [17], are receiving special attention. In the meantime, DL tools such as convolutional neural networks (CNN) [18], [19], long short term memory (LSTM) [2], [20], recurrent neural networks (RNN) [21], and deep belief neural networks (DBN) [22] are also widely investigated. Table 1 is therefore summarizing these approaches contributions and limitations. According to Table 1 and concerning SML methods, the prediction process can be considered as a feature extraction topic, where the more processed data are consistent, the better the approximation will be [1], [14], [17]. We refer to extraction as a limitation of the prediction model. Indeed, the lack of patterns in accelerated aging should be solved by generating new data examples either via domain adaptation or generative models (see Fig. 2 in [23]). Besides, adaptive, incremental learning, and dynamic adaptation of parameters are considered as available solutions for filling the gap of missing patterns [12], [13]. On the other hand, it can be noticed that DL methods do not require that much a feature extraction since the original learning philosophy of DL is already built upon learning from representation [2], [13], [18], [20], [22]. However, hyperparameters tuning in DL is still yet a problem similar to SML methods. Generally speaking, both SML and DL methods have treated the problem of SoH estimation as either a feature extraction or representation learning more than an approximation process (i.e., approximating the inputs towards targets). However, from our perspective, the problem seems related to incomplete data with missing patterns (i.e., real health deterioration time) related to the accelerated aging experiment. In such a particular situation, we have two main solutions; either we should generate new representation (e.g., using generative models) to provide additional samples or to use domain adaptation through transfer learning to gain extra information from similar deterioration behaviors. In this case, examples in [18] and [19] of Table 1 fit the current situation perfectly. In [18], the authors successfully used ensemble learning to reduce the risk of choosing poorly performing initial learning weights by combining prediction results from multiple CNNs. Besides, transfer learning is used as the main solution of domain adaptation to strengthen generalization capability and fill-in the gap resulting from missing labels. However, there is an issue regarding model architecture in this case. CNNs are known for their deep complex construction, more specifically the one presented in Fig. 3 from reference [18]. It is also worth mentioning that Li-ion batteries are well used in transportation or mobile device applications such as electric vehicles, where data may be subject to centralized/decentralized learning mechanisms or even federated learning. One of the main challenges under these criteria is maintaining model accuracy under resource allocation constraints, including communication efficiency in addition to data heterogeneity. The overall architecture will therefore be more or less complex and computationally expensive depending on the application under consideration [23]. TABLE I. ML LEARNING MODELS FOR SOH PREDICTION UNDER DEGRADATION ANALYSIS. Ref. Year Description Limits SML methods [12] 2022 ML model is an online adaptive Kalman filter used along with maximum expectation with Rauch–Tung–Striebel for SoH estimation. SoH is in this case defined as the capacity of the battery obtained by discharge. The main addressed issue is the lack of patterns and labels for a single battery life cycle. The main solution to the lack of patterns and labels is assumed to be the continuous model update through online adaptive learning. [1] 2021 The ML model is an enhanced GPR one. Instead of the conventional voltage, current, and temperature features, the energy characteristics extracted from the direct measurement is used as inputs to the ML model. SoH is defined as the ratio of instant battery capacity to the initial one. Lack of patterns is considered as a feature extraction topic. [14] 2021 ML model is the GPR one. SoH is defined the same as battery capacity. Feature extraction and fusion are done via canonical correlation analysis. Lack of patterns is considered as a feature extraction topic. [15] 2021 ML model is GPR one. SoH is defined the same as battery capacity. Noise reduction and feature selection (i.e., ﬁlter-based, rapper-based, and fusion-based methods) are the main data preprocessing steps. Lack of patterns is considered as a feature selection and extraction topic. [16] 2021 ML model is a hybrid between support vector regression (SVR) and Elman neural network (ENN). SoH is defined the same as battery capacity. Impedance spectroscopy is extracted in frequency domain and combined with features extracted from capacity in time domain. Lack of patterns is considered as a feature extraction topic. [17] 2021 ML model is an ANN trained with backpropagation algorithm. SoH is defined the same as battery capacity. Feature extraction is done via all recorded charging and discharging channels through several statistical features. Lack of patterns is considered as a feature extraction topic. [13] 2020 ML model is an incremental SVM regression model continuously tuned with quantum behavior particle swarm optimization. SoH is defined as the battery capacity. The prediction problem is considered as an online learning problem solved with random search swarm intelligence search. DL methods [2] 2021 ML model is an adaptive Levy flight optimized particle filter and LSTM network. SoH is defined same as battery capacity. Lack of patterns is considered as a representation learning scheme that can be solved via DL. [20] 2021 ML model is a hybrid LSTM one with an attention mechanism optimized by a differential evolution algorithm. SoH is defined the same as battery capacity. Lack of patterns is considered as a representation learning scheme that can be solved via DL. [22] 2021 ML model is a DBN one. SoH is defined same as capacity. Lack of patterns is considered as a representation learning scheme that can be solved via DL. [21] 2021 ML model is a nonlinear autoregressive one with external input RNN and time delay neural network. SoH is defined the same as battery capacity. Lack of patterns is considered as a representation learning scheme that can be solved via DL. [19] 2021 ML is a combination of CNN, RNN, and generative adversarial networks (GANs). SoH is defined the same as battery capacity. Lack of patterns is solved via generating new real-like samples through GANs. [18] 2019 ML model is a CNN one incorporating both transfer learning and ensemble learning. SoH is defined the same as battery capacity. CNN ensemble learning and deep architecture are extremely computationally expensive. In [19], a combination of CNN, RNN, and generative adversarial networks (GANs) is used to predict the battery SoH. CNN and RNN training rules are used to fit adaptive learning constraints imposed by changes in battery operating conditions. While GANs philosophy is used to strengthen the learning model with the self-generating capability to overcome the lack of patterns problem. An important issue related to previously discussed works is explaining the prediction results according to real-world meaning. In this context, metrics such as relative error (RE), root mean squared error (RMSE), mean squared error (MSE), and mean absolute percentage error (MAPE) have been used to assess the accuracy of the prediction models. However, when speaking about prognosis, which is the concept of an early predictive diagnosis, one may notice that something is missing about model precision. Thus, the prediction results require further explanation in addition to the model accuracy through precision analysis to provide an accurate maintenance schedule. Indeed, a maintenance program could be impacted by imperfect SoH measures, including late and early predictions [24], [25] (see also Section 3.3 of [26] for more details on the evaluation of the prognostic model). Precision analysis studies the reduction of late predictions, as they are more harmful and lead to potentially catastrophic events while late predictions are not harmful but require many maintenance resources. By accuracy, we refer to the model attempt to produce a clear representation of its performance (i.e., errors and scores) according to the prognosis criteria of understandability and reliability of SoH predictions. In other words, the model will be able to show its strengths and weaknesses and make developers aware of them. In addition, it will be able to explain how it will perform for future predictions about unseen samples. Effectively, the prediction will decide when the batteries need to be replaced. Therefore, early and late predictions can affect the decision-making process. Too early predictions will require premature battery replacement, resulting in incremental costs, while late predictions will result in system shutdown and potentially catastrophic consequences. Given this, knowledge transfer and representational learning were kept to a minimum cost. In addition, it is mandatory that the prognostic results for Li-ion batteries be more meaningful. Furthermore, it is widely known that SoH estimation suffers from the propagation of uncertainty. Unfortunately, this issue has not been properly addressed in the available literature. Therefore, quantifying the uncertainty in SoH predictions is paramount to obtaining accurate late and early predictions [27]. In light of the above, the main contributions of this paper are as follows: 1. Augmented representations: to avoid the risk of using inappropriate initial learning weights for the training model, we propose the use of the NAHL approach proposed in [28], [29]. Indeed, The NAHL architectures substitute the ensemble architecture of feedforward networks with only a single augmented layer. This reduces the training process computational cost and keeps the learning efficiency from representations. 2. Automatic training: As previously discussed, the effect of hyperparameters tuning on the model accuracy is not taken into account. Manual tuning or a search through a grid of hyperparameters will be computationally expensive and does not guarantee stacking in optimal combinations. We, therefore, propose automatic learning and hyperparameters optimization via swarm intelligence methods. 3. Collaborative training: In order to remedy the poor generalization resulting from the lack of deterioration patterns in the accelerated aging process. A set of I-RBMs is used to learn health indicators from input samples. Each I-RBM is separately trained. A collaborative model is designed by merging training results into a single RCFE for better knowledge sharing and more generalization. 4. Precision analysis: In the context of prognosis, which is mainly related to early and late predictions, we propose a scoring function to observe the behavior of early and late predictions in quantitative and distributional terms in order to explain the performance of the designed models and make them meaningful to users. 5. Uncertainty quantification: a confidence interval of the range of predicted values, in which the expected estimate falls within the confidence level interval, is used to visually quantify the prediction uncertainties. This paper is organized as follows: Section II is devoted to the SoH prediction problem, the used dataset, and its processing. Section III deals with the adopted methodology and proposed algorithms, while Section IV presents the experiments, results, and discussion. II. DATASET DESCRIPTION AND PROCESSING Cyclic accelerated aging experiment is very important to study batteries SoH attenuation trends, especially when health conditions vary over time. In this context, NASA introduced a set of recorded aging datasets from 18,650 series of Li-ion batteries [30]. In our study, batteries No. 5, 6, 7, 18, and 36 are selected to build the ML model for SoH prediction. This set of batteries was specifically chosen to achieve the best results when estimating the SoH based on a specific amount of data, in the same way that was explicitly clarified in [1]. In general, prediction errors are the result of smaller amounts of data, while large data require additional computational resources and feature engineering. Therefore, this selection is made based on some analyses performed on the effect of training data on prediction accuracy (see last paragraph of Section II of [31]). The selected batteries are repeatedly operated at a temperature of 24°C in various CC and CV charging modes and CC discharging modes. During the charging process, as illustrated by Fig. 1-a, the current is constantly set at 1.5A until the voltage reaches 4.2V as in Fig. 1-b. After that, the charging process continues with a CV until the current drops at 20mA (Fig. 1-a). The discharging processes are quite different from the charging ones. Each battery has its own different discharging current and cut-off voltage as illustrated by Figs. 1- d and 1-e, respectively. Regarding temperature curves in Figs. 1-c and 1-f, they have a specific uniform variation with respect to each aging condition. It should be noted that the aged cell has the ability to reach its maximum temperature earlier than the fresh one. Fig. 1. Charging-discharging cycle characteristics in case of fresh and aged battery cell No.18: (a, b, c) Current, voltage, and temperature cycles in case of fresh and aged cell during charging conditions; (d, e, f) Current, voltage, and temperature cycles in case of fresh and aged cell during discharging conditions; (g) Capacity variation during discharging process of selected Li-ion batteries. Fig. 2. Prepared data for the learning model reconstruction process: (a, b, c, d, e) prepared features for battery No.5, 6, 7, 18, 36; (f) Constructed SoH indicators ML model training. The reason is closely related to the repeated process of charging, resting, and discharging, respectively. As the temperature at the end of the discharge generally increases compared to that at the beginning, this affects the initial temperature of the following load profile. The capacity variation curves of these batteries are shown in Fig. 1-g. It should be mentioned that the discharging process was subjected to many disturbances leading to the existence of outliers in the recorded cycles as well as the variation in battery capacity similar to curves shown in Fig. 1-g. Therefore, for better ML model design; these outliers should be removed at the SoH identification stage to ensure that the degradation path is clearly illustrated. Since the standard deviation has a great advantage in expressing the amount of sample sparseness and variation from the mean value and to avoid the complexity of using signal processing tools, we simply extracted the value of the standard deviation from each load cycle. We only extracted the charging characteristics to accommodate the unavailability of all discharging functions in a real application. In addition to the duration of the prediction process, we used the first 80 cycles of the training process to predict the future capacity and avoid stacking into the same data unavailability problem. Under these circumstances, all the batteries first 80 cycles will be seen by the model, while each battery remaining cycles are used for testing (i.e., unseen to the model). On the other hand, for SoH identification, we calculated the ratio of instantaneous capacity to initial discharge capacity as shown by (1), where t stands for time instant and cap refers to the capacity value. Fig. 2 is then illustrating these extracted features with respect to the target SoH values. () () (0) cap t SoH t cap = (1) III. METHODOLOGY AND PROPOSED ALGORITHMS The above-prepared data (Section II) are directly fed to the proposed RCFE-NAHL for the approximation process. ib 1w2w3wlw1 2 3 l1b2b3blb1h2h3hlhy Input layer Biases vectors Temporary hidden layer Augmented hidden layer Output layer Input weight matrix Discount parameter Biases vector Output weight matrixx … … … Randomly generated biases Randomly generated weights Analytically determined weights Hyperparameters determined by search Nodes in NAHL do not refer to neurons. Nodes can refer to layers, mappings, entire networks, etc. 1 ( ) | ( ) l i i i i i i h f h h f w x b = =  = + Fig. 3. NAHL approach architecture. As shown in Fig. 2 curves, the data currently processed are subject to feature complexity appearing in recorded measurements non-linearity and non-stationarity, which makes the degradation process difficult to follow a clear trend. Moreover, as the recorded measurements were carried out under accelerated aging, the designed model should address generative and representational learning capabilities (see, Figure 2 of [26]). Accordingly, RCFE-NAHL is designed to address these challenges by providing both deep representation learning and generative modeling via NAHL and RCEF, respectively. In this context, this section is dedicated to describing the proposed algorithm. The NAHL network philosophy will be first introduced, followed by the I- RBM and RCFE-NAHL proposed approaches. A. NAHL NAHL, illustrated by Fig. 3, is a neural network developed to avoid miss-initialization of training weights in a feedforward network [28], [29]. This problem is generally solved by either retraining the neural network in a loop using several initial weights and finally selecting the best ones, or by following ensemble learning paradigms. Both methods are computationally expensive, besides, the first one could not guarantee better selection. As a solution to this problem, NAHL comes up with a very simple architecture and more accurate mapping. NAHL training rules can be summarized in only three steps. First, random linear mapping via multiple input weights wi and biases bi of the input layer x into several layers called temporary hidden layers ih . After that, these feature mappings will be subject to some sort of weighting with a discount parameters i before final summation and activation with activation function f. Finally, the result obtained from these mappings, which presents the augmented layer h will be linked to the output layer y through the only tuned and analytically determined weights . All these steps are mathematically presented in (2), (3), and (4). It is worth mentioning that the learning weights  are determined through the least square method depending on the pseudo-inverse of the matrix pinv as addressed in (5). Additionally, the discount parameters are determined through a random search particle swarm optimization algorithm (see Algorithm 1, Figs. 7, and 8 from [28] for further examples of NAHL parameters). iiih w x b= + (2) 1 () l ii i fhh =  = (3) yh=  (4) ()pinv h y= (5) B. I-RBM The RBM is the first neural network used for unsupervised learning. RBM has two neural layers, the input one called the visible layer and the mapping one called the hidden layer. Nodes in RBM receive connections from the visible and hidden layers only. Nodes from the same layer are restricted from any connection from each other [32]. In the forward pass, the visible layer is mapped to the hidden layer through weights and biases and activated with an activation function. In the backward pass, the hidden layer is mapped again to reconstruct the visible layer and measure the quality of results. These movements are known as Gibbs sampling. The reconstruction is generally done using the contrastive divergence (CD) algorithm that generally requires a lot of Gibbs sampling, neurons and iterations, which is computationally expensive [32]. In this work, we propose an I-RBM which simply adopts the use of a recursive least square (RLS) method for more accurate training with less computational complexity [33]. I-RBM learning rules can be simply summarized in a few steps. First, the learning weights wr and biases {bh,bx} for both hidden layer hr and visible one x will be randomly generated. Besides, the covariance matrix mr of the hidden layer can be initialized according to any probability distribution. After that, the learning weights will be updated thoroughly according to Sherman Morison and Woodbury (SMW) formulas given in (6)-(11), where er is the reconstruction error and pr is the gain matrix. Subscript k and superscript T indicate the Gibbs sampling index and the matrix transpose, respectively. ( )r r hh f w x b=+ (6) () T r r r xx f h w b=+ (7) ( 1)r k ke x x+ =− (8) ( 1)( 1) ( 1) ( 1) ( )k T r k r k r k r km m p h m ++ + +=+ (9) ( 1) ( 1) ( 1) ( 1) ( ) ( 1) r k k rk TT k r k r k mh p h m h ++ + ++ = (10) ( 1) ( 1) ( 1) ( 1) T r k r r k r k r kw w m h e+ + + +=+ (11) C. RCFE-NAHL RCFE-NAHL learning philosophy entails the addition of a slice of RCFEs to the NAHL architecture. As illustrated in Fig. 4, each RCFE is connected to one temporary hidden layer. An RFCE uses a set of trained I-RBMs and merges their obtained weights in a single global extraction model. Unlike NAHL, where each temporary hidden layer uses only a single weights matrix, The RCFE uses multiple weights matrices depending on the number of used I-RBMs. As previously stated, the purpose of this collaboration is to share knowledge between several training models and improve the generalization of the predictor when dealing with missing data. In this case, the same SMW mathematical formula will be used to merge the learning weights in single global mapping weights wg as illustrated in (12). Wg(1) can be obtained from the learning weights of one I-RBM. The others will be used for continuous merging. n refers to the number of used I- RBMs in each RCFE. ( 1) ( 1) ( 1) ( 1) T g n g g n g n g nw w m h e+ + + +=+ (12) IV. EXPERIMENTAL RESULTS AND DISCUSSION To test the performances of the I-RBM reconstruction capability, we compared it to basic RBM trained with the CD algorithm. The comparison process is done by initiating a loop incrementing both iteration (i.e., Gibbs sampling) and the number of neurons, which are the main important features of mapping and reconstruction. The RMSE, training, and testing times are used to measure the results quality. Data from battery No. 5 is used to assess the reconstruction process. Figure 5 summarizes obtained results of this experiment. From sub-figures (a, b, c, d), in any case of incremental learning, the I-RBM always outperforms the CD algorithm. It stabilizes early in just a few iterations. I- RBM requires from only 1 to 5 iterations or neurons in all cases to stabilize and achieve maximum extraction capability. Contrariwise, the CD algorithm does not show significant improvements in any condition, which confirms its instability and miss-reconstruction performances. In terms of computational time, CD fails to keep algorithmic simplicity while I-RBM shows great performances in both algorithmic simplicity and efficiency. 1 2 3 l1b2b3blb1h2h3hlhy Input layer Biases vectors Temporary hidden layer Augmented hidden layer Output layer Input weight matrix Discount parameter Biases vector Output weight matrix x … … … ib Randomly generated biases Different from NAHL where each node receive a single weights matrix, in RCFE-NAHL the input weights Matrices are generated for each I-RBM network. So, each RCFC has a different number of RBMs. Analytically determined weights Hyperparameters determined by search ( 1) ( ) 1 1 1g k g k k k kw w h P e+ + + +=+(1)gw (2)gw (3)gw ()glw I-RBM network Collaborative network Collaborated weight matrices Nodes in NAHL do not refer to neurons. Nodes can refer to layers, mappings, entire networks, etc. kw 1 ( ) | ( ) l i i i i i i h f h h f w x b = =  = + 1RCFE2RCFE3RCFE I-RBM m I-RBM 2 I-RBM 1 Perview of a single RCFE netwok iw Each RCFE merge the learning weights obtained from each I-RBM and create a single mapping weights matrix Fig. 4. Proposed RCFE-NAHL approach architecture. Fig. 5. I-RBM reconstruction capability performance: (a) RMSE of training process respect to number of neurons; (b) RMSE of training respect to number of iterations; (c) RMSE of testing respect to number of neurons; (d) RMSE of training respect number of iterations; (e) Training time; (f) testing time. Fig. 6. RMSE of features reconstruction experiments with local and global models: (a) Training RMSE versus number of neurons; (b) Testing RMSE versus number of neurons. The same data from battery No. 5 are used to illustrate the reason behind using collaborative training. In the example showcased in Fig. 6, two I-RBM models are locally trained in a parallel computing pool with two cores. After that, the two models are merged using (12). The comparison process was carried out by incrementing the number of neurons at each time and measuring the reconstruction RMSE during both training and testing. Results in Fig. 6-a indicate that almost nothing is changed in the training process. Training performances can be the same at this stage. However, observing the testing RMSE variation in Fig. 6-b, it can notice that the RCFE model started with less reconstruction RMSE: this means that more generalization is gained from the weights sharing process. This demonstrates the need for collaborative learning to improve the quality of feature extraction. The RCFE-NAHL is thereafter tested on the selected batteries to perform the curve fitting task on future SoH starting the prediction from the 80th cycle. The results of the curve fitting for the unseen samples (i.e., testing set) are shown in Fig. 7. Gaussian distributed measurement noise-based 99% confidence interval (CI), as in [4], is also calculated to provide insight into the uncertainties of the predictions. Accordingly, Eq. (13) will be used to determine intervals for each prediction with the help of the total prediction error variance 2 , prediction variance 2 y and Gaussian noise variance 2 g . 22.576CI y=   (13) 2 2 2 yg =  +  (14) In Fig. 7, we can observe that the RCFE-NAHL predictions are closer to the desired SoH than those of the NAHL. Specifically, there are many predictions that fall into the CI for RECFE-NAHL more than those of NAHL, especially for batteries 5, 6, and 7 that are shown by sub- figures (7a, 7b, 7c). Similarly, there are signs of stacking difficulties in the CI for batteries 18 and 36 depicted by sub- figures (7d, 7e). These uncertain predictions result from non- stationary working conditions. However, NAHL and CRFE- NAHL have generally excellent performance in fitting SoH curves for unseen samples. In this case, and as mentioned earlier in the introduction section, another metric related to precision is needed to investigate the actual meaning of the predictions. In other words, we wanted to know the difference between these models and how they behave according to prognosis criteria (i.e., early and late predictions). It is therefore proposed the use of the scoring function in (13). This equation describes a symmetric function that allows displaying the accuracy of the prediction model with respect to the prediction error. In this case, the closer the score value is to 1, the more accurate the model is. Fig. 7. Estimation process of deteriorated SoH function: (a, b, c, d, e) Curve fitting results for testing set of battery No.5, 6, 7, 18, and 36, respectively. Fig. 8. Distributions of SoH early and late predictions according to the proposed score function: (a, b, c, d, e) Score results for batteries No.5, 6, 7, 18, and 36, respectively. Conversely, the more the spare representations are, the worse the prediction is. ln(0.5).( )yyse−−= (15) Scores distribution also has a meaning that can explain whether the model is an early predictor, a late one, or somewhere in between. Figure 8 is derived using Eq. (15). In general, in all prediction cases of the five selected batteries, the RCFE-NAHL outperforms the NAHL by approaching the value 1 of the score function. This is also confirmed by the prediction error mean values and the score value. In a more specific way, sub-figures a, c, d, and e show that the RCFE- NAHL has a sort of balance in the distribution of early and late predictions, where only the case of Fig. 8-b gives evidence to the contrary (i.e., early prediction). This means that RCFE-NAHL has both accuracy and balanced prediction between early and late predictions. By contrast, sub-figures a, b, and d prove the opposite for NAHL, where, in fact, late prediction dominates, which leads to miss-prediction and harms the system in terms of maintenance (e.g. battery replacement) and can also lead to catastrophic loss of life. This also means that RCFE-NAHL is a fair predictor and not an early one that could cause large maintenance resource wastage, while a late predictor is very detrimental to the system. In order to show the performances of the proposed RCFE-NAHL learning scheme against recent and relevant earlier cited ML methods, Table 2 is provided to highlight a comparative evaluation. Similar metrics such as RMSE, MAE, and MAPE have been used. Approximation errors clearly prove the accuracy of the learning model and again confirm the appropriateness of the proposed RCFE-NAHL approach. It is worth mentioning that the investigated NAHL variants were able to achieve such results in 7.25ms during the training process while the testing time is almost negligible. Compared to a previous study that provided such training time insights [15], which reached around 10ms during training, NAHL variants have less computational complexity. TABLE 2 II NUMERICAL EVALUATION OF ALGORITHMS PERFORMANCE. Algorithm Year Prediction cycle RMSE (x100%) MAE (x100%) MAPE (x100%) Battery #5 #6 #7 #18 #36 #5 #6 #7 #18 #36 #5 #6 #7 #18 #36 RCFE-NAHL 2022 Cycle No. 80 0.41 0.50 0.43 0.46 0.34 0.31 0.41 0.33 0.37 0.27 0.41 0.62 0.41 0.48 0.40 NAHL 2022 Cycle No. 80 0.59 0.88 0.53 0.81 0.47 0.51 0.66 0.41 0.65 0.37 0.66 0.95 0.52 0.85 0.55 [34] 2022 Multiple 1.70 1.70 1.70 1.70 - 1.81 1.81 1.81 1.81 - - - - - - [12] 2022 Cross-validation 2.844 4.152 3.883 6.535 - 2.185 3.080 3.366 5.182 - - - - - - [1] 2021 Cycle No. 80 0.60 0.35 0.28 0.81 0.84 0.47 0.28 0.21 0.75 0.65 0.64 0.43 0.27 0.99 0.79 [2] 2021 Cycle No. 100 1.16 1.61 1.10 - - - - - - - 0.56 0.90 0.52 - - [17] 2021 70% training cycles 0.51 2.42 0.70 2.66 - - - - - - 0.21 0.83 0.25 0.75 - [35] 2021 70% training cycles 0.344 0.258 5.09 0.0107 - - - - - - - - - - - [20] 2021 Cycle No. 80 0.78 1.32 0.74 1.12 - - - - - - 0.54 1.15 0.63 1.12 - [16] 2021 60% training cycles - 1.95 0.66 - - - 2.83 1.22 - - - - - - - [21] 2021 Cycle No. 80 1.64 2.30 1.66 2.37 - 1.15 1.10 1.06 1.34 - - - - - - [19] 2021 Cycle No. 50 5.36 6.99 - 2.39 - - - - - - - - - - - [15] 2020 50% training cycles 0.55 1.27 0.39 1.63 - 2.07 3.55 1.03 5.14 - - - - - - [13] 2020 Cycle No. 80 2.02 - - 2.55 - - - - - - 0.82 - - 4.21 - V. CONCLUSION In this paper a new algorithm, namely a robust collaborative feature extractor (RCFE) evolved through a neural network with an augmented hidden layer (NAHL), has been proposed to assess Li-ion batteries state of health under different operating conditions. The algorithm adopts both augmented representations and collaborative training to solve the lack of patterns problem in accelerated aging by keeping algorithmic simplicity as much as possible. The RCFE extractors were built on collaborating a set of I-RBMS designed specifically for this purpose. The RCFE-NAHL investigations, in terms of precision and approximation features, show that the algorithm seems able to reach stability and accuracy while keeping balanced predictions between early and late ones. A comparative study, carried out between the proposed RCFE-NAHL with NAHL and a set of recent and relevant machine learning-based approaches, has clearly demonstrated the proposed collaborative approach capability and algorithmic simplicity. The current algorithmic architecture of NAHL and its variants are designed to provide an approximation for data that do not suffer from a high level of dynamism. Consequently, one of its limitations is the inability to support adaptive learning and dynamic programming. Future investigations should therefore be focused on strengthening the proposal by adding online adaptive learning features and targeting other datasets for further generalization. REFERENCES [1] L. Cai, J. Lin, and X. Liao, “An estimation model for state of health of lithium-ion batteries using energy-based features,” J. Energy Storage, vol. 46, no. December 2021, p. 103846, Feb. 2022, doi: 10.1016/j.est.2021.103846. [2] Y. Zhang, L. Chen, Y. Li, X. Zheng, J. Chen, and J. Jin, “A hybrid approach for remaining useful life prediction of lithium-ion battery with Adaptive Levy Flight optimized Particle Filter and Long Short- Term Memory network,” J. Energy Storage, vol. 44, no. January, 2021, doi: 10.1016/j.est.2021.103245. [3] S. Wang, S. Jin, D. Deng, and C. Fernandez, “A Critical Review of Online Battery Remaining Useful Lifetime Prediction Methods,” Front. Mech. Eng., vol. 7, no. August, pp. 1–19, 2021, doi: 10.3389/fmech.2021.719718. [4] B. Gou, Y. Xu, and X. Feng, “State-of-Health Estimation and Remaining-Useful-Life Prediction for Lithium-Ion Battery Using a Hybrid Data-Driven Method,” IEEE Trans. Veh. Technol., vol. 69, no. 10, pp. 10854–10867, 2020, doi: 10.1109/TVT.2020.3014932. [5] B. Wu, W. D. Widanage, S. Yang, and X. Liu, “Battery digital twins: Perspectives on the fusion of models, data and artificial intelligence for smart battery management systems,” Energy AI, vol. 1, p. 100016, 2020, doi: 10.1016/j.egyai.2020.100016. [6] C. Chen and M. Pecht, “Prognostics of lithium-ion batteries using model-based and data-driven methods,” in Proceedings of the IEEE 2012 Prognostics and System Health Management Conference (PHM-2012 Beijing), May 2012, pp. 1–6, doi: 10.1109/PHM.2012.6228850. [7] D. Jung, K. Y. Ng, E. Frisk, and M. Krysander, “A combined diagnosis system design using model-based and data-driven methods,” in 2016 3rd Conference on Control and Fault-Tolerant Systems (SysTol), Sep. 2016, pp. 177–182, doi: 10.1109/SYSTOL.2016.7739747. [8] A. Fotouhi, D. J. Auger, K. Propp, S. Longo, and M. Wild, “A review on electric vehicle battery modelling: From Lithium-ion toward Lithium–Sulphur,” Renew. Sustain. Energy Rev., vol. 56, pp. 1008–1021, Apr. 2016, doi: 10.1016/j.rser.2015.12.009. [9] N. A. Chaturvedi, R. Klein, J. Christensen, J. Ahmed, and A. Kojic, “Modeling, estimation, and control challenges for lithium-ion batteries,” Proc. 2010 Am. Control Conf. ACC 2010, pp. 1997– 2002, 2010, doi: 10.1109/acc.2010.5531623. [10] S. Wang, S. Jin, D. Bai, Y. Fan, H. Shi, and C. Fernandez, “A critical review of improved deep learning methods for the remaining useful life prediction of lithium-ion batteries,” Energy Reports, vol. 7, pp. 5562–5574, 2021, doi: 10.1016/j.egyr.2021.08.182. [11] S. Jin, X. Sui, X. Huang, S. Wang, R. Teodorescu, and D. I. Stroe, “Overview of machine learning methods for lithium-ion battery remaining useful lifetime prediction,” Electron., vol. 10, no. 24, pp. 1–18, 2021, doi: 10.3390/electronics10243126. [12] J. Zhang, Y. Jiang, X. Li, M. Huo, H. Luo, and S. Yin, “An adaptive remaining useful life prediction approach for single battery with unlabeled small sample data and parameter uncertainty,” Reliab. Eng. Syst. Saf., vol. 222, no. February, p. 108357, Jun. 2022, doi: 10.1016/j.ress.2022.108357. [13] J. Ben Ali, C. Azizi, L. Saidi, E. Bechhoefer, and M. Benbouzid, “Reliable state of health condition monitoring of Li-ion batteries based on incremental support vector regression with parameters optimization,” Proc. Inst. Mech. Eng. Part I J. Syst. Control Eng., p. 095965182095084, Aug. 2020, doi: 10.1177/0959651820950849. [14] L. Fan, P. Wang, and Z. Cheng, “A remaining capacity estimation approach of lithium-ion batteries based on partial charging curve and health feature fusion,” J. Energy Storage, vol. 43, no. May, p. 103115, 2021, doi: 10.1016/j.est.2021.103115. [15] X. Hu, Y. Che, X. Lin, and S. Onori, “Battery Health Prediction Using Fusion-Based Feature Selection and Machine Learning,” IEEE Trans. Transp. Electrif., vol. 7, no. 2, pp. 382–398, 2021, doi: 10.1109/TTE.2020.3017090. [16] T. Xu, Z. Peng, D. Liu, and L. Wu, “A hybrid drive method for capacity prediction of lithium-ion batteries,” IEEE Trans. Transp. Electrif., vol. 8, no. 1, pp. 1000–1012, 2021, doi: 10.1109/TTE.2021.3118813. [17] S. Ansari, A. Ayob, M. S. Hossain Lipu, A. Hussain, and M. H. M. Saad, “Multi-Channel Profile Based Artificial Neural Network Approach for Remaining Useful Life Prediction of Electric Vehicle Lithium-Ion Batteries,” Energies, vol. 14, no. 22, p. 7521, Nov. 2021, doi: 10.3390/en14227521. [18] S. Shen, M. Sadoughi, M. Li, Z. Wang, and C. Hu, “Deep convolutional neural networks with ensemble learning and transfer learning for capacity estimation of lithium-ion batteries,” Appl. Energy, vol. 260, no. November 2019, p. 114296, 2020, doi: 10.1016/j.apenergy.2019.114296. [19] X. Zhang, Y. Qin, C. Yuen, L. Jayasinghe, and X. Liu, “Time-Series Regeneration with Convolutional Recurrent Generative Adversarial Network for Remaining Useful Life Estimation,” IEEE Trans. Ind. Informatics, vol. 17, no. 10, pp. 6820–6831, 2021, doi: 10.1109/TII.2020.3046036. [20] T. Mamo and F. K. Wang, “Attention-based long short-term memory recurrent neural network for capacity degradation of lithium-ion batteries,” Batteries, vol. 7, no. 4, pp. 1–9, 2021, doi: 10.3390/batteries7040066. [21] S. Bamati toosi and H. Chaoui, “Lithium-ion Batteries Long Horizon Health Prognostic Using Machine Learning,” IEEE Trans. Energy Convers., vol. 8969, no. c, pp. 1–11, 2021, doi: 10.1109/TEC.2021.3111525. [22] M. Cao, T. Zhang, J. Wang, and Y. Liu, “A deep belief network approach to remaining capacity estimation for lithium-ion batteries based on charging process features,” J. Energy Storage, vol. 48, no. January, p. 103825, 2022, doi: 10.1016/j.est.2021.103825. [23] T. Berghout, T. Bentrcia, M. A. Ferrag, and M. Benbouzid, “A Heterogeneous Federated Transfer Learning Approach with Extreme Aggregation and Speed,” Mathematics, vol. 10, no. 19, p. 3528, Sep. 2022, doi: 10.3390/math10193528. [24] I. de Pater, A. Reijns, and M. Mitici, “Alarm-based predictive maintenance scheduling for aircraft engines with imperfect Remaining Useful Life prognostics,” Reliab. Eng. Syst. Saf., vol. 221, no. January, p. 108341, 2022, doi: 10.1016/j.ress.2022.108341. [25] I. de Pater and M. Mitici, “Developing health indicators and RUL prognostics for systems with few failure instances and varying operating conditions using a LSTM autoencoder,” Eng. Appl. Artif. Intell., vol. 117, no. January, p. 105582, 2023, doi: 10.1016/j.engappai.2022.105582. [26] T. Berghout and M. Benbouzid, “A Systematic Guide for Predicting Remaining Useful Life with Machine Learning,” Electronics, vol. 11, no. 7, p. 1125, Apr. 2022, doi: 10.3390/electronics11071125. [27] S. Sankararaman and K. Goebel, “Why is the remaining useful life prediction uncertain?,” PHM 2013 - Proc. Annu. Conf. Progn. Heal. Manag. Soc. 2013, pp. 337–349, 2013, doi: https://doi.org/10.36001/phmconf.2013.v5i1.2263. [28] T. Berghout, M. Benbouzid, S. M. Muyeen, T. Bentrcia, and L.-H. Mouss, “Auto-NAHL: A Neural Network Approach for Condition- Based Maintenance of Complex Industrial Systems,” IEEE Access, vol. 9, pp. 152829–152840, 2021, doi: 10.1109/ACCESS.2021.3127084. [29] T. Berghout and M. Benbouzid, “EL-NAHL: Exploring labels autoencoding in augmented hidden layers of feedforward neural networks for cybersecurity in smart grids,” Reliab. Eng. Syst. Saf., vol. 226, p. 108680, Oct. 2022, doi: 10.1016/j.ress.2022.108680. [30] B. Saha and K. Goebel, “Battery data set,” NASAAMES Progn. Data Repos. 2007. [31] V. M. Nagulapati et al., “A novel combined multi-battery dataset based approach for enhanced prediction accuracy of data driven prognostic models in capacity estimation of lithium ion batteries,” Energy AI, vol. 5, p. 100089, Sep. 2021, doi: 10.1016/j.egyai.2021.100089. [32] G. E. Hinton, “A Practical Guide to Training Restricted Boltzmann Machines,” in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), vol. 7700 LECTU, 2012, pp. 599–619. [33] B. Tarek, “Online Sequential Extreme Learning Machine: A New Training Scheme for Restricted Boltzmann Machines,” May 2020, doi: 10.20944/PREPRINTS202005.0444.V1. [34] G. Hong, W. Song, Y. Gao, E. Zio, and A. Kudreyko, “An iterative model of the generalized Cauchy process for predicting the remaining useful life of lithium-ion batteries,” Measurement, vol. 187, no. September 2021, p. 110269, Jan. 2022, doi: 10.1016/j.measurement.2021.110269. [35] C. J. Lee, B. K. Kim, M. K. Kwon, K. Nam, and S. W. Kang, “Real- time prediction of capacity fade and remaining useful life of lithium-ion batteries based on charge/discharge characteristics,” Electron., vol. 10, no. 7, 2021, doi: 10.3390/electronics10070846.","libVersion":"0.3.2","langs":""}