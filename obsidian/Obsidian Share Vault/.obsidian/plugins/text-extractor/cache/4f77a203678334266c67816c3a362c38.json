{"path":"lit/lit_notes_OLD_PARTIAL/Liu22CoupledLearningEnabled.pdf","text":"Coupled Learning Enabled Stochastic Programming with Endogenous Uncertainty ∗ Junyi Liu Guangyu Li Suvrajeet Sen Original Aug 2020 Abstract Predictive analytics, empowered by machine learning, is usually followed by decision-making problems in prescriptive analytics. We extend the above sequential prediction-optimization paradigm to a coupled scheme such that the prediction model can guide the decision problem to produce coordinated decisions yielding higher levels of performance. Speciﬁcally, for stochastic programming (SP) models with latently decision-dependent uncertainty, we develop a coupled learning enabled optimization (CLEO) algorithm in which the learning step of predicting the latent dependency and the optimization step of computing a candidate decision are conducted interactively. The CLEO algorithm automatically balances the exploration and exploitation via the trust region method with active sampling. Under certain assumptions, we show that the sequence of solutions provided by CLEO converges to a directional stationary point of the original SP problem with probability 1. In addition, we present preliminary experimental results which demonstrate the computational potential of this data-driven approach. 1 Introduction Beginning with George Dantzig’s well-known formulation in the mid 1950’s, stochastic programming (SP) has provided a class of optimization models in which uncertainties are modeled by probability distributions. Since then, due to the enormous amount of decision-making problems in the presence of uncertainty in practice, the SP ﬁeld has ﬂourished with theoretical and algorithmic advances [5, 38, 41]. Without knowing the exact probability distribution of the uncertainty, SP methods utilize discretization with scenarios of the uncertainty. Current studies of SP methods pay little attention to the generation process underlying scenarios. Instead SP methods simply assume that scenarios are generated a priori. This is reasonable when the uncertainty is decision-independent and scenarios can be generated from a historical data set or simulated from prediction models. For two-stage and multi-stage stochastic optimization problems with the decision independent un- certianty, there is an abundant literature [22, 25] on scenario reduction and scenario generation to ensure that the scenario tree is not too large, and yet representative of the uncertainty being modeled. Several works by Grossman and the coauthors such as [20] consider a scenario tree based method for a type of endogenous uncertainty such that the optimization decision variables inﬂu- ence the time of information discovery for discrete uncertainty. In the present paper, another type of endogenous uncertainty is considered, meaning that the probability distribution of the random variable is dependent on the decision variable. ∗All authors are aﬄiated with University of Southern California. Email: junyiliu@usc.edu, guangyul@usc.edu, s.sen@usc.edu. 1 Speciﬁcally, we focus on a task of solving an SP equipped with an uncharacterized uncertainty which has a dependency on the continuous decision variable: minimize f (x) ≜ c(x) + Ẽω|x[ h(x, ̃ω) + g(x, ̃ω ) ] subject to x ∈ X ⊆ Rp (1) where ̃ω ∈ Rm is a continuous random vector deﬁned on a probability space (Ω, F, P(x)), with Ω being the sample space, F being the σ-algebra generated by subsets of Ω and P(x) being a probability measure parameterized by x deﬁned on F. This type of uncertainty is also called endogenous uncertainty. At the outset, one needs to be sure that the conditional expectation in (1) is well deﬁned. For a general treatment of this issue, the reader may consult [41, Section 2.3], in particular Theorem 7.37. We are interested in the setting when the random variable is a regression model of the decision variable, i.e., ̃ω = m(x, ̃ε ) = ψ(x) + ̃ε where: ψ(·) : Z ⊆ Rp → Rm, Z is an open convex set containing the feasible set X and ̃ε is a random variable independent of x. With the regression model, the problem (1) has a standard SP formulation as follows. minimize x∈X⊆Rp f (x) = c(x) + Ẽε[ h(x, ψ(x) + ̃ε ) ] + Ẽε[ g(x, ψ(x) + ̃ε ) ]. (2) However, standard SP approaches cannot be applied, since both the regression function ψ and the distribution of the random variable ̃ε are unknown, and moreover the realizations of ̃ε cannot be observed. In order to solve such SP problems eﬀectively, data pairs of decisions and uncertainties should be collected together to learn the relationship of uncertainty with the decision variable. A practical method is “Predict-then-Optimize” (PO) ([18]). In this sequential paradigm, with a given set of data pairs {(xi, ωi)}, one ﬁrst predicts the probability distribution of the random variable parameterized by the decision variable, and then solves the SP problem composed with the predicted probability distribution. However, there are several technical issues associated with the PO scheme: a) in most practical cases, the true probability distribution of uncertainty may not be approximated well by parametric models; b) it may be expensive to acquire data pairs in the entire decision space, hence nonparametric prediction models may not approximate the true probability distribution of uncertainty well; c) it is computationally challenging to solve the coupled nonconvex and nonsmooth composite optimization problem in the PO scheme and the obtained solution is not guaranteed when the prediction errors are signiﬁcant. In fact, the interdependence between predictions and decisions are at the center of the trade- oﬀ between predictive accuracy and mathematical optimization of decision-making. So a question that arises is: without any parametric assumption on the latent dependency, what class of composite prediction-optimization structure could be amenable to algorithmic optimization for solving the SP with latently endogenous uncertainty? We address this question by coupling learning models with iterative optimization algorithms with several major contributions summarized as below. 1. Without making any parametric assumption of the probability distribution of decision-dependent uncertainty, we develop an algorithm called “Coupled Learning Enabled Optimization” (CLEO) and the sequence of solutions produced by CLEO is shown to converge to a stationary solu- tion of the original nonlinear, non-convex and non-smooth constrained SP problem (1) with probability 1. 2 2. Instead of acquiring data pairs of decisions and uncertainties in the entire decision space beforehand, the CLEO algorithm acquires data pairs in a sequence of trust regions (TR) in order to iteratively learn the local dependency within local regions. Numerical experiments show that the total number of data pairs required in CLEO could be signiﬁcantly lower on average than the data size required in the PO schemes. 3. In the CLEO scheme, on one hand, local linear regression model is locally comparable to the nonparametric prediction models and locally better than parametric prediction models. On the other hand, the composite optimization subproblem with a local linear regression model is a convex problem in the trust region, thus a simpler optimization problem to solve. This connection between learning and optimization in CLEO automatically balances the trade-oﬀ between prediction accuracy and optimization complexity. 4. Central points and radius of small regions for local learning models are automatically deter- mined by the ratio of improved performance at solutions obtained in iterative TR optimization steps. This connection between learning and optimization balances the trade-oﬀ between ex- ploring new solution region and exploiting the current solution region. We note that this is analogous to the exploitation-exploration trade-oﬀ in reinforcement learning, but this type of trade-oﬀ is novel in stochastic programming with endogenous uncertainty. 1.1 Problem setting We make several assumptions about the program (1) so that we focus on the treatment of latent dependency. (A1) The regression function ψ(·) : Z ⊆ Rp → Rm is a twice-diﬀerentiable function, ̃ε is a random vector independent of x, with a compact sample space. It has zero mean and ﬁnite variance Σ. (A2) The function h(x, ω) = maxj∈J hj(x, ω). The set J is a ﬁnite index set and for each j ∈ J , hj(·, ·) : Zj × Ωj → R is a convex and C1 smooth function where Zj ⊆ Rp is an open convex set containing X and Ωj ⊆ Rm is an open convex set containing Ω. (A3) The function c(·) : Rp → R is C1 smooth on X and the function g(·, ·) is C1 smooth on X × Ω. The functions c, g, h and ψ have the Lipschitz continuity modulus L1, and c, g, {hj}j∈J and ψ have Lipschitz gradient modulus L2. (A4) The feasible set X ⊆ Rp is a deterministic, convex and compact set We provide some motivation for the above assumptions. In assumption (A1), we assume that the random variable ̃ω is generated from a homoscedastic regression model which means that the noise ̃ε has a ﬁnite variance independently of x. Notice that we do not have any parametric assumption on the regression function ψ. Given the widespread use of regression models, this assumption can easily leverage modern tools of statistical learning. Assumptions (A2) and (A3) characterize properties of the objective function f (x). In particular, c(·) is a smooth but nonconvex function independent of the randomness. There are two functions associated with randomness: g(·, ·) is a smooth but potentially nonconvex function and h(·, ·) is a convex and nonsmooth function due to the structure of ﬁnite pointwise maximization. Such functions arise in some applications such as two-stage stochastic linear programs (SLP). Assumption (A4) imposes a deterministic and convex feasible solution set so that we focus on the treatment of the latent decision-dependency. 3 This type of latently decision-dependent uncertainty appears: (a) in marketing where x may denote an advertising plan and ω may denote sales [39]; (b) in revenue management where x may denote a booking policy and ω may denote demands [13]; (c) in disaster preplanning where x may denote a preparatory plan and ω may denote the survival of links after a disaster [35] and so on. In order to make the connection with standard statistical/machine learning terminology, we treat x as the predictor, and ω as the response. To seek an approximate solution of (1), we will estimate the dependency of the response on the predictor using an entirely data-driven approach. Though problem (2) shares some relationships with composite optimization problems (such as [15]) or the ﬁnite sum in regularized empirical risk minimization problems (such as [36]), the most signiﬁcant diﬀerence of (2) from the previous problems is that the objective function f (x) has an implicitly composite structure due to the unknown endogenous uncertainty. The composition of a nonsmooth function h with the unknown nonconvex function ψ integrated with the randomness ̃ε leads to the signiﬁcant challenges in solving an implicitly-composite, nonsmooth and nonconvex SP problem (2). To motivate the class of applications of SP with implicit endogenous uncertainty, we discuss a joint production and pricing example. The demand is a random variable which is implicitly aﬀected by the price. Numerical performance of CLEO on this joint production and pricing problem is presented in Section 4. Besides, a joint production, shipment and pricing problem can be formulated as a two-stage SLP with endogenous uncertainty as well and we refer the interested readers to [3] for details. Example: Joint production and pricing problem Suppose we have a set of K products to be launched. For each product i, we need to decide its price pi and the amount qi to produce at the cost of c1i per unit. The demand di of each product i is not only aﬀected by its own price but also by the price of other products. We use bold vectors p, q, c1 and d to represent the price, production units, production cost, and demand for K products. Suppose that the demand d is a regression model of the price p in the form that d = ψ(p) + ̃ε where ̃ε is a random variable with bounded variance and is independent of p and q. Due to the variability of the random demand, we have the option of last-minute production at the cost of c2 > c1 per unit to satisfy the demand. Moreover, we suﬀer the penalty cost of c3 per unit if the production exceeds the demand. The goal is to decide the price and production quantity to minimize the expected total cost. This problem is modeled as a stochastic programming problem as follows. It is straightforward to notice that this problem satisﬁes assumptions (A1)-(A4). minimize q,p≥0 c⊤ 1 q + Ed|p[ − p⊤d + c ⊤ 2 max{d − q, 0} + c ⊤ 3 max{q − d, 0} ] (3) In practice, besides the price, the demand could depend on features such as seasonality and pro- motion. Actually, these features can be categorized into two classes, controllable features (e.g., price, promotion) and environmental features (e.g., seasonality). When only controllable features are considered in modeling the uncertainty, the CLEO scheme could be applied for such situa- tions. When both price and seasonality features are considered, the goal is to seek the best plan of production and pricing for a speciﬁed season. Mathematically, the SP model aims to mini- mize Ed|(p,¯z) [ f (p, q, d) ], where ¯z represents a speciﬁc seasonality and f (p, q, d) ≜ c⊤ 1 q − p⊤d + c⊤ 2 max{d − q, 0} + c⊤ 3 max{q − d, 0}. If we can obtain data pairs of (p, d) for the speciﬁed season ¯z, then the CLEO scheme is suitable. If we can only obtain the data pairs of (p, z, d), then the CLEO scheme might need further adaptations. However, the study of the SP problem accounting for both controllable and environmental features is beyond the scope of the present paper. 4 1.2 Literature review Decision-dependent uncertainty is common in operations management (OM) models. In revenue management, Cooper et al. [13] analyzed that if the dependency of demand and price is ignored, this modeling error could result in the systematic deterioration when the decisions are made based on the prediction using observed data over time. In dynamic pricing, there is a growing literature [1, 10] which combines demand learning and pricing to control the regret. We refer to [14] for a comprehensive review of literature in dynamic pricing. Most of the work in revenue management assumes known or parametric demand functions while there are a few works [4, 8] addressing the nonparametric demand models. In newsvendor-type problems, Lee et al. [28] utilize the quantile structure to design an iterative decision process which is combined with a forecasting model. Liyan- age and Shanthikumar [31] proposes operational statistics by integrating parameter estimation and optimization to obtain a better solution compared with the traditional approach for the newsvendor inventory control problem with ambiguous demand. In these works, the integration of learning and optimization relies on special structures of these operations management models. Connections with Stochastic Programming In stochastic programming, Dupaˇcov´a [16] cat- egorized endogenous uncertainty into two subclasses, where the decision can either aﬀect the prob- ability distribution of the uncertainty or aﬀect the time when the information of the uncertainty is revealed. In the current literature, the decision-dependent information revelation has received the most attention (see [20, 23]). As for decision-dependent probability distribution, the literature is quite sparse since nonconvexity can easily creep in. Dupaˇcov´a [16] addresses two classes of problems where the decision either aﬀects parameters of the parametric probability distribution or aﬀects the choice of a probability distribution among a ﬁnite set of probability distributions. Hellemo et al. [23] add another class of problems where the probabilities are distorted by decision variables. Noyan et al. [34] study the distributionally robust optimization model with decision-dependent uncertainty in risk measures such as CVaR. Current studies of endogenous uncertainty in SP ei- ther take the dependency of uncertainty on the decision variable being provided a priori, or have parametric assumptions of dependency. In contrast to the above modeling-oriented viewpoints in SP, we do not make any parametric assumptions on the endogenous uncertainty. We integrate the local prediction model of the unknown endogenous uncertainty models with the decision-making using a trust-region type algorithm in this paper. There are also sampling approaches which mimic trust-region type algorithms via adaptive proximal parameter choices for stochastic linear programming (e.g., [24]) and more recently [30]. In the former paper, an iterative choice of the proximal parameter is akin to the iterative choice of a trust region radius. In the present paper, the need for model-ﬁtting within endogenous uncertainty models in this paper, makes the trust region approach a more natural choice. Predict-then-Optimize(PO) To accommodate the latent dependency, we take the decision variable as the predictor and the uncertainty as the response. PO schemes of this nature are very common in practice. For instance, in revenue management, a common approach is to ﬁrst approximate the demand curve by a linear function of price (see [10]) and then plug the approximate linear demand curve into pricing problems. Actually, techniques used for SP with endogenous uncertainty in most of the literature can be seen as PO approaches. In such a paradigm, a choice among various prediction models aﬀects the approximate optimization problem and thus aﬀects the quality of the derived decision. In the case of exogenous uncertainty, Elmachtoub and Grigas 5 [18] develop “smart” predict-then-optimize approach which modiﬁes the loss function of prediction models by accounting for the objective value of a special class of linear programming problems. Since PO approaches deal with prediction and optimization separately, one needs a novel way of balancing the trade-oﬀ between predictive accuracy and optimization complexity. Derivative-free methods Instead of estimating the latent dependency, one could use derivative- free methods [12, 27] without knowing function structures. In [19], a zeroth-order method is applied to compute a critical point for the stochastic programming problem with known decision-dependent uncertainty under a smoothness condition. Another applicable method is trust region (TR) methods based on derivative-free models. We refer to Conn et al. [11] for comprehensive study of trust region methods. A classical trust region method iteratively solves a subproblem using the second-order approximation in the trust region centered at the proposed solution. As the algorithm proceeds, the trust region radius is either contracted or expanded depending on the ratio of actual-to-predicted reduction on the objective value. Without using derivative and the second-order information of the objective function, we can construct a random trust region model using either interpolation or regression models over decision variables. Recent studies [2, 6, 9, 21, 26] develop various trust region methods with random models for convergence to a ﬁrst-order and second-order stationary solution of smooth and unconstrained optimization problems. In addition, a type of derivative-free approach was developed by Bertsimas et al. [3] which approximates the conditional expectation of a random function given imperfect observations using machine learning (ML) methods including LOESS, regression trees and random forests. In the case of decision-dependent uncertainty, the approach in [3] overcomes non-convexity by discretizing the space of continuous decision variables and aggregating the optimal value of subproblems for all discretized decisions. Such discretization of the decision space introduces exponential growth in the size of decision-making problem. The CLEO algorithm, which is developed in the present paper, is based on a type of derivative-free trust region method for solving SP with latently decision-dependent uncertainty. Speciﬁcally, the CLEO algorithm is comprised of an iterative scheme consisting of learning steps and optimization steps. In a learning step, we predict the local latent dependency using local linear regression (LLR) centered at the current iterate. In the optimization step we seek a candidate solution of a trust region subproblem composed with the random LLR model. The diﬀerence of CLEO with the current literature on derivative-free trust region methods such as [9] is that the proposed TR- based method is adapted for nonsmooth, latently composite, constrained stochastic programming problems. The other work relevant to our approach is [26] in which a derivative-free optimization method is developed by utilizing the trust region framework with regression models from data. The setting considered here is diﬀerent from the above reference due to a latent composite structure in SP problem caused by the decision-dependent uncertainty. Local linear regression is an old approach dating back to late 19th century, which approximates the mean of dependent variables locally by a member in a parametric function class (see [32]). Hence, we can estimate a much wider class of regression surfaces than parametric regression models. The bandwidth of local regression models is traditionally chosen to be a constant or to contain a ﬁxed number of points as a means of balancing the bias and variance of estimation. In its more recent incarnation, local regression includes weights using a kernel based on a given bandwidth. In CLEO, we use the uniform kernel in local linear regression, then the bandwidth represents the radius of the region for ﬁtting a linear regression model. Moreover, we integrate learning with optimization by allowing the bandwidth of LLR model to follow the trust region radius rule so that it is automatically adjusted to the ratio of actual-to-predicted reduction. Such interaction provides a bridge between 6 the accuracy of local learning models and the optimality of optimization subproblems. Though a local regression model with the second or higher order functions could provide higher accuracy, it would result in a more challenging nonconvex composite subproblem. In an eﬀort to control the complexity of any iteration, we use simple local linear regression without much loss of accuracy. To the best of our knowledge, the CLEO algorithm is the ﬁrst to present a provably convergent algorithm for coupling learning and stochastic optimization to control the overall complexity in seeking a near-optimal solution for SP with decision-dependent uncertainty. 2 The CLEO algorithm 2.1 Notations In the following analysis, we use 1p×q to denote the matrix of size p × q with all one entries, 1p to denote the vector of size p with all one entries, 0p×q to denote the matrix of size p × q with all zero entries and Ip denote the identity matrix of size p. For a vector v ∈ Rm, ∥v∥ denotes the Euclidean norm of a vector. For a matrix M ∈ Rm×n, ∥M ∥ denotes the matrix norm induced by the Euclidean vector norm. We follow the classical O(·) and o(·) representations for asymptotic behavior. For a smooth function g(·, ·) : X1 × X2 → R, we use ∇1g(x1, x2) to denote the gradient taken with respect to the ﬁrst variable at (x1, x2) and ∇2 g(x1, x2) to denote the gradient taken with respect to the second variable at (x1, x2). For a convex function h(·, ·) : X1 × X2 → R, we use ∂1 h(x1, x2) nad ∂2 h(x1, x2) to denote the subdiﬀerentials taken with respect to the ﬁrst variable and the second variable at (x1, x2) respectively. When we address the probability distributions of random variables, we use MN m,n(M, U, V ) to denote the matrix normal distribution and U(S) to denote the uniform distribution on a set S. Because problem (2) is potentially a nonconvex optimization problem, we limit our scope to seeking a directional stationary point which relieves the computational burden of searching for a global or local optimum. With the fact that a composition of convex and diﬀerentiable function h(x, ψ(x)+̃ε) is Clarke regular and locally Lipschitz continuous, we can compute the directional derivative of f by [15] and Theorem 7.44 in [41]. For any x ∈ X and any d ∈ T (x; X) where T (x; X) deﬁnes the tangent cone of the set X at x, the directional derivative of f at x for the direction d is computed as follows. f ′(x; d) = ∇c(x) ⊤d + Ẽε [ h ′((x, ψ(x) + ̃ε ); (d, ∇ψ(x)⊤d)) + g ′((x, ψ(x) + ̃ε ); (d, ∇ψ(x) ⊤d) ] (4) where h ′((x, ψ(x) + ̃ε ); (d, ∇ψ(x)⊤d)) = sup{q⊤ 1 d + q⊤ 2 ∇ψ(x) d : q1 ∈ ∂1h(x, ψ(x) + ̃ε ), q2 ∈ ∂2h(x, ψ(x) + ̃ε )} g ′((x, ψ(x) + ̃ε ); (d, ∇ψ(x)⊤d) = ∇1g (x, ψ(x) + ̃ε )⊤d + ∇2g (x, ψ(x) + ̃ε )⊤∇ψ(x)⊤d Accordingly, the directional stationarity of (2) is deﬁned as follows which can be found in Chapter 8 in [37] by Rockafellar and Wets. We refer to [29] for a recent review of stationarity in nonconvex problems. Deﬁnition 1. We say that ¯x is a directional stationary point of the problem (2) if f ′(¯x; x − ¯x ) ≥ 0, for any x ∈ X, or equivalently, χ(x) = 0 with χ(x) ≜ | min{f ′(x; d) : x + d ∈ X, ∥ d ∥ ≤ 1 }| (5) 7 Since ψ(·) and the probability distribution of ̃ε are not available a priori, our strategy couples the estimation of a regression model with the optimization in (2). In the CLEO algorithm, we iteratively conduct a learning step with LLR and an optimization step using the TR method. In the rest of this section, we touch upon LLR models and the trust region method in turn. 2.2 LLR models We assume that we are able to obtain data pairs of the decisions and uncertainties in local regions as the algorithm proceeds. In practice, this can be achieved by simulations from the complex model of the random variable ̃ω. In learning steps, we consider a hypothesis class of aﬃne functions, i.e., H ≜ { φ(·) : R p → Rm | φ(x) = (B1) ⊤x + (B0)⊤, and B1 ∈ Rp×m, B0 ∈ R1×m }. At the kth iteration, given the current point ̂xk and the current trust region radius δk, suppose we draw the data set Tk = {(xi, ωi)} of size Nk with the set of points {xi} Nk i=1 uniformly generated in the local region ∈ B(̂xk, δk) ∩ X. Among parametric functions in the hypothesis class H, we seek the one which minimizes the sum of square errors on the data set Tk. One may use a kernel to weight data points according to their distance to the current point ̂xk or use weighted least squares to deal with heteroscedasticity when the variance of the noise in regression is dependent on x. In the present paper, under the homoscedasticity assumption, the simplest variant is to use a uniform kernel for local linear regression. Then, the estimation of parameters ̂Bk,1, ̂Bk,0 and residuals {ek,i} are constructed as follows. { ̂Bk,0, ̂Bk,1} ∈ argmin B0,B1 ∑ (xi,ωi)∈Tk ∥ ∥ ∥ ωi − (B1)⊤xi − (B0)⊤ ∥ ∥ ∥ 2, (6) e k,i ← ωi − ( ̂Bk,1) ⊤xi − ( ̂Bk,0) ⊤, for i = 1, 2, . . . , Nk (7) Let ̂ε k denote a random variable with the empirical probability distribution of {ek,i}Nk i=1. The LLR model mk is constructed as follows. mk(̂x k + s, ̂ε k) ≜ ( ̂Bk,1) ⊤(̂xk + s) + ( ̂Bk,0) ⊤ + ̂ε k. (8) 2.3 TR models The TR model fk is then constructed with Êεk denoting the expectation with respect to the empirical probability distribution of {ek,i} Nk i=1. fk(̂xk + s) ≜ c(̂xk + s) + Êε k [ h(̂xk + s, mk(̂xk + s, ̂ε k)) + g(̂xk + s, mk(̂x k + s, ̂ε k)) ]. (9) From an intuitive perspective, the LLR model mk is a ﬁrst-order probabilistically accurate approx- imation of latent dependency with enough number of samples. By composite structure, the trust region model fk is a probabilistically accurate approximation to the original objective function. Such a criterion on accuracy will be formally discussed in the convergence analysis in section 3.1. A trust region subproblem is formulated as follows. (Pk) minimize s fk(̂xk + s) subject to ̂x k + s ∈ X, ∥ s ∥ ≤ δk (10) 8 Note that under assumptions (A2) and (A3), fk is the sum of two smooth functions and a convex nonsmooth function. If the smooth part is convex, the trust region subproblem (10) is a convex problem and we could ﬁnd a global optimum by using any eﬃcient numerical algorithms for con- vex programs, such as the stochastic approximation algorithm [33], the stochastic decomposition algorithm [40, 30] and others. If the smooth part is nonconvex, we can compute a suitable point to- wards the steepest descent direction that satisﬁes some “suﬃcient” decrease condition. Speciﬁcally, following the construction in Chapter 11 of [11], for any given point ̂xk ∈ X, we say sk is a suitable step of (Pk) if ̂xk + s ∈ X, ∥sk∥ ≤ δk; moreover, there exists a positive constant κdcp ∈ (0, 1) such that, fk(̂xk) − fk(̂xk + sk) ≥ κdcp χk(̂xk) min { δk, 1} , for any ¯x ∈ B(̂xk, ϵ) ∩ X, (11) where χk(x) ≜ | minimize x + d ∈ X ∥ d ∥ ≤ 1 fk ′(x; d) |. (12) Theorem 12.2.2 in [11] implies that the “suﬃcient” decrease condition (11) can be satisﬁed by a step to the boundary of the steepest descent direction. The method to derive such a point is beyond the scope of our paper; instead we refer the interested readers to section 12.2 in Conn et al. [11]. Because of modeling error, one needs to verify whether the derived suitable step sk is a descent step. Trust region methods use the ratio of actual-to-predicted reduction as a criterion. Due to the unknown decision-dependency, actual function values can not be computed, but can be estimated using local regression models. Speciﬁcally, to estimate function values f (̂xk) and f (̂xk + sk), we ﬁrst generate two independent data sets Sk = {(xj,1, ωj,1)} and Sk+1/2 = {(xj,2, ωj,2)} with two sets of decision points {xj,1} and {xj,2} uniformly generated in neighborhoods B(̂xk, ∥sk∥/2) ∩ X and B(̂xk + sk, ∥sk∥/2) ∩ X respectively. Following (8), with Sk and Sk+1/2 we ﬁt two local linear regression models respectively denoted by mk,1(̂xk + s, ̂ε k,1) and mk,2(̂xk + s, ̂ε k,2) . Then function values f (̂xk) and f (̂xk + sk) are estimated by vk and vk+1/2 as follows. vk ≜ c(̂xk) + Êε k,1[ h(̂xk, mk,1(̂xk, ̂ε k,1)) + g(̂xk, mk,1(̂xk, ̂ε k,1)) ] (13) vk+1/2 ≜ c(̂xk + sk) + Êε k,2[ h(̂x k + sk, mk,2(̂xk + sk, ̂ε k,2)) + g(̂xk + sk, mk,2(̂xk + s k, ̂ε k,2))] (14) The ratio of estimated actual-to-predicted reduction is then approximated as ρk ≜ (vk − vk+1/2)/ ( fk(̂xk) − fk(̂x k + sk) ) (15) The criteria that whether the new step ̂x k + sk will be rejected or accepted contain two parts. One is that if the ratio ρk is large enough, the other is the that if the ratio between the generalized gradient χk(̂xk) and the TR radius δk is large enough. In section 11.4 in [11], there is a discussion on how to compute the generalized gradient for a composite function h(c(x)) when h is a piecewise aﬃne function and c is a diﬀerentiable function. We can easily extend the formulation of generalized 9 gradient for fk under the assumption (A2). In particular, we have χk(x) = − min x + d ∈ X ∥d∥ ≤ 1 fk ′(x; d) = − min x + d ∈ X ∥d∥ ≤ 1       ∇c(x)⊤d + 1 Nk Nk∑ i=1 h ′(x, mk(x, e k,i ); (d, (B1,k)⊤d)) + 1 Nk Nk∑ i=1 ∇1 g(x, mk(x, e k,i )) ⊤d + ∇2 g(x, mk(x, e k,i )) ⊤(B1,k) ⊤d       = − min x + d ∈ X ∥d∥ ≤ 1       ∇c(x)⊤d + 1 Nk Nk∑ i=1 ∇1 g(x, mk(x, e k,i )) ⊤d + ∇2 g(x, mk(x, e k,i )) ⊤(B1,k)⊤d + 1 Nk Nk∑ i=1 max j∈A(x,ek,i) { ∇1hj(x, mk(x, e k,i )) ⊤d + ∇2hj(x, mk(x, e k,i ) ⊤(B1,k)⊤d }       where A(x, ek,i) ≜ {j ∈ J : hj(x, mk(x, ek,i)) = h(x, mk(x, ek,i))}. Hence, the computation of generalized gradient is equivalent to solving a convex program as above. 2.4 CLEO algorithm We present the CLEO algorithm which combines the learning step and the optimization step in Algorithm 1. At each iteration, given the data set Tk, the CLEO algorithm successively constructs an LLR model mk and a trust region model fk following lines 3-5 of Algorithm 1. A suitable step sk is derived in line 6 satisfying the suﬃcient decrease condition (11). The actual-to-predicted reduction ratio ρk is computed through lines 7-9. According to the update rule from line 10 to line 14, a new iterate point is accepted if the suﬃcient function reduction is achieved, and the trust-region radius is small compared to the norm of the generalized gradient. The logic behind this update criterion on trust-region radius follows from the fact that the step size obtained by the minimization of a smooth function is typically proportional to the norm of its gradient, hence the trust region should be of comparable size as well. In the next iterate, we take the bandwidth of LLR model to be the same as the updated trust region radius. If the current local linear regression model does not ﬁt the local dependency well, this would lead to a large ratio ρk, and then the suitable step is rejected so that the next LLR model with a shrunk bandwidth is more appropriate in a smaller region. In this way, the CLEO algorithm connects the predictive model with the optimization problem through a “smart” bandwidth choice. This connection automatically balances the trade- oﬀ between the exploration of the new decision region and the exploitation of the current decision region. To practically implement CLEO, one needs to specify the size of data generated in each trust region. In the convergence analysis in section 3.2, we present the sample size requirement for the convergence. However, it is not a practical guide as most of the constants (i.e., Lipschitz gradients) in the sample size requirement are not usually available in practice. We assume that the sequence of sample sizes {Nk} are given for now and we will discuss the empirical choices of sample sizes in Section 4. 10 Algorithm 1 CLEO 1: Initialization: ̂x0 ∈ X, δ0 ∈ (0, δmax) with δmax > 0, γ > 1, η1 ∈ (0, 1), η2 > 0. 2: for k = 0, 1, 2, . . . do 3: generate a set of samples {ui} from a uniform distribution U(B(0p, 1)). Let {xi} ≜ {δk ui + ̂xk} ∩ X and {ωi} are corresponding scenarios according to the true models {m(xi, ̃ε )}. Let Tk ≜ {(xi, ωi)}. 4: construct a local linear regression model mk(̂xk + s, ̂ε k) by (8) with the data set Tk. 5: construct the trust region model fk(̂xk + s) by (9). 6: compute a suitable step sk of the TR subproblem (10) satisfying the condition (11). 7: generate sets of data pairs Sk and Sk+1/2 uniformly in trust regions B(̂xk, ∥sk∥/2) ∩ X and B(̂xk + sk, ∥sk∥/2) ∩ X respectively. 8: construct two local linear regression model mk,1(̂xk + sk, ̂ε k,1) and mk,2(̂xk + sk, ̂ε k,2) by ﬁtting data sets Sk and Sk+1/2 respectively. 9: compute vk by (13) , vk+1/2 by (14), ρk by (15) and χk(̂xk) by (12). 10: if ρk ≥ η1 and χk(̂xk) ≥ η2δk then 11: ̂xk+1 = ̂xk + sk, δk+1 = min {γδk, δmax} 12: else 13: ̂xk+1 = ̂xk, δk+1 = γ−1δk 14: end if 15: end for 3 Convergence analysis of the CLEO algorithm In this section, we show that the sequence {̂xk} produced by the CLEO algorithm converges to a stationary point of (2) with probability 1. Intuitively, the convergence should hold if the trust region models {fk} are probabilistically accurate within the trust region. The condition of probabilistic accuracy that is required for the convergence is formally deﬁned as probabilistically fully linearity in the literature [2, 9]. The convergence analysis for CLEO is comprised of two parts. In section 3.1, we ﬁrst show that under the sample size requirement of data in trust regions, the TR random model fk is probabilistically fully linear. Using this property, we then show in section 3.2 the sequential convergence of CLEO to a stationary point with probability 1. Though CLEO can be seen as an extension of the trust region method for unconstrained smooth optimization problem in [9], the convergence analysis for CLEO is nontrivial due to the challenges in dealing with a constrained, latently composite, nonsmooth and nonconvex stochastic optimization problem. 3.1 Probabilistically fully linear property of a TR model In the following analysis, when we describe a random process in the CLEO algorithm, we use uppercase letters, such as the kth iterate ̂X k, to denote random variables, while we use lowercase letter to denote realizations of the random variable, such as ̂xk which denotes the k-th iterate for a particular realization of our algorithm. This kind of notation will be applied to the LLR models {mk}, {Mk}, TR random models {fk}, {Fk} and random value estimates {vk, vk+1/2}, {Vk, Vk+1/2} as well. Hence, our algorithm results in a stochastic process {Mk, Fk, Xk, Sk, ∆k, Vk, Vk+1/2}. Our goal is to show that under certain conditions on the sequences {Fk} and {Vk, Vk+1/2}, the resulting stochastic process has desirable convergence properties almost surely. We ﬁrst provide concepts 11 of κ-fully linear approximation of deterministic and random trust region models respectively in Deﬁnition 2 and 3. The deﬁnition of fully linear model is introduced in section 6 of [12]. With this notion, model functions are characterized to behave similarly to Taylor approximations in a given trust region. This notion was generalized to random models in the probabilistic sense in [2]. Deﬁnition 2. Let f : Z → R and fk : Z → R be locally Lipschitz continuous and directionally diﬀerentiable functions deﬁned on an open set Z ⊆ Rm containing the convex compact set X. We say that the function fk is a κ-fully linear model of f on B( ̂xk, δk ) with κ = (κef , κed) and κef , κed ≥ 0, if for any x ∈ B( ̂xk, δk ) ∩ X, χ(x) − χk(x) ≤ κed δk, | f (x) − fk(x) | ≤ κef δ 2 k , where χ(x) is deﬁned in (5) and χk(x) is deﬁned in (12). Deﬁnition 3. Let f : Z → R be a locally Lipschitz continuous and directional diﬀerentiable function deﬁned on an open set Z ⊆ Rm containing the convex compact set X. Let {Fk : Z → R} be a sequence of random functions, each of which is locally Lipschitz continuous and directionally diﬀerentiable almost surely. A sequence of random functions {Fk} are said to be α-probabilistically κ-fully linear with respect to {B( ̂X k, ∆k )} if and only if for a scalar α ∈ (0, 1), a constant vector κ ∈ R2 + and any k ≥ 1, the event Ik = { Fk is a κ-fully linear model of f on B( ̂Xk, ∆k) } satisﬁes the condition P ( Ik | Fk−1 ) ≥ α, where Fk−1 denotes the σ-algebra generated by {Fi, Vi, Vi+1/2}k−1 i=0 , and P(• | Fk−1) is a conditional probability given the past history of Fk−1. In addition to the probabilistically accurate condition for TR random models, we require suﬃciently accurate value estimates. Deﬁnition 4. The value estimates vk and vk+1/2 are ϵF -accurate estimates of f (̂xk) and f (̂xk +sk), respectively, for a given δk if and only if | vk − f (̂x k) | ≤ ϵF δ 2 k , | vk+1/2 − f (̂xk + s k) | ≤ ϵF δ 2 k . Deﬁnition 5. A sequence of random value estimates {(Vk, Vk+1/2)} are said to be β-probabilistically ϵF -accurate with respect to the corresponding sequence {Xk, ∆k, Sk} if for the nonnegative con- stants β ∈ [0, 1], ϵF and any k ≥ 1, the event Jk = { Vk, Vk+1/2 are ϵF -accurate estimates of f (̂xk) and f (̂xk + sk) respectively for ∆k } satisﬁes the condition P ( Jk | Fk−1/2 ) ≥ β, where Fk−1/2 denotes the σ-algebra generated by {Fi}k i=1 and {Vi, Vi+1/2} k−1 i=0 , and P(• | Fk−1/2) is a conditional probability given the past history of Fk−1/2. For the linear regression model, we introduce deﬁnitions of poised and strongly Λ-poised condition according to section 6 of [12], which will be utilized for the probabilistically fully linear property 12 and probabilistically accurate property. Recall that a trust region data set of size Nk is denoted by Tk = {(xi, ωi)}. Let ̂U k ≜    1 (x1)⊤ ... ... 1 (xNk )⊤    Deﬁnition 6. The set {xi} is poised for the linear regression model if the matrix ̂U k has full column rank. If the set {xi} is poised, then the least-square linear regression is unique. However, the condition of poisedness is not suﬃcient to derive a uniform error bounds for the convergence analysis. Under the condition of poisedness, when the number of samples is allowed to grow arbitrarily large, we introduce the strongly Λ-poisedness condition which imposes an upper bound on the Lagrangian polynomials l(z) in the ℓ2 norm. Deﬁnition 7. Let a scalar Λ > 0 and a set B ⊆ Rp be given. A poised set {xi} of size Nk is said to be strongly Λ-poised for the linear regression model in B if √Nk maxz∈B ∥ l(z) ∥ ≤ Λ, where the Lagrangian polynomials l(z) ≜ ( ̂U k)(( ̂U k)⊤ ̂U k)−1 ( 1 z ). We refer to section 6.5 in [12] on ensuring a strongly Λ-poised set for derivative-free optimization. Speciﬁcally, for the regression model, algorithm 6.7 in [12] provides an approach to compute a Λ-poised set given an initial set of points Y based on Theorem 6.3 and Algorithm 6.3 in [12]. To show that trust region models {Fk} constructed in (10) satisﬁes the α-probabilistically κ-fully linear property for α ∈ (0, 1), we need the probabilistically accurate properties of the LLR in Proposition 8 with the proof given in the Appendix. In [26], similar properties are analyzed for regression models under the strongly Λ-poised condition using the Markov inequality. Our analysis of this property is diﬀerent from theirs by using the Law of Large Numbers and Berry-Esseen Theorem under the same strongly Λ-poised condition. Proposition 8. Under assumptions (A1) and (A3), given a feasible point ̂xk ∈ X and a trust region radius δk > 0, for the data set Tk = {(xi, ωi)} of size Nk generated from line 3 in CLEO, suppose that the set {xi} is strongly Λ-poised in B(̂xk, δk) ∩ X. Let ̂Bk,1 and ̂Bk,0 be the least square estimators of the local linear regression model following (6). Then for any z ∈ B(̂xk, δk) ∩ X, we have the following results. (a) For any 0 < α < 1, there exists a constant κeg > 0 such that when Nk ≥ max{O(δ−4 k κ−2 eg ), O(α−2)}, P (∥ ∇ψ(x) − ̂Bk,1 ∥ ≤ κeg ∆k, ∀x ∈ B( ̂X k, ∆k) ∩ X | Fk−1 ) ≥ 1 − α. (b) For any 0 < α < 1, there exists a constant κef > 0, when Nk ≥ O(δ−4 k κ −2 ef α−1), P ( ∥ ψ(x) − ( ̂Bk,1)⊤x − ( ̂Bk,0)⊤ ∥ ≤ κef ∆ 2 k, ∀x ∈ B( ̂X k, ∆k) ∩ X | Fk−1 ) ≥ 1 − α. Now we establish the probabilistically fully linear property in Proposition 9 with the proof given in the Appendix. It relates the probabilistic error of TR models with the probabilistic error of 13 LLR estimators given in Proposition 8. It is worth noting that we utilize some properties of ϵ-approximate directional derivative in the proof to provide the probabilistic bound for the gap χ(x) − χk(x). Proposition 9. Suppose assumptions (A1)-(A4) hold for the composite SP problem (2). At the k-th iteration of the CLEO algorithm, given a feasible point ̂xk ∈ X and a trust region radius δk > 0, for the data set Tk = {(xi, ωi)} of size Nk generated in CLEO, suppose that the set {xi} is strongly Λ-poised in B(̂xk, δk) ∩ X. (a) There exists a constant κef > 0, when Nk ≥ max{O(δ−4 k κ −4 ef ), O(α −2)}, we have P (|f (x) − Fk(x)| ≥ κef ∆ 2 k , ∀x ∈ B(̂xk, ∆k) ∩ X | Fk−1 ) ≤ α 2 . (b) There exists a constant κed > 0, when Nk ≥ max{O(δ−2 k κ −2 ed ), O(α −2)}, we have P (χ(x) − χk(x) ≥ κed∆k, ∀x ∈ B(̂xk, ∆k) ∩ X | Fk−1 ) ≤ α 2 . From (a) and (b), we can derive that there exists a constant vector κ = (κef , κed), when Nk ≥ O(max{δ−4 k , O(α−2)}), we have P (| f (x) − Fk(x) | ≤ κef ∆ 2 k , χ(x) − χk(x) ≤ κed ∆k, ∀x ∈ B(̂xk, ∆k) ∩ X ∣ ∣ Fk−1) ≥ 1 − α. We can derive the probability accuracy of the random estimates (Vk, Vk+1/2) by using the similar analysis as in Proposition 9. So we omit the proof and present the result as follows. Proposition 10. For the composite SP problem (2) under assumptions (A1)- (A4), for the data set Tk = {(xi, ωi)} of size Nk generated in CLEO, suppose that the set {xi} is strongly Λ-poised in B(̂xk, δk) ∩ X. Then for any 0 < β < 1, there exist positive constants ϵF , and Mk(β) of order O(∆ −4 k ), such that if |Sk|, |Sk+1/2| ≥ Mk(β), then random estimates (Vk, Vk+1/2) is β- probabilistically ϵF -fully accurate with respect to B( ̂X k, ∆k). 3.2 Convergence analysis to a d-stationary point The convergence analysis serves as an extension of trust region method with random models [9] to the nonsmooth, composite, constrained stochastic programming problem. The convergence analysis is based on Proposition 9 and Proposition 10, which hold under the requirement of sample size in the trust region with the scale of constants depending on the smooth functions {hj(·)}j∈J and g(·). With a fair estimation of the constants, we assume that in the process of the CLEO algorithm, we could generate data pairs from reality or simulator so that the size of TR data sets {Tk} satisfy the requirements in Proposition 9 and Proposition 10. While this requirement may be demanding sometimes, numerical experiments in section 4 show that CLEO needs much smaller size of data than the PO scheme in achieving a suboptimal objective value. Hence, we assume the following assumption on the sample size requirement for the sake of the theoretical convergence analysis. (B) Suppose for some chosen probability parameters α and β, for any given positive number k, feasible point ̂xk and trust region radius δk, we are able to generate a sample set of size in order of O(δ−4 k ) in the trust region B(̂xk, δk) ∩ X with which the TR random model Fk is α-probabilistically κ-fully linear and random value estimates (Vk, Vk+1/2) are β-probabilistically ϵF -accurate. 14 The following lemmas hold under the assumptions (A1)-(A4). So for the sake of brevity, we will not include the assumptions in the lemmas. We ﬁrst show the guarantees of the decrease of the objective value in the composite SP problem (2). Lemma 11. Suppose that the TR model fk is κ = (κef , κed)-fully linear on B(̂xk, δk) with δk ≤ δmax. If δk ≤ 1 ( 4κef κdcp + κed) δmax χ(̂x k), (16) then a suitable step sk under (11) leads to an improvement in f (̂xk + sk) such that f (̂xk + sk) − f (̂xk) ≤ −C1χ(̂x k)δk. where C1 ≜ 2κdcp κef (4κef + κed κdcp) δmax . Proof. The deﬁnition of a κ = (κef , κed)-fully linear model yields that, χk(̂xk) ≥ χ(̂xk) − κedδk ≥ 4κef κdcp δk (17) χk(̂xk) ≥ χ(̂xk) − κedδk ≥ (1 − κed κdcp 4κef + κed κdcp ) χ(̂xk) = 4κef 4κef + κed κdcp χ(̂xk) (18) With a suitable step sk by (11) fk(̂xk) − fk(̂xk + sk) ≥ κdcp χk(̂xk) min{δk, 1} ≥ κdcp δmax χk(̂xk) δk, From the deﬁnition of a κ-fully linear model, we have f (̂xk + sk) − f (̂xk) = f (̂xk + s k) − fk(̂xk + s k) + fk(̂xk + s k) − fk(̂xk) + fk(̂xk) − f (̂xk) ≤ 2 κef δ2 k − κdcp δmax χk(̂xk) δk ≤ − κdcp 2 δmax χk(̂xk) δk, (19) where the last inequality (19) is derived from (17) that δk ≤ κdcp 4 κef ·δmax χk(̂xk). Because of (18), we have f (̂xk + s k) − f (̂xk) ≤ − 2κdcp κef (4κef + κed κdcp) δmax χ(̂xk)δk Lemma 12. Suppose that the TR model fk is κ-fully linear on B(̂xk, δk) and the estimates (vk, vk+1/2) is ϵF -accurate with κ = (κef , κed) and ϵF ≤ κef . If δk ≤ δ0, and δk ≤ min { 1 η2 , κdcp(1 − η1) 4κef δmax } χk(̂x k). where the constant η2 is the step acceptance parameter in line 10 of the CLEO algorithm, then k-th iteration is successful, i.e., the suﬃcient decrease condition ρk ≥ η1 deﬁned in (15) is achieved. 15 Proof. The trust region random function fk being (κef , κeg)-fully linear implies that | f (̂xk) − fk(̂x k) | ≤ κef δ 2 k , and | f (̂xk + s k) − fk(̂xk + s k) | ≤ κef δ 2 k . (20) Since value estimates (vk, vk+1/2) are ϵF -accurate with ϵF ≤ κef , we have | vk − f (̂xk) | ≤ κef δ2 k, and | vk+1/2 − f (̂xk + s k) | ≤ κef δ 2 k . (21) Consider the parameter ρk = vk − vk+1/2 fk(̂xk) − fk(̂xk + sk) = vk − f (̂xk) fk(̂xk) − fk(̂xk + sk) + f (̂xk) − fk(̂xk) fk(̂xk) − fk(̂xk + sk) + fk(̂xk) − fk(̂xk + sk) fk(̂xk) − fk(̂xk + sk) + fk(̂xk + sk) − f (̂xk + sk) fk(̂xk) − fk(̂xk + sk) + f (̂xk + sk) − vk+1/2 fk(̂xk) − fk(̂xk + sk) . Then | ρk − 1 | ≤ |vk − f (̂xk)| fk(̂xk) − fk(̂xk + sk) + |f (̂xk) − fk(̂xk)| fk(̂xk) − fk(̂xk + sk) + |fk(̂xk + sk) − f (̂xk + sk)| fk(̂xk) − fk(̂xk + sk) + |f (̂xk + sk) − vk+1/2| fk(̂xk) − fk(̂xk + sk) By the condition of a suitable step in (11), and inequalities (20) and (21), we have | ρk − 1 | ≤ 4 κef δmax δk κdcpχk(̂xk) ≤ 1 − η1, where the last inequality comes from the fact that δk ≤ κdcp(1−η1) 4κef δmaxχk(̂xk). Lemma 13. Suppose the function value estimates {(vk, vk+1/2)} are ϵF -accurate and ϵF < 1 2 η1 η2 κdcp δmax . If the kth iteration is successful, i.e. a trial step sk is accepted, then the improvement in f is bounded such that f (̂xk+1) − f (̂xk) ≤ −C2 δ2 k, where C2 ≜ η1 η2 κdcp δmax − 2ϵF . Proof. When k-th iteration is successful, ρk ≥ η1 and χk(̂xk) ≥ η2 δk, then vk − vk+1/2 ≥ η1 ( fk(̂xk) − fk(̂xk + sk) ) ≥ η1 κdcp χk(̂x k) min {δk, 1} ≥ η1 η2 κdcp δmax δ 2 k . 16 Since vk and vk+1/2 are ϵF -accurate, the improvement of f can be bounded as below. f (̂x k) − f (̂x k + sk) = ( f (̂xk) − vk ) + ( vk − vk+1/2 ) + ( vk+1/2 − f (̂xk + sk) ) ≥ ( η1 η2 κdcp δmax − 2ϵF ) δ2 k. Now with Lemma 11, 12, 13, we show in Proposition 14 that the probability parameters α and β can be chosen as constant values, so that the sum of trust region radii in the CLEO algorithm is ﬁnite almost surely. The speciﬁc condition for parameters α and β is illustrated in the proof of Proposition 14 in the Appendix. Furthermore, we show that the sequence of random iterates converges to a directional stationary point almost surely in Theorem 15 with the proof in the Appendix. It is worth noting that due to the constrained, composite nonsmooth trust region models, some modiﬁcations of the proofs are made based on proof of Theorem 4.11 in [9]. Proposition 14. For the composite SP (2), under the assumptions (A1)-(A4), suppose that the strongly Λ-poisedness condition holds for data sets in every trust region, and the step acceptance parameter η2 and the accuracy parameter ϵF satisfy η2 ≥ 4κef κdcp(1 − η1) , and ϵF ≤ min { κef , 1 4 η1 η2 κdcp δmax } . (22) Then the probability parameters α and β can be chosen so that if the assumption (B) holds for these values, then the sequence of trust-region radius, {∆k} generated by the CLEO algorithm satisﬁes ∑∞ k=0 ∆2 k < ∞ almost surely. Theorem 15. For the composite SP (2), under the same assumptions as in Proposition 14, the probability parameters α and β can be chosen so that if the assumption (B) holds for these values, we have limk→∞ χ( ̂X k) = 0 almost surely; moreover, the sequence of random iterates {X k} generated by the CLEO Algorithm, converges to a directional stationary point almost surely. 4 Numerical experiments In this section, we discuss the performance of the CLEO algorithm compared with the PO scheme. In the PO scheme, we ﬁrst predict the dependency of the uncertainty on decision variables using statistical learning models and then solve the SP problem equipped with prediction models. In order to make a fair comparison of the PO scheme and the CLEO algorithm, we use the L-BFGS method to solve both the approximate optimization problems in the PO scheme or the trust region subprob- lems in the CLEO scheme. The comparisons are conducted for three decision-making problems, including a nonconvex problem on synthetic data, a joint production and pricing problem on syn- thetic data and a price sensitive problem of hotel rooms on real world data. The code of the CLEO algorithm for the joint production and pricing instance is available at github.com/junyiliu99/CLEO. 4.1 A synthetic nonconvex problem We consider an SP problem as follows. minimize −4 ≤ x1 ≤ 4 −5 ≤ x2 ≤ 3 1 5 ∥ x ∥ 2 + Ẽω|x[ ̃ω2 ] (23) 17 The random variable ̃ω is a regression model of the decision variable x, i.e., ̃ω = − sin(x1)+sin(x2)+ ̃ε, and ̃ε ∼ N (0, 1). The SP problem (23) is thus a nonconvex and smooth problem. Without the knowledge of the actual relationship of ̃ω and x, we utilize the CLEO algorithm as well as the PO scheme with prediction models including Ridge Regression(RR), Support Vector Regression(SVR), and Gaussian Process(GP) with randomly generated data pairs to seek a near-optimal decision of problem (23) by proximal gradient descent (PGD). The hyperparameter tuning of these prediction models is accompalished by grid search, which means that we manually discretize the value space of hyperparameters and select the best hyperparameters in the prediction model. The parameters of prediction models are estimated by the package “scikit learn” in Python. When implementing the CLEO algorithm, the data in each neighborhood are actively generated and the data size is set to be a constant number (e.g., 10). The performance of four algorithms is evaluated with respect to two criteria: 1) a snapshot of convergence process in Figure 1(a) where red, green, blue and yellow surfaces respectively refer to the surface of ground truth objective function, objective value with the uncertainty ﬁtted by SVR, GPR and RR; 2) objective value versus the number of samples in Figure 1(b) with the same stopping criterion. These plots are produced based on a fair and careful parameter-tuning together with an average of 50 random replications. As expected, CLEO converges to a stationary point of the true objective surface with the smallest number of iterations. As indicated by Figure 1(a), the yellow surface constructed by RR model does not ﬁt well to the true one, therefore, PO scheme with RR model does not provide the convergence to any stationary point. When the sample size is large, the surface constructed by GPR is close to the true surface. As shown in Figure 1(b), the solution produced by the PO scheme with GPR has its objective value slightly higher than the one produced by CLEO. However, the derived objective values over replications in the PO scheme with GPR are more volatile than the CLEO scheme. Moreover, training a GPR model is very time-consuming when the sample size grows large. (a) Process snapshot (b) Objective value Figure 1: Comparisons of the CLEO algorithm and the PO schemes for a synthetic nonconvex problem 4.2 Joint production and pricing problem We follow the setting in the joint pricing and production example in Section 1.1 with K = 1, demand curve φ(p) = a eb−cp 1+eb−cp and the noise ̃ε ∼ U (−¯ε, ¯ε) and parameters a = 470, b = 6, c = 18 0.3, ¯ε = 0.1. We evaluate the performance of the CLEO algorithm by choosing diﬀerent sample sizes in trust regions in Figure 2. As we can see, except for the sample size of 2, CLEO algorithms with other choices of sample size have similar performance in terms of the convergence of the objective value. This indicates that the sample size requirement in the assumption (B) is for the sake of the theoretical analysis, whereas in practice the sample size in the neighborhoods could be set as a constant in the CLEO algorithm. Figure 2: Convergence curve of CLEO for the sample size chosen as 2,3,5,10,20 0 100 200 300 400 500 Number of samples 2500 2000 1500 1000 500 0 500Objective function value Global Minimum GPR+LBFGS GPR+Global Min QR+LBFGS QR+Global Min CLEO Figure 3: Convergence curve of the CLEO algorithm and the PO schemes for the joint production and pricing problem. We compare the performance of the CLEO algorithm with the PO scheme with two prediction models, GPR model and Quadratic Regression (QR) model. The blue line at the bottom of Figure 3 represents the globally minimal objective value of the true composite SP problem (3), which 19 Figure 4: Convergence curve for the price-senstive problem of hotel rooms could be taken as the ground truth. The red curve represents the objective function value at the solution derived by the CLEO algorithm with respect to the number of samples. The red curve indicates that the CLEO algorithm converges to the value slightly higher than the ground truth as the sample size increases. The performance of the PO schemes relies on the accuracy of the prediction models and the op- timality of the solution derived by the solver. To illustrate how these two parts contribute to the overall performance of the PO schemes, we compute two types of convergence curves for each PO scheme. For the approximate optimization problem composed with the GPR model, the green curve represents the globally optimal objective value and the orange curve represents the objective value at the solution derived by the L-BFGS solver. The green curve indicates that its global minimum converges to the ground truth as the sample size increases, whereas the derived solution by L-BFGS solver for the PO scheme is suboptimal with a large variance indicated by the orange curve. Since we only consider two decision variables in this instance, the global minimum of the highly noncon- vex composite problem can be found graphically. However, when the dimension is higher than 2, the gap between the orange curve and the ground truth is mainly the result of the highly noncon- vex structure of the approximate optimization problem composed with the GPR model. For the approximate optimization problem composed with the QR model, the gap between the light and dark purple curves is small and relatively stable, whereas the gap between the purple curves and the ground truth is large. This indicates that the estimation error of the latent dependency using QR models results in an unsatisfactory solution even though the composite optimization problem in the PO scheme can be solved eﬃciently. Combining the performance of two PO schemes, we can see the trade-oﬀ between the accuracy of the prediction model and the complexity of the composite optimization problem. 4.3 A pricing problem for hotel rooms We consider a pricing problem for hotel rooms. We use the hotel booking dataset from [7] which contains 17,838 booking records with check-in dates from March 12, 2007 to April 15, 2007, in one of ﬁve continental U.S. hotels. The decision variable x ∈ R3 + is the price vector corresponding to 20 three room types: King, Queen, Standard, and the demand vector ̃ω is the number of booking records for each room type. The decision-making problem is formulated as maximize x∈R3 + E ̃ω|x [ xT ̃ω ] − λ ∥ x ∥2 (24) where λ ≥ 0 is a parameter for the regularization of the price. Regardless of other market factors, the demand ω is implicitly aﬀected by the price decision x. We use the CLEO algorithm and three PO schemes with SVR, GP and RR for computing the price decision. Since the true optimization problem is unknown, the objective value at a solution is estimated by the sample average using samples within a neighborhood to the solution. In Figure 4, because of the randomness of the TR model constructed in CLEO, the performance curve mildly ﬂuctuates, but overall it dominates the other three approaches in terms of the rate of progress and the objective value for this data set. 5 Conclusions We proposed the CLEO algorithm coupling the local regression models and trust region meth- ods for solving the stochastic programming problem with the decision-dependent uncertainty. The CLEO algorithm iteratively deals with local behaviors in both estimation and optimization prob- lems to control the overall complexity with the asymptotic convergence to a stationary point with probability 1. The CLEO algorithm is then supported by computational results in simulation ex- periments and a real-world pricing problem. It shows that the CLEO algorithm outperforms the the uncoupled “Predict then Optimize” approach in terms of the convergent objective value and the associated variance. Acknowledgments. The ﬁrst and the third authors acknowledge the support of AFOSR under Grant FA9550-15-1-0267 and FA9550-20-1-0006. References [1] Victor F Araman and Ren´e Caldentey. Dynamic pricing for nonperishable products with demand learning. Operations research, 57(5):1169–1188, 2009. [2] Afonso S Bandeira, Katya Scheinberg, and Lu´ıs N Vicente. Convergence of trust-region meth- ods based on probabilistic models. SIAM Journal on Optimization, 24(3):1238–1264, 2014. [3] Dimitris Bertsimas and Nathan Kallus. From predictive to prescriptive analytics. Management Science, 2019. [4] Omar Besbes and Assaf Zeevi. Dynamic pricing without knowing the demand function: Risk bounds and near-optimal algorithms. Operations Research, 57(6):1407–1420, 2009. [5] John R Birge and Francois Louveaux. Introduction to stochastic programming. Springer Science & Business Media, 2011. 21 [6] Jose Blanchet, Coralia Cartis, Matt Menickelly, and Katya Scheinberg. Convergence rate analysis of a stochastic trust region method for nonconvex optimization. arXiv preprint arXiv:1609.07428, 2016. [7] Tudor Bodea, Mark Ferguson, and Laurie Garrow. Data set–choice-based revenue manage- ment: Data from a major hotel chain. Manufacturing & Service Operations Management, 11(2):356–361, 2009. [8] Boxiao Chen, Xiuli Chao, and Hyun-Soo Ahn. Coordinating pricing and inventory replenish- ment with nonparametric demand learning. Operations Research, 67(4):1035–1052, 2019. [9] Ruobing Chen, Matt Menickelly, and Katya Scheinberg. Stochastic optimization using a trust- region method and random models. Mathematical Programming, 169(2):447–487, 2018. [10] Wang Chi Cheung, David Simchi-Levi, and He Wang. Dynamic pricing and demand learning with limited price experimentation. Operations Research, 65(6):1722–1731, 2017. [11] Andrew R Conn, Nicholas IM Gould, and Ph L Toint. Trust region methods, volume 1. SIAM, 2000. [12] Andrew R Conn, Katya Scheinberg, and Luis N Vicente. Introduction to derivative-free opti- mization, volume 8. SIAM, 2009. [13] William L Cooper, Tito Homem-de Mello, and Anton J Kleywegt. Models of the spiral-down eﬀect in revenue management. Operations Research, 54(5):968–987, 2006. [14] Arnoud V den Boer. Dynamic pricing and learning: historical origins, current research, and new directions. Surveys in operations research and management science, 20(1):1–18, 2015. [15] John C Duchi and Feng Ruan. Stochastic methods for composite and weakly convex optimiza- tion problems. SIAM Journal on Optimization, 28(4):3229–3259, 2018. [16] Jitka Dupaˇcov´a. Optimization under exogenous and endogenous uncertainty. University of West Bohemia in Pilsen, 2006. [17] Rick Durrett. Probability: theory and examples. Cambridge university press, 2010. [18] Adam N Elmachtoub and Paul Grigas. Smart “predict, then optimize”. arXiv preprint arXiv:1710.08005, 2017. [19] Saeed Ghadimi and Guanghui Lan. Stochastic ﬁrst- and zeroth-order methods for nonconvex stochastic programming. SIAM Journal on Optimization, 23(4):2341–2368, 2013. [20] Vikas Goel and Ignacio E Grossmann. A class of stochastic programs with decision dependent uncertainty. Mathematical programming, 108(2-3):355–394, 2006. [21] Serge Gratton, Cl´ement W Royer, Lu´ıs N Vicente, and Zaikun Zhang. Complexity and global rates of trust-region methods based on probabilistic models. IMA Journal of Numerical Anal- ysis, 38(3):1579–1597, 2018. [22] Holger Heitsch and Werner R¨omisch. Scenario reduction algorithms in stochastic programming. Computational optimization and applications, 24(2-3):187–206, 2003. 22 [23] Lars Hellemo, Paul I Barton, and Asgeir Tomasgard. Decision-dependent probabilities in stochastic programs with recourse. Computational Management Science, 15(3-4):369–395, 2018. [24] Julia L Higle and Suvrajeet Sen. Finite master programs in regularized stochastic decomposi- tion. Mathematical Programming, 67(1-3):143–168, 1994. [25] Michal Kaut and Stein W Wallace. Evaluation of scenario-generation methods for stochastic programming. Paciﬁc Journal of Optimization, 3(2):257–271, 2007. [26] Jeﬀrey Larson and Stephen C Billups. Stochastic derivative-free optimization using a trust region framework. Computational Optimization and applications, 64(3):619–645, 2016. [27] Jeﬀrey Larson, Matt Menickelly, and Stefan M Wild. Derivative-free optimization methods. Acta Numerica, 28:287–404, 2019. [28] Soonhui Lee, Tito Homem-de Mello, and Anton J Kleywegt. Newsvendor-type models with decision-dependent uncertainty. Mathematical Methods of Operations Research, 76(2):189–221, 2012. [29] Jiajin Li, Anthony Man-Cho So, and Wing-Kin Ma. Understanding notions of stationarity in non-smooth optimization. arXiv preprint arXiv:2006.14901, 2020. [30] Junyi Liu and Suvrajeet Sen. Asymptotic results of stochastic decomposition for two-stage stochastic quadratic programming. SIAM Journal on Optimization, 30(1):823–852, 2020. [31] Liwan H. Liyanage and J. George Shanthikumar. A practical inventory control policy using operational statistics. Operations Research Letters, 33(4), 2005. [32] Clive Loader. Local regression and likelihood. Springer Science & Business Media, 2006. [33] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, and Alexander Shapiro. Robust stochas- tic approximation approach to stochastic programming. SIAM Journal on optimization, 19(4):1574–1609, 2009. [34] Nilay Noyan, G´abor Rudolf, and Miguel Lejeune. Distributionally robust optimization with decision-dependent ambiguity set. Optimization Online Http://www.optimization- online.org/DBHTML/2018/09/6821. html, 2018. [35] Srinivas Peeta, F Sibel Salman, Dilek Gunnec, and Kannan Viswanath. Pre-disaster in- vestment decisions for strengthening a highway network. Computers & Operations Research, 37(10):1708–1719, 2010. [36] Sashank J Reddi, Suvrit Sra, Barnabas Poczos, and Alexander J Smola. Proximal stochastic methods for nonsmooth nonconvex ﬁnite-sum optimization. In Advances in Neural Information Processing Systems, pages 1145–1153, 2016. [37] R Tyrrell Rockafellar and Roger J-B Wets. Variational analysis, volume 317. Springer Science & Business Media, 2009. [38] Suvrajeet Sen. Stochastic programming. In Encyclopedia of Operations Research and Man- agement Science, pages 1486–1497. Springer, 2013. 23 [39] Suvrajeet Sen and Yunxiao Deng. Learning enabled optimization: Towards a fusion of statis- tical learning and stochastic optimization, 2017. [40] Suvrajeet Sen and Yifan Liu. Mitigating uncertainty via compromise decisions in two-stage stochastic linear programming: Variance reduction. Operations Research, 64(6):1422–1437, 2016. [41] Alexander Shapiro, Darinka Dentcheva, and Andrzej Ruszczy´nski. Lectures on stochastic pro- gramming: modeling and theory. SIAM, 2009. 6 Appendix Lemma 16 (Berry Esseen Theorem). Let X1, X2, ..., be identitcal independent Rd-valued random vectors with E[X1] = 0 and VaR(X1) = Σ assuming that Σ is invertible. Let Z ∼ N (0, Σ) be a d-dimensional Gaussian random vector. Then for all convex sets S ∈ Rd, there exists a positive constant C such that ∣ ∣ ∣ P ( ∑n i=1 Xi √n ∈ S) − P(Z ∈ S) ∣ ∣ ∣ ≤ C d1/4n−1/2 E[ ∥Σ−1/2 X1 ∥ 3 2 ]. Proof of Proposition 8. For the trust region data set Tk, let U k ≜    (x1)⊤ ... (xNk )⊤    , ̂U k ≜    1 (x1)⊤ ... ... 1 (xNk )⊤    , W k ≜    (ω1)⊤ ... (ωNk )⊤    , ψ(U k) ≜    ψ(x1)⊤ ... ψ(xNk )⊤    . The matrix of error is deﬁned to be Ξk ≜ W k − ψ(X k). Under the poisedness condition, least square estimators of the LLR model are unique and can be written in matrix form. ( ̂Bk,0 ̂Bk,1 ) = (( ̂U k)⊤ ̂U k)−1 ( ̂U k) ⊤ W k (25) Under (A1) and (A3), by the Taylor’s expansion of ψ at z ∈ B(̂xk, δk) ∩ X, we derive ψ(xi) = ψ(z) + ∇ψ(z)⊤(xi − z) + O(L2 δ 2 k ) 1m, ∀i = 1, . . . , |Tk|. We rewrite the Taylor’s expansion in the matrix form. ψ(U k) = 1Nk ψ(z) ⊤ + (U k − 1Nk z⊤) ∇ψ(z) + O(L2 δ 2 k ) 1Nk×m = ̂U k ( ψ(z)⊤ − z⊤∇ψ(z) ∇ψ(z) ) + O(L2 δ 2 k ) 1Nk×m. Under the poisedness condition, we derive ( ψ(z)⊤ − z⊤∇ψ(z) ∇ψ(z) ) = (( ̂U k)⊤ ̂U k)−1 ( ̂U k)⊤ (ψ(U k) + O(L2 δ 2 k ) 1Nk×m) (26) 24 By subtracting (26) from the LLR estimation (25), we derive ( ̂Bk,0 ̂Bk,1 ) − ( ψ(z)⊤ − z⊤∇ψ(z) ∇ψ(z) ) = (( ̂U k)⊤ ̂U k)−1 ( ̂U k)⊤ (Ξ k + O(L2 δ 2 k ) 1Nk×m) (27) The above equation (27) provides the estimates for the gap ∇ψ(z) − ̂Bk,1 and ψ(z) − ( ̂Bk,0)⊤ − ∇ψ(z)⊤z. Next we consider the asymptotical convergence of two LLR estimators, ∇ψ(z) − ̂Bk,1 and ψ(z) − ( ̂Bk,0)⊤ − ( ̂Bk,1)⊤z on B(̂xk, δk) ∩ X respectively. (a) Let ¯x = ∑Nk i=1 xi/Nk, and ¯U k ≜ (INk − 1 Nk 1Nk×Nk ) U k =    (x1 − ¯x)⊤ ... (xNk − ¯x)⊤   . Let ̂Ip ≜ (0p×1, Ip). From the inverse of block matrix ( ̂U k)⊤ ̂U k, we derive that, ̂Ip (( ̂U k) ⊤ ̂U k)−1 ( ̂U k) ⊤ = (0p×1, Ip) ( ∗ ∗ Ck Dk ) ( 1 ⊤ Nk ( ̂U k)⊤ ) = Ck 1 ⊤ Nk + Dk ( ̂U k) ⊤ = (( ¯U k) ⊤ ¯U k)−1 ( ¯U k) ⊤ where ∗ represents the matrices on the ﬁrst row of the matrix, and Ck ≜ − 1 Nk Dk ( ̂U k)⊤1Nk = − 1 Nk (( ¯U k)⊤ ¯U k)−1 ( ̂U k)⊤1Nk Dk ≜ [ ( ̂U k) ⊤ ̂U k − 1 Nk ( ̂U k)⊤1Nk 1 ⊤ Nk ̂U k]−1 = (( ¯U k) ⊤ ¯U k) −1. By (27) we derive ∇ψ(z) − ̂Bk 1 = ̂Ip (( ̂U k) ⊤ ̂U k)−1 ( ̂U k) ⊤Ξ k + O(L2 δ 2 k ) ̂Ip (( ̂U k) ⊤ ̂U k)−1 ( ̂U k) ⊤1Nk×m = (( ¯U k)⊤ ¯U k)−1 ( ¯U k)⊤Ξ k + O(L2 δ 2 k ) (( ¯U k)⊤ ¯U k)−1 ( ¯U k)⊤1Nk×m = 1 δk (( ̃U k) ⊤ ̃U k)−1 ( ̃U k) ⊤Ξ k where ̃U k ≜ ¯U k/δk. According to the construction of {xi} at line 3 in CLEO algorithm, ̃U k =    (̃u1 − ¯u)⊤ ... (̃uNk − ¯u)⊤    where each ̃ui is independently sampled from U(B(0p, 1)) for i = 1, . . . , Nk and ¯u = 1 Nk ∑Nk i=1 ui. Now we show that the matrix (( ̃U k)⊤ ̃U k)−1 ( ̃U k)⊤Ξk asymptotically converges in distribution. By the Law of Large Numbers, 1 Nk ( ̃U k)⊤ ̃U k→Vu almost surely where Vu ≜ Ẽx [̃u ̃u⊤] and ̃u ∼ U(B(0p, 1)). By Theorem 2.57 in [17], 1 Nk ( ̃U k)⊤ ̃U k converges with the rate of o(N −1/2 k ). By the Berry-Esseen Theorem, there exists a constant C such that with the rate of CN −1/2 k , we have 1 √Nk ( ̃U k) ⊤Ξ k d → MN p×m(0, Vu, Σ), as Nk → ∞. 25 By the Slutsky’s Theorem, with the rate of O(N −1/2 k ), √Nk (( ̃U k) ⊤ ̃U k)−1 ( ̃U k) ⊤Ξ k d → MN p×m(0, V −1 u , Σ), as Nk → ∞. (28) Let H1 ∼ MN p×m(0, V −1 u , Σ) be a random matrix and let Ψ1 be a cumulative probability distribu- tion of ∥H1∥. For any 0 < α < 1, there exists a constant κeg > 0, when Nk ≥ max { δ −4 k (Ψ1(1 − α/2))2κ −2 eg , 4C 2α−2) }, we have P ( ∥∇ψ(z) − ̂Bk,1 ∥ ≥ κeg∆k, ∀z ∈ B( ̂X k, ∆k) ∩ X ∣ ∣ Fk−1 ) ≤ P ( ∥ (∆k) −1 (( ̃U k) ⊤ ̃U k)−1 ( ̃U k)⊤Ξ k∥ ≥ κeg∆k | Fk−1 ) ≤ P ( 1 √Nk ∥H1∥ ≥ κeg(∆k)2 ∣ ∣ Fk−1 ) + CN −1/2 k ≤ α/2 + α/2 = α. (b) Consider ψ(z) − ( ̂Bk,1) ⊤z − ( ̂Bk,0) ⊤ = [ψ(z) − ∇ψ(z)⊤z − ( ̂Bk,0)⊤] + (∇ψ(z) − ̂Bk,1)⊤z = ( ψ(z)⊤ − z⊤∇ψ(z) − ̂Bk,0 ∇ψ(z) − ̂Bk,1 )⊤ ( 1 z ) = − (Ξ k) ⊤( ̂U k) (( ̂U k) ⊤ ̂U k)−1 ( 1 z ) ︸ ︷︷ ︸ T 1 +O( δ 2 k ) 1m×Nk ( ̂U k) (( ̂U k)⊤ ̂U k)−1 ( 1 z ) ︸ ︷︷ ︸ T 2 (29) By deﬁnition 7, l(z) = ( ̂U k)(( ̂U k)⊤ ̂U k)−1 ( 1 z ). Under the strong poisedness condition, we have √Nk maxz∈B ∥ l(z) ∥ ≤ Λ. Therefore, E [∥ T1 ∥2 ] = E [ ∥ (Ξk)⊤l(z) ∥2 ] ≤ ∑Nk i=1 E [ ∥ εi ∥2] · E [ | li(z) |2] ≤ Λ2 Nk E[ ∥ ̃ε ∥2] ∥ T2 ∥ = ∥ 1m×Nk l(z) ∥ = √m |1⊤ Nk l(x)| ≤ √Nk √m ∥ l(x) ∥ ≤ Λ√m. From the Markov’s Inequality, there exists a constant C such that P ( ∥ ψ(z) − ( ̂Bk,1)⊤z − ( ̂Bk,0)⊤ ∥ ≥ κef ∆2 k, ∀z ∈ B( ̂X k, ∆k) ∩ X ∣ ∣ Fk−1) ≤ P ( ∥T1∥ + C ∆ 2 k ∥T2∥ ≥ κef ∆ 2 k , ∀z ∈ B( ̂X k, ∆k) ∩ X ∣ ∣ Fk−1) ≤ P ( ∥T1∥ ≥ (κef − CΛ√m)∆ 2 k , ∀z ∈ B( ̂X k, ∆k) ∩ X ∣ ∣ Fk−1) ≤ E [ ∥T1∥2 ] (κef − CΛ √m)2 δ 4 k ≤ Λ2E[ ∥ ̃ε ∥2] Nk(κef − CΛ √m)2 δ 4 k . 26 Therefore for any 0 < α < 1, there exists a constant κef > 0, when Nk ≥ O(δ−4 k κ−2 ef α−1), the statement (b) holds. □ We need the following lemma for the proof of Proposition 9. Lemma 17. With a ﬁnite index set J , for each j ∈ J , suppose hj(·) : Z ⊆ Rn → R is a smooth convex function on a compact set Z. Let h(z) ≜ maxj∈J hj(z). For any z ∈ Z, A(z) ≜ {j ∈ J : hj(z) ≥ h(z)}, Aϵ(z) ≜ {j ∈ J : hj(z) ≥ h(z) − ϵ} for any ϵ > 0, and L1 ≜ max{ ∥ ∇hj(z) ∥ : j ∈ J , z ∈ Z }. For any z ∈ Z, any δ ≥ 0, any z ′ ∈ B (z, δ) and any ϵ ≥ 2L1δ, we have A(z ′) ⊆ Aϵ(z). Proof. For the max of convex functions, this lemma establishes the relation between the active index set A(z ′) and ϵ-active index set Aϵ(z) for any z ′ ⊆ B(z, δ) with an appropriate choice of ϵ. Speciﬁcally, for any z ∈ Z, any δ ≥ 0 and any z ′ ∈ B (z, δ), we have for each j ∈ A(z ′), hj(z) = h(z) − h(z) + h(z ′) − h(z ′) + hj(z ′) − hj(z ′) + hj(z) ≥ h(z) − 2Lδ. Hence j ∈ Aε(z) and A(z ′) ⊆ Aε(z). Proof of Proposition 9. For each (xi, ωi), let εi ≜ ωi − ψ(xi) and the residual of LLR model is ek,i ≜ ωi − ( ̂Bk,1)⊤xi − ( ̂Bk,0)⊤ = ψ(xi) − ( ̂Bk,1)⊤xi − ( ̂Bk,0)⊤ + εi. For any z ∈ B(̂xk, δk) ∩ X, ∣ ∣ f (z) − fk(z) ∣ ∣ ≤ ∣ ∣ ∣ Ẽε [ h(z, ψ(z) + ̃ε ) ] − 1 Nk ∑Nk i=1 h(z, ψ(z) + εi ) ∣ ∣ ∣ + ∣ ∣ ∣ 1 Nk ∑Nk i=1 h(z, ψ(z) + εi) − 1 Nk ∑Nk i=1 h(z, mk(z, ek,i)) ∣ ∣ ∣ + ∣ ∣ ∣ Ẽε [ g(z, ψ(z) + ̃ε ) ] − 1 Nk ∑Nk i=1 g(z, ψ(z) + εi ) ∣ ∣ ∣ + ∣ ∣ ∣ 1 Nk ∑Nk i=1 g(z, ψ(z) + εi) − 1 Nk ∑Nk i=1 g(z, mk(z, ek,i)) ∣ ∣ ∣ ≤ |τk(z)| + |ξk(z)| + 2L1 max z∈B( ̂X k,∆k)∩X ∥ ψ(z) − ( ̂Bk,1)⊤z − ( ̂Bk,0)⊤ ∥ where τk(z) ≜ Ẽε [ h(z, ψ(z) + ̃ε ) ] − 1 Nk ∑Nk i=1 h(z, ψ(z) + εi ), ξk(z) ≜ Ẽε [ g(z, ψ(z) + ̃ε ) ] − 1 Nk ∑Nk i=1 g(z, ψ(z) + εi ), and L1 is the Lipschitz continuous modulus for functions h(z, ·) and g(z, ·). Consider the stochastic process Fk given Fk−1. P ( |f (z) − fk(z)| ≥ κef ∆ 2 k , ∀z ∈ B( ̂X k, ∆k) ∩ X | Fk−1 ) ≤ P ( |τk(z)| ≥ 1 3 κef ∆ 2 k , ∀z ∈ B( ̂X k, ∆k) ∩ X | Fk−1 ) + P (|ξk(z)| ≥ 1 3 κef ∆ 2 k , ∀z ∈ B( ̂X k, ∆k) ∩ X | Fk−1 ) + P ( 2L1 max z∈B( ̂X k,∆k)∩X ∥ ψ(z) − ( ̂Bk,1) ⊤z − ( ̂Bk,0) ⊤ ∥ ≥ 1 3 κef ∆ 2 k | Fk−1 ) (30) 27 Since {εi} are iid samples of the bounded random variable ̃ε, the Berry-Esseen Theorem implies that with the rate O(1/√Nk), we have √Nk τk(z) d → N (0, Vh(z)) where Vh(z) = V ar̃ε (h(z, ψ(z) + ̃ε)). Similarly, with rate O(1/√Nk), we have √ Nk ξk(z) d → N (0, Vg(z)) where Vg(z) = V ar̃ε (g(z, ψ(z)+ ̃ε)). Moreover, with Proposition 8, there exists a constant κef > 0, when Nk ≥ max{O(δ−4 k κ −4 ef ), O(α −2)}, each term on the right-hand side of (30) is bounded by α/6. Therefore, we establish part (a). For part (b), we denote ∂γh(x, ω) the γ-subdiﬀerential of the convex function h for any γ > 0, i.e., ∂γh(x, ω) ≜ {(q1, q2) ∈ Rm+p : h(x ′, ω ′) ≥ h(x, ω) + q⊤ 1 (x ′ − x) + q⊤ 2 (ω ′ − ω) − γ}. The γ-directional derivative of h(x, ω) with the direction (d1, d2) ∈ Rm+p is deﬁned as h ′ γ((x, ω); (d1, d2)) ≜ max{ d ⊤ 1 q1 + d ⊤ 2 q2 : (q1, q2) ∈ ∂γh(x, ω) }. Moreover, we denote an γ-approximate directional derivative based on the γ-subdiﬀerential by ̂χϵ(x). ̂χγ(x) ≜ ∣ ∣ ∣ min x + d ∈ X ∥ d ∥ ≤ 1 ( ∇c(x)⊤d + Ẽε [ h ′ γ((x, ψ(x) + ̃ε ); (d, ∇ψ(x)⊤d)) ] + Ẽε[ g ′((x, ψ(x) + ̃ε ); (d, ∇ψ(x)⊤d)) ], ) ∣ ∣ ∣. (31) Let κL ≜ 2κef · max{ ∥ ∇hj(x, ω) ∥ : j ∈ J , (x, ω) ∈ X × Ω } and ¯ϵk ≜ κLδ 2 k . For any x ∈ B(̂xk, δk) ∩ X, let ¯dk be the optimal direction in deﬁning ̂χ¯ϵk (x). Then χ(x) − χk(x) ≤ ̂χ¯ϵk (x) − χk(x) ≤ f ′ k (x; ¯dk) −   ∇c(x)⊤ ¯dk + Ẽε [ h ′ ¯ϵk ((x, ψ(x) + ̃ε ); ( ¯dk, ∇ψ(x)⊤ ¯dk))] + Ẽε[ g ′ ((x, ψ(x) + ̃ε ); ( ¯dk, ∇ψ(x)⊤ ¯dk)) ],   = 1 Nk Nk∑ i=1 ( h ′((x, mk(x, e k,i ); ( ¯dk, ( ̂Bk,1)⊤ ¯dk)) + g ′((x, mk(x, e k,i )); ( ¯dk, ( ̂Bk,1)⊤ ¯dk)) ) −Ẽε [ h ′ ¯ϵk ((x, ψ(x) + ̃ε ); ( ¯dk, ∇ψ(x)⊤ ¯dk)) + g ′ ((x, ψ(x) + ̃ε ); ( ¯dk, ∇ψ(x)⊤ ¯dk)) ] = ηk1(x) + ηk2(x) + γk1(x) + γk2(x), where ηk1(x) ≜ −Ẽε [ h ′ ¯ϵk ((x, ψ(x) + ̃ε ); ( ¯dk, ∇ψ(x)⊤ ¯dk) )] + 1 Nk Nk∑ i=1 h ′ ¯ϵk ((x, ψ(x) + εi ); ( ¯dk, ∇ψ(x) ⊤ ¯dk) ) , ηk2(x) ≜ 1 Nk Nk∑ i=1 h ′((x, mk(x, e k,i)); ( ¯dk, ( ̂Bk,1)⊤ ¯dk )) − 1 Nk Nk∑ i=1 h ′ ¯ϵk ((x, ψ(x) + εi ); ( ¯dk, ∇ψ(x) ⊤ ¯dk)) , γk1(x) ≜ −Ẽε [ g ′ ((x, ψ(x) + ̃ε ); ( ¯dk, ∇ψ(x) ⊤ ¯dk)) ] + 1 Nk Nk∑ i=1 g ′ ((x, ψ(x) + εi ); ( ¯dk, ∇ψ(x)⊤ ¯dk)), γk2(x) ≜ 1 Nk Nk∑ i=1 g ′((x, mk(x, e k,i )); ( ¯dk, ( ̂Bk,1) ⊤ ¯dk)) − 1 Nk Nk∑ i=1 g ′ ((x, ψ(x) + εi ); ( ¯dk, ∇ψ(x) ⊤ ¯dk)). 28 By the Berry-Esseen Theorem, since ̃ε is a bounded random variable, we can derive that √Nkηk1(x) and √Nkγk1(x) converge in distribution to a normal distribution with the rate O(1/√Nk) uniformly for all x ∈ B(̂xk, δk) ∩ X. We then bound ηk2(x). From Proposition 8, for any 0 < α < 1, for any Nk ≥ max{O(δ−4 k κ−2 eg ), O(α−2), O(δ−4 k κ −2 ef α−1)}, we have P   ∥ ∥ ∥ ψ(x) − ( ̂Bk,1)⊤x − ( ̂Bk,0)⊤ ∥ ∥ ∥ ≤ κef ∆2 k, ∥ ∥ ∥ ∇ψ(x) − ̂Bk,1 ∥ ∥ ∥ ≤ κeg∆k, ∀x ∈ B( ̂X k, ∆k) ∩ X ∣ ∣ ∣ Fk   ≥ 1 − α/8. (32) Based on the deﬁnition, we know that h ′ ¯ϵk ((x, ψ(x) + εi ); ( ¯dk, ∇ψ(x)⊤ ¯dk)) = max { ¯d⊤ k q1 + ¯d⊤ k ∇ψ(x) q2 : (q1, q2) ∈ ∂ ¯ϵk h(x, ψ(x) + εi )} , h ′((x, mk(x, ek,i) ); ( ¯dk, ( ̂Bk,1)⊤ ¯dk)) = max { ¯d⊤ k q1 + ¯d⊤ k ̂Bk,1 q2 : (q1, q2) ∈ ∂ h(x, mk(x, ek,i) ) } . For the max of convex functions, it is known that ∂h(x, ω) = conv{∇hj(x, ω) : j ∈ A(x, ω)} and conv{∇hj(x, ω) : j ∈ Aϵ(x, ω)} ⊆ ∂ϵh(x, ω) for any ϵ > 0. Since ∥ ∥ ∥ ψ(x) + εi − mk(x, e k,i) ∥ ∥ ∥ ≤ ∥ ∥ ∥ ψ(x) − ( ̂Bk,1)⊤x − ( ̂Bk,0) ⊤ ∥ ∥ ∥ + ∥ ∥ ∥ ψ(xi) − ( ̂Bk,1)⊤xi − ( ̂Bk,0)⊤ ∥ ∥ ∥ , from Lemma 5, under the condition that the event in (32) holds, for any x ∈ B(̂xk, δk) ∩ X, A(x, mk(x, e k,i) ) ⊆ A¯ϵk (x, ψ(x) + εi ) ∀i = 1, . . . , Nk. Hence, under the same condition, for any x ∈ B(̂xk, δk) ∩ X, we can derive that ηk2(x) ≤ 1 Nk Nk∑ i=1 max j∈A(x,mk(x,ek,i)) { ¯d ⊤ k ∇1hj(x, mk(x, e k,i) ) + ¯d ⊤ k ̂Bk,1 ∇2hj(x, mk(x, e k,i) ) } − 1 Nk Nk∑ i=1 max j∈A¯ϵk (x,ψ(x)+εi ) { ¯d ⊤ k ∇1hj(x, ψ(x) + εi ) + ¯d ⊤ k ∇ψ(x) ∇2hj(x, ψ(x) + εi ) } ≤ 1 Nk Nk∑ i=1 max j∈J ∥ ∥ ∥ ∇1hj(x, mk(x, e k,i) ) − ∇1hj(x, ψ(x) + εi) ) ∥ ∥ ∥ + 1 Nk Nk∑ i=1 max j∈J ∥ ∥ ∥ ( ̂Bk,1) ∇2hj(x, mk(x, e k,i)) − ∇ψ(x) ∇2hj(x, ψ(x) + εi ) ∥ ∥ ∥ ≤ 2 (L1L2 + L2) max x∈B(̂xk,δk)∩X ∥ ∥ ∥ ψ(x) − ( ̂Bk,1)⊤x − ( ̂Bk,0)⊤ ∥ ∥ ∥ + L1∥ ∇ψ(x) − ̂Bk,1∥. For the term γk2(x), we derive for any x ∈ B(̂xk, δk) ∩ X, γk2(x) = 1 Nk ∑Nk i=1 [ −g ′ ((x, ψ(x) + ε i ); ( ¯dk, ∇ψ(x)⊤ ¯dk)) + g ′((x, mk(x, e k,i); ( ¯dk, ∇ψ(x)⊤ ¯dk)) ] + 1 Nk ∑Nk i=1 [ −g ′((x, mk(x, e k,i); ( ¯dk, ∇ψ(x)⊤ ¯dk)) + g ′((x, mk(x, e k,i )); ( ¯dk, ( ̂Bk,1)⊤ ¯dk)) ] ≤ 2(L2 + L1L2) max x∈B(̂xk,δk)∩X ∥ ∥ ∥ ψ(x) − ( ̂Bk,1)⊤x − ( ̂Bk,0)⊤ ∥ ∥ ∥ + L1 ∥ ∥ ∥ ∇ψ(x) − ̂B k,1 ∥ ∥ ∥ , where L1 is the Lipschitz continuity modulus and L2 is the Lipschitz gradient modulus of the function g. Now we can combine the bounds of ηk,1, ηk,2, γk,1, and γk,2. Consider the stochastic 29 process Fk given Fk−1. With Proposition 8, there exists a constant κed > 0, such that for any Nk ≥ max{O(δ−4 k κ −2 ed α−1), O(α −2)}, we have P (χ(x) − χk(x) ≥ κed∆k, ∀x ∈ B(̂xk, ∆k) ∩ X | Fk−1 ) ≤ P (̂χ¯ϵk (x) − χk(x) ≥ κed∆k, ∀x ∈ B(̂xk, ∆k) ∩ X | Fk−1 ) ≤ P (ηk1(x) + ηk2(x) + γk1(x) + γk2(x) ≥ κed∆k, ∀x ∈ B(̂xk, ∆k) ∩ X | Fk−1 ) ≤ P (ηk1(x) ≥ 1 4 κed∆k, ∀x ∈ B(̂xk, ∆k) ∩ X | Fk−1 ) + P (ηk2(x) ≥ 1 4 κed∆k, ∀x ∈ B(̂xk, ∆k) ∩ X | Fk−1 ) + P (γk1(x) ≥ 1 4 κed∆k, ∀x ∈ B(̂xk, ∆k) ∩ X | Fk−1 ) + P (γk2(x) ≥ 1 4 κed∆k, ∀x ∈ B(̂xk, ∆k) ∩ X | Fk−1 ) ≤ 4 · α 8 = α 2 , which establishes part (b). Combining the results in (a) and (b), we have for any 0 < α < 1, there exists a constant vector κ = (κef , κed), for any Nk ≥ max{O(δ−4 k κ −2 ed α−1), O(δ−4 k κ −2 ef ), O(α −2)} we have P (| f (x) − Fk(x) | ≤ κef ∆ 2 k , χ(x) − χk(x) ≤ κed ∆k, ∀x ∈ B(̂x k, ∆k) ∩ X ∣ ∣ Fk−1) ≥ 1 − α, which establishes the statement. □ Proof of Proposition 14. The proof of this result is similar to Theorem 4.11 in [9] except that ∥ ∇f (̂xk) ∥ in the last reference for smooth functions need to be replaced by χ(̂xk), the nonsmooth counterpart. Due to this change, we present the proof with several modiﬁcations here. Deﬁne the random function Φk = νf ( ̂Xk) + (1 − ν)(∆2 k − ∆k) where ν ∈ (0, 1) satisfying ν 1 − ν > max { 4γ 2 ζC1 , 4γ 2 C2 , γ2 C3 } , (33) where C1 and C2 are deﬁned in Lemma 11 and Lemma 13. The goal of the analysis is to show that there exists constants τ > 0 such that for all k E [Φk+1 − Φk | Fk−1] ≤ −τ ∆2 k < 0. (34) Since f is bounded from below by assumption, and ∆k ∈ [0, δmax], Φk is bounded from below for all k. By summing over the above inequality over k and taking expectations on both sides, we can conclude that ∑∞ k=0 ∆k is ﬁnite almost surely. To show (34) holds for every iteration, we discuss 2 cases depending on whether χ(̂xk) ≥ ζδk or not, where ζ ≥ δmax κed + max {η2, 4κef δmax κdcp(1 − η1) } . Within each of these cases, there are 4 combined outcomes of the event Ik and Jk as deﬁned in Deﬁnition 3 and 5 with diﬀerent probabilities. For each outcome we develop an upper bound of the diﬀerence φk+1 − φk where φk denotes the outcome of Φk. Then we bound E[Φk+1 − Φk | Fk−1] by combining the bounds of 4 outcomes, which results in (34) for all iterations. We only analyze one case that χ(̂xk) ≥ ζδk to obtain (34), since the analysis of the other case can be completed with similar modiﬁcations based on the proof of Theorem 4.11 in [9]. 30 We ﬁrst analyze φk+1 − φk for successful and unsuccessful iterations respectively. For all successful iterations, xk+1 = xk + sk and δk+1 = γ δk with γ > 1, hence, φk+1 − φk = ν(f (̂xk+1) − f (̂xk)) + (1 − ν)(γ2 − 1)δ 2 k + (1 − ν)(1 − γ)δk. (35) For all unsuccessful iterations, xk+1 = xk and δk+1 = δk/γ, hence φk+1 − φk = (1 − ν) ( 1 γ2 − 1) δ 2 k + (1 − ν) ( 1 − 1 γ ) δk ≜ b1. (36) We now analyze the case when χ(̂xk) ≥ ζ δk. (a) Ik and Jk are both true, i.e., the model fk is κ = (κef , κed)-fully linear and the estimates vk and vk+1/2 are ϵF -accurate. With η1 ∈ (0, 1), we have χ(̂xk) ≥ (κed + 4κef κdcp ) δmax δk. So the condition (16) in Lemma 11 holds, and the trial step sk lead to a decrease of f such that f (̂xk + sk) − f (̂xk) ≤ −C1 χ(̂x k) δk, where C1 ≜ 2κdcp κef (4κef + κed κdcp) δmax as deﬁned in Lemma 11. Moreover, since ϵF ≤ κef and χk(̂xk) ≥ χ(̂xk) − κed δk ≥ (ζ − κeg ) δk ≥ max {η2, 4 κef δmax κdcp(1 − η1) } δk, the condition in Lemma 12 holds. Hence k-th iteration is a successful, i.e., ̂xk+1 = ̂xk + sk and δk+1 = γ δk. This indicates that φk+1 − φk ≤ −ν C1 χ(̂xk) δk + (1 − ν)(γ2 − 1) δ 2 k + (1 − ν)(1 − γ)δk ≜ b2. (37) (b) Ik is true and Jk is false, under which Lemma 11 holds. If the iteration is successful, we can obtain (37). If the iteration is unsuccessful, we can obtain (36). The right-hand side of (37) is strictly smaller than the right-hand side of (36), i.e., b2 − b1 ≤ −ν C1 ζδ 2 k + (1 − ν)δ 2 k ( γ2 − 1 γ2 ) + (1 − ν)δk ( 1 γ − γ) < 0, when ν 1 − ν ≥ 4 γ2 C1ζ . Therefore, whether the iteration is successful or not, (36) holds, and we have φk+1 − φk ≤ (1 − ν) ( 1 γ2 − 1) δ 2 k + (1 − ν) ( 1 − 1 γ ) δk. (38) (c) Ik is false and Jk is true. If the iteration is successful, since Lemma 13 holds with the condition on ϵF , we have f (̂x k+1) − f (̂xk) ≤ −C2δ 2 k , with C2 ≜ η1η2 κdcp δmax − 2ϵF . Hence, in the case when the iteration is successful, we have φk+1 − φk ≤ −νC2δ 2 k + (1 − ν)(γ2 − 1) δ 2 k + (1 − ν)(1 − γ)δk ≜ b3. 31 If the iteration is unsuccessful, we can obtain (36), which is strictly larger than b3 as ν 1 − ν ≥ 4 γ2 C2 . Therefore, whether the iteration is successful or not, (36) holds, and we have φk+1 − φk ≤ (1 − ν) ( 1 γ2 − 1) δ 2 k + (1 − ν) ( 1 − 1 γ ) δk. (39) (d) Ik and Jk are both false, which can cause the algorithm to accept a bad step and lead to an increase in both f and δ. This part diﬀers from the analysis in [9] due the nonsmoothness of the function h. f (̂xk + sk) − f (̂xk) = (c(̂xk + sk) − c(̂xk) ) + Ẽε [ g(̂xk + sk, ψ(̂xk + sk) + ̃ε ) − g(̂xk, ψ(̂xk) + ̃ε ) ] +Ẽε [ max j∈J {hj(̂xk + sk, ψ(̂xk + sk) + ̃ε )} − max j∈J {hj(̂xk, ψ(̂xk) + ̃ε )}] Since both c and g are smooth functions with Lipschitz gradient modulus L2, by the Taylor’s expansion, we have c(̂x k + sk) − c(̂xk) ≤ ∇c(̂xk + s k) ⊤sk + 1 2 L2 δ 2 k ≤ L1δk + L2 2 δ 2 k , (40) and for each realization ε, g(̂x k + sk, ψ(̂xk + sk) + ε) − g(̂xk, ψ(̂xk) + ε) ≤ ∇1g(̂xk + sk, ψ(̂xk + s k) + ε) ⊤sk + ∇2 g(̂xk + sk, ψ(̂xk + s k) + ε) ⊤(ψ(̂xk + sk) − ψ(̂xk)) + L2 2 ∥ ∥ ∥ ψ(̂xk + sk) − ψ(̂xk) ∥ ∥ ∥ 2 + L2 2 δ2 k ≤ L1(1 + L1) δk + L 2 1 L2 + L2 2 δ2 k (41) where the last second inequality is derived from the Lipschitz continuity and Lipschitz gradient property of g and ψ. Now we bound the nonsmooth part involving maxj∈J hj(x, ω). For each realization ε, since hj are convex functions, we have max j∈J {hj(̂x k + sk, ψ(̂xk + sk) + ε )} − max j∈J {hj(̂xk, ψ(̂xk) + ε )} ≤ q⊤ 1 sk + q⊤ 2 (ψ(̂xk + sk) − ψ(̂xk)) + L2 2 ∥ ∥ ∥ ψ(̂x k + sk) − ψ(̂xk) ∥ ∥ ∥ 2 + L2 2 δ2 k ≤ L1(1 + L1) δk + L 2 1 L2 + L2 2 δ 2 k , (42) where q1 ∈ ∂1h(̂xk + sk, ψ(̂xk + sk) + ε), q2 ∈ ∂2h(̂xk + sk, ψ(̂xk + sk) + ε). Hence, f (̂xk + sk) − f (̂xk) ≤ (3L1 + 2L 2 1 )δk + 2L 2 1 L2 + 3L2 2 δ 2 k . If the iteration is successful, with C3 ≜ (3L1 + 2L 2 1 ), C4 ≜ 2L 2 1 L2 + 3L2 2ζ and χ(̂xk) ≥ ζ δk, we have φk+1 − φk ≤ ν C3 δk + ν C4χ(̂xk) δk + (1 − ν)(γ2 − 1) δ 2 k + (1 − ν)(1 − γ) δk. (43) 32 If the iteration is unsuccessful, we can obtain (36), which is strictly smaller than the right-hand side of (43) as ν 1 − ν ≥ γ2 C3 . Therefore, whether the iteration is successful or not, (43) holds. Now with the bounds of the diﬀerences φk+1 − φk for all 4 outcomes of {Ik, Jk}, we have E [Φk+1 − Φk | Fk−1] ≤ α β [ −ν C1 χ( ̂X k) ∆k + (1 − ν)(γ2 − 1) ∆ 2 k + (1 − ν)(1 − γ)∆k] +(α(1 − β) + β(1 − α)) [(1 − ν) ( 1 γ2 − 1 ) ∆ 2 k + (1 − ν) ( 1 − 1 γ ) ∆k ] +(1 − α)(1 − β) [ ν C3∆k + ν C4χ( ̂X k) ∆k. + (1 − ν)(γ2 − 1)∆ 2 k + (1 − ν) (1 − γ) ∆k] = (−ν αβ C1 + (1 − α)(1 − β) ν C4) χ( ̂X k) ∆k + (1 − α)(1 − β)ν C3 ∆k + ( αβ − 1 γ 2 (α(1 − β) + (1 − α)β) + (1 − α)(1 − β) ) (1 − ν)(γ 2 − 1)∆ 2 k − ( αβ − 1 γ (α(1 − β) + (1 − α)β) + (1 − α)(1 − β) ) (1 − ν)(γ − 1)∆k. Since αβ − 1 γ 2 (α(1 − β) + (1 − α)β) + (1 − α)(1 − β) ≤ (α + (1 − α))(β + (1 − β)) = 1, αβ − 1 γ (α(1 − β) + (1 − α)β) + (1 − α)(1 − β) ≥ (α − (1 − α))(β − (1 − β)) = (2α − 1)(2β − 1), we have E [Φk+1 − Φk | Fk−1] ≤ (−αβ C1 + (1 − α)(1 − β) C4) ν χ( ̂X k)∆k + (1 − ν)(γ 2 − 1)∆ 2 k + ( (1 − α)(1 − β)ν C3 − (2α − 1)(2β − 1)(1 − ν)(γ − 1)) ∆k. By choosing parameters α and β close to 1 satisfying αβ − 1 2 (1 − α)(1 − β) ≥ C4 C1 , and (2α − 1)(2β − 1) (1 − α)(1 − β) ≥ ν C3 (1 − ν)(γ − 1) , (44) we have E [Φk+1 − Φk | Fk−1] ≤ (− 1 2 C1νζ + (1 − ν)(γ 2 − 1) ) ∆ 2 k ≤ − 1 4 C1 ν ζ∆ 2 k , where the last inequality is due to ν 1 − ν > 4γ 2 ζC1 from (33). Similar bound can be derived for the case χ(̂xk) ≤ ζδk. By summing it up for all iterations, it can be proved that ∑∞ k=0 ∆ 2 k < ∞ almost surely. □ Proof of Theorem 15. As an extension of Theorem 4.16 in [9], we can derive the liminf con- vergence result that lim inf k→∞ χ( ̂X k) = 0 almost surely under the assumptions in Proposition 14. 33 We omit the proof for this liminf convergence result since it only needs to replace ∥∇f ( ̂Xk)∥ in the proof of Theorem 4.16 [9] with χ( ̂Xk). Regarding the convergence result that limk→∞ χ( ̂X k) = 0 almost surely, its proof is similar to the proof of Theorem 4.3 in [2], except that we need to make some modiﬁcations based on χ( ̂X k). Suppose that limk→∞ χ( ̂X k) = 0 does not hold almost surely. Then with a positive probability, there exists ϵ > 0 such that χ( ̂X k) > 2ϵ holds for inﬁnitely many k. For any ϵ > 0, deﬁne a sequence of random variables {Kϵ} consisting of the natural numbers k for which χ( ̂Xk) > ϵ. Then∑ k∈{Kϵ} ∆k < ∞ almost surely by following the proof of Lemma 4.17 in [9] replacing ∥∇f ( ̂Xk)∥ with χ( ̂Xk). We are going to show if such ϵ exists then ∑ j∈{Kϵ} ∆j is a divergent sum, and hence, we must have limk→∞ χ( ̂X k) = 0 almost surely. Since lim inf k→∞ χ( ̂X k) = 0, there are inﬁnitely many intervals of integers with a positive probabil- ity, such that each interval {W ′ + 1, . . . , W ′′} satisﬁes: 0 < W ′ < W ′′, χ( ̂X W ′) ≤ ϵ, χ( ̂X W ′+1) > ϵ, χ( ̂X W ′′) > 2ϵ, and for any integer w ∈ (W ′, W ′′), ϵ < χ( ̂X w) ≤ 2ϵ. Let {(W ′ r, W ′′ r )}r be an inﬁnite sequence of such intervals. Let (w′ r, w′′ r ) be the realization of (W ′ r, W ′′ r ). ϵ < χ(̂x w′′ r ) − χ(̂x w′ r ) = w′′ r −1∑ k=w′ r (χ(̂xk+1) − χ(̂xk) ) ≤ w′′ r −1∑ k=w′ r ̂χ(Lδk)(̂xk+1) − χ(̂xk), (45) with L ≜ 2L1(L1 + 1) and ̂χ(Lδk)(•) is deﬁned in (31). From Lemma 17 with the deﬁnitions of active index sets A(x, ω) for the max function h(x, ω), for almost every ε, A(̂xk, ψ(̂xk) + ε) ⊆ A(Lδk)(̂xk+1, ψ(̂xk+1) + ε). Furthermore, let ˆdk be the optimal direction in deﬁning ̂χ(Lδk)(̂xk+1), then we have ̂χ(Lδk)(̂xk+1) − χ(̂xk) ≤ f ′(̂xk; ˆdk) − ∇c(̂xk+1)⊤ ˆdk −Ẽε [ h ′ (L·δk) ((̂xk+1, ψ(̂xk+1) + ̃ε ); ( ˆdk, ∇ψ(̂xk+1)⊤ ˆdk) )] − Ẽε[ g ′ ((̂xk+1, ψ(̂xk+1) + ̃ε ); ( ˆdk, ∇ψ(̂xk+1)⊤ ˆdk)) ] ≤ 2(L1 L2 + L2) ∥ ∥ ̂xk+1 − ̂xk ∥ ∥ + Ẽε [h ′((̂xk, ψ(̂xk) + ̃ε); ( ˆdk, ∇ψ(̂xk)⊤ ˆdk)) ] − Ẽε [ h ′ (L·δk) ((̂xk+1, ψ(̂xk+1) + ̃ε ); ( ˆdk, ∇ψ(̂xk+1)⊤ ˆdk) )] . Since A(̂xk, ψ(̂xk) + ε) ⊆ A(Lδk)(̂xk+1, ψ(̂xk+1) + ε), we have Ẽε [h ′((̂xk, ψ(̂xk) + ̃ε); ( ˆdk, ∇ψ(̂xk)⊤ ˆdk)) − h ′ (L·δk) ((̂xk+1, ψ(̂xk+1) + ̃ε ); ( ˆdk, ∇ψ(̂xk+1)⊤ ˆdk) )] ≤ Ẽε [ maxj∈J ∥ ∥ ∇1hj(̂xk, ψ(̂xk) + ̃ε) − ∇1hj(̂xk+1, ψ(̂xk+1) + ̃ε) ) ∥ ∥ ] +Ẽε [ maxj∈J ∥ ∥ ∇ψ(̂xk) ∇2hj(̂xk, ψ(̂xk) + ̃ε) − ∇ψ(̂xk+1) ∇2hj(̂xk+1, ψ(̂xk+1) + ̃ε) ∥ ∥ ] ≤ L0 ∥ ∥ ̂xk+1 − ̂xk ∥ ∥ , for some L0 depending on L1 and L2. This indicates that χ(Lδk)(̂xk+1) − χ(̂xk) ≤ L′ ∥ ∥ ̂xk+1 − ̂xk ∥ ∥ with L′ = L0 + 2(L1 L2 + L2). Combining with (45), we derive that for any l, L′ W ′′ l −1∑ k=W ′ l ∥ ∥ ∥ ̂xk+1 − ̂xk ∥ ∥ ∥ ≥ ϵ, 34 which yields that ∑ k∈{Kϵ} ∆k = ∞ almost surely, thus contradicts the initial assumption. Hence we have limk→∞ χ( ̂X k) = 0 almost surely. Furthermore, by Lemma 11.1.2 in [11], this implies that the sequence produced by the CLEO algorithm converges to a directional stationary point almost surely. □ 35","libVersion":"0.3.2","langs":""}