{"path":"lit/papers_to_add/papers_to_markup_over_weekend/Johnstone12econValProbFrcstPortfolio.pdf","text":"Loss Functions for Binary Class Probability Estimation and Classiﬁcation: Structure and Applications Andreas Buja 1 Werner Stuetzle 2 Yi Shen 3 November 3, 2005 Abstract What are the natural loss functions or ﬁtting criteria for binary class probability estimation? This question has a simple answer: so-called “proper scoring rules”, that is, functions that score probability estimates in view of data in a Fisher-consistent manner. Proper scoring rules comprise most loss functions currently in use: log-loss, squared error loss, boosting loss, and as limiting cases cost-weighted misclassiﬁcation losses. Proper scoring rules have a rich structure: • Every proper scoring rules is a mixture (limit of sums) of cost-weighted misclassiﬁ- cation losses. The mixture is speciﬁed by a weight function (or measure) that describes which misclassiﬁcation cost weights are most emphasized by the proper scoring rule. • Proper scoring rules permit Fisher scoring and Iteratively Reweighted LS algo- rithms for model ﬁtting. The weights are derived from a link function and the above weight function. • Proper scoring rules are in a 1-1 correspondence with information measures for tree-based classiﬁcation. • Proper scoring rules are also in a 1-1 correspondence with Bregman distances that can be used to derive general approximation bounds for cost-weighted misclassiﬁcation errors, as well as generalized bias-variance decompositions. We illustrate the use of proper scoring rules with novel criteria for 1) Hand and Vinciotti’s (2003) localized logistic regression and 2) for interpretable classiﬁcation trees. We will also discuss connections with exponential loss used in boosting. Keywords: Boosting, stagewise regression, machine learning, proper scoring rules, proper score functions, information measures, entropy, Gini index, Bregman distances, link functions, binary response data, stumps, tree-based classiﬁcation, CART, logistic regression, Fisher scoring, iteratively reweighted least squares, stagewise ﬁtting. 1 Introduction Consider predictor-response data with a binary response y representing the observation of classes y = 1 and y = 0. Such data are thought of as realizations of a Bernoulli random variable Y with η = P [Y = 1]. The class 1 probability η is interpreted as a function of predictors x: η = η(x). If the predictors are realizations of a random vector X, then η(x) is the conditional class 1 probability given x: η(x) = P [Y = 1|X = x]. Of interest are two types of problems: • Classiﬁcation: Estimate a region in predictor space in which class 1 is observed with the greatest possible majority. This amounts to estimating a region of the form {η(x) > c}. • Class probability estimation: Approximate η(x) as well as possible by ﬁtting a model q(x, β) (β = parameters to be estimated). Of the two problems, classiﬁcation is prevalent in machine learning (“concept learning” in AI), whereas class probability estimation is prevalent in statistics (usually as logistic regression). — The classiﬁcation problem is peculiar in that estimation of a class 1 region is often based on two kinds of criteria: • the primary criterion of interest: misclassiﬁcation loss/rate/error. This is an intrinsi- cally unstable criterion for estimating models, a fact that motivates the use of • surrogate criteria for estimation, such as log-loss (logistic regression) and exponential loss (boosting). These are just estimation devices and not of primary interest (see, for example, Lugosi and Vayatis 2004). In a sense that can be made precise the surrogate criteria of classiﬁcation are exactly the primary criteria of class probability estimation. It seems therefore that classiﬁcation goes the detour via class probability estimation. This is a contentious issue on which we will comment below. — We turn to two standard examples of surrogate criteria: • Log-loss: L(y|q) = − log(qy(1 − q)1−y) = −y log(q) − (1 − y) log(1 − q) • Squared error loss : L(y|q) = (y − q)2 = y (1 − q)2 + (1 − y) q2 Log-loss is the negative log-likelihood of the Bernoulli model. Its expected value, −η log(q) − (1 − η) log(1 − q), is called Kullback-Leibler loss or cross-entropy. The equality for squared error loss holds because y ∈ {0, 1}. Note that its expected value is η (1 − q)2 + (1 − η) q2, not (η − q)2. — Both losses penalize an estimate q of η in light of an observation y. They yield Fisher consistent estimates of η in the sense that η = argminq∈[0,1] Ey L(y|q) , for y ∼ Bernoulli(η) . Loss functions L(y|q) with this property have been known as proper scoring rules. In subjective probability they are used to judge the quality of probability forecasts by experts, whereas here they are used to judge the quality of class probabilities estimated by automated 1 procedures. [Proper scoring rules are Fisher consistent for class probability estimation, whereas Y. Lin’s (2002) notion of Fisher consistency applies to classiﬁcation. This is a weaker notion as it only requires “argminq∈[0,1] Ey L(y|q) ≷ 0.5” iﬀ “η ≷ 0.5”.] In light of current interest in boosting we indicate how boosting’s exponential loss maps to a proper scoring rule: Friedman, Hastie and Tibshirani (2000) observed that estimates produced by boosting can be mapped to class probability estimates with a certain link function. This link function can be used to transport exponential loss to the probability scale where it turns into a proper scoring rule as follows (see Section 4): L(y|q) = y (1 − q • Theory: The integral representation, when carried over to Bregman distances (Sec- tion 19-22), lends itself to the derivation of bounds on cost-weighted misclassiﬁca- tion losses in terms of ω(), thereby generalizing approximation theorems such as Zhang’s (2004) and Bartlett et al.’s (2003; 2004 p. 87) to estimation with arbitrary proper scoring rules and classiﬁcation with arbitrary cost weights c. An immediate beneﬁt of the weight functions is their interpretability: Locations where ω(c) puts most mass... • ...correspond to the cutoﬀs c for which the estimated class probabilities attempt the most accurate classiﬁcation, that is, the most accurate estimation of {η(x) > c}; • ...determine the observations that get the most weight in the minimization of the proper scoring rule. This can be seen from the IRLS iterations in which observations are upweighted when ω(q) is large. For example, from the form of the weight function for log-loss, which is ω(q) = (q(1 − q))−1, one infers immediately a heavy reliance on extreme probability estimates. This has indeed been an issue in logistic regression; see Hand and Vinciotti (2003) for a detailed discussion. Surprisingly boosting loss is even more lopsided than log-loss in its reliance on extreme probability estimates: ω(q) = (q(1 − q))−3/2. If boosting loss looks more problematic than log-loss, why would boosting be so successful in practice? The answer is most likely that boosting is successful not because but in spite of its loss function. The loss function is benign if used for classiﬁcation based on non-parametric models (as in boosting), but boosting loss is certainly not more successful than log-loss if used for ﬁtting linear models as in linear logistic regression. What guidance can one give for choosing proper scoring rules? One can follow Hand and Vinciotti’s (2003) lead and choose weight functions ω() that concentrate mass around the classiﬁcation threshold c of interest. Hand and Vinciotti (2003) achieved this eﬀect by modifying the IRLS algorithm and upweighting observations with estimates q near the threshold c. This, however, is nothing other than minimizing a proper scoring rule whose weight function ω() concentrates mass around the threshold c. Adapting loss functions in this way will be called “tailoring the proper scoring rule to the classiﬁcation threshold c”. We will illustrate successful tailoring with Hand and Vinciotti’s (2003) artiﬁcial data example and with a well-known real dataset (Section 14). Tailoring proper scoring rules should be most eﬀective for models that are likely to have substantial bias for class probability estimation, such as linear models, while more ﬂexible nonparametric models are less likely to gain. Among the latter are boosting approaches that rely on very ﬂexible function classes such as sums of shallow trees. Although the present work was motivated by boosting, the main beneﬁt of tailored proper scoring rules may be not so much in boosting as in classical linear models, but also in tree-based classiﬁcation as we indicate next. Most well-known tree algorithms rely on one of two splitting criteria: entropy or the Gini index. These criteria derive directly from proper scoring rules (Section 17): entropy 3 from log-loss, and the Gini index from squared error loss. In fact, every proper scoring rule deﬁnes an information measure that can be used as a splitting criterion, hence tailoring can be applied to tree-growing as well. Trees, however, form a highly ﬂexible class of ﬁts, so one would expect little beneﬁt from tailoring the criterion. Yet, tailoring for trees turns out to be useful when focusing one-sidedly on extreme probabilities, for example those near one. To this end one can design proper scoring rules that put progressively more weight on larger and larger probabilities. This produces unusually interpretable trees that layer the data in highly unbalanced, cascading trees. This form of trees was proposed by Buja and Lee (2001), but the splitting criteria used there were heuristic and did not derive from information measures. Finally a word on the relation of this work to boosting: Although motivated by Friedman, Hastie and Tibshirani’s (2000) interpretation of boosting, the present analysis is of greater use for techniques other than boosting. One of our contributions to boosting consists of showing that IRLS can be tweaked for ﬁtting stagewise additive models with arbitrary proper scoring rules. For those interested in the original interpretation of boosting as reweighting, we observe that IRLS schemes often produce weights that depend on the response values yn only through the estimated class-1 probabilities q(xn), not the yn’s directly. This is the case when IRLS is used to implement Fisher scoring as opposed to Newton steps, and even for Newton steps if the link function is canonical with regard to the weight function ω(q). The notion of “canonical” is the same as in generalized linear models but it applies to all proper scoring rules. Unlike logistic loss, exponential loss does not decompose into a pair of canonical link and weight functions. There has been recent theory in the context of boosting that may not directly explain why boosting is successful but may nevertheless have merit on its own terms (for example, Bartlett et al. 2003, and the “Three Papers on Boosting”: Jiang; Lugosi and Vayatis; Zhang; 2004). As Bartlett et al. (2004, p. 86f) note, a common ﬁrst step of such theories consists of “comparison theorems” that bound the excess misclassiﬁcation risk by the excess surrogate risk, where “excess” refers to excess over the best achievable risk at the population. To date such bounds have been derived individually for special choices of surrogate loss functions and unweighted misclassiﬁcation losses. We contribute to these theories by deriving bounds for arbitrary cost-weighted misclassiﬁcation losses in terms of surrogate losses that are arbitrary proper scoring rules. The only case we do not cover is hinge loss used in support vector machines because it is related to absolute deviation loss L(y|η) = |y − η| which is not a proper scoring rule. Thus SVMs seem to be the only case that truly bypasses estimation of class probabilities and directly aims at classiﬁcation (see Freund and Schapire (2004, p. 114) along similar lines). Our contribution, however, is not about the pros and cons of class probability estimation but about its structural connection with cost-weighted classiﬁcation. Acknowledgments: We thank J.H. Friedman, D. Madigan, D. Mease and A.J. Wyner for discussions that resulted in several clariﬁcations, and J. Berger and L. Brown for pointing us to the literature on proper scoring rules. We owe a special debt to two articles: Friedman, Hastie and Tibshirani (2000) and Hand and Vinciotti (2003). In what follows we refer to these articles as FHT (2000) and HV (2003), respectively. 4 2 Deﬁnition of proper scoring rules Given predictor-response data (xn, yn) with binary response yn ∈ {0, 1}, we are interested in ﬁtting a model q(x) for the conditional class 1 probabilities η(x) = P [Y = 1|x]. (For now it is immaterial whether the model is parametric or nonparametric, which is why we write q(x) without unknown parameters.) This problem would be approached by most statisticians with maximum likelihood with regard to the conditional Bernoulli model, but there exist many other possibilities, and their exploration is the purpose of this article. We assume the model q(x) takes on values in [0, 1] for estimating η(x). The model is to be ﬁtted to the values 0 and 1 of the response y by minimizing a loss function which we take to be the sample average of losses of individual observations: L(q()) = 1 0.0 0.2 0.4 0.6 0.8 1.0 qR(η|q) η=0.05 η=0.25 η=0.5 η=0.75 η=0.95 0.0 0.2 0.4 0.6 0.8 1.0 q η=0.05 η=0.25 η=0.5 η=0.75 η=0.95 Figure 1: Depiction of two proper scoring rules. The curves represent sections of expected loss, q ↦→ R(η |q) for a few ﬁxed values of η. By the deﬁnition of proper scoring rules the minimizing value q for given η is q = η. Left: log-loss or Beta loss with α = β = 0; see Section 11. This loss is symmetric about 0.5. Right: Beta loss with α = 1, β = 3. This loss is not symmetric about 0.5. It is tailored for classiﬁcation with misclassiﬁcation cost c = α whose optimization results in “honest” inference reporting policies. See for example Bernardo and Smith (2000, Def. 2.21 and 3.16). For more background and modern uses of proper scor- ing rules the reader should consult a wide-ranging discussion by Gneiting and Raftery (2004). 3 Commonly used proper scoring rules For most loss functions the partial losses L1(1 − q) and L0(q) are smooth, hence the proper scoring rule property implies the stationarity condition 0 = ∂ While the previous two examples are strict proper scoring rules, misclassiﬁcation loss is non-strict. The deﬁnition requires some convention for q = 0.5, but the particular choice is irrelevant for most purposes. 4 A proper scoring rule derived from exponential loss We derive a new type of proper scoring rule that is implicit in boosting. As this is not the place to discuss the motivations and details of boosting, we refer the reader to FHT (2000) for an introduction that is accessible to statisticians. The one detail we need here is that boosting can be interpreted as minimization of so-called “exponential loss”, deﬁned as 1 as “boosting loss”. Together with log-loss, squared error loss, and misclassiﬁcation loss, this will be one of the standard examples in what follows. 5 Counterexamples of proper scoring rules Wald’s decision theory has a notion of loss function whose purpose is to relate estimates (more generally: decisions) to true parameter values. Therefore, |q −η| is a valid loss function in the sense of Wald, with η being the unknown true parameter and q the estimate (decision). Observed losses L(y|q), however, are estimation devices whose purpose is to relate estimates q to observations y. The only connection is that expected losses R(η|q) = ηL1(1 − q) + (1 − η)L0(q) form a proper subset of Wald loss functions, namely those that are aﬃne in η. Hence the Wald loss function |q − η| is not an expected loss because it is not aﬃne in η. Absolute deviation, L(y|q) = |y − q| qualiﬁes as an observed loss but it is not a proper scoring rule. It is identical to L(y|q) = y (1 − q) + (1 − y) q because y ∈ {0, 1}. The corresponding expected loss is not |q − η| but R(η|q) = η (1 − q) + (1 − η) q. Yet this is not a proper scoring rule because R(η|q) is minimized by q = 1 for η > 1/2 and q = 0 for η < 1/2 and arbitrary q ∈ [0, 1] for η = 1/2. Absolute deviation loss must therefore be considered as a classiﬁcation loss: it provides Fisher consistent estimates of the majority class, not the class probability. It is similar to misclassiﬁcation loss of Section 3 in that both have Bayes risk as minimum expected loss: min q R(η|q) = min(η, 1 − η) . Yet absolute deviation and misclassiﬁcation loss are distinct in that the latter is indiﬀerent to the value of q as long as it is on the same side of 1/2 as η. Misclassiﬁcation loss is a proper scoring rule because it is minimized, although not uniquely, by the true class probability q = η, whereas absolute deviation is not. — Absolute deviation loss underlies classiﬁcation with support vector machines; see for example Zhang (2004). Power losses are generalizations of absolute deviation loss: L(y|q) = |y − q|r = y (1 − q)r + (1 − y) qr , L1(1 − q) = (1 − q)r , L0(q) = qr , R(η|q) = η (1 − q)r + (1 − η) qr for positive exponent r. For the ﬁrst identiy one makes again use of y ∈ {0, 1}. The stationarity condition (5) for a proper scoring rule specializes to r (1 − q)r−2 = r qr−2 , which is violated for all choices of r except r = 2. Hence in the power family only squared error is a proper scoring rule. 9 Power divergences of Cressie and Read (1984), specialized to the two class case: R(η|q) = 2 • The weight function ω(q) does not need to be globally integrable on (0, 1), which is the same as saying that L0 and L1 can be unbounded near 0 and 1. • L1 and L0 are bounded below iﬀ ∫ 1 0 t (1−t) ω(t) dt < ∞, which limits power tail weights of ω(t) to t γ and (1 − t)γ with γ > −2. • Assuming L1 and L0 bounded below and hence w.l.o.g. normalized to L1(0) = L0(0) = 0, the proposition yields the following integral representation: L1(1 − q) = ∫ 1 q (1 − t) ω(t) dt , L0(q) = ∫ q 0 t ω(t) dt . (14) A larger universe of proper scoring rules can be characterized by the following construc- tion which is a subset of a more general theorem by Schervish (1989, Theorem 4.2). Theorem 1: Let ω(dt) be a positive measure on (0, 1) that is ﬁnite on intervals (ǫ, 1 − ǫ) ∀ ǫ > 0. Then the following deﬁnes a proper scoring rule: L1(1 − q) = ∫ f1 q (1 − t) ω(dt) , L0(q) = ∫ q f0 t ω(dt) . (15) The proper scoring rule is strict iﬀ ω(dt) has non-zero mass on every open interval of (0, 1). Theorem 4.2 of Schervish (1989) has an “only if” part which shows that essentially ev- ery proper scoring rule has an integral representation. The formulation of the theorem is intentionally kept informal. Here are a few details to be ﬁlled in: • When the measure µ(dt) has point masses one needs a convention for integration limits. For example, excluding the upper limit and including the lower limit makes L1(1 − q) and L0(q) left-continuous, while the reverse convention makes them right-continuous. Averaging these two conventions produces further conventions. The convention is irrelevant as long as it is applied consistently. • The ﬁxed integration limits, f0 and f1, are somewhat arbitrary because of the fact that if L1(1 − q), L0(q) form a proper scoring rule, so do L1(1 − q) + C1, L0(q) + C0 for all constants C1 and C0, and these proper scoring rules are all equivalent. • Under certain conditions, however, there are restrictions on f0 and f1: we need f1 < 1 if ∫ 1 1−ǫ(1 − t)ω(dt) = ∞, and consequently L1(1 − q) is unbounded below near q = 1. Similarly we need f0 > 0 if ∫ ǫ 0 tω(dt) = ∞, which makes L0(q) unbounded below near q = 0. • If ∫ ǫ 0 ω(dt) = ∞, then Ll(1−q) is unbounded above near 0, and similarly if ∫ 1 1−ǫ ω(dt) = ∞, then L0(q) is unbounded above near 1. • While two important proper scoring rules are unbounded above, log-loss and boosting loss, we don’t know of any proposals that are unbounded below. Thus all common proper scoring rules seem to satisfy ∫ 1 0 t(1 − t)ω(dt) < ∞. 11 t 0 η q 1 0 η 0 1−η t → (1 − η) t t → η (1 − t) Figure 2: Illustration for the proof of Theorem 1. The union of shaded areas represents the integrand in Equation (17). It is the lowest for q = η when the lightly shaded area vanishes. • As in the continuous case, if ∫ 1 0 t(1 − t)ω(dt) < ∞, then both L1(1 − q) and L0(q) are bounded below and can be normalized to L1(0) = L0(0) = 0 so that L1(1 − q) = ∫ 1 q (1 − t) ω(dt) , L0(q) = ∫ q 0 t ω(dt) . (16) The proof of Theorem 1 is very short, but to avoid notational diﬃculties we only give it under the assumption ∫ 1 0 t(1 − t)ω(dt) < ∞ so that we can choose f1 = 1 and f0 = 0. We also use the left-continuous convention for the integrals: R(η|q) = η L1(1 − q) + (1 − η) L0(q) = ∫ [ η (1 − t) 1[t≥q] + (1 − η) t 1[t<q] ] ω(dt) (17) The integrand on the right hand side is depicted in Figure 2 as a function of t. It is immediate that q = η is a minimum. The minimum is unique iﬀ the open intervals (η, η+ǫ) and (η−ǫ, η) have non-zero mass for all ǫ > 0. — The following is a direct consequence of Figure 2: Corollary: Any proper scoring rule q ↦→ R(η|q) is non-ascending to the left of η and non- descending to the right of η. If ω(dt) puts non-zero mass on all open intervals, then the function is strictly descending/ascending to the left/right of η, and q = η is the unique minimum for all η. From the above follows that there exists a wealth of proper scoring rules. Here are the standard examples with their weight functions ω(t) or measures ω(dt), respectively: 12 • Boosting loss: ω(q) = 1 There is arbitrariness at q = c, but the choice is immaterial. We restate Theorem 1: Theorem 1’: If ∫ 1 0 t(1 − t) ω(dt) < ∞, the proper scoring rules of Theorem 1 are mixtures of cost-weighted misclassiﬁcation losses with ω(dc) as the mixing measure: L(η|q()) = ∫ 1 0 Lc(η|q()) ω(dc) (25) L1(1 − q) = ∫ 1 0 L1,c(1 − q) ω(dc) , L0(q) = ∫ 1 0 L0,c(q) ω(dc) , (26) R(η|q) = ∫ 1 0 Rc(η|q) ω(dc) . (27) The proof is immediate by substituting the deﬁnitions (23) in the right hand sides of (26) to arrive at the right hand sides of (16). The rest is using the deﬁnitions (4) and (1). — Some practical implications of the theorem are as follows: • Interpretation of proper scoring rules: The inﬁnite mass placed near zero and one by the weight functions (18) and (19) of boosting loss and of log-loss indicates an emphasis on getting classiﬁcation right for extreme misclassiﬁcation costs of both classes. We will see below (Section 14) that this eagerness to perform well on both ends of the cost axis can lead to situations in which classiﬁcation performance is low on both ends. • Robustness to misspeciﬁed costs: In practice one can often argue that misclassiﬁ- cation costs are not known precisely. The relative indeterminacy of costs suggests that classiﬁcation results should be insensitive to small changes in c or, more precisely, it should be accurate across a range of indeterminacy of c. It would then seem natural not to seek optimality for a single misclassiﬁcation loss but for an average of misclassi- ﬁcation losses, that is, for a proper scoring rule. The proper scoring rule should localize by peaking its weight function ω(q) at costs in the range of interest. • Class probability estimation versus classiﬁcation: The mixture representation of proper scoring rules gives simple evidence that classiﬁcation is easier than class prob- ability estimation when the model is biased. While η(x) may not be well-approximated by the model q(x), it may still be possible for each cost c to approximate {η(x) > c} well with {q(x) > c}, but each c requiring a separate model ﬁt q(.). This is expressed by the following simple inequality: min q() Lω(q()) ≥ ∫ min q() Lc(q()) ω(dc) , where Lω() = ∫ Lc()ω(dc). 14 8 Proper scoring rules = negative quasi-likelihoods Identity (11) can be used to show that smooth proper scoring rules are exactly the (negative) quasi-likelihoods for binary observations y. To this end re-write this identity for observations y instead of probabilities η as follows: ∂ Newton updates have the form bnew = bold − ( ∂2 bL(b))−1 (∂bL(b)) . The equivalent IRLS form of these updates is as solutions to normal equations with a suitable design matrix X, a diagonal weight matrix W , and response vector z, the latter two changing from update to update: bnew = bold + (X T W X)−1 ( X T W z) , We write the IRLS update in an incremental form whereas in the form usually shown in the literature one artiﬁcally absorbs bold in the current response z. The incremental form leds itself more directly to boosting-like stagewise ﬁtting (Section 10). Abbreviating qn = q(x T n b) , q′ n = q′(x T n b) , we have ∂bqn = q′ n xn. Making use of the proposition of Section 6 the ingredients for Newton updates become ∂bL(b) = − 1 10 Boosting as stagewise ﬁtting of additive models with proper scoring rules In FHT’s (2000) interpretation, boosting is a form of stagewise forward regression for building a possibly very large additive model. While Freund and Schapire conceived boosting as a weighted majority vote among a collection of weak learners, FHT see it as the thresholding of a linear combination of basis functions, in other words, of an additive model. We adopt FHT’s view of boosting and adapt the IRLS iterations to stagewise forward additive ﬁtting. For additive modeling one needs a set F of admitted basis functions f (x). For Real AdaBoost, F is a constrained set of trees such as stumps (trees of depth one), and for Discrete AdaBoost F is the set of indicator functions obtained by thresholding trees. These examples explain why F is not assumed to form a linear space. An additive model is a linear combination of elements of F : F (x) = ∑ k bkfk(x). Stagewise ﬁtting is the successive acquisition of terms f (K) ∈ F given that terms f (1), . . . , f (K−1) for a model F (K−1) = ∑ k=1..K−1 bk f (k) have already been acquired. In what follows we write Fold for F (K−1), f for f (K), b for bK, and ﬁnally Fnew = Fold + b f . Given a training sample {(xn, yn)}n=1..N , the empirical loss is L(Fold + b f ) = 1 11 The Beta family of proper scoring rules We introduce a continuous 2-parameter family of scoring rules that is suﬃciently rich to encompass most commonly used losses, including boosting loss, log-loss, squared error loss, and misclassiﬁcation loss in the limit. It will later serve us to “tailor” the weight function ω(q) to the desired cost for cost-weighted classiﬁcation. The family is modeled after the Beta densities, but we permit weight functions that are not integrable and hence cannot be normalized to densities: ω(q) = qα−1 (1 − q)β−1 (36) L ′ 1(1 − q) = qα−1(1 − q)β L ′ 0(q) = qα(1 − q)β−1 The partial losses L1 and L0 are bounded below iﬀ α, β > −1. As the following list suggests, the lowest values ever proposed (at least implicitly) are α = β = − 1 0.0 0.2 0.4 0.6 0.8 1.001234 qL0(q) α = − 1 2 α = 0 α = 1 α = 2 α = 20 α = 100 α = ∞ 0.0 0.2 0.4 0.6 0.8 1.001234 qω(q)α = − 1 2 α = 0 α = 1 α = 2α = 20 α = 100 α = ∞ Figure 3: Loss functions L0(q) and weight functions ω(q) for various values of α = β: exponential loss (α = − 1 In the limit for large a and b this is equivalent to tailoring at the mean. These constructions have obvious practical applications: log-loss can be replaced with the proper scoring rules generated by the above weight functions ωα,β(q). In doing so we can possibly achieve improved classiﬁcation for particular cost ratios or class-probability thresh- olds when the ﬁtted model is biased but adequate for describing classiﬁcation boundaries individually. The appropriate degree of peakedness of the weight function could be estimated from the data using cross-validation of cost-weighted misclassiﬁcation loss. In Section 14 we will illustrate ﬁtting biased linear models with “tailored” proper scoring rules. 13 The Hand-Vinciotti reweighting method as mini- mization of tailored proper scoring rules HV’s (2003) tailoring method based on reweighting can be interpreted as the minimization of certain proper scoring rules. HV devised their scheme algorithmically by modifying the weights of IRLS for Fisher scoring in logistic regression. Their weights are Gaussian kernels: ω(q) = φ (q − c0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0 Figure 4: Hand and Vinciotti’s Artiﬁcial Data: The class probability function η(x) has the shape of a smooth spiral ramp on the unit square with axis at the origin. The bold line marked “0.3 log” shows a linear logistic ﬁt thresholded at c = 0.3. The other bold line, marked “0.3 Beta”, shows a thresholded linear ﬁt corresponding to a proper scoring rule in the Beta family with parameters α = 6 and β = 14. is that the optimal classiﬁcation boundaries η(x) = c are all linear but not parallel. The absence of parallelism renders any linear model q(b T x) unsuitable as a global ﬁt, but the linearity of the classiﬁcation boundaries allows linear models to describe these boundaries, although every level requires a diﬀerent linear model. The purpose of HV’s (2003) and our tailoring schemes is to home in on these level-speciﬁc models. In recreating HV’s (2003) example, we simulated 4,000 data points whose two predictors were uniformly distributed in the unit square, and whose class labels had a conditional class 1 probability η(x1, x2) = cos−1(x1/(x 2 1 + x 2 2)1/2)/(π/2). We ﬁtted a linear model with the logistic function q(t) = 1/(1 + exp(−t)), using a proper scoring rule in the Beta family with α = 29 and α/β = 0.3/0.7 in order to home in on the c = 0.3 boundary. Figure 4, which is similar to HV’s (2003), shows the success: the estimated boundary is close to the true 0.3-boundary. The ﬁgure also shows that the 0.3-boundary estimated with the log-loss of logistic regression is essentially parallel to the 0.5-boundary, which is sensible because logistic regression is bound to ﬁnd a compromise model which, for reasons of symmetry between the two labels, should be a linear model with level lines roughly parallel to the true 0.5-boundary. We turn to the Pima Indians Diabetes data to show that non-parallel linear boundaries 21 50 100 150 200203040506070 plasmab.mass0.1 0.5 0.9 Figure 5: Illustration of non-parallel linear classiﬁcation boundaries for diﬀerent classiﬁca- tion thresholds or cost weights: the Pima Indians Diabetes Data, “b.mass” plotted against “plasma”, with boundaries for the thresholds c =0.1, 0.5 and 0.9. Glyphs: open squares = no diabetes, class 0; ﬁlled circles = diabetes, class 1. for diﬀering classiﬁcation thresholds can produce improvements in real data as well. We start with a graphic illustration similar to Figure 4 by restricting attention to the most powerful predictors, plasma and b.mass: Figure 5 shows estimated linear classiﬁcation boundaries for the levels 0.1, 0.5 and 0.9, clearly indicating that at least for level 0.1 the boundary is not parallel to the other two. We now give quantitative evidence for signiﬁcant improvements from tailoring using all predictors. [The data have numerous missing values. Some details about their treatment: We removed the cases with zero values on plasma (5), b.press (35) and b.mass (11) for a total of 44, thus reducing the sample size from 768 to 724. For the variables skin and insulin with 227 and 374 missings, respectively, we introduced two dummy variables for missingness.] To compare tailoring with standard logistic regression, we performed a cross- validation experiment, not in the conventional manner of 10-fold cross-validation, but for greater inferential precision with many more folds as follows: We randomly split the data 400 times into an 80% training set and a 20% test set. On 200 of the splits we ﬁtted a standard linear logistic regression (α = β = 0) to the training set and evaluated the cost- weighted misclassiﬁcation errors for c =0.50, 0.80, 0.90 and 0.95 on the test set. On the other 200 splits we ﬁtted a linear model with the logit link and a tailored proper scoring rule with α = 4.5 and β = 0.5 to the training set, and again evaluated the cost-weighted 22 0.08 0.10 0.12 0.14 0.160.080.100.120.140.16 α=0 β=0α=3 β=1/3 cost weight = 0.5 0.04 0.05 0.06 0.07 0.08 0.090.040.050.060.070.080.09 α=0 β=0α=3 β=1/3 cost weight = 0.8 0.02 0.03 0.04 0.05 0.060.020.030.040.050.06 α=0 β=0α=3 β=1/3 cost weight = 0.9 0.015 0.020 0.025 0.0300.0150.0200.0250.030 α=0 β=0α=3 β=1/3 cost weight = 0.95 Figure 6: Pima Indians Diabetes data: Comparison of logistic regression with a proper scoring rule tailored for high class 1 probabilities: α = 9, β = 1, hence cw = 0.9. The black traces with points are empirical Q-Q curves of 200 cost-weighted misclassiﬁcation costs computed on randomly selected test sets of size 20%. Overplotted in gray are one hundred null traces obtained with random permutations. misclassiﬁcation errors for c =0.50, 0.80, 0.90 and 0.95 on the test set. We are interested in comparing the 200 misclassiﬁcation errors of the logistic ﬁt with the 200 of the tailored ﬁt, for all four cost weights c. This amounts to four 2-sample comparisons of cost-weighted misclassiﬁcation errors of one ﬁtting method with those of the other ﬁtting method. Such comparisons are conventionally done in terms of 2-sample t-tests for means, but instead we present the results more informatively in terms of 2-sample Q-Q plots, which essentially amount to plots of the two sorted series of 200 values against each other. This is carried out in Figure 6, which shows one plot for each of the four cost weights. The Q-Q traces are shown in black, with the misclassiﬁcation errors of the tailored Beta rule shown on the vertical axis, those of logistic regression on the horizontal axis. To inject statistical inference in these plots, we added 100 “null” Q-Q traces overplotted in gray, based on a permutation test idea: by construction of the experiment, the 400 values are exchangeable under the null assumption of identical distributions of the misclassiﬁcation errors of both methods. Hence we can randomly split the pool of 400 values into two sets of 23 200 and draw their Q-Q traces, simulating the null hypothesis conditional on the observed values, repeated and overplotted 100 times. Thus, wherever the black trace reaches outside the gray band of null traces, statistical signiﬁcance is achieved. This is the case in the bottom right hand plot for cost weight c = 0.95, and border line in the bottom left plot for c = 0.90. In the top left plot we see that the tailored ﬁt performs somewhat worse for cost weight c = 0.50, but only marginally so. — In summary, we see evidence that tailoring of proper scoring rules to cost-weights does indeed provide an advantage over standard logistic regression. 15 Stability of tailoring: convexity and asymptotics Tailoring may raise fears of unstable ﬁts because for peaked weight functions the composite loss function L(y|q(F )) loses convexity rather quickly. If L(y|q(F )) is suﬃciently smooth in F , a suﬃcient condition for convexity is a non-negative second derivative, which according to (32) amounts to ω(q) q′2 − (y − q) [ ω(q) q′ ] ′ ≥ 0 . (39) This requirement results in two inequalities, one for y = 1 and one for y = 0, which we can summarize as follows: Proposition: Composite losses L(y|q(F )) are convex in F if ω(q) and q′ are strictly positive, both are smooth, and they satisfy q′ −3 −2 −1 0 1 2 30.00.20.40.60.81.0 F η(F) q(F) Figure 7: A stable situation for tailored estimation, shown for a single predictor: q(F ) has positive bias for q(F ) < c and negative bias for q(F ) > c. however, in view of a simple asymptotic argument which is as follows: Standard formulas for asymptotic variances in estimating equations (for example, Shao 2003, p. 369) yield AVar(ˆb) ≈ N ( E ∂2L(b))−1 Var (∂L(b)) ( E ∂2L(b))−1 From Section 9, Equations (30) and (31), we obtain Var ∂L(b) = 1 reduce E ∂2L(b) and hence inﬂate the asymptotic variance for some linear combinations of b. On the other hand, this same term can also contribute to stability by enlarging E ∂2L(b) and hence diminishing the asymptotic variance, namely, when −(ηn − qn) [ ω(qn) q′ n ] ′ ≥ 0 . (42) To see the meaning of this condition, we specialize it to the Beta family and the logistic link, as used for tailoring in Section 12, and in particular we consider α, β > 0, which is possibly problematic because of non-convexity. Making use of q′ = q(1 − q) for the logistic link, we see that (42) is equivalent to −(ηn − qn) [ α(1 − qn) − βqn ] ≥ 0 or ηn ⪌ qn when qn ⪌ α in the Hessian ∂2 L(b) is a potential source of problems: non-convexity and asymptotic variance inﬂation. One may therefore wonder whether this term could not be made to disappear altogether. In fact, it can, and the condition it generates constrains the weight function ω(q) and the link function q(F ) to each other in a “canonical” way that coincides with the meaning of “canonical link functions” in generalized linear models. As implied by the previous section, canonicity has beneﬁts: the loss function L(y|q(F )) is convex, Newton interations and Fisher scoring are the same, the second derivative and hence the degree of convexity is not directly aﬀected by the response values yn, and the ingredients of the asymptotic variance take on a simple and robust form: Var ∂L(b) = 1 • Squared error loss: L1(1 − q) = (1 − q)2 and L0(q) = q2, hence the inverse link is essentially the identity transform: F (q) = 2q − 1 . • Log-loss: L1(1 − q) = − log(q) and L0(q) = − log(1 − q), hence, as is well-known, the natural link is the logit, F (q) = log q 17 Information measures for tree estimation Proper scoring rules and information measures such as the Gini index and entropy are in a one-to-one relationship. Given an expected loss R(η|q) = ηL1(1 − q) + (1 − η)L0(q), the associated information measure is the minimal achievable loss, which we write as H(η) = min q R(η|q) = R(η|η) . Information measures are of technical interest; see for example Zhang (2004; Def. 2.1, Lemma 2.1), Lugosi and Vayatis (2004; Lemma 4), Bartlett, Jordan and McAuliﬀe (2003; Section 2). — Information measures are also of practical interest in algorithms for tree-based classiﬁcation: CART (Breiman et al. 1984) uses the Gini index, and C4.5 (Quinlan 1993) and the original tree functions in the S language (Clark and Pregibon 1992) use entropy. The former is the information measure derived from squared error loss, the latter from log-loss. Tree algorithms agree with each other in that they all estimate local conditional class proba- bilities with simple proportions, but they diﬀer in how they judge the ﬁt of these proportions in terms of information measures. Here are the usual examples from the Beta family: They are also contained in a similar list given by Zhang (2004, after Deﬁnition 2.1): • α = β = −1/2: Boosting loss leads to a semi-circle criterion, H(q) = 2 · [q(1 − q)] 1/2 . • α = β = 0: Log-loss leads to entropy, H(q) = −q log(q) − (1 − q) log(1 − q) . • α = β = 1: Squared error loss leads to the Gini index, H(q) = q(1 − q) . • α, β → ∞, α η H(η)=L(η|η) q1 H(q1) L(η|q1) q2 H(q2) L(η|q2) q3 H(q3) L(η|q3) Figure 8: Envelopes and proper scoring rules: For a true η and any estimate q, the proper scoring rule can be read oﬀ the tangent of the envelope H() at q evaluated at the location η. Trivially, the minimum of R(η|q) w.r.t. q is taken on at q = η. The solid vertical segments at η rising from H(η) indicate the Bregman distances between η and qi: B(η|qi) = R(η|qi)−H(η) (Section 19). concave function, it determines a proper scoring rule R(η|q) which is unique except at lo- cations where there are multiple upper tangents, in which case any of the tangents can be selected as part of the deﬁnition of the proper scoring rule. Corollary: If H(q) is concave and smooth, its associated proper scoring rule is L1(1 − q) = H(q) + H′(q) (1 − q) , L0(q) = H(q) − H′(q) q . (49) This proposition in some form goes back to Savage (1971). A generalization from the binary case to general probability spaces and a careful analysis for the ﬁnite case is given by Gneiting and Raftery (2004, Theorems 2.1, 3.2 and 3.4). For a proof, note that R(η|q) is aﬃne in η and R(η|q) ≥ H(η), which makes η ↦→ R(η|q) an upper tangent for all q and hence H(q) the concave lower envelope. Conversely, given a concave function H(q), there exist upper tangents at every q. They are aﬃne functions and can be written η ↦→ η T1(q) + (1 − η) T0(q), so one can deﬁne L1(1 − q) = T1(q) and L0(q) = T0(q). For the corollary, the upper tangent at q is unique and can be written as an aﬃne function η ↦→ H′(q)(η−q)+H(q). Hence R(η|q) = H′(q)(η − q) + H(q) deﬁnes the proper scoring rule: L1(1 − q) = R(1|q) and L0(q) = R(0|q). 30 Proposition: If H(q) is concave and suﬃciently smooth, the weight function ω(q) and the canonical link function of the associated proper scoring rule are: ω(q) = − H′′(q) , F (q) = − H′(q) . (50) The proof is a simple calculation. The relation links concavity and non-negative weights, as well as strict concavity and positive weights. The proposition indicates that information measures with the same second derivative are equivalent. In other words, information mea- sures that diﬀer only in an aﬃne function are equivalent: H(q) + C1 q + C0 (1 − q). This fact follows for all information measures, not only smooth ones, from the equivalence of proper scoring rules that diﬀer in two constants only, L1(1 − q) + C1 and L0(q) + C0. The mixture proposition of Section 7 for proper scoring rules has an immediate analog for information measures: Proposition: Under conditions analogous to Theorem 1, information measures are mixtures of cost-weighted Bayes risks (48) with ω(dc) as the mixing measure: H(q) = ∫ 1 0 Hc(q) ω(dc) . (51) Tailored classiﬁcation trees: In light of the above facts it is natural to apply the tailoring ideas of Section 12 to information measures used in tree-based classiﬁcation. The idea is again to put weight on the class probabilities that are of interest. “Weight” is meant literally in terms of the weight function ω(q). In practice, areas of interest are often the extremes with highest or lowest class probabilities. In the Pima Indians Diabetes data (Section 18), for example, this may mean focusing on the cases with an estimated probability of diabetes of 0.9 or greater. It would then be reasonable to use an information measure derived from a weight function that puts most of its mass on the right end of the interval (0,1). In Section 18 we will show experiments with weights that are simple power functions of q. In terms of the Beta family of weights (Section 11) this could mean using β = 1 and α > 1: ω(q) ∼ qα−1. An associated information measure is H(q) ∼ −qα+1, but taking advantage of the indeterminacy of information measures modulo aﬃne functions, an equivalent but more pleasing choice is H(q) = (1 − qα)q, which is normalized such that H(0) = H(1) = 0. 18 A data example for tailoring in classiﬁcation trees “Tailoring” means putting weight ω(q) on the class probabilities of greatest interest. In practice, areas of interest are often the extremes with highest or lowest class probabilities. In the Pima Indians Diabetes data (UCI ML Repository, Newman et al. 1998), for example, this may mean focusing on the cases with an estimated probability of diabetes of 0.9 or greater. We interpret this as meaning that increasing values of q are of increasing interest, implying an ascending ω(q). In our experiments we used members of the Beta family that are simple power functions of q: ω(q) ∼ qα−1 (β = 1 and α > 1). An associated information 31 measure is H(q) ∼ −qα+1, but taking advantage of the indeterminacy of information mea- sures modulo aﬃne functions, an equivalent but more pleasing choice is H(q) = (1 − qα)q, which is normalized such that H(0) = H(1) = 0. Our experiments use again the Pima Indians Diabetes data (UCI ML Repository, New- man et al. 1998). Figure 18 shows a conventional tree grown with the Gini index (ω(q) = const). The depth to which it is grown and the quality of the ﬁt is not of concern; instead, we focus on interpretability. This tree shows the usual relative balance whereby most splits are not more lopsided than about 1:2 in bucket size. Overall, interpretation is not easy, at least in comparison to the trees shown in the following two ﬁgures. The tree in Figure 18 is based on the parameters α = 16 and β = 1, which means a strong focus on large class 1 probabilities (more correctly: class 1 frequencies). By contrast, Figure 18 is based on α = 1 and β = 31, hence a strong focus on small class 1 probabilities. The focus on the upper and the lower end of probabilities in these two trees amounts to prioritizing the splits according to decreasing and increasing class 1 probabilities from the top down. Figure 18 therefore shows a highly unbalanced tree that peels oﬀ small terminal nodes with high class 1 probabilities from the top down. The result is a cascading tree that layers the data as best as possible from highest to lowest class 1 probabilities. The dual eﬀect is seen in Figure 18. While it may be true that the lopsided focus of the criterion is likely to lead to suboptimal trees for prediction, cascading trees are vastly more powerful in terms of interpretation: they are able, for example, to express monotone dependences between predictors and responses. This is illustrated by both cascading trees: “plasma”, the most frequent splitting variable, appears to correlate positively with the probability of diabetes; as we descend the trees and as the splitting values on “plasma” decrease in Figure 18 and increase in Figure 18, the class 1 probabilities decrease and increase, respectively. In Figure 18 the variable “b.mass” asserts itself as the second most frequent predictor, and again a positive association with class 1 probabilities can be gleaned from the tree. Similarly, Figure 18 exhibits positive dependences for “age” and “pedigree” as well. A second aspect that helps the interpretation of cascading trees is the fact that repeat appearances of the same predictors lower the complexity of the description of low hanging nodes. For example, in Figure 18 the right most leaf at the bottom with the highest class 1 probability q = 0.91 is of depth nine, yet it does not require nine inequalities to describe it. Instead, the following four suﬃce: “plasma > 155”, “pedigree > 0.3”, “b.mass > 29.9” and “age > 24”. Interestingly the tree of Figure 18 that peels oﬀ low class 1 probabilities ends up with a crisper high-probability leaf than the tree of Figure 18 whose greedy search for high class 1 probabilities results only in an initial leaf with q = 0.86 characterized by the single inequality “plasma > 166”. We reiterate and summarize: the extreme focus on high or low class 1 probabilities cannot be expected to perform well in terms of conventional prediction, but it may have merit in producing trees with vastly greater interpretability. The present approach to interpretable trees produces results that are similar to an earlier proposal by Buja and Lee (2001) based on splitting that maximizes the larger of the two class 1 probabilities. The advantage of the tailored trees introduced here is that there actually exists a criterion that is being minimized, 32|plasma<127/plasma>127age<28/age>28b.mass<30.9/b.mass>30.9plasma<104/plasma>104pedigree<0.48/pedigree>0.48plasma<99/plasma>99b.mass<29.6/b.mass>29.6b.mass<29.9/b.mass>29.9plasma<157/plasma>157age<30/age>300.0000.0400.1160.2600.1190.2910.4890.3200.4600.7230.8701.00:0.000.96:0.040.88:0.120.74:0.260.88:0.120.71:0.290.51:0.490.68:0.320.54:0.460.28:0.720.13:0.87sz= 12.1%sz= 6.6%sz= 9.2%sz= 6.6%sz= 8.9%sz= 7.3%sz= 11.7%sz= 10.0%sz= 6.6%sz= 8.6%sz= 12.2%0.65:0.350.81:0.190.91:0.090.99:0.010.82:0.180.68:0.320.59:0.410.38:0.620.28:0.720.39:0.61sz=100.0%sz= 62.5%sz= 34.6%sz= 18.8%sz= 15.8%sz= 27.9%sz= 19.0%sz= 37.5%sz= 27.5%sz= 15.3%Classification Tree : method = Gini misclass. error = 0.22 (167/752) Figure 9: Tree based on the Gini criterion, as in CART. Each split shows the predictor variable and the threshold that were used. Each node shows the ratio of class 0 to class 1 and the size of the node. The terminal nodes redundantly show the ﬁnal ﬁtted class 1 probability. 33|plasma<166/plasma>166plasma<143/plasma>143b.mass<40.7/b.mass>40.7pedigree<0.83/pedigree>0.83plasma<130/plasma>130age<39/age>39age<30/age>30plasma<118/plasma>118pedigree<0.5/pedigree>0.5b.mass<29/b.mass>290.0110.0650.1600.1960.2620.3260.3730.4400.5000.5980.8610.99:0.010.94:0.060.84:0.160.80:0.200.74:0.260.67:0.330.63:0.370.56:0.440.50:0.500.40:0.600.14:0.86sz= 11.7%sz= 10.2%sz= 6.6%sz= 6.8%sz= 8.6%sz= 11.4%sz= 7.8%sz= 6.6%sz= 6.6%sz= 12.9%sz= 10.5%0.65:0.350.71:0.290.76:0.240.79:0.210.81:0.190.83:0.170.88:0.120.91:0.090.93:0.070.96:0.04sz=100.0%sz= 89.5%sz= 76.6%sz= 69.9%sz= 63.3%sz= 55.5%sz= 44.0%sz= 35.4%sz= 28.6%sz= 21.9%Classification Tree : method = Ploss a = 16 b = 1 misclass. error = 0.25 (188/752) Figure 10: Tree that focuses on large class 1 probabilities (α = 16, β = 1). 34|b.mass<23.2/b.mass>23.2plasma<94/plasma>94age<25/age>25b.mass<26.3/b.mass>26.3plasma<107/plasma>107age<24/age>24b.mass<29.9/b.mass>29.9plasma<123/plasma>123pedigree<0.3/pedigree>0.3plasma<155/plasma>1550.0170.0160.1380.1410.2530.3250.4060.4200.5870.7210.9140.98:0.020.98:0.020.86:0.140.86:0.140.75:0.250.68:0.320.59:0.410.58:0.420.41:0.590.28:0.720.09:0.91sz= 7.8%sz= 8.4%sz= 7.7%sz= 10.4%sz= 12.6%sz= 10.2%sz= 8.5%sz= 9.2%sz= 8.4%sz= 9.0%sz= 7.7%0.65:0.350.62:0.380.93:0.070.56:0.440.51:0.490.45:0.550.40:0.600.35:0.650.26:0.740.19:0.81sz=100.0%sz= 92.2%sz= 16.1%sz= 76.1%sz= 65.7%sz= 53.1%sz= 42.8%sz= 34.3%sz= 25.1%sz= 16.8%Classification Tree : method = Ploss a = 1 b = 31 misclass. error = 0.23 (175/752) Figure 11: Tree that focuses on small class 1 probabilities (α = 1, β = 31). 35 and tree-performance can be measured in terms of this criterion. 19 Proper scoring rules and their Bregman distances Any proper scoring rule has an associated “Bregman distance” (Bregman 1967) deﬁned as B(η|q) = R(η|q) − H(η) . (52) See again Figure 8. A Bregman distance is the expected loss of a proper scoring rule nor- malized such that a value zero obtains for the minimum at q = η: inf q B(η|q) = B(η|η) = 0 . Because B and R diﬀer only in a function of η, minimizing one or the other w.r.t. q is equivalent. Because R(η|q) is aﬃne in η and H(η) is concave, Bregman distances as deﬁned here are convex in the ﬁrst argument η. There is a division of labor between proper scoring rules and Bregman distances in that the latter are technically useful in proofs whereas proper scoring rules are practically useful in estimation. The technical usefulness of Bregman distances stems from the fact that they describe the excess of the proper scoring rule of an estimate q above the best achievable value of a proper scoring rule. If a procedure can be shown to have zero Bregman distance in the limit, it means that it achieves the minimal possible value of the proper scoring rule. Bregman distances are used in proving convergence of boosting algorithms (Laﬀerty et al. 1997, Collins et al. 2002) and in proving consistency of boosting-inspired algorithms as class probability estimation methods (Lugosi and and Vayatis 2004, Zhang 2004). Bregman distances are non-negative but not generally symmetric in their arguments. They are therefore not metrics in the usual sense, yet by convention the term “distance” is used, although the variant “Bregman divergence” is in use also. The closest thing to squared distances is given by the following second order approximation which, however, exhibits asymmetry again: B(η|q) ≈ 1 • α = β = 0: Log-loss leads to Kullback-Leibler divergence, B(η|q) = − η log q The meaning of Bc(η|q) is easily seen from Figure 2 where the lightly shaded area is bounded by (1 − η)t and η(1 − t) so that the diﬀerence is |(1 − η)t − η(1 − t)| = |η − t|. One infers immediately the following facts: η ≤ c : Bc(η|q) = (c − η) 1[c<q] , c < η : Bc(η|q) = (η − c) 1[q≤c] , (58) This can be summarized as follows: Lemma: Bc(η|q) = |η − c| · 1[min(η,q)≤c<max(η,q)] (59) This lemma is a pointwise version and generalization of an identity that is well-known in one form or another (see, e.g., Koltchinskii 2004, identity (1)). The mixture representations for proper scoring rules and information measures immedi- ately imply corresponding representations for Bregman distances: Proposition: Under the lower-bounding condition ∫ 1 0 t(1 − t)ω(dt) < ∞, the Bregman distance for ω(dt) is a mixture of cost-weighted excesses-over-Bayes: B(η|q) = ∫ 1 0 Bc(η|q) ω(dc) . From this proposition and the preceding lemma we immediately obtain: Corollary: B(η|q) = ∫ max(η,q) min(η,q) |η − c| ω(dc) . (60) This corollary is easily interpreted in terms of Figure 2 where the Bregman distance is essentially the integral of the lightly shaded area with regard to ω(dt). 21 A bias-variance decomposition for Bregman distances The results of the previous section can be used to derive a “bias-variance” type of decompo- sition for Bregman distances. To this end, we assume q to be a random variable with values in [0, 1]. In any application q will be a conditional estimate q(x) of class probability 1 given a ﬁxed predictor vector x. The estimate is random due to ﬁtting on a training dataset. There- fore, the expected value Eq, which we will need below, refers to averaging across training sets. For expected values of Bregman distances we write EqB(η|q) to indicate that only q is considered random. If EqB(η|q) is a generalized mean squared error, then we can deﬁne the minimizing η to be the generalized ﬁrst order moment: ηm = argminη Eq B(η|q) . 38 q η ηm t1 t2 t3 t4 t1 + t4 = t2 + t3 η q ηm t1 t2 t3 t4 t1 + t4 = t2 + t3 η ηm q t1 t2 t3 t4 t1 = t2 + t3 + t4 q ηm η t1 t2 t3 t4 t1 = t2 + t3 + t4 ηm q η t1 t2 t3 t4 t1 + t4 = t2 + t3 ηm η q t1 t2 t3 t4 t1 + t4 = t2 + t3 Figure 12: Proof of the decomposition (62) for excess-over-Bayes: t1, ..., t4 are the magnitudes of the four terms of Equation (62), t1 = Bc(η|q), t2 = Bc(η|ηm), t3 = Bc(ηm|q) and t4 = |Sc(η, ηm|q)|. Dark-gray indicates the ﬁrst term t1, which corresponds to the left hand side of (62). Note that the height of t4 is |η − ηm|. The six frames correspond to all possible orderings of q, η and ηm. For each ordering, the four terms add up as indicated at the top in each frame. These equalities are identical to (62) in each case, which completes the proof. With a stationariy condition it is easily seen that the idea of ηm as a generalized moment is correct: ∂ Thus, if EqB(η|q) is a generalized mean squared error, then EqB(ηm|q) is a generalized variance, and consequently B(η|ηm) would be a generalized squared bias. It will turn out that these three terms will add up to form a generalized bias-variance decomposition. We proceed with its derivation. The main idea is to prove a version for excess-over- Bayes and then use the mixture property of Bregman distances. The derivation relies on the piecewise linearity of the integrand c ↦→ Bc(η|q), which as a graph represents a triangle. The decomposition will amount to a jigsaw puzzle of triangles and rectangles, which is why we also need a piecewise constant function to represent rectangles, speciﬁcally deﬁned as follows: c ↦→ Sc(η, ηm|q) = − (η − ηm) sign(q − ηm) 1[min(q,ηm)≤c<max(q,ηm)] . We use the symbols q, η and ηm which have speciﬁc meaning, but in this deﬁnition they are just three arbitrary values in [0, 1]. The deﬁnition is arranged such that Sc(η, ηm|q) takes on a positive sign exactly when ηm is between η and q. This property is necessary to obtain the following identity for arbitrary q, η and ηm: Bc(η|q) = Bc(η|ηm) + Bc(ηm|q) + Sc(η, ηm|q) . (62) This identity is informally proven in the legend of Figure 21. Next we integrate both sides of the identity w.r.t. ω(dc) and generalize it from excess-over-Bayes to general Bregman distances. Assuming absolute continuity, ω(dc) = ω(c)dc, we note from the deﬁnition of Sc(η, ηm|q) that ∫ Sc(η, ηm|q) ω(dc) = − (η − ηm) (F (q) − F (ηm)) , where F (q) = ∫ q ω(c)dc is the canonical link function associated with ω(dt) (Section 16). Therefore: B(η|q) = B(η|ηm) + B(ηm|q) − (η − ηm) (F (q) − F (ηm)) . (63) This identity is reminiscent of an inner product expansion ∥a−b∥2 = ∥a∥2+∥b∥2−2⟨a, b⟩, and indeed it can be used to prove generalized Pythagorean theorems (see for example, Csisz´ar 1995; also Laﬀerty et al. 1997, Collins et al. 2002, Murata et al. 2004). In Pythagorean theorems one uses some sort of orthogonality between ηm −η and F (q) −F (ηm), for example, with regard to an inner product formed by integrating over x (Murata et al. 2004). Our goal, however, is a generalized bias-variance decomposition, which is why we now need the assumption that q is a random variable. Unlike Pythagorean theorems, we construct ηm in such a way that the term F (q) − F (ηm) disappears: F (ηm) = EF (q) , that is, we choose ηm to be the generalized ﬁrst moment with regard to EqB(η|q). Therefore: Theorem: If we assume the canonical link function F associated with ω(c) is invertible and the expectation of F (q) exists, and if ηm satisﬁes F (ηm) = EF (q) or equivalently 40 EqB(ηm|q) = minη EqB(η|q), we obtain the following generalized bias-variance decompo- sition: Eq B(η|q) = B(η|ηm) + Eq B(ηm|q) . (64) We note that the moment condition F (ηm) = EF (q) is simple only when the canonical link is used to form the composite loss function. In this case F (q(x)) = ˆb T x for a linear model, say, hence F (ηm) = Eˆb T x. Examples: For squared error loss, F () is linear, hence ηm = E q, and the decomposition specializes to the actual bias-variance decomposition because the Bregman distance is the square of the diﬀerence (56): Eq [(q − η)2] = (ηm − η)2 + Var q . For log loss, ηm is deﬁned by log(ηm/(1 − ηm)) = E log(q/(1 − q)), and the decomposition is for the Kullback-Leibler divergence (55). For boosting loss, the deﬁnition of ηm is not the same because (half) the logit is the actual link function used the composite exponential loss, but it is not the canonical link function. The bias-variance decomposition is for the Bregman distance (54). 22 Bounds on cost-weighted misclassiﬁcation loss We can use the mixture representation to derive bounds on Bc(η|q) in terms of B(η|q). We use the following facts: • A Bregman distance as a function of q, q ↦→ B(η|q), is descending for q < η and ascending for q > η. (This follows from B(η|q) = R(η|q) − H(η) and the corollary at the end of Section 6.) • Excess-over-Bayes as a function of q, q ↦→ Bc(η|q), is a step function with a step at q = c. (This follows from (58) above.) Thus, if we standardize both a Bregman distance and excess-over-Bayes such that their graphs pass through 1 at q = c, the former will dominate the latter, as depicted in Figure 13: (Bc(η|q) qnormalized Bregman distance 0 η c 101 q 0 c η 101 Figure 13: Bregman distance as a bound on excess-over-Bayes: The curves show sections of a normalized Bregman distance as a function of q for ﬁxed η: q ↦→ B(η|q)/B(η|c) (right hand side of Inequality (65)). The normalization has the sections go through 1 at a chosen classiﬁcation threshold c. Also shown is a step function representing excess-over-Bayes as a function of q, q ↦→ Bc(η|q)/|η − c| equally normalized to 1 at c (left hand side of Inequal- ity (65)). The two plots reﬂect the situations η < c and η > c. The bound is rather loose for η near c as the right hand plot shows. The problem with the term is that it is possibly ill-behaved because the denominator vanishes at η = c, unless the power k in the numerator is large enough to cause cancellation. This can indeed be achieved for k = 2, as is intuitively clear from Equation (53): B(η|c) ≈ 1 The assumption is true, for example, for the members of the Beta family for α, β ≤ 1, including squared error loss (α = β = 1), log-loss (α = β = 0), and boosting loss (α = β = −1/2). • Assume the weight function attains its maximum at c and descends with increasing distance from c. Then a bound is: Bc(η|q)2 ≤ 2 terms of Bregman distances could be used to generalize much of their programs to proper scoring rules in combination with arbitrary link functions. To this end one would consider estimates of class probabilities, ˆqN (X), and true class probabilities η(X) as functions on predictor space and examine the limiting behavior of E B(η(X)|ˆqN (X)). We will not carry this program forward but end by comparing Zhang’s and our analyses: • The assumption of convexity on the modeling scale, made by Zhang (2004) and others, can be replaced by the more natural assumption that the loss function is decomposable into a link function and a proper scoring rule. We thereby exclude some cases that do not conﬁne probability estimates to [0, 1], but we beneﬁt from the full information geometry that links Bregman distances and Bayes risks, even for combinations of proper scoring rules and link functions that result in non-convex losses, such as those for tailoring to speciﬁc costs c (Section 12) and implied by HV (2003) (Section 13). • Much of Zhang’s (2004, Section 2 and 3) interpretations hinge on bounds on misclas- siﬁcation loss for c = 0.5. We extend these bounds to arbitrary cost weights c ∈ (0, 1) and non-convex losses, but our interpretations ﬂow straighforwardly from the mixture representations: the costs c on which the weight function ω(c) puts the most mass are those for which the proper scoring rule attempts classiﬁcation with the greatest precision. 23 Summary and Discussion We developed a theory of binary class probability estimation based on Fisher-consistent loss functions, known as “proper scoring rules”. We showed that proper scoring rules L(y|q) have a simple structure in that they are mixtures of cost-weighted misclassiﬁcation losses: L(y|q) = ∫ Lc(y|q) ω(c)dc, where c and 1−c are the costs of false positives and false negatives, respectively. The weight function ω(c) has an immediate interpretation: the proper scoring rule emphasizes cost weights c to the degree that ω(c) puts mass on the costs c. This provides the heuristic for “tailoring” of proper scoring rules to arbitrary costs c and 1 − c, in particular costs other than 0.5. Tailoring addresses situations in which false positives and false negatives have diﬀerent cost implications and where the class of ﬁts succeeds for classiﬁcation but fails for global class probability estimation. We showed that any proper scoring rule combined with any link function can be used to ﬁt linear and additive class probability models to binary response data. The IRLS algorithm used to this end can be given a stagewise additive and hence boosting-like form, with LogitBoost (FHT 2000) as a particular instance. Furthermore, information measures associated with proper scoring rules can equally be tailored and used for estimating tree-based models in novel ways. Although we see our study as having practical implications mostly for linear and tree models, it was initially motivated by boosting (FHT 2000) and it does indeed address two conceptual limitations of the boosting literature: One limitation has to do with the notion of “large-margin classiﬁers”, where margin is deﬁned as −y∗ F (x) (y∗ = ±1) and loss functions L(−y∗ F (x)) are assumed monotone increasing and convex in the margin. This dependence on the margin limits all theory and practice to a symmetric treatment of class 0 and class 1, 44 and in particular to the equal-cost case c = 1 − c = 0.5. The possibility of asymmetric treatment is apparent from the identity L(−y∗ F (x)) = yL(−F (x)) + (1 − y)L(F (x)) which could be freed of the constraint of equal partial losses L() in the two terms. — The second limitation of the boosting literature has to do with the idea that L() should be convex. We gave evidence that convexity is not a structural necessity for large-margin classiﬁers and that a more plausible requirement is decomposability of the loss function into a (inverse) link function q(F ) and a proper scoring rule L(y|q): L(y|q(F (x))) = yL1(1 − q(F (x))) + (1 − y)L0(q(F (x))) . This approach makes it plain that margin is linked to class probabilities and that the loss function is meant to estimate class probabilities in a Fisher consistent manner. Link functions and class probability estimation have been lurking in the literature, in particular in the “Three Papers on Boosting” (Jiang; Lugosi and Vayatis; Zhang; 2004). This leaves us with the old question of why boosting so often classiﬁes well even though it vastly overﬁts in terms of class probabilities (Mease et al. 2005). The answer is that boosting does rely on class probability gradients without attempting to estimate class probability with any precision. This explains what should not be a surprise: boosting can improve misclassiﬁcation error out-of-sample even after it has dropped to zero in-sample — the surrogate criterion keeps borrowing strength from data points with estimated probabilities above and below the cut- oﬀ, c = 0.5, even if these estimates run oﬀ to 0 and 1 due to overﬁt. The degree of reliance on these estimates is revealed by the weight function ω(c). References [1] BARTLETT, P. L., JORDAN, M. I., and MCAULIFFE, J. D. (2003). Large margin classiﬁers: convex loss, low noise, and convergence rates. In: Advances in Neural Infor- mation Processing Systems 16. [2] BARTLETT, P. L., JORDAN, M. I., and MCAULIFFE, J. D. (2004). Discussion of Jiang (2004), Lugosi and Vayatis (2004) and Zhang (2004). The Annals of Statistics, 32, 85-91. [3] BASU A., HARRIS, I. R., HJORT, N.L., and JONES, M.C. (1998), Robust and eﬃcient estimation by minimising a density power divergence, Biometrika, 85, 549-559. [4] BERNARDO, J. M., and SMITH, A. F. M. (2000). Bayesian Theory. Chichester, UK: Wiley and Sons. [5] BREGMAN, L. M. (1967). The Relaxation Method of Finding the Common Point of Convex Sets and its Applications to the Solution of Problems in Convex Programming. U.S.S.R. Computational Mathematics and Mathematical Physics 7 (1), 200-217. [6] BREIMAN, L. (1996). Bias, variance and arcing classiﬁers. Technical Report 460, Statis- tics Department, University of California at Berkeley, Berkeley, CA. 45 [7] BREIMAN, L., FRIEDMAN, J. H., OLSHEN, R., and STONE, C. J. (1984). Classiﬁ- cation and Regression Trees, Belmont, California: Wadsworth. [8] BRIER, G. W. (1950). Veriﬁcation of Forecasts Expressed in Terms of Probability. Monthly Weather Review, 78, 1-3. [9] BUJA, A., SHEN, Y., and STUETZLE, W. (2005). Cost-Weighted Mis- classiﬁcation and Class Probability Estimation Technical Report, http://www- stat.wharton.upenn.edu/˜buja/paper-cost-weighting.pdf [10] BUJA, A., and LEE, Y.-S. (2001). Data Mining Criteria for Tree-Based Regression and Classiﬁcation, Proceedings of KDD 2001, 27-36. [11] CLARK, L. A., and PREGIBON, D. (1992). Tree-Based Models, in Statistical Models in S, edited by J. M.CHAMBERS and T. J. HASTIE, Paciﬁc Grove, CA: Wadsworth & Brooks/Cole, 377-419. [12] COLLINS, M., SCHAPIRE, R. E., and SINGER, Y. (2002). Logistic Regression, Ad- aBoost and Bregman Distances, Machine Learning, 48 (1/2/3). [13] CRESSIE, N. and READ, T. R. C. (1984). Multinomial Goodness-of-ﬁt Tests, J. R. Statist. Soc. B, 46, No. 3, 440-464. [14] CSISZ ´AR, I. (1995). Maxent, mathematics, and information theory. In Proceedings of the Fifteenth International Workshop on Maximum Entropy and Bayesian Methods, 35-50. [15] DEGROOT, M., and FIENBERG, S.E. (1983). The Comparison and Evaluation of Probability Forecasters. The Statistician 32, 12-22. [16] GNEITING, T., and RAFTERY, A. E. (2004). Strictly Proper Scor- ing Rules, Prediction, and Estimation. Technical Report no. 463, Dept. of Statistics, Univ. of Washington. Preprint available from http://www.stat.washington.edu/www/research/reports/2004/tr463.pdf [17] FREUND, Y., and SCHAPIRE, R. (1996). Experiments with a New Boosting Algo- rithm. In: Machine Learning: Proceedings of the Thirteenth International Conference, 148-156. [18] FREUND, Y., and SCHAPIRE, R. (2004). Discussion of Jiang (2004), Lugosi and Vayatis (2004) and Zhang (2004). The Annals of Statistics, 32, 113-117. [19] FRIEDMAN, J.H., HASTIE, T., and TIBSHIRANI, R. (2000). [Abbreviated FHT.] Additive Logistic Regression: A Statistical View of Boosting, The Annals of Statistics 28, 337-407. [20] FRIEDMAN, J. H. (2001). Greedy function approximation: A gradient boosting ma- chine. The Annals of Statistics 29, 1189-1232. 46 [21] HAND, D. J., and VINCIOTTI, V. (2003). [Abbreviated HV.] Local Versus Global Models for Classiﬁcation Problems: Fitting Models Where it Matters. The American Statistician 57, 124-131. [22] JIANG, W. (2004). Process Consistency for AdaBoost. The Annals of Statistics 32, 13-29. [23] KEARNS, M., and MANSOUR, Y. (1996). On the boosting ability of top-down decision tree learning algorithms. Proceedings of the Annual ACM Symposium on the Theory of Computing, 459-468. [24] KOLTCHINSKII, V. (2004). “Discussion” of “Three Papers on Boosting”. The Annals of Statistics 32, 107-113. [25] LAFFERTY, J. D., DELLA PIETRA S., and DELLA PIETRA V. (1997). Statistical Learning Algorithms based on Bregman Distances, in: Proceedings of the Canadian Workshop on Information Theory 1997. [26] LUGOSI, G., and VAYATIS, N. (2004). On the Bayes-Risk Consistency of Regularized Boosting Methods, The Annals of Statistics 32, 30-55. [27] MCCULLAGH, P. and NELDER, J. A. (1989). Generalized Linear Models (2nd edition), London: Chapman & Hall/CRC. [28] MEASE, D., WYNER, A. J., and BUJA, A. (2005). Boosted Classication Trees and Probability/Quantile Estimation. Submitted. [29] MURATA, N., TAKENOUCHI, T., KANAMORI, T., and EGUCHI, S. (2004). In- formation Geometry of U-Boost and Bregman Divergence. Neural Computation, 16, 1437-1481. [30] MURPHY, A.H., and DAAN, H. (1985). Forecast Evaluation, in: Probability, Statistics and Decision Making in the Atmospheric Sciences, eds. Murphy, A.H. and Katz, P.W. [31] QUINLAN, J.R. (1993). C4.5: Programs for Machine Learning. San Francisco, CA: Morgan Kaufmann Publishers. [32] SAVAGE, L.J. (1971). Elicitation of Personal Probabilities and Expectations, J. of the American Statistical Association 66, No. 336, 783-801. [33] SCHERVISH, M.J. (1989). A General Method for Comparing Probability Assessors, The Annals of Statistics 17, 1856-1879. [34] SHUFORD, E. H., ALBERT, A., and MASSENGILL, H. E. (1966). Admissible Prob- ability Measurement Procedures, Psychometrika 31, 125-145. [35] SCHAPIRE, R. E., and SINGER, Y. (1998). Improved Boosting Algorithms Using Conﬁdence-Rated Predictions, in Proceedings of the Eleventh Annual Conference on Computational Learning Theory. 47 [36] SCHAPIRE, R. E. (2002). The Boosting Approach to Machine Learning: An Overview. In: MSRI Workshop on Nonlinear Estimation and Classiﬁcation. [37] SHAO, J. (2003). Mathematical Statistics, New York: Springer. [38] NEWMAN, D. J., HETTICH, S., BLAKE, C. L., and MERZ, C.J. (1998). UCI Repository of machine learning databases [http://www.ics.uci.edu/˜mlearn/MLRepository.html]. Irvine, CA: University of California, Department of Information and Computer Science. [39] WINKLER, R. L (1993). Evaluating Probabilities: Asymmetric Scoring Rules, Man- agement Science 40, No. 11, 1395-1405. [40] ZHANG, T. (2004). Statistical Behavior and Consistency of Classiﬁcation Methods based on Convex Risk Minimization. The Annals of Statistics (to appear). 48","libVersion":"0.3.2","langs":""}