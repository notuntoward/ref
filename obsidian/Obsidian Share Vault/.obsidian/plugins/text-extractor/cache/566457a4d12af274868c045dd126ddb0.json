{"path":"lit/lit_sources/Donti23optInLoopTalk.pdf","text":"Optimization-in-the-loop ML for energy and climate Priya L. Donti Executive Director, Climate Change AI Incoming Assistant Professor, MIT Climate change warrants rapid action Impacts felt globally Disproportionate impacts on most disadvantaged populations Need net-zero greenhouse gas emissions by 2050 (IPCC 2018) - Across energy, transport, buildings, industry, agriculture, forestry, etc. Can machine learning play a role? 2 Filippo Monteforte | AFP | Getty Images David Mcnew | Getty Images NASA Piyaset | Shutterstock.com 3 Electricity systems Buildings & cities Transportation Farms & forests Climate prediction Industry Societal adaptationarXiv:1906.05433v1 [cs.CY] 10 Jun 2019 Tackling Climate Change with Machine Learning David Rolnick1 ∗,Priya L.Donti2,Lynn H.Kaack3,Kelly Kochanski4,Alexandre Lacoste 5, Kris Sankaran6,7,Andrew Slavin Ross8,Nikola Milojevic-Dupont9,10,Natasha Jaques11, Anna Waldman-Brown11,Alexandra Luccioni6,7,Tegan Maharaj6,7,Evan D.Sherwin2, S. Karthik Mukkavilli6,7,Konrad P.Kording1,Carla Gomes12,Andrew Y.Ng13, Demis Hassabis14,John C. Platt15,Felix Creutzig9,10,Jennifer Chayes16,Yoshua Bengio6,7 1University of Pennsylvania, 2Carnegie Mellon University, 3ETH Z¨urich, 4University of Colorado Boulder, 5Element AI, 6Mila, 7Universit´e de Montr´eal, 8Harvard University, 9Mercator Research Institute on Global Commons and Climate Change, 10Technische Universit¨at Berlin, 11Massachusetts Institute of Technology, 12Cornell University, 13Stanford University, 14DeepMind, 15Google AI, 16Microsoft Research Abstract Climate change is one of the greatest challenges facing humanity, and we, as machine learning ex- perts, may wonder how we can help. Here we describe how machinelearning can bea powerful tool in reducing greenhouse gas emissions and helping society adaptto a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be ﬁlled by machine learning, in collaboration with other ﬁelds. Our recommendations encompass exciting research ques- tions as well as promising business opportunities. We call onthe machine learning community to join the global effort against climate change. Introduction The effects of climate change are increasingly visible.1 Storms, droughts, ﬁres, and ﬂooding have become stronger and more frequent [3]. Global ecosystems are changing, including the natural resources and agri- culture on which humanity depends. The 2018 intergovernmental report on climate change estimated that the world will face catastrophic consequences unless globalgreenhouse gas emissions are eliminated within thirty years [4]. Yet year after year, these emissions rise. Addressing climate change involves mitigation (reducing emissions) and adaptation (preparing for un- avoidable consequences). Both are multifaceted issues. Mitigation of greenhouse gas (GHG) emissions re- quires changes to electricity systems, transportation, buildings, industry, and land use. Adaptation requires climate modeling, risk prediction, and planning for resilience and disaster management. Such a diversity of problems can be seen as an opportunity: there are many ways to have an impact. In recent years, machine learning (ML) has been recognized asa broadly powerful tool for technological progress. Despite the growth of movements applying ML and AI to problems of societal and global good,2 ∗D.R. conceived and edited this work, with P.L.D., L.H.K., andK.K. Authors P.L.D., L.H.K., K.K., A.L., K.S., A.S.R., N.M-D., N.J., A.W-B., A.L., T.M., and E.D.S. researched and wrote individual sections. S.K.M., K.P.K., C.G., A.Y.N., D.H., J.C.P., F.C., J.C., and Y.B. contributed expert advice. Correspondence to drolnick@seas.upenn.edu. 1For a layman’s introduction to the topic of climate change, see [1, 2]. 2See the AI for social good movement (e.g. [5, 6]), ML for the developing world [7], and the computational sustainability 1 Power & energy problems involve physics, hard constraints, and decision-making Figure adapted from: US Congressional Budget Office Physics: Power flows along lines Hard constraints: Equipment constraints Decision-making: Given (uncertain) demand, how do we schedule supply? 4 Hard constraints: Stability constraints Machine learning methods struggle with physics, hard constraints, and decision-making Figure adapted from: US Congressional Budget Office Hard constraints: Equipment constraints Decision-making: Given (uncertain) demand, how do we schedule supply? Need: Adaptive control of power generators, inverters, and batteries - ML: Dynamic, data-driven control - Limitation: Difficulty enforcing constraints (physics, equipment, stability) Need: Electricity demand prediction - ML: Time series forecasting - Limitation: Difficulty making decision- cognizant error tradeoffs How do we reap the benefits of ML methods while mitigating limitations? Physics: Power flows along lines Hard constraints: Stability constraints 5 Optimization-in-the-loop ML Framework for developing ML methods that incorporate knowledge of physics, hard constraints, or downstream decision-making procedures, via optimization problems 6 Model Objective Optimization Optimization Optimization-in-the-loop ML Framework for developing ML methods that incorporate knowledge of physics, hard constraints, or downstream decision-making procedures, via optimization problems Examples: 7 Model !! ℎ!(#)# Inputs Outputs Functional form of model Model parameters Optimization-in-the-loop ML Framework for developing ML methods that incorporate knowledge of physics, hard constraints, or downstream decision-making procedures, via optimization problems Example: Robust control (e.g., power system control with stability constraints) Example: Prediction (e.g., decision-cognizant demand forecasting) 8 Model !! ℎ!(#)# System state Control action Optim. Model !! ℎ!(#)# Historical data Prediction Optim. %⋆(#; ') Decision 9 Talk outline Optimization-in-the-loop ML Setting: Hard control constraints Setting: Downstream decision-making Toolkit: Differentiable optimization 10 Talk outline Setting: Hard control constraints Setting: Downstream decision-making Toolkit: Differentiable optimization Optimization-in-the-loop ML Overview: Differentiable optimization Motivation: Need for tools to implement optimization-in-the-loop methods Approach: Differentiable optimization in deep learning - General framework [GFCASG2016, AK2017, DAK2017] - Additional tools 11 Model Objective Optimization Optimization Model !! Background: Deep learning 12 \" ℎ\"(\") Loss, e.g., ℓ ), ℎ! # Inputs Outputs “Score” for quality of outputFunctional form of model Model parameters Model !! Background: Deep learning 13 - Neural network ℎ! = composition of nonlinear, parameterized functions (layers) - Update parameters ' to minimize loss ℓ using gradients from backpropagation - All components (layers and loss) must be differentiable \" ℎ\"(\") Loss, e.g., ℓ ), ℎ! # … ! ℎ!,#! ℎ$,#\"Optimization layer Backpropagation Differentiating through optimization problems 14 Brandon Amos and J. Zico Kolter. “OptNet: Differentiable optimization as a layer in neural networks.” ICML 2017. Priya L. Donti, Brandon Amos, and J. Zico Kolter. \"Task-based end-to-end model learning in stochastic optimization.\" NeurIPS 2017. Example optimization problem minimize ! ½ )\"*) + ,\") subject to 4) = 6 7) ≤ ℎ Selected KKT optimality conditions *)⋆ + , + 4 \":⋆ + 7\"; ⋆ = 0 4)⋆ − 6 = 0 diag ; ⋆ 7)⋆ − ℎ = 0 Step 1: Apply implicit function theorem to the KKT conditions \" #% $% diag ) ⋆ # diag(#+⋆ − ℎ) 0 $ 0 0 d+ d) dν = − d\"+⋆ + d2 + d#%)⋆ + d$%3⋆ diag )⋆ d#+⋆ − diag )⋆ dℎ d$+⋆ − d4 Generalized Jacobian of KKT conditions Desired gradients Gradients of problem parameters Step 2: Use “Jacobian-vector trick” for efficient backpropagation Insight: Apply the implicit function theorem to the KKT optimality conditions 15 [DAK2017, AK2017]: KKT differentiation techniques for convex optimization problems Many additional tools since then: - Combinatorial optimization [DK2017, TSK2018, WDT2018] - AC optimal power flow [DAK2018] - Disciplined convex programs [AABBDK2019] - Maximum satisfiability problems [WDWK2019] - Additional optimization problems [GHC2019] Powerful toolkit for optimization-in-the-loop ML in the context of deep learning Follow-on work in differentiable optimization 16 Talk outline Setting: Hard control constraints Setting: Downstream decision-making Toolkit: Differentiable optimization Optimization-in-the-loop ML Overview: Enforcing hard control constraints Motivation: Need for well-performing control methods that also guarantee enforcement of hard constraints 17 Approach: Optimization-in-the-loop reinforcement learning (RL) techniques with guaranteed enforcement of hard constraints Settings: - Asymptotic stability in power grids [DRFK2021] - Realistic-scale building control [CDBKB2021] Deep reinforcement learning vs. robust control Deep RL Robust control Pro: Expressive, well-performing policies Con: Potential (catastrophic) failures Can we improve performance while still guaranteeing stability? Pro: Provable stability guarantees Con: Simple policies (e.g., linear) Priya L. Donti, Melrose Roderick, Mahyar Fazlyab, and J. Zico Kolter. \"Enforcing robust control guarantees within neural network policies.\" International Conference on Learning Representations (ICLR) 2021. 18 Differentiable projection onto stabilizing actions Reward… \" #$ !Projection onto!\" $ Deep learning-based policy with provable robustness guarantees, trainable using standard reinforcement learning approaches System state Nominal action Action Model (*) Backpropagate 19 Details: Finding a set of stabilizing actions Given the following (from robust control): - Uncertainty model: e.g., ̇\" # ∈ %\" # + '( # + )* # s. t. ||* # ||5 ≤ ||0\" # + 1( # ||5 - Lyapunov function 2 obtained via robust control synthesis - Exponential stability criterion: ̇# $ % ≤ −(#($ % ), ∀$ ≠ 0 Find: For given \", set of actions satisfying exponential stability criterion even in worst case 3 \" ≡ { (: sup 6 ∶ 6 $8 9:;<= $ ̇2 \" ≤ −:2 \" } ⇒ {(: => \" + 1( 5 ≤ =5 \" + =? \" @(} 20 Convex (non-empty) set in / % Note: A-dependence has been dropped for brevity {u : S (u) < 0} Kx(t) f (x(t)) π(x(t)) A B C D# B C EB(C) FD# B C Convex projection Insight: Find a set of actions that are guaranteed to satisfy relevant Lyapunov stability criteria at a given state, even under worst-case conditions Illustrative results: Synthetic NLDI system 1 10 100 1000 10000 LQR MBP PPO Robust LQR Robust MBP* Robust PPO*LQR Cost (log scale) Ordinary Adversarial 1 10 100 1000 10000 LQR MBP PPO Robust LQR Robust MBP* Robust PPO*LQR Cost (log scale) Ordinary Adversarial Non-robust methods Our methodsRobust control 21 Unstable Stable Improved “average-case” performance over robust baselines Provably stable under “worst-case” dynamics (unlike non-robust baselines) Downside: Speed / computational cost [lower is better] Energy-efficient heating and cooling Goal: Control the HVAC supply water temperature to minimize energy use, while respecting equipment constraints and maintaining thermal comfort 22 Intelligent Workplace Margaret Morrison Hall, 4th Floor (✤ Zhang & Lam, 2018) HVAC Schematic Bingqing Chen*, Priya L. Donti*, Kyri Baker, J. Zico Kolter, and Mario Berges. \"Enforcing Policy Feasibility Constraints through Differentiable Projection for Energy Optimization.\" ACM International Conference on Future Energy Systems (ACM e-Energy) 2021. Differentiable projection onto feasible actions Reward… \" #$ !Projection ontofeasible actions $ System state Nominal action Action Model (*) 23 Summary: Enforcing hard control constraints Motivation: Need for well-performing control methods that also guarantee enforcement of hard constraints Settings: - Asymptotic stability in power grids [DRFK2021] - Realistic-scale building control [CDBKB2021] Insight: Project outputs of neural network onto a set of “safe” actions - Obtain safe actions using domain knowledge - Differentiable projection (optimization layer) = end-to-end training Future directions: - Additional paradigms for bridging RL and robust control - Improving computational costs 2425 Talk outline Setting: Hard control constraints Setting: Downstream decision-making Toolkit: Differentiable optimization Optimization-in-the-loop ML Motivation: Predictive methods operate within some larger decision-making process but do not often take this into account, potentially leading to critical mistakes. 26 Approach: Construction of decision-cognizant (“task-based”) models via optimization-in- the-loop learning Settings: - Decision-cognizant electricity demand forecasting [DAK2017] - Approximating AC optimal power flow [DRK2021] Overview: Incorporating downstream decision-making Decision-cognizant demand forecasting Past demand, weather, time ≡ \" Future demand (w/ uncertainty) ≡ #ℎ!? Usual goal: Minimize distance between predicted and actual quantities (e.g., demand) minimize ! ℓ(#, ℎ! \" ) Generation schedule (e.g.) ≡ . Goal: Optimize for quality of generation schedule when we observe actual demands minimize ! /B(#, .⋆ \"; 1 ) Priya L. Donti, Brandon Amos, and J. Zico Kolter. \"Task-based end-to-end model learning in stochastic optimization.\" Conference on Neural Information Processing Systems (NeurIPS) 2017. 27 Decision-cognizant model 28 %>(', )⋆)… \" +' !Power system optimization )⋆ Loss function Backpropagate Past demand, weather, time Generation schedule Predicted demand Decision-cognizant approach can dramatically improve generation scheduling outcomes Decision-cognizant approach gives ~39% improvement in decision cost. 29 (ours)Decision cost (ours)RMSE [lower is better] [lower is better] Approximating AC optimal power flow Goal: Provide fast, feasible approximations to AC optimal power flow (ACOPF) Approach: 30 minimize subject to costs physicspower demand power generation ACOPF power demand power generation Priya L. Donti*, David Rolnick*, and J. Zico Kolter. \"DC3: A learning method for optimization with hard constraints.” International Conference on Learning Representations (ICLR) 2021. physical quantities infeasibilities costs + Loss functionphysics Results (57-bus test case): High-quality solutions 10x faster than baseline optimizer Motivation: Predictive methods operate within some larger decision-making process but do not often take this into account, potentially leading to critical mistakes. 31 Settings: - Electricity demand forecasting [DAK2017] - Approximating ACOPF [DRK2021] Summary: Incorporating downstream decision-making Insight: Incorporate knowledge of downstream decision-making (or physics) into the loss function, via differentiable optimization. Future directions: - Incorporating a wider range of decision-making paradigms - Understanding tradeoffs between task-agnostic vs. task-based models Summary - Optimization-in-the-loop ML (framework), via differentiable optimization in deep learning - Enforcing hard control constraints: RL with provable robustness / constraint enforcement - Asymptotic stability (power grids) - Operational constraints (HVAC in buildings) - Incorporating downstream decision-making: Decision-cognizant predictive models - Electricity demand forecasting - Approximate power system optimization 32 Model Objective Optim. Optim. Priya L. Donti: donti@mit.edu","libVersion":"0.3.2","langs":""}