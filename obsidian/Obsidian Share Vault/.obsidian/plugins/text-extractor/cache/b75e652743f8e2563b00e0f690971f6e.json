{"path":"lit/lit_notes_OLD_PARTIAL/CausuaLens23CausalGenAItogeth.pdf","text":"Causal AI & Generative AI Better Together 2 Together, Generative AI and Causal AI complement one another: responses grounded in cause-and-effect reality accessible through a fluid natural language interface. Generative AI Alone Cannot be Trusted with Decision-Making Generative AI provides a new way for users to interact with applications seamlessly with natural language. Nevertheless, Generative AI exhibits limitations when employed independently for enterprise decision-making due to issues related to consistency, transparency, and a deeper comprehension of causal relationships within data. Causal AI Enhances Generative AI Safety Causal AI offers a framework for building transparent models on top of cause-and-effect relationships grounded in real-world understanding, constraints, and domain expertise. Generative AI offers a powerful natural language interface that enhances the user experience with free text prompts. By providing the Causal AI tools to the Generative AI models, answers can be grounded in cause-and-effect reality, enhancing safety for enterprise decision- making. • The presence of cause-effect relationships within the data. • The direction of causation: which variables cause which others. • Critiquing the existing relationships, confirming or refuting them. • The mathematical type of relationship between two variables. causaLens has pioneered human guided causal discovery that blends domain expertise with the best algorithmic approaches to discover cause-effect relationships from data. Generative AI enhances this solution by introducing a domain knowledge co-pilot. The domain knowledge co-pilot can be relied upon to suggest: 3 System 2 Rational Thinking Conscious Logical Analytical System 1 Intuition & Instinct Unconscious Fast Intuitive Causal AIGenAI In many cases, this can remove the bottleneck of waiting for a human domain expert to begin causal discovery and allow data science practitioners to accelerate the process- allowing use cases to be scaled and accelerated. Human domain expertise remains integral to the process of retaining the ability to accept or reject these suggestions. All these suggestions are accompanied by natural language explanations justifying the suggestions made. This can be likened to how the two sides of the human brain serve as the foundations of our cognitive processes: Scale Causal AI with a Domain Knowledge Co-Pilot 4 Instant Human Interpretable Outputs Causal graphs are inherently transparent, clearly showing the relationships between variables. Meanwhile, causal models embed the mathematical relationships that flow through the graph. A generative model can simplify the interpretation of the causal model in a language more accessible to business users. Users can instantly receive explanations of causal relationships, models, and outputs, which enhances the accessibility and understanding of these artifacts. causaLens.com info@causaLens.com Get more info","libVersion":"0.3.2","langs":""}