{"path":"lit/lit_sources/Zhang01multiWvltFrcst.pdf","text":"IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 12, NO. 4, JULY 2001 765 Multiresolution Forecasting for Futures Trading Using Wavelet Decompositions Bai-Ling Zhang, Richard Coggins, Member, IEEE, Marwan Anwar Jabri, Senior Member, IEEE, Dominik Dersch, and Barry Flower, Member, IEEE Abstract—In this paper, we investigate the effectiveness of a financial time-series forecasting strategy which exploits the mul- tiresolution property of the wavelet transform. A financial series is decomposed into an over complete, shift invariant scale-related representation. In transform space, each individual wavelet series is modeled by a separate multilayer perceptron (MLP). To better utilize the detailed information in the lower scales of wavelet coef- ficients (high frequencies) and general (trend) information in the higher scales of wavelet coefficients (low frequencies), we applied the Bayesian method of automatic relevance determination (ARD) to choose short past windows (short-term history) for the inputs to the MLPs at lower scales and long past windows (long-term history) at higher scales. To form the overall forecast, the indi- vidual forecasts are then recombined by the linear reconstruction property of the inverse transform with the chosen autocorrelation shell representation, or by another perceptron which learns the weight of each scale in the prediction of the original time series. The forecast results are then passed to a money management system to generate trades. Compared with previous work on combining wavelet techniques and neural networks to financial time-series, our contributions include 1) proposing a three-stage prediction scheme; 2) applying a multiresolution prediction which is strictly based on the autocorrelation shell representation, 3) incorporating the Bayesian technique ARD with MLP training for the selection of relevant inputs; and 4) using a realistic money management system and trading model to evaluate the forecasting performance. Using an accurate trading model, our system shows promising profitability performance. Results comparing the performance of the proposed architecture with an MLP without wavelet preprocessing on 10–year bond futures indicate a doubling in profit per trade ($AUD1753:$AUD819) and Sharpe ratio improvement of 0.732 versus 0.367, as well as significant improvements in the ratio of winning to loosing trades, thus indicating significant potential profitability for live trading. Index Terms—Autocorrelation shell representation, automatic relevance determination, financial time series, futures trading, multilayer perceptron, relevance determination, wavelet decom- position. Manuscript received August 1, 2000; revised February 5, 2001. This work was supported by the Australian Research Council and Crux Financial Engineering Pty. Ltd. B.-L. Zhang and R. Coggins are with the Computer Engineering Laboratory (CEL), School of Electrical and Information Engineering, University of Sydney, NSW 2006, Australia. M. A. Jabri is with the Computer Engineering Laboratory (CEL), School of Electrical and Information Engineering, University of Sydney, NSW 2006, Australia and also with the Electrical and Computer Engineering Department, Oregon Graduate Institute, Beaverton, OR 97006 USA. D. Dersch and B. Flower are with the Research and Development, Crux Fi- nancial Engineering, NSW 1220, Australia. Publisher Item Identifier S 1045-9227(01)05016-0. I. INTRODUCTION D URING the last two decades, various approaches have been developed for time series prediction. Among them linear regression methods such as autoregressive (AR) and au- toregressive moving average (ARMA) models have been the most used methods in practice [18]. The theory of linear models is well known, and many algorithms for model building are available. Linear models are usually inadequate for financial time se- ries as in practice almost all economic processes are nonlinear to some extent. Nonlinear methods are widely applicable nowa- days with the growth of computer processing speed and data storage. Of the nonlinear methods, neural networks have be- come very popular. Many different types of neural networks such as MLP and RBF have been proven to be universal func- tion approximators, which make neural networks attractive for time series modeling, and for financial time-series forecasting in particular. An important prerequisite for the successful application of some modern advanced modeling techniques such as neural net- works, however, is a certain uniformity of the data [14]. In most cases, a stationary process is assumed for the temporally ordered data. In financial time series, such an assumption of stationarity has to be discarded. Generally speaking, there may exist dif- ferent kinds of nonstationarities. For example, a process may be a superposition of many sources, where the underlying system drifts or switches between different sources, producing different dynamics. Standard approaches such as AR models or nonlinear AR models using MLPs usually give best results for stationary time series. Such a model can be termed as global as only one model is used to characterize the measured process. When a se- ries is nonstationary, as is the case for most financial time series, identifying a proper global model becomes very difficult, unless the nature of the nonstationarity is known. In recent years, local models have grown in interest for improving the prediction ac- curacy for nonstationary time series [25]. To overcome the problems of monolithic global models, an- other efficient way is to design a hybrid scheme incorporating multiresolution decomposition techniques such as the wavelet transform, which can produce a good local representation of the signal in both the time domain and the frequency domain [13]. In contrast to the Fourier basis, wavelets can be supported on an arbitrarily small closed interval. Thus, the wavelet transform is a very powerful tool for dealing with transient phenomena. There are many possible applications of combining wavelet transformations into financial time-series analysis and fore- casting. Recently some financial forecasting strategies have been discussed that used wavelet transforms to preprocess the 1045–9227/01$10.00 © 2001 IEEE 766 IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 12, NO. 4, JULY 2001 data [1], [2], [19], [27]. The preprocessing methods they used are based on the translation invariant wavelet transform [7] or à trous wavelet transform [4], [23]. In this work, we have developed a neuro-wavelet hybrid system that incorporates multiscale wavelet analysis into a set of neural networks for a multistage time series prediction. Compared to the work in [11], our system exploits a shift invariant wavelet transform called the autocorrelation shell representation (ASR) [4] instead of the multiscale orthogonal wavelet transform as was originally presented in [13]. It is cumbersome to apply the commonly defined DWT for real-time time series applications due to the lack of shift invariance, which plays an important role in time series forecasting. Using a shift invariant wavelet transform, we can easily relate the resolution scales exactly to the original time series and preserve the integrity of some short-lived events [2]. Basically, we suggest the direct application of the à trous wavelet transform based on the ASR to financial time series and the prediction of each scale of the wavelet’s coefficients by a separate feedforward neural network. The separate predictions of each scale are proceeded independently. The prediction re- sults for the wavelet coefficients can be combined directly by the linear additive reconstruction property of ASR, or prefer- ably, as we propose in this paper, by another NN in order to predict the original time series. The aim of this last network is to adaptively choose the weight of each scale in the final pre- diction [11]. For the prediction of different scale wavelet coef- ficients, we apply the Bayesian method of automatic relevance determination (ARD) [16] to learn the different significance of a specific length of past window and wavelet scale. ARD is a practical Bayesian method for selecting the best input variables, which enables us to predict each scale of wavelet coefficients by an appropriate neural network, thus simplifying the learning task as the size of each network can be quite small. Comparing the previous work on applying wavelet tech- niques together with connectionist methods to financial time series in [1], [2] our contributions consist of 1) applying some three-stage prediction schemes; 2) a multiresolution prediction which is strictly based on the autocorrelation shell representation; 3) selecting relevant MLP inputs from the overcomplete shell representation using the Bayesian technique ARD; and 4) demonstrating performance using a realistic money management system and trading model. This paper is organized as follows. In the next section, we briefly describe the wavelet transform and the autocorrelation shell representation. The principle of the Bayesian method of ARD is also introduced. Section III presents our hybrid neuro- wavelet scheme for time-series prediction and system details. The simulation results and performance comparison over dif- ferent data sets using a realistic trading simulator are summa- rized in Section IV followed by discussions and conclusions in Section V. II. COMBINING BAYESIAN AND WAVELET BASED PREPROCESSING A. Discrete Wavelet Transform and Autocorrelation Shell Representation Generally speaking, a wavelet decomposition provides a way of analysing a signal both in time and in frequency. If ZHANG et al.: MULTIRESOLUTION FORECASTING FOR FUTURES TRADING 767 Fig. 1. Illustration of the procedure for preparing data in the hybrid neuro-wavelet prediction scheme. Note that each time a segment of the time seriesis transformed, only the last coefficient is retained. Using the filters 768 IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 12, NO. 4, JULY 2001 Fig. 2. Overview of the wavelet/neural net multiresolution forecasting system. w ZHANG et al.: MULTIRESOLUTION FORECASTING FOR FUTURES TRADING 769 transform as described above provides a simple method. Here we set up an à trous wavelet transform based on the autocor- relation shell representation. That is, (5) and (6) are applied to successive values of 770 IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 12, NO. 4, JULY 2001 As pointed out in [3], target selection is an important issue in applying neural networks to financial series forecasting. We follow the guideline suggested by Azoff to minimize the number of targets required for a given problem. A neural network whose output neurons are reduced from two to one, will have half the number of network weights required, with important con- sequences for the generalization capability of the network. A single output neuron is the ideal, as the network is focused on one task and there is no danger of conflicting outputs causing credit assignment problems in the output layer. Accordingly, we prefer a forecasting strategy which proceeds separately for each horizon in the second stage. IV. SIMULATIONS AND PERFORMANCES Our simulations involved the closing prices of four different futures contracts: The three-year and ten-year Treasury bonds (sfe3yb, sfe10yb) traded on the Sydney Futures Exchange, the Australian US dollar contract (cmedolaus) and the Swiss Franc US dollar contract (cmesfus) traded on the Chicago Mercantile Exchange. In order to derive a continuous time series from a set of individual futures contracts, special care must be taken at the expiry of a contract. The price change from one contract to the next cannot be directly exploited in a trading system. Instead a contract must be rolled from the expiry month to a forward month. We found that the four securities we are considering are characterized by a price gap at roll over in the range of the close to close price variation. The concatenation of spot month contracts is therefore a reasonable approximation. In Fig. 4, we show the sfe10yb closing price over a ten-year period. We study the approach of forecasting each wavelet derived coefficient series individually and then recombining the mar- ginal forecasts. Our objective is to perform seven days ahead forecasting of the closing price. As a byproduct, the corre- sponding price changes are simultaneously derived. To compare with other similar work in the literature, we also construct five days ahead forecastes of the relative price change, i.e., the relative difference percent (RDP) between today’s closing price and the closing price five days ahead, denoted ZHANG et al.: MULTIRESOLUTION FORECASTING FOR FUTURES TRADING 771 TABLE I HYPER-PARAMETERS \u000b FOR THE MLP NETWORK INPUTS ON DIFFERENT LEVELS FOR THE sfe10yb DATA SET.THE ORDER OF THE PARAMETERS ARE FROM PAST TO FUTURE TABLE II STRUCTURE OF MLPS ON DIFFERENT LEVELS Fig. 5. From top to bottom: one step ahead predictions for the four wavelet coefficient series w 772 IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 12, NO. 4, JULY 2001 Fig. 6. Demonstration of one day ahead forecasting for the closing price of sfe10yb on a testing data set over a 100 days period (from Nov. 15, 1993 to April 13, 1994), using the prediction methods (I, II, and IV). In each figure, the solid line is the target price and the dashed line is the prediction. strategy by accurately modeling the market dynamics. As an input REMM requires the time and price information and a sequence of trade entry signals. The latter is obtained from the forecaste output of the various prediction systems. Accurate and realistic risk and trade management strategies can be selected to test the quality of the prediction system. This includes the consideration of transaction costs. They are incurred each time a futures contract is purchased or sold. Slippage is a common phenomenon in trading futures. It is the discrepancy between the theoretical entry or exit price and the actual price. In REMM slippage is modeled using a volatility based approach. REMM allows the selection of a number of realistic trade exit strategies like profit take and partial profit take at various target levels, trade expiry and stop loss levels. The exit conditions, e.g., target and stop loss levels, are dynamically adjusted due to changing market conditions. Risk management strategies are implemented by providing trading capital of $1 million and applying risk limits of $10 000 for each trade. For a given sequence of trade entry signals and a set of risk and trade management parameters the trading system is simu- lated using a forward stepping approach. At each time step the system is updated by checking for new trade entries and ad- justing the exit conditions for open positions caused by the new market price. When an exit condition is satisfied, e.g., due to a target being reached or a stop loss level hit, etc. the open po- sition is novated and the overall portfolio position is updated. More than 50 different performance measures are derived that Fig. 7. One step ahead price changes (RDP) forecasts (dashed lines) vs the true RDP series (solid line) for a segment of 100 days in the testing set (from Nov. 15, 1993 to April 13, 1994). See text for explanation for the prediction methods I, II and IV. TABLE III FOR sfe10yb DATA,PREDICTION PERFORMANCES FROM THE FOUR DIFFERENT PREDICTION METHODS allow assessment of the quality of the trading system over the given training period. The most relevant measures are listed in the following. The profit per trade is the average profit per trade over the trading period. The win/loss ratio is the ratio of winning trades to loosing trades over the trading period. The Sharpe ratio is the ratio of the annualised monthly return. The worst monthly loss is the total of losses from trades in the worst calendar month. An optimal trading strategy is derived from the training set and applied to the test set. Using the REMM simulator, we further compared the prof- itability related performances of the four forecasting methods, namely, directly summing up the wavelet coefficients predic- tions from the linear reconstruction property (6) (method I), using a perceptron (method II) or an MLP (method III) to com- bine the wavelet coefficients prediction and simply applying an MLP without wavelet features involved (method IV). For the ten-year bond contract on the test set (consisting of 1000 days of ZHANG et al.: MULTIRESOLUTION FORECASTING FOR FUTURES TRADING 773 TABLE IV FOR sfe10yb DATA,COMPARISON OF THE PROFITABILITY RELATED PERFORMANCES FROM THE FOUR DIFFERENT FORECASTING METHODS TABLE V PERFORMANCE COMPARISON FOR DIFFERENT DATA SETS data), the measures shown in Table IV were calculated to eval- uate the performance of the system under realistic trading con- ditions. Table IV summarizes the profit per trade, the win/loss ratio, the Sharpe ratio and the worst monthly loss. Each trade is based on a number of contracts determined by the risk per trade. From Table IV, it is obvious that method II has the highest values of both Sharpe ratio (0.7321) and profit/loss ratio (1.6307), together with a satisfactory trading number and profit per trade. Though a plain MLP (method IV) generates the most trades, it yields the worst performance with regard to the profit per trade, profit-loss ratio and Sharpe ratio. Simply combining wavelet coefficients using (6) (method I) offers reasonable results of profit per trade and profit-loss ratio, but leads to the most conservative trading activity (only 71 trades in more than three years!). Overall, we can recommend method II as a practical forecasting strategy for a trading system. We have also tested the neuro-wavelet prediction method on the closing prices of other futures contracts: sfe3yb, cmedolaus and cmesfus. In Table V, we show MSE for price prediction, NMSE and DS for RDP series prediction, all for testing data sets. Profit/loss results are given in Figs. 8 and 9 for the sef3yb data and sef10yb, respectively. Prediction method I was compared with method IV in Fig. 8 while method II was compared with method I in Fig. 9. From these evaluations, we can conclude that multiscale neural-network architectures generally show better profitability than applying an MLP alone and the hybrid scheme exploiting a second-stage perceptron has best performance. V. DISCUSSION AND CONCLUSION Forecasting of financial time series is often difficult and complex due to the interaction of the many variables involved. In this paper, we introduced the combination of shift invariant wavelet transform preprocessing and neural-network prediction models trained using Bayesian techniques at the different levels of wavelet scale. We compared this with a conventional MLP by simulation on four sets of futures contract data and determined both forecasting performance and profitability measures based Fig. 8. Comparison of profit/loss results from applying the neuro-wavelet forecasting scheme method I and the MLP alone (method IV), using the three-year Treasury bonds data sfe3yb. The solid line results from method I by applying the linear reconstruction property (6) while the dashed line corresponds to the plain MLP. (a) profit and loss on the training set in \\$AUD against trading days. (b) profit and loss for the testing set. on an accurate trading system model. Our results show signif- icant advantages for the neuro-wavelet technique. Typically, a doubling in profit per trade, Sharpe ratio improvement, as well as significant improvements in the ratio of winning to loosing trades were achieved compared to the MLP prediction. Although our results appear promising, additional research is necessary to further explore the combination of wavelet tech- niques and neural networks, particularly over different market conditions. Financial time series, as we have noted, often show considerable abrupt price changes; the extent of outliers often decides the success or otherwise for a given model. While the 774 IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 12, NO. 4, JULY 2001 (a) (b) Fig. 9. Comparison of profit/loss results from applying neuro-wavelet forecasting scheme method I and method II, using the ten-year bond (sfe10yb) data. The solid line results from the hybrid architecture using a perceptron for combining the wavelet coefficients (method II) while the dashed line is the simpler architecture (method I), in which the wavelet coefficients are directly summed up. (a) profit and loss on training set in AUD against trading days. (b) profit and loss for the testing set. prediction performance is improved, the neuro-wavelet hybrid scheme is still a global model, which is susceptible to outliers. Ongoing work includes 1) the integration of the time-based à trous filters studied here and mixture of local expert model, which may explicitly account for outliers by special expert net- works and 2) direct volatility forecasting by a similar hybrid architecture. Other research areas include the online adaptation of the network models including ARD hyper-parameters, the in- vestigation of wavelet based denoising techniques and solutions to the associated boundary condition problems for the online learning case in order to further improve generalization perfor- mance and the investigation of the joint optimization of fore- casting and money management systems. REFERENCES [1] A. Aussem and F. Murtagh, “Combining neural networks forecasts on wavelet-transformed time series,” Connection Sci., vol. 9, pp. 113–121, 1997. [2] A. Aussem, J. Campbell, and F. Murtagh, “Wavelet-based feature extrac- tion and decomposition strategies for financial forecasting,” J. Comput. Intell. Finance, pp. 5–12, Mar. 1998. [3] A. M. Azoff, Neural Network Time Series Forecasting of Financial Mar- kets. New York: Wiley, 1994. [4] G. Beylkin and N. Satio, “Wavelets, their autocorrelation functions and multiresolution representation of signals,” IEEE Trans. Signal Processing, vol. 7, pp. 147–164, 1997. [5] C. M. Bishop, Neural Networks for Pattern Recognition. Oxford, U.K.: Oxford Univ. Press, 1995. [6] , “Bayesian methods for neural networks,”, Tech. Rep. NCRG/95/009, 1995. [7] R. R. Coifman and D. L. Donoho, “Translation-invariant de-noising,” in Wavelets and Statistics, Springer Lecture Notes, A. Antoniades, Ed. New York: Springer-Verlag, 1995. [8] D. R. Dersch, B. G. Flower, and S. J. Pickard, “Exchange rate trading using a fast retraining procedure for generalized radial basis function networks,” in Proc. Neural Networks Capital Markets, 1997. [9] R. J. Van Eyden, The Application of Neural Networks in the Forecasting of Share Prices. Haymarket, VA: Finance & Technology Publishing, 1995. [10] B. G. Flower, T. Cripps, M. Jabri, and A. White, “An artificial neural network based trade forecasting system for capital markets,” in Proce. Neural Networks Capital Markets, 1995. [11] A. B. Geva, “ScaleNet—Multiscale neural-network architecture for time series prediction,” IEEE Trans. Neural Networks, vol. 9, pp. 1471–1482, 1998. [12] A. Kehagias and V. Petridis, “Predictive modular neural networks for time series classification,” Neural Networks, vol. 10, pp. 31–49, 1997. [13] S. G. Mallat, “A theory for multiresolution signal decomposition: The wavelet representation,” IEEE Trans. Pattern Anal. Machine Intell., vol. 11, pp. 674–693, 1989. [14] K. R. Müller, J. Kohlmorgen, and K. Plawelzik, “Analysis of switching dynamics with computing neural networks,” Univ. Tokyo, Tech. Rep., 1997. [15] D. J. C. MacKay, “A practical Bayesian framework for backpropagation networks,” Neural Comput., vol. 4, pp. 448–472, 1992. [16] , “Bayesian nonlinear modeling for the 1993 energy prediction competition,” in Maximum Entropy and Bayesian Methods, Santa Barbara 1993, G. Heidbreder, Ed. Dordrecht, The Netherlands: Kluwer, 1995. [17] T. Masters, Neural, Novel & Hybrid Algorithms for Time Series Predic- tion. New York: Wiley, 1995. [18] S. Makridakis, S. C. Wheelwright, and R. J. Hyndman, Forecasting, Methods and Applications, 3rd ed. New York: Wiley, 1998. [19] F. F. Murtagh, “Wedding the wavelet transform and multivariate data analysis,” J. Classification, vol. 15, pp. 161–183, 1998. [20] V. Petridis and A. Kehagias, “Modular neural networks for MAP classi- fication of time series and the partition algorithm,” IEEE Trans. Neural Networks, vol. 17, pp. 73–86, 1996. [21] N. Saito and G. Beylkin, “Multiresolution representations using the auto-correlation functions of compactly supported wavelets,” IEEE Trans. Signal Processing, 1992. [22] W. F. Sharpe, “The Sharpe ratio,” J. Portfolio Management, pp. 49–58, Fall 1994. [23] M. J. Shensa, “The discrete wavelet transform: Wedding the á trous and Mallat algorithms,” IEEE Trans. Signal Processing, vol. 10, pp. 2463–2482, 1992. [24] M. R. Thomason, “Financial forecasting with wavelet filters and neural networks,” J. Comput. Intell. Finance, pp. 27–32, Mar. 1997. [25] A. S. Weigend and M. Mangeas, “Nonlinear gated experts for time se- ries: Discovering regimes and avoiding overfitting,” Int. J. Neural Syst., vol. 6, pp. 373–399, 1995. [26] P. Zuohong and W. Xiaodi, “Wavelet-based density estimator model for forecasting,” J. Comput. Intell. Finance, pp. 6–13, Jan. 1998. [27] Z. Gonghui, J.-L. Starck, J. Campbell, and F. Murtagh, “The wavelet transform for filtering financial data streams,” J. Comput. Intell. Fi- nance, pp. 18–35, June 1999. [28] J. S. Zirilli, Financial Prediction Using Neural Networks: International Thomson Computer Press, 1997. ZHANG et al.: MULTIRESOLUTION FORECASTING FOR FUTURES TRADING 775 Bai-Ling Zhang was born in China. He received the Bachelor of Engineering degree in electrical engineering from Wuhan Institute of Geodesy, Photogrammetry, and Chartography in 1983, the Master of Engineering degree in electronic system from the South China University of Technology in 1987, and the Ph.D. degree in electrical and com- puter engineering from the University of Newcastle, Australia in 1999. From 1998 to 1999, he was a Research Assistant with School of Computer Science and Engineering, University of New South Wales, Australia. From 1999 to 2000, he worked as a Postdoctoral Fellow with the Computer Engineering Laboratory (CEL), School of Electrical and Information Engineering, University of Sydney. Currently, he is a member of the research staff in the Kent Ridge Digital Labs (KRDL), Singa- pore. His research interests include artificial neural networks, image processing and computer vision, pattern recognition, and time-series analysis and predic- tion. Richard Coggins (M’95) received the B.Sc. degree in physics and pure mathematics in 1985 and the B.E. Hons. degree in electrical engineering in 1987 from the University of Sydney, Australia. He received the Ph.D. degree in electrical engineering from the Uni- versity of Sydney in 1997. From 1988 to 1990, he worked at Ausonics Pty. Ltd. in the diagnostic ultrasound products group. In 1990, he received the Graduate Management qualifi- cation from the Australian Graduate School of Man- agement. He joined the University of Sydney as a Re- search Engineer in 1990. He is currently a Senior Lecturer at the School of Electrical and Information Engineering at the University of Sydney. He was ap- pointed as a Girling Watson Research Fellow in the Computer Engineering Lab- oratory in 1997. He was appointed as a Senior Lecturer in 2000. His research interests include machine learning, time series prediction, low-power microelec- tronics, and biomedical signal processing. Marwan Anwar Jabri (S’84–M’85–SM’94) was born in Beirut, Lebanon, in 1958. He received the License de Physique and Maitrise de Physique degrees from the Université de Paris VII, France, in 1981 and 1983, respectively. He received the Ph.D. degree in electrical engineering at the University of Sydney in 1988. He was a Research Assistant during 1984 as part of the Sydney University Fleurs Radiotelescope re- search team. He was appointed as Lecturer at the Uni- versity of Sydney in 1988, Senior Lecturer in 1992, Reader in 1994, and Professor in 1996. Since January 2000, he has been the Gordon and Betty Moore endowed Chair Professor at the Electrical and Com- puter Engineering Department, Oregon Graduate Institute (OGI), Beaverton, and Professor in Adaptive Systems at the University of Sydney, School of Elec- trical and Information Engineering. He was a Visiting Scientist at AT&T Bell Laboratories in 1993 and the Salk Institute for Biological Studies in 1997. He is author, coauthor, and editor of three books and more than 150 technical papers and is an invited speaker at many conferences and forums. His research interests include digital and analog integrated circuits, biomedical and neuromorphic en- gineering, and multimedia communication systems. Dr. Jabri is a recipient of the 1992 Australian Telecommunications and Elec- tronics Research Board Outstanding (ATERB) Young Investigator Medal. He is on the editorial board of several journals. He is member of INNS and a Fellow of the Institute of Engineering Australia. Dominik Dersch received the masters degree in physics from the Technical University of Munich, Munich, Germany, in 1991 and the Doctorate degree in Natural Science from the Ludwig Maximilians University, Munich, in 1995. From 1996 to 1997, he was a Research Fellow in the Speech Technology Group at the University of Sydney. From 1997 to 1999, he worked as a Senior Forecasting Analyst in Electricity Trading for Integral Energy Australia. From 1999 to 2000, he was Head of Research and Development of Crux Cybernetics and then of Crux Financial Engineering. He is currently a Senior Quantitative Analyst at HypoVereinsbank in Munich. His research interests include statistical physics, statistics, pattern recognition, classification, and time series analysis. He has worked and published in areas including speech recognition and speech analysis, remote sensing data analysis, medical image processing and classifi- cation, and financial time series analysis and prediction. He holds a license as financial advisor with the Sydney Futures Exchange. Barry Flower (M’96) received the Bachelor of Engineering and Bachelor of Computing Science degrees from the University of New South Wales, Australia, in 1987 and the Ph.D. degree in electronic and computer engineering from the University of Sydney, Australia, in 1995. From 1990 to 1995, he was a Research Associate and then Girling Watson Research Fellow in the System Engineering and Design Automation Lab- oratory at the University of Sydney. From 1995 to 2000, he was a Founder and Joint Managing Director of Crux Cybernetics and then Crux Financial Engineering. He is currently Manager of E-Commerce, Strategic Development at Hong Kong and Shanghai Banking Corporation. His research interests include connectionists techniques applied to time series analysis, financial markets, speech recognition, and autonomous robotic systems.","libVersion":"0.3.1","langs":""}