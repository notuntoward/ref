{"path":"lit/sources/papers_added/papers/Ornstein20GaussProceDiscontin.pdf","text":"Gaussian Process Regression Discontinuity Joseph T. Ornstein ∗ JBrandon Duck-Mayr † February 20, 2020 Abstract In applied settings, regression discontinuity (RD) designs often suﬀer from noisy data and low power. This tends to produce exaggerated causal eﬀect estimates, typiﬁed by implausibly large slope and/or concavity parameters. We propose a new method for estimating causal eﬀects in RD designs called Gaussian Process Regression Discontinu- ity (GPRD). This approach overcomes the major disadvantages of global polynomial estimators and does so with lower variance than local linear estimators. When applied to several recent empirical examples from the published literature, GPRD yields more modest and plausible treatment eﬀect estimates. We make this new method available through the R package gprd. ∗Postdoctoral Research Associate, Washington University in St. Louis †PhD Candidate, Washington University in St. Louis 1 1 Introduction Regression discontinuity (RD) is an approach to causal inference that leverages a discontin- uous change in treatment at a cutoﬀ. The key identiﬁcation assumption of the RD design is the continuity of other pre-treatment covariates; so long as treatment status is the only vari- able that changes discontinuously at the cutoﬀ, the causal eﬀect of treatment is identiﬁable at that point (Hahn, Todd and Van Der Klaauw, 2001). Because such thresholds, cutoﬀs, and boundaries are a common feature of political institutions, RD has proven a popular research design in political science over the past two decades (de la Cuesta and Imai, 2016). Estimating the average treatment eﬀect at the cutoﬀ requires ﬁnding the limits of the outcome variable as it approaches from the left and right. Traditionally, researchers have estimated these limits in one of two ways. The ﬁrst approach is to ﬁt a global polynomial regression on either side of the cutoﬀ, then take the diﬀerence between the two regressions’ predictions at the cutoﬀ. This approach suﬀers from a disadvantage common to any paramet- ric estimation strategy: if the true data generating process is not captured by the researcher’s model speciﬁcation, then any causal eﬀect estimate is likely to be biased. Gelman and Im- bens (2017) catalogue three other disadvantages of this approach: global methods tend to overﬁt to observations far away from the cutoﬀ, estimates are sensitive to the researcher’s choice of polynomial degree, and conﬁdence intervals have poor coverage. In response to these problems, researchers have developed a more sophisticated nonpara- metric approach based on local linear regression. An important practical consideration in this literature involves choosing a bandwidth – i.e. how much data to include in the estimation (Imbens and Kalyanaraman, 2012). This choice involves a bias-variance tradeoﬀ: too wide a bandwidth yields biased estimates; too narrow a bandwidth reduces number of observations used to estimate the treatment eﬀect, increasing the variance of the RD estimator. Calonico, Cattaneo and Titiunik (2014), hereafter CCT, propose a nonparametric ap- proach to RD estimation that selects the bandwidth (h) to minimize the mean squared 2 error of the RD estimator. Their approach estimates the limits approaching the cutoﬀ using local linear regression weighted by a triangular kernel and adjusting for a bias-correction term, and the authors derive robust standard errors for inference. Conﬁdence intervals from this method produce the best empirical coverage of any method proposed to date, and its estimates perform well in a wide array of simulations. Because local linear RD estimates focus exclusively on observations near the cutoﬀ, datasets that are sparse or noisy in that neighborhood can yield low-powered hypothesis tests. As the ongoing replication crisis in experimental sciences has demonstrated, such low- powered studies are pernicious when combined with a publication bias towards statistically signiﬁcant results (Button et al., 2013). The estimated treatment eﬀects from publishable low-powered studies tend to signiﬁcantly overestimate the true eﬀect, a distortion that Gel- man and Carlin (2014) refer to as Type M errors. To illustrate this problem in the RD case, consider a simulation in which the variables X and Y are generated as follows: X ∼ U (−1, 1) Yi = 1(Xi ≥ 0)τ + Xiβ + εi ε ∼ N (0, σ2) where 1(·) is the indicator function, β is a slope parameter, and τ is the true causal eﬀect of treatment. When τ and β equal zero, Y is pure Gaussian noise. Figure 1 displays two instances of this simulated data when τ = 0, including local linear and local quadratic RD estimates with CCT optimal bandwidths. When the true eﬀect of treatment equals 0, the CCT 95% conﬁdence intervals reject the null hypothesis (H0 : τ = 0) roughly 7% of the time. Of these rejections, over 90% display a characteristic ‘Zig Zag’ pattern illustrated in the ﬁgure – steep-sloped regression functions on either side of the 3 Figure 1: False positive estimates from the Monte Carlo simulation. Dashed vertical lines are the CCT MSE-optimal bandwidth. Solid vertical line is the cutoﬀ. Gray points are the raw data, and black lines are the local low-order polynomial ﬁts. Left two ﬁgures generated with parameters τ = 0, β = 0, σ = 1 2, n = 500. Right two ﬁgures generated with parameters τ = 0, β = 0, σ = 1, n = 1000. cutoﬀ and a treatment eﬀect of the opposite sign.1 This pattern is emblematic of false positive or exaggerated claims from noisy RD data, and will be present in the empirical applications below. In some cases, there may be a good theoretical reason to believe that the treatment eﬀect will move in the opposite direction of the slope of the regression function. For examples, see RD studies on the incumbency disadvantage in Latin America (Klaˇsnja and Titiunik, 2017) or the eﬀect of property tax incentives on homeowners’ mobility rates (Ferreira, 2010). But one would rarely expect the slope of the conditional expectation function to diverge sharply 1Or, when estimated using a local quadratic regression, a concave regression function on one side of the cutoﬀ, and a convex function on the other side. 4 only in the neighborhood of the cutoﬀ. Absent such a theoretical motivation, large slope or concavity estimates near the cutoﬀ are indicative of overﬁtting to noisy data. Figure 2 plots the estimated RD treatment eﬀect on the y-axis against the sum of the estimated slopes on the x-axis, but only for simulations where the CCT 95% conﬁdence intervals reject the null hypothesis. In the top two panels of Figure 2, the value of τ is small relative to noise (σ). As a result, the test is low-powered, only rejecting the null hypothesis in 9% and 17% of iterations. When an estimate passes the statistical signiﬁcance threshold, it tends to be many multiples of the true value (Type M error) or have the wrong sign (Type S error). The largest distortions are associated with large estimated slopes on each side of the cutoﬀ. Only when power is high (bottom two panels) are statistically signiﬁcant estimates roughly centered around the true value of τ . In the following section, we introduce a Bayesian method for estimating RD treatment eﬀects based on Gaussian Process regression. Because it imposes a prior on the smooth- ness of the conditional expectation functions, it is a particularly useful method to moderate the exaggerated claims from low-powered RD studies. Gaussian Process Regression Discon- tinuity (GPRD) performs well in simulations, overcoming the disadvantages of traditional global polynomial approaches while producing lower variance estimates than local linear ap- proaches. In section 3 we apply GPRD to several empirical examples from the published literature where low power has yielded exaggerated treatment eﬀects. 2 Gaussian Process Regression for RD Designs In regression discontinuity (RD) designs, we attempt to estimate the causal eﬀect of a treat- ment that is assigned at a speciﬁc value of some forcing variable, x. We assume the outcomes y are a noisy function of the forcing variable x, and we are interested in the discontinuity in f (x) induced by the treatment. We propose using Gaussian process regression to approxi- mate this conditional expectation function f (x) and estimate causal eﬀects in RD designs. 5 Figure 2: Observed treatment eﬀect and slope estimates from Monte Carlo after applying statistical signiﬁcance ﬁlter α = 0.05, for varying values of τ . More extreme slope estimates yield more distorted treatment eﬀect estimates. When the true value of τ is low, the esti- mated treatment eﬀects from cases that pass statistical signiﬁcance are greatly exaggerated (Type M error) and many have the wrong sign (Type S error). This approach was ﬁrst proposed in Branson et al. (2019); we extend the method to relax some restrictive assumptions (the “same covariance” assumption from that paper) and per- mit more powerful assumptions (adding a “same mean function” assumption) as beﬁts the researcher, and provide open source software for estimation (an R package, gprd). To formalize the RD problem we start by assuming the outcomes are normally distributed, y ∼ N ( f (x) , σ2 yI) , (1) where f (x) is an unknown function of the forcing variable x. A treatment occurs at a 6 cutoﬀ value c of x; that is, all outcomes where x ≥ c receive the treatment. For simplicity here we will assume c = 0. Alternatively, we might assume that the outcomes are normally distributed but with diﬀerent mappings between input and output on either side of the cutoﬀ; y+ ∼ N ( f+ (x+) , σ2 yI) , (2) y− ∼ N ( f− (x−) , σ2 yI) , (3) We will propose two diﬀerent methods to estimate the treatment eﬀect τ of the inter- vention using Gaussian process (GP) regression. The ﬁrst, which we call the global GPRD estimator, ﬁts a single GP model for all observations, with a dummy variable to indicate treatment, and estimates the treatment eﬀect using the diﬀerence in prediction when x = c and D = 1 and D = 0. The second, which we call the piecewise GPRD estimator, models the data separately on either side of the cutoﬀ and estimates the treatment eﬀect using the diﬀerence between predictions at the cutoﬀ from the “right equation” and “left equation.” 2.1 Gaussian Process Regression GP regression is a method used to learn the mapping from x to y when its functional form is not known, accomplished by placing a GP prior over the function space. As this methodology is uncommon in the political science literature, we provide a brief overview here. A Gaussian process (GP) is an inﬁnite dimensional generalization of the normal distri- bution. More speciﬁcally, it is “collection of random variables, any ﬁnite number of which have a joint Gaussian distribution” (Rasmussen and Williams, 2006, 13). The mean and covariance of this normal distribution is given as functions of the inputs, so that we say f (x) ∼ GP(m(x), K(x)). (4) 7 Common examples for the mean function are the “mean zero” function m(x) = 0 and the “linear mean” function m(x) = xβ. A common example of a covariance function (also called a kernel) is the isometric squared exponential covariance function, also called simply the squared exponential covariance function or the radial basis function, K (x, x ′) = σ2 f exp ( −0.5(x − x′)2 ℓ2 ) , (5) where σf is a hyperparameter called the scale factor, which scales the entire covariance matrix, and ℓ is a hyperparameter called the length scale, which inﬂuences how quickly f varies in x. Then the i, j element of the covariance matrix is given by K(xi, xj). This setup allows us to model distributions over functions rather than simply distribu- tions over variables. Then, rather than assume we know the form of the mapping between the input variables X and outcomes y—such as a polynomial of a particular order—we can instead use a GP to place a probability distribution over all possible mappings from X to y. With a Gaussian likelihood for the data given X and f (x), a posterior distribution over f (x) is then given by application of Bayes’ rule utilizing Gaussian identities. 2 Crucially for our purposes, well known results provide the posterior predictive distribution for a test observation x∗ as f (x∗) ∼ N (m∗, C ∗) (6) m ∗ = m(x∗) + K(x∗, x)[K(x) + σ2 yI]−1(y − m(x)) (7) C ∗ = K(x∗) − K(x∗, x)[K(x) + σ2 yI]−1K(x, x ∗). (8) Note that Bayesian linear regression is a special case of Gaussian process regression, using the linear covariance function K(x, x ′) = x · x′.3 When using other kernels, we simply allow 2For a more detailed derivation of this posterior distribution, see Rasmussen and Williams (2006), Chapter 2. 3A constant hyperparameter is added to K if an intercept is desired. 8 non-linearity in the mapping from input to response. In other words, GP regression is a ﬂexible extension to Bayesian linear regression to account for uncertainty in the functional form mapping predictors to response by assuming the covariance between outcomes is a function of the predictor variables. In the case of the common squared exponential covariance function (and its extension discussed in Section 2.2, the automatic relevance determination kernel), we assume that covariance between outcomes is simply a function of distance in the covariate space. 2.2 The Global GPRD Estimator For the global GPRD estimator, we place a Gaussian process (GP) prior on f (x), p(f ) = GP(Xβ, K(X)), (9) where K is the squared exponential automatic relevance determination covariance func- tion K (X, X ′) = σ2 f exp ( −0.5 ∑ j (X·,j − X ′ ·,j)2 ℓ 2 j ) (10) with hyperparameters σf , the scale factor as in the squared exponential covariance func- tion from Equation 5, and ℓ is a length scale vector with a separate length scale for each predictor variable, and where X = [ 1|x|D ] , with D =  || || 1 if x ≥ c, 0 otherwise. (11) Note that there is never a diﬀerence between observations on the value of the intercept column, so the X that goes into the mean function Xβ will include that column, but the X going into the covariance function does not (and accordingly ℓ is of length two, not three); 9 we suppress this diﬀerence in the notation for simplicity. We use a Gaussian prior for β, with mean b and covariance B. Then the posterior over β is given by β | y, X ∼ N ( ¯β, Σβ) , (12) ¯β = Σβ ( X T K −1 y y + B−1b) , (13) Σβ = (B−1 + X T K −1 y X)−1 , (14) Ky = K(X) + σ2 yI (15) (see Rasmussen and Williams (2006), section 2.7). Note that for the common case where b = 0, ¯β simpliﬁes to Σβ(X T K −1 y y). Then the mean and variance of f at a test point X∗ is ¯f (X∗) = X∗ ¯β + K∗K −1 y (y − X ¯β), (16) cov(f∗) = K∗∗ − K∗K −1 y K T ∗ + RT (X T K −1 y X) −1R, (17) K∗ = K(X∗, X), (18) K∗∗ = K(X∗), (19) R = X T ∗ − X T K −1 y K T ∗ (20) (See Equations 2.24, 2.38, and 2.41 in Rasmussen and Williams 2006). These diﬀer from Equations 7 and 8 because we have incorporated uncertainty in the mean function parameters. 4 4One could instead select mean function coeﬃcients by maximizing the marginal log likelihood as we discuss for the covariance function hyperparameters in Section 2.4, in which case ¯f (X∗) and cov(f∗) would again be given by Equations 7 and 8. 10 So we are interested in the treatment eﬀect τGP RD−G def = f ([ 0 1 ]) − f ([ 0 0 ]) , (21) or the diﬀerence between f (x = 0, D = 1) and f (x = 0, D = 0), which is distributed τGP RD−G ∼ N (µ∗, Σ∗) , (22) µ∗ = ¯f ([ 0 1 ]) − ¯f ([ 0 0 ]) , (23) Σ∗ = cov ( f ([ 0 1 ])) + cov ( f ([ 0 0 ])) . (24) Note the key diﬀerences between the global GPRD estimator and the global polynomial RD estimator. In the global polynomial model, the treatment eﬀect is taken to be the coef- ﬁcient on D, which gives the diﬀerence in expected outcomes for the treated and untreated observations at any point x. In the GP model, this is not true; the coeﬃcient on D impacts the expected outcome, but the eﬀect of the treatment also runs through the kernel (see Equation 16). Also note the diﬀerences between the global GPRD estimator we introduce and the approach taken in Branson et al. (2019). Branson et al. assume shared covariance function parameters while ﬁtting separate GP regressions to observations to the left and right of the treatment cutoﬀ.5 The global GPRD estimator makes stronger assumptions about the relationship between outputs in the treatment and control in assuming that not only are the covariance function parameters shared, but by ﬁtting only one GP regression to all the data. Then the diﬀerence in function values is given only by allowing a mean intercept shift for the treated group and added unit covariate space distance in the kernel, rather than ﬁtting entirely separate functions for the treated and control groups. With appropriate selection of 5While they state the shared covariance assumption as one that can be used or not, they rely on the assumption in all applications and in most proofs. 11 the treatment dummy length scale, this modeling choice may be able to improve precision by leveraging more data while allowing enough change in function outputs between treatment and control groups to appropriately model the data. 2.3 The Piecewise GPRD Estimator Non-parametric regression discontinuity designs ﬁt polynomials on either side of the discon- tinuity, and estimate the treatment eﬀect as the diﬀerence of the limit of the polynomials at the cutoﬀ. The piecewise GP estimation strategy is to simply place Gaussian process (GP) priors over the functions on either side of the cutoﬀ, which will be much more ﬂexible than the polynomial regression approach and less sensitive to overﬁtting predictions close to the cutoﬀ to observations far away from the cutoﬀ. By design, the ﬁt near the cutoﬀ will rely more on inputs close to the cutoﬀ than those far away. To formalize, x+ will be the inputs to the right of the cutoﬀ and y+ the corresponding outcomes, and analogously for x− and y−. Then we will learn two functions, f+ : x+ → y+ and f− : x− → y−. To do so, we place GP priors over the functions, f+ ∼ GP(X+β+, K(x+)), (25) f− ∼ GP(X−β−, K(x−)), (26) where X· prepends the column vector 1 to x·, β· is a vector giving the intercept and slope of the linear mean function, and K(·) is the isometric squared exponential covariance function from Equation 5. We again use a Gaussian prior for β, with mean b and covariance B, and the mean and variance of f· at a test point x∗ is as given in Equations 16 and 17. Then we are interested in the treatment eﬀect τGP RD−L def = f+(0) − f−(0), (27) 12 which is distributed τGP RD−L ∼ N ( ¯f+(0) − ¯f−(0), cov(f+(0)) + cov(f−(0))). (28) Note the key diﬀerences between the piecewise GPRD estimator and local linear or poly- nomial RD estimators. The local polynomial estimators use only a portion of the data to either side of the cutoﬀ to avoid undue inﬂuence of observations far from the cutoﬀ. In contrast, the GP model is able to use all of the available data because the covariance be- tween outputs decreases with distance in the covariate space, a natural and smooth way to decrease undue inﬂuence of observations far from the cutoﬀ while still borrowing some information from them. Additionally, the local methods require speciﬁcation of the degree of the local polynomials, and this researcher-imposed model restriction can signiﬁcantly impact inference. By contrast, in the GP model, we place a prior over the possible mappings from x to y and learn f (x) from the data. The combination of these diﬀerences largely appeases the criticisms of global polynomial RD estimation in (Gelman and Imbens, 2017). Also note the diﬀerences between the piecewise GPRD estimator we introduce and the approach taken in Branson et al. (2019). While Branson et al. largely rely on a shared covariance assumption, the piecewise GPRD estimator is the result of abandoning that as- sumption and selecting diﬀerent covariance function hyperparameters for the treatment and control groups. When the covariance function hyperparameters in fact should be shared, parameter selection or sampling routines should be able to recover that. When they are not, and the mapping from forcing variable to outcomes is truly best viewed as potentially wholly diﬀerent between the treatment and control groups, the piecewise GPRD estimator we intro- duce may be most appropriate. Taken together, our global and piecewise GPRD estimators can be seen as capturing a fairly wide range of restrictiveness of prior assumptions in GP regression estimation of treatment eﬀects in RD designs. It is also useful to acknowledge one important assumption shared by our approaches, that of stationarity, or that covariance 13 hyperparameters do not themselves also vary as a function of the forcing variable. We leave the relaxation of that assumption to future work. 2.4 Choosing Hyperparameters Because our inferences are strongly aﬀected by the choice of hyperparameters σy, σf , and ℓ, we need a theoretically-grounded, automatic procedure for selecting their values. The common practice in GP regression is to use the hyperparameters that maximize the log marginal likelihood. In the case of a linear mean, the log marginal likelihood is log p(y | X, b, B) = −1 2M T Q−1M − 1 2 log |Q| − n 2 log 2π, (29) M = Xb − y, (30) Q = Ky + XBX T , (31) (see Equation 2.43 in Rasmussen and Williams 2006). Again, note that for the common case b = 0, M reduces to −y. Then the gradient of the log marginal likelihood with respect to the hyperparameters θ = (σy, σf , ℓ) in the case of the isometric covariance function is ∂ ∂θi log p(y | X, b, B) = 1 2M Q−1 ∂Q ∂θi Q −1M − 1 2 Tr ( Q −1 ∂Q ∂θi ) , (32) ∂Q ∂θ =       2σyI 2σf exp (−0.5K0) σ2 f exp (−0.5K0) ◦ K0       , (33) where the i, j element of the matrix K0 is given by K0 i,j = (xi − xj) 2 ℓ2 , (34) 14 and we can use (e.g.) the conjugate gradient method to optimize the hyperparameters. The gradient for the automatic relevance determination case is analogous, but just extended with an element for each element of ℓ accordingly. Alternatively, we could simply place a prior over the covariance function hyperparameters to include our uncertainty over them into the posterior distribution of the treatment eﬀect. Note that in this case, however, we can no longer use exact inference but must instead resort to simulating the posterior. Instead, we can use priors with positive support and simulate the posterior with an MCMC sampler. For the remainder of the paper, we use covariance function parameters chosen by maximizing the marginal log likelihood (in particular to save time during the simulations), though an MCMC sampler for a fully Bayesian approach will be available in the gprd package. 2.5 Comparing Models: Simulation Evidence To assess performance of the GPRD estimators compared to existing methods, we engage in two simulation exercises. First, we use a common set of simulations from the RD literature, where the forcing variable x is given by 2z − 1, with z ∼ B(2, 4), and y = fj(x) + ε, with ε ∼ N (0, 0.1295 2). To specify the shape function fj(x), we use the three functions explored in Cattaneo, Frandsen and Titiunik (2014), themselves taken from Lee (2008) and Ludwig and Miller (2007). We additionally use global linear and quadratic functions, f (x) = x + τ I(x > 0) and f (x) = x2 + τ I(x > 0), with τ = 0 and τ = 1, for a total of seven tested data generating processes. For each DGP, we simulate 1,000 datasets of 500 observations. We estimate treatment eﬀects and conﬁdence intervals for global GPRD, piecewise GPRD, local linear, and ﬁfth-degree global polynomial approaches (the Lee and Ludwig and Miller DGPs both use ﬁve-degree polynomials). Figure 3 depicts the root mean squared error, mean absolute error, conﬁdence interval length, and conﬁdence interval coverage averaged 15 by simulation condition. ●● ●● ●● ●● ●● ●● ●● Linear (τ = 0) Linear (τ = 1) Quadratic (τ = 0) Quadratic (τ = 1) Lee (τ = 0.04) Lee Mod. (τ = 0.04) Ludwig (τ = − 3.45)0.00.51.01.5RMSE ● ● Local GPRD Global GPRD Local Linear Local Polynomial Global Linear Global Polynomial (a) Root mean squared error of treatment eﬀect estimates. ●● ●● ●● ●● ●● ●● ●● Linear (τ = 0) Linear (τ = 1) Quadratic (τ = 0) Quadratic (τ = 1) Lee (τ = 0.04) Lee Mod. (τ = 0.04) Ludwig (τ = − 3.45)0.00.51.01.5MAE ● ● Local GPRD Global GPRD Local Linear Local Polynomial Global Linear Global Polynomial (b) Mean absolute error of treatment eﬀect estimates. ● ● ● ● ● ● ● ● ● ● ●● ●● Linear (τ = 0) Linear (τ = 1) Quadratic (τ = 0) Quadratic (τ = 1) Lee (τ = 0.04) Lee Mod. (τ = 0.04) Ludwig (τ = − 3.45)0.00.10.20.30.40.5Mean Interval Length ● ● Local GPRD Global GPRD Local Linear Local Polynomial Global Linear Global Polynomial (c) Mean conﬁdence interval length for treat- ment eﬀect estimates. ● ● ● ● ● ● ●● ● ● ●● ● ● Linear (τ = 0) Linear (τ = 1) Quadratic (τ = 0) Quadratic (τ = 1) Lee (τ = 0.04) Lee Mod. (τ = 0.04) Ludwig (τ = − 3.45)0.00.20.40.60.81.0Mean Coverage ● ● Local GPRD Global GPRD Local Linear Local Polynomial Global Linear Global Polynomial (d) Mean 95% conﬁdence interval coverage of true treatment eﬀects. Figure 3: Fit statistics for treatment eﬀect estimates from the global and piecewise GPRD models (plotted in empty and ﬁlled green circles respectively), local linear and polynomial regression (plotted in ﬁlled and empty blue squares respectively), and global linear and polynomial regression (plotted in ﬁlled and empty yellow triangles). The GPRD methods generally outperform other methods in terms of error and conﬁ- dence interval length; when averaged across conditions, the GPRD methods outperform all other methods on these metrics, and for some DGPs, this diﬀerence is more pronounced. However, for the Lee and Ludwig and Miller datasets, GPRD method coverage suﬀered, though error only grew very slightly; this echoes ﬁndings in Branson et al. (2019), who note that with these DGPs, the functions’ slope increases markedly near the cutoﬀ, violating the stationarity assumption we leverage. This may be cured by using bandwidth cutoﬀs for the GP regressions’ training data, a solution explored in Branson et al. (2019), or by using a non-stationary kernel, an extension we leave for future work. The results averaged across 16 all conditions for all data generating processes, as well as only stationary data generating processes, are given in Table 1. Table 1: Fit statistics averaged across replicates and data generating processes. Estimator MAE RMSE Mean CI Length Mean CI Coverage All DGPs Global GPRD 0.041 0.061 0.138 0.830 Piecewise GPRD 0.047 0.067 0.161 0.851 Local Linear 0.052 0.068 0.259 0.928 Local Polynomial 0.103 0.136 0.511 0.914 Global Linear 0.466 0.735 0.137 0.330 Global Polynomial 0.059 0.075 0.288 0.949 Stationary DGPs Global GPRD 0.028 0.038 0.126 0.928 Piecewise GPRD 0.032 0.043 0.149 0.936 Local Linear 0.047 0.060 0.247 0.932 Local Polynomial 0.102 0.137 0.506 0.916 Global Linear 0.303 0.422 0.129 0.380 Global Polynomial 0.059 0.075 0.288 0.948 In the absence of a violation of the stationarity assumption, the GPRD methods show a substantial improvement in terms of reduced bias and increased precision while retaining coverage. Importantly, note that these simulations, standard in the literature, assume very low observation noise. Returning to the setting discussed earlier in the paper where prior methods can produce exaggerated results, we see an even greater diﬀerence in performance between the methods. We explore the settings where ε ∼ N (0, 0.5 2) and ε ∼ N (0, 1) for f (x) = x + τ I(x > 0) for τ = 0 and τ = 1 to consider the diﬀerence in performance in (perhaps more realistic) noisier environments. We display the RMSE, MAE, interval length, and coverage by condition in Figure 4 and report the pooled results in Table 2. In this setting, the mean absolute error, root mean squared error, and conﬁdence interval length are all more than twice as large for the local linear regression method than the piecewise GPRD method, and the global GPRD method edges out the piecewise GPRD 17 ●● ● ● ● ● ● ● σ 2 = 0.25 (τ = 0) σ2 = 0.25 (τ = 1) σ 2 = 1 (τ = 0) σ 2 = 1 (τ = 1)0.00.20.40.60.81.0RMSE ● ● Local GPRD Global GPRD Local Linear Local Polynomial Global Linear Global Polynomial (a) Root mean squared error of treatment eﬀect estimates. ●● ● ● ● ● ● ● σ 2 = 0.25 (τ = 0) σ2 = 0.25 (τ = 1) σ 2 = 1 (τ = 0) σ 2 = 1 (τ = 1)0.00.20.40.6MAE ● ● Local GPRD Global GPRD Local Linear Local Polynomial Global Linear Global Polynomial (b) Mean absolute error of treatment eﬀect estimates. ● ● ● ● ● ● ● ● σ 2 = 0.25 (τ = 0) σ2 = 0.25 (τ = 1) σ 2 = 1 (τ = 0) σ 2 = 1 (τ = 1)01234Mean Interval Length ● ● Local GPRD Global GPRD Local Linear Local Polynomial Global Linear Global Polynomial (c) Mean conﬁdence interval length for treat- ment eﬀect estimates. ● ● ● ● ● ● ● ● σ 2 = 0.25 (τ = 0) σ2 = 0.25 (τ = 1) σ 2 = 1 (τ = 0) σ 2 = 1 (τ = 1)0.00.20.40.60.81.0Mean Coverage ● ● Local GPRD Global GPRD Local Linear Local Polynomial Global Linear Global Polynomial (d) Mean 95% conﬁdence interval coverage of true treatment eﬀects. Figure 4: Fit statistics for treatment eﬀect estimates from the global and piecewise GPRD models (plotted in empty and ﬁlled green circles respectively), local linear and polynomial regression (plotted in ﬁlled and empty blue squares respectively), and global linear and polynomial regression (plotted in ﬁlled and empty yellow triangles). Table 2: Fit statistics averaged across replicates and noise and eﬀect sizes. Estimator MAE RMSE Mean CI Length Mean CI Coverage Global GPRD 0.111 0.149 0.476 0.913 piecewise GPRD 0.128 0.170 0.627 0.946 Local Linear 0.265 0.360 1.410 0.931 Local Polynomial 0.580 0.796 2.880 0.910 Global Linear 0.102 0.135 0.511 0.951 Global Polynomial 0.345 0.461 1.660 0.949 method further still. OLS, the global linear model, does very well, as may be expected when the simulation’s DGP matches exactly the OLS assumptions. Remarkably, the GPRD methods perform similarly to the model whose assumptions match the DGP. In the common 18 scenario where noise is appreciable, the GPRD methods outperform existing local methods substantially and do no worse than when the researcher can correctly intuit the precise functional form of the mapping from forcing variable to outcomes. 3 Empirical Applications We selected the following empirical applications based on three criteria. First, they are all published in top political science and economics journals over the past ﬁve years. Second, they all adhere to current best practices for RD studies, employing local polynomial es- timators with automated bandwidth selectors and robust standard errors, and conducting extensive falsiﬁcation and robustness tests. Third, the authors provide suﬃcient replication materials to reproduce their work. In short, we select these examples not because they are bad examples of applied RD, but because they are good examples of careful and rigorous empirical work. Nevertheless, each of these examples exhibits low power stemming from small or noisy datasets, suggesting that the treatment eﬀects estimated using local linear approaches are likely to be exaggerated in some way. 3.1 The Radical Right and Party Manifestos Abou-Chadi and Krause (2018) study how the presence of radical right parties inﬂuence the platforms of mainstream parties. Their causal identiﬁcation strategy is based on electoral thresholds in parliamentary systems; typically it is required that a party clear some per- centage of the total vote before gaining representation in parliament, where the particular threshold varies by country. The authors compare elections where radical right parties barely exceeded the threshold (gaining representation) and barely missed the threshold, observing how mainstream political parties respond. The dependent variable is change in a measure of Cultural Protection in the party’s man- 19 ifesto during the following election. These data are compiled by the Comparative Manifestos Project (Volkens, Pola Lehmann, Theres Matthieß, Nicolas Merz and Werner, 2015), and the outcome variable is a function of the diﬀerence between the number of favorable mentions of cultural diversity and encouragement of integration and cultural homogeneity in the party’s platform (Lowe et al., 2011). In their paper, Abou-Chadi and Krause (2018) present esti- mates from a diverse range of speciﬁcations, which range from 3.1 to 4.9. Replicating these results using CCT bias-corrected standard errors and robust conﬁdence intervals yields an estimate of 3.96, with 95% conﬁdence interval [1.7, 6.2]. To get a sense of the relative magnitude of this estimated eﬀect, consider Figure 5. This plots the average value of the Cultural Protection score, by country, for each family of political party since 1980. Although the Cultural Protection score is noisy from election year to election year, averaging across years yields predictable patterns. Right-leaning parties tend to score higher on the measure than left-leaning parties, and Nationalist parties – where they exist – typically score 2 to 3 points higher than the average mainstream party. In this context, an estimated eﬀect size of 3.9 is enormous. If true, it suggests that not only do mainstream parties respond to Radical Right representation by moving their plat- forms to the right, but they do so in such a way that their rhetoric completely closes or even overtakes the average gap between mainstream and rightwing nationalist party positions. We apply our GPRD methodology to this data and ﬁnd the GPRD methods aﬃrm the ﬁnding of a reliable positive eﬀect, but a more plausible eﬀect. Table 3 compares the eﬀect sizes estimated by GPRD, local linear regression, and global polynomial regression. Figure 6 visualizes those estimates. We can see the local linear and global polynomial methods drag down the prediction line just to the left of the cutoﬀ substantially, based on a relatively small number of observations in that area. The GPRD methods do not suﬀer from this weakness and therefore recover a more plausible, but still reliably positive, eﬀect of 1.7 for the piecewise GPRD estimate and 1.9 for the global GPRD estimate. 20 Figure 5: Mean Cultural Protection score by country and party family (all elections post- 1980; Center-Left includes Social Democrats and Liberals, Center-Right includes Christian Democrats and Conservatives). Table 3: Treatment eﬀect comparison between the GPRD methods and local linear and global polynomial regression for the Abou-Chadi and Krause (2018) application. Estimator Treatment eﬀect 95% CI Global GPRD 1.735 [0.804, 3.074] Piecewise GPRD 1.939 [0.603, 2.867] Local Linear 3.972 [1.698, 6.238] Global Polynomial 3.983 [1.707, 6.258] 3.2 Ethnic Diversity and Municipal Public Spending The second empirical illustration comes from Beach and Jones (2017), who study the eﬀect of diverse city council representation on municipal-level public goods spending. There is a large literature on this topic, dating back to Alesina, Baqir and Easterly (1999) and 21 −5 0 5 10−6−4−20246 Radical Right MarginChange in Cultural Protectionism (a) Piecewise GPRD. ● ● ● ● ● ●● ● ● ● ● ● ● ● ●●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ●● ● ● ●● ● ● ● ●●●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●●●●● ● ● ● ● ●●●●●● ● ● ●●●● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ●●●●● ● ● ● ● ● ● ●●●●● ● ● ● ● ● ●●●●● ● ● ● ● ● ●●●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ●● ● ● ● ● ● ● ●● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●● ●● ● ● ● ● ● ● ● ● ●●●● ● ● ● ● ●●●●● ● ● ● ● ● ● ●●●●● ● ● ● ● ● ●●●● ● ● ● ● ● ●●●● ● ● ● ●●●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● −4 0 4 −5 0 5 10 Radical Right MarginChange in Cultural Protectionism (b) Local Linear Regression. −5 0 5 10−6−4−20246 Radical Right MarginChange in Cultural Protectionism (c) Global GPRD. −4 0 4 −5 0 5 10 Radical Right MarginChange in Cultural Protectionism (d) Global Polynomial Regression. Figure 6: Fit comparison between the GPRD methods and local linear and global polynomial regression for the Abou-Chadi and Krause (2018) application. continuing through Hopkins (2011) and Trounstine (2015), ﬁnding that in ethnically diverse and segregated cities, municipal governments devote less spending to public goods than in ethnically homogeneous cities. All of these studies rely on cross-sectional or longitudinal regression analysis of public ﬁnance data, and so lack a credible causal identiﬁcation. Beach and Jones (2017) approach the problem through an RD analysis of city council elections in California. Because narrowly elected city councilors from a ‘non-modal’ ethnicity should increase the diversity of a city council, the discontinuity at the plurality margin allows for the causal identiﬁcation of an eﬀect of council diversity on public spending. By regressing per capita public goods spending on the vote margin of ‘non-modal’ can- didates for races where a non-modal candidate faced a modal candidate, Beach and Jones (2017) estimate a treatment eﬀect of -0.31 on a log scale, implying that the election of a councilor that increases ethnic diversity causes a 31% drop in public goods spending. 22 To consider this estimate in context, a 31% cut in public goods spending amounts to roughly $463 per capita for the average city. This is equivalent to eliminating all spending on police (13% in the average city), ﬁre protection (9%), and roads (9%). By comparison, similar studies suggest much more modest eﬀects. In an RD analyis of Democratic vs. Republican mayoral candidates, de Benedictis-Kessner and Warshaw (2016) ﬁnd that narrowly-elected Democratic mayors increase public spending by 5% on average. In their original study of US cities, Alesina, Baqir and Easterly (1999) ﬁnd that ethnically diverse cities spend 6% to 9% lower shares on “productive” public goods than ethnically homogeneous cities.6 All of these estimates are several multiples smaller than 30%. Even assuming that the eﬀect of a non-modal city councilmember is comparable to that of a Democratic mayor, 7 the RD analysis would be too underpowered to reliably detect a more plausible eﬀect. The minimum detectable eﬀect size given the number of observations in this study is 0.32 8, and the RD plots in Figure 7 makes this problem clear: although a substantial fraction of the sample lies within the bandwidth, the variation in public goods spending is very large relative to any plausible eﬀect size. A suﬃciently high powered study to detect an eﬀect size of 5% would require many times more observations within the neighborhood of the cutoﬀ. Given the Monte Carlo simulation evidence, it may be that the eﬀect is entirely spurious and due to the noisy nature of the data; our simulation results in the context of noisy data give us hope that the GPRD estimators can uncover a more plausible eﬀect if present, or signal the lack of evidence of a reliable eﬀect. Table 4 and Figure 7 compares the GPRD methods with local linear and global polynomial regression. Both GPRD estimators fail to ﬁnd a reliable eﬀect while both traditional methods ﬁnd reliable and implausibly large eﬀects. 6This is the estimated eﬀect of changing the Herﬁndahl ethnic fractionalization index from 0 to 1 (i.e. from perfect homogeneity to perfect heterogeneity). 7Not an unreasonable assumption, since in many municipalities the mayor does not wield strong executive power, and is essentially the chair of the city council. 8See Calonico et al. (2018) for derivation of power calculations in the RD context 23 −0.4 −0.2 0.0 0.2 0.4 0.65.56.06.57.07.58.08.5 Non−Modal Candidate MarginPer−Capita Public Goods Spending (a) Piecewise GPRD. ● ● ● ● ●● ● ● ● ● ● ●● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ●● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●● ● ●● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●● ● ● ● ● ●● ● ● ● ● ●● ● ● ● ● ● ● ● ● ●● ● ● ● ● ●● ● ● ● ● ● ● ● ● ●● ● ● ● ● 6 7 8 −0.6 −0.3 0.0 0.3 0.6 Non−Modal Candidate MarginPer−Capita Public Goods Spending (b) Local Linear Regression. −0.4 −0.2 0.0 0.2 0.4 0.65.56.06.57.07.58.08.5 Non−Modal Candidate MarginPer−Capita Public Goods Spending (c) Global GPRD. 6 7 8 −0.6 −0.3 0.0 0.3 0.6 Non−Modal Candidate MarginPer−Capita Public Goods Spending (d) Global Polynomial Regression. Figure 7: Fit comparison between the GPRD methods and local linear and global polynomial regression for the Beach and Jones (2017) application. Table 4: Treatment eﬀect comparison between the GPRD methods and local linear and global polynomial regression for the Beach and Jones (2017) application. Estimator Treatment eﬀect 95% CI Global GPRD 0.019 [−0.115, 0.154] Piecewise GPRD −0.137 [−0.311, 0.038] Local Linear −0.344 [−0.595, −0.093] Global Polynomial −0.438 [−0.734, −0.142] 4 Conclusion In this paper, we have demonstrated how low-powered regression discontinuity analyses can yield misleading and exaggerated causal eﬀect estimates, characterized by an implausibly large divergence in the slope of the conditional expectation function in the neighborhood of the cutoﬀ. We introduce a novel RD estimator, Gaussian Process Regression Discontinuity (GPRD), to address these problems. GPRD performs well in simulations and provides more 24 plausible treatment eﬀect estimates in empirical applications. In future work we hope to extend GPRD in several directions. First, we plan to develop novel methods for optimizing the covariance kernel hyperparameters in the RD context, placing greater weight on observations closer to the cutoﬀ when estimating the length scale and introducing a fully Bayesian MCMC approach. Second, we plan to expand GPRD to handle fuzzy RD designs and the inclusion of pre-treatment covariates, both natural extensions to the current framework. All of these will be made available for researchers in the forthcoming R package gprd. References Abou-Chadi, Tarik and Werner Krause. 2018. “The Causal Eﬀect of Radical Right Success on Mainstream Parties’ Policy Positions: A Regression Discontinuity Approach.” British Journal of Political Science pp. 1–19. Alesina, Alberto, Reza Baqir and William Easterly. 1999. “Public Goods and Ethnic Divi- sions.” The Quarterly Journal of Economics 114(4):1243–1284. Beach, Brian and Daniel B. Jones. 2017. “Gridlock: Ethnic Diversity in Government and the Provision of Public Goods.” American Economic Journal: Economic Policy 9(1):112–136. Branson, Zach, Maxime Rischard, Luke Bornn and Luke W. Miratrix. 2019. “A nonpara- metric Bayesian methodology for regression discontinuity designs.” Journal of Statistical Planning and Inferenc 202:14–30. Button, Katherine S., John P. A. Ioannidis, Claire Mokrysz, Brian A. Nosek, Jonathan Flint, Emma S. J. Robinson and Marcus R. Munaf`o. 2013. “Power failure: why small sample size undermines the reliability of neuroscience.” Nature Reviews Neuroscience 14(5):365–376. Calonico, Sebastian, Matias D. Cattaneo, Max H. Farrell and Rocio Titiunik. 2018. “Re- 25 gression Discontinuity Designs Using Covariates.” Review of Economics and Statistics pp. 1–30. Calonico, Sebastian, Matias D. Cattaneo and Rocio Titiunik. 2014. “Robust Nonparamet- ric Conﬁdence Intervals for Regression-Discontinuity Designs.” Econometrica 82(6):2295– 2326. Cattaneo, Matias D., Brigham Frandsen and Roc´ıo Titiunik. 2014. “Randomization Inference in the Regression Discontinuity Design: An Application to Party Advantages in the U.S. Senate.”. de Benedictis-Kessner, Justin and Christopher Warshaw. 2016. “Mayoral Partisanship and Municipal Fiscal Policy.” The Journal of Politics 78(4):1124–1138. de la Cuesta, Brandon and Kosuke Imai. 2016. “Misunderstandings About the Regression Discontinuity Design in the Study of Close Elections.” Annual Review of Political Science 19:375–396. Ferreira, Fernando. 2010. “You can take it with you: Proposition 13 tax beneﬁts, residential mobility, and willingness to pay for housing amenities.” Journal of Public Economics 94(9- 10):661–673. Gelman, Andrew and Guido Imbens. 2017. “Why high-order polynomials should not be used in regression discontinuity designs.” Journal of Business & Economic Statistics . Gelman, Andrew and John Carlin. 2014. “Beyond power calculations: Assessing Type S (sign) and Type M (magnitude) errors.” Perspectives on Psychological Science pp. 1–11. Hahn, Jinyong, Petra Todd and Wilbert Van Der Klaauw. 2001. “Identiﬁcation and Es- timation of Treatment Eﬀects with a Regression-Discontinuity Design.” Econometrica 69(1):201–209. 26 Hopkins, Daniel J. 2011. “The limited local impacts of ethnic and racial diversity.” American Politics Research 39(2):344–379. Imbens, Guido and Karthik Kalyanaraman. 2012. “Optimal bandwidth choice for the re- gression discontinuity estimator.” The Review of Economic Studies 79(3):933–959. Klaˇsnja, Marko and Rocio Titiunik. 2017. “The Incumbency Curse: Weak Parties, Term Lim- its, and Unfulﬁlled Accountability.” The American Political Science Review 111(1):129– 148. Lee, David S. 2008. “Randomized experiments from non-random selection in US House elections.” Journal of Econometrics 142(2):675–697. Lowe, Will, Kenneth Benoit, Slava Mikhaylov and Michael Laver. 2011. “Scaling policy preferences from coded political texts.” Legislative Studies Quarterly 36(1):123–155. Ludwig, J and D L Miller. 2007. “Does Head Start improve children’s life chances?” The Quarterly Journal of Economics 122:159–208. Rasmussen, Carl Edward and Christopher K. I. Williams. 2006. Gaussian Processes for Machine Learning. MIT Press. Trounstine, Jessica. 2015. “Segregation and Inequality in Public Goods.” American Journal of Political Science 60(3):709–725. Volkens, Andrea, Sven Regel Pola Lehmann, Theres Matthieß, Nicolas Merz and Annika Werner. 2015. The Manifesto Data Collection: Manifesto Project (MRG/CMP/MARPOR). Version 2015a. Berlin: . 27","libVersion":"0.3.1","langs":""}