{"path":"lit/lit_sources/Yang20fakeNewsReduceShare.pdf","text":"https://doi.org/10.1177/2056305120955173 Creative Commons Non Commercial CC BY-NC: This article is distributed under the terms of the Creative Commons Attribution- NonCommercial 4.0 License (https://creativecommons.org/licenses/by-nc/4.0/) which permits non-commercial use, reproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage). Social Media + Society July-September 2020: 1 –11 © The Author(s) 2020 Article reuse guidelines: sagepub.com/journals-permissions DOI: 10.1177/2056305120955173 journals.sagepub.com/home/sms Original Article Is fake news on social media an important concern for social media users? Most likely the answer is a definite “yes.” However, the degree to which people feel they are influenced by social media themselves is still less clear. Even more important are questions about how audiences deal with fake news. Do they attempt to avoid it? If they do, what measures do they take? This research is focused on some of those ques- tions and considers not only how individuals think about fake news but how their perceptions impact their interactions with all news, whether fake or not. Social media has quickly become an important outlet for news distribution. Two-thirds of Americans report that they get some news on social media (Shearer & Gottfried, 2017). In some instances, audiences are moving away from tradi- tional media such as newspapers, and in other instances such as with television audiences are supplementing their news consumption with online stories. As news audiences increas- ingly turn to social media platforms like Facebook and Twitter for information, these changes bring new challenges. In 2016, social media came under fire for allowing fake news sites to be readily shared. A Columbia Journalism arti- cle reported that while the audience that shares fake news is relatively small, nearly 30% of all fake news traffic could be linked back to Facebook (Nelson, 2017). Other research has found that fake news content creators are motivated by at least two factors (Allcott & Gentzkow, 2017). In some instances, it is simply an opportunity to use fake news web- sites as a revenue source for advertising (Sydell, 2016). As fake news is shared, it directs traffic back to websites that contain advertising. This strategy creates “clicks” that trans- late into advertising dollars for site content creators. In other instances, fake news has become a political tool for foreign interests to exacerbate social and political tensions that already exist. This is confirmed by Stukal et al. (2017) that misinformation has been spread across social media through various techniques including automated bots and human agents who supported state-run propaganda. In fact, the proliferation of fake news on social sites has become so common it has sparked global concerns from law- makers. While recent elections in the United States were per- haps among the first to have uncovered attempts by foreign interests to use fake news to alter the attitudes of the electorate, 955173 SMSXXX10.1177/2056305120955173Social Media <span class=\"symbol\" cstyle=\"Mathematical\">+</span> SocietyYang and Horning research-article20202020 1University at Albany, State University of New York, USA 2Virginia Tech, USA Corresponding Author: Fan Yang, Department of Communication, University at Albany, State University of New York, SS 375, 1400 Washington Avenue, Albany, NY 12222, USA. Email: fyang@albany.edu Reluctant to Share: How Third Person Perceptions of Fake News Discourage News Readers From Sharing “Real News” on Social Media Fan Yang 1,2 and Michael Horning 2 Abstract Rampant fake news on social media has drawn significant attention. Yet, much remains unknown as to how such imbalanced evaluations of self versus others could shape social media users’ perceptions and their subsequent attitudes and behavioral intentions regarding social media news. An online survey (N = 335) was conducted to examine the third person effect (TPE) in fake news on social media and suggested that users perceived a greater influence of fake news on others than on themselves. However, although users evaluated fake news as socially undesirable, they were still unsupportive of government censorship as a remedy. In addition, the perceived prevalence of fake news leads audiences to reported significantly less willingness to share all news on social media either online or offline. Keywords fake news, third person effect, social media 2 Social Media + Society countries in Europe, Africa, and South America have all wres- tled with the problem. In both Bavaria and France, lawmakers have sought legislation that would require social media com- panies to tighten up standards to reduce fake news that people are exposed to (Scott, 2018). Facebook, in particular, has faced harsh criticism and has been required to attend several hear- ings on the topic. In one recent hearing, nine countries—UK, France, Canada, Argentina, Belgium, Brazil, Ireland, Latvia, and Singapore—met with Facebook representatives to discuss the impact of fake news on both European and South American Elections (Romm, 2018). While lawmakers wrestle with the issue, social media users seem to be struggling with identifying the fake news in their social feeds. As a large-scale survey revealed, newsreaders believed fake news headlines 75% of the time (Ipsos Public Affairs, 2016). Researchers have further suggested that even when aware of fake news people tend to underestimate its impact on themselves and exaggerate the effect on others (Jang & Kim, 2018). Yet, little has been known as to how such imbal- anced evaluations of self versus others could shape social media users’ actual attitudes and behavioral intentions regard- ing social media news. Drawing upon the theory of third person effect (TPE), this study examines social media users’ percep- tions, attitudes, as well as behavioral intentions with respect to fake news. Findings of this study could deepen our understand- ings regarding the impact of fake news on social media users and shed light on devising effective strategies and policies. Theoretical Background Conceptual Definitions of Fake News While a good deal of fake news looks at its impact on politi- cal processes, fake news does not necessarily need to be political. Research suggests that fake news has addressed everything from vaccinations to nutrition to stock values (D. M. J. Lazer et al., 2018). Conceptually speaking fake news seems to be information that has the appearance of real news but that has other motives than to merely inform. As a type of misinformation, fake news is primarily disseminated by “the auspices of media or formal organizational authority” (Donovan, 2007, p. 67). As such, it differs from the generic misinformation as well as other forms of misinformation such as rumors, gossip, or legend that are mainly fabricated and spread by the general population. Scholars have defined fake news as “news articles that are intentionally and verifi- ably false and that could mislead readers” (Allcott & Gentzkow, 2017). Others have suggested that fake news is news that is designed to mimic real news but that lacks “edi- torial norms and processes that ensure its accuracy and cred- ibility” (D. M. J. Lazer et al., 2018, p. 9). Relevant Research on Fake News The term fake news is a general term recently made popular primarily by political events. However, researchers have long been exploring concepts related to fake news. The scholarship has separated fake news into news which is intended to deceive (misinformation) and news which may be inaccurate but was not necessarily intended to be inaccurate (misinfor- mation) (Bode & Vraga, 2015; Ecker et al., 2014; Iosifidis & Nicoli, 2020; Tudjman & Mikelic, 2003). Several studies have provided some insight into the factors that lead people to accept fake news (Flynn et al., 2017). Research on political misperceptions, which is a concept that has some similarity with fake news, suggests that fake news is more easily accepted by people who are highly partisan and by individu- als with prior opinions on an issue (Taber & Lodge, 2006). In another study on fake news headlines, the researchers found that Republicans were more likely to believe fake news sto- ries than Democrats. In addition, the same study found that people who spend less time with social media have less edu- cation, are younger, and are more likely to rate fake news headlines as true (Allcott & Gentzkow, 2017). Some research has focused on how people combat encounters with false or misleading information—for example, how people accept “pseudo-profound bullshit,” which was conceptualized as statements that appear to have deep truths but that are either false or lacking in any sub- stance. In this research, the authors found people who engaged in a deeper reflection of the statements were more likely to reject them as true, but individuals with less criti- cally reflective capacities were more accepting of such statements (Pennycook et al., 2015). Research also suggests that people are led to accept mis- information because they sometimes rely on peripheral cues. For example, some research has found that people rely on the opinions of elites to form opinions about an issue. This is often a tactic used in fake news as well (Kiely & Robertson, 2016). Druckman et al. (2013) found that when political elites were perceived to be more divided on an issue, people often defaulted to side with elites with whom they agreed and failed to reflect critically on the issue at hand. Other research suggests that peripheral cues provided by a technol- ogy can also persuade people to accept information as more credible. In one experiment that looked at political campaign websites, the authors found websites that were more interac- tive rated political candidates highly and expressed more agreement with their policy positions (Sundar et al., 2003). While this study did not specifically assess how people are led to accept false information, it does lend some evidence to the idea that fake news is not just evaluated by the content, but also by other contextual factors such as the “look” and affordances of a piece of digital content. Perhaps the most unsettling is the recent findings that show that even when people are told that information is false, they sometimes are more prone to be more accepting of fake news. Several studies have documented that on highly charged issues, exposing people to facts and corrective infor- mation often does not change opinions (Berinsky, 2009; Kuklinski et al., 2000; Sides & Citrin, 2007). Other research shows that merely informing people about fake news is not a Yang and Horning 3 simple solution. Facebook, for example, recently removed red flags and other marks to indicate news might be false because such indicators may cause people to become further entrenched in their beliefs as they sense an elite presence (with whom they may disagree) “judging” the content (Shu, 2017; Vosoughi et al., 2018). Third Person Perception and Fake News The focus of this current research was designed to better understand how social media users are processing fake news. There are questions about the degree to which indi- viduals think fake news is a concern, how much they think they are impacted by fake news, and how they feel it should be dealt with. Our theoretical framework is the TPE hypoth- esis. As one of the most heavily tested theories in the field of communication research (Bryant & Miron, 2004), the TPE hypothesis (Davison, 1983) refers to a self-other discrep- ancy in relation to perceptions of media effects, such that individuals tend to exaggerate the effects of media on others and underestimate such effects on themselves. Serving as a “self-serving bias” (Gunther & Mundy, 1993) or “self- enhancement bias” (Perloff, 2002), the third person percep- tion (TPP)—the conceptual component of TPE—drives individuals to downplay their susceptibility to socially undesirable messages and overstate their receptivity to socially desirable messages (Scharrer & Leone, 2008) for the purpose of maintaining a superior self-image and boost- ing one’s ego (Gunther, 1995). The prevalence of TPE has been frequently identified on various media (Sun et al., 2008) such as the internet (Antonopoulos et al., 2015; Chen & Ng, 2016), and social media (Buturoiu et al., 2017; Lev-On, 2017; Schweisberger et al., 2014), all of which pointed to the self-other asymme- tries when it comes to gauging media effects. This “percep- tual fallacy” often dictates the formulations of our perceptions, particularly our judgments of bias and objectiv- ity (Pronin et al., 2004). The same news coverage of a con- troversial issue may be considered as false by readers on both sides who hold exactly opposing opinions (Gunther & Liebhart, 2006). Individual evaluations of “misleading” media content are especially susceptible to TPP when the content is riddled with harmful consequences (Lim, 2017; Perloff, 2002). Fake news—information deliberatively fabricated and propagated to cause certain parties damage—therefore ren- ders itself highly relevant to TPE because it is possible that individuals who are exposed to fake news are biased about its effect and see it as having a stronger influence on “others” than on themselves. Coverage of fake news has exploded ever since the 2016 presidential election when social media like Facebook were strategically utilized to micro-target users with intentional misinformation (Bodó et al., 2017; Rao, 2017). The unprecedented marriage of social media and fake news is particularly problematic in today’s convergent media environment wherein people are increasingly reliant on social media for news consumption (Tambuscio et al., 2015). This is particularly problematic because individuals might be overestimating their own confidence when it comes to identifying fake news. Specifically, while most people (64%) expressed their concerns regarding the proliferation of fake news in a national survey, 84% of them, interestingly, also indicated that they were very or somewhat confident in identifying fake news (Pew Research Center, 2016). While there is little evidence to suggest that social media users are particularly adept at identifying fake news, reports do suggest that they often feel it is a problem for “other” social media users. For example, in examining fake news in a political context, Jang and Kim (2018) found that Democrats believed Republicans to be significantly more affected by fake news on social media and vice versa. Although fake news has been frequently politically charged, its damage is not necessarily confined to the political realm. For example, in June 2017 the fake news about Ethereunm’s founder had died in a car crash caused the company’s market value to shrink by US$4 billion (Wong, 2017). Regardless of its topic—social, financial, or political—fake news comes off as a term with inherently negative connotations and can be subject to the TPE. Given survey reports that suggest indi- viduals tend to underestimate fake’s news’ influence on themselves, we propose the following hypothesis: H1. Individuals will perceive the influence of fake news on others as greater than it is on themselves. Attitudinal Outcomes of TPE in Fake News Research has also found that TPEs were also magnified when people were asked about the influence of socially undesir- able media messages (Eveland & McLeod, 1999; Jensen & Hurley, 2005), such as pornography (Lo & Wei, 2002) and violent content (Duck et al., 1995). In other words, individu- als often tend to feel undesirable media content has a greater influence on others than themselves. The underlying psycho- logical mechanism, as discussed earlier, is the human ten- dency to maintain positive images of ourselves. Individuals, as a result of being subject to TPP, are often compelled to side with the opinions and behaviors of others that are deemed socially desirable but often feel that socially unde- sirable messages are more likely to influence others and to be avoided (Sun et al., 2008). Therefore, while the extant litera- ture has extensively examined social desirability as one of the key antecedents for TPE, it could also serve as a conse- quence of TPE such that individuals are more likely to per- ceive an issue as socially undesirable when they consider it more impactful on the “vulnerable others.” While how people respond to TPP varies by context, one commonly researched behavioral outcome is support for censorship (McLeod et al., 1997; Salwen, 1998), or other types of restriction (de Vreese & Semetko, 2002) as a means 4 Social Media + Society to intervene in the production and propagation of malicious media content. The association between TPE and support for censorship, however, is not conclusive (Chung & Moon, 2016) as scholars also found a non-significant relationship between the two (Lo & Wei, 2002; Wu & Koo, 2001). In a meta-analysis, Xu and Gonzenbach (2008) pointed out that support for censorship might be contingent upon the genre of media content. Individuals are more likely to support government regulations of entertainment content such as pornography and advertising but are less accepting of the idea of news censorship. Deeply ingrained in Western val- ues is the concept of freedom of speech. News readers, with the expectation of a free press, often do not support news censorship even in the presence of false news coverage (Salwen & Driscoll, 1997; Salwen & Dupagne, 1999). This reluctance to support news censorship of fake news was found by Jang and Kim (2018) who observed a significantly negative relationship between TPP of fake news and support for regulation. Besides the issue of freedom of speech, social media are by design harder to monitor and censor (Bamman et al., 2012). Therefore, the association between TPP of fake news and support for censorship might not be as easily predicted as the relationship between TPE and the social desirability of fake news: H2. Individuals subject to greater TPP of fake news are more likely to deem it as socially undesirable. RQ. What is the relationship between TPP of fake news and support for censorship? Protective Behaviors of TPE in Fake News Beyond attitude change, TPP has also been increasingly identified as a predictor of behavioral change. Individuals under the assumption that others are more vulnerable to media influence are more likely to enact protective behaviors (Nathanson et al., 2002), including parental mediation of adolescents’ problematic media use (Leung & Lee, 2012; Livingstone & Helsper, 2008) and promotion of media liter- acy education (D. Lazer et al., 2017). In the case of fake news, individuals, who are concerned about the grave impact of fake news on others, might exer- cise extra caution when it comes to sharing news on social media and even in offline situations for the purpose of pro- tecting others. The relationship could also be further medi- ated by their perceived social desirability of fake news on social media because such an evaluation may serve as moti- vation to suppress the influence of fake news on others (Hoffner & Buchanan, 2002; Tsfati & Cohen, 2003). In addi- tion, this reluctance to share fake news stemming from an inability to detect what is real from fake may lead individuals to share less news altogether as a way of avoiding the sharing of potential misinformation. As a result, the research considered the impact of TPP on the sharing of news on social media: H3. Individuals more subject to TPP of fake news are less willing to share news they read on social media. H4. TPP of fake news on social media decreases individ- ual news sharing intent via (H4a) perceived social desir- ability of fake news and (H4b) support for censorship. Methods Participants and Procedure A total number of 335 MTurk master workers were recruited from Amazon Mechanical Turk (MTurk) (https://www. mturk.com/)—a crowdsourcing internet service for research. The MTurk platform has been shown to be as reliable as those obtained from other national sampling methods (Coppock, 2018; Stewart et al., 2015) and was chosen because it provided an opportunity to capture a broader range of perspectives representative of individuals from various countries and cultures. Berinsky et al. (2012) have found that MTurk samples differ somewhat slightly from US popula- tions in certain characteristics such as marital status and home ownership and they are somewhat more politically aware, but that overall these differences do not present “a wildly distorted view of U.S. populations” (p. 361). MTurk also provides a way for researchers to recruit from respon- dents with a unique set of characteristics. As a result, because this research concerns fake news on social media, a qualifi- cation criterion was set to screen participants, such that only those whose major news source was social media were eli- gible to participate. A total of 163 (48.7%) of the participants were female. Participants aged between 20 and 65 years (Mage = 37.30, standard deviation [SD] = 10.85). A link using Qualtrics survey software was sent to the par- ticipants. Upon clicking the link, they were directed to the questionnaire on Qualtrics. Also, because the concept of “fake news” is only loosely defined in popular media and has been interpreted in different ways, participants were given a clear definition of fake news based on Allcott and Gentzkow (2017) research at the beginning of the survey that read, Fake news is a form of news disseminated by both traditional media (e.g., newspapers, broadcast, and TV) and new media (e.g., social media). This type of news is different from other news in that it contains deliberate false facts that are included in the news story for the purposes of financial or political gain. Once they read this definition, participants were asked to answer a series of questions regarding their perceptions of fake news’ influence on themselves and others, their atti- tudes toward fake news, their news sharing intentions, as well as demographics such as gender and age. As scholars clearly advised keeping the questions about the effects of Yang and Horning 5 media messages on self and others widely separated in a questionnaire to avoid respondents noticing that we were asking them to compare both their perceptions of themselves and others (Davison, 1983), we placed one of the two ques- tions either at the beginning or at the end of the question- naire. We also randomized other questions to account for possible order effects. Measures TPE. The TPE was measured by subtracting the perceived influence of fake news on self from the one on others (Jang & Kim, 2018). The three items measuring the perceived influence of fake news on self included “I am frequently con- cerned that the news I read on social media might be false,” “I personally have a hard time telling whether the news that I see on social media is true or not,” and “fake news on social media has greatly affected me” (Cronbach’s α = .73, M = 4.17, SD = 1.48). The three items measuring the perceived influ- ence of fake news on others included “I am frequently con- cerned that the news that others are reading on social media might be false,” “I think others often have a hard time telling whether the news that they see online is true or not,” and “fake news on social media has greatly affected others” (Cronbach’s α = .82, M = 5.57, SD = 1.15). Participants were asked to indicate their agreement on a 7-point Likert-type scale (1 = strongly disagree; 7 = strongly agree). Support for Censorship. Three items on a 7-point Likert-type scale (1 = strongly disagree; 7 = strongly agree) adapted from Jang and Kim (2018) were used to measure support for cen- sorship of fake news on social media. Items included “fake news should be banned by the government,” “I support leg- islation to prohibit fake news,” and “fake news should be regulated by the government” (Cronbach’s α = .93, M = 4.79, SD = 1.99). Perceived Social Desirability. Two items on a semantic-differ- ential scale adapted from Lim (2017) were used to measure perceived social desirability of fake news. Participants were asked to indicate whether the degree of impact fake news has on our society is 1 = undesirable; 7 = desirable, and 1 = nega- tive; 7 = positive (Cronbach’s α = .94, M = 2.24, SD = 1.60). News Sharing Intent. Five items on a 7-point Likert-type type scale (1 = very unlikely; 7 = very likely) adapted from DiStaso et al. (2015) were used to measure news sharing intent. The scale emphasizes individuals’ intent to share news they read on social media via both online and offline channels. Partici- pants were asked to rate on sample items like how often they intended to “share news stories on social media such as Twit- ter, Facebook, and so on,” as well as “talk about the news stories you read on social media to others around you in real life” (Cronbach’s α = .90, M = 4.21, SD = 1.46). Data Analysis A paired-sample t-test was adopted to investigate H1 to understand whether individuals perceived that fake news to affected others more than it did themselves. In subsequent analyses, the proposed relationships among TPE in fake news, perceived social desirability of fake news, support for fake news censorship, and news sharing intent (H2–H4 and RQ) were tested using structural equation modeling (SEM) (Jöreskog & Sörbom, 1999). This modeling technique inves- tigates the theoretical relationships among variables of research interest while accounting for the overall model fit (Kline, 2011). According to Bentler (in press), an appropriate sample size for SEM should yield a ratio of N (total sample size) versus q (the number of free parameter estimates) between 5:1 and 10:1—that is, 5–10 observations for every parameter to be estimated. Given that there are 27 distinct parameter estimates (covariates included) in the full measure- ment model, the current sample size (N = 335) is sufficient. Results TPE in Fake News Consistent with H1, the paired-sample t test revealed that participants perceived a greater influence of fake news on others (M = 5.57, SD = 1.15) than on themselves (M = 4.17, SD = 1.47), t(334) = 15.22, p < .001. Such a result confirmed that there was, indeed, a TPE with respect to fake news. Impact of TPE Measurement Model. The full measurement model was first assessed utilizing a standard confirmatory factor analysis with maximum likelihood estimation procedure. The factor analysis yielded a moderated fit, χ 2 = 110.698, degrees of freedom (df) = 39, p < .001, root mean square error of approx- imation (RMSEA) = .074, comparative fit index (CFI) = .972, 95% confidence interval [CI] = [0.058, 0.091]. Table 1 reports the bivariate correlations among all variables. The chi-square test is usually sensitive to sample size (Kline, 2011). Larger samples (e.g., N > 200) will almost always result in a chi-square at p < .05. The chi-square Table 1. Correlations Among All Variables Tested in the SEM Model. 1 2 3 4 1. Third person effect (TPE) – 2. Perceived social desirability (PSD) −.48** – 3. Support for censorship (SFC) .82*** −.51** – 4. News sharing intent (NSI) −.44*** .24* −.59*** – SEM: structural equation modeling. *p < .05, **p < .01, ***p < .001. 6 Social Media + Society goodness-of-fit test might be, in this case, too conservative in this case given the current sample size. According to the cut- off criteria suggested in Hu and Bentler (1999) and Holbert and Stephenson (2002), the RMSEA estimate index and the CFI both indicate an acceptable measurement model for fur- ther analyses. Structural Model. Utilizing single-variable-as-indicators technique for the latent variables (Stephenson & Holbert, 2003), the structure model with bootstrapping of 5,000 sam- ples and 95% bias-corrected CIs was properly identified and fits the data well, χ 2 = 1.510, df = 1, p < .001, RMSEA = .039, CFI = .997, 95% CI = [0.000, 0.157] (Figure 1). It is, never- theless, important to note that the goodness-of-fit statistics matters less when a model is near saturation. In this case, the paths should be given more credit than the overall model fit. Consistent with H2, a TPE was negatively associated with perceived social desirability of fake news (β = −.41, p < .001). In other words, the more individuals perceived that fake news influenced others, the more they thought fake news was socially undesirable. The analysis also revealed TPE was negatively related to support for censorship (β = −.25, p < .001). In other words, individuals who thought that fake news had a significant influence on others were also less likely to support censorship. We discuss possible implica- tions of this somewhat counter-intuitive finding below. As predicted by H4a and H4b, the TPE had a significant direct effect on individuals’ news sharing intent (β = −.22, p < .001), such that a higher level of TPE led to lower intent to share news individuals obtained from social media online and offline. In addition to the direct effect, the analysis also suggested a significant indirect effect of TPE regarding news sharing intent via perceived social desirability of fake news and support for censorship of fake news altogether (β = −.36, p < .001). Using the phantom model approach recommended by Macho and Ledermann (2011), bootstrapping procedures using 5,000 bootstrap samples and bias-corrected CIs were employed to test the mediating roles of perceived social desirability of fake news and support for fake news censor- ship between TPE of fake news and news sharing intent. This analysis revealed significant indirect effects for both media- tors, perceived social desirability of fake news: β = −.09, p < .001; support for censorship: β = −.06, p < .001. Therefore, all hypotheses received support. Discussion This study examines the TPE of fake news on social media and how such a TPP of fake news associated with individual attitudes and behavioral intentions. Consistent with the extant literature regarding TPE and social media (Buturoiu et al., 2017; Lev-On, 2017; Schweisberger et al., 2014), we also found the “self-other” asymmetries in perceiving the influence of fake news on social media. Driven by the psy- chological need for self-enhancement (Perloff, 2002), indi- viduals are, consciously or not, more inclined to project a greater effect of fake news on others than on themselves. This also helps explain the sharp contrast between the grave concern expressed by most respondents in the Pew Research Center (2016) survey regarding the severity of fake news and the optimism toward one’s own ability to identify fake news at the same time. Our findings also identify the association between atti- tudes and TPP, such that individuals who are more subject to TPP reported the issue of fake news on social media as more socially undesirable. While most of the prior literature has focused on social desirability as a predictor of TPP (Eveland & McLeod, 1999; Jensen & Hurley, 2005), individuals also further reinforce their perceived social undesirability of fake news when they regard others as more susceptible to the harm of fake news on social media. This study thus offers empirical evidence regarding a possibly reciprocal relation- ship between perceptions of social desirability and TPP. Implications for Censorship and Press Freedom Beyond our attitudinal measures, we also tried to understand how individuals thought about addressing their fake news concerns. Interestingly, despite clearly viewing fake news on social media as socially undesirable, individuals also explic- itly disfavor the idea of government censorship as a solution. Such a finding confirms prior literature about the weak rela- tionship between TPE and support for censorship in the con- text of news (Salwen & Driscoll, 1997; Salwen & Dupagne, 1999). We note that these findings, however, may raise more questions than answers given the fact that the very concept of Figure 1. The relationships between TPE in fake news and news sharing intent via perceived social desirability of fake news and support for censorship. TPE: third person effect; PSD: perceived social desirability; SFC: support for censorship; NSI: news sharing intent. Standardized regression weights were reported. ***p< .001. Yang and Horning 7 censorship itself is changing. To put a finer point on it, we used Jang and Kim’s (2018) approach, which focused pri- marily on acts taken by government entities to control the flow of fake news. Our measures asked participants whether they supported such approaches as banning fake news, legis- lating its prohibition, and regulating fake news in some way. Our respondents opposed such action. A possible explana- tion of this finding may be found in a recent study conducted by the Knight Foundation and Gallup (2019). According to the study, while the majority of Americans express concern for fake news, they often have difficulty defining it and agreeing on what actually constitutes fake news. Given the general lack of agreement on fake news, individuals may be cautious to see government oversight. It may also be that as concerning as fake news is, respondents may still be deeply subscribed to the idea of the free press and are, therefore, very cautious of involving any government interventions despite the need to protect other vulnerable social media users (Jang and Kim, 2018). However, we also note that our measure of fake news cen- sorship here is wholly limited to a focus on government action and that it does not address how the public might feel about other forms of censorship taking place on social net- works. Censorship of media has traditionally been conceptu- ally linked to notions of some form of government or authoritarian control (Siebert et al., 1956), but increasingly censorship on social media can occur through algorithmic choices resulting from corporate and economic interests. Social media companies like Facebook and Google, for example, regularly use algorithms to make choices about what information users based on demographic make-up and personal preferences. These choices often have implications for press freedoms and for how people experience news. While the idea of a free press is often embedded in demo- cratic principles of a press that is free to publish what it sees as important for an informed public (Siebert et al., 1956), Ananny (2018) has argued that press freedom has never been just about the right for the media to publish but for the right for people to hear. Ananny points out that press freedom has always been dependent not just on legal and constitutional restraint but on access to and knowledge of socio-technical apparatuses that allow the press to communicate ideas. In a networked society, Ananny argues, this means that we need to rethink the degree to which media organizations should be both separate and dependent on social networks to create an informed electorate. While our findings might suggest that the public’s value press freedoms more than they fear fake news, there are still questions about how to maximize those freedoms in a social media environment that can experience censorship outside of government regulation. Research has shown that social media often make choices about what news is seen and who sees it (Jolly, 2014). While not as overt, this form of soft censorship results from algo- rithmic choices that rank certain types of information as more important and more valuable to audiences. Diakopoulos (2019) has explored this idea extensively and has docu- mented how various social networks use algorithms to make value choices on certain types of news. He notes that “for people seeking to inform themselves on important civic issues, search engines such as Google play an increasingly important role as algorithmic gatekeepers, steering massive amounts of human attention through their relevance algo- rithms” (p. 147). For example, in his study on Google’s news feed, Diakopoulos shows that their algorithms privilege only a select number of traditional news sources, and that when the algorithm highlights other news, it has sometimes been guilty of passing off unvented tweets, questionable video content and foreign state-run propaganda as “news.” Another study followed algorithmic ranking of news during the 2016 congressional election found that Bing and Yahoo in particu- lar were often guilty of promoting fake news in their news feeds, leading the researchers to ask how such choices could impact the outcome of electoral processes (Metaxas & Pruksachatkun, 2017). In a related experiment, Epstein and Robertson (2015) manipulated page rankings on a search engine to privilege one political candidate over another, and in doing so speculated that these types of algorithmic biases in search engine rankings could make the difference in close elections. While one could argue that there is a difference between governments making overt decisions to limit access to cer- tain types of information and algorithms giving more weight to certain types of content over others, both actions consti- tute a certain type of gatekeeping. In the former, however, publics may not be aware of how algorithmic choices influ- ence the content they see in their search engines and their social media news feeds, and it may be that our results would be different had we focused on these issues in our measures of censorship. Future work might show that pub- lics would prefer to see more transparency in terms of how social media companies go about making their own deci- sions about what types of content to highlight (Diakopoulos, 2019). In other words, the idea of censorship of media in today’s social media environment extends beyond just gov- ernment oversight, and it may well be that while audiences resist government selection of content, they may well sup- port legislation that required social media to provide more transparency on how that content arrived in newsfeeds in the first place. A key contribution of this research also provides some insights into how people are responding to fake news on social media. While they are not in favor of government cen- sorship, the findings show that they are self-censoring in many cases. Prior research in TPP of fake news has found TPP to be significantly associated with greater protective behavioral intentions as suggested in prior studies (Nathanson et al., 2002). Our findings also support this. The results showed that individuals who were more concerned about the 8 Social Media + Society TPEs of fake news said they decreased their total news shar- ing intent online and offline as a means to protect others, whom they deemed at a much higher risk of falling victims of fake news on social media. Their intent to share news online and offline, on the other hand, also decreases indi- rectly via their perceptions of social desirability regarding fake news as well as their support for censorship. In other words, as individuals project a greater impact of fake news on others, they are less likely to consider the issue as socially desirable. The decrease in perceived social desirability of fake news on social media subsequently lowers their intent to share the news they read on social media either online or offline. In addition, although the growing concern regarding others’ susceptibility to fake news on social media still decreases their support for censorship, individuals, on the lookout for others, significantly decrease their news sharing intent—an alternative, individual approach to protecting oth- ers without infringing the deeply cherished value of free press. Hence, individuals become more cautious and less willing to share the news they read on social media either online or offline. This finding has several implications for journalism. While newsrooms may take some solace in the fact that the public seems to endorse the idea of a free and open press despite the threats of fake news, they are also more reluctant to share news on social media when the risk of sharing fake news is high. This suggests that both the flow of accurate and inaccurate misinformation is equally impacted by the growth of fake news on social media. Moreover, for newsrooms that are increasingly reliant on readership coming from social media sites, this finding should raise concerns. It may also raise concerns for social media companies that share a sym- biotic relationship with news media, which often provide content for news feeds. The findings suggest that fake news has the unintended consequence of diminished news sharing, which also includes real news. This could over time impact the bottom line of companies that rely on the sharing of con- tent as part of their revenue model. Furthermore, there may be additional democratic con- cerns that are raised from this finding. There is a long his- tory of research that has linked general news consumption to political involvement, voting, and participation (Scheufele et al., 2002). However, more recent research suggests that there is also a similar positive relationship between the use of news on social media and political efficacy and political participatory behaviors (Gil de Zúñiga & Valenzuela, 2012). Facebook, in particular, has been found to be an important network for political discussions (Halpern & Gibbs, 2013). Given these prior findings, the fact that fake news tends to diminish the sharing of news information may also serve to diminish political discussions. While one does not have to look far on social media to see political discussions often devolve into political battles, the sharing of news and infor- mation also can foster positive dialogue and exposure to dif- ferencing points of view (Anderson, 2016). However, when the public are reluctant to share news, these opportunities are lost. Limitations and Future Directions The findings should be considered in light of several limita- tions. For example, our study focused specifically on social media users, while other readers who consume news from traditional media (e.g., newspaper, TV, broadcast) may have different responses. Nor did this study provide an exhaustive list of factors associated with intentions to share news. Future studies may consider similar questions on other media chan- nels and may find differences in attitudes given the distinct culture and structures of social media versus traditional media. The findings also do not provide a clear understanding of the degree to which fake news actually influences attitudes. Instead, it only helps us understand how individuals are eval- uating these effects on other individuals and themselves. Future research using experimental methods may provide such answers. No doubt social media companies will con- tinue to grapple with the influx of fake news on their social media sites, our research suggests that while individuals do see it as concerning, they still remain supportive of press free- doms. Meanwhile, as the desire to share news diminishes as citizens grapple with the accuracy of the content, this trend raises potential economic and democratic concerns to both social media companies and news organizations. Conclusion By exploring the TPE of fake news on social media and its association with individual attitudes on censorship and news sharing intentions, this research reveals that publics still hold dear the value of press freedom even though they are also, at the same time, concerned by fake news. As a result, they may be less inclined to sharing news on social media, which could ultimately sap public debate on real news across various social media platforms. This is alarming for social media companies, news organizations, policymakers, as well as our society as a whole because lively public deliberations have always been deemed as the bedrock of democracy. Effective actions, there- fore, should be undertaken continuously and systematically to detect, debunk, and eradicate fake news on social media. While combating fake news is perhaps one of the most chal- lenging work in the age of social media, it is certainly a neces- sary endeavor invaluable to uphold our democracy. Declaration of Conflicting Interests The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article. Funding The author(s) received no financial support for the research, author- ship, and/or publication of this article. Yang and Horning 9 ORCID iD Fan Yang https://orcid.org/0000-0002-2880-6271 References Allcott, H., & Gentzkow, M. (2017). Social media and fake news in the 2016 election. Journal of Economic Perspectives, 31(2), 211–236. https://doi.org/10.1257/jep.31.2.211 Ananny, M. (2018). Networked press freedom: Creating infrastruc- tures for a public right to hear. MIT Press. Anderson, M. (2016, November 7). Social media causes some users to rethink their views on an issue. Pew Research Center. http:// www.pewresearch.org/fact-tank/2016/11/07/social-media- causes-some-users-to-rethink-their-views-on-an-issue/ Antonopoulos, N., Veglis, A., Gardikiotis, A., Kotsakis, R., & Kalliris, G. (2015). Web Third-person effect in structural aspects of the information on media websites. Computers in Human Behavior, 44, 48–58. Bamman, D., O’Connor, B., & Smith, N. (2012). Censorship and deletion practices in Chinese social media. First Monday, 17(3). https://doi.org/10.5210/fm.v17i3.3943 Bentler, P. M. (in press). EQS 6 structural equations program man- ual. Multivariate Software. Berinsky, A. J. (2009). In time of war: Understanding American public opinion from World War II to Iraq. University of Chicago Press. Berinsky, A. J., Huber, G. A., & Lenz, G. S. (2012). Evaluating online labor markets for experimental research: Amazon.com’s Mechanical Turk. Political Analysis, 20(3), 351–368. Bode, L., & Vraga, E. K. (2015). In related news, that was wrong: The correction of misinformation through related stories func- tionality in social media. Journal of Communication, 65(4), 619–638. Bodó, B., Helberger, N., & de Vreese, C. H. (2017). Political micro- targeting: A Manchurian candidate or just a dark horse? Internet Policy Review, 6(4). https://doi.org/10.14763/2017.4.776 Bryant, J., & Miron, D. (2004). Theory and research in mass com- munication. Journal of Communication, 54(4), 662–704. Buturoiu, R., Durach, F., Udrea, G., & Corbu, N. (2017). Third- person perception and its predictors in the age of Facebook. Journal of Media Research, 10(2), 18–36. Chen, G. M., & Ng, Y. M. M. (2016). Third-person perception of online comments: Civil ones persuade you more than me. Computers in Human Behavior, 55, 736–742. Chung, S., & Moon, S.-I. (2016). Is the third-person effect real? A critical examination of rationales, testing methods, and previ- ous findings of the third-person effect on censorship attitudes. Human Communication Research, 42(2), 312–337. Coppock, A. (2018). Generalizing from survey experiments con- ducted on mechanical Turk: A replication approach. Political Science Research and Methods. https://isps.yale.edu/research/ publications/isps18-07 Davison, W. P. (1983). The third-person effect in communication. Public Opinion Quarterly, 47(1), 1–15. de Vreese, C. H., & Semetko, H. A. (2002). Public perception of polls and support for restrictions on the publication of polls: Denmark’s 2000 Euro referendum. International Journal of Public Opinion Research, 14(4), 367–390. Diakopoulos, N. (2019). Automating the news: How algorithms are rewriting the media. Cambridge, MA: Harvard University Press. DiStaso, M. W., Vafeiadis, M., & Amaral, C. (2015). Managing a health crisis on Facebook: How the response strategies of apology, sympathy, and information influence public relations. Public Relations Review, 41(2), 222–231. Donovan, P. (2007). How idle is idle talk? One hundred years of rumor research. Diogenes, 54(1), 59–82. Druckman, J. N., Peterson, E., & Slothuus, R. (2013). How elite par- tisan polarization affects public opinion formation. American Political Science Review, 107(1), 57–79. Duck, J. M., Terry, D. J., & Hogg, M. A. (1995). The perceived influence of AIDS advertising: Third-person effects in the context of positive media content. Basic and Applied Social Psychology, 17(3), 305–325. Ecker, U. K. H., Lewandowsky, S., Fenton, O., & Martin, K. (2014). Do people keep believing because they want to? Preexisting attitudes and the continued influence of misinfor- mation. Memory & Cognition, 42(2), 292–304. Epstein, R., & Robertson, R. E. (2015). The Search Engine Manipulation Effect (SEME) and its possible impact on the outcomes of elections. Proceedings of the National Academy of Sciences, 112(33), E4512–E4521. Eveland, W. P., Jr., & McLeod, D. M. (1999). The effect of social desirability on perceived media impact: Implications for third- person perceptions. International Journal of Public Opinion Research, 11(4), 315–333. Flynn, D. J., Nyhan, B., & Reifler, J. (2017). The nature and ori- gins of misperceptions: Understanding false and unsupported beliefs about politics. Political Psychology, 38(S1), 127–150. Gallup. (2019). American views: Trust, media and democracy. https://knightfoundation.org/reports/american-views-trust- media-and-democracy/ Gil de Zúñiga, H., Jung, N., & Valenzuela, S. (2012). Social media use for news and individuals’ social capital, civic engagement and political participation. Journal of Computer-Mediated Communication, 17(3), 319–336. Gunther, A. C. (1995). Overrating the X-rating: The third-person perception and support for censorship of pornography. Journal of Communication, 45(1), 27–38. Gunther, A. C., & Liebhart, J. L. (2006). Broad reach or biased source? Decomposing the hostile media effect. Journal of Communication, 56(3), 449–466. Gunther, A. C., & Mundy, P. (1993). Biased optimism and the third-person effect. Journalism Quarterly, 70(1), 58–67. Halpern, D., & Gibbs, J. (2013). Social media as a catalyst for online deliberation? Exploring the affordances of Facebook and YouTube for political expression. Computers in Human Behavior, 29(3), 1159–1168. Hoffner, C., & Buchanan, M. (2002). Parents’ responses to televi- sion violence: The third-person perception, parental mediation, and support for censorship. Media Psychology, 4(3), 231–252. Holbert, R. L., & Stephenson, M. T. (2002). Structural equation modeling in the communication sciences, 1995-2000. Human Communication Research, 28(4), 531–551. Hu, L. T., & Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria ver- sus new alternatives. Structural Equation Modeling: A Multidisciplinary Journal, 6(1), 1–55. Iosifidis, P., & Nicoli, N. (2020). The battle to end fake news: A qualitative content analysis of Facebook announcements on how it combats disinformation. International Communication Gazette, 82(1), 60–81. 10 Social Media + Society Ipsos Public Affairs. (2016, December 7). Ipsos/BuzzFeed poll: Fake news. https://www.ipsos.com/en-us/news-polls/ipsos- buzzfeed-poll-fake-news Jang, S. M., & Kim, J. K. (2018). Third person effects of fake news: Fake news regulation and media literacy interventions. Computers in Human Behavior, 80, 295–302. Jensen, J. D., & Hurley, R. J. (2005). Third-person effects and the environment: Social distance, social desirability, and presumed behavior. Journal of Communication, 55(2), 242–256. Jolly, J. (2014, May 20). How algorithms decide the news you see. Columbia Journalism Review. https://archives.cjr.org/news_ literacy/algorithms_filter_bubble.php Jöreskog, K. G., & Sörbom, D. (1999). LISREL 8.30: Interactive LISREL. Scientific Software International. Kiely, E., & Robertson, L. (2016, November 18). FactCheck.org. Factcheck.org. https://www.factcheck.org/2016/11/how-to- spot-fake-news/ Kline, R. B. (2011). Principles and practice of structural equation modeling (3rd ed.). Guilford Press. Kuklinski, J. H., Quirk, P. J., Jerit, J., Schwieder, D., & Rich, R. F. (2000). Misinformation and the currency of democratic citizen- ship. The Journal of Politics, 62(3), 790–816. Lazer, D., Baum, M., Grinberg, N., Friedland, L., Joseph, K., Hobbs, W., & Mattsson, C. (2017). Combating fake news: An agenda for research and action. https://shorensteincenter.org/ combating-fake-news-agenda-for-research/ Lazer, D. M. J., Baum, M. A., Benkler, Y., Berinsky, A. J., Greenhill, K. M., Menczer, F., . . . Zittrain, J. L. (2018). The science of fake news. Science, 359(6380), 1094–1096. Leung, L., & Lee, P. S. (2012). The influences of information lit- eracy, internet addiction and parenting styles on internet risks. New Media & Society, 14(1), 117–136. Lev-On, A. (2017). The third-person effect on Facebook: The sig- nificance of perceived proficiency. Telematics and Informatics, 34(4), 252–260. Lim, J. S. (2017). The third-person effect of online advertising of cosmetic surgery: A path model for predicting restrictive ver- sus corrective actions. Journalism & Mass Communication Quarterly, 94(4), 972–993. Livingstone, S., & Helsper, E. J. (2008). Parental mediation of children’s internet use. Journal of Broadcasting & Electronic Media, 52(4), 581–599. Lo, V.-H., & Wei, R. (2002). Third-person effect, gender, and por- nography on the Internet. Journal of Broadcasting & Electronic Media, 46(1), 13–33. Macho, S., & Ledermann, T. (2011). Estimating, testing, and com- paring specific effects in structural equation models: The phan- tom model approach. Psychological Methods, 16(1), 34. McLeod, D. M., Eveland Jr, W. P., & Nathanson, A. I. (1997). Support for censorship of violent and misogynic rap lyrics: An analysis of the third-person effect. Communication Research, 24(2), 153–174. Metaxas, P. T., & Pruksachatkun, Y. (2017). Manipulation of search engine results during the 2016 U.S. congressional elections. http://cs.wellesley.edu/~pmetaxas/Metaxas-Search- Engine-Manipulation-US-Elections-2016.pdf Nathanson, A. I., Eveland, W. P., Jr., Park, H.-S., & Paul, B. (2002). Perceived media influence and efficacy as predictors of caregivers’ protective behaviors. Journal of Broadcasting & Electronic Media, 46(3), 385–410. Nelson, J. (2017, January 31). Is “fake news” a fake problem? Columbia Journalism Review. https://www.cjr.org/analysis/ fake-news-facebook-audience-drudge-breitbart-study.php Pennycook, G., Cheyne, J. A., Barr, N., Koehler, D. J., & Fugelsang, J. A. (2015). On the reception and detection of pseudo-profound bullshit. Judgment and Decision Making, 10(6), 549–563. Perloff, R. M. (2002). The third-person effect. In J. Bryant & D. Zillmann (Eds.), Media effects: Advances in theory and research (2nd ed., pp. 489–506). Lawrence Erlbaum. Pew Research Center. (2016, December 15). Many Americans believe fake news is sowing confusion. http://www.journal- ism.org/2016/12/15/many-americans-believe-fake-news-is- sowing-confusion/ Pronin, E., Gilovich, T., & Ross, L. (2004). Objectivity in the eye of the beholder: Divergent perceptions of bias in self versus others. Psychological Review, 111(3), 781–799. Rao, A. R. (2017). Red, blue and purple states of mind: Segmenting the political marketplace. Journal of Consumer Psychology, 27(4), 521–531. Romm, T. (2018, November 27). Facebook faces fresh lashing from nine countries for its inability to stop the spread of fake news. Washington Post. https://www.washingtonpost.com/ technology/2018/11/27/facebook-faces-global-lashing-nine- countries-its-inability-protect-data-stop-fake-news/ Salwen, M. B. (1998). Perceptions of media influence and support for censorship: The third-person effect in the 1996 presidential election. Communication Research, 25(3), 259–285. Salwen, M. B., & Driscoll, P. D. (1997). Consequences of third- person perception in support of press restrictions in the OJ Simpson trial. Journal of Communication, 47(2), 60–78. Salwen, M. B., & Dupagne, M. (1999). The third-person effect: Perceptions of the media’s influence and immoral conse- quences. Communication Research, 26(5), 523–549. Scharrer, E., & Leone, R. (2008). First-person shooters and the third-person effect. Human Communication Research, 34(2), 210–233. Scheufele, D. A., Shanahan, J., & Kim, S. H. (2002). Who cares about local politics? Media influences on local political involve- ment, issue awareness, and attitude strength. Journalism & Mass Communication Quarterly, 79(2), 427–444. Schweisberger, V., Billinson, J., & Chock, T. M. (2014). Facebook, the third-person effect, and the differential impact hypothesis. Journal of Computer-Mediated Communication, 19(3), 403–413. Scott, M. (2018, October 7). Why we’re losing the battle against fake news. Politico. https://www.politico.eu/article/fake-news- regulation-misinformation-europe-us-elections-midterms- bavaria/ Shearer, E., & Gottfried, J. (2017). News use across social media platforms 2017. Pew Research Center’s Journalism Project. http://www.journalism.org/2017/09/07/news-use-across- social-media-platforms-2017/ Shu, C. (2017). Facebook will ditch disputed flags on fake news and display links to trustworthy articles instead. https:// techcrunch.com/2017/12/20/facebook-will-ditch-disputed- flags-on-fake-news-and-display-links-to-trustworthy-articles- instead/?guccounter=1&guce_referrer=aHR0cHM6Ly93d 3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQA AAGENRO_1dAXG9Z7-Mx2odQeDQvQp9oZllR0fhScbT Yang and Horning 11 Sides, J., & Citrin, J. (2007). European opinion about immigration: The role of identities, interests and information. British Journal of Political Science, 37(3), 477–504. Siebert, F., Siebert, F. T., Peterson, T. B., Peterson, T., & Schramm, W. (1956). Four theories of the press: The authoritarian, lib- ertarian, social responsibility, and Soviet communist concepts of what the press should be and do. University of Illinois press. Stephenson, M. T., & Holbert, R. L. (2003). A Monte Carlo sim- ulation of observable versus latent variable structural equa- tion modeling techniques. Communication Research, 30(3), 332–354. Stewart, N., Ungemach, C., Harris, A. J., Bartels, D. M., Newell, B. R., Paolacci, G., & Chandler, J. (2015). The average laboratory samples a population of 7,300 Amazon Mechanical Turk work- ers. Judgment and Decision Making, 10(5), 479–491. Stukal, D., Sanovich, S., Bonneau, R., & Tucker, J. A. (2017). Detecting bots on Russian political Twitter. Big Data, 5(4), 310–324. Sun, Y., Pan, Z., & Shen, L. (2008). Understanding the third-per- son perception: Evidence from a meta-analysis. Journal of Communication, 58(2), 280–300. Sun, Y., Shen, L., & Pan, Z. (2008). On the behavioral component of the third-person effect. Communication Research, 35(2), 257–278. Sundar, S. S., Kalyanaraman, S., & Brown, J. (2003). Explicating Web site interactivity impression formation effects in political campaign sites. Communication Research, 30, 30–59. https:// doi.org/10.1177/0093650202239025 Sydell, L. (2016, November 23). We tracked down a fake-news creator in the suburbs: Here’s what we learned. Npr.org. https://www.npr.org/sections/alltechconsidered/2016/11/ 23/503146770/npr-finds-the-head-of-a-covert-fake-news- operation-in-the-suburbs Taber, C. S., & Lodge, M. (2006). Motivated skepticism in the evaluation of political beliefs. American Journal of Political Science, 50(3), 755–769. Tambuscio, M., Ruffo, G., Flammini, A., & Menczer, F. (2015, May 18–22). Fact-checking effect on viral hoaxes: A model of misinformation spread in social networks [Conference ses- sion]. 24th International Conference on World Wide Web. Florence Italy. Tsfati, Y., & Cohen, J. (2003). On the effect of the “third-person effect”: Perceived influence of media coverage and residen- tial mobility intentions. Journal of Communication, 53(4), 711–727. Tudjman, M., & Mikelic, N. (2003). Information science: Science about information, misinformation and disinformation. Proceedings of Informing Science + Information Technology Education, 3, 1513–1527. Vosoughi, S., Roy, D., & Aral, S. (2018). The spread of true and false news online. Science, 359(6380), 1146–1151. https://doi. org/10.1126/science.aap9559 Wong, J. I. (2017, June 26). Fake news of a fatal car crash wiped out $4 billion in ethereum’s market value yesterday. Quartz. https://qz.com/1014559/vitalik-buterin-dead-a-hoax-on- 4chan-crashed-ethereums-price/ Wu, W., & Koo, S. H. (2001). Perceived effects of sexu- ally explicit Internet content: The third-person effect in Singapore. Journalism & Mass Communication Quarterly, 78(2), 260–274. Xu, J., & Gonzenbach, W. J. (2008). Does a perceptual discrep- ancy lead to action? A meta-analysis of the behavioral compo- nent of the third-person effect. International Journal of Public Opinion Research, 20(3), 375–385. Author Biographies Fan Yang (PhD, the Pennsylvania State University) is an assistant professor in the Department of Communication at University at Albany, SUNY. Her research focuses on new media and strategic communications. She is interested in examining the psychological effects of new communication technologies on decision-making using methods such as survey, experiment, big-data analysis, and meta-data analysis. Michael Horning (PhD, the Pennsylvania State University) is an associate professor of multimedia journalism in the Department of Communication at Virginia Tech. Horning’s research has been focused on how emerging media technologies influence how audi- ences experience and respond to news. He is interested in under- standing how emerging technologies shape journalistic practices and audience perceptions of news content.","libVersion":"0.3.2","langs":""}