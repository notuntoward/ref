{"path":"lit/lit_notes_OLD_PARTIAL/Quan20probIrradTranspos.pdf","text":"See discussions, st ats, and author pr ofiles for this publication at: https://www.r esearchgate.ne t/publication/339873793 Probabilistic solar irradiance transposition models Article  in  Renewable and Sustainable Energy Reviews · June 2020 DOI: 10.1016/ j.r ser.2020.109814 CITATIONS 14 READS 439 2 author s: Some of the authors of this publication are also working on these related projects: Data science in solar engineering View project Renewable integration View project Hao Quan Nanjing University of Science and Technology 27 PUBLICATIONS   1,235 CITATIONS    SEE PROFILE Dazhi Yang Harbin Institute of Technology 130 PUBLICATIONS   3,767 CITATIONS    SEE PROFILE All content following this page was uploaded by Dazhi Yang on 13 Mar ch 2020. The user has requested enhancement of the downloaded file. Probabilistic solar irradiance transposition models Hao Quan a, Dazhi Yang b,∗ aDepartment of Electrical Engineering, School of Automation, Nanjing University of Science and Technology, Nanjing, Jiangsu, China bSingapore Institute of Manufacturing Technology, Agency for Science, Technology and Research (A∗STAR), Singapore Abstract Transposition models convert the solar irradiance received on a horizontal surface to in-plane irradiance. All trans- position models to date, unfortunately, only produce deterministic (as oppose to probabilistic) estimates. In modern energy meteorology, having the entire predictive distribution is more amenable than relying only on deterministic estimates. To that end, this paper outlines two strategies for creating probabilistic transposition models (PTMs), that can quantify the various types of uncertainty involved in the modeling process. The ﬁrst strategy seeks the analytic expressions of data, parameter, and model uncertainty, and the ﬁnal predictive variance is the sum of these three types of uncertainty. On the other hand, the second strategy directly models the overall uncertainty as a whole, and uses ensemble model output statistics to estimate the predictive distribution through optimizing a loss function. Both strategies generate estimates of tilted irradiance with Gaussian predictive distribution. As compared to their determin- istic counterparts, PTMs clearly oﬀer more insights on uncertainty quantiﬁcation, during solar energy system design, simulation, performance evaluation, and power output forecasting. Highlights • Probabilistic solar irradiance transposition is demonstrated for the ﬁrst time. • Two novel approaches are proposed to perform probabilistic transposition. • Probabilistic transposition models generate predictive distributions and point estimates. • The theory is empirically veriﬁed with research-grade radiometry data. Keywords: Probabilistic transposition, Solar radiation modeling, Prediction interval, Predictive distribution Word count: 6565. 1. Introduction Solar resource assessment is a central topic in the emerging ﬁeld of solar energy meteorology, and is the foremost step in all solar energy system design, simulation, and performance evaluation [1]. In that, solar engineers study the availability and variability of solar resource, and how the various types of uncertainty in solar resource can aﬀect solar ∗Corresponding author. Tel.: +65 9159 0888. Email address: yangdazhi.nus@gmail.com (Dazhi Yang) Abbreviations: BFGS, Broyden–Fletcher–Goldfarb–Shanno; BHI, beam horizontal irradiance; BMS, Baseline Measurement System; BNI, beam normal irradiance; BTI, beam tilted irradiance; CRPS, continuous ranked probability score; DHI, diﬀuse horizontal irradiance; DTI, diﬀuse horizontal irradiance; ECDF, empirical cumulative distribution function; EMOS, ensemble model output statistics; GHI, global horizontal irra- diance; GTI, global tilted irradiance; IGN, ignorance score; nMAE, normalized mean abslute error; nMBE, normalized mean bias error; NREL, National Renewable Energy Laboratory; nRMSE, normalized root mean square error; OLS, ordinary least squares; PICP, prediction interval coverage probability; PIAW, prediction interval average width; PIT, probability integral transform; PTM, probabilistic transposition model; PV, photovoltaic; QC, quality control; and SRRL, Solar Radiation Research Laboratory; Preprint submitted to Renewable & Sustainable Energy Reviews March 13, 2020 energy production. A particularly important aspect of resource assessment is solar radiation modeling. For instance, clear-sky models describe the amount of radiation reaching the Earth’s surface under a cloud-free atmosphere [2, 3]; separation models split diﬀuse and direct radiation components from the global solar radiation [4, 5]; and satellite-to- irradiance models covert the visible or infrared images taken by instruments onboard geostationary satellites to spatial irradiance snapshots [6, 7]. In this paper, another important class of radiation models—transposition models—is discussed. Stated simply, transposition models enable projection of solar irradiance between planes of diﬀerent tilts. Since irradiance data are mostly measured or estimated for horizontal surfaces, e.g., using ground-based radiometers, in- struments onboard geostationary weather satellites, or numerical weather prediction models [8], one needs to convert such horizontal irradiance to in-plane irradiance. The reason is that the solar PV collectors are often installed on inclined surfaces—either to maximize the annual electricity production, or constrained by the inclinations of roofs. To that end, transposition modeling is ubiquitously involved in the aforementioned solar energy system applications. In 2016, Yang reviewed a total of 26 transposition models using 18 datasets from worldwide locations [9], which is by far the most comprehensive and rigorous review on this topic. Hence, to save space, this paper does not reiterate the literature review, instead, the readers are referred to [9]. Uncertainty quantiﬁcation is becoming increasingly important in energy meteorology [10]. From the long-term (e.g., annual) solar resource variability studies to the short-term (e.g., several seconds to a few days) solar power forecasting, load ﬂow or power trading, probabilistic representations of the quantities of interest have been shown to carry more value than their deterministic counterparts [11–14]. In contrary, there is only a handful of works that explicitly discusses the various types of uncertainty involved in transposition modeling. Furthermore, almost all studies of this kind do not go beyond a few overall measures of uncertainty, such as the expanded uncertainty at the 95% conﬁdence level (or more widely known as U95 in the solar community). To that end, this paper proposes two strategies for generating predictive distributions, predictive intervals, or equivalently, predictive quantiles, using transposition models. Formally, this class of transposition models should be referred to as probabilistic transposition models (PTMs). PTM is a new and novel concept, and it aligns well with other probabilistic modeling approaches used in solar energy meteorology, bringing new insights and opportunities to the ﬁeld of solar irradiance and power modeling. 1.1. Terminology and the optimal transposition equation Before anything else is discussed, the terminology is ﬁrst introduced. Solar engineers are interested in three types of irradiance, namely, global, diﬀuse, and beam (or direct) irradiance. On a horizontal surface, these irradiance components are known as global horizontal irradiance (GHI, denoted as Gh), diﬀuse horizontal irradiance (DHI, denoted as Dh), and beam horizontal irradiance (BHI, denoted as Bh), respectively. On an inclined surface, the irradiance components are analogously named as global titled irradiance (GTI, denoted as Gc), diﬀuse tilted irradiance (DTI, denoted as Dc), and beam tilted irradiance (BTI, denoted as Bc), where the subscript c comes from the word “collector”—this choice of subscript comes from the seminal papers of Perez et al. [15–18]. Aside from the above, a quantity called the beam normal irradiance (BNI, denoted as Bn) is also of interest, which is the beam irradiance received on a plane normal to the sun-ray. Lastly, inclined surfaces receive an irradiance component due to ground reﬂection, denoted as Dg. This completes the terminology on irradiance used in transposition modeling. It should be noted that, due to historical reasons, the word “direct” has now become the more popular choice when it comes to describing the beam irradiance. Nonetheless, since both “direct” and “diﬀuse” have the initial letter “d,” to make the abbreviations less ambiguous, and to avoid notation clash, BHI, BTI, and BNI are used throughout. Mathematically, transposition models are functions that map h = {Gh, Bh, Dh} to c = {Gc, Bc, Dg, Dc}, i.e., c = f (h). The inverse functions, i.e., h = f −1(c), are known as inverse transposition models. In this paper, only f (·) is discussed, and the reader is referred to [19–23] for discussions on the various options of f −1(·). The general form of 2 f (·) is: Gc = Bc + Dg + Dc, (1) Bc = Bn cos θ = Bh cos θ cos z , (2) Dg = ρGhRr = ρGh 1 − cos s 2 , (3) Dc = DhRd, (4) where θ is the incidence angle, z is the zenith angle, s is the tilt angle of the inclined surface, ρ is the foreground’s albedo, and Rd is known as the diﬀuse transposition factor, whereas Rr is known as the transposition factor for ground reﬂection. The above Rr formulation assumes isotropy. Although such a formulation is highly ideal, as noted by Gueymard [24], “in the vast majority of transposition calculations, the reﬂection process is assumed Lambertian, the foreground is assumed inﬁnite, and no shading is assumed to aﬀect the components of GHI incident on the reﬂective surface.” The closure equation suggests that Gh in Eq. (3) can be expressed as the sum of DHI and BHI, that is, Gh = Bh + Dh = Bn cos z + Dh. (5) Hence, combining Eqs. (1)–(5) yields Gc = Bn cos θ + ρ(Bn cos z + Dh) 1 − cos s 2 + DhRd. (6) Clearly, Bn and Dh measurements are required to predict Gc. The best practice to obtain Bn and Dh data is through direct measurements using a thermopile pyrheliometer and a thermopile pyranometer (with a tracking shade), instead of deriving one or both of them using Gh measurements [25]. In fact, it is shown by Gueymard [26] that the best way to obtain Gh data is by combining high-quality Bn and Dh measurements through the closure equation. In this regard, Eq. (6) is considered to be the optimal transposition equation, and will be used throughout the paper. 1.2. Uncertainty quantiﬁcation for nonparametric transposition models There are tens of transposition models proposed in the literature, and all of them diﬀer only in terms of Rd for- mulation [9]. Furthermore, many older models seek nonparametric representations of the transposition process. For instance, the isotropic model is given by R Iso d = 1 + cos s 2 , (7) where isotropic diﬀuse radiance is assumed over the hemispherical sky. The reader is referred to [27] for the most updated perspectives on the origin, derivation, meaning, and signiﬁcance of the isotropic sky model. This model is only a function of s. If ρ, z, and θ are assumed to be known values with negligible uncertainty, the variance of the prediction can be derived from the basic properties of variance. That is V ( ˆGc) =V {Bn cos θ + ρ(Bn cos z + Dh) 1 − cos s 2 + DhR Iso d + ϵ} =V {Bn [cos θ + ρ cos z(1 − cos s) 2 ] + Dh [ 1 + cos s 2 + ρ(1 − cos s) 2 ] + ϵ} = [ cos θ + ρ cos z(1 − cos s) 2 ]2 V(Bn) + [ 1 + cos s 2 + ρ(1 − cos s) 2 ]2 V(Dh) + V(ϵ), (8) where V denotes the variance operator, ϵ ∼ N(0, σ 2) is the normally distributed modeling error, V(Bn) and V(Dh) can be inferred from the measurement uncertainty of BNI and DHI, respectively. Eq. (8) assumes the BNI and DHI measurement errors and ϵ are pairwise independent, which is perfectly reasonable by construct. 3 When a transposition model is nonparametric, i.e., the model does not contain any empirically ﬁtted parame- ter, only two types of uncertainty are involved, namely, measurement (or data) uncertainty and model uncertainty. Whereas the former addresses the fact that no radiation measurement is perfectly accurate, the latter describes the model inadequacy originated from incomplete or surrogate representation of the true physical process. Hence, as far as the nonparametric transposition models are concerned, the variance of the predicted Gc can be derived using principles of error propagation, despite some ﬁnal expressions of uncertainty might be tedious to obtain. Besides the isotropic model, other nonparametric models include [28–38]—this list is probably exhaustive. The reader is referred to [9] for a review on these models. 1.3. Uncertainty quantiﬁcation for parametric transposition models As evidenced by the results of Yang [9], the performance of the above-mentioned nonparametric models is almost always limited. On one hand, this motivates research into better physical representations of the transposition process. On the other hand, it suggests that the atmospheric scattering and absorption processes are intricate, and parametric transposition models can be useful. Similar to the case of nonparametric models, many parametric transposition models have been proposed in the literature [e.g., 39–42]. Among these parametric models, the various versions of the Perez model [15–18] have the best overall performance, and are commonly recognized as the quasi-universal ones [9].Parametric transposition models are generally more complex than the nonparametric ones. For instance, the Gueymard model has 34 empirical parameters, and the Perez model has 48. As a result, the error propagation in parametric models, from measurements to the ﬁnal prediction, can be extremely diﬃcult to derive. Moreover, the parameters in these models are ﬁtted using experimental data, e.g., using least squares methods. This procedure introduces a third type of uncertainty, namely, parameter uncertainty, into the transposition models. Hence, to arrive at a probabilistic representation of the predicted Gc using parametric models, the uncertainty quantiﬁcation strategy is clearly challenging. 1.4. Contribution of this paper Two strategies are proposed to quantify the uncertainty involved in transposition modeling. The ﬁrst strategy explicitly derives the analytic expressions of the aforementioned three types of uncertainty. This requires converting a transposition model to a linear regression. Since the variance expression of a linear regression prediction is known, it can be used to represent the parameter uncertainty, and to a certain extent, data and model uncertainty. In principle, all parametric transposition models with empirically ﬁtted parameters are suitable for this strategy—least squares method is ubiquitously used by solar engineers during model ﬁtting. Without loss of generality, the 1990 version of the Perez model [18], which is by far the most popular choice in the solar community, is used to exemplify this strategy. The second strategy adopts an ensemble approach. Instead of considering the uncertainty quantiﬁcation for indi- vidual models, predictions from several transposition models are treated as ensemble members, to form an empirical cumulative distribution function (ECDF) that can be used as the predictive distribution. This strategy is analogous to the analog ensemble technique used in renewable energy forecasting, where past observations corresponding to the m-best weather analogs jointly form the predictive distribution [43, 44]. One particular issue with the second strategy is that the predictive distribution generated by the diﬀerent transposition models could be under- or over-dispersive [44]. Therefore, an ensemble model output statistics (EMOS) approach [45] is used to calibrate the predictions. Re- cently, the EMOS approach has been applied to the site-adaptation problem—a procedure to bias-correct the outputs from satellite-to-irradiance models—it has shown exceptional performance [46]. These two strategies are empirically veriﬁed against data from a research-grade measurement center under the National Renewable Energy Laboratory (NREL). Various deterministic and probabilistic accuracy measures are used to test whether or not the PTMs are producing satisfactory results. It is found that the point prediction performance of PTMs does not deteriorate from their deterministic counterparts, i.e., the bias, absolute, and squared errors do not change. Moreover, the prediction intervals generated by PTMs demonstrate suﬃcient coverage (calibration) and appropriate spread (sharpness), which is amenable for subsequent solar engineering applications. 4 2. Methodology In this section, two strategies for constructing PTMs are outlined. In Section 2.1, the direct construction strategy is exempliﬁed using the Perez model. To distinguish the probabilistic Perez model proposed in this paper from the original deterministic Perez model, the former is referred to as the Perez PTM hereafter, whereas the latter is simply called the Perez model as per usual. In Section 2.2, the indirect construction strategy is exempliﬁed using an ensemble of 26 transposition models. In ensemble modeling, these individual models are also known as component models. Since the predictions made by these 26 component transposition models can be treated as quantiles, and thus form an empirical predictive distri- bution, the corresponding PTM is called the raw ensemble PTM. After the EMOS technique is applied to the raw ensemble, the resulting PTM is called the EMOS-corrected ensemble PTM. 2.1. Probabilistic transposition through the Perez model 2.1.1. The Perez model Among the various versions of the Perez model, the 1990 version is the most widely accepted one [9]. It describes the hemispherical sky dome with a three-part geometrical framework, consisting of the isotropic background, a point source representing the circumsolar disc, and a horizon band [18]. The RPerez d is given by R Perez d = (1 − F1) 1 + cos s 2 + F1 a b + F2 sin s, (9) where a = max(0, cos θ), (10) b = max(0.087, cos z), (11) F1 = max{0, F11(ε) + ∆F12(ε) + zF13(ε)}, (12) F2 = F21(ε) + ∆F22(ε) + zF23(ε). (13) Model parameters F11(ε), F12(ε), F13(ε), F21(ε), F22(ε), F23(ε) take diﬀerent values for diﬀerent ε’s. Variable ε is the sky’s clearness: ε = 1 + Bn/Dh + 1.041z3 1 + 1.041z3 . (14) Variable ∆ is the sky’s brightness, which is given by ∆ = Dh E0n cos z , (15) where E0n is the extraterrestrial BNI, which is a function of the solar constant, Esc, i.e., E0n =Esc[1.00011 + 0.034221 cos(τ) + 0.00128 sin(τ) + 0.00719 cos(2τ) + 0.000077 sin(2τ)], (16) τ =2π day of year 365 . (17) The latest research reports a solar constant value of 1361.1 W/m2 [47]. Perez et al. divided the observed sky clearness into 8 bins [18]. Subsequently, a total of 6 × 8 = 48 parameters were ﬁtted using an extensive hourly dataset, as shown in Table 1. 5 Table 1: Perez model coeﬃcients for irradiance as a function of the sky’s clearness, reported in [18]. ε F11(ε) F12(ε) F13(ε) F21(ε) F22(ε) F23(ε) [1, 1.065) -0.008 0.588 -0.062 -0.060 0.072 -0.022 [1.065, 1.23) 0.130 0.683 -0.151 -0.019 0.066 -0.029 [1.23, 1.5) 0.330 0.487 -0.221 0.055 -0.064 -0.026 [1.5, 1.95) 0.568 0.187 -0.295 0.109 -0.152 -0.014 [1.95, 2.8) 0.873 -0.392 -0.362 0.226 -0.462 0.001 [2.8, 4.5) 1.133 -1.237 -0.412 0.288 -0.823 0.056 [4.5, 6.2) 1.060 -1.600 -0.359 0.264 -1.127 0.131 [6.2, +∞) 0.678 -0.327 -0.250 0.156 -1.377 0.251 2.1.2. Linear regression form of the Perez model The model parameters can be ﬁtted using 8 least squares regressions, one for each ε bin. For simplicity, the ε’s in the model parameters are dropped hereafter. Suppose there are n events in an ε bin—these events may come from diﬀerent locations and inclined surfaces—the optimal transposition equation under R Perez d , for the ith event, is thus Gc,i =Bn,i cos θi + ρ(Bn,i cos zi + Dh,i) 1 − cos si 2 + Dh,i 1 + cos si 2 + Dh,i ( ai bi − 1 + cos si 2 ) (F11 + ∆iF12 + ziF13) + Dh,i sin si(F21 + ∆iF22 + ziF23) + ei, (18) where i = 1, . . . , n, and ei ∼N(0, σ 2), (19) is a term that accounts for the homogenous modeling error. Eq. (18) can be equivalently written as yi = x⊤ i β + ei, (20) where yi =Gc,i − Bn,i [cos θi + ρi cos zi(1 − cos si) 2 ] − Dh,i [ 1 + cos si 2 + ρi(1 − cos si) 2 ] , (21) is the response for i = 1, . . . , n; β = (F11 F12 F13 F21 F22 F23)⊤ , ∈ R6×1, (22) are the regression coeﬃcients; and xi = (x(1) i x(2) i x(3) i x(4) i x(5) i x(6) i )⊤ , ∈ R6×1, (23) is the vector of predictors, with x(1) i = Dh,i [ai/bi − (1 + cos si)/2], x(2) i = ∆i x(1) i , x(3) i = zi x(1) i , x(4) i = Dh,i sin si, x(5) i = ∆i x(4) i , x(6) i = zi x(4) i . In matrix notation, these n equations become y = Xβ + e, (24) where y = (y1 y2 · · · yn)⊤ , ∈ Rn×1, (25) X =   x⊤ 1 x⊤ 2 ... x⊤ n   =   x(1) 1 x(2) 1 x(3) 1 x(4) 1 x(5) 1 x(6) 1 x(1) 2 x(2) 2 x(3) 2 x(4) 2 x(5) 2 x(6) 2 ... ... ... ... ... ... x(1) n x(2) n x(3) n x(4) n x(5) n x(6) n   , ∈ Rn×6 6 and e = (e1 e2 · · · en)⊤ , ∈ Rn×1. (26) The ordinary least squares (OLS) estimate of β is given by the formula ˆβ = (X⊤X)−1 X⊤ y. (27) 2.1.3. Making predictions When making prediction using a new set of predictor variables, x0, x0 = (x(1) 0 x(2) 0 x(3) 0 x(4) 0 x(5) 0 x(6) 0 )⊤ , ∈ R6×1, (28) the ﬁtted value at x0, denoted with y ∗ 0, has the following mean and variance (see Section 3.6 of [48]): E ( y∗ 0|x0) = x ⊤ 0 ˆβ, (29) V ( y∗ 0|x0) = σ 2 · x ⊤ 0 (X⊤X)−1 x0, (30) where an unbiased estimator of σ2 is given by ˆσ2 = 1 n − 6 n∑ i=1 ˆe 2 i , (31) which is the residual sum of squares evaluated at ˆβ. It is emphasized here that one should not mix up the ﬁtted value with the predicted value. In linear regression the uncertainty in the predicted value, denoted with ˆy0, comes from two sources: (1) the uncertainty introduced by the estimated β, i.e., parameter uncertainty, and (2) the uncertainty caused by model inadequacy, i.e., model uncertainty [48]. For this reason, the prediction interval, which is parameterized by the variance of the predicted value, is wider than the conﬁdence interval, which is parameterized by the variance of the ﬁtted value. Mathematically, the mean of the predicted value remains unchanged from that of the ﬁtted value, E (ˆy0|x0) = E (y ∗ 0|x0) + E(e0) = x ⊤ 0 ˆβ, (32) whereas V (ˆy0|x0) =V (y∗ 0|x0) + V(e0) = ˆσ 2 · x ⊤ 0 (X⊤ X)−1 x0 + ˆσ 2. (33) With the obtained expression for mean of ˆy0, the mean of ˆGc,0 can be derived. E ( ˆGc,0|x0) =E (ˆy0|x0) + [ cos θ0 + ρ0 cos z0(1 − cos s0) 2 ] E (Bn,0) + [ 1 + cos s0 2 + ρ0(1 − cos s0) 2 ] E (Dh,0) =x⊤ 0 ˆβ + [ cos θ0 + ρ0 cos z0(1 − cos s0) 2 ] B ∗ n,0 + [ 1 + cos s0 2 + ρ0(1 − cos s0) 2 ] D∗ h,0. (34) 7 In Eq. (34), B ∗ n,0 and D∗ n,0 are the measured BNI and DHI of the new event. Similarly, the variance of the predicted Gc,0 is V ( ˆGc,0|x0) =V (ˆy0|x0) + [ cos θ0 + ρ0 cos z0(1 − cos s0) 2 ]2 V (Bn,0) + [ 1 + cos s0 2 + ρ0(1 − cos s0) 2 ]2 V (Dh,0) = ˆσ 2 [ 1 + x ⊤ 0 (X⊤ X)−1 x0] + [ cos θ0 + ρ0 cos z0(1 − cos s0) 2 ]2 (0.0102B ∗ n,0)2 + [ 1 + cos s0 2 + ρ0(1 − cos s0) 2 ]2 (0.0255D∗ h,0)2 . (35) The variances of Bn,0 and Dh,0 in Eq. (35) are inferred from the typical values of expanded uncertainty of research- grade BNI and DHI measurements, namely, 2% for BNI and 5% for DHI, under a coverage factor of k = 1.96 [26].1 Eqs. (34) and (35) jointly parameterize the predictive distribution of Gc. It is important to note that the above parameter-ﬁtting procedure relies on a set of data, which preferably contains events coming from multiple locations and inclined surfaces. In addition, to perform probabilistic transposition at unseen locations, ˆσ 2 and (X⊤ X)−1 for each ε bin are required on top of F11, F12, F13, F21, F22, and F23. The set of pa- rameters listed in Table 1 were ﬁtted by Perez et al. [18] using hourly data from Albany (USA), Geneva (Switzerland), Los Angeles (USA), Albuquerque (USA), Phoenix (USA), Cape Canaveral (USA), Osage (USA), Trappes (France), and Carpentras (France). Unfortunately, the corresponding ˆσ 2 and (X⊤X)−1 values were not reported. Since it is now impossible to trace the original data used in [18], this paper reﬁts F11, F12, F13, F21, F22, and F23 using a more cur- rent, but less extensive, dataset. In this way, ˆσ2 and (X⊤ X)−1 can be obtained using the current dataset. Nonetheless, it is said that the Perez 1990 parameters have reached an asymptotic level of optimization [21]. Stated diﬀerently, those parameters are suﬃciently stable for the model to be used at unseen locations. Hence, it might be of interest to identify an extensive dataset to re-optimize the Perez PTM in the future. 2.2. Probabilistic transposition through ensemble 2.2.1. Ensemble model output statistics The second strategy for creating probabilistic transposition models uses a diﬀerent approach to generate predictive distribution. It takes the predicted Gc values from m transposition models, and forms an ensemble. Mathematically, one can use a regression to combine these component-model predictions. That is, ˆGens c = b1 ˆG(1) c + · · · + bm ˆG(m) c + ϵ, (36) where b1, . . . , bm are the mixing weights, and ϵ is a normally-distributed error term with zero mean. In general, it is unclear whether the prediction distributions formed this way are calibrated or not—the spread of the ensemble could be either under- or over-dispersive. Hence, considering a spread correction of the ensemble variance is useful, i.e., V(ϵ) = cS 2, (37) where c is a nonnegative correction coeﬃcient, and S 2 is the ensemble variance. Combining these two equations leads to the Gaussian predictive distribution ˆGens c ∼ N (b1 ˆG(1) c + · · · + bm ˆG(m) c , cS 2) . (38) 1Given expanded uncertainty U and coverage factor k, the standard uncertainty u is given by u = U/k, which is a percentage. Then, this percentage is multiplied by the measured value, to obtain the standard deviation. 8 This procedure belongs to a class of methods called ensemble model output statistics (EMOS), which was proposed in [45] to correct ensemble forecasts on sea-level pressure and surface temperature. The EMOS coeﬃcients (b1, . . . , bm, c) can be found by minimizing the continuous ranked probability score (CRPS) of the ensemble prediction. Gneiting et al. [45] showed that the CRPS of n training samples can be expressed as an analytic function of the coeﬃcients, namely, CRPS = 1 n n∑ i=1 (cS 2 i ) 1 2 {Zi [Φ(Zi) − 1] + 2ϕ(Zi) − 1 √ π } , (39) where Φ(·) and ϕ(·) are CDF and PDF of a standard normal distribution, respectively, and Zi is the standardized EMOS model error, i.e., Zi = G∗ c,i − (b1 ˆG(1) c,i + · · · + bm ˆG(m) c,i ) (cS 2 i ) 1 2 . (40) G∗ c,i is the ith measured GTI in the training data. The EMOS framework is general, and minimizing CRPS is but one option. For instance, one may consider minimizing the ignorance score, which is the negative logarithm of the predictive density. In the case of a normal predictive PDF with mean ∑m i=1 bi ˆG(i) c and variance cS 2, the average ignorance of n predictions is IGN = 1 2n n∑ i=1 [ ln(2π) + ln (cS 2 i ) + Z2 i ] , (41) where Zi is deﬁned in Eq. (40). Anyone who is familiar with statistical inference would immediately realize that Eq. (41) is the negative of the log likelihood of a normal distribution that is represented by a ﬁnite sample. In other words, minimizing IGN is equivalent to maximizing the likelihood, which is a major type of parameter estimation technique used in statistics. For this reason, this paper considers minimizing the average ignorance score. 2.2.2. Optimizing the EMOS coeﬃcients The optimization solver suggested by Gneiting et al. [45] is an oﬀ-the-shelf implementation of the Broyden– Fletcher–Goldfarb–Shanno (BFGS) algorithm, which does not guarantee convergence to the global minimum. Fur- thermore, it was reported that the solutions reached are sensitive to initial values. Nonetheless, in terms of forecast performance—the original paper is on ensemble weather forecasting—the local solution is shown to be more than suﬃcient. On one hand, such evidence indicates that the objective function has a bumpy surface. On the other hand, it suggests that the diﬀerence in the application results, between using the global minimum and local minimum, might not be signiﬁcant. Local optimization methods are fast, and can handle large-scale problems. Where there is value in ﬁnding a good solution, if not the very best, local optimization are widely used [49]. Although there are several known disadvantages of local optimization methods, counter measures, such as using multiple restarts and sets of initial values, are also available. That said, the experience learned from the past might not transfer to the current problem at hand. Convergence behavior is known, a priori, to depend on the experimental data. In this paper, the Rsolnp package in R is considered, which performs general nonlinear optimization [50] The optimization routine is based on the augmented Lagrange multiplier method of Ye [51]. The function gosolnp automatically generates random sets of initial values based on the upper and lower bounds on the optimization variables. Since the response variable of EMOS in Eq. (36) is in the same range as the input variables, the range −1 ≤ bi ≤ 1, ∀i ∈ 1, · · · , m appears to be a reasonable choice. Furthermore, an equality constraint, ∑m i=1 bi = 1, is included for better generalization. For coeﬃcient c, its nonnegativity leads to a lower bound of 0, whereas the upper bound is set to a conservative estimate of 5, i.e., the EMOS variance can be at most 5 times larger than the ensemble variance. 2.2.3. Component models As a general rule, the performance of an ensemble depends on its component models. Therefore, it is reasonable to opt for the highest-performance transposition models for the ensemble. Yang [9] reviewed a set of 26 transposition 9 models. It was found that the Perez family of models, namely, Perez1, Perez2, Perez3, and Perez4 according to the naming convention of [9], has clear advantage over the others. However, the Perez family of models employs the same prediction mechanism, namely, the three-part sky geometry. Such high collinearity will introduce diﬃculties during the optimization step, e.g., problem in inverting the Hessian matrix. It is thus useful to consider other models which use other prediction mechanisms, to diversify the ensemble. To ensure a suﬃciently diverse pool of component models, all 26 transposition models as appeared in [9] are used. The reader is referred to that paper for the detailed formulations of those models. 3. Data The empirical part of this work considers a research-grade dataset from NREL, Solar Radiation Research Labo- ratory (SRRL), Baseline Measurement System (BMS). SRRL has close to 40 years of history in performing surface radiometry [52]. The instruments at BMS go under regular calibration and maintenance. The data are publicly avail- able and can be accessed from https://midcdmz.nrel.gov/. The training dataset consists of hourly averaged GHI, DHI, BNI, GTI (on ﬁve diﬀerent tilts, namely, 40◦S, 90◦N, 90◦E, 90◦S, 90◦W) records from 2016 January 1 to 2017 November 30, whereas the testing dataset spans a period from 2017 December 1 to 2019 August 31. Despite the high quality of BMS data, quality control (QC) is still deemed beneﬁcial. Since the data of interest is hourly, three basic QC steps are considered, namely, 1. z < 85◦; 2. Gh > 0, Dh > 0, Bn > 0, and Gc > 0; 3. |(Bn cos z + Dh − Gh)/Gh| < 5%. The zenith angle ﬁlter removes irradiance at low-sun conditions in early mornings and late afternoons. These time instants are of marginal importance to solar applications. The second ﬁlter removes all negative irradiance values, which are considered to be physically impossible at the hourly timescale. The third ﬁlter removes the irradiance components that do not suﬃciently comply (with a 5% tolerance) to the closure equation. 4. Result and discussion 4.1. Evaluation metrics To verify the PTMs, both their deterministic and probabilistic predictive accuracies need to be evaluated. A total of seven accuracy measures are considered: three for deterministic prediction and four for probabilistic prediction. The normalized mean bias error (nMBE), normalized mean absolute error (nMAE) and normalized root mean square error (nRMSE) are given as nMBE = 1 n ∑n t=1 pt − ot 1 n ∑n t=1 ot × 100, (42) nMAE = 1 n ∑n t=1 |pt − ot| 1 n ∑n t=1 ot × 100, (43) nRMSE = √ 1 n ∑n t=1(pt − ot)2 1 n ∑n t=1 ot × 100, (44) respectively, where ot and pt are the observation–prediction pair at time t (or the tth data point in the testing dataset). All three metrics are in percent. For prediction interval evaluation, the prediction interval coverage probability (PICP) is considered, that is PICP = 1 n n∑ t=1 δt × 100, (45) 10 where δt is 1 if ot ∈ [Ut, Lt], i.e., the observation at time t falls inside the lower and upper bounds of the prediction interval; δt is 0, if ot < [Ut, Lt]. The (1 − α) × 100% conﬁdence interval for pt is [Ut, Lt] =E(pt) ± tα/2,N √ V(pt), (46) where the expectation and variance are computed based on Eqs. (34) and (35). In this paper, PICP is evaluated at a nominal coverage of 95%, i.e., t0.025,N = 1.96, for N > 500. PICP is a measure of calibration, i.e., whether the prediction actually falls inside the interval. A good PICP should be close to its nominal coverage. On the other hand, the sharpness of the prediction intervals can be assess through the prediction interval average width (PIAW), PIAW = 1 n n∑ t=1 (Ut − Lt). (47) PIAW is also evaluated at a nominal coverage of 95%. It is noted that the reason for not using the somewhat more popular normalized version of PIAW, namely, prediction interval normalized average width (PINAW), is because sharpness is a property of predictions only, as noted by Gneiting and Raftery [53]. In this regards, PINAW, which uses the range of observations for normalization, is an inappropriate metric, and thus must be avoided in all probabilistic veriﬁcation. Whereas PICP and PIAW assess calibration and sharpness, separately, to evaluate the entire predictive distribution, CRPS is used. CRPS = 1 n n∑ t=1 ∫ ∞ 0 [F pt (w) − 1(w − ot) ]2 dw, (48) where F pt is the distribution function of pt and 1(w − ot) is the Heaviside step function shifted to the observation ot. Note that Eq. (48) gives the average CRPS of n predictions. CPRS has a unit of W/m2. CRPS is a proper scoring rule, and provides composite measures of the predictive performance that address calibration and sharpness, simultaneously [53]. Lastly, the predicted quantiles are evaluated through the pinball loss, Lt,τ (pt,τ, ot) =    (1 − τ) (pt,τ − ot) , if pt,τ ≥ ot; τ ( ot − pt,τ) , otherwise, (49) where pt,τ is the prediction for the τ th quantile. With n veriﬁcation samples, the average pinball loss is given by: Pinball = 1 n × card(Q) n∑ t=1 ∑ τ∈Q Lt,τ (pt,τ, ot) , (50) where Q is the set of quantiles, taken to be Q = {0.005, 0.05, 0.1, · · · , 0.9, 0.95, 0.995}, (51) in this paper, and card(Q) denotes the cardinality of the set Q. In this case, card(Q) = 21. 4.2. Performance evaluation Based on the method described in Section 2.1, the model coeﬃcients of the Perez PTM are ﬁtted using the NREL BMS data. These new coeﬃcients are shown in Table 2. It is noted that these coeﬃcients have a similar magnitude, indicating appropriate model stability—if some coeﬃcients are much larger than the others, it may suggest potential overﬁtting, and thus may destablize model performance during out-of-sample testing. On the other hand, the aforementioned 26 transposition models are used to generate the component predictions. Subsequently, the EMOS procedure described in Section 2.2 is used to optimize the mixing weights, and thus generates predictive distributions. It should be noted that besides the parametric predictive distribution, i.e., Eq. (38), one can also create empirical distributions using the raw component predictions without any post-processing. Hence, probabilistic transposition results using both the raw ensemble PTM and the EMOS-corrected ensemble PTM are of interest, so that the relative improvement of EMOS, as a post-processing technique, can be quantiﬁed. 11 Table 2: Perez model coeﬃcients ﬁtted using NREL data. ε F11(ε) F12(ε) F13(ε) F21(ε) F22(ε) F23(ε) [1, 1.065) 0.007 0.446 -0.060 -0.073 0.105 -0.029 [1.065, 1.23) 0.236 0.468 -0.181 -0.014 0.095 -0.041 [1.23, 1.5) 0.391 0.392 -0.253 0.025 0.035 -0.033 [1.5, 1.95) 0.656 -0.072 -0.320 0.104 -0.085 -0.042 [1.95, 2.8) 0.843 -0.679 -0.326 0.166 -0.384 0.016 [2.8, 4.5) 0.868 -1.193 -0.296 0.229 -0.916 0.101 [4.5, 6.2) 0.846 -1.644 -0.326 0.082 -0.735 0.258 [6.2, +∞) 0.403 1.734 -0.407 -0.048 -0.449 0.402 Table 3: Performance evaluation of three probabilistic transposition models. Hourly veriﬁcation data are from ﬁve tilted surfaces, at Golden, Colorado (39.742◦N, 105.18◦W), over a period from December 1, 2017 to August 31, 2019. The mean observed Gc value, Gc, is used to perform the normalization for mean bias error (MBE), mean absolute error (MAE), and root mean square error (RMSE). Prediction interval coverage probability (PICP) and prediction interval average width (PIAW), which assess calibration and sharpness, respectively, are calculated for a nominal coverage of 95%. Continuous ranked probability score (CRPS) and pinball loss are used to assess the predictive distribution and predictive quantiles, respectively. Tilt Gc [W/m2] nMBE [%] nMAE [%] nRMSE [%] PICP [%] PIAW [W/m2] CRPS [W/m2] Pinball [W/m2] Probabilistic transposition using the Perez model 40◦S 518.27 -1.39 2.43 3.45 97.27 79.44 9.34 4.46 90◦N 120.02 0.63 8.19 11.77 98.36 73.65 7.64 3.65 90◦E 276.62 0.75 5.00 7.06 93.84 74.61 10.32 4.92 90◦S 341.56 1.76 4.47 6.15 93.17 75.02 11.20 5.34 90◦W 228.23 2.67 5.69 8.00 95.96 74.22 9.73 4.64 Overall 296.94 0.88 5.16 7.29 95.72 75.39 9.65 4.60 Probabilistic transposition using raw ensemble 40◦S 518.27 -1.36 2.73 3.83 85.50 72.83 10.70 5.14 90◦N 120.02 0.83 14.48 18.77 80.22 89.10 12.03 5.78 90◦E 276.62 1.59 6.13 7.94 87.55 96.39 12.60 6.02 90◦S 341.56 2.64 5.02 6.61 86.71 79.27 12.43 5.97 90◦W 228.23 2.85 7.95 10.01 86.21 98.33 12.69 6.06 Overall 296.94 1.31 7.26 9.43 85.24 87.18 12.09 5.79 Probabilistic transposition using ensemble with EMOS 40◦S 518.27 0.34 2.02 3.03 94.19 71.52 8.10 3.87 90◦N 120.02 2.38 8.16 11.79 94.73 59.78 7.29 3.48 90◦E 276.62 0.33 4.61 6.49 93.77 78.19 9.51 4.54 90◦S 341.56 0.52 3.58 5.20 93.23 68.64 9.08 4.33 90◦W 228.23 0.99 5.15 7.18 93.53 69.35 8.77 4.18 Overall 296.94 0.91 4.71 6.74 93.89 69.49 8.55 4.08 4.2.1. Performance of the deterministic predictions Table 3 depicts the errors of three PTMs using the test dataset. Firstly, it is evident that the performance of deterministic prediction agrees well with the literature. That is, the nMBEs are small, indicating that the Gc estimates are unbiased. Furthermore, the RMSEs are below 10%, except for the North-facing surface, and are found slightly lower than those reported in [9]. This is expected, since the model parameters are ﬁtted using local data. Among the ﬁve tilted surfaces, the South-facing 40 ◦ surface has the smallest nRMSE, which is about half of that from the South-facing 90 ◦ surface. Given the fact that most ﬁxed-tilt PV systems are built with a tilt close to the site’s latitude, facing the Equator [54, 55], for mid-latitude regions where solar resource is rich, PTM is likely to deliver a decent performance. It is also interesting to observe that the predictions made by the raw ensemble PTM, at the North-facing surface, are far worse than those made using the Perez PTM and the EMOS-corrected ensemble PTM. This suggests that some transposition models issue poor ensemble members, which then shift the mean of the predictive distribution in an undesired fashion and lower the performance of the ensemble prediction. In this regard, EMOS is clearly justiﬁed, since it allows mean averaging and variance scaling. Recall that the Perez PTM requires parameter ﬁtting, as shown in Table 2. This introduces some limitations on its applicability, since one should not expect good-quality local data on diﬀerent tilts to be available on-site. When 12 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● 40S 90N 90E 90S 90WPerezRaw ensembleEMOS Aug/01 Aug/02 Aug/03 Aug/01 Aug/02 Aug/03 Aug/01 Aug/02 Aug/03 Aug/01 Aug/02 Aug/03 Aug/01 Aug/02 Aug/03 250 500 750 1000 250 500 750 1000 250 500 750 1000 TimeGc [W/m2] Figure 1: 95% prediction intervals from the three probabilistic transposition models, over a period of three days in 2019 August. Perez proposed the 1990 version of his model [18], a comprehensive collection of hourly data were used to ﬁt the parameters, which in turn led to the asymptotic level of optimization that is still being used today. To that end, the best way to ensure the universality of the Perez PTM is to use the original data, and record the matrix (X⊤ X)−1 and constant σ2, see Section 2.1.3, so that the Perez PTM can be used without training. However, after we contacted Richard Perez in mid 2019, we were told that all of the original data were unfortunately lost during a major computer crash that took place in 1993 [56]. Clearly, gathering the same data would not be possible, and some new initiative on data pooling is thought to be beneﬁcial for the worldwide uptake of the Perez PTM. This will be considered in a future work. 4.2.2. Performance of the probabilistic predictions In terms of the quality of prediction intervals, both the Perez PTM and the EMOS-corrected ensemble PTM show PICPs close to the nominal coverage of 95%, indicating well-calibrated predictions. On the other hand, the PICPs of the raw ensemble PTM are far from the nominal coverage, suggesting that without EMOS, the performance of ensemble transposition could be limited. The EMOS-corrected ensemble PTM has the lowest PIAW, i.e., its prediction intervals are the sharpest. Since the goal of probabilistic prediction is to maximize the sharpness of the predictive distributions subject to calibration [53], the EMOS-corrected ensemble PTM is clearly the best option here. This is also reﬂected by CRPS and pinball loss, where the EMOS-corrected ensemble PTM performs better than the Perez PTM, with an overall CRPS of 8.55 W/m2 and an overall pinball loss of 4.08 W/m2. These results are impressive as compared to the CRPS or pinball loss from solar power forecasting models, which are typically one order of magnitude higher. To visualize the predictive distributions, the 95% prediction intervals of all three PTMs are plotted, over a period of three days in 2019 August, in Fig. 1. It can be seen that the prediction intervals in all cases are quite narrow—in contrast to the wide intervals usually observed during irradiance forecasting, cf. Fig. 6 in [44]. That said, the raw ensemble PTM does seem to have the widest prediction intervals among the three PTMs. Hence, in this particular case, the raw ensemble predictions are over-dispersed, and EMOS is able to correct that by shrinking the spread of the ensemble variance, i.e., with c < 1 in Eq. (37). To further understand the probabilistic prediction, probability integral transform (PIT) histograms of predictions from the three PTMs are plotted in Fig. 2. PIT histogram is a graphical tool originally proposed in meteorology for assessing the calibration of probabilistic forecasts. PIT is the value of the predictive distribution at the materialized ot, 13 40S 90N 90E 90S 90WPerezRaw ensembleEMOS 0 0.25 0.5 0.75 1 0 0.25 0.5 0.75 1 0 0.25 0.5 0.75 1 0 0.25 0.5 0.75 1 0 0.25 0.5 0.75 1 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 Probability integral transformRelative frequency Figure 2: Probability integral transform (PIT) histograms of predictions from the three probabilistic transposition models. PIT histograms corre- spond to the EMOS predictions are closest to uniform distributions, thus can be deemed as the best among three models, in terms of calibration. i.e., F pt (ot). Visually, perfectly calibrated probabilistic forecasts correspond to a PIT histogram that appear to follow a uniform distribution. It is clear that the EMOS-corrected ensemble PTMs have the best calibration, whereas the raw ensemble PTMs are not as calibrated, as evidenced by the L-shaped or U-shaped PIT histograms. Similarly, the Perez PTMs result in inverse-U-shaped PIT histograms, indicating prediction intervals that are too wide. 5. Conclusion Transposition modeling is ubiquitously involved in solar energy system design, simulation, output modeling, and forecasting. Traditionally, solar engineers have to rely on the deterministic transposition models, which evidently do not provide suﬃcient information on the various types of uncertainty associated to the modeling process. The merit of this paper goes to the two proposed strategies for creating probabilistic transposition models (PTMs). Unlike the traditional transposition models, which only provide point estimates, PTMs generate the entire predictive distribution, prediction interval, or equivalently, predictive quantiles. Such formal uncertainty quantiﬁcation could bring substan- tial methodological advance to solar system modeling. Moreover, such probabilistic representation of the modeling process aligns well with other energy meteorology applications such as probabilistic forecasting or probabilistic load ﬂow. In terms of accuracy, the two PTMs proposed in this paper, namely, the Perez PTM and the EMOS-corrected ensemble PTM, are both able to achieve a remarkable accuracy. As evidenced by Table 3, the root mean square errors of the Perez PTM and the EMOS-corrected ensemble PTM are clearly smaller than most, if not all, traditional transposition models in the literature. For more details on this, the reader could compare the current results with those numbers appeared in the review by Yang [9]. Probabilistically, the prediction intervals generated by the proposed PTMs are able to provide a suﬃcient coverage, which is a necessary condition for reliable uncertainty quantiﬁcation. The advantage of the Perez PTM lies in its consistency with the well-accepted, quasi-universal, deterministic Perez model. It provides a direct uncertainty quantiﬁcation to the transposed global tilted irradiance (GTI). Stated diﬀerently, the measurement, model, and parameter uncertainties are expressed in an analytical way. In general, if a comprehensive dataset representing various climate classes can be used to ﬁt the model parameter, the Perez PTM would gain universality. Nonetheless, such a dataset is missing from the current paper, but should be assembled in the future. For that reason, we welcome data contributions from the readers. The requirement would be to have at least 14 all three horizontal irradiance components, and GTI on a couple of tilts, over a few years. All data contributions will be acknowledged and thanked. On the other hand, the EMOS-corrected ensemble PTM is general. In that, there is no requirement on which component transposition model should enter the ensemble. As opposed to the Perez PTM, the EMOS-corrected ensemble PTM is indirect—the uncertainty is quantiﬁed via an optimization routine. As a rule-of-thumb in ensemble modeling, if a low performer could be identiﬁed, it is customary to remove that from the analysis. Nonetheless, it has been shown here that even with low-accuracy component transposition models, such as the nonparametric ones mentioned in Section 1.2, the performance of the EMOS-corrected ensemble PTM still has slight advantages over the Perez PTM. This is again analogous to ensemble forecasting, where the ensemble forecasts are often better than the best component forecasts [57]. Aside from performing transposition modeling, the proposed frameworks could be readily applied to other classes of radiation models, such as separation models, which could separate BNI and DHI from GHI [4]. Yang and Boland [5] showed that a large class of separation models can be written as linear regression problems after some variable transformation. Hence, the direct uncertainty quantiﬁcation approach, as used in Perez PTM, can be applied to all of those separation models. On the other hand, since there is a large pool of available separation models in the literature—140 of them were reviewed in [4]—EMOS can be used as a post-processing tool for ensemble separation modeling. Acknowledgment This work is partially supported by the National Natural Science Foundation of China (No. 51907090), and the Fundamental Research Funds for the Central Universities (No. 30919011292). The authors would like to thank J.Y. Li for proofreading the paper. References [1] D. Yang, C. A. Gueymard, Producing high-quality solar resource maps by integrating high- and low-accuracy measurements using Gaussian processes, Renewable and Sustainable Energy Reviews 113 (2019) 109260. doi:https://doi.org/10.1016/j.rser.2019.109260. URL http://www.sciencedirect.com/science/article/pii/S136403211930468X [2] X. Sun, J. M. Bright, C. A. Gueymard, B. Acord, P. Wang, N. A. Engerer, Worldwide performance assessment of 75 global clear-sky irradiance models using principal component analysis, Renewable and Sustainable Energy Reviews 111 (2019) 550 – 570. doi:https://doi.org/10.1016/j.rser.2019.04.006. URL http://www.sciencedirect.com/science/article/pii/S1364032119302187 [3] J. A. Ruiz-Arias, C. A. Gueymard, Worldwide inter-comparison of clear-sky solar radiation models: Consensus-based review of direct and global irradiance components simulated at the earth surface, Solar Energy 168 (2018) 10 – 29, advances in Solar Resource Assessment and Forecasting. doi:https://doi.org/10.1016/j.solener.2018.02.008. URL http://www.sciencedirect.com/science/article/pii/S0038092X18301257 [4] C. A. Gueymard, J. A. Ruiz-Arias, Extensive worldwide validation and climate sensitivity analysis of direct irradiance predictions from 1-min global irradiance, Solar Energy 128 (2016) 1 – 30. doi:https://doi.org/10.1016/j.solener.2015.10.010. URL http://www.sciencedirect.com/science/article/pii/S0038092X15005435 [5] D. Yang, J. Boland, Satellite-augmented diﬀuse solar radiation separation models, Journal of Renewable and Sustainable Energy 11 (2) (2019) 023705. doi:https://doi.org/10.1063/1.5087463. [6] Z. Qu, A. Oumbe, P. Blanc, B. Espinar, G. Gesell, B. Gschwind, L. Klüser, M. Lefèvre, L. Saboret, M. Schroedter-Homscheidt, L. Wald, Fast radiative transfer parameterisation for assessing the surface solar irradiance: The Heliosat-4 method, Meteorologische Zeitschrift 26 (1) (2017) 33 – 57. doi:https://doi.org/10.1127/metz/2016/0781. [7] M. Sengupta, Y. Xie, A. Lopez, A. Habte, G. Maclaurin, J. Shelby, The National Solar Radiation Data Base (NSRDB), Renewable and Sustainable Energy Reviews 89 (2018) 51 – 60. doi:https://doi.org/10.1016/j.rser.2018.03.003. URL http://www.sciencedirect.com/science/article/pii/S136403211830087X [8] D. Yang, R. Perez, Can we gauge forecasts using satellite-derived solar irradiance?, Journal of Renewable and Sustainable Energy 11 (2) (2019) 023704. doi:https://doi.org/10.1063/1.5087588. [9] D. Yang, Solar radiation on inclined surfaces: Corrections and benchmarks, Solar Energy 136 (2016) 288 – 302. doi:https://doi.org/10.1016/j.solener.2016.06.062. URL http://www.sciencedirect.com/science/article/pii/S0038092X16302432 [10] H. Quan, A. Khosravi, D. Yang, D. Srinivasan, A survey of computational intelligence techniques for wind power uncertainty quantiﬁcation in smart grids, IEEE Transactions on Neural Networks and Learning Systems (2019) 1 – 18doi:https://doi.org/10.1109/TNNLS.2019.2956195. [11] D. van der Meer, J. Widén, J. Munkhammar, Review on probabilistic forecasting of photovoltaic power production and electricity consump- tion, Renewable and Sustainable Energy Reviews 81 (2018) 1484 – 1512. doi:https://doi.org/10.1016/j.rser.2017.05.212. URL http://www.sciencedirect.com/science/article/pii/S1364032117308523 15 [12] D. Yang, A guideline to solar forecasting research practice: Reproducible, operational, probabilistic or physically-based, ensemble, and skill (ROPES), Journal of Renewable and Sustainable Energy 11 (2) (2019) 022701. doi:https://doi.org/10.1063/1.5087462. [13] D. L. Woodruﬀ, J. Deride, A. Staid, J.-P. Watson, G. Slevogt, C. Silva-Monroy, Constructing probabilistic scenarios for wide-area solar power generation, Solar Energy 160 (2018) 153 – 167. doi:https://doi.org/10.1016/j.solener.2017.11.067. URL http://www.sciencedirect.com/science/article/pii/S0038092X17310605 [14] H. Quan, D. Yang, A. M. Khambadkone, D. Srinivasan, A stochastic power ﬂow study to investigate the eﬀects of renewable energy in- tegration, in: 2018 IEEE Innovative Smart Grid Technologies - Asia (ISGT Asia), 2018, pp. 19 – 24. doi:https://doi.org/10.1109/ISGT- Asia.2018.8467977. [15] R. Perez, R. Stewart, C. Arbogast, R. Seals, J. Scott, An anisotropic hourly diﬀuse radiation model for sloping surfaces: Description, performance validation, site dependency evaluation, Solar Energy 36 (6) (1986) 481 – 497. doi:https://doi.org/10.1016/0038-092X(86)90013- 7. URL http://www.sciencedirect.com/science/article/pii/0038092X86900137 [16] R. Perez, R. Seals, P. Ineichen, R. Stewart, D. Menicucci, A new simpliﬁed version of the Perez diﬀuse irradiance model for tilted surfaces, Solar Energy 39 (3) (1987) 221 – 231. doi:https://doi.org/10.1016/S0038-092X(87)80031-2. URL http://www.sciencedirect.com/science/article/pii/S0038092X87800312 [17] R. Perez, R. Stewart, R. Seals, T. Guertin, The development and veriﬁcation of the perez diﬀuse radiation model, Tech. Rep. SAND88- 7030, Atmospheric Sciences Research Center, SUNY at Albany, Albany, NY (October 1988). [18] R. Perez, P. Ineichen, R. Seals, J. Michalsky, R. Stewart, Modeling daylight availability and irradiance components from direct and global irradiance, Solar Energy 44 (5) (1990) 271 – 289. doi:https://doi.org/10.1016/0038-092X(90)90055-H. URL http://www.sciencedirect.com/science/article/pii/0038092X9090055H [19] S. Halilovic, J. M. Bright, W. Herzberg, S. Killinger, An analytical approach for estimating the global horizontal from the global tilted irradiance, Solar Energy 188 (2019) 1042 – 1053. doi:https://doi.org/10.1016/j.solener.2019.06.027. URL http://www.sciencedirect.com/science/article/pii/S0038092X19306000 [20] B. Marion, A model for deriving the direct normal and diﬀuse horizontal irradiance from the global tilted irradiance, Solar Energy 122 (2015) 1037 – 1046. doi:https://doi.org/10.1016/j.solener.2015.10.024. URL http://www.sciencedirect.com/science/article/pii/S0038092X15005757 [21] D. Yang, Z. Ye, A. M. Nobre, H. Du, W. M. Walsh, L. I. Lim, T. Reindl, Bidirectional irradiance transposition based on the Perez model, Solar Energy 110 (2014) 768 – 780. doi:https://doi.org/10.1016/j.solener.2014.10.006. URL http://www.sciencedirect.com/science/article/pii/S0038092X14004927 [22] D. Yang, Z. Dong, A. Nobre, Y. S. Khoo, P. Jirutitijaroen, W. M. Walsh, Evaluation of transposition and decomposition mod- els for converting global solar irradiance from tilted surface to horizontal in tropical regions, Solar Energy 97 (2013) 369 – 387. doi:https://doi.org/10.1016/j.solener.2013.08.033. URL http://www.sciencedirect.com/science/article/pii/S0038092X13003435 [23] D. Faiman, A. Zemel, A. Zangvil, A method for monitoring insolation in remote regions, Solar Energy 38 (5) (1987) 327 – 333. doi:https://doi.org/10.1016/0038-092X(87)90004-1. URL http://www.sciencedirect.com/science/article/pii/0038092X87900041 [24] C. A. Gueymard, Cloud and albedo enhancement impacts on solar irradiance using high-frequency measurements from thermopile and photodiode radiometers. Part 2: Performance of separation and transposition models for global tilted irradiance, Solar Energy 153 (2017) 766 – 779. doi:https://doi.org/10.1016/j.solener.2017.04.068. URL http://www.sciencedirect.com/science/article/pii/S0038092X17303730 [25] F. Vignola, J. Michalsky, T. Stoﬀel, Solar and infrared radiation measurements, CRC press, 2012. [26] C. A. Gueymard, Direct and indirect uncertainties in the prediction of tilted irradiance for solar engineering applications, Solar Energy 83 (3) (2009) 432 – 444. doi:https://doi.org/10.1016/j.solener.2008.11.004. URL http://www.sciencedirect.com/science/article/pii/S0038092X08002983 [27] N. Kamphuis, C. Gueymard, M. Holtzapple, A. Duggleby, K. Annamalai, Perspectives on the origin, derivation, meaning, and signiﬁcance of the isotropic sky model, Solar Energy 201 (2020) 8 – 12. doi:https://doi.org/10.1016/j.solener.2020.02.067. URL http://www.sciencedirect.com/science/article/pii/S0038092X20301948 [28] J. Bugler, The determination of hourly insolation on an inclined plane using a diﬀuse irradiance model based on hourly measured global horizontal insolation, Solar Energy 19 (5) (1977) 477 – 491. doi:https://doi.org/10.1016/0038-092X(77)90103-7. URL http://www.sciencedirect.com/science/article/pii/0038092X77901037 [29] R. C. Temps, K. Coulson, Solar radiation incident upon slopes of diﬀerent orientations, Solar Energy 19 (2) (1977) 179 – 184. doi:https://doi.org/10.1016/0038-092X(77)90056-1. URL http://www.sciencedirect.com/science/article/pii/0038092X77900561 [30] T. Klucher, Evaluation of models to predict insolation on tilted surfaces, Solar Energy 23 (2) (1979) 111 – 114. doi:https://doi.org/10.1016/0038-092X(79)90110-5. URL http://www.sciencedirect.com/science/article/pii/0038092X79901105 [31] J. E. Hay, J. A. Davies, Calculation of the solar irradiance incident on an inclined surface, in: J. E. Hay, T. K. Won (Eds.), First Canadian Solar Radiation Data Workshop, Toronto, Ontario, Canada, 1980, pp. 59–72. [32] J. E. Hay, D. C. McKay, Estimating solar irradiance on inclined surfaces: A review and assessment of methodologies, International Journal of Solar Energy 3 (4-5) (1985) 203 – 240. doi:https://doi.org/10.1080/01425918508914395. [33] J. E. Hay, Calculating solar radiation for inclined surfaces: Practical approaches, Renewable Energy 3 (4) (1993) 373 – 380, solar radiation, environment and climate change. doi:https://doi.org/10.1016/0960-1481(93)90104-O. URL http://www.sciencedirect.com/science/article/pii/096014819390104O [34] P. S. Koronakis, On the choice of the angle of tilt for south facing solar collectors in the Athens basin area, Solar Energy 36 (3) (1986) 217 – 225. doi:https://doi.org/10.1016/0038-092X(86)90137-4. 16 URL http://www.sciencedirect.com/science/article/pii/0038092X86901374 [35] Y. Tian, R. Davies-Colley, P. Gong, B. Thorrold, Estimating solar radiation on slopes of arbitrary aspect, Agricultural and Forest Meteorology 109 (1) (2001) 67 – 74. doi:https://doi.org/10.1016/S0168-1923(01)00245-3. URL http://www.sciencedirect.com/science/article/pii/S0168192301002453 [36] A. Skartveit, J. A. Olseth, Modelling slope irradiance at high latitudes, Solar Energy 36 (4) (1986) 333 – 344. doi:https://doi.org/10.1016/0038-092X(86)90151-9. URL http://www.sciencedirect.com/science/article/pii/0038092X86901519 [37] D. Reindl, W. Beckman, J. Duﬃe, Evaluation of hourly tilted surface radiation models, Solar Energy 45 (1) (1990) 9 – 17. doi:https://doi.org/10.1016/0038-092X(90)90061-G. URL http://www.sciencedirect.com/science/article/pii/0038092X9090061G [38] V. Badescu, 3D isotropic approximation for solar diﬀuse irradiance on tilted surfaces, Renewable Energy 26 (2) (2002) 221 – 233. doi:https://doi.org/10.1016/S0960-1481(01)00123-9. URL http://www.sciencedirect.com/science/article/pii/S0960148101001239 [39] C. J. Willmott, On the climatic optimization of the tilt and azimuth of ﬂat-plate solar collectors, Solar Energy 28 (3) (1982) 205 – 216. doi:https://doi.org/10.1016/0038-092X(82)90159-1. URL http://www.sciencedirect.com/science/article/pii/0038092X82901591 [40] C. Gueymard, An anisotropic solar irradiance model for tilted surfaces and its comparison with selected engineering algorithms, Solar Energy 38 (5) (1987) 367 – 386. doi:https://doi.org/10.1016/0038-092X(87)90009-0. URL http://www.sciencedirect.com/science/article/pii/0038092X87900090 [41] T. Muneer, Solar radiation model for Europe, Building Services Engineering Research and Technology 11 (4) (1990) 153 – 163. doi:https://doi.org/10.1177/014362449001100405. [42] T. Muneer, C. Gueymard, H. Kambezidis, Hourly slope irradiation and illuminance, in: Solar Radiation and Daylight Models, Butterworth- Heinemann, Oxford, 2004, pp. 143 – 221. [43] D. Yang, S. Alessandrini, An ultra-fast way of searching weather analogs for renewable energy forecasting, Solar Energy 185 (2019) 255 – 261. doi:https://doi.org/10.1016/j.solener.2019.03.068. URL http://www.sciencedirect.com/science/article/pii/S0038092X19302944 [44] D. Yang, E. Wu, J. Kleissl, Operational solar forecasting for the real-time market, International Journal of Forecasting 35 (4) (2019) 1499 – 1519. doi:https://doi.org/10.1016/j.ijforecast.2019.03.009. URL http://www.sciencedirect.com/science/article/pii/S0169207019300755 [45] T. Gneiting, A. E. Raftery, A. H. Westveld, T. Goldman, Calibrated probabilistic forecasting using ensemble model output statistics and minimum CRPS estimation, Monthly Weather Review 133 (5) (2005) 1098 – 1118. doi:https://doi.org/10.1175/MWR2904.1. [46] D. Yang, Ensemble model output statistics as a probabilistic site-adaptation tool for satellite-derived and reanalysis solar irradiance, Journal of Renewable and Sustainable Energy 12 (1) (2020) 016102. doi:https://doi.org/10.1063/1.5134731. [47] C. A. Gueymard, A reevaluation of the solar constant based on a 42-year total solar irradiance time series and a reconcil- iation of spaceborne observations, Solar Energy 168 (2018) 2 – 9, advances in Solar Resource Assessment and Forecasting. doi:https://doi.org/10.1016/j.solener.2018.04.001. URL http://www.sciencedirect.com/science/article/pii/S0038092X18303463 [48] S. Weisberg, Applied Linear Regression, John Wiley & Sons, 2005. [49] S. Boyd, L. Vandenberghe, Convex optimization, Cambridge university press, 2004. [50] A. Ghalanos, S. Theussl, Rsolnp: General Non-linear Optimization Using Augmented Lagrange Multiplier Method, r package version 1.16. (2015). [51] Y. Ye, Interior algorithms for linear, quadratic, and linearly constrained non-linear programming, Ph.D. thesis, Department of ESS, Stanford University (1987). [52] A. Habte, M. Sengupta, A. Andreas, S. Wilcox, T. Stoﬀel, Intercomparison of 51 radiometers for determining global horizontal irradiance and direct normal irradiance measurements, Solar Energy 133 (2016) 372 – 393. doi:https://doi.org/10.1016/j.solener.2016.03.065. URL http://www.sciencedirect.com/science/article/pii/S0038092X16300184 [53] T. Gneiting, A. E. Raftery, Strictly proper scoring rules, prediction, and estimation, Journal of the American Statistical Association 102 (477) (2007) 359 – 378. doi:https://doi.org/10.1198/016214506000001437. [54] Y. S. Khoo, A. Nobre, R. Malhotra, D. Yang, R. Rüther, T. Reindl, A. G. Aberle, Optimal orientation and tilt angle for maximizing in-plane solar irradiation for pv applications in singapore, IEEE Journal of Photovoltaics 4 (2) (2014) 647 – 653. doi:https://doi.org/10.1109/JPHOTOV.2013.2292743. [55] D. Yang, Z. Dong, L. H. I. Lim, L. Liu, Analyzing big time series data in solar engineering using features and PCA, Solar Energy 153 (2017) 317 – 328. doi:https://doi.org/10.1016/j.solener.2017.05.072. URL http://www.sciencedirect.com/science/article/pii/S0038092X17304796 [56] R. Perez, personal communication (2019). [57] D. Yang, Z. Dong, Operational photovoltaics power forecasting using seasonal time series ensemble, Solar Energy 166 (2018) 529 – 541. doi:https://doi.org/10.1016/j.solener.2018.02.011. URL http://www.sciencedirect.com/science/article/pii/S0038092X18301282 17 View publication statsView publication stats","libVersion":"0.3.2","langs":""}