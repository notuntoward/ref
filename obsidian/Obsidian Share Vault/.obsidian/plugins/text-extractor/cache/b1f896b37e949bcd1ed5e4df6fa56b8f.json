{"path":"lit/lit_sources.backup/Hu23branchLrnUnkParamCnstrnts.pdf","text":"arXiv:2303.06698v1 [cs.LG] 12 Mar 2023 Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints evaluated using the true parameters. The challenge is, regret, the new error metric, is piecewise constant and non- differentiable [4], thus gradient-based methods do not apply. A number of prior works [5, 4, 6, 7, 8] propose methods to overcome the nondifferentiability of regret, and they can be roughly divided into approximation and exact methods. Approximation methods [6, 8] compute the (approximate) gradients of (approximations of) the regret function. They work not with the regret loss itself, but an approximation of it. While novel, they are not always reliable. On the other hand, exact methods [5, 4, 7] work directly with the regret to ﬁnd a good prediction model, even if the method cannot always ﬁnd the global-optimum model for the training data (e.g. if the method uses a local optimization method to ﬁnd the output model). To overcome the nondifferentiability of the regret, they exploit the structure of optimization problems to train models without computing gradients, and can be applied to dynamic programming solvable problems [4] and recursively solvable problems [7]. Despite the variety of approaches, most of the previous works [5, 4, 6, 7, 8] on Predict+Optimize handle problems with unknowns only in the objective. When constraints contain also unknown parameters, one major challenge is that the estimated solution may end up being infeasible under the true parameters—an issue inherent with uncertainty in constraints. The regret function designed for ﬁxed solution space is not applicable in this situation. Hu et al. [9] propose a more general loss function called post-hoc regret, in which an infeasible estimated solution is ﬁrst corrected into a feasible one (with respect to true parameters), and then the error of prediction is the sum of 1) the objective difference between the true optimal solution and the feasible solution, and 2) potential penalty incurred by correction. When unknown parameters only appear in the objective, the post-hoc regret degenerates into the regret. The post-hoc regret is also nondifferentiable, and Hu et al. further propose an approximation approach for packing and covering linear programs [9]. However, exact approaches considering the post-hoc regret remain uncovered. The contributions of this paper are threefold. First, we propose the ﬁrst exact approach for Predict+Optimize with unknown parameters in both the objective and constraints. The proposed method is extended from Branch & Learn [7] and handles recursively solvable problems with unknown constraints. Second, extensive experiments are conducted to investigate the performance of post-hoc regret. We experimentally compare the proposed method with the state-of- the-art approximation method [9] and investigate the performance of post-hoc regret on more general problems. Third, we empirically study different combinations of the two key components of post-hoc regret, i.e., the correction function and the penalty function to gain insights for deﬁning post-hoc regret in different scenarios. 2 Background Without loss of generality, we deﬁne an optimization problem (OP) P as ﬁnding: x ∗ = arg min x obj(x) s.t. C(x) where x ∈ Rd is a vector of decision variables, obj : Rd → R is a real-valued objective function in x which is to be minimized, and C is a set of constraints over x. We say x ∗ is an optimal solution and obj(x ∗) is the optimal value. A parameterized optimization problem (Para-OP) P (θ) is an extension of an OP P : x ∗(θ) = arg min x obj(x, θ) s.t. C(x, θ) where θ ∈ Rt is a vector of parameters. The objective obj(x, θ) and the constraints C(x, θ) all depend on θ. An OP is a degenerated case of a Para-OP when there are no unknowns. The true parameters θ ∈ Rt for a Para-OP are hidden at the time of solving in the Predict+Optimize (P+O) setting [5], and estimated parameters ˆθ are utilized in their places. Suppose each parameter is estimated by m features. The estima- tion will rely on a machine learning model trained over n observations of a training data set {(A 1, θ1), . . . , (A n, θn)} where A i ∈ Rt×m is a feature matrix for θi, in order to yield a prediction function f : Rt×m → Rt predicting parameters ˆθ = f (A). Solving the Para-OP under the estimated parameters, we can obtain an estimated solution x ∗(ˆθ). When constraints contain unknown parameters, a big challenge is that the feasible region is only approximated at solving time, and thus the estimated solution may be infeasible under the true parameters. Fortunately, some applications allow us to correct an infeasible solution into a feasible one, after the true parameters are revealed. Under these applications, Pre- dict+Optimize can use a novel error measurement, called Post-hoc Regret [9], to evaluate the quality of the estimated parameters ˆθ. The correction process can be formalized as a correction function, which takes an estimated solution x ∗(ˆθ) and true parameters θ and returns a corrected solution x ∗ corr(ˆθ, θ) that is feasible under θ. Although some sce- narios may allow for post-hoc correct of an estimated solution, some penalties may incur from such correction. A penalty function P en(x ∗(ˆθ) → x ∗ corr(ˆθ, θ)) takes an estimated solution x ∗(ˆθ) and the corrected solution x ∗ corr(ˆθ, θ) 2 Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints and returns a non-negative penalty. The choice of both the correction function and the penalty function are problem and application-speciﬁc. With respect to the corrected solution x ∗ corr(ˆθ, θ) and penalty function P en, we are now ready to deﬁne the Post-hoc Regret. The post-hoc regret contains two parts, one is the objective difference between the true optimal solution x ∗(θ) and the corrected solution x ∗ corr(ˆθ, θ) under the true parameters θ, another one is the penalty that changing from the estimated solution x ∗(ˆθ) to the corrected solution x ∗ corr(ˆθ, θ) will incur. The Post-hoc Regret P Reg(ˆθ, θ) can be formally deﬁned as: P Reg(ˆθ, θ) = obj(x ∗ corr(ˆθ, θ), θ) − obj(x ∗(θ), θ) + P en(x ∗(ˆθ) → x ∗ corr(ˆθ, θ)) (1) where obj(x ∗ corr(ˆθ, θ), θ) is the corrected optimal value and obj(x ∗(θ), θ) is the true optimal value. When only the objective contains unknown parameters, Post-hoc Regret degenerates into the Regret function [6], which compares the difference between the objective value of the true optimal solution x ∗(θ) and the estimated solution x ∗(ˆθ) under true parameters θ. The regret function can be deﬁned as: Reg(ˆθ, θ) = obj(x ∗(ˆθ), θ) − obj(x ∗(θ), θ), where obj(x ∗(ˆθ), θ) is the estimated optimal value. Following the empirical risk minimization principle, Hu et al. [9] choose the prediction function to be the function f from the set of models F attaining the smallest average post-hoc regret over the training data: f ∗ = arg min f ∈F 1 Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in ConstraintsBranch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints parameters appear in constraints, the form of the post-hoc regret function Li returned from Evaluate depends on the correction function and the penalty function, which are both problem and application speciﬁc. Under different scenarios, the post-hoc regret function may even be a piecewise nonlinear function, which leads to a technical obstacle: how to sum up two piecewise nonlinear functions and ﬁnd the minimum of the resulted function efﬁciently. We will discuss this obstacle in Section 4. While coordinate descent is a standard technique, a challenge of using this framework is how to construct Convert for an algorithm. B&L presents a standard template for recursive algorithms and shows how to cleanly adapt a recursive algorithm to Convert. We use their template to construct Convert here. Therefore, the proposed B&L-C framework has the same restrictions on the optimization problems as the B&L. 4 Case Studies 4.1 Maximum Flow with Unknown Edge Capacities We ﬁrst demonstrate, using the example of the maximum ﬂow problem (MFP), how our framework can solve problems solvable by a state-of-the-art approximation method (IntOpt-C) [9]. The problem aims to ﬁnd the largest possible ﬂow sent from a source s to a terminal t in a directed graph, under the constraints that the ﬂow sent on each edge cannot exceed the edge capacity. Using the template proposed in B&L [7], we adapt the Edmonds–Karp algorithm [11] to Convert, which recursively ﬁnds an unblocking path with remaining capacity and sends a ﬂow such that at least one edge along the path is saturated. The estimated solution x ∗(aiγ + bi) of MFP is the ﬂows sent through each path and therefore will change with the capacities of saturated edges. In each interval of Ei(γ) returned by Convert, the saturated edges remain the same, but the estimated solution will change when γ changes. When the edge capacities are unknown, we need to consider a case where the ﬂow computed with the estimated capacities might exceed the true capacities of some edges. We consider two possible correction functions: • Correction Function A: given an infeasible estimated solution x ∗, ﬁnd the largest λ ∈ [0, 1] such that λx ∗ satisﬁes the constraints under the true parameters. Note that Correction Function A is the same as the one used in IntOpt-C [9], which is designed for packing linear programs. By using the same correction function, we can investigate the performance difference between B&L-C and IntOpt-C. • Correction Function B: re-compute the blocking ﬂows of the chosen paths in the infeasible estimated solu- tion with the true capacities, and then augment the paths one by one with the re-computed blocking ﬂows. The ordering of path augmentation is important but computing the best order requires O(n!) time. We can adopt an approximate method: the paths are augmented according to the order of the path augmentation of the Edmonds-Karp algorithm. Using Correction Function B, augmenting the chosen paths by their blocking ﬂows one by one may lead to a situation that, since some edges are shared by several paths, they may be blocked before some paths are used. Thus the blocking ﬂows of some chosen paths in the estimated solution may be zero and these chosen paths are wasted. Therefore, we propose a penalty function: • Penalty Function I: whenever a chosen path in the estimated solution is wasted, deduct K units of ﬂow. Penalty Function I is not needed if Correction Function A is used, since the true capacities are all positive, λ will not be zero in this problem and no chosen paths in the estimated solution will be wasted. Using Correction Function A, the corrected solution x ∗ corr(aiγ + bi, θi) will not remain the same in each interval I ∈ I(Ci(γ)) either, where Ci(γ) is the piecewise rational linear function returned from Convert. Since the true optimal value obj(x ∗(θi), θi) is a constant value, the post-hoc regret function L(γ) returned from Evaluate is a piecewise rational linear function. This will lead to the technical obstacle mentioned in Section 3: how to sum up two piecewise rational linear functions and ﬁnd the minimum of the resulting piecewise rational linear function efﬁciently. In this work, we deal with this obstacle by using grid search. Using Correction Function B, the corrected solution x ∗ corr(aiγ+bi, θi) remains the same in each interval I ∈ I(Ci(γ)), where Ci(γ) is the piecewise constant function returned from Convert. Using Penalty Function I, P en(x ∗(aiγ + bi) → x ∗ corr(aiγ + bi, θi)) is also a piecewise constant function. Therefore, the post-hoc regret function L(γ) returned from Evaluate is a piecewise constant function, and we can easily sum up two piecewise constant functions and minimizes L(γ) in Lines 9 and 10 respectively in Algorithm 1. 5 Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints 4.2 0-1 Knapsack with Unknown Weights In the second example, we showcase our framework on a packing integer programming problem, the 0-1 knapsack problem, which can be handled by our framework straightforwardly but not by IntOpt-C. Given a set of items, each with a weight wi and a value vi, and a knapsack with a maximum capacity C. The aim is to maximize the total value of the selected items under the constraint that the total weight of the selected items is less than or equal to the maximum capacity. Using the template proposed in B&L [7], we adapt the branching algorithm for the 0-1 knapsack problem to Convert. The estimated solution x ∗(aiγ + bi) is a set of the selected items. In each interval of Ei(γ) returned by Convert, the set of the selected items, i.e., the estimated solution, remains the same. When the weights are unknown, we need to consider a case where the items are selected with the estimated weights, but the total true weights might exceed the capacity. We propose three correction functions here: • Correction Function A: remove the selected items in the estimated solution one by one in increasing order of the ratios of value/weight until the capacity is sufﬁcient. • Correction Function B: remove the selected items in the estimated solution one by one in decreasing order of the weights until the capacity is sufﬁcient. • Correction Function C: remove all the selected items in the estimated solution when it is infeasible. Removing selected items from the knapsack may incur some removal fees, which are formulated as the penalty func- tion here. We consider two possible penalty functions: • Penalty Function I: when the ith item is removed from the estimated solution, σivi units of value is deducted, where σ ≥ 0 is a non-negative tunable vector. • Penalty Function II: whenever a selected item in the estimated solution is removed, K units of value is deducted, where K is a constant. Since the solution set is discrete and ﬁnite, the estimated solution x ∗(aiγ + bi) remains the same in each interval I ∈ I(Ei(γ)), where Ei(γ) is the piecewise linear function returned from Convert. Using the above three correction functions, the corrected solution x ∗ corr(aiγ + bi, θi) remains the same in each interval I ∈ I(Ci(γ)), where Ci(γ) is the piecewise constant function returned from Convert. Using the above two penalty functions, P en(x ∗(aiγ + bi) → x ∗ corr(aiγ + bi, θi)) is also a piecewise constant function. Therefore, the post-hoc regret function L(γ) returned from Evaluate is a piecewise constant function, and we can easily sum up two piecewise constant functions and minimizes L(γ) in Lines 9 and 10 respectively in Algorithm 1. 4.3 Minimum Cost Vertex Cover with Unknown Costs and Edge Values Our last example is a variant of the minimum cost vertex cover (MCVC) problem, where we show how to apply our framework to an optimization problem that has unknown parameters in both the objective and the constraints. This problem is also not solvable by IntOpt-C. Given a graph G = (V, E), there is an associated cost c ∈ R|V | denoting the cost of picking each vertex, as well as edge values ℓ ∈ R|E|, one real value for each edge. Both the costs and edge values are unknown parameters. The goal is to pick a subset of vertices, minimizing the total cost, subject to the constraint that for all edges except the one with the smallest edge value, the edge needs to be covered, namely at least one of the two vertices on the edge needs to be picked. This problem is relevant in applications such as building public facilities. Consider, for example, the graph being a road network with edge values being trafﬁc ﬂow, and we wish to build speed cameras at intersections with minimum cost, while covering all the roads except the one with the least trafﬁc. Using the template proposed in B&L [7], we adapt the branching algorithm for the MCVC to Convert. The estimated solution x ∗(aiγ + bi) is a set of the picked vertices. In each interval of Ei(γ) returned by Convert, the set of the picked vertices, i.e., the estimated solution, remains the same. When the edge values are unknown, the estimated edge values might cause an edge to be wrongly removed. The selected vertices might not cover all the edges that need to be covered. Therefore, we propose one correction function: • Correction Function A: if there is an edge not covered by the selected vertices, add both of the edge end- points to the selection. Since the solution set is discrete and ﬁnite, the estimated solution x ∗(aiγ + bi) remains the same in each interval I ∈ I(Ei(γ)), where Ei(γ) is the piecewise linear function returned from Convert. Using Correction Function A, the corrected solution x ∗ corr(aiγ +bi, θi) remains the same in each interval I ∈ I(Ci(γ)), where Ci(γ) is the piecewise constant function returned from Convert. Since there is no penalty function in this example, P en(x ∗(aiγ + bi) → 6 Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints x ∗ corr(aiγ + bi, θi)) = 0 is a constant function. Therefore, the post-hoc regret function L(γ) returned from Evaluate is a piecewise constant function, and we can easily sum up two piecewise constant functions and minimizes L(γ) in Lines 9 and 10 respectively in Algorithm 1. 5 Experimental Evaluation In this section, we evaluate the proposed B&L-C framework and the post-hoc regret function on the three optimization problems mentioned in Section 4. We compare the proposed framework (B&L-C) with 7 different methods: the B&L framework [7], a state-of-the-art approximation method (IntOpt-C) [9], and 5 classical regression methods including linear regression (LR), k-nearest neighbors (k-NN), classiﬁcation and regression tree (CART), random forest (RF) and neural network (NN) [12]. The original deﬁnition of regret directly compares the (absolute) difference between the true optimal value and the estimated optimal value, no matter whether the estimated solution is feasible or not. The “B&L” method in the experiments trains using this original regret as the loss function, and completely disregards the correction process during training, even though the resulting prediction model is evaluated with correction at test time. This is a silly training method in the presence of uncertainty in constraints and feasibility, but we provide it for comparison anyway for completeness. 5.1 General Setting We now brieﬂy discuss the experiment setting of each problem: 5.1.1 MFP with unknown edge capacities. Our aim is to use this problem to compare the proposed B&L-C framework with IntOpt-C [9]. Therefore, we use the same dataset and follow the experiment setting in the work of IntOpt-C. The real-life dataset [13] is used on three real-life graphs: POLSKA [14], with 12 vertices and 18 edges, USANet [15], with 24 vertices and 43 edges, and GÉANT [16], with 40 vertices and 61 edges. In this dataset, each unknown edge capacity is related to 8 features. Following the setting in IntOpt-C, we divide the dataset into two sets: training and test. For experiments on POLSKA and USANet, 610 instances are used for training and 179 instances for testing the model performance, while for experiments on GÉANT, 490 instances are used for training and 130 instances for testing the model performance. 5.1.2 0-1 knapsack with unknown weights. In this experiment, each instance consists of 10 items. The weights W will be predicted from data, while values V and capacity C are given. Given that we are unable to ﬁnd datasets speciﬁcally for the 0-1 knapsack problem, we follow the experimental approach in the previous works of P+O [17, 7] and use real data from a different problem (the ICON scheduling competition) [13] as numerical values required for our experiment instances. In this dataset, each unknown weight is related to 8 features. We use a 70%/30% training/testing data split: 210 instances are used for training and 90 instances for testing the model performance. We generate the values following the generation method proposed by Pisinger [18], which is widely used to generate knapsack data [19, 20]. Three groups of values, which are uncorrelated, weakly correlated, and almost strongly correlated with the weights, are considered. Suppose the value of the ith item is vi, the weight of the ith item is wi. These 3 groups of values are generated as: 1) uncorrelated: vi is randomly chosen in [1, R], 2) weakly correlated: vi is randomly chosen in [max{1, wi − R/10}, wi + R/10], 3) almost strongly correlated: vi is randomly chosen in [wi + R/10 − R/500, wi + R/10 + R/500], where R is set to be 500 since the weights in the dataset are around 40 to 60. Since the average total weight of each instance is around 400, we conduct experiments on the 0-1 knapsack problem with 100, 200, and 300 capacities. The σ in Penalty Function I is set to be 0.1 and K in Penalty Function II is set to be 500. 5.1.3 MCVC with unknown costs and edge values. Since the MCVC is an NP-hard problem, we conduct experiments on two small graphs from the Survivable Network Design Library [14]: ABILENE, with 12 vertices and 15 edges, and PDH, with 11 vertices and 34 edges. Given that we are unable to ﬁnd datasets speciﬁcally for the MCVC, we use the same real data from the ICON scheduling competition [13] as numerical values required for our experiment instances. We use a 70%/30% training/testing data split: 210 instances are used for training and 90 instances for testing the model performance. 7 Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints Table 1: Mean post-hoc regrets and standard deviations for the MFP with unknown edge capacities using Correction Function A and no penalty function. Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints Table 3: Mean post-hoc regrets and standard deviations for the 0-1 knapsack problem with unknown weights and 3 groups of values using Correction Function A with Penalty Function I. Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints Table 5: Mean post-hoc regrets and standard deviations for the MFP with unknown edge capacities using Correction Function B and no penalty function. Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints Table 7: Mean post-hoc regrets and standard deviations for the 0-1 knapsack problem with weakly correlated values using different correction functions with Penalty Function I. Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints Table 8: Mean post-hoc regrets and standard deviations for the 0-1 knapsack problem with unknown weights and weakly correlated values using Penalty Function II. Branch & Learn with Post-hoc Correction for Predict+Optimize with Unknown Parameters in Constraints [13] Helmut Simonis, Barry O’Sullivan, Deepak Mehta, Barry Hurley, and Milan De Cauwer. Energy-Cost Aware Scheduling/Forecasting Competition, 2014. [14] S. Orlowski, M. Pióro, A. Tomaszewski, and R. Wessäly. SNDlib 1.0–Survivable Network Design Library. In Proceedings of the Third International Network Optimization Conference, April 2007. http://sndlib.zib.de, extended version accepted in Networks, 2009. [15] Diego Lucerna, Nicola Gatti, Guido Maier, and Achille Pattavina. On the efﬁciency of a game theoretic approach to sparse regenerator placement in WDM networks. In GLOBECOM 2009-2009 IEEE Global Telecommunica- tions Conference, pages 1–6. IEEE, 2009. [16] MultiMedia LLC. Geant topology map dec2018 copy. https://www.geant.org/Resources/Documents/ GEANT_Topology_Map_December_2018.pdf, 2018. Accessed: 2020-09-10. [17] Jayanta Mandi, Peter J Stuckey, Tias Guns, et al. Smart Predict-and-Optimize for hard combinatorial optimization problems. In Proceedings of the Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, volume 34, pages 1603–1610, 2020. [18] David Pisinger. Where are the hard knapsack problems? Computers & Operations Research, 32(9):2271–2284, 2005. [19] Quentin Cappart, Thierry Moisan, Louis-Martin Rousseau, Isabeau Prémont-Schwarz, and Andre A Cire. Com- bining reinforcement learning and constraint programming for combinatorial optimization. In Proceedings of the Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, volume 35, pages 3677–3687, 2021. [20] Duanshun Li, Jing Liu, Dongeun Lee, Ali Seyedmazloom, Giridhar Kaushik, Kookjin Lee, and Noseong Park. A novel method to solve neural knapsack problems. In Proceedings of the Thirty-Eighth International Conference on Machine Learning, pages 6414–6424. PMLR, 2021. 13","libVersion":"0.3.2","langs":""}