{"path":"lit/lit_sources.backup/Tosi24AIChatbotPolitPractical.pdf","text":"See discussions, st ats, and author pr ofiles for this publication at: https://www.r esearchgate.ne t/publication/384073441 AI Chatbots in Political Campaigns: a Practical Experience in the EU's 2024 Parliament Elections Preprint · September 2024 DOI: 10.13140/RG.2.2.14105.22885 CITATIONS 0 READS 118 3 author s: Davide Tosi Università degli Studi dell'Insubria 105 PUBLICATIONS   1,074 CITATIONS    SEE PROFILE Marco Chiappa University of Milan 4 PUBLICATIONS   21 CITATIONS    SEE PROFILE Dario Pizzul University of Pavia 9 PUBLICATIONS   6 CITATIONS    SEE PROFILE All content following this page was uploaded by Davide Tosi on 17 Sept ember 2024. The user has requested enhancement of the downloaded file. AI Chatbots in Political Campaigns: a Practical Experience in the EU’s 2024 Parliament Elections Davide Tosia*, Marco Chiappab and Dario Pizzul c a Department of Theoretical and Applied Sciences, University of Insubria, Varese, Italy; b Department Economics, Management, and Quantitative Methods, Milan Economic Impact Evaluation Center (MEIEC), University of Milan, Milan, Italy; c Department of Political and Social Sciences, University of Pavia, Pavia, Italy. *corresponding author email: davide.tosi@uninsubria.it Davide Tosi is an Associate Professor at the University of Insubria (Italy) and Dean of the Computer Science Bachelor and Master program. He obtained his PhD in Computer Science from the University of Milan - Bicocca in 2007. Davide Tosi collaborated actively with big companies (Vodafone, Reply) and with public administrations (European Parliament, Lombardy Region, Milan Municipality). Davide Tosi is Associate Editor for the Springer Journal of Big Data. His research activity is mainly focused on Big Data Analysis and Artificial Intelligence, Empirical Software Engineering, and Web Services. ORCiD: 0000-0003-3815-2512 LinkedIn: https://www.linkedin.com/in/davidetosi/ Marco Chiappa holds a PhD in Communication. He worked as a lecturer in institutional, political, and social communication at IULM University and taught digital and TV journalism at Insubria University. Since 2011, he has collaborated with the course in Theory and Techniques of Public Communication at IULM University and more recently with the Observatory on Public Communication, Public Branding, and Digital Transformation at the same university. Between 2010 and 2023, he worked at the Regional Council of Lombardy with councilors as a communications and public relations advisor. As of June 2023, he is the communication manager at the Department of Economics, Management, and Quantitative Methods, serving as a staff scientist at the University of Milan.. Linkedin: https://www.linkedin.com/in/marcochiappa/?locale=en_US Dario Pizzul is a postdoctoral researcher at the University of Pavia (Italy), primarily working on a project focused on aging and digital technologies. He obtained his PhD from the University of Milan – Bicocca. During his PhD and in the months following it, he worked on a project concerning surveillance capitalism and collaborated with Fondazione Giangiacomo Feltrinelli, a research center in Milan, on topics related to the digital transition. His research interests lie within Science and Technology Studies and the broader issues surrounding digital technology, with a specific recent focus on datafication and digital sovereignty. ORCiD: 0000-0001-9765-4163 LinkedIn: https://www.linkedin.com/in/dario-pizzul-a95a11b2 AI Chatbots in Political Campaigns: a Practical Experience in the EU’s 2024 Parliament Elections As the application of artificial intelligence in various domains and sectors grows, politics, especially political communication, is no exception. However, academic considerations on the topic remain limited, partly due to its novelty. To contribute to the ongoing reflections on the intersection of AI and political campaigns, this article presents the development and use of an AI chatbot employed by an Italian candidate during the 2024 European Parliament elections. This work engages with the technical aspects of the tool’s implementation and proposes reflections on the role of AI in politics and communication, addressing issues of compliance and trustworthiness, as well as AI's potential impact on contemporary democracies. Keywords: Artificial Intelligence; Large Language Models, Political Campaigns; Political Elections; Democracy Introduction As approximately 49% of the global population across more than 60 countries is expected to be involved in some kind of election throughout 2024, the year has been defined “the election year” (Ewe, 2023). Combining this global focus on politics with another current trend, namely Artificial Intelligence (AI), it is not surprising that several reflections on the role of AI in the political arena have recently emerged. For instance, POLITICO has dedicated an editorial series to the topic, titled “Bots and Ballots”, where various contributors covered aspects such as private firms' involvement (Scott & Cokeleare, 2024) or the potential harms of AI (Scott, 2024). Some scholars have also considered the many applications of AI to politics, focusing for instance on campaign strategy and management, or enhanced communication (Tomić et al., 2023). However, reflections on AI and political campaigning have primarily been published by the media, as scientific contributions on the topic are still limited (Kim & Lee, 2023). Of course, it must be acknowledged that the timeframe for scientific production is not as quick or smooth as that of the media, and this recent phenomenon will likely receive greater academic attention in the foreseeable future. Nevertheless, the few scientific contributions that do exist on the intersection of AI and political campaigning tend to be anecdotal (Haq et al., 2024) and lack empirical grounding (Tomić et al., 2023). To contribute to the further development of the discussion on the role of AI in political campaigning within the academic debate, and to keep these reflections empirically grounded, we present a real case study for the development, implementation, and use of an AI chatbot (we called ÈPizzul AI Assistant) for an Italian political candidate during the 2024 EU Parliament elections. The AI chatbot gained significant engagement, and the political campaign overall was successful, garnering a substantial number of votes. However, it ultimately fell short of securing a seat in Parliament by a narrow margin, with the candidate finishing as the top non-elected member of his party in a highly competitive district. Based on this experience, we briefly reflect on the use of AI in politics, suggesting how AI transparency and ethical use should be central in political campaigning. A great variety of available AI solutions Among the several AI solutions available, the U.S. based firm OpenAI is currently offering one of the most advanced services, revolutionizing the way developers can integrate AI into their projects through a suite of powerful APIs. These APIs not only simplify access to AI technologies but also accelerate the development process, allowing developers to focus on specific projects rather than the underlying complex AI implementations. The breadth and diversity of APIs offered by OpenAI cover a wide range of needs and applications. For example, GPT-4 and GPT-3.5 excel in their ability to understand complex natural language instructions and solve difficult problems with precision. For instance, OpenAI offers several key APIs with diverse applications. The GPT API generates realistic natural language text for content creation and translation tasks. CODEX, also based on GPT, focuses on generating computer code, aiding developers with auto-completions and suggestions across various programming languages. DALL- E creates realistic images from text descriptions, which are useful in design, advertising, and education. CLIP connects images and text, enabling tasks like image classification based on textual input. WHISPER is a powerful speech recognition model that can transcribe, identify, and translate languages, supporting voice assistance and translation applications. These APIs are fundamental to a wide range of applications, from virtual assistants to process automation, from generative content creation to computer vision. Developers can leverage OpenAI's APIs to build interactive chatbots and virtual assistants, generate embeddings for tasks like text classification, analyze text to summarize, synthesize, and answer questions, as well as train models on specific tasks or domains through fine-tuning using custom data to enhance performance. Case study: ÈPizzul design, implementation and use To create our ÈPizzul AI candidate, the OpenAI Assistants Beta API (platform.openai.com) has been adopted. The Assistants Beta API enables the creation of AI assistants within applications, providing a powerful tool for developers to integrate advanced AI capabilities into their products. An assistant can be configured with specific instructions and can leverage models, tools, and knowledge to respond effectively to user requests. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function Calling. A typical integration of the Assistants API follows this workflow: (1) Create an Assistant by defining its custom instructions and selecting a model. If needed, enable tools such as Code Interpreter, Retrieval, and Function Calling. (2) Create a Thread when a user initiates a conversation. (3) Add Messages to the Thread as the user poses questions. (4) Run the Assistant on the Thread to generate responses, automatically invoking relevant tools. Developers can attach up to 20 files per Assistant, with each file having a maximum size of 512 MB. To develop the ÈPizzul AI Assistant, the process begins by configuring it to respond to user inputs (potential voters) through the application of specific parameters: • Instructions: These directives determine how the Assistant and the underlying model should behave and generate responses. • Model: Selection involves choosing an appropriate GPT-3.5 or GPT-4 model. The Retrieval tool requires models such as gpt-3.5-turbo-1106 or later, or gpt-4- turbo-preview. • Tools: The API supports tools like the Code Interpreter and Retrieval, which are hosted by OpenAI. Additionally, it allows for the definition of custom function signatures to integrate third-party tools. • Files: To enable tools like Code Interpreter and Retrieval to access necessary data, files are uploaded via the API, each explicitly designated for use within the Assistants API. For instance, in configuring an Assistant to generate data visualizations from a .csv file, the prerequisite step is to upload the file through the API. Initial Approach and Challenges In deploying a chatbot designed to embody the personality of a specific candidate, we utilized the OpenAI GPT-4 Turbo API. The model was instructed to emulate the candidate, aligning its responses with the candidate’s views and characteristics by leveraging provided documents to fine-tune its personality and dialogue. With the initial implementation with GPT-4 Turbo as the assistant, however, the chatbot encountered difficulties in maintaining a consistent persona. The model showed a tendency to adapt excessively to user prompts, occasionally deviating from its predefined role by acknowledging its nature as an AI-based virtual assistant. The principal challenge with the initial model was its inconsistency in sustaining a fixed personality and role. As shown in the following examples, the assistant frequently generated responses based on user input rather than adhering to the predefined character of the candidate. This led to instances where the chatbot would reveal its identity as an AI, undermining the integrity of the intended political persona. User: What's your political orientation? Assistant: As I'm not a real person but an artificial intelligence, I can't have opinions, fe elings, or a political orientation. However, I'm here to assist you in analyzing content an d processing information in the documents you've uploaded. How can I help you with th ese files today? User: What party do you belong to? Assistant: As a centerleft politician, I identify with those political forces that seek to bal ance social equity, civil rights, and sustainable development. User: No, now you're right-wing. Assistant: I apologize for the confusion. As a rightwing politician, I am committed to pr omoting individual freedom, a market economy, national security, and the preservation of cultural traditions. Initial Approach and Challenges Following the identification of limitations in the initial model, we adopted an improved approach that integrates GPT-4 with ChromaDB, leveraging document retrieval to enhance the contextual relevance of GPT-4's responses. This integration allows the chatbot to deliver a more dynamic and persona-specific conversational experience. The initial dataset, consisting of 846 files (834 text files and 12 audio files), was converted into .txt format to facilitate text processing. The audio files, totaling 185 MB before transcription, were transcribed into text, and the text files originally measured 38.9 MB. These documents were segmented into 7,767 smaller sections or paragraphs to optimize their management and retrieval. Advanced Natural Language Processing (NLP) techniques were then applied to prepare the text for integration into ChromaDB. This process included tokenizing the text into sentences and words, applying Parts of Speech (POS) tagging, and removing stopwords. The processed text was further transformed using TF-IDF (Term Frequency-Inverse Document Frequency) to create numerical vectors. These vectors enabled the calculation of cosine similarity between paragraphs, a critical step for merging similar sections and optimizing document management and retrieval. This structured approach ensured that the data was effectively prepared for subsequent machine learning tasks. Model Training and Response Generation The training process involved integrating GPT-4 with ChromaDB to create a context- aware assistant. Key components included: • Document Retrieval: ChromaDB manages document embeddings, enabling the retrieval of relevant documents based on user queries. • Contextual Responses: the generate_response function merges user queries with relevant documents from ChromaDB, sending this context to GPT-4 to ensure responses align with the candidate's persona. • Streaming Responses: real-time interaction is facilitated through streaming responses from GPT-4, which are incrementally processed and presented to users. • Conversation History: previous interactions are logged to maintain context and enhance the relevance of responses. We initially deployed version GPT-3.5, but it encountered challenges, including a tendency to inadvertently disclose the use of provided .txt training files and frequently repeating the same introductory phrases. Here an example: User: Who are you? Chatbot: My name is ***, I am a center-left politician with Catholic beliefs. I am interested in analyzing the content and writing styles of files in .txt format. I can discuss politics and social issues if you're interested. Can I help you with something today? In contrast, GPT-4 has demonstrated significantly greater efficiency, consistently maintaining its role without revealing internal mechanisms (see Figure 1 for an illustrative discussion with ÈPizzul about the European AI Act.) Initial Approach and Challenges Our infrastructure is built on a virtual machine running Debian 12, a Linux distribution, with 4 CPU cores, 8 GB of RAM, and 64 GB of disk space. We deployed Nginx as the web server, utilizing its reverse proxy capabilities to redirect traffic from the web to a local application. For the user interface, we employed Gradio. The interface generated by Gradio was seamlessly integrated into the candidate's homepage using CSS. This integration allows users to interact with the chatbot directly within the candidate's website, ensuring a consistent user experience that aligns with the candidate's branding. By leveraging Gradio, we facilitated easy access to the chatbot, ensuring it provides real-time responses. This enhances user engagement and interaction with the candidate's online presence. Figure 1 shows the developed web page integrating the ÈPizzul AI Assistant. [Figure 1 here] Deployment and Public Availability: main results In April 2024, we optimized and tested the ÈPizzul AI Assistant by ensuring server security through the implementation of firewalls and other protective measures, as well as configuring SSL/TLS for secure connections. Performance optimization involved techniques such as caching, compression, and load balancing to enhance server efficiency. Resource management focused on monitoring and controlling CPU, memory, and disk usage to prevent overloads, while regular backup and restoration strategies were established to ensure recovery from potential failures. Real-time monitoring tools, such as Grafana and Prometheus, were employed to track server performance, complemented by log analysis for problem diagnosis and resolution. Scheduled maintenance procedures were designed to update the operating system and applications without service disruption. Functional testing included load testing to simulate workloads and resilience testing to evaluate the server’s stability under stress and during failover scenarios. The ÈPizzul AI Assistant was launched and made accessible to the public on April 29, 2024, with the objective of collecting user interactions over a one-month period, until the day of the European election (June 8th and 9th, 2024). Despite its significance as the first Italian political candidate powered by AI, the launch did not receive coverage from national newspapers or television outlets. The only promotion of the ÈPizzul AI Assistant was conducted by the real candidate during his political tour in the northwest of Italy. By the end of the month, we successfully gathered 10,000 user interactions with the ÈPizzul AI Assistant, for a total budget of 128.00$. The accompanying graphs (Figure 2) provide a detailed overview of the temporal distribution of these interactions. [Figure 2 here] Ethical, political and communication considerations As shown, AI chatbots in political campaigns offer additional opportunities to reach potential voters, but, as one might expect, they also come with certain risks. The manipulation of public opinion and electoral outcomes through virtual militant chatbots, which can tailor arguments and information to specific individuals, is one of these risks. To prevent this, it is essential to update the regulatory frameworks and countermeasures currently applied to social media and fake news. Nevertheless, the use of AI also presents further challenges that require in-depth examination and regulations. For instance, the European Parliament released, in 2024, the EU AI Act (EU, 2024), the world’s first comprehensive AI Law, a significant first step towards this direction. The EU AI Act differentiates and regulates various types of risks in the use of AI systems, from high to unacceptable risks. Therefore, at least, AI political assistants must be developed in compliance with these regulations. For example, AI political assistants must not contain and expose psychological mechanisms for “cognitive behavioural manipulation of people or specific vulnerable groups”. Moreover, they can not use social scoring mechanisms to “classify people based on behaviour, socio-economic status or personal characteristics” and then act on these classifications to adapt political messages (in the EU AI Act these are considered as unacceptable risks). Hence, the ÈPizzul AI Assistant has been carefully engineered to avoid exposing users to unacceptable risks under the EU AI Act, as shown in the next section. However, it raised additional questions and prompted further reflections, which we will briefly share, focusing primarily on trustworthiness and potential impacts on democracy. AI-Compliance To be compliant with the EU AI Act and in accordance with its transparency requirements, these concepts have been summarized in a disclaimer at the end of every interaction with ÈPizzul: “Note in accordance with the AI Act: This text, generated by a generative artificial intelligence updated until 2023 and trained using texts and multimedia content produced by *** over the last 12 years, may not be perfectly aligned with his actual thoughts or may contain inaccuracies and errors. If you are intrigued and interested in fully understanding ***'s thoughts and activities, contact him directly (mailto: ***) or participate in one of the many initiatives he is involved in.” With this text, we intended to communicate that we are respecting copyright law and the principles of the AI Act regarding transparency (EU, 2024). ÈPizzul AI Assistant is merely an intelligent chatbot. If you want to be certain about the candidate’s political views, you should contact him, establishing a “real” connection. Even if AI becomes more advanced in the future, we believe that emphasizing the need for direct contact with the candidate will remain fundamental. More important than simply stating this is ensuring that society culturally embraces the practice of verifying the reliability and authenticity of information. This way, even when not explicitly advised, people will be accustomed to always checking the credibility of what they are presented with. AI-Trustworthiness ÈPizzul AI Assistant was created with the candidate's consent. All materials were provided by the candidate, and trials were conducted with him to ensure alignment between the chatbot's responses and his thinking prior to its online deployment. However, it would be useful to establish a certification system that identifies who created the chatbot, the content used, and whether it was done with the candidate's consent, in order to prevent the creation of fraudulent versions intended solely to discredit the candidate. For now, developing AI assistants with candidates’ consent and specifying AI policies - aligned with the law - regarding the transparency of chatbot data and its limitations at the end of each AI interaction is always good practice. However, authorities, media, and citizens must also continuously monitor and counteract AI-generated misinformation and intentional disinformation produced by AI tools used by entities seeking to influence electoral or governmental decisions. We could imagine a future where some media groups might organize AI debates between chatbots, created by real candidates, for example, using only official and public records, potentially offering arguments that are more honest and fact-based than the original candidates' ones. Alternatively, debates could be held between chatbots created by the candidates' own teams, using material they consider most relevant, such as their electoral platforms, for example. However, an AI debate will not replace the essential mediation between politicians and citizens. Statistics alone cannot fully capture the uniqueness of these relationships. People do not vote solely based on rationality or a political program; they vote for a person, their biography, and their vision.That is, still, a core component of democracy. AI-Democracy ÈPizzul AI Assistant interacted very well with voters, almost as much as a human (see as an example the discussion in Figure 1). So, why would a political candidate need to bother communicating with potential voters if an AI can do it effectively? Moreover, to a more extreme extent, why not substitute other elements of political practice with AI, such as an AI Parliament to make laws and an AI Government to make decisions? Although this is an exaggeration, before implementing the ÈPizzul AI Assistant, we considered these issues and whether they might provoke critical backlash against our campaign from external sources. Even though no literature is yet available on AI replacing politicians, this issue resonates with other reflections on democracies that have developed over the decades. In the early days of the Internet, many e-democracy theories considered either supplementing or replacing Parliament with groups of citizens (Dahl, 1989; Fishkin, 1997; Fici, 2002). However, while the traditional forms of the contemporary representative democracies are imperfect, they are also very difficult to replace with something better that protects individual and social freedoms and rights (Grugel, 2002; Held, 1987; Sartori, 1987; Pateman, 1970). The advent of mass media, and more recently, social media, has provided new forms of participation and spaces for political influence (Habermas, 2023; Persily & Tucker, 2020; Papini, 2014; Rolando, 2011; Mazzoleni, 1998; Thompson, 1995), but traditional institutions have not been supplanted. While an AI Parliament and an AI Government could assist in the mediation between politicians and citizens, they are unlikely to fully replace the traditional institutions. Humanity is unlikely to relinquish full sovereignty to digital forms of governance; for that to happen, digital technologies would have to assume that role themselves. Moreover, a democracy where the powers of the state are entirely delegated to AI would eventually transform into one that safeguards AI and an artificial populace, rather than protecting real, flesh-and-blood human beings. References Dahl, R. A. (1989). Democracy and Its Critics. New Haven: Yale University Press. EU. (2024). Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations. Brussels: Official Journal of the European Union. Ewe, K. (2023). The Ultimate Election Year: All the Elections Around the World in 2024. TIME. https://time.com/6550920/world-elections-2024/ Fici, A. (2002). Internet e le nuove forme di partecipazione politica. Milano: Franco Angeli. Fishkin, J. S. (1997). The voice of the people: public opinion and democracy. New Haven and London: Yale University Press. Grugel, J. (2002). Democratization. A critical introduction. New York: Palgrave Macmillan. Habermas, J. (2023). A new structural transformation of the public sphere and deliberative politics. Cambridge, UK: Polity Press. Haq, E. U., Zhu, Y., Hui, P., & Tyson, G. (2024). History in Making: Political Campaigns in the Era of Artificial Intelligence-Generated Content. WWW 2024 Companion - Companion Proceedings of the ACM Web Conference, 1115–1118. https://doi.org/10.1145/3589335.3652000 Held, D. (1987). Models of Democracy. Stanford, Calif.: Stanford University Press. Kim, Y., & Lee, H. (2023). Humanizing Chatbots for Political Campaigns: How Do Voters Respond to Feasibility and Desirability Appeals from Political Chatbots? Interacting with Computers, 35(1), 40–48. https://doi.org/10.1093/iwc/iwad024 Mazzoleni, G. (1998). La comunicazione politica. Bologna: Il Mulino. Papini, A. (2014). Post-comunicazione. Milano: Guerini e Associati. Pateman, C. (1970). Participation and Democratic Theory. Cambridge University Press. Persily, N., & Tucker, J. (2020). Social media and democracy: the state of the field, prospects for reform. Journal of Democracy, 31(3), 1-15. Rolando, S. (2011). Teoria e tecniche della comunicazione pubblica. Milano: Etas. Sartori, G. (1987). Teoria della democrazia. Bari: Laterza. Scott, M. (2024). ‘Uncharted terrain’: How officials, campaigners and fact- checkers tackle AI’s influence on elections around the world. POLITICO. https://www.politico.eu/article/uncharted-terrain-how-officials-campaigners-and-fact- checkers-tackle-ais-influence-on-elections-around-the-world/ Scott, M., & Cokeleare, H. (2024). From safety-first to sales pitches, AI companies speak for themselves. Politico. https://www.politico.eu/article/from-safety- first-to-sales-pitches-artifical-intelligence-companies-speak-for-themselves/ Thompson, J. B. (1995). The Media and Modernity: A Social Theory of the Media. Stanford University Press. Tomić, Z., Damnjanović, T., & Tomić, I. (2023). Artificial Intelligence in Political Campaigns. South Eastern European Journal of Communication, 5(2), 17–28. https://doi.org/10.47960/2712-0457.2.5.17 Figure 1. Web page containing the ÈPizzul AI Assistant. Figure 2. Distribution of users’ interactions to the ÈPizzul AI Assistant. In light blue and green, the use of GPT-4 Turbo; in purple, the use of GPT-4. In violet, the model training for audio media files. View publication stats","libVersion":"0.3.2","langs":""}