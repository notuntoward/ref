{"path":"lit/lit_sources.backup/Karpatne17physNNlakeT.pdf","text":"Physics-guided Neural Networks (PGNN): An Application in Lake Temperature Modeling Arka Daw∗ Virginia Tech darka@vt.edu Anuj Karpatne ∗ Virginia Tech karpatne@vt.edu William Watkins U.S. Geological Survey wwatkins@usgs.gov Jordan Read U.S. Geological Survey jread@usgs.gov Vipin Kumar University of Minnesota kumar001@umn.edu Abstract This paper introduces a framework for combining scientiﬁc knowledge of physics- based models with neural networks to advance scientiﬁc discovery. This framework, termed physics-guided neural networks (PGNN), leverages the output of physics- based model simulations along with observational features in a hybrid modeling setup to generate predictions using a neural network architecture. Further, this framework uses physics-based loss functions in the learning objective of neural networks to ensure that the model predictions not only show lower errors on the training set but are also scientiﬁcally consistent with the known physics on the unlabeled set. We illustrate the effectiveness of PGNN for the problem of lake temperature modeling, where physical relationships between the temperature, den- sity, and depth of water are used to design a physics-based loss function. By using scientiﬁc knowledge to guide the construction and learning of neural networks, we are able to show that the proposed framework ensures better generalizability as well as scientiﬁc consistency of results. All the code and datasets used in this study have been made available on this link https://github.com/arkadaw9/PGNN. 1 Introduction Data science has become an indispensable tool for knowledge discovery in the era of big data, as the volume of data continues to explode in practically every research domain. Recent advances in data science such as deep learning have been immensely successful in transforming the state-of-the-art in a number of commercial and industrial applications such as natural language translation and image classiﬁcation, using billions or even trillions of data samples. In light of these advancements, there is a growing anticipation in the scientiﬁc community to unlock the power of data science methods for accelerating scientiﬁc discovery [1, 2, 3, 4]. However, a major limitation in using “black-box” data science models, that are agnostic to the underlying scientiﬁc principles driving real-world phenomena, is their sole dependence on the available labeled data, which is often limited in a number of scientiﬁc problems. In particular, a black- box data science model for a supervised learning problem can only be as good as the representative quality of the labeled data trained on. When the size of both the training and test sets are small, it is easy to learn spurious relationships that look deceptively good on both training and test sets (even after using standard methods for model evaluation such as cross-validation), but do not generalize well outside the available labeled data. A more serious concern with black-box applications of data science models is the lack of consistency of its predictions with respect to the known laws of physics (demonstrated in section 4). Hence, even if a black-box model achieves somewhat more accurate ∗Equal ContributionarXiv:1710.11431v3 [cs.LG] 28 Sep 2021 performance but lacks the ability to adhere to mechanistic understandings of the underlying physical processes, it cannot be used as a basis for subsequent scientiﬁc developments. On the other end of the spectrum, physics-based models, which are founded on core scientiﬁc princi- ples, strive to advance our understanding of the physical world by learning explainable relationships between input and output variables. These models have been the cornerstone of knowledge discovery in a wide range of scientiﬁc and engineering disciplines. There are two basic forms in which physical knowledge is generally available: (a) as physics-based rules or equations that dictate relationships between physical variables, and (b) in the form of numerical models of complex physical systems, e.g., simulations of dynamical systems that are heavily used in computational chemistry, ﬂuid dy- namics, climate science, and particle physics. While these models have signiﬁcantly advanced our understanding of the physical universe, they are limited in their ability to extract knowledge directly from data and are mostly reliant only on the available physics. For example, many physics-based models use parameterized forms of approximations for representing complex physical processes that are either not fully understood or cannot be solved using computationally tractable methods. Calibrating the parameters in physics-based models is a challenging task because of the combinatorial nature of the search space. In particular, this can result in the learning of over-complex models that lead to incorrect insights even if they appear interpretable at a ﬁrst glance. For example, these and other challenges in modeling hydrological processes using state-of-the-art physics-based models were the subject of a series of debate papers in Water Resources Research (WRR) [5, 6, 7]. One perspective [5] argues that many physics-based models are excessively constrained by their a priori parameterizations. The dichotomy between physics-based models and black-box neural network models is schematically depicted in Figure 1, where they both occupy the two extreme ends of knowledge discovery, either relying only on the data (black-box neural networks) or only on scientiﬁc knowledge (physics-based models). In this paper, we introduce a framework of knowledge discovery in scientiﬁc problems that combines the power of neural networks with physics-based models, termed physics-guided neural networks (PGNN). There are two primary contributions of this work. First, we present an approach to create hybrid combinations of physics-based models and neural network architectures to make full use of both physics and data. Second, we present a novel framework for training neural network architectures using the knowledge contained in physics-based equations, to ensure the learning of physically consistent solutions. To demonstrate the framework of PGNN, we consider the illustrative problem of modeling the temperature of water in a lake at varying depths and times, using input drivers as well as physics-based model simulations. For this problem, we exploit a key physical relationship between the temperature, density, and depth of water in the form of physics-based loss function. Use of DataUse of Scientific TheoryTheory-based Models Data Science Models Theory-guided Data Science Models Low High High Low\t\r  Physics-­‐based\t\r  Models\t\r  \t\r   \t\r   Black-­‐box\t\r  Neural\t\r  Networks\t\r   \t\r   \t\r   \t\r   \t\r   Physics-­‐guided\t\r  \t\r   Neural\t\r  Networks\t\r   (PGNN)\t\r   \t\r   \t\r   Figure 1: A schematic representation of physics-guided neural networks in the context of other knowledge discovery approaches that either use physics or data. The X-axis measures the use of data while the Y -axis measures the use of scientiﬁc knowledge. 2 The remainder of this paper is organized as follows. Section 2 presents the generic framework of physics-guided neural networks that can be applied in any domain with some availability of scientiﬁc knowledge. Section 3 presents the speciﬁc PGNN formulation for the illustrative problem of lake temperature modeling. Section 4 describes the evaluation procedure and presents experimental results, Section 5 presents some discussion on the approach used for hybrid modeling, while Section 6 provides concluding remarks. 2 Physics-guided Neural Networks The generic framework of physics-guided neural networks (PGNN) involves two key steps: (a) creating hybrid combinations of physics-based models and neural networks, termed hybrid-physics- data (HPD) models, and (b) using scientiﬁc knowledge as physics-based loss functions in the learning objective of neural networks, as described in the following. 2.1 Constructing Hybrid-Physics-Data Models Consider a predictive learning problem where we are given a set of input drivers, D, that are physically related to a target variable of interest, Y . A standard approach is to train a data science model, e.g., a neural network, fN N : D → Y , over a set of training instances, which can then be used to produce estimates of the target variable, ˆY . Alternatively, we can also use a physics-based numerical model, fP HY : D → Y , to simulate the value of the target variable, YP HY , given its physical relationships with the input drivers. Analogous to the process of training, physics-based models often require “calibrating\" their model parameters using observational data—a process that is both time-consuming and label-expensive. Furthermore, YP HY may provide an incomplete representation of the target variable due to simpliﬁed or missing physics in fP HY , thus resulting in model discrepancies with respect to observations. Hence, the basic goal of HPD modeling is to combine fP HY and fN N so as to overcome their complementary deﬁciencies and leverage information in both physics and data. One simple way for combining fP HY and fN N is to use the simulated outputs of the physics-based model, YP HY , as another input in the data science model (neural network) along with the drivers, D. This results in the following basic HPD model: fHP D : X = [D, YP HY ] → Y, which is schematically illustrated in Figure 2. In this setup, notice that if the physics-based model is accurate and YP HY perfectly matches with observations of Y , then the HPD model can learn to predict ˆY = YP HY . However, if there are systematic discrepancies (biases) in YP HY , then fHP D can learn to complement them by extracting complex features from the space of input drivers and thus reducing our knowledge gaps. 2.2 Using Physics-based Loss Functions A standard approach for training the HPD model described in Figure 2 is to minimize the empirical loss of its model predictions, ˆY , on the training set, while maintaining low model complexity as Figure 2: A schematic illustration of a basic hybrid-physics-data (HPD) model, where the output YP HY of a physics-based model fP HY is used as another feature in the data science model fHP D along with the drivers D to produce the ﬁnal outputs ˆY. In this schematic, white boxes represent physics-based models while black boxes represent ML models. 3 follows: arg min f Loss( ˆY , Y ) + λ R(f ), (1) where R(.) measures the complexity of a model and λ is a trade-off hyper-parameter. However, the effectiveness of any such training procedure is limited by the size of the labeled training set, which is often small in many scientiﬁc problems. In particular, there is no guarantee that model trained by minimizing Equation 1 will produce results that are consistent with our knowledge of physics. Hence, we introduce physics-based loss functions to guide the learning of data science models to physically consistent solutions as follows. Let us denote the physical relationships between the target variable, Y , and other physical variables, Z using the following equations: G(Y, Z) = 0, H(Y, Z) ≤ 0. (2) Note that G and H are generic forms of physics-based equations that can either involve algebraic manipulations of Y and Z (e.g., in the laws of kinematics), or their partial differentials (e.g., in the Navier–Stokes equation for studying ﬂuid dynamics or in the Schrödinger equation for studying computational chemistry). These physics-based equations must meet the same criteria as other loss function terms (i.e. continuous and differentiable). One way to measure if these physics-based equations are being violated in the model predictions, ˆY , is to evaluate the following physics-based loss function: Loss.P HY ( ˆY ) = ||G( ˆY , Z)|| 2 + ReLU (H( ˆY , Z)), (3) where ReLU(.) denotes the rectiﬁed linear unit function. Since Loss.P HY does not require actual observations of the target variable, Y , it can be evaluated even on unlabeled data instances, in contrast to traditional loss functions. The complete learning objective of PGNN involving Loss.P HY can then be stated as: arg min f Loss( ˆY , Y ) ︸ ︷︷ ︸ Empirical Error + λ R(f ) ︸ ︷︷ ︸ Structural Error + λP HY Loss.P HY ( ˆY ) ︸ ︷︷ ︸ Physical Inconsistency , (4) where λP HY is the hyper-parameter that decides the relative importance of minimizing physical inconsistency compared to the empirical loss and the model complexity. Since the known laws of physics are assumed to hold equally well for any unseen data instance, ensuring physical consistency of model outputs as a learning objective in PGNN can help in achieving better generalization performance even when the training data is small and not fully representative. Additionally, the output of a PGNN model can also be interpreted by a domain expert and ingested in scientiﬁc workﬂows, thus leading to scientiﬁc advancements. There are several optimization algorithms that can be used for minimizing Equation 4, e.g., the stochastic gradient descent (SGD) algorithm and its variants that have found great success in training deep neural networks. In particular, the gradients of Loss.P HY w.r.t model parameters can be easily computed using the automatic differentiation procedures available in standard deep learning packages. This makes neural networks a particularly suited choice for incorporating physics-based loss functions in the learning objective of data science models. 3 PGNN for Lake Temperature Modeling In this section, we describe our PGNN formulation for the illustrative problem of modeling the temperature of water in lakes. In the following, we ﬁrst provide some background information motivating the problem of lake temperature modeling, and then describe our PGNN approach. 3.1 Background: Lake Temperature Modeling The temperature of water in a lake is known to be an ecological “master factor” [8] that controls the growth, survival, and reproduction of ﬁsh (e.g., [9]). Warming water temperatures can increase the 4 occurrence of aquatic invasive species [10, 11], which may displace ﬁsh and native aquatic organisms, and result in more harmful algal blooms (HABs) [12, 13]. Understanding temperature change and the resulting biotic “winners and losers” is timely science that can also be directly applied to inform priority action for natural resources. Accurate water temperatures (observed or modeled) are critical to understanding contemporary change, and for predicting future thermal habitat of economically valuable ﬁsh. Since observational data of water temperature at broad spatial scales is incomplete (or non-existent in some regions) high-quality temperature modeling is necessary. Of particular interest is the problem of modeling the temperature of water at a given depth2, d, and on a certain time, t. This problem is referred to as 1D-modeling of temperature (depth being the single dimension). A number of physics-based models have been developed for studying lake temperature, e.g., the state-of-the-art general lake model (GLM) [14]. This model captures a variety of physical processes governing the dynamics of temperature in a lake, e.g., the heating of the water surface due to incoming shortwave radiation from the sun, the attenuation of radiation beneath the surface and the mixing of layers with varying energies at different depths, and the dissipation of heat from the surface of the lake via evaporation or longwave radiation, shown pictorially in Figure 3. We use GLM as our preferred choice of physics-based model for lake temperature modeling. The GLM has a number of parameters (e.g., parameters related to vertical mixing, wind energy inputs, and water clarity) that needs to be custom-calibrated for each lake if some training data is available. The basic idea behind these calibration steps is to run the model for each possible combination of parameter values and select the one that has maximum agreement with the observations. Because this step of custom-calibrating is both labor- and computation-intensive, there is a trade-off between increasing the accuracy of the model and expanding the feasability of study to a large number of lakes. 3.2 Proposed PGNN Formulation We consider the physical variables governing the dynamics of lake temperature at every depth and time-step as the set of input drivers, D. This includes meteorological recordings at the surface of water such as the amount of solar radiation at different wavelengths, wind speed, and air temperature, as well as the value of depth and the day of the year. To construct an HPD model of the type shown in Figure 2, we use simulations of lake temperature from the GLM, YP HY , along with the input drivers D at every depth and time-step to obtain the augmented set of features, X = [D, YP HY ]. 2Depth is measured in the direction from the surface of the water to the lake bottom. Figure 3: A pictorial description of the physical processes governing the dynamics of temperature in a lake. Figure courtesy: [14]. (Note: Figures in this paper are best viewed in color.) 5 We adopt a basic multi-layer perceptron architecture to regress the temperature, Y , on any given depth and time, using X. For a fully-connected network with L hidden layers, this amounts to the following modeling equations relating the input features, x, to its target prediction, ˆy: z1 = WT 1 x + b1 (5) zi = WT i ai−1 + bi ∀ i = 2 to L (6) ai = f (zi) ∀ i = 1 to L (7) ˆy = wT L+1aL + bL+1 (8) where (W, b) = {(Wi, bi)} L+1 1 represents the set of weight and bias parameters across all hidden and output layers, and f is the activation function used at the hidden layers. We use the mean squared error as our choice of loss function and L1 and L2 norms of network weights, W as regularization terms in Equation 1 as follows: Loss( ˆY , Y ) = 1 n n∑ i=1(yi − ˆyi)2, (9) λ R(W) = λ1||W||1 + +λ2||W||2, (10) where {x, y}n 1 is the set of training instances. To incorporate the knowledge of physics as a loss function in the training of neural networks, we employ a key physical relationship between the temperature, density, and depth of water as our physics-based equation (Equation 2). In the following, we introduce the two key components of this physical relationship and describe our approach for using it to ensure the learning of physically consistent results. 3.2.1 Temperature–Density Relationship: The temperature, Y , and density, ρ, of water are non-linearly related to each other according to the following known physical equation [15]: ρ = 1000 × (1 − (Y + 288.9414) × (Y − 3.9863)2 508929.2 × (Y + 68.12963) ) (11) Figure 4(a) shows a plot of this relationship between temperature and density, where we can see that water is maximally dense at 4◦Celsius (due to the hydrogen bonding between water molecules)3. Given the temperature predictions of a model, ˆY [d, t], at depth, d, and time-step, t, we can use Equation 11 to compute the corresponding density prediction, ˆρ[d, t]. 3This simple fact is responsible for the sustenance of all forms of aquatic life on our planet, as water at 4 ◦C moves down to the bottom and stops the freezing of lakes and oceans. -10 -5 0 4 10 15 20 25 30 996 997 998 999 1000 (a) Temperature–Density Relationship DensityDepth (b) Density–Depth Relationship Figure 4: Plots of physical relationships between temperature, density, and depth of water that serve as the basis for introducing physical consistency in PGNN. 6 3.2.2 Density–Depth Relationship: The density of water monotonically increases with depth as shown in the example plot of Figure 4(b), since denser water is heavier and goes down to the bottom of the lake. Formally, the density of water at two different depths, d1 and d2, on the same time-step, t, are related to each other in the following manner: ρ[d1, t] − ρ[d2, t] ≤ 0 if d1 < d2. (12) To ensure that this physics-based equation is upheld in the temperature predictions of a physics-based model, ˆY , we can construct a physics-based loss function as follows. Let us consider an unlabeled data set of input features on a regular grid of nd depth values and nt time-steps. On any pair of consecutive depth values, di and di+1 (di < di+1), we can compute the difference in the density estimates of a model on time-step t as ∆[i, t] = ˆρ[di, t] − ˆρ[di+1, t] (13) A positive value of ∆[i, t] can be viewed as a violation of the physics-based equation 12 on depth di and time t. This can be evaluated as a non-zero occurrence of ReLU(∆[di, t]). Hence, we can consider the mean of all physical violations across every consecutive depth-pair and time-step as our physics-based loss function: P HY .Loss( ˆY ) = 1 nt(nd − 1) nt∑ t=1 nd−1∑ i=1 ReLU(∆[i, t]). (14) Using this physics-based loss (Equation 14) along with the empirical loss (Equation 9) and regular- ization terms (Equation 10) in the learning objective (Equation 4), we obtain our complete PGNN formulation. Note that in our particular problem of lake temperature modeling, even though the neural network is being trained to improve its accuracy on the task of predicting water temperatures, the use of physics-based loss function ensures that the temperature predictions also translate to consistent relationships between other physical variables, namely density and depth, thus resulting in a wholesome solution to the physical problem. 4 Evaluation In this section, we ﬁrst describe the data collected over two lakes for evaluation along with the experimental design, choice of baselines, evaluation metrics, and experimental results. 4.1 Data We consider two example lakes to demonstrate the effectiveness of our PGNN framework for lake temperature modeling, Mille Lacs Lake in Minnesota, USA, and Lake Mendota in Wisconsin, USA. Both these lakes are reasonably large (536 km2 and 40 km2 in area, respectively), have extensive observation records relative to other similar lakes, and show sufﬁcient dynamics in the temperature proﬁles across depth over time to make them interesting test cases for analyses. Observations of lake temperature were collated from a variety of sources including Minnesota Department of Natural Resources and a web resource that collates data from federal and state agencies, academic monitoring campaigns, and citizen data [16]. These temperature observations vary in their distribution across depths and time, with some years and seasons being heavily sampled, while other time periods having little to no observations. The overall data for Mille Lacs Lake consisted of 7,072 temperature observations from 17 June 1981 to 01 Jan 2016, and the overall data for Lake Mendota consisted of 13,543 temperature observations from 30 April 1980 to 02 Nov 2015. For each observation, we used a set of 11 meteorological drivers as input variables, listed in Table 1. While many of these drivers were directly measured, we also used some domain-recommended ways of constructing derived features such as Growing Degree Days [17]. We used the General Lake Model (GLM) [14] as the physics-based approach for modeling lake temperature in our experimental studies. The GLM uses the drivers listed in Table 1 as input parameters and balances the energy and water budget of lakes or reservoirs on a daily or sub-daily timestep. It performs a 1D modeling (along depth) of a variety of lake variables (including water temperature) using a vertical Lagrangian layer scheme. 7 Apart from the labeled set of data instances where we have observations of temperature, we also considered a large set of unlabeled instances (where we do not have temperature observations) on a regular grid of depth values at discrete steps of 0.5m, and on a daily time-scale from 02 April 1980 to 01 Jan 2016 (amounting to 13,058 dates). We ran the GLM model on the unlabeled instances to produce YP HY along with the input drivers D at every unlabeled instance. Ignoring instances with missing values, this amounted to a total of 299,796 unlabeled instances in Mille Lacs Lake and 662,781 unlabeled instances in Lake Mendota. Input Drivers 1 Day of Year (1 – 366) 2 Depth (in m) 3 Short-wave Radiation (in W/m 2) 4 Long-wave Radiation (in W/m 2) 5 Air Temperature (in ◦C) 6 Relative Humidity (0 – 100 %) 7 Wind Speed (in m/s) 8 Rain (in cm) 9 Growing Degree Days [17] 10 Is Freezing (True or False) 11 Is Snowing (True or False) Table 1: Input drivers for lake temperature modeling. 4.2 Experimental Design We considered contiguous windows of time to partition the labeled data set into training and test splits, to ensure that the test set is indeed independent of the training set and the two data sets are not temporally auto-correlated. In particular, we chose the center portion of the overall time duration for testing, while the remainder time periods on both ends were used for training. For example, to construct a training set of n instances, we chose the median date in the overall data and kept on adding dates on both sides of this date for testing, till the number of observations in the remainder time periods became less than or equal to n. Using this protocol, we constructed training sets of size n = 3000 for both Mille Lacs Lake and Lake Mendota, which were used for calibrating the physics-based model, PHY, on both lakes. We used the entire set of unlabeled instances for evaluating the physics-based loss function on every lake. All neural network models used in this paper were implemented using the Keras package [18] using Tensorﬂow backend. We used the AdaDelta algorithm [19] for performing stochastic gradient descent on the model parameters of the neural network. We used a batch size of 1000 with maximum number of epochs equal to 10,000. To avoid over-ﬁtting, we employed an early stopping procedure using 10% of the training data for validation, where the value of patience was kept equal to 500. We also performed gradient clipping (for gradients with L2 norm greater than 1) to avoid the problem of exploding gradients common in regression problems (since the value of Y is unbounded). We standardized each dimension of the input attributes to have 0 mean and 1 standard deviation, and applied the same transformation on the test set. The fully-connected neural network architecture comprised of 3 hidden layers, each with 12 hidden nodes. The value of hyper-parameters λ1 and λ2 (corresponding to the L1 and L2 norms of network weights, respectively) were kept equal to 1 in all experiments conducted in the paper, to demonstrate that no special tuning of hyper-parameters was performed for any speciﬁc problem. The value of the hyper-parameter λP HY corresponding to the physics-based loss function was kept equal to std(Y 2)/std(ρ), to factor in the differences in the scales of the physics-based loss function and the mean squared error loss function. We used uniformly random initialization of neural network weights from 0 to 1. Hence, in all our experiments, we report the mean and standard deviation of evaluation metrics of every neural network method over 50 runs, each run involving a different random initialization. 4.3 Baseline Methods and Evaluation Metrics We compared the results of PGNN with the following baseline methods: 8 • PHY: The GLM models calibrated on the training sets of size n = 3000 for both lakes were used as the physics-based models, PHY. • Black-box Models: In order to demonstrate the value in incorporating the knoweldge of physics with data science models, we consider three standard non-linear regression models: support vector machine (SVM) with radial basis function (RBF) kernel, least squares boosted regression trees (LSBoost), and the neural network (NN) model. All of these models were trained to predict temperature using the same set of input drivers as PGNN, but without using any knowledge of physics (either in the form of model simulations or as physics-based loss functions). • PGNN0: In order to understand the contribution of the physics-based loss function in PGNN, we consider an intermediate product of our framework, PGNN0, as another baseline, which uses the hybrid-physics-data modeling setup described in Figure 2, but does not use the physics-based loss function in its learning objective (Equation 1). Hence, PGNN0 differs from black-box models in its use of physics-based model simulations as input attributes, and differs from PGNN in its use of a purely data-driven learning objective. We considered the following evaluation metrics for comparing the performance of different algo- rithms: • RMSE: We use the root mean squared error (RMSE) of a model on the test set as an estimate of its generalization performance. The units of this metric are in ◦C. • Physical Inconsistency: Apart from ensuring generalizability, a key contribution of PGNN is to ensure the learning of physically consistent model predictions. Hence, apart from computing the RMSE of the model on the test set, we also compute the fraction of time- steps where the model makes physically inconsistent predictions (i.e., the density-depth relationship stated in Equation 12 is violated). We report this fraction as the physical inconsistency measure in Figures 5, 6(b), and 7(a). Note that this measure does not require actual observations, and hence, we compute this measure over the plentifully large unlabeled data set. 4.4 Results Figure 5 provides a summary of the performance of different methods for modeling lake temperature on the two example lakes, Mille Lacs Lake and Lake Mendota. The X-axis in these plots represents the physical inconsistency of a model, while the Y -axis represents the RMSE of the model predictions w.r.t. observations on the test set. We also show the standard deviation around the evaluation metrics of neural network-based methods (i.e., PGNN, PGNN0, and NN), since we used random initialization of network weights for every one of the 50 runs. 0 0.2 0.4 0.6 0.8 1 Physical Inconsistency 0.5 0.75 1 1.25 1.5 1.75 2 2.25 2.5 2.75 3Test RMSE PGNN PGNN0 NN PHY SVM LSBoost (a) Results on Mille Lacs Lake 0 0.2 0.4 0.6 0.8 1 Physical Inconsistency 1.6 1.8 2 2.2 2.4 2.6 2.8 3Test RMSE PGNN PGNN0 NN PHY SVM LSBoost (b) Results on Lake Mendota Figure 5: Scatter plots showing test RMSE values (Y -axis) and physical inconsistency (X-axis) of comparative methods. Points and error bars respectively represent the mean and +/- one standard deviation from the mean of results from all 50 random weight initializations. 9 For Mille Lacs Lake, we can see from Figure 5(a) that the test RMSE of the physics-based model, PHY, is 1.69. If we use black-box data science models such as SVM and LSBoost, that try to learn non-linear relationships between drivers and temperature directly without using physics, we would end up with a test RMSE that is even higher than that of PHY. Further, they also show high physical inconsistency in their model predictions (greater than 0.8). If we instead use a black-box NN model that learns non-linear compositions of features from the space of input drivers, we can achieve a test RMSE of 1.18 that is signiﬁcantly lower than that of PHY. This provides evidence of the information contained in the driver data, which if used effectively, can help in closing the knowledge gaps of PHY. However, this improvement in RMSE comes at the cost of a large value of physical inconsistency in the model predictions of NN (almost 73% of the time-steps have inconsistent density-depth relationships in its predictions). This makes NN unﬁt for use in the process of scientiﬁc discovery, because although it is able to somewhat improve the predictions of the target variable (i.e. temperature), it is incurring large errors in capturing the physical relationships of temperature with other variables, leading to non-meaningful results. If we use the output of the physics-based model along with the drivers as inputs in the PGNN0 model, we can achieve an even lower value of test RMSE than that of NN. This is because the output of PHY (although with a high RMSE) contains vital physical information about the dynamics of lake temperature, which when coupled with powerful data science frameworks such as neural networks, can result in major improvements in RMSE. However, the results of PGNN0 are still physically inconsistent for roughly 72% of the time. In contrast, it is only by the use of physics-based loss functions in PGNN that we can not only achieve an RMSE of 0.73, but also substantially lower value of physical inconsistency (close to 0). To appreciate the signiﬁcance of a drop in RMSE of 0.96◦C, note that a lake-speciﬁc calibration approach that produced a median RMSE of 1.47◦C over 28 lakes is considered to be the state-of-the-art in the ﬁeld [20]. By being accurate as well as physically consistent, PGNN provides an opportunity to produce physically meaningful analyses of lake temperature dynamics that can be used in subsequent scientiﬁc studies. A similar summary of results can also be obtained from Figure 5(b) for Lake Mendota. We can see that the test RMSE of the physics-based model in this lake is 2.77, which is considerably higher than that of Mille Lacs Lake. This shows the relatively complex nature of temperature dynamics in Lake Mendota compared to Mille Lacs Lake, which are more difﬁcult for any model to approximate. Mille Lacs Lake is generally well-mixed (i.e. bottom temperature is similar to the surface temperature) while Lake Mendota is more stratiﬁed. The average test RMSE scores of NN and PGNN0 for Lake Mendota are 2.07 and 1.93, respectively. On the other hand, PGNN is able to achieve an average RMSE of 1.79, while being physically consistent. This is a demonstration of the added value of using physical consistency in the learning objective of data science models for improving generalization performance. 800 1250 1500 2500 3000 0.5 0.75 1 1.25 1.5 1.75 2 2.25 2.5Test RMSE Training Size PGNN PGNN0 NN PHY (a) Effect on Test RMSE 800 1250 1500 2500 3000 0 0.5 1Physical Inconsistency Training Size PGNN PGNN0 NN PHY (b) Effect on Physical Inconsistency Figure 6: Effect of varying training size on the performance of different methods on Mille Lacs Lake. Points and error bars respectively represent the mean and +/- one standard deviation from the mean of results from all 50 random weight initializations. 10 4.4.1 Effect of Varying Training Size We next demonstrate the effect of varying the size of the training set on the performance of PGNN, in comparison with other baseline methods. Figure 6 shows the variations in the test RMSE and physical inconsistency of different methods on Mille Lacs Lake, as we vary the training size from 3000 to 800. We can see from Figure 6(a) that the test RMSE values of all data science methods increase as we reduce the training size. For example, the test RMSE of the black-box model, NN, can be seen to over-shoot the test RMSE of the physics-based model for training sizes smaller than 1500. On the other hand, both PGNN and PGNN0 show a more gradual increase in their test RMSE values on reducing training size. In fact, the PGNN can be seen to provide smaller RMSE values than all baseline methods, especially at training sizes of 1250 and 1500. This is because the use of physics-based loss function ensures that the learned PGNN model is consistent with our knowledge of physics and thus is not spurious. Such a model thus stands a better chance at capturing generalizable patterns and avoiding the phenomena of over-ﬁtting, even after being trained with limited number of training samples. If we further reduce the training size to 800, the results of PGNN and PGNN0 become similar because there is not much information left in the data that can provide improvements in RMSE. While the lower RMSE values of PGNN is promising, the biggest gains in using PGNN arise from its drastically lower values of physical inconsistency as compared to other data science methods, as shown in Figure 6(b), even when the training sizes are small. Note that the results of PGNN are physically consistent across all time-steps, while PGNN0 and NN violate the density-depth relationship more than 50% of time-steps on an average. We can also see that PHY has an almost zero value of physical inconsistency, since it is inherently designed to be physically consistent. 4.4.2 Sensitivity to hyperparameter λPHY 0 10 20 50 100 200 500 1000 2000 λP HY 0.0 0.1 0.2 0.3 0.4 0.5PercentInconsistencyPGNN (a) Effect on Physical Inconsistency 0 10 20 50 100 200 500 1000 2000 λP HY 0.50 0.75 1.00 1.25 1.50 1.75 2.00 2.25 2.50TestRMSE PGNN (b) Effect on Test RMSE Figure 7: Sensitivity to hyperparameter λP HY on Mille Lacs Lake. Points and error bars respectively represent the mean and +/- one standard deviations from the mean of results from all 50 random weight initializations. To understand how the choice of the trade-off hyperparameter λP HY affects the model results, we analyse the physical inconsistency and the Test RMSE while varying λP HY (See Figure 7). With the increase in the value of λP HY , we impose a more stringent physics-constraint on the model which ultimately leads to the generation of more and more physically consistent predictions (Figure 7(a)). Simultaneously, it can be observed that the change in λP HY does not signiﬁcantly affect the Test RMSE of the learned model which is also desirable (Figure 7(b)). Ideally, with the introduction of the physics-based loss during training, we would want the model to generate more physically consistent predictions while not degrading its predictive performance. 4.4.3 Analysis of Results To provide a deeper insight into the results produced by competing methods, we analyze the predic- tions of lake temperature produced by a model as follows. As described previously, any estimate of temperature can be converted to its corresponding density estimate using the physical relationship 11 between temperature and density represented in Equation 11. Hence, on any given time-step, we can produce a proﬁle of density estimates at varying values of depth for every model, and match it with the density estimates of observed temperature on test instances. Visualizing such density proﬁles can help us understand the variations in model predictions across depth, in relationship to test observations. Some examples of density proﬁles on different dates in Mille Lacs Lake and Lake Mendota are provided in Figure 8, where the X-axis represents estimated density, and the Y -axis represents depth. In the density proﬁles of different algorithms on Mille Lacs Lake in Figure 8(a), we can see that the density estimates of PHY are removed from the actual observations by a certain amount, indicating a bias in the physics-based model. All three data science methods, NN, PGNN0, and PGNN, attempt to compensate for this bias by shifting their density proﬁles closer to the actual observations. On the three depth values where we have observations, we can see that both PGNN and PGNN0 show lower discrepancy with observations as compared to PHY. In fact, the density proﬁle of PGNN matches almost perfectly with the observations, thus demonstrating the value in using physics-based loss function for better generalizability. However, the most striking insight from Figure 8(a) is that although the density estimate of PGNN0 is reasonably close to the three observations (thus indicating a low value of test RMSE), the density estimates soon start showing physically inconsistent patterns as we move lower in depth beyond the observations. In particular, the density estimates of PGNN0 start decreasing as we increase the depth beyond 6m. This is a violation of the monotonic relationship between density and depth as illustrated in Figure 4(b). The presence of such physical inconsistencies reduces the usefulness of a model’s predictions in scientiﬁc analyses, even if the model shows low test RMSE. In contrast, the predictions of PGNN, while being closer to the actual observations, are always consistent with the monotonic relationship between density and depth. Figure 8(b) shows another example of density proﬁles on a different date in Lake Mendota. We can see that PGNN is again able to improve upon PHY and produce density estimates that are closest to the observations. On the other hand, both PGNN0 and NN shows large discrepancies with respect to the actual observations. This is because of the complex nature of relationships between the drivers and the temperature in Lake Mendota that are difﬁcult to be captured without the use of physical relationships in the learning of neural networks. Additionally, the model predictions of PGNN0 can be seen to violate the physical relationship between density and depth (density estimates of PGNN0 decrease as we increase the depth from 10m to 12m), thus further reducing our conﬁdence in PGNN0 representing physically meaningful results. 998.7 998.8 998.9 999 999.1 999.2 999.3 999.4 999.5 0 2 4 6 8 10 12 DensityDepth 02−Oct−2012 Obs PGNN PGNN0 NN PHY (a) Mille Lacs Lake on 02-October-2012 998.4 998.6 998.8 999 999.2 999.4 999.6 999.8 1000 1000.2 0 5 10 15 20 25 DensityDepth 27−May−2003 Obs PGNN PGNN0 NN PHY (b) Lake Mendota on 27-May-2003 Figure 8: Density proﬁles of varying algorithms on different dates in Mille Lacs Lake (Figure 8(a)) and Lake Mendota (Figure 8(b)). 12 (a) Residual (Res) Model (b) Hybrid-Physics-Data-Residual (HPD-Res) Model Figure 9: Alternate Hybrid-Physics-Data (HPD) model designs, where white boxes represent physics- based models while black boxes represent ML models. 5 Discussion on Alternate HPD Model Designs So far, we have demonstrated the value of hybrid-physics-data (HPD) modeling using a simple HPD design as illustrated in Figure 2), where the outputs of the physics-based model are fed into the neural network model as additional features, along with the input drivers. In this section, we discuss its relevance in the context of two alternate HPD model designs based on residual modeling techniques (see Figure 9), which are commonly used in the scientiﬁc literature to correct residuals of physics-based models using data-driven methods. The ﬁrst HPD design (Figure 9(a)), termed the “Residual Model,” uses a simple ML model fRes to ﬁx the residuals of physics-based model outputs YP HY as additive correction terms. Speciﬁcally, instead of building an ML model to directly predict the target variable Y from the input drivers D, we adopt a residual modeling strategy to predict YRes(= Y − YP HY ), which when added to YP HY provides corrected estimates of the target variable. Note that residual modeling is one of the simplest and most commonly used strategies for HPD modeling [21, 22, 23, 24, 25]. The primary motivation for building a residual model is to solve the simpler problem of estimating the residuals of a physics-based model, which are indicative of the systematic biases or equivalently the uncaptured variability of the physics-based model, instead of estimating the complete functional mapping from D to Y . The ﬁnal prediction of the target variable Y is obtained by simply adding the predicted residual YRes with the output of the physics model YP HY . In other words, a residual model can be thought of as a rectifying unit which aims to correct the predictions of the physics-based model. Another innovation in HPD design is illustrated in Figure 9(b), where the idea of residual modeling is combined with the idea of the basic HPD model described in Figure 2. In this alternate HPD design, termed the “Hybrid-Physics-Data-Residual (HPD-Res) Model,” the ML model uses both the input drivers D as well as the output of the physics-based models YP HY to predict the residuals of the physics-based model YRes. The predicted residuals are then added to YP HY to obtain the ﬁnal predictions of the target variable Y . Note that HPD-Res shares some similarity with the basic residual (Res) model, as both of them predict the residual of the physics-based model instead of directly predicting the target variable. However, the difference in HPD-Res is that it uses YP HY as additional inputs in the ML architecture, which simpliﬁes the task of learning the residuals (note that in some cases, it may be easier to identify patterns of systematic biases in the physics-based model by observing D and YP HY together). HPD-Res is also similar to the basic HPD model as both of them use D and YP HY as inputs in the ML model. However, the difference is that HPD-Res only predicts the residual YRes to be added to YP HY for deriving ﬁnal predictions of the target variable Y . Hence, HPD-Res can be viewed as a ‘fusion’ of the basic HPD and the basic Res models. 13 To empirically understand the differences between the three HPD designs: basic HPD, basic Res, and HPD-Res, we compare their performances on Lake Mendota and Mille Lacs Lake at varying training sizes in Figure 10. Note that in these experiments, we did not include the physics-based loss function in the learning objective to solely evaluate the effect of HPD designs on generalization performance (as a result, the performance of the basic HPD model here corresponds to the PGNN0 baseline). We can see that across both lakes, the HPD-Res performs slightly better than the basic HPD and the basic Residual formulations. In Lake Mendota, HPD-Res has a considerable difference in performance from HPD across all training sizes, and from Res at larger training sizes. On the other hand, in Mille Lacs Lake, the Res model performs the worst out of the three while HPD performs almost equivalently as HPD-Res. These results provide new insights on the differences between HPD model designs and suggests that further research on the choice of constructing HPD models is necessary. For example, one potential reason behind HPD-Res performing better than the basic HPD and the basic Res models is that HPD-Res combines the strengths of both these models; it uses the input drivers as well as YP HY as inputs in the ML model, and the ML output is further added to YP HY to correct its biases. Further research is needed to evaluate the validity of such claims regarding HPD model designs in different scientiﬁc problems involving a combination of physics knowledge and data. 6 Conclusions and Potential Future Work This paper presented a novel framework for learning physics-guided neural networks (PGNN), by using the outputs of physics-based model simulations as well as by leveraging physics-based loss functions to guide the learning of neural networks to physically consistent solutions. By anchoring neural network methods with scientiﬁc knowledge, we are able to show that the proposed framework not only shows better generalizability, but also produces physically meaningful results in comparison to black-box data science methods. This paper serves as a stepping stone in the broader theme of research on using physics-based learning objectives in the training of data science models. While the speciﬁc formulation of PGNN explored in this paper was developed for the example problem of modeling lake temperature, similar developments could be explored in a number of other scientiﬁc and engineering disciplines where known forms of physical relationships can be exploited as physics-based loss functions. This paper paves the way towards learning neural networks by not only improving their ability to solve a given task, but also being cognizant of the physical relationships of the model outputs with other tasks, thus producing a more holistic view of the physical problem. There are a number of directions of future research that can be explored as a continuation of this work. First, for the speciﬁc problem of lake temperature modeling, given the spatial and temporal nature of 800 1250 1500 2500 3000 Training Size 1 2 3 4 5TestRMSE HPD HPD-Res Res (a) Lake Mendota 800 1250 1500 2500 3000 Training Size 0.6 0.8 1.0 1.2 1.4 1.6 1.8TestRMSE HPD HPD-Res Res (b) Mille Lacs Lake Figure 10: Comparing the performance of different hybrid-physics-data (HPD) model designs on Mille Lacs Lake and Lake Mendota at varying training sizes. Points and error bars respectively represent the mean and +/- one standard deviations from the mean of results from all 50 random weight initializations. The HPD model here corresponds to PGNN0 in Fig. 5. Note that mean and standard deviations also vary from Fig. 5 due to different random weight initializations, and different versions of the Keras library used. 14 the problem domain, a natural extension would be to exploit the spatial and temporal dependencies in the test instances, e.g., by using recurrent neural network based architectures. Second, the analysis of the physically consistent model predictions produced by PGNN could be used to investigate the modeling deﬁciencies of the baseline physics-based model in detail. Third, while this paper presented a simple way of constructing hybrid-physics-data (HPD) models where YP HY was ingested as an input in the data science model, more complex ways of constructing HPD models where the physics-based and data science components are tightly coupled need to be explored. Fourth, theoretical analyses studying the impact of introducing physics-based loss functions on the sample complexity or convergence guarantees need to be investigated. Fifth, the research direction of PGNN can be complemented with other related efforts on producing interpretable data science results. In particular, the use of physics-based equations for interpreting the results of data science methods needs to be explored. Finally, while this paper explored the use of physical relationships between temperature, density, and depth of water in the learning of multi-layer perceptrons, other forms of physical relationships in different neural network models can be explored as future work. Of particular value would be to develop generative models that are trained to not only capture the structure in the unlabeled data, but are also guided by physics-based models to discover and emulate the known laws of physics. The paradigm of PGNN, if effectively utilized, could help in combining the strengths of physics-based and data science models, and opening a novel era of scientiﬁc discovery based on both physics and data. Disclaimer: Any use of trade, ﬁrm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government. References [1] Tim Appenzeller. The scientists’ apprentice. Science, 357(6346):16–17, 2017. [2] D Graham-Rowe, D Goldston, C Doctorow, M Waldrop, C Lynch, F Frankel, R Reid, S Nelson, D Howe, SY Rhee, et al. Big data: science in the petabyte era. Nature, 455(7209):8–9, 2008. [3] TO Jonathan, AM Gerald, et al. Special issue: dealing with data. Science, 331(6018):639–806, 2011. [4] Terrence J Sejnowski, Patricia S Churchland, and J Anthony Movshon. Putting big data to good use in neuroscience. Nature neuroscience, 17(11):1440–1441, 2014. [5] Hoshin V Gupta and Grey S Nearing. Debates—the future of hydrological sciences: A (common) path forward? using models and data to learn: A systems theoretic perspective on the future of hydrological science. Water Resources Research, 50(6):5351–5359, 2014. [6] Upmanu Lall. Debates—the future of hydrological sciences: A (common) path forward? one water. one world. many climes. many souls. Water Resources Research, 50(6):5335–5341, 2014. [7] Jeffrey J McDonnell and Keith Beven. Debates—the future of hydrological sciences: A (common) path forward? a call to action aimed at understanding velocities, celerities and residence time distributions of the headwater hydrograph. Water Resources Research, 50(6): 5342–5350, 2014. [8] John J Magnuson, Larry B Crowder, and Patricia A Medvick. Temperature as an ecological resource. American Zoologist, 19(1):331–343, 1979. [9] James J Roberts, Kurt D Fausch, Douglas P Peterson, and Mevin B Hooten. Fragmentation and thermal risks from climate change interact to affect persistence of native trout in the colorado river basin. Global Change Biology, 19(5):1383–1398, 2013. [10] Frank J Rahel and Julian D Olden. Assessing the effects of climate change on aquatic invasive species. Conservation biology, 22(3):521–533, 2008. [11] James J Roberts, Kurt D Fausch, Mevin B Hooten, and Douglas P Peterson. Nonnative trout invasions combined with climate change threaten persistence of isolated cutthroat trout populations in the southern rocky mountains. North American Journal of Fisheries Management, 37(2):314–325, 2017. 15 [12] Ted D Harris and Jennifer L Graham. Predicting cyanobacterial abundance, microcystin, and geosmin in a eutrophic drinking-water reservoir using a 14-year dataset. Lake and Reservoir Management, 33(1):32–48, 2017. [13] Hans W Paerl and Jef Huisman. Blooms like it hot. Science, 320(5872):57–58, 2008. [14] MR Hipsey, LC Bruce, and DP Hamilton. Glm—general lake model: Model overview and user information. Perth (Australia): University of Western Australia Technical Manual, 2014. [15] James L Martin and Steven C McCutcheon. Hydrodynamics and transport for water quality modeling. CRC Press, 1998. [16] Emily K Read, Lindsay Carr, Laura De Cicco, Hilary A Dugan, Paul C Hanson, Julia A Hart, James Kreft, Jordan S Read, and Luke A Winslow. Water quality data for national-scale aquatic research: The water quality portal. Water Resources Research, 53(2):1735–1745, 2017. [17] I Colin Prentice, Wolfgang Cramer, Sandy P Harrison, Rik Leemans, Robert A Monserud, and Allen M Solomon. Special paper: a global biome model based on plant physiology and dominance, soil properties and climate. Journal of biogeography, pages 117–134, 1992. [18] François Chollet. keras. https://github.com/fchollet/keras, 2015. [19] Matthew D Zeiler. Adadelta: an adaptive learning rate method. arXiv preprint arXiv:1212.5701, 2012. [20] Xing Fang, Shoeb R Alam, Heinz G Stefan, Liping Jiang, Peter C Jacobson, and Donald L Pereira. Simulations of water quality and oxythermal cisco habitat in minnesota lakes under past and future climate scenarios. Water Quality Research Journal, 47(3-4):375–388, 2012. [21] Urban Forssell and Peter Lindskog. Combining semi-physical and neural network modeling: An example oﬁts usefulness. IFAC Proceedings Volumes, 30(11):767–770, 1997. [22] Michael L Thompson and Mark A Kramer. Modeling chemical processes using prior knowledge and neural networks. AIChE Journal, 40(8):1328–1340, 1994. [23] Omer San and Romit Maulik. Machine learning closures for model order reduction of thermal ﬂuids. Applied Mathematical Modelling, 60:681–710, 2018. [24] Omer San and Romit Maulik. Neural network closures for nonlinear model order reduction. Advances in Computational Mathematics, 44(6):1717–1750, 2018. [25] Zhong Yi Wan, Pantelis Vlachas, Petros Koumoutsakos, and Themistoklis Sapsis. Data-assisted reduced-order modeling of extreme events in complex dynamical systems. PloS one, 13(5): e0197704, 2018. 16","libVersion":"0.3.2","langs":""}