{"path":"lit/lit_sources/papers_to_add/papers_to_markup_over_weekend/Scolnik16binPredAccIncAndOpt_PhD.pdf","text":"Florida State University Libraries 2016 Follow this and additional works at the FSU Digital Library. For more information, please contact lib-ir@fsu.edu FLORIDA STATE UNIVERSITY COLLEGE OF ARTS AND SCIENCES PREDICTIVE ACCURACY MEASURES FOR BINARY OUTCOMES: IMPACT OF INCIDENCE RATE AND OPTIMIZATION TECHNIQUES By RYAN SCOLNIK A Dissertation submitted to the Department of Statistics in partial fulﬁllment of the requirements for the degree of Doctor of Philosophy 2016 Copyright c⃝ 2016 Ryan Scolnik. All Rights Reserved. Ryan Scolnik defended this dissertation on April 8, 2016. The members of the supervisory committee were: Daniel McGee Professor Co-Directing Thesis Elizabeth Slate Professor Co-Directing Thesis Isaac Eberstein University Representative Fred Huﬀer Committee Member The Graduate School has veriﬁed and approved the above-named committee members, and certiﬁes that the dissertation has been approved in accordance with university requirements. ii To my family and friends. iii ACKNOWLEDGMENTS I would like to thank my major advisors, Dr. Daniel McGee and Dr. Elizabeth Slate. They provided tremendous support throughout my research and helped guide me when the road ahead seemed unclear. They have also provided outstanding advice in my career search and been available for a conversation on any subject at any time. Additionally, I would like to thank the two other members of my committee, Dr. Fred Huﬀer and Dr. Isaac Eberstein, who have also been helpful and available during my time at Florida State University. The support staﬀ in the statistics department also deserves acknowledgement. Without them, my experience would have been completely diﬀerent. Lastly, I would like to thank all of the faculty in the statistics department. I have learned so much in a wide variety of topics. iv TABLE OF CONTENTS List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii 1 Introduction 1 1.1 Background and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Logistic Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.3 Maximizing the Likelihood Equation for Logistic Regression . . . . . . . . . . . . . . 3 2 Predictive Accuracy Measures 5 2.1 Log-Loss (LogLoss) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.2 Area Under the Receiver Operating Curve (AU C) . . . . . . . . . . . . . . . . . . . 5 2.3 Brier Score (BS) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.4 Discrimination Slope (DS) and Integrated Discrimination Improvement (IDI) . . . 8 2.5 Coeﬃcient of Determination (R2) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.6 F-Score (Fβ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 3 Data Analysis using Real and Simulated Data 11 3.1 Simulation Study of the Relationship among Measures . . . . . . . . . . . . . . . . . 11 3.1.1 Results from Simulation Study . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.2 Using Real Data to Study the Relationship among Measures . . . . . . . . . . . . . . 14 3.2.1 Results from Real Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 15 3.3 Analysis of Relationships among Measures . . . . . . . . . . . . . . . . . . . . . . . . 17 3.3.1 Relationship between Brier Score and Log-Loss . . . . . . . . . . . . . . . . . 17 3.3.2 Relationship between R2 and Discrimination Slope . . . . . . . . . . . . . . . 18 3.3.3 Relationship between R2 and Brier Score . . . . . . . . . . . . . . . . . . . . 18 3.3.4 Relationship Between AU C and Other Measures . . . . . . . . . . . . . . . . 19 3.4 Impact of Incidence on the Measures . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 3.4.1 Second Simulation Study of the Relationships Under Various Incidence Rates 21 3.4.2 Brier Score and Incidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 3.4.3 Meta-regression using Area Under the ROC Curve and Incidence . . . . . . . 27 4 Relationships Under Binormal Settings 29 4.1 Deﬁnition of Binormal Setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 4.2 Binormal ROC Curve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 4.3 Brier Score in Binormal Setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 4.4 Relationships . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 4.4.1 Under General Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 4.4.2 Under Low Incidence Rate Settings . . . . . . . . . . . . . . . . . . . . . . . . 35 4.5 Simulation Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 4.5.1 Relationships Under General Settings . . . . . . . . . . . . . . . . . . . . . . 37 v 4.5.2 Relationships Under Low Incidence Rate Settings . . . . . . . . . . . . . . . . 38 5 Maximization/Minimization of Predictive Accuracy Measures 40 5.1 Maximization and Minimization Algorithms . . . . . . . . . . . . . . . . . . . . . . . 40 5.1.1 Newton-Raphson Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 5.1.2 Nelder-Mead Simplex Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 41 5.2 Predictive Accuracy Measures as Functions of β . . . . . . . . . . . . . . . . . . . . . 42 5.2.1 Log-Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 5.2.2 Brier Score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 5.2.3 Area Under the ROC Curve . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 5.3 Simulation Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 5.3.1 Simulation I: Two Normal Covariates and Standard Incidence Rate . . . . . . 48 5.3.2 Simulation II: Two Normal Covariates and Low Incidence Rate . . . . . . . . 51 5.3.3 Simulation III: One Continuous and One Binary Covariate . . . . . . . . . . 52 5.4 Use of Optimization Routines on Real Data . . . . . . . . . . . . . . . . . . . . . . . 56 5.4.1 Framingham Oﬀspring Cohort (FOC) and Data . . . . . . . . . . . . . . . . . 56 5.4.2 Logistic Regression on the FOC Data . . . . . . . . . . . . . . . . . . . . . . 56 5.4.3 Optimizing the Log-Loss on the FOC Data . . . . . . . . . . . . . . . . . . . 57 5.4.4 Optimizing the Brier Score on the FOC Data . . . . . . . . . . . . . . . . . . 58 5.4.5 Optimizing the AUC on the FOC Data . . . . . . . . . . . . . . . . . . . . . 58 5.4.6 Summary of Estimated Coeﬃcients and Predictive Accuracy Measures . . . . 59 5.4.7 Optimizing the AUC on the Original 55 Data Sets . . . . . . . . . . . . . . . 59 6 Consistency and Asymptotic Behavior of the Coeﬃcient Estimates from the AUCRanks Optimization 63 6.1 Relationship to the Maximum Rank Correlation Estimator . . . . . . . . . . . . . . 63 6.1.1 Consistency and Distribution of the Maximum Rank Correlation Estimator . 63 6.2 Other Rank Estimators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 6.2.1 Consistency and Distribution of the AUCRanks Estimator . . . . . . . . . . . 65 6.3 Estimating the Variation in the Estimators . . . . . . . . . . . . . . . . . . . . . . . 69 7 Determining the Uncertainty in Optimization Results 73 7.1 Calculating Standard Errors on Simulated Data . . . . . . . . . . . . . . . . . . . . . 73 7.2 Calculating Standard Errors on FOC Data . . . . . . . . . . . . . . . . . . . . . . . . 75 8 Case Study: Boston Housing Data 77 8.1 Boston Housing Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 8.2 Two Parameter Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 8.3 Comparing Two AUCs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 8.4 Evaluating the Impact of Adding a Variable . . . . . . . . . . . . . . . . . . . . . . . 79 9 Discussion and Future Work 81 9.1 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 9.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 vi Appendix A IRB Clearance 85 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90 Biographical Sketch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94 vii LIST OF TABLES 3.1 Correlation Among the Measures in Simulation Study. . . . . . . . . . . . . . . . . . . 12 3.2 Summary Statistics for the Measures in Simulation Study. . . . . . . . . . . . . . . . . 12 3.3 Results from Simulation Study. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 3.4 Results from Real Data Analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 3.5 Correlation Among the Metrics in Real Data. . . . . . . . . . . . . . . . . . . . . . . . 17 3.6 Correlation Among the Metrics in Studies with Prevalence < 10% (n = 41). . . . . . . 20 3.7 Correlation Among the Metrics in Studies with Prevalence between 10% and 50% (n = 14). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.8 Summary Statistics for Incidence Rate for Each Choice of β0. . . . . . . . . . . . . . . 24 3.9 Correlation Among the Measures from Simulation Study II (β0=0). . . . . . . . . . . 24 3.10 Correlation Among the Measures from Simulation Study II (β0=−1). . . . . . . . . . 25 3.11 Correlation Among the Measures from Simulation Study II (β0=−2). . . . . . . . . . 25 3.12 Correlation Among the Measures from Simulation Study II (β0=−4). . . . . . . . . . 25 3.13 Correlation Among Measures for each Choice of β0. . . . . . . . . . . . . . . . . . . . 25 3.14 Meta-Analysis Results. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 4.1 Correlation Among the Measures in a Binormal Setting. . . . . . . . . . . . . . . . . . 37 4.2 Correlation Among the Measures in a Low Incidence Binormal Setting. . . . . . . . . 39 5.1 An Example of the Mann-Whitney U Statistic. . . . . . . . . . . . . . . . . . . . . . . 44 5.2 Results from Logistic Regression Model in Simulation I. . . . . . . . . . . . . . . . . . 48 5.3 Results from Minimizing the Log-Loss in Simulation I. . . . . . . . . . . . . . . . . . . 49 5.4 Results from Minimizing the Brier Score in Simulation I. . . . . . . . . . . . . . . . . 49 5.5 Results from Maximizing the AUCRanks in Simulation I. . . . . . . . . . . . . . . . . 49 5.6 Calculated Predictive Accuracy Measures in Simulation I for Each Optimization Routine. 50 5.7 Sum of Predicted Probabilities in Simulation I for the Optimization Routines. . . . . 50 viii 5.8 Results from Minimizing the Log-Loss in Simulation II. . . . . . . . . . . . . . . . . . 51 5.9 Results from Minimizing the Brier Score in Simulation II. . . . . . . . . . . . . . . . . 51 5.10 Results from Maximizing the AUCRanks in Simulation II. . . . . . . . . . . . . . . . . 51 5.11 Calculated Predictive Accuracy Measures in Simulation II for Each Optimization Rou- tine. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 5.12 Sum of Predicted Probabilities in Simulation II for the Optimization Routines. . . . . 52 5.13 Sample Data Including a Binary Covariate. . . . . . . . . . . . . . . . . . . . . . . . . 53 5.14 Results from Logistic Regression Model in Simulation III. . . . . . . . . . . . . . . . . 54 5.15 Results from Minimizing the Log-Loss in Simulation III. . . . . . . . . . . . . . . . . . 54 5.16 Results from Minimizing the Brier Score in Simulation III. . . . . . . . . . . . . . . . 55 5.17 Results from Maximizing the AUCRanks in Simulation III. . . . . . . . . . . . . . . . 55 5.18 Calculated Predictive Accuracy Measures in Simulation III for Each Optimization Routine. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 5.19 Results from Logistic Regression Model on FOC Data. . . . . . . . . . . . . . . . . . . 57 5.20 Predictive Accuracy Measures on FOC Data from Logistic Regression Model. . . . . . 57 5.21 Results from Minimizing the Log-Loss on FOC Data. . . . . . . . . . . . . . . . . . . 57 5.22 Results from Minimizing the Brier Score on FOC Data. . . . . . . . . . . . . . . . . . 58 5.23 Results from Maximizing the AUC on FOC Data. . . . . . . . . . . . . . . . . . . . . 58 5.24 Results from Maximizing the AUC on FOC Data with Comparisons. . . . . . . . . . . 58 5.25 Coeﬃcient Estimates for the FOC Data. . . . . . . . . . . . . . . . . . . . . . . . . . . 59 5.26 Calculated Predictive Accuracy Measures on FOC Data for Each Optimization Routine. 59 5.27 Comparison of the Coeﬃcient Estimates for the 55 Data Sets. . . . . . . . . . . . . . 61 5.28 Comparison of the AUC for the 55 Data Sets. . . . . . . . . . . . . . . . . . . . . . . . 62 6.1 Results from Studies with Incidence Rate Near 50%. . . . . . . . . . . . . . . . . . . . 67 6.2 Results from Studies with Incidence Rate Near 2.5%. . . . . . . . . . . . . . . . . . . 69 7.1 Coeﬃcients and Standard Errors from Logistic Regression Model. . . . . . . . . . . . 74 7.2 Coeﬃcients and Standard Errors from Optimizing the Log-Loss. . . . . . . . . . . . . 74 ix 7.3 Coeﬃcients and Standard Errors from Optimizing the Brier Score. . . . . . . . . . . . 74 7.4 Coeﬃcients and Standard Errors from Optimizing the AUCRanks. . . . . . . . . . . . 74 7.5 Results from Logistic Regression Model on FOC Data. . . . . . . . . . . . . . . . . . . 75 7.6 Coeﬃcients and Standard Errors from Optimizing the Log-Loss on FOC Data. . . . . 76 7.7 Coeﬃcients and Standard Errors from Optimizing the Brier Score on FOC Data. . . . 76 7.8 Coeﬃcients and Standard Errors from Optimizing the AUCRanks on FOC Data. . . . 76 8.1 A subset of the Boston Housing Data. . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 8.2 Results from Logistic Regression Model on Boston Housing Data. . . . . . . . . . . . 78 8.3 Results from Maximizing the AUC on Boston Housing Data. . . . . . . . . . . . . . . 78 8.4 Results from Logistic Regression Model w/NOX on Boston Housing Data. . . . . . . . 79 8.5 Results from Maximizing the AUC with NOX variable included. . . . . . . . . . . . . 80 x LIST OF FIGURES 2.1 Sample ROC Curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2.2 Side-by-side Boxplots of Predicted Probabilities. . . . . . . . . . . . . . . . . . . . . . 8 3.1 Scatter Plot of the Measures from Simulated Data. . . . . . . . . . . . . . . . . . . . . 14 3.2 Scatter Plot of the Measures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 3.3 Bubble Plot of AUC versus Log-Loss sized by Incidence. . . . . . . . . . . . . . . . . . 19 3.4 Plot of Log-Loss versus Discrimination Slope grouped by Incidence. . . . . . . . . . . 20 3.5 Scatter Plot of the Measures from Simulation Study II (β0=0). . . . . . . . . . . . . . 22 3.6 Scatter Plot of the Measures from Simulation Study II (β0=-1). . . . . . . . . . . . . 23 3.7 Scatter Plot of the Measures from Simulation Study II (β0=−2). . . . . . . . . . . . . 23 3.8 Scatter Plot of the Measures from Simulation Study II (β0=−4). . . . . . . . . . . . . 24 4.1 Brier Score versus AUC for ﬁxed b. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 4.2 R2 versus AUC for ﬁxed b. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 4.3 Brier Score versus R2 for ﬁxed b. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 4.4 Brier Score versus AUC for ﬁxed a. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 4.5 R2 versus AUC for ﬁxed a. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 4.6 Brier Score versus R2 for ﬁxed a. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 4.7 Binormal Setting for a = 1 and α = 0.5. . . . . . . . . . . . . . . . . . . . . . . . . . . 34 4.8 Binormal Distributions of X|Y = 1 and X|Y = 0 for a = 1 b = 1 α = 0.5. . . . . . . . 34 4.9 Binormal Distributions of X|Y = 1 and X|Y = 0 for a = 1 b = 0.5 α = 0.5. . . . . . . 34 4.10 Binormal Distributions of X|Y = 1 and X|Y = 0 for a = 1 b = 3 α = 0.5. . . . . . . . 34 4.11 Brier Score versus AUC for ﬁxed a and α = 0.5. . . . . . . . . . . . . . . . . . . . . . 35 4.12 Brier Score versus AUC for ﬁxed a and α = 0.02. . . . . . . . . . . . . . . . . . . . . . 35 4.13 Brier Score versus AUC for ﬁxed b and α = 0.5. . . . . . . . . . . . . . . . . . . . . . 36 4.14 Brier Score versus AUC for ﬁxed b and α = 0.02. . . . . . . . . . . . . . . . . . . . . . 36 xi 4.15 Relationships Among the Predictive Accuracy Measures in a Binormal Setting. . . . . 38 4.16 Relationships Among the Predictive Accuracy Measures in a Low Incidence Binormal Setting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 5.1 3D plot of the AUCRanks as a function of β1 and β2 using the simulated data. . . . . 46 5.2 Heat map of the AUCRanks as a function of β1 and β2 using the simulated data. . . . 47 6.1 Histogram of ˆβ1, N = 500, ¯α = 0.500. . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 6.2 Histogram of ˆβ1, N = 1, 000, ¯α = 0.500. . . . . . . . . . . . . . . . . . . . . . . . . . . 66 6.3 Histogram of ˆβ1, N = 5, 000, ¯α = 0.500. . . . . . . . . . . . . . . . . . . . . . . . . . . 66 6.4 Histogram of ˆβ1, N = 10, 000, ¯α = 0.500. . . . . . . . . . . . . . . . . . . . . . . . . . 66 6.5 Histogram of ˆβ2, N = 500, ¯α = 0.500. . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 6.6 Histogram of ˆβ2, N = 1, 000, ¯α = 0.500. . . . . . . . . . . . . . . . . . . . . . . . . . . 67 6.7 Histogram of ˆβ2, N = 5, 000, ¯α = 0.500. . . . . . . . . . . . . . . . . . . . . . . . . . . 67 6.8 Histogram of ˆβ2, N = 10, 000, ¯α = 0.500. . . . . . . . . . . . . . . . . . . . . . . . . . 67 6.9 Histogram of ˆβ1, N = 500, ¯α = 0.0259. . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 6.10 Histogram of ˆβ1, N = 1, 000, ¯α = 0.0259. . . . . . . . . . . . . . . . . . . . . . . . . . 68 6.11 Histogram of ˆβ1, N = 5, 000, ¯α = 0.0259. . . . . . . . . . . . . . . . . . . . . . . . . . 68 6.12 Histogram of ˆβ1, N = 10, 000, ¯α = 0.0260. . . . . . . . . . . . . . . . . . . . . . . . . . 68 6.13 Histogram of ˆβ2, N = 500, ¯α = 0.0259. . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 6.14 Histogram of ˆβ2, N = 1, 000, ¯α = 0.0259. . . . . . . . . . . . . . . . . . . . . . . . . . 68 6.15 Histogram of ˆβ2, N = 5, 000, ¯α = 0.0259. . . . . . . . . . . . . . . . . . . . . . . . . . 69 6.16 Histogram of ˆβ2, N = 10, 000, ¯α = 0.0259. . . . . . . . . . . . . . . . . . . . . . . . . . 69 6.17 Histogram of ˆβ1 that maximizes the AUC in the simulated data. . . . . . . . . . . . . 70 6.18 Histogram of ˆβ2 that maximizes the AUC in simulated data. . . . . . . . . . . . . . . 70 6.19 Histogram of βchol that maximizes the AUC in the FOC data. . . . . . . . . . . . . . 71 6.20 Histogram of βage that maximizes the AUC in the FOC data. . . . . . . . . . . . . . . 71 6.21 Histogram of βsbp that maximizes the AUC in the FOC data. . . . . . . . . . . . . . . 71 xii ABSTRACT Evaluating the performance of models predicting a binary outcome can be done using a variety of measures. While some measures intend to describe the model’s overall ﬁt, others more accurately describe the model’s ability to discriminate between the two outcomes. If a model ﬁts well but doesn’t discriminate well, what does that tell us? Given two models, if one discriminates well but has poor ﬁt while the other ﬁts well but discriminates poorly, which of the two should we choose? The measures of interest for our research include the area under the ROC curve, Brier Score, discrimination slope, Log-Loss, R2 and Fβ. To examine the underlying relationships among all of the measures, real data and simulation studies are used. The real data comes from multiple cardiovascular research studies and the simulation studies are run under general conditions and also for incidence rates ranging from 2% to 50%. The results of these analyses provide insight into the relationships among the measures and raise concern for scenarios when the measures may yield diﬀerent conclusions. The impact of incidence rate on the relationships provides a basis for exploring alternative maximization routines to logistic regression. While most of the measures are easily optimized using the Newton-Raphson algorithm, the max- imization of the area under the ROC curve requires optimization of a non-linear, non-diﬀerentiable function. Usage of the Nelder-Mead simplex algorithm and close connections to economics research yield unique parameter estimates and general asymptotic conditions. Using real and simulated data to compare optimizing the area under the ROC curve to logistic regression further reveals the impact of incidence rate on the relationships, signiﬁcant increases in achievable areas under the ROC curve and diﬀerences in conclusions about including a variable in a model. xiii CHAPTER 1 INTRODUCTION 1.1 Background and Motivation In many industries there exist scenarios where one wishes to model a dichotomous outcome. As examples, a bank is interested in whether a new customer will default on a loan and a marketing company wants to know if a customer will respond to a certain advertisement. Regardless of the scenario or industry, an important aspect of modeling data includes a thorough evaluation of the model’s predictive accuracy. There are various methodologies and measures used in practice, and David Hand is correct by saying: “All too often, however, there is a mismatch between the criterion used to choose the model, the criterion used to evaluate its performance, and the criterion which actually matters in real application” [15]. To better understand this quote, a comparison of two popular modeling techniques can be examined. The ﬁrst, simple linear regression, will demonstrate a scenario in which the all the criterion are aligned and can be thought of as consistent. The second, simple logistic regression, will violate this consistency and provide motivation to understand the impacts of various choices. In simple linear regression, the most popular method of ﬁtting a model is through maximizing the likelihood equation. Under the assumption of normality in the error terms, the solutions for the coeﬃcients in the model have a closed form that is easily calculated. Performing step-wise variable selection is most commonly done using AIC or BIC; both of which are functions of the likelihood equation. Lastly, to evaluate the model’s performance, the most popular measure that is calculated is the sum of the squared diﬀerences between the predicted and observed values. Conveniently, the solutions for the coeﬃcients that minimize the sum of the squared diﬀerences are exactly the same that maximize the likelihood. Therefore, in linear regression, there is complete consistency among each of the steps - everything is a function of the likelihood equation. Unfortunately, in logistic regression this consistency is not observed. Similar to linear regression, the model ﬁtting is completed by maximizing the likelihood equation and the variable selection is done using a function of the likelihood (deviance is commonly used to select variables). However, 1 for model evaluation the standard measure reported is the area under the ROC curve - a measure with no apparent relationship to the likelihood. This is clearly a violation of consistency throughout the modeling process and a great example of what David Hand is referring to in his quote. Predictive accuracy measures other than the area under the ROC curve for use in evaluating models for binary outcomes include the Brier Score, Log-Loss, Discrimination Slope, R2 and F- score. Of these, some are functions of the likelihood and can provide the consistency seen in the linear regression scenario. However, with such a wide variety, it is important to understand the relationships among the various predictive accuracy measures and the impact of choosing one over another on the overall analysis and conclusions. 1.2 Logistic Regression Logistic regression is a common method used to model data with a binary response variable and will be used throughout this study. However, all of the evaluation measures used in this paper can be applied to other modeling techniques as well. All simulations and models will be built in SAS 9.4 using proc logistic and parameter estimates will be found using maximum likelihood methods. For consistency in notation, the following will be used in the deﬁnitions below: for the ith record, yi is the true value of the response, ˆyi is the predicted value of the response, and xij is the value of the jth independent variable. The model parameter estimates are represented by ˆβj for the jth independent variable (and j = 0 for the intercept). Using the above notation and assuming k independent variables, the logistic model can be written as shown in 1.1. Note that 0 ≤ ˆyi ≤ 1 represents Pr(yi = 1|X ̃ ) ˆyi = 1 1 + e−( ˆβ0+ ˆβ1xi1+...+ ˆβkxik) (1.1) The parameters in the logistic regression model, ˆβ0 through ˆβk, are estimated by maximizing the likelihood equations for logistic regression. The method of maximum likelihood will result in values for the parameters that maximize the probability of obtaining the observed data set that was used for modeling [17]. The likelihood function can be seen below in 1.2. L(β0, ..., βk) = n∏ i=1 ( 1 1 + e−(β0+β1xi1+...+βkxik) )yi(1 − 1 1 + e−(β0+β1xi1+...+βkxik) )1−yi (1.2) 2 Complete derivation of the parameter estimates that maximize the log likelihood are shown in the following section. It is important to note that although the model is built using the likelihood equation, the evaluation measures may not use any information from the likelihood equation. 1.3 Maximizing the Likelihood Equation for Logistic Regression The complete likelihood equation can be expressed as L(β) = n∏ i=1 ( 1 1 + e−(β0+β1xi1+...+βkxik) )yi(1 − 1 1 + e−(β0+β1xi1+...+βkxik) )1−yi To simplify the notation, we will use πi in the likelihood equation πi = 1 1 + e−(β0+β1xi1+...+βkxik) which will simplify the likelihood equation to n∏ i=1 πyi i (1 − πi)1−yi Taking the derivative of a product is diﬃcult, so one may look at the log-likelihood. l(β) = n∑ i=1 yiln(πi) + (1 − yi)ln(1 − πi) Using multiplicative distribution, this formula can be rewritten as n∑ i=1 yi(ln(πi) − ln(1 − πi)) + ln(1 − πi) With basic logrithmic rules this formula can now be written as n∑ i=1 yiln ( πi 1 − πi ) + ln(1 − πi) A general property of the logistic function πi is that ln ( πi 1 − πi ) = β0 + ... + βkxik Using this property further simpliﬁcation can be completed in the log likelihood equation. n∑ i=1 yi(β0 + ... + βkxik) + ln(1 − πi) 3 Also, using the general logistic function property it can be shown that ln(1 − πi) = −ln(eβ0+...+βkxik + 1) which leaves the ﬁnal ”simpliﬁed” log-likelihood equation to be l(β) = n∑ i=1 yi(β0 + ... + βkxik) − ln(eβ0+...+βkxik + 1) Now one must take the deriviative of the log-likelihood with respect to each β in order to ﬁnd the system of equations used to maximize the log-likelihood (where xij is equal to 1 for j = 0). ∂l(β) ∂βj = n∑ i=1 yixij − πixij The k + 1 estimating equations for β0 through βk are: For β0: n∑ i=1 [yi − 1 1 + e−(β0+β1xi1+...+βkxik) ] = 0 and for βj (j = 1, 2, ..., k): n∑ i=1 xij [yi − 1 1 + e−(β0+β1xi1+...+βkxik) ] = 0 It should be noted that the likelihood equations do not yield a closed form solution of estimates for β0 through βk so numerical methods, most often the Newton-Raphson algorithm, are used to establish the estimates. 4 CHAPTER 2 PREDICTIVE ACCURACY MEASURES 2.1 Log-Loss (LogLoss) Since the estimates of the parameters in the logistic regression model are estimated by maximiz- ing the likelihood equation, a natural measure of model performance is the value of the likelihood function. In practice, the log of the likelihood equation is used for simplicity. For logistic regression, the formula for the log-likelihood function (LL) is shown in 2.1. Although the scale of the log- likelihood function is signiﬁcantly diﬀerent from other metrics (−∞ to 0), the objective in ﬁtting a model is to maximize the likelihood and therefore larger values of the log-likelihood function are better than smaller ones when evaluating model ﬁt. LL = n∑ i=1 {yi ∗ ln(ˆyi) + (1 − yi) ∗ ln(1 − ˆyi)} (2.1) The log-likelihood is a function of the number of observations in a data set (O(n)) and therefore in its current form, would be an invalid measure to compare across diﬀerent data sets. To address this issue, the average log-likelihood is more appropriate when comparing values across diﬀerent studies. Additionally, since the log-likelihood is always less than or equal to zero, a negative term is included to ensure positive values for the predictive accuracy measure. Finally, the Log-Loss, shown in equation 2.2, can be thought of the negative average contribution by each observation to the overall log-likelihood value. LogLoss = − 1 n n∑ i=1 yi ∗ ln(ˆyi) + (1 − yi) ∗ ln(1 − ˆyi) (2.2) 2.2 Area Under the Receiver Operating Curve (AU C) When predicting a dichotomous outcome, it is sometimes useful to classify the predicted proba- bilities into events or non-events using a cut-oﬀ value. All observations above the cut-oﬀ value are classiﬁed as events and all observations below the cut-oﬀ value are classiﬁed as non-events. Using 5 the newly deﬁned classiﬁcations, two important measures can be calculated: sensitivity and speci- ﬁcity. The sensitivity is the proportion of correctly identiﬁed events out of all known true events. Speciﬁcity is the proportion of correctly identiﬁed non-events out of all known true non-events. Both sensitivity and speciﬁcity are a function of the cut-oﬀ value and can range from 0 to 1. The Receiver Operating Characteristic (ROC) curve is created by plotting the sensitivity and one minus the speciﬁcity at diﬀerent cut-oﬀ points. A sample ROC curve can be seen in ﬁgure 2.1. One of the extreme points of the graph, 0.00 for sensitivity and 0.00 for one minus the speciﬁcity is when the cut-oﬀ point is 1, meaning all observations are marked as non-events. The other extreme point of the graph, 1.00 for sensitivity and 1.00 for one minus the speciﬁcity is when the cut-oﬀ point is 0, and all observations are classiﬁed as events. Figure 2.1: Sample ROC Curve. What is used for evaluation in practice is the area under the ROC curve (AU C). It is a measure of discrimination, meaning how well the model can separate the two outcomes of interest, and is the most popular measure in cardiovascular literature used to evaluate model ﬁt [11]. A common interpretation of the AU C is “the probability that given two subjects, one who will develop an event and the other who will not, the model will assign a higher probability of an event to the former” [31]. As such, the value of the AU C ranges from 0 (no discriminate ability) to 1 (perfect discrimination). 6 There are many formulas that can be used to calculate the AU C, however one only needs the ranking of the predicted probabilities, not the values themselves for most of the equations. For example, given that the predicted probabilities for the n1 events are ordered from ˆy1+ to ˆyn1+ and the predicted probabilities for the n0 non-events are ordered from ˆy1− to ˆyn0− the formula in equation 2.3 can be used to calculate the AU C. AU C = n1∑ i=1 n0∑ j=1 I(ˆyi+ > ˆyj−) n1 ∗ n0 (2.3) 2.3 Brier Score (BS) The Brier Score (BS) was originally developed to evaluate the performance of weather forecasts [6] but can be used in any scenario with predicted probabilities for categorical events. Although an equation exists to accommodate more than two classes in the outcome variable, the most common form of the Brier Score is shown in 2.4. The Brier Score in a dichotomous outcome setting can take values between 0 (best possible) and 1 (worst possible). BS = 1 n n∑ i=1(ˆyi − yi)2 (2.4) Although in its simplest form, the Brier Score is the sum of squared distances between predicted and true values, the Brier Score can also be represented as a sum of a calibration component and a reﬁnement component. The calibration component is a simple measure of how well the predicted probabilities agree with the true event probability. The reﬁnement component is a measure of the likeness of true outcome for observations with the same predicted probability [4]. Assuming the following: the ˆyis take on K ﬁnite values v1, v2...vK, the number of observations for which ˆy = vj is nj and within the nj observations the proportion of true events is rj, the calibration component is deﬁned in 2.5 and the reﬁnement component is deﬁned in 2.6. Now, the Brier Score can be represented as the sum of the two components (BS = R + C). Calibration Component (C) = 1 n K∑ k=1 nk(rk − ˆyk)2 (2.5) Reﬁnement Component (R) = 1 n K∑ k=1 nkrk(1 − rk) (2.6) 7 2.4 Discrimination Slope (DS) and Integrated Discrimination Improvement (IDI) Although the Discrimination Slope (DS) may sound as if it requires classiﬁcations as predictions, it is a measure of the predicted probabilities and does not require cut-oﬀ values or classiﬁcations. The formal deﬁnition of the DS is the diﬀerence between the mean of the predicted probabilities for the known true events and the mean of the predicted probabilities for the known true non-events. The formula is provided in 2.7, and this can be considered visually by looking at side-by-side box plots of the predicted probabilities grouped by known true events and non-events in ﬁgure 2.2. DS = 1 n1 n1∑ i=1 ˆyi − 1 n0 n0∑ j=1 ˆyj (2.7) Figure 2.2: Side-by-side Boxplots of Predicted Probabilities. The Integrated Discrimination Improvement (IDI) is a measure used to evaluate the diﬀerence between two classiﬁcation models [31]. Similarly to the AU C, the IDI is a function of sensitivity 8 and one minus speciﬁcity. More speciﬁcally, the IDI is the diﬀerence between the area under the curve of sensitivity for all cutoﬀs and the area under the curve of one minus speciﬁcity for all cutoﬀs. Mathematically, the integral of sensitivity is equal to the expected value of the predicted probabilities given an event and the integral of one minus speciﬁcity is equal to the expected value of the predicted probabilities given a non-event [31]. Therefore, given two models, A and B, and predicted probabilities for the ith observation for each model are ˆyAi and ˆyBi, the formula to estimate the IDI is shown in 2.8. This is equivalent to the diﬀerence between the discrimination slopes for the two models. IDI = (¯yA,events − ¯yB, events) − (¯yA,nonevents − ¯yB,nonevents) (2.8) The value of the IDI ranges from a best possible value of 2 to a worst possible value of −2. When used as a measure of model performance or ability, the assumption will be that model B outputs a constant predicted probability and therefore the IDI is equal to the Discrimination Slope. 2.5 Coeﬃcient of Determination (R2) The coeﬃcient of determination, or R2, is a common metric reported in settings with continuous outcomes, mainly due to its interpretability. However, in a dichotomous outcome setting, the value of R2 is usually much smaller and is impacted signiﬁcantly by the overall incidence of the outcome event of interest [3]. Due to this, there have been many variations of R2 used to either create a better measure of model performance or to explain the variation in the model. Mittlb¨ock and Schemper [28] examined many of these variations of R2 in a logistic regression setting and suggest using equation 2.9 as one that has the following characteristics: has an intuitively clear interpretation, is consistent with the character of logistic regression, takes values between 0 and 1, and will be similar to a value calculated on the same data using linear regression. This however, is not the most commonly reported form of R2 by statistical software (SAS and Stata report psuedo R2s based on the likelihood equations). R2 = 1 − ∑( ˆyi − yi)2 ∑(¯y − yi)2 (2.9) As seen in the equation, it is very clear that incidence, ¯y, is an important factor in calculating R2 and in general, lower incidence will result in lower values for R2. This can lead to models with low values of R2 but that provide useful discrimination as seen in Ash and Shwartz [3]. 9 2.6 F-Score (Fβ) The F-Score (or F-measure) is a common metric used in the ﬁeld of Information Retrieval where retrieved documents are classiﬁed as relevant or not. It is a function of two other common metrics, precision, the proportion of correctly identiﬁed known true events out of the total predicted events, and sensitivity, the proportion of correctly identiﬁed events out of the total known true events. The F-Score, Fβ, is a weighted average of precision and sensitivity and is shown in 2.10. The F1 Score is the most commonly used version and results in the harmonic mean of precision and sensitivity [18]. Regardless of the choice for β, the F-Score ranges from a best possible value of 1 and worst possible value of 0. By looking at the formula, it can be seen that large values of both precision and sensitivity result in higher values for the F-Score rather than maximizing one or the other. Although a valid measure of predictive accuracy, the F-Score is criticized because it ignores the number of correctly identiﬁed non-events [34]. Fβ = (1 + β2) ∗ precision ∗ sensitivity β2 ∗ precision + sensitivity (2.10) In order to calculate precision and sensitivity, predicted probabilities must be classiﬁed into events or non-events using a cut-oﬀ value. This cut-oﬀ value can vary from data set to data set and is not used in calculating any of the previously mentioned measures. Due to the requirement of a predetermined cutoﬀ value, the inclusion of Fβ score will be very limited in this research. 10 CHAPTER 3 DATA ANALYSIS USING REAL AND SIMULATED DATA 3.1 Simulation Study of the Relationship among Measures Simulating data is an easy method to develop a baseline understanding of the relationships among the measures introduced in the previous section. We conducted a simulation that mimicked multiple studies using the same risk indicators to predict a dichotomous outcome. For each study we randomly simulated two explanatory variables for each observation, age and systolic blood pressure. Age was simulated from a normal distribution with mean 50 and standard deviation 15 and systolic blood pressure (sbp) was simulated from a normal distribution with mean 130 and standard deviation 25. A logistic regression model was assumed and ˆyi calculated using formula 3.1 below. For each observation, we then generated a value for yi from a Bernoulli distribution with parameter ˆyi. ˆyi = 1 1 + e−(β0+β1agei+β2sbpi) (3.1) To increase the variance between each study, the values for the coeﬃcients in the logistic re- gression model for each study were also randomly generated. β0 was generated from a normal distribution with mean −7 and standard deviation 2, β1 was generated from a normal distribution with mean 0.08 and standard deviation 0.03, and β2 was generated from a normal distribution with mean 0.02 and standard deviation 0.005. To summarize the simulation study, the following steps were followed: for k in 1:m (m = total number of desired studies) generate βk,0 ∼ N (−7, 2) generate βk,1 ∼ N (0.08, 0.03) generate βk,2 ∼ N (0.02, 0.005) for i in 1:nk (nk is the number of observations in study k) generate agek,i ∼ N (50, 15) 11 generate sbpk,i ∼ N (130, 25) calculate ˆpk,i using formula 3.1 generate yk,i ∼ Bernoulli(ˆpk,i) We chose to run the simulation for 50 studies with 1,000 observations each (m = 50, nk = 1, 000 for all k). Using the simulated data, logistic regression models were ﬁt on each data set and predictions, ˆyis, acquired using the ﬁtted models. 3.1.1 Results from Simulation Study The measures of predictive accuracy calculated for this study were the area under the ROC curve, Brier Score, Log-Loss, Discrimination Slope and R2. The results from the simulation can be found in table 3.3. A plot of all of the measures can be found in ﬁgure 3.1 and the resulting correlation values can be found in table 3.1. It should be noted that the measures cover acceptable ranges for possible values found in real data - the values of Log-Loss range from 0.59563 to 0.02633, the values for the AU C range from 0.64480 to 0.89668, the values for the Brier Score range from 0.20508 to 0.00494, the values for the Discrimination Slope range from 0.01058 to 0.35600 and the values for the R2 range from 0.00741 to 0.35778. Also, the incidence in the datasets ranged from 0.005 to 0.98. Table 3.1: Correlation Among the Measures in Simulation Study. AUC Brier Score R2 Discrimination Slope Log-Loss AUC 1.000 Brier Score −0.110 1.000 R2 0.585 0.620 1.000 Discrimination Slope 0.586 0.628 0.999 1.000 Log-Loss −0.140 0.998 0.612 0.618 1.000 Table 3.2: Summary Statistics for the Measures in Simulation Study. Minimum (Worst) Value Maximum (Best) Value AUC 0.64480 0.89668 Brier Score 0.20508 0.00494 R2 0.00741 0.35778 Discrimination Slope 0.01058 0.35600 Log-Loss 0.59563 0.02633 12 Table 3.3: Results from Simulation Study. Model Number Log-Loss Brier Score AU C Discrimination Slope R2 1 0.02633 0.00494 0.88884 0.01373 0.00741 2 0.34781 0.10658 0.78222 0.15641 0.15480 3 0.59563 0.20508 0.71572 0.13986 0.13955 4 0.37779 0.11539 0.74317 0.11314 0.11428 5 0.36079 0.11452 0.81723 0.20562 0.19585 6 0.42978 0.13571 0.76848 0.17112 0.17325 7 0.08257 0.02012 0.88286 0.13382 0.14126 8 0.47681 0.15668 0.76595 0.18403 0.18157 9 0.48645 0.15957 0.82551 0.30762 0.30909 10 0.12574 0.02926 0.74437 0.03108 0.02607 11 0.55325 0.18717 0.75853 0.19322 0.19245 12 0.25411 0.07659 0.86635 0.26419 0.25868 13 0.54654 0.18528 0.78105 0.23514 0.23404 14 0.19764 0.04902 0.66460 0.02266 0.02330 15 0.15108 0.04167 0.89668 0.26943 0.27256 16 0.50050 0.16552 0.83219 0.32868 0.32950 17 0.31132 0.09047 0.73373 0.07813 0.07591 18 0.50717 0.16606 0.83229 0.32439 0.32959 19 0.44850 0.14286 0.73082 0.12513 0.12657 20 0.49091 0.16376 0.79658 0.23511 0.23167 21 0.37144 0.11151 0.69644 0.08317 0.08475 22 0.48121 0.15765 0.79219 0.22417 0.22469 23 0.04340 0.00784 0.71560 0.01058 0.01190 24 0.56307 0.19207 0.77104 0.22173 0.21972 25 0.25376 0.07099 0.79826 0.14999 0.15834 26 0.18336 0.04917 0.80202 0.07889 0.06997 27 0.16206 0.04099 0.77965 0.06709 0.06596 28 0.44030 0.14227 0.77017 0.15846 0.15419 29 0.47058 0.15390 0.79286 0.22739 0.22808 30 0.09193 0.02063 0.79638 0.04240 0.04140 31 0.49118 0.16171 0.80902 0.27357 0.27516 32 0.33915 0.10345 0.79061 0.16337 0.16073 33 0.43976 0.14463 0.83846 0.31493 0.31128 34 0.22350 0.06261 0.81846 0.14772 0.14938 35 0.45244 0.14388 0.71039 0.10348 0.10413 36 0.31647 0.09449 0.78085 0.13823 0.13613 37 0.46808 0.15409 0.84335 0.33784 0.33745 38 0.43322 0.14125 0.83428 0.30341 0.30238 39 0.16531 0.04351 0.85102 0.17910 0.19046 40 0.21960 0.06239 0.84523 0.19578 0.19779 41 0.08094 0.01829 0.83541 0.06455 0.06697 42 0.22954 0.05881 0.64480 0.01824 0.01833 43 0.33751 0.10511 0.87119 0.35287 0.35503 44 0.29960 0.08882 0.78070 0.11956 0.11389 45 0.33994 0.10293 0.81138 0.22052 0.22630 46 0.50410 0.16768 0.80503 0.26283 0.26197 47 0.40005 0.12780 0.83462 0.28120 0.28054 48 0.40275 0.12890 0.86133 0.35600 0.35778 49 0.52665 0.17769 0.78294 0.21776 0.21473 50 0.50178 0.16569 0.80584 0.27584 0.27818 13 Figure 3.1: Scatter Plot of the Measures from Simulated Data. 3.2 Using Real Data to Study the Relationship among Measures The real data used for this study contains information from 17 observational studies, each with two or more cohorts. This data set has been widely used to study the relationship between coronary heart disease and various risk factors. The outcome of interest will be a binary variable indicating death due to coronary heart disease. The risk factors that will be used in this study include continuous variables age, systolic blood pressure, HDL cholesterol and total cholesterol and a binary variable to indicate if the person is a current cigarette smoker or not. These risk factors have been shown in multiple studies to be eﬀective in predicting death from coronary heart disease 14 and are currently a subset of the variables used to calculate the 10 year risk of death from coronary heart disease based on the Framingham Heart Study [40]. Observations with missing values for any of the risk factors will be dropped from the data set prior to any analysis. Similar to the simulation study, for each cohort in the dataset (a total of 55), a logistic model was ﬁt and the measures of predictive accuracy calculated. 3.2.1 Results from Real Data Analysis The results for the real data analysis are similar to that of the simulation study. For the real data analysis, the maximum F1 Score was calculated for each of the cohorts and included in the scatter plot and correlation table. The scatter plot of the measures is shown in ﬁgure 3.2 and the correlation values are in table 3.5. Although the correlation directions are the same, the strengths of some of the correlations are signiﬁcantly diﬀerent. For example, the correlation between the AU C and Brier Score in the simulation study was −0.110 but in the real data analysis the correlation is −0.488. The correlation values that stay extremely consistent are those between the Log-Loss and Brier Score and between the R2 and DS, both of which are very close to 1. Figure 3.2: Scatter Plot of the Measures. 15 Table 3.4: Results from Real Data Analysis. Cohort Number Log-Loss Brier Score AU C Discrimination Slope R2 1 1 0.02909 0.00587 0.89077 0.04107 0.03088 1 2 0.09501 0.01992 0.69356 0.01363 0.01299 1 3 0.01801 0.00328 0.91542 0.01837 0.00841 1 4 0.06717 0.01337 0.74597 0.01430 0.01101 3 7 0.39926 0.12474 0.73795 0.09069 0.08447 3 8 0.45517 0.14572 0.69323 0.05836 0.05202 3 9 0.35428 0.10968 0.78151 0.12984 0.11853 310 0.50305 0.16441 0.69363 0.08199 0.07976 411 0.08638 0.01899 0.79196 0.05671 0.06398 412 0.16716 0.04258 0.78370 0.09185 0.09826 413 0.10917 0.02517 0.79266 0.03048 0.01842 414 0.24095 0.06338 0.67850 0.03248 0.03214 617 0.40515 0.12503 0.70698 0.07305 0.07183 618 0.41731 0.13003 0.67239 0.04956 0.04642 619 0.41422 0.13255 0.76223 0.12382 0.11703 620 0.51434 0.17074 0.68633 0.07638 0.07157 721 0.29693 0.08678 0.75795 0.08532 0.07639 722 0.50455 0.16457 0.66161 0.05577 0.05368 823 0.02349 0.00484 0.94472 0.10585 0.10481 824 0.13812 0.03510 0.82106 0.04743 0.02929 1233 0.12046 0.02764 0.76251 0.05037 0.05729 1234 0.25640 0.06962 0.70469 0.03804 0.03534 1235 0.13223 0.03110 0.77386 0.07621 0.08602 1236 0.18367 0.04771 0.76620 0.04976 0.04260 1237 0.11027 0.02485 0.75594 0.03996 0.03927 1238 0.18792 0.04827 0.74096 0.03823 0.03193 1239 0.11249 0.02627 0.79743 0.06933 0.06909 1240 0.18797 0.04797 0.73681 0.04589 0.04415 1341 0.18755 0.04742 0.73269 0.04602 0.04252 1645 0.12919 0.03376 0.85722 0.11577 0.10651 1646 0.18475 0.04973 0.81293 0.10276 0.09280 1647 0.07631 0.01873 0.89247 0.11032 0.10779 1648 0.14019 0.03703 0.85347 0.10193 0.08865 1851 0.13584 0.03021 0.64479 0.00791 0.00749 1852 0.14732 0.03359 0.65244 0.00947 0.00836 1953 0.21251 0.06035 0.81892 0.10341 0.09885 1954 0.32648 0.09786 0.75789 0.09893 0.09616 1955 0.19395 0.05841 0.87034 0.15287 0.14252 1956 0.34060 0.10651 0.78552 0.12451 0.11610 2057 0.19466 0.05533 0.83405 0.09892 0.08494 2058 0.20577 0.05653 0.77703 0.06071 0.05184 2059 0.15745 0.04179 0.82161 0.07463 0.06883 2060 0.26618 0.07765 0.78118 0.09205 0.08922 2369 0.12434 0.02875 0.74627 0.03506 0.02972 2370 0.15536 0.03843 0.76527 0.04486 0.03591 2675 0.15535 0.04566 0.90179 0.18093 0.15470 2676 0.27666 0.08354 0.83557 0.17762 0.16506 2777 0.12134 0.02799 0.75730 0.03359 0.03147 2778 0.14640 0.03569 0.77239 0.05329 0.04958 2879 0.20097 0.06012 0.86102 0.14510 0.13696 2880 0.27328 0.08571 0.84044 0.16615 0.15564 2881 0.10581 0.02839 0.89197 0.10729 0.09288 2882 0.17557 0.04827 0.83686 0.10683 0.09957 2883 0.09739 0.02661 0.91206 0.14264 0.13658 2884 0.13676 0.03788 0.87920 0.11483 0.10025 16 Table 3.5: Correlation Among the Metrics in Real Data. AUC Brier Score DS Log-Loss R2 max(F1) AUC 1.000 Brier Score −0.488 1.000 DS 0.589 0.233 1.000 Log-Loss −0.540 0.996 0.197 1.000 R2 0.550 0.243 0.991 0.209 1.000 max(F1) 0.090 0.737 0.748 0.709 0.766 1.000 3.3 Analysis of Relationships among Measures The results from the simulation study and real data analysis reveal relationships between the predictive accuracy measures that require additional analysis. The two extremely obvious rela- tionships that appear to be linear are between the Brier Score and Log-Loss and between the Discrimination Slope and R2. The relationships that appear to have no correlation are the AU C and Log-Loss and the AU C and Brier Score. There are also relationships between the measures that are unexpected. The Brier Score should be negatively correlated with all of the measures except the Log-Loss (a decrease in Brier Score represents an increase in predictive accuracy), yet the R2 and DS are positively (and fairly strongly) correlated with the Brier Score. 3.3.1 Relationship between Brier Score and Log-Loss In ﬁgure 3.2, there is clearly a relationship between the Brier Score and the Log-Loss. This is also seen in table 3.5 from the simulation in section 3.1 where the correlation between the Brier Score and Log-Loss is 0.998. The reason for a strong correlation between these two metrics is slightly less obvious as the Brier Score is a quadratic scoring rule and the Log-Loss contains natural logarithms. However, the Brier Score can be written in a similar looking formula to the Log-Loss as seen in 3.2. BS = 1 n n∑ i=1(yi(ˆyi − 1)2 + (1 − yi)ˆy2 i ) (3.2) The Brier Score consists of the sum of (ˆyi −1)2 for events plus the sum of ˆy2 i for non-events while the Log-Loss consists of the sum of ln(ˆyi) for events plus the sum of ln(1 − ˆyi) for non-events. The link between (ˆyi − 1)2 and ln(ˆyi) for events and ˆy2 i and ln(1 − ˆyi) for non-events lies in the Taylor 17 series approximations for the function ln(x) centered at 1 and the function ln(1 − x) centered at 0 shown in equations 3.3 and 3.4 below. ln(x) ≈ ∞∑ n=1 (−1)n−1 n (x − 1)n (3.3) ln(1 − x) ≈ ∞∑ n=1 −1 ∗ (xn) n (3.4) Using the approximations for the two functions ln(x) and ln(1 − x), the Log-Loss can now be written in terms of the Brier Score with some constant C to account for the remaining terms in the Taylor series. Log-Loss ≈ 1 2 BS + C (3.5) Although this is an approximate linear relationship, it clearly explains the results from the simulation study and real data analysis. 3.3.2 Relationship between R2 and Discrimination Slope Another interesting relationship seen in ﬁgure 3.2 is that between R2 and the Discrimination Slope. The correlation from table 3.5 between these two measures is 0.991. Using the deﬁnition of R2 presented in the previous section, Pepe, Feng and Gu proved that the Discrimination Slope is equivalent to the R2 under the assumption of the law of large numbers and the convergence of R2 to 1 − E(V ar(y|X) V ar(y) [32, 19]. To conﬁrm the 1:1 relationship, a linear regression model of Discrimination Slope to R2 was ﬁt and yielded a 95% conﬁdence interval of the parameter estimate of (0.944,1.037) and a non-signiﬁcant intercept term. 3.3.3 Relationship between R2 and Brier Score The R2 can be written as a function of the Brier Score and incidence rate as shown in equation 3.6. R2 = 1 − BS incidence ∗ (1 − incidence) (3.6) Now it is clear that relationships exist among most of the measures except with the area under the ROC curve. Because of this, special interest will be focused on these relationships. 18 3.3.4 Relationship Between AU C and Other Measures Due to the uninformative relationships, deeper analysis of the overall incidence rate in the model population was considered. Figure 3.3 shows a bubble plot of area under the ROC curve versus Log-Loss sized by the incidence rate in the study using the data from the real data analysis in section 3.2. Clearly, the observations that are furthest from the linear trend have the lowest incidence rates. Figure 3.3: Bubble Plot of AUC versus Log-Loss sized by Incidence. 3.4 Impact of Incidence on the Measures What becomes apparent in the ﬁgures shown in the previous sections is that the expected relationships are much clearer for the cohorts with incidence rates closer to 50% than those with much lower incidence rates. Additionally, a plot of Discrimination Slope versus Log-Loss grouped by incidence rates is shown in ﬁgure 3.4. The group labeled 1 includes the studies with incidence rates between 25% and 75% while the group labeled 0 has the remaining studies having extreme (high or low) incidence rates. Clearly the negative trend that is expected between the two measures 19 is evident in group 1 (reasonable incidence rates) and completely opposite for group 2 (extreme incidence rates). Figure 3.4: Plot of Log-Loss versus Discrimination Slope grouped by Incidence. To examine the impact of incidence on the correlation between the measures in the real data, the correlation between the measures in cohorts with incidence less than 10% was compared to the correlation between the measures in cohorts with incidence between 10% and 50%. The two correlation tables are shown in tables 3.6 and 3.7. A correlation in bold represents a stronger relationship. Table 3.6: Correlation Among the Metrics in Studies with Prevalence < 10% (n = 41). AUC Brier Score R2 DS Log-Loss max(F1) AUC 1.000 Brier Score −0.251 1.000 R2 0.681 0.282 1.000 DS 0.724 0.289 0.987 1.000 Log-Loss −0.394 0.986 0.163 0.162 1.000 max(F1) 0.550 0.415 0.899 0.883 0.312 1.000 20 Table 3.7: Correlation Among the Metrics in Studies with Prevalence between 10% and 50% (n = 14). AUC Brier Score R2 DS Log-Loss max(F1) AUC 1.000 Brier Score −0.847 1.000 R2 0.948 −0.671 1.000 DS 0.956 −0.684 0.998 1.000 Log-Loss −0.897 0.997 −0.716 −0.729 1.000 max(F1) 0.150 0.370 0.405 0.390 0.319 1.000 Ignoring the maximum F1 Score, all of the relationships between the measures are stronger in the cohorts with an incidence rate between 10% and 50% than those with incidence less than 10%. Furthermore, the relationship between the Brier Score and R2 (and DS) is positive for the cohorts with incidence less than 10% but negative (the expected outcome) for those between 10% and 50%. The same is true for the Log-Loss and the R2 (and DS) in that the relationship is positive (as expected) in the cohorts with incidence rate greater than or equal to 10% but oddly negative within those cohorts with incidence rate less than 10%. To further analyze the impact of incidence rate on the relationships among the measures, a second simulation study was conducted. 3.4.1 Second Simulation Study of the Relationships Under Various Incidence Rates To investigate the relationships between the measures under varying incidence rates, a similar simulation to the ﬁrst will be used except, this time, controlling for the incidence rate. To simplify the model, only one covariate will be generated from a normal distribution with mean 1.5 and standard deviation 0.5. The intercept term will be ﬁxed for a given run of the simulation which will control the overall incidence rate. The following steps were followed for this simulation study: for k in 1:m (m = total number of desired studies) Choose a value for β0 for i in 1:nk (nk is the number of observations in study k) generate β1X1 ∼ N (1.5, 0.5) calculate ˆpk,i = 1 1+e−(β0+β1X1) generate yk,i ∼ Bernoulli(ˆpk,i) 21 The results of this simulation will be k diﬀerent studies using the same variables, all with very similar incidence rates. The number of studies for our simulation was chosen to be 100 and 1,000 observations were generated for each study (m=100, nk = 1,000 for all k). Using the simulated data, logistic regression models were ﬁt on each data set and predictions ˆyis acquired using the ﬁtted models. To investigate the relationships under diﬀerent incidence rates, the simulation was run for diﬀerent choices of β0. In this paper, we provide the results for β0 = 0, −1, −2, and −4. Simulation II Results. The plots for the results of the second simulation only contain the area under the ROC curve, Log-Loss, and discrimination slope due to redundancy in plotting the other metrics (R2 and Brier Score). However, the tables of correlation values contains all of the measures to conﬁrm the linear relationships found in simulation I results. In table 3.8, the summary statistics for the incidence rate in each run of the simulation can be found. An interesting result seen in the plots and correlation tables in the decrease in correlation between the area under the ROC curve and Log-Loss and between the area under the ROC curve and Discrimination Slope as the incidence decreases. This is shown more clearly in table 3.13. Figure 3.5: Scatter Plot of the Measures from Simulation Study II (β0=0). 22 Figure 3.6: Scatter Plot of the Measures from Simulation Study II (β0=-1). Figure 3.7: Scatter Plot of the Measures from Simulation Study II (β0=−2). 23 Figure 3.8: Scatter Plot of the Measures from Simulation Study II (β0=−4). Table 3.8: Summary Statistics for Incidence Rate for Each Choice of β0. β0 k min max mean 0 100 0.467 0.536 0.499 −1 100 0.260 0.336 0.293 −2 100 0.114 0.178 0.143 −4 100 0.013 0.035 0.023 Table 3.9: Correlation Among the Measures from Simulation Study II (β0=0). AUC Brier Score R2 Discrimination Slope Log-Loss AUC 1.000 Brier Score −0.989 1.000 R2 0.991 −0.998 1.000 Discrimination Slope 0.987 −0.998 0.999 1.000 Log-Loss −0.977 0.997 −0.995 −0.997 1.000 24 Table 3.10: Correlation Among the Measures from Simulation Study II (β0=−1). AUC Brier Score R2 Discrimination Slope Log-Loss AUC 1.000 Brier Score −0.680 1.000 R2 0.956 −0.581 1.000 Discrimination Slope 0.966 −0.583 0.997 1.000 Log-Loss −0.703 0.996 −0.595 −0.603 1.000 Table 3.11: Correlation Among the Measures from Simulation Study II (β0=−2). AUC Brier Score R2 Discrimination Slope Log-Loss AUC 1.000 Brier Score −0.476 1.000 R2 0.882 −0.280 1.000 Discrimination Slope 0.917 −0.331 0.995 1.000 Log-Loss −0.561 0.994 −0.351 −0.373 1.000 Table 3.12: Correlation Among the Measures from Simulation Study II (β0=−4). AUC Brier Score R2 Discrimination Slope Log-Loss AUC 1.000 Brier Score 0.082 1.000 R2 0.673 0.122 1.000 Discrimination Slope 0.792 0.118 0.975 1.000 Log-Loss −0.225 0.988 0.005 −0.017 1.000 Table 3.13: Correlation Among Measures for each Choice of β0. β0 Average Incidence Rate ρAU C,LogLoss ρAU C,DS 0 0.499 −0.977 0.987 −1 0.293 −0.703 0.966 −2 0.143 −0.561 0.917 −4 0.023 −0.225 0.792 3.4.2 Brier Score and Incidence The role of incidence in the Brier Score can be seen in decomposing the formula similar to section 3.3.1. Let N be the total number of observations in the data set and n1 represent the 25 number of positive cases (and therefore a proxy for incidence). The Brier Score can then be written as shown below and is now a function of the incidence. BS = 1 N N∑ i=1(ˆyi − yi)2 = 1 N N∑ i=1(ˆy2 i − 2ˆyiyi + y2 i ) = 1 N N∑ i=1(ˆy2 i − 2ˆyiyi + yi) = 1 N [ N∑ i=1 ˆy2 i − N∑ i=1 2ˆyiyi + N∑ i=1 yi ] = 1 N [ N∑ i=1 ˆy2 i − N∑ i=1 2ˆyiyi + n1 ] Furthermore, in looking at the terms in the sum, the valid range of values that each summation can take is also dependent on the prevalence. BS = 1 N [ N∑ i=1 ˆy2 i − N∑ i=1 2ˆyiyi + n1 ] = 1 N [n1 + ∑ i∋yi=1(ˆy2 i − 2ˆyiyi) + ∑ i∋yi=0(ˆy2 i )] = 1 N [n1 + ∑ i∋yi=1(ˆy2 i − 2ˆyi) + ∑ i∋yi=0(ˆy2 i )] = 1 N [n1 + ∑ i∋yi=1(ˆy2 i − 2ˆyi + 1 − 1) + ∑ i∋yi=0(ˆy2 i )] = 1 N [n1 + ∑ i∋yi=1(ˆy2 i − 2ˆyi + 1) ∑ i∋yi=0(−1) + ∑ i∋yi=0(ˆy2 i )] = 1 N [n1 − n1 ∑ i∋yi=1(ˆyi − 1)2 + ∑ i∋yi=0(ˆy2 i )] = 1 N [ ∑ i∋yi=1(1 − ˆyi)2 + ∑ i∋yi=0(ˆy2 i )] = 1 N [ ∑ i∋yi=1(1 − ˆyi)2 | {z } 0≤n1 + ∑ i∋yi=0(ˆy2 i ) | {z } 0≤N −n1 ] 26 3.4.3 Meta-regression using Area Under the ROC Curve and Incidence To attempt to explain the lack of relationships and impact of incidence rate, a meta-analysis was performed on the real data explained in section 3.2. For a meta-analysis, the basic assumption is that there are n studies in which a parameter of interest has been estimated [38]. The parameter is assumed to follow a normal distribution with unknown mean but known sample standard deviation. In this analysis, the value of the area under the ROC curve will be the parameter of interest. For consistency, the following notation will be used throughout this section: ˆAi will represent the estimated value of the area under the ROC curve and si will be the sample standard deviation of the area under the ROC curve for the ith study. The ﬁrst and easiest analysis to perform is what is referred to as a ﬁxed eﬀects or analysis under homogeneity. Under this scenario, the estimated parameter of interest is assumed to be equal for all studies and using maximum likelihood, an estimation of the common parameter and its standard error can be calculated using the following equations. ˆAF E = ∑i ˆAi s2 i∑i 1 s2 i (3.7) SE( ˆAF E) = 1 √∑i 1 s2 i (3.8) Using equations 3.7 and 3.8 the value for ˆAF E is 0.816 and for SE( ˆAF E) is 0.002. The assumption that the parameter of interest is equal for each study is usually too restric- tive and requires an alternative assumption to compare the measures across multiple studies. The updated assumption is that each A is an independent random variable from a normal population with unknown mean and standard deviation, Ai ∼ N (A, τ 2). Furthermore, the marginal distri- bution of Ai is ˆAi ∼ N (A, τ 2 + s2 i ). The variation in this assumption is thought to be a sum of the within-study variation and between-study variation. This scenario is referred to as random eﬀects or analysis under heterogeneity. Under these assumptions, the following equations based on maximizing the log-likelihood can be used to provide estimates of A and τ . ˆARE = ∑i ˆAi τ 2+s2 i∑i 1 τ 2+s2 i (3.9) SE( ˆARE) = 1 √∑i 1 τ 2+s2 i (3.10) 27 Using equations 3.9 and 3.10 the value for ˆARE is 0.786 and for SE( ˆARE) is 0.010. The estimate of the between-study variance, ˆτ 2, is 0.005. Although the value for τ 2 is quite small, occasionally it is important to determine if a variable is able to explain the between study variance [38]. The method of meta-regression uses study-level information as a covariate (Xi) to attempt to explain the between study variance and assumes that the Ai ∼ N (Xiβ, τ 2). Again, the marginal distribution of Ai is ˆAi ∼ N (Xiβ, τ 2 + s2 i ) and the estimates for τ , β and SE( ˆβ) can be found using maximum likelihood or iterative weighted least squares. The covariate used to explain the between-study variance was incidence rate within each study. The results of the meta-regression are ˆβ = −0.572, SE( ˆβ) = 0.151 and ˆτ 2 = 0.004. Since the estimate of τ 2 in the random-eﬀects scenario was 0.005, incidence rate does not explain the between study variance. Table 3.14: Meta-Analysis Results. Method ˆA SE( ˆA) ˆτ 2 ˆβ SE( ˆβ) Fixed Eﬀects 0.816 0.002 Random Eﬀects 0.786 0.010 0.005 Meta-Regression 0.004 −0.572 0.151 28 CHAPTER 4 RELATIONSHIPS UNDER BINORMAL SETTINGS 4.1 Deﬁnition of Binormal Setting As often seen in practice, the distributions of the variables may follow normal distributions. In the case of a binary response, the normal distribution must appear in the explanatory variables. There is a fair amount of research dedicated to the speciﬁc case when a covariate X follows two normal distributions with diﬀerent means and standard deviations conditional on the value of the response variable - a unique scenario referred to as the binormal case [43, 20, 7, 27]. More specif- ically, the notions for the covariate X given the response variable Y are shown below. Although there are no restrictions on the vales for µ1 or µ0, intuitively µ1 > µ0, and σ1 and σ0 must be > 0. X|Y = 1 ∼ N (µ1, σ1) X|Y = 0 ∼ N (µ0, σ0) 4.2 Binormal ROC Curve It is clear that the sensitivity and speciﬁcity at a given cutoﬀ value c, are easily calculated using the normal distribution (where Φ is the probit function). Sensitivity = P (x > c|Y = 1) = ∫ ∞ c f (x|Y = 1)dx = Φ [ µ1 − c σ1 ] Speciﬁcity = P (x < c|Y = 0) = ∫ c −∞ f (x|Y = 0)dx = Φ [ c − µ0 σ0 ] Recall, an ROC curve is the plot of sensitivity against 1−speciﬁcity. Let sensitivity be denoted as S1(c) = P (x > c|Y = 1) and 1−speciﬁcity as S0(c) = P (x > c|Y = 0). If we let g be the value of 1−speciﬁcity that corresponds to cutoﬀ value c on the ROC curve, then c = S−1 0 (g) and sensitivity can be written as a function of 1−speciﬁcity. Consequently, the ROC curve can expressed as ROC = S1(S−1 0 (g)). For the binormal model, S−1 0 (g) = µ0 + σ0Φ−1(g) and, if we let a = µ1−µ0 σ1 and b = σ0 σ1 , then the ROC function can be represented in terms of a and b as ROC = Φ[a + bΦ−1(g)]. 29 The interest for this study is the area under the ROC curve, which, under the standard deﬁ- nition, is equal to the probability of a randomly selected event having a higher value for X than a randomly selected non-event. Formally, AU C = P ([X|Y = 1] > [X|Y = 0]) and if we let Z = (X|Y = 1) − (X|Y = 0), then clearly Z is normally distributed with mean µ1 − µ0 and standard deviation √ σ2 1 + σ2 0. Therefore, the AU C = Φ [ µ1−µ0√σ2 1+σ2 0 ]. Simple algebra leads to an area under the ROC curve shown below in terms of a and b. AU C = Φ ( a √1 + b2 ) 4.3 Brier Score in Binormal Setting Ikeda et al. [20] show that the Brier Score can be represented by functions of the distribution of X under the assumption that the calibration in the predicted probabilities is perfect. Using this assumption, the probability of the event conditional on the value of X can be written as shown below (using Bayes theorem) given the incidence rate is P (Y = 1) = α. p(xi) = P (Y = 1|xi) = αf (xi|Y = 1) αf (xi|Y = 1) + (1 − α)f (xi|Y = 0) To start their justiﬁcation, they look at the expected value of the summed term in the Brier Score (BS). E[(yi − p(xi))2] = E[(yi − p(xi))2|Y = 1] × P (Y = 1) + E[(yi − p(xi))2|Y = 0] × P (Y = 0) = αE[(yi − p(xi))2|Y = 1] + (1 − α)E[(yi − p(xi))2|Y = 0] = ∫ ∞ −∞(1 − p(x))2αf (x|Y = 1)dx + ∫ ∞ −∞ p(x)2(1 − α)f (x|Y = 0)dx = ∫ ∞ −∞ [ 1 − αf (x|Y = 1) αf (x|Y = 1) + (1 − α)f (x|Y = 0) ]2αf (x|Y = 1)dx + ∫ ∞ −∞ [ αf (x|Y = 1) αf (x|Y = 1) + (1 − α)f (x|Y = 0) ]2(1 − α)f (x|Y = 0)dx = ∫ ∞ −∞ [ (1 − α)f (x|Y = 0) αf (x|Y = 1) + (1 − α)f (x|Y = 0) ]2αf (x|Y = 1)dx + ∫ ∞ −∞ [ αf (x|Y = 1) αf (x|Y = 1) + (1 − α)f (x|Y = 0) ]2(1 − α)f (x|Y = 0)dx 30 = ∫ ∞ −∞ [(1 − α)f (x|Y = 0)]2 [αf (x|Y = 1) + (1 − α)f (x|Y = 0)]2 αf (x|Y = 1)dx + ∫ ∞ −∞ [αf (x|Y = 1)]2 [αf (x|Y = 1) + (1 − α)f (x|Y = 0)]2 (1 − α)f (x|Y = 0)dx = ∫ ∞ −∞ (1 − α)αf (x|Y = 1)f (x|Y = 0)[αf (x|Y = 1) + (1 − α)f (x|Y = 0)] [αf (x|Y = 1) + (1 − α)f (x|Y = 0)]2 dx = ∫ ∞ −∞ (1 − α)αf (x|Y = 1)f (x|Y = 0) αf (x|Y = 1) + (1 − α)f (x|Y = 0) dx multiplying through by 1 f (x|Y =0) and then through by f (x|Y =0) f (x|Y =1) results in: = ∫ ∞ −∞ (1 − α)αf (x|Y = 0) α + (1 − α) f (x|Y =0) f (x|Y =1) dx From the law of large numbers, this expected value of the Brier Score converges to this quantity. Then applying general rules of the relationships between a pdf f(x) and cdf F(x) the expected Brier Score can be expressed as shown in 4.1. BS = ∫ 1 0 (1 − α)α α + (1 − α) dFY =0(x) dFY =1(x) dFY =0(x) (4.1) Focusing on the ratio of the two distributions and using a simple substitution can result in a Brier Score as a function of α, a and b. dFY =0(x) dFY =1(x) = f (x|Y = 0) f (x|Y = 1) = 1√2πσ2 0 exp[− (x−µ0)2 2σ2 0 ] 1√2πσ2 1 exp[− (x−µ1)2 2σ2 1 ] = σ1 σ0 exp [ (x − µ1)2 2σ2 1 − (x − µ0)2 2σ2 0 ]] Now let Φ−1(z) = x−µ0 σ0 and also solve for x and substitute both into the equation above. = σ1 σ0 exp [ 1 2 [ (σ0Φ−1(z) + µ0 − µ1)2 σ2 1 − (Φ−1(z))2]] Using the same deﬁnitions of a and b from the previous section, the large sample expectation of the Brier Score can also be represented in terms of α, a, and b. BS = ∫ 1 0 (1 − α)αb αb + (1 − α) exp ( (b2−1)[Φ−1(z)]2+2abΦ−1(z)+a2 2 ) dz (4.2) 31 4.4 Relationships The relationship between the Brier Score and Log-Loss is not impacted by the binormal distri- bution of X as the relationship has no dependency on the distribution of X or Y . Similarly, the relationship between the Brier Score and R2 still holds as this relationship is also independent of the distribution of X (although it is dependent on the incidence rate α). Lastly, the relationship between R2 and Discrimination Slope is not impacted by the binormal setting. As a reminder the Brier Score ≈ 2Log-Loss using Taylor Series expansions, the Brier Score = (1 − R2)α(1 − α) and R2 converges in probability to the same quantity as the Discrimination Slope [32]. While a relationship between the AUC and and any other measure does not exist in the previous settings, in the binormal case, Ikeda et al. [20] show that the AUC and Brier Score can be written as functions of three parameters: α, a and b. Therefore, if two of the three parameters are chosen to be ﬁxed, a functional relationship can be explicitly determined. Since the AUC does not depend on α it makes the most sense to ﬁx α and either a or b and examine the relationship. 4.4.1 Under General Settings When α and b are ﬁxed, it is apparent that the Brier Score decreases as the area under the ROC curve increases and that the rate at which the Brier Score decreases increases as the AUC increases [20]. Similar ﬁgures to those shown in Ikeda et al. [20] are shown below. The value of α was set to 0.5 and b was ﬁxed for values of 1, 2, 3, 4 and 5 in ﬁgure 4.1. Figure 4.1: Brier Score versus AUC for ﬁxed b. Figure 4.2: R2 versus AUC for ﬁxed b. Figure 4.3: Brier Score versus R2 for ﬁxed b. From this plot, it’s evident that both measures are sensitive to variations in a for a given value of b. Since the slope of the curve is increasing with the value of the area under the curve, it can 32 be claimed that the Brier Score is more sensitive to changes in a when the AUC is larger and the area under the curve is more sensitive to changes in a when the AUC is smaller. When α and a are ﬁxed, the relationship is not monotonic anymore. Furthermore, ﬁxing a limits the values that the AUC can take because a Φ−1(AU C) must be greater than 1. The plots of AUC versus Brier Score now follow a parabolic nature as can be seen in ﬁgure 4.4. An interesting note is that given a Brier Score, there are two corresponding areas under the ROC curve that are possible, regardless of the value of a. Figure 4.4: Brier Score versus AUC for ﬁxed a. Figure 4.5: R2 versus AUC for ﬁxed a. Figure 4.6: Brier Score versus R2 for ﬁxed a. In this ﬁgure, we see that the Brier Score is much more sensitive to changes in b when a and α are ﬁxed. This is most apparent when the AUC is approaching it’s maximum value. This is similar to what was found in the plots for ﬁxing b and α - however it is much clearer when a is ﬁxed. The results match general intuition. For a ﬁxed value of b, the change in a directly impacts the distance between the peaks for each of the distributions of X|Y = 1 and X|Y = 0. As the distance increases between the two distributions, it’s clear that the impact on the Brier Score and AUC will be positive. On the other hand, for a ﬁxed value of a, the change in b impacts how narrow or wide the distributions of the two populations are. As the ratio of the standard deviations increases from B′ (where B′ is the value of b that maximizes the Brier Score), the distribution of the X’s given Y = 1 is getting narrower and narrower but the distance between the two distributions is staying the same (visa versa for the distribution of X given Y = 0 when b decreases from B′). Clearly this is going to have a much larger impact on the Brier Score than the AUC because the AUC is sensitive to the overlap in the tails of the distribution while the Brier Score is more sensitive to the shape of the distribution. This also explains the parabolic nature of the functional relationship between 33 Brier Score and AUC. There are equivalent Brier Scores for two values of b (one below B′ and one above B′) yet the corresponding areas under the ROC curve are going to be diﬀerent for those two scenarios. This is because when a distribution is very narrow, it’s weight towards the Brier Score will be smaller than a wider distribution. Since choices of b will either make one distribution wide and the other narrow or visa versa, we see two equal Brier Scores for two diﬀerent AUCs. To visualize the scenarios mentioned above, plots below are for α = 0.5, a = 1 (µ0 = 0, µ1 = 1 and σ1 = 1). The plot of Brier Score versus AUC is shown for a = 1 and α = 0.5 in ﬁgure 4.7 (this is the same plot that can be seen in ﬁgure 4.4). In ﬁgure 4.8, the value for b is set to 1 and we see that the area under the curve is 0.760 and Brier Score is equal to 0.199 (just slightly past the maximum value of the Brier Score for α = 0.5 and a = b = 1). In ﬁgure 4.9, the value of b has been decreased to 0.5 and we see the impact of the change in standard deviation ratio on the curve for the X’s when Y = 0. When b is changed to 3 in ﬁgure 4.10, the same eﬀect is seen for the distribution of X given Y = 1. Figure 4.7: Binormal Setting for a = 1 and α = 0.5. Figure 4.8: Binormal Distribu- tions of X|Y = 1 and X|Y = 0 for a = 1 b = 1 α = 0.5. Figure 4.9: Binormal Distribu- tions of X|Y = 1 and X|Y = 0 for a = 1 b = 0.5 α = 0.5. Figure 4.10: Binormal Distribu- tions of X|Y = 1 and X|Y = 0 for a = 1 b = 3 α = 0.5. 34 4.4.2 Under Low Incidence Rate Settings In most real world scenarios the incidence rate in the data is not equal to 50%. There should be interest in the relationships among these measures when the incidence is less than or greater than 50% and also near extreme values (less than 5% or greater than 95%). The same ﬁgures shown above can be compared to plots when the incidence rate is much smaller. In the ﬁrst comparison, the value of a will be ﬁxed at various values and α will be changed from 0.5 to 0.02. The plots of the AUC against the Brier Score can be shown in ﬁgures 4.11 and 4.12 below. Figure 4.11: Brier Score versus AUC for ﬁxed a and α = 0.5. Figure 4.12: Brier Score versus AUC for ﬁxed a and α = 0.02. There are multiple comments and observations to be made from these plots. First of all, it is important to note the diﬀerence in the scale of the Brier Score for the two plots. With changes in incidence rate the range of achievable Brier Scores is also impacted. The next observation relates to the sensitivity of the Brier Score with changes in the AUC when the incidence rate is only 2%. The plot shows that the Brier Score is insensitive to changes in the AUC when the AUC is relatively lower. However, when the AUC is near its maximum value the Brier Score is extremely sensitive. This observation can be seen for every value of a whereas when the incidence rate is 50%, the sensitivity of the Brier Score to changes in the AUC is signiﬁcantly diﬀerent for each value of a. Also important to notice is that the entire range of values for the Brier Score can be achieved for a very small range of AUC values. A similar exercise can be completed for ﬁxed values of b. The results are shown in ﬁgures 4.13 and 4.14 below. 35 Figure 4.13: Brier Score versus AUC for ﬁxed b and α = 0.5. Figure 4.14: Brier Score versus AUC for ﬁxed b and α = 0.02. As was seen for ﬁxing the value of a, when the incidence rate is small, there are two distinct regions of interest - one when the Brier Score is insensitive to changes in the AUC and one where it is extremely sensitive to changes in the AUC. As was seen when a was ﬁxed, the Brier Score is sensitive to very high values of AUC and not very sensitive to lower values of AUC. Except for when b = 1 (a“special” case), the behavior and values of the curves for the various values of b is very similar. These results indicate that the Brier Score may be a more desirable measure of predictive accuracy when the model performs well (AUC is near maximum achievable value) and the AUC would be a better measure for models with average performance. 4.5 Simulation Study To further understand the relationships among the predictive accuracy measures, a simulation study can be completed similar to the non-binormal setting. For this study, multiple datasets will be created under the binormal scenario: X|Y = 1 ∼ N (µ1, σ1) and X|Y = 0 ∼ N (µ0, σ0). By setting the values of the parameters in the normal distribution and controlling the incidence rate, the values of a, b and α in the calculations for AUC and Brier Score are all ﬁxed. This setup will allow for validation of the calculations of Brier Score and AUC under the binormal setting along with examination of the relationships among the predictive accuracy measures. The simulation will follow the steps below: 1. Set the values of µ1, σ1, µ0, σ0 and α. 36 2. Generate αN observations with Y = 1 and X ∼ N (µ1, σ1). 3. Generate (1 − α)N observations with Y = 0 and X ∼ N (µ0, σ0). 4. Fit a logistic regression model using X and an intercept term. 5. Find the predicted probabilities from the model and calculate each evaluation measure. 6. Repeat steps 2-5 a total of M times. With the ability to control all of the parameters impacting the predictive accuracy measures, the relationships can be examined under various scenarios. 4.5.1 Relationships Under General Settings The general setting is one in which the incidence rate is 50% and the values of a and b are not too far from realistic settings [35]. The ﬁrst simulation was run with µ1 = 5, µ0 = 3, σ1 = 2, σ0 = 2 and α = 0.5. In this setting, a = 1 and b = 1, which results in expected values for AUC of 0.760 and Brier Score of 0.199 (Refer to ﬁgures 4.7 and 4.8 for the curves of AUC vs Brier Score and the distribution of X given Y ). A total of 100 datasets were generated (M =100) each with 10,000 observations (N =10,000) and the predictive accuracy measures were calculated. The average of the calculated AUC was found to be 0.760 and the average of the calculated Brier Scores was found to be 0.199, which match the expected results using the explicit formulas for the AUC and Brier Score in the binormal setting. The plots of each calculated predictive accuracy measure for each study is shown in ﬁgure 4.15. Similar to the results in the general data setup, all of the measures are highly linearly correlated with correlation coeﬃcients near −1 or 1 (see table 4.1). Notice that since α is ﬁxed for each dataset, the correlation between Brier Score and R2 is equal to 1. Table 4.1: Correlation Among the Measures in a Binormal Setting. AUC Brier Score R2 Discrimination Slope Log-Loss AUC 1.000 Brier Score −0.999 1.000 R2 0.999 −1.000 1.000 Discrimination Slope 0.995 −0.999 0.999 1.000 Log-Loss −0.987 0.994 −0.994 −0.998 1.000 37 Figure 4.15: Relationships Among the Predictive Accuracy Measures in a Binormal Setting. 4.5.2 Relationships Under Low Incidence Rate Settings If we maintain the values of the parameters from the previous simulation but change the inci- dence rate α to 0.02, the expected value of the AUC maintains the same, 0.760, but the expected value of the Brier Score is now 0.019. After running the simulation, the average of the calculated AUCs was found to be 0.761 and the average of the Brier Scores was found to be 0.019. The slight diﬀerence in the area under the curve is due to randomness in the simulated data. The biggest diﬀerence in the relationships among the measures in the plot shown in ﬁgure 4.16. The strong linear correlation has deteriorated (see table 4.2) with correlation values not nearly as close to 1 or −1 as was seen in the balanced class scenario. These results are not much of a surprise based on the plots shown in 4.12 or 4.14. When the incidence rate is smaller, the regions where changes in the AUC (or Brier Score) have no impact 38 on the Brier Score (or AUC) is large. This will result in essentially no correlation between the measures. An interesting observation is that the Log-Loss is still highly correlated with the AUC even when the incidence rate is low. Furthermore, the correlation between the Log-Loss and AUC is higher than the Log-Loss and Brier Score which have an approximate equivalence. Figure 4.16: Relationships Among the Predictive Accuracy Measures in a Low Incidence Binormal Setting. Table 4.2: Correlation Among the Measures in a Low Incidence Binormal Setting. AUC Brier Score R2 Discrimination Slope Log-Loss AUC 1.000 Brier Score −0.601 1.000 R2 0.601 −1.000 1.000 Discrimination Slope 0.776 −0.968 0.968 1.000 Log-Loss −0.933 0.839 −0.839 −0.944 1.000 39 CHAPTER 5 MAXIMIZATION/MINIMIZATION OF PREDICTIVE ACCURACY MEASURES 5.1 Maximization and Minimization Algorithms There are many methods and algorithms that specialize in ﬁnding maximums or minimums of non-linear functions. In general, such methods are referred to as optimization routines and will fall in to two categories for the purpose of this research. The ﬁrst category is the most common and occurs when the non-linear function that is being optimized is continuous and diﬀerentiable. The second is, of course, when the non-linear function that is being optimized is not diﬀerentiable. For diﬀerentiable non-linear functions, the optimization algorithms will use values of the deriva- tive at certain points to update and ﬁnd the global or local maximum/minimum. However, when the non-linear function is not diﬀerentiable these procedures cannot be used and alternative meth- ods, such as a direct search, need to be used to ﬁnd the global or local maximum/minimum. The speciﬁc algorithms that will be used to optimize the predictive accuracy measures presented in this paper are the Newton-Raphson algorithm and the Nelder-Mead Simplex algorithm. 5.1.1 Newton-Raphson Algorithm For continuous, diﬀerentiable non-linear functions, the Newton-Raphson algorithm is one of the most frequently used methods to ﬁnd maximums or minimums [41]. The Newton-Raphson method is an iterative algorithm that uses information from the derivatives of the function to move along the function until a “root” has been found [10]. To update the value each iteration, the algorithm uses the properties of Taylor series approximations. Although the original Newton method is for ﬁnding the value of x where the function is equal to 0 (the “roots”) it can easily be adapted to ﬁnd the value of x where the derivative is equal to zero. This slight adaptation allows for the use of the Newton-Raphson algorithm as an optimization routine. The second order Taylor series approximations for a diﬀerentiable function f (x) about a point x(k) can be written as shown in 5.1. 40 f (x(k) + h) ≈ f (x(k)) + f ′(x(k))h + 1 2 f ′′(x(k))h2 (5.1) Taking the derivative of the above second order Taylor series, we can see that f ′(x(k) + h) has the following formula: f ′(x(k) + h) = f ′(x(k)) + f ′′(x(k))h (5.2) If we set f ′(x(k) + h) = 0 and solve for h, we see that h = f ′(x(k)) f ′′(x(k)) . The term h can be thought of as an oﬀset required to move closer to the true root. Therefore, x(k+1) = x(k) − h is the adjustment made to x in each iteration of the algorithm. In the multivariate case, which is the scenario for a majority of regression setups, the Newton- Raphson algorithm can be deﬁned using the gradient and Hessian of f . The gradient (∇f ) is simply the vector of all partial derivatives of f and the Hessian (Hf ) is the square-matrix of all second partial derivatives of f . The update to x in each step is then deﬁned as x(k+1) = x(k) − [Hf (x(k))]−1∇f (x(k)). For optimizing the Log-Loss, Brier Score and other continuous and diﬀerentiable predictive accuracy measures, the Newton-Raphson algorithm will be run within the PROC IML statements in SAS. In our conﬁguration, we use the default SAS options with no scaling of nor a sparsity constraint on the Hessian matrix and maximum of 200 iterations [21]. 5.1.2 Nelder-Mead Simplex Algorithm When the function that is being optimized is no longer continuous, the derivative style approach used in the Newton-Raphson method can no longer applied. Instead, in 1965, J. A. Nelder and R. Mead introduced an algorithm to minimize (or maximize) a function using a general simplex and comparing the function values and each vertex [29]. A simplex in n-dimensions contains n + 1 linear independent points and connecting line segments. It is best thought of as geometric ﬁgure in the n-dimensional space – a 2-dimensional simplex is a triangle and and 3-dimensional simplex is a tetrahedron. In the Nelder-Mead Simplex algorithm, the simplex will “adapt itself to the local landscape” by reﬂecting, expanding or contracting given the current function values at each vertex [29]. Using the original paper, a detailed explanation of the algorithm to ﬁnd the minimum follows below [29]. 41 Given an n-dimensional space (n variables in the non-linear function to be minimized), there exist n + 1 points, P0,...,Pn+1, that deﬁne the current simplex. At each point, the value of the function is expressed as yi. The ﬁrst step is to ﬁnd the maximum and minimum of the yis – namely ymax and ymin. Now let ¯P be the centroid of all of the points yi ̸= ymax. For a reﬂection coeﬃcient α, P ∗ is deﬁned as (1 + α) ¯P − αPmax. Now we decide whether to keep the new shape, reﬂect, contract or expand. If ymin < y∗ < ymax then Pmax is replaced by P ∗ and a new simplex is created and the process started over. If y∗ < ymin then reﬂection will happen and P ∗ is expanded to P ∗∗ by an expansion coeﬃcient, γ, by P ∗∗ = γP ∗ + (1 − γ) ¯P . The expansion coeﬃcient has an explicit form and is the ratio of the distance between P ∗∗ and ¯P and the distance between P ∗ and ¯P . If y∗∗ ≤ ymin then Pmax is replaced by P ∗∗ and the process is restarted with the new simplex. If y∗∗ ≥ ymin then the expansion has failed and Pmax is simply replaced by P ∗ and the process restarted. Lastly, if y∗ > ymin then replace Pmax with either Pmax, P ∗ - whichever has the lower value of y and calculate P ∗∗ = βPmax + (1 − β) ¯P using a contraction coeﬃcient β. Similar to the expansion coeﬃcient, the contraction coeﬃcient has an explicit form and is equal to the ratio of the distance between P ∗∗ and ¯P and the distance between P (star or max) and ¯P . Unless y∗∗ is worse than both ymax and y∗ then replace Pmax with P ∗∗ and restart with the new simplex. In the case that y∗∗ is worse than both ymax and y∗, a completely new simplex in generated with all new values for the Pis equal to (Pi + Pmin)/2. This process is continued until deﬁned stopping criteria are met. Speciﬁcally, the algorithm terminates if the standard deviation of the value of the function at each vertex of the simplex (the yis) is less than some pre-speciﬁed value or a maximum number of iterations have been performed. To implement the Nelder-Mead Simplex algorithm, the NLPNMS subroutine from within the PROC IML procedure will be used [21]. The termination criteria uses the default levels of 1E-6 for the standard deviation of the yis, maximum number of iterations of 1,000. 5.2 Predictive Accuracy Measures as Functions of β For each of the predictive accuracy measures, the goal of the optimization routine will be to ﬁnd the value(s) of β that maximize (or minimize) the predictive accuracy measure. For some of 42 the measures, the structural form of the logistic model may not be appropriate and a more general function will be used. 5.2.1 Log-Loss The Log-Loss is simply the negative average contribution to the log-likelihood and can be seen in 5.3 in terms of X, y and β. LogLossβ = − 1 n n∑ i=1 yi ∗ ln ( 1 1 + e−XiβT ) + (1 − yi) ∗ ln (1 − 1 1 + e−XiβT ) (5.3) This is a continuous function that can be easily minimized using the Newton-Raphson optimization procedure. It is important to note that the value of the ln ( 1 1+e−XiβT ) or ln (1 − 1 1+e−XiβT ) will always be negative but that negative sign is reversed with the leading negative sign in the formula. The goal is to have a small Log-Loss and therefore the search will be for the value of β that minimizes the Log-Loss. The constraints for the Log-Loss are minimal – the value of each element can range from −∞ to ∞. 5.2.2 Brier Score Similar to the Log-Loss, the Brier Score is also a continuous function that can be minimized using the Newton-Raphson procedure. In terms of X, y and β, the Brier Score is shown in 5.4. BSβ = 1 n n∑ i=1 ( 1 1 + e−XiβT − yi)2 (5.4) The Brier Score is always greater than or equal to 0 (with 0 being the best possible score) and therefore, the search will be for the value(s) of β that minimize the Brier Score. Just as for the Log-Loss, there will be no constraints on the value of each element of β. 5.2.3 Area Under the ROC Curve The area under the ROC curve does not fall under the same category as the Brier Score or Log-Loss. As seen in section 2.2, to estimate the area under the ROC curve, the Wilcoxon statistic can be used [16]. This formula is shown in 5.5 where the function Ψ(ˆyi, ˆyj) takes values 0 if ˆyi < ˆyj, 1 if ˆyi > ˆyj and 0.5 if ˆyi = ˆyj and n1 is the number of events and n0 the number of non-events. AU Cβ = n1∑ i=1 n0∑ j=1 Ψ(ˆyi, ˆyj) n1 ∗ n0 (5.5) 43 Mason and Graham [25] show that the AUC can be also be estimated using the Mann-Whitney U statistic. Formally, the Mann-Whitney U statistic for two samples is shown in 5.6 where n1 is the number of observations in sample 1 and R1i is the rank of the ith case from sample 1. U = n1∑ i=1 R1i − n1 ∗ (n1 + 1) 2 (5.6) Mason and Graham [25] approach the calculation of the AUC as uniquely ranked probabilities coming from two samples – one in which the response, y, is 1 and the other in which the response is 0. Using the stepwise nature of the ROC curve they look at the “area gained” (the empirical area under the ROC curve when a step occurs) as a function of the number of non-events that have a higher predicted probability than the current observation. Using this notion, it follows that the area under the ROC curve is equal to U n1n0 . In looking at the Mann-Whitney U statistic, it is easy to see that n1∗(n1+1) 2 is the minimum value of n1∑ i=1 R1i and therefore U is always greater than or equal to 0. Also important to note is the maximum value of n1∑ i=1 R1i, N ∗(N +1)−n0∗(n0+1) 2 , where N = n1 + n0, which results in a U statistic of n1n0 and estimated area under the ROC curve of 1. Below in table 5.1 is an example of the calculation and properties of the U statistic and area under the ROC curve. Table 5.1: An Example of the Mann-Whitney U Statistic. yi ˆyi Rank R1i 1 0.56 3 3 0 0.72 4 n/a 0 0.33 2 n/a 1 0.92 5 5 0 0.14 1 n/a Given this data, U = (3 + 5) − 2∗3 2 = 5 and the AUC = 5 2∗3 = 0.833. Also, the maximum value that R1i could take is 5∗6−3∗4 2 = 9. What is unfortunate about the U statistic is that the functional form is not diﬀerentiable and therefore it requires alternative optimization procedures to the Newton-Raphson procedure. However, given a dataset, the values for n1 and n0 are ﬁxed and therefore the optimization routine only needs to consider the sum of the ranks for the events, n1∑ i=1 R1i. 44 For the Brier Score and Log-Loss the predictions, ˆyi, have been the output of the logistic regression equation for the given value of β. Although the same equation can be used to provide predictions and then ﬁnd the ranks, 1 1+e−XiβT is a monotonically increasing function of XiβT and therefore R1i will be the same for both equations. Additionally, including an intercept term in β does not alter the ranking of the observations. Hence, the function providing “predictions” to be ranked for a given β can be a linear combination of the Xs without an intercept term as shown in equation 5.7. ˆyi = β1xi1 + β2xi2 + ... + βpxip (5.7) It is important to point out that a unique solution that maximizes the ranks does not exist for β because multiplying β by any positive constant returns the same ranking. However, using this form, the function to be optimized can be calculated quite simply. The function that is being optimized in terms of X, y and β is shown in equation 5.8 below, where rank(zi) returns the rank 1,2,...,N of the ith observation. AU CRanksβ = N∑ i=1 yi ∗ rank(β1xi1 + β2xi2 + ... + βpxip) (5.8) This function is quite desirable as it only requires one pass through the data to rank the observations. Pepe et al. [33] considered maximizing the AUC using equation 5.5 with the Wilcoxon statistic. They point out that it is a special case of the maximum rank correlation estimator [14] that has been examined and researched thoroughly [9, 36]. Most of the interest in the maximum rank correlation estimator has been to reduce the order of the computation time from n2 as the the function Ψ(ˆyi, ˆyj) requires comparing each observation to every other observation [2, 39]. Cavanagh and Sherman [9] optimized the maximum rank correlation estimator using the Nelder-Mead Simplex algorithm with a slight adaptation to the convergence criteria. Similarly, to ﬁnd the value(s) of β that maximize the AUCRanks function, the Nelder-Mead Simplex algorithm will be used, however, the objective function does not require ﬁnding all pairs of events and non-events and no adaptation of the convergence criteria will be applied. Instead, an additional constraint will be required in order to ensure a “unique” solution. As mentioned previously (and seen in ﬁgures 5.1 and 5.2), multiplying the β vector by a positive constant results in the same value of the AUCRanks function and therefore a truly unique solution 45 does not exist for the optimization routine. In order to ensure a “unique” solution is attained by the optimization algorithm, the constraint that the norm of the β vector is equal to 1 is enforced. This is particularly important for determining the standard error of the estimate. To better grasp the functional form of the AUCRanks function, simulated data was generated. The simulated data is from a two parameter logistic regression model where X1 ∼ N(0,0.5), X2 ∼ N(0,0.5), β0 = 0.5, β1 = 2, β2 = −3, ˆpi = 1 1+e−(β0+β1xi1+β2xi2) and yi ∼ Bernoulli(ˆpi). Below in ﬁgure 5.1 is a plot of the AUCRanks as a function of β1 and β2 using the simulated data. Although this plot looks smooth, the AUCRanks function only takes integer values and the plot can be thought of as a series of lines or ridges, not a smooth surface. Additionally, a two dimensional heat map of the AUCRanks function in shown in ﬁgure 5.2. This further demonstrates the stepwise nature of the function. Figure 5.1: 3D plot of the AUCRanks as a function of β1 and β2 using the simulated data. 46 Figure 5.2: Heat map of the AUCRanks as a function of β1 and β2 using the simulated data. 5.3 Simulation Studies In this section, various simulated data will be used to exhibit the performance and diﬀerences between the optimization techniques described in the previous section. For each simulation, the optimization routines for each predictive accuracy measure will be run, along with running a stan- dard logistic regression procedure. The simulations will vary with respect to the distribution of the covariates, the incidence rate and the sample size. Consistent for all of the simulations is that the data will arise from a logistic regression type simulation (similar to the simulations used in sections 3.1 and 3.4.1). A general outline of the simulation is below: 1. Set desired values of β 2. for i in 1 : N (a) generate xi from desired distribution 47 (b) calculate ˆp using xi and β in the logistic model (c) generate yi from Bernoulli(ˆp) Controlling the incidence rate can be done by choosing a speciﬁc value of the intercept term, β0, in the ﬁrst step. The signiﬁcance of the coeﬃcients in the model (and therefore performance of the model) can be controlled by choices made in the distribution of X. 5.3.1 Simulation I: Two Normal Covariates and Standard Incidence Rate The ﬁrst simulation will be the most “standard” of the simulations. The β vector will contain three elements – an intercept term of −0.5, a value of 2 for the ﬁrst coeﬃcient and a value of −3 for the second coeﬃcient. Both elements of the x vector will be drawn from two independent Normal distributions with mean 0 and standard deviation 0.5. The total number of observations generated for this simulation study was 500 and, under this conﬁguration, the total number of events was 289 (incidence rate of 58%). The ﬁrst part of the simulation study is to run a logistic regression procedure on the data and rely on maximum likelihood to ﬁnd the estimated values of the coeﬃcients. The results are shown in table 5.2. As expected, the estimated coeﬃcients are very close to the true values and also very statistically signiﬁcant. Table 5.2: Results from Logistic Regression Model in Simulation I. Parameter True Value Estimated Value p-value β0 0.5 0.5786 < 0.0001 β1 2 2.1127 < 0.0001 β2 −3 −3.1876 < 0.0001 The following parts of the simulation study will ignore any maximum likelihood theory and that the data was generated using logistic regression procedures. Instead, the optimization routines described in the previous section will be applied to the data to ﬁnd the estimated values of β that maximize (or minimize) the predictive accuracy measures. The results from minimizing the Log- Loss are shown in table 5.3, from minimizing the Brier Score in table 5.4 and for maximizing the AUCRanks in table 5.5. For the Newton-Raphson procedures (Brier Score and Log-Loss) the initial value of each β was 0 and there were no constraints on the values for each element of β. For the maximizing the 48 AUCRanks function, a starting point of 0 for each value of β is not suggested as that starting point provides constant ranks of 0 for all observations and the simplex cannot adapt properly. Therefore, starting values close to the ratio of the true values were provided (β1 = 0.5 and β2 = −0.75). Also note that the AUCRanks function is a linear combination of β without an intercept term. Table 5.3: Results from Minimizing the Log-Loss in Simulation I. Parameter True Value Estimated Value β0 0.5 0.5786 β1 2 2.1126 β2 −3 −3.1876 The resulting estimated coeﬃcients that minimize the Log-Loss are almost identical to the coeﬃcients found from the logistic regression procedure that maximize the log-likelihood (the only diﬀerence is in the fourth decimal place of the estimate for β1). This conﬁrms our algorithm is performing adequately because the Log-Loss is simply the negative average of the log-likelihood and therefore the same values of β that maximize the log-likelihood will minimize the negative average log likelihood. Table 5.4: Results from Minimizing the Brier Score in Simulation I. Parameter True Value Estimated Value β0 0.5 0.5167 β1 2 2.0670 β2 −3 −3.1493 Similar results to the output from the logistic regression model are found that minimize the Brier Score. Again, as seen in previous sections, the Brier Score can be approximated using Taylor Series as a function of the Log-Loss. The values of β that minimize these two functions should be very similar. Table 5.5: Results from Maximizing the AUCRanks in Simulation I. Parameter True Value Estimated Value β1 2 0.5422 β2 −3 −0.8402 49 Lastly, the results from maximizing the AUCRanks are also not surprising. The constraint of norm of the β vector equaling 1 (√ 0.49792 + (−0.8672)2 = 1) may at ﬁrst look disappointing, but if we multiply each value by 3.75, the estimates would be 2.0332 and -3.1508, which are closer to the true values than the estimates from logistic regression or minimizing the Brier Score or Log-Loss. The estimated coeﬃcients are not the only output to be considered from the ﬁrst simulation study. First, the predictive accuracy of each method should be computed and compared. Note that the functional form of the objective function in the AUCRanks function is not of the logistic form and the outputed predictions cannot be considered probabilities and are not necessarily between 0 and 1. Therefore, calculation of the Log-Loss and Brier Score for the AUCRanks solution is not appropriate. In table 5.6, the results of calculating the Log-Loss, Brier Score and Area Under the ROC Curve for each optimization routine are shown. Table 5.6: Calculated Predictive Accuracy Measures in Simulation I for Each Optimization Routine. Optimized Function Log-Loss Brier Score Area Under the ROC Curve Log-Loss 0.4637 0.1528 0.8569 Brier Score 0.4639 0.1527 0.8568 AUCRanks n/a n/a 0.8570 Although to be expected, it is clear from table 5.6 that each optimized function returns better values than the other two functions - i.e. when the Log-Loss was the optimized function the resulting predictions had a smaller Log-Loss than the predictions from the βs that optimized the Brier Score. Table 5.7: Sum of Predicted Probabilities in Simulation I for the Optimization Routines. Optimized Function Sum of Predictions (actual events = 289) Log-Loss 288.9991 Brier Score 284.6560 There is one other important diﬀerence between the optimization routines and the maximum likelihood methods that should be explored. One of the estimating equations for maximizing the likelihood in logistic regression is n∑ i=1[yi − π(xi)], which consequently means that the sum of the observed events is equal to the sum of the predicted probabilities [17]. This however does not hold true for the optimization of the Brier Score (or AUCRanks function as the output isn’t 50 probabilities). As a result, maximizing the Brier Score may result in a sum of the predicted probabilities that is not equal to the incidence rate in the data. This can be seen in table 5.7. 5.3.2 Simulation II: Two Normal Covariates and Low Incidence Rate The next simulation will follow the same structure as the ﬁrst but a slight change to the intercept term used to generate the data will be applied in order to adjust the incidence rate. In this simulation the intercept term will be equal to −5 (changed from 0.5) but the other coeﬃcients will remain the same (2 and −3). In generating 500 observations, a total of 15 events were observed resulting in an incidence rate in the simulated data of 3%. The results of optimizing each predictive accuracy measure are shown in tables 5.8, 5.9 and 5.10 below. The coeﬃcient estimates for the Log-Loss and Brier Score are quite diﬀerent from one another and also not too close to the true values. Both of these diﬀerences can be partly attributed to the small number of events observed in the data. Table 5.8: Results from Minimizing the Log-Loss in Simulation II. Parameter True Value Estimated Value β0 −5 −5.2146 β1 2 1.8598 β2 −3 −3.8805 Table 5.9: Results from Minimizing the Brier Score in Simulation II. Parameter True Value Estimated Value β0 −5 −7.6322 β1 2 4.5703 β2 −3 −5.4798 Table 5.10: Results from Maximizing the AUCRanks in Simulation II. Parameter True Value Estimated Value β1 2 0.1839 β2 −3 −0.9829 The coeﬃcients estimated from the AUCRanks optimization routine are signiﬁcantly diﬀerent from the true values and those found from the other routines. The ratio of the second coeﬃcient to 51 the third coeﬃcient is roughly 5 for the combination of coeﬃcients that maximizes the AUCRanks function and closer to 2 for the Log-Loss and 1 for the Brier Score. It is clear from the tables above that the optimization routines provide signiﬁcantly diﬀerent results when the incidence rate is low. As shown in Simulation I, when the incidence rate is around 0.5, the solutions to each routine were very similar and that this breaks down in the low incidence setting. The next step is to examine the performance of the estimated coeﬃcients from each optimization. These results are shown in table 5.11. Again we see that the optimized function results in the “best” score for its respective predictive accuracy measure. The magnitude of the diﬀerence is much larger, though, in comparison to the standard incidence rate setting. Table 5.11: Calculated Predictive Accuracy Measures in Simulation II for Each Optimization Rou- tine. Optimized Function Log-Loss Brier Score Area Under the ROC Curve Log-Loss 0.0931 0.0223 0.8762 Brier Score 0.1057 0.0216 0.8608 AUCRanks n/a n/a 0.8819 An additional primary diﬀerence mentioned in the ﬁrst simulation is the fact that the sum of the predicted probabilities is a critical property of logistic regression that may not hold when using the optimization routines. Below in table the sums of the predicted probabilities are shown. We see in table 5.12 that (as expected) the sum of the predicted probabilities that minimize the Log-Loss is exactly 15 but that for the Brier Score predictions, it is roughly 12. Again, the objective function for the AUCRanks function does not follow the logistic exponential form and the predictions cannot be thought of as probabilities and therefore a sum is not provided for the AUCRanks predictions. Table 5.12: Sum of Predicted Probabilities in Simulation II for the Optimization Routines. Optimized Function Sum of Predictions (actual events = 15) Log-Loss 15.0000 Brier Score 12.2957 5.3.3 Simulation III: One Continuous and One Binary Covariate The existence of at least one binary covariate is common in cardiovascular research (gender and smoking status are two key examples). The presence of a binary covariate plays an interesting 52 role in the AUCRanks optimization. The AUCRanks function takes the linear combination of the covariates so in a setting with a binary covariate and a normal covariate, the result of the sum is the addition of some amount (the estimated coeﬃcient) to any observations for which the binary variable is equal to 1 and addition of zero for the other observations. In this setting the functional form of the AUCRanks function will be very dependent on the structure of the non-binary covariate and number of events observed in the binary covariate. If the non-binary covariate has a large variance and the observations are very spread apart, then the value for the coeﬃcient on the binary coeﬃcient can take a large range of values with no change in the AUCRanks function. For example, consider the data shown in table 5.13. Note that the value for β1x1i is already given so the ordering of the continuous variable has been completed. Now, it is clear that for any value of β2 between 0 and 0.16 (0.72-0.56) will result in the same AUCRanks value. If the variance of the non-binary covariate was smaller, the range of β2 that yields constant AUCRanks will also get smaller. Table 5.13: Sample Data Including a Binary Covariate. yi β1x1i x2i 1 0.56 1 0 0.72 0 0 0.33 0 1 0.92 1 0 0.14 0 Because of this very clear dependence on the structure of both the binary covariate and the non-binary covariate, overﬁtting and large ranges of non-unique solutions is a serious concern in optimizing the AUCRanks function. Luckily, these conditions do not have this signiﬁcant impact on the Brier Score or Log-Loss and the optimization routines for those two predictive accuracy measures should perform adequately. However, it is important to note that the multiplicative property seen in the continuous covari- ates still applies for the scenario with one continuous and one binary covariate. Namely, if both coeﬃcients are multiplied by some positive constant, the AUCRanks function takes the same values. In the example above (see table 5.13), it’s clear that any value of β2 greater than 0.16 maxmimizes the AUCRanks function (for the ﬁrst observation to have a rank higher than the second observa- 53 tion, the coeﬃcient must be bigger than the diﬀerence between β1x11 and β1x12: 0.76-0.56). If we multiply β1 by a positive constant, α, then the the diﬀerence between αβ1x11 and αβ1x12 is simply α[β1x11 - β1x12]. This shows that the multiplicative property still holds in a binary setting. To demonstrate the above material, data was simulated with one binary covariate and one continuous covariate. The same steps as the ﬁrst simulation were followed. The distribution of the ﬁrst covariate was Bernoulli with parameter 0.2 and the second was Normal with mean 0 and standard deviation 0.25. A total of 1,000 observations were generated with β0 = −0.5, β1 = 2 and β2 = −2. This resulted in a total of 460 observed events in the outcome variable (46% incidence rate) and 194 observed events in the binary variable. The results of running the standard logistic regression routine on the simulated data is shown in table 5.14. Table 5.14: Results from Logistic Regression Model in Simulation III. Parameter True Value Estimated Value p-value β0 −0.5 −0.5238 < 0.0001 β1 2 2.1304 < 0.0001 β2 −2 −1.9139 < 0.0001 The results from optimizing the Log-Loss and Brier Score are shown in tables 5.15 and 5.16 below. Again, these algorithms use information from the derivatives of the objective functions and are not subject to a step-wise structure like the AUCRanks function. The solutions for β that optimize the Log-Loss are the same as those found through maximum likelihood using the logistic regression procedure. The values that optimize the Brier Score are similar but do vary slightly. Although the binary covariate introduces what seems to be more data dependency on the AUCRanks function, the restriction of the norm of the estimated β vector equaling 1 will still be enforced in the optimization of the AUCRanks. The estimated coeﬃcients that maximize the AUCRanks function are shown below in table 5.17. Table 5.15: Results from Minimizing the Log-Loss in Simulation III. Parameter True Value Estimated Value β0 −0.5 −0.5238 β1 2 2.1304 β2 −2 −1.9139 54 Table 5.16: Results from Minimizing the Brier Score in Simulation III. Parameter True Value Estimated Value β0 −0.5 −0.5309 β1 2 2.1694 β2 −2 −1.9807 Table 5.17: Results from Maximizing the AUCRanks in Simulation III. Parameter True Value Estimated Value β1 2 0.938507 β2 −2 −0.345249 Similar to the previous simulations, the estimated predictive accuracy measures can be com- puted for each optimization solution. Again, the output from the AUCRanks function is not a value between 0 and 1 and cannot be thought of as a probability. Therefore, the optimized solution for the AUCRanks function is not used in comparing Brier Score and Log-Loss. The results of the predictive accuracy measures for each optimization routine are shown in table 5.18. Table 5.18: Calculated Predictive Accuracy Measures in Simulation III for Each Optimization Routine. Optimized Function Log-Loss Brier Score Area Under the ROC Curve Log-Loss 0.6016 0.2070 0.7250 Brier Score 0.6016 0.2070 0.7250 AUCRanks n/a n/a 0.7253 For this simulation, the Brier Score and Log-Loss do not diﬀer in the fourth decimal place for either of their predictive accuracy measures. However, the AUCRanks function does provide a solution that yields a larger AUC than the other two optimization functions. The inclusion of a binary covariate introduces data dependency and the potential of signiﬁcant overﬁtting when optimizing the AUCRanks function. Due to this, less common coding of categorical variables may be eﬀective in optimizing the AUCRanks function. In this simulation, the binary variable was left in its original form, taking values of 1 or 0. For future studies, it may be interesting to compare results of various coding methods for categorical variables. 55 5.4 Use of Optimization Routines on Real Data Through simulation studies, it was apparent that the choice of optimization function can have a signiﬁcant impact on the estimated coeﬃcients and the predictive accuracy performance. The simulation studies relied on standard distributions and well behaved data. In practice, this data structure rarely exists and therefore application of the optimization routines on real data should provide interesting results. 5.4.1 Framingham Oﬀspring Cohort (FOC) and Data In 1948, a longitudinal cohort study intended to identify risk factors associated with cardiovas- cular disease was started in the city of Framingham, Massachusetts. The name of the study was the Framingham Heart Study [1] and the original cohort consisted of men and women aged 30 to 62 with no previous symptoms or experience of cardiovascular disease. In 1971, the children (along with their spouses) of participants in the ﬁrst cohort were recruited to conduct a second longitudi- nal cohort study aimed at further understanding of the risk factors associated with cardiovascular disease. This cohort of individuals is known as the Framingham Oﬀspring Cohort and is the source for data used in this analysis. The data set used is a snapshot in time after months of followup. It contains a total of 4,363 individuals with baseline age ranges from 25 to 62. The information collected on each individual includes potential risk factors such as age, gender, height, weight, systolic blood pressure, choles- terol, diabetes, and smoking status along with cardiovascular disease indicators such as death due to stroke and death due to coronary heart disease. 5.4.2 Logistic Regression on the FOC Data To provide a baseline or standard approach for explaining the relationships between various risk factors and coronary heart disease, a logistic regression model will be ﬁt on the FOC data. The variables that are of interest include cholesterol levels, systolic blood pressure and age at baseline. Binary and categorical covariates such as smoking status and race will be excluded for this study due to the severe data dependency and overﬁtting in the AUCRanks function explained in the previous section. 56 The results of ﬁtting a logistic regression model to the FOC data is shown in table 5.19. All of the variables are signiﬁcant at the α = 0.05 level and the large intercept term is a result of a small incidence rate (93 events out of 4,363 observations = 2.12%). Table 5.19: Results from Logistic Regression Model on FOC Data. Parameter Estimated Coeﬃcient Standard Error p-value β0 −11.8705 0.8786 < 0.0001 βchol 0.0114 0.0023 < 0.0001 βsbp 0.0107 0.0054 0.0483 βage 0.0968 0.0144 < 0.0001 The resulting predictive accuracy measures calculated on the FOC data using predictions from the logistic regression model are shown below in table 5.20. Table 5.20: Predictive Accuracy Measures on FOC Data from Logistic Regression Model. Predictive Accuracy Measure Value Log-Loss 0.0878 Brier Score 0.0201 AUC 0.8321 These values will be compared to output from the optimization of the various predictive accuracy measures, along with the estimated coeﬃcients found using the optimization routines. 5.4.3 Optimizing the Log-Loss on the FOC Data Optimizing the Log-Loss using the FOC data will result in coeﬃcient estimates for the intercept, cholesterol, systolic blood pressure and age. The results of the optimization are shown in table 5.21 and it can be seen that the estimated coeﬃcients are the same as the logistic regression. The initial values for the optimization routine were at the origin. Table 5.21: Results from Minimizing the Log-Loss on FOC Data. Parameter Estimated Value β0 −11.8705 βchol 0.0114 βsbp 0.0107 βage 0.0968 57 5.4.4 Optimizing the Brier Score on the FOC Data Similar to the optimization of the Log-Loss, the Brier Score will also be ﬁnding a solution that includes an intercept term. The estimates of the coeﬃcients that minimize the Brier Score are shown in table 5.22. The initial values for the optimization routine were also at the origin. Table 5.22: Results from Minimizing the Brier Score on FOC Data. Parameter Estimated Value β0 −9.5440 βchol 0.0089 βsbp 0.0060 βage 0.0754 5.4.5 Optimizing the AUC on the FOC Data Lastly, the optimization of the AUCRanks function was completed on the FOC data. As in previous examples of optimizing the AUCRanks function, an intercept term is not included and the ranked function is of linear form, not logistic. The resulting estimates are shown in table 5.23. The initial values for the optimization routine were 0.01 for all coeﬃcients. Table 5.23: Results from Maximizing the AUC on FOC Data. Parameter Estimated Value βchol 0.1608 βsbp 0.1146 βage 0.9803 Note that the norm of the coeﬃcient estimates is equal to 1 as required to ﬁnd a unique solution (√0.16082 + 0.11462 + 0.98032 = 1). Although the initial results appear to be dramatically diﬀerent from those from the logistic regression estimates and the results from the Brier Score and Log-Loss optimization, dividing each estimate by 10 results in the following estimates shown in table 5.24. Table 5.24: Results from Maximizing the AUC on FOC Data with Comparisons. Parameter Estimated Value Estimate/10 Logistic Regression Coeﬃcient Estimate βchol 0.1608 0.0161 0.0114 βsbp 0.1146 0.0115 0.0107 βage 0.9803 0.0980 0.0968 58 Note that dividing each estimate by 10 does not impact the ranking and therefore does not impact the AUC. 5.4.6 Summary of Estimated Coeﬃcients and Predictive Accuracy Measures The estimated coeﬃcients for each of the optimization routines and for logistic regression can be found in table 5.25. It is clear that most of the approaches result in very similar estimates for the coeﬃcients. Table 5.25: Coeﬃcient Estimates for the FOC Data. Optimization Routine Logistic Regression Log-Loss Brier Score AUCRanks Parameter β0 −11.8705 −11.8705 −9.5440 n/a βchol 0.0114 0.0114 0.0089 0.0161 βsbp 0.0107 0.0107 0.0060 0.0115 βage 0.0968 0.0968 0.0754 0.0980 For each of coeﬃcient estimates, predictions can be made on the FOC data and predictive accuracy measures reported. Again, since the functional form of the AUCRanks function is linear, the output are not truly probabilities and calculating the Log-Loss or Brier Score is therefore inappropriate. The resulting values of the predictive accuracy measures are shown in table 5.26. Table 5.26: Calculated Predictive Accuracy Measures on FOC Data for Each Optimization Routine. Optimized Function Log-Loss Brier Score Area Under the ROC Curve Log-Loss 0.0878 0.0201 0.8321 Brier Score 0.0888 0.0200 0.8317 AUCRanks n/a n/a 0.8337 As seen in the simulation studies, the maximum predictive accuracy measure is achieved for each of their respective optimization routines (as marked in bold), i.e. the AUC is highest for the coeﬃcients that maximized the AUCRanks function. 5.4.7 Optimizing the AUC on the Original 55 Data Sets In this section, a comparison of the optimization of the AUC and logistic regression will be completed on the original 55 data sets from section 3.2. For this comparison, ﬁrst a logistic 59 regression model will be ﬁt on each of the data sets. Then the estimated coeﬃcients will be used as starting values for the AUC optimization routine. Again, the explanatory variables of interest are age, systolic blood pressure and cholesterol and the dependent variable is death due to coronary heart disease. In the table below, the parameter estimates are shown that result from logistic regression and AUC optimization. The values in parentheses are the starting values used for the AUC optimization (recall the restriction that the norm of the estimated β vector in the AUC optimization routine must be 1). Although most of the estimates that maximize the AUC are similar to the “normalized” coeﬃcients from logistic regression, there are a few examples of large diﬀerences (see the highlighted studies 10, 17, 25, 37, 46 and 55). Futhermore, there are examples where the sign of the coeﬃcient is diﬀerent that maximizes the AUC versus the estimate for logistic regression (see the bolded entries in the table for studies 6 and 52). However, this occurrence is in the models with very small coeﬃcient estimates for cholesterol and may not actually be signiﬁcant factors in the model. The next comparison is to look at the value of the AUC for the logistic regression model versus the AUC linear model for each data set. The results are in table 5.28, which is sorted by descending diﬀerence in AUC. In all 55 data sets, the AUC of the linear model with coeﬃcients from the AUC optimization is higher than the AUC from the logistic regression model. 60 Table 5.27: Comparison of the Coeﬃcient Estimates for the 55 Data Sets. Study β0,LR βage,LR βage,AU C βsbp,LR βsbp,AU C βchol,LR βchol,AU C 1 -18.3577 0.1227 (0.9731) 0.9712 0.0266 (0.2107) 0.2179 0.0117 (0.0927) 0.0967 2 -11.1022 0.0668 (0.9684) 0.9550 0.0159 (0.2309) 0.2819 0.0065 (0.0942) 0.0929 3 -12.7397 0.0490 (0.9229) 0.9155 0.0183 (0.3443) 0.3370 0.0092 (0.1725) 0.2198 4 -11.3413 0.0741 (0.9865) 0.9857 0.0091 (0.1211) 0.1339 0.0083 (0.1099) 0.1028 5 -6.4651 0.0453 (0.9820) 0.9805 0.0071 (0.1534) 0.1683 0.0051 (0.1101) 0.1017 6 -4.4549 0.0341 (0.9721) 0.9874 0.0082 (0.2347) 0.1567 -0.0001 (-0.0019) 0.0239 7 -8.2702 0.0333 (0.8467) 0.9449 0.0196 (0.4970) 0.3147 0.0075 (0.1899) 0.0902 8 -5.2575 0.0533 (0.9941) 0.9771 0.0053 (0.0984) 0.2011 0.0025 (0.0468) 0.0701 9 -10.3156 0.0633 (0.9021) 0.9048 0.0279 (0.3972) 0.3818 -0.0118 (-0.1684) -0.1889 10 -14.9838 0.1189 (0.9891) 0.9702 -0.0027 (-0.0228) -0.2079 0.0175 (0.1454) 0.1243 11 -13.8645 0.1149 (0.9974) 0.9962 0.0079 (0.0682) 0.0818 0.0028 (0.0240) 0.0295 12 -8.1221 0.0706 (0.9991) 0.9997 0.0029 (0.0416) 0.0101 -0.0006 (-0.0081) 0.0210 13 -5.7438 0.0412 (0.9767) 0.9501 0.0089 (0.2117) 0.3097 0.0015 (0.0345) 0.0381 14 -4.5043 0.0298 (0.9486) 0.9487 0.0098 (0.3125) 0.3030 -0.0015 (-0.0494) -0.0907 15 -7.1211 0.0524 (0.9807) 0.9619 0.0079 (0.1489) 0.2356 0.0068 (0.1268) 0.1384 16 -5.4549 0.0376 (0.9581) 0.8685 0.0105 (0.2677) 0.4923 0.0040 (0.1016) 0.0583 17 -8.9690 0.0467 (0.9323) 0.8872 0.0160 (0.3197) 0.4346 0.0085 (0.1693) 0.1554 18 -6.5652 0.0308 (0.8863) 0.8809 0.0140 (0.4034) 0.4060 0.0079 (0.2274) 0.2432 19 -17.4691 0.0830 (0.9147) 0.9155 0.0301 (0.3320) 0.3345 0.0209 (0.2307) 0.2235 20 -9.9637 0.1013 (0.9951) 0.9906 0.0010 (0.0102) 0.0093 0.0100 (0.0987) 0.1368 21 -10.5060 0.0804 (0.9928) 0.9930 0.0079 (0.0972) 0.1007 0.0057 (0.0699) 0.0615 22 -7.3495 0.0527 (0.9692) 0.9711 0.0134 (0.2462) 0.2385 -0.0005 (-0.0101) -0.0138 23 -11.7562 0.0786 (0.9859) 0.9851 0.0093 (0.1164) 0.1193 0.0096 (0.1205) 0.1238 24 -11.1669 0.0871 (0.9837) 0.9847 0.0153 (0.1724) 0.1576 0.0046 (0.0521) 0.0738 25 -9.6003 0.0231 (0.7478) 0.6953 0.0197 (0.6371) 0.6954 0.0058 (0.1871) 0.1818 26 -8.7783 0.0611 (0.9876) 0.9872 0.0078 (0.1258) 0.1303 0.0058 (0.0941) 0.0919 27 -13.5418 0.0509 (0.8369) 0.8370 0.0327 (0.5379) 0.5392 0.0062 (0.1016) 0.0938 28 -10.1844 0.0741 (0.9844) 0.9583 0.0118 (0.1571) 0.2806 0.0060 (0.0795) 0.0541 29 -11.0398 0.0626 (0.9477) 0.9414 0.0191 (0.2889) 0.3100 0.0090 (0.1357) 0.1325 30 -10.8512 0.0845 (0.9785) 0.9572 0.0177 (0.2053) 0.2854 0.0015 (0.0174) 0.0476 31 -10.4328 0.0791 (0.9853) 0.9852 0.0105 (0.1310) 0.1315 0.0088 (0.1101) 0.1098 32 -13.5595 0.1074 (0.9921) 0.9909 0.0077 (0.0715) 0.0748 0.0112 (0.1036) 0.1118 33 -11.2239 0.0884 (0.9875) 0.9738 0.0107 (0.1191) 0.1906 0.0092 (0.1031) 0.1242 34 -7.8930 0.0536 (0.9824) 0.9855 0.0100 (0.1831) 0.1665 0.0021 (0.0378) 0.0312 35 -8.3898 0.0510 (0.9644) 0.9623 0.0137 (0.2588) 0.2654 0.0029 (0.0545) 0.0592 36 -8.5397 0.0707 (0.9866) 0.9831 0.0116 (0.1624) 0.1823 0.0013 (0.0184) 0.0147 37 -8.7641 0.0498 (0.9545) 0.9188 0.0131 (0.2504) 0.3242 0.0085 (0.1622) 0.2253 38 -10.7668 0.1049 (0.9941) 0.9931 0.0112 (0.1066) 0.1141 0.0023 (0.0217) 0.0282 39 -8.5191 0.0699 (0.9819) 0.9643 0.0128 (0.1804) 0.2529 0.0041 (0.0570) 0.0786 40 -11.5559 0.0897 (0.9877) 0.9879 0.0124 (0.1365) 0.1366 0.0070 (0.0769) 0.0731 41 -10.8363 0.0787 (0.9872) 0.9784 0.0075 (0.0935) 0.1280 0.0103 (0.1296) 0.1621 42 -12.3560 0.1039 (0.9917) 0.9906 0.0126 (0.1208) 0.1306 0.0047 (0.0452) 0.0407 43 -10.3594 0.0928 (0.9924) 0.9911 0.0105 (0.1122) 0.1264 0.0048 (0.0509) 0.0421 44 -11.2426 0.0686 (0.9508) 0.9295 0.0218 (0.3030) 0.3617 0.0047 (0.0645) 0.0729 45 -11.6550 0.0727 (0.9572) 0.9372 0.0208 (0.2733) 0.3311 0.0072 (0.0949) 0.1094 46 -10.2982 0.0853 (0.9821) 0.9582 0.0163 (0.1873) 0.2859 0.0019 (0.0215) 0.0145 47 -10.1475 0.0741 (0.9688) 0.9673 0.0168 (0.2195) 0.2243 0.0088 (0.1148) 0.1187 48 -10.2477 0.0733 (0.9429) 0.9262 0.0258 (0.3316) 0.3733 -0.0024 (-0.0305) -0.0533 49 -11.0293 0.0685 (0.9555) 0.9562 0.0194 (0.2708) 0.2690 0.0084 (0.1168) 0.1156 50 -9.8943 0.0831 (0.9954) 0.9942 0.0069 (0.0826) 0.0956 0.0041 (0.0491) 0.0494 51 -9.5577 0.0771 (0.9871) 0.9876 0.0117 (0.1497) 0.1376 0.0044 (0.0563) 0.0752 52 -8.7219 0.0872 (0.9996) 0.9964 0.0024 (0.0280) 0.0848 0.0008 (0.0097) -0.0086 53 -7.6137 0.0658 (0.9965) 0.9925 0.0038 (0.0576) 0.1008 0.0040 (0.0607) 0.0700 54 -10.7065 0.0916 (0.9928) 0.9900 0.0105 (0.1135) 0.1391 0.0036 (0.0393) 0.0256 55 -9.3553 0.0768 (0.9845) 0.9490 0.0136 (0.1742) 0.3128 0.0017 (0.0224) 0.0383 61 Table 5.28: Comparison of the AUC for the 55 Data Sets. Study Number Incidence Rate AU CLR AU CAU CRanks Diﬀerence 10 4.878% 0.69331 0.70433 0.011018 8 23.290% 0.69247 0.69757 0.005106 41 6.368% 0.77601 0.77992 0.003918 6 18.971% 0.67010 0.67393 0.003834 7 14.820% 0.77238 0.77607 0.003692 13 15.955% 0.69321 0.69588 0.002670 28 5.300% 0.72368 0.72627 0.002592 9 2.052% 0.77818 0.78061 0.002424 17 10.497% 0.75053 0.75273 0.002193 16 24.510% 0.68522 0.68735 0.002127 25 2.658% 0.72920 0.73129 0.002095 2 2.053% 0.67663 0.67839 0.001760 46 5.716% 0.89967 0.90124 0.001567 30 3.990% 0.84046 0.84201 0.001544 15 18.406% 0.75878 0.76017 0.001391 55 4.476% 0.87654 0.87781 0.001270 44 3.054% 0.73196 0.73320 0.001237 20 3.757% 0.80262 0.80383 0.001214 12 7.035% 0.61284 0.61387 0.001026 52 3.234% 0.89059 0.89158 0.000983 33 4.234% 0.83532 0.83624 0.000919 24 5.260% 0.75693 0.75784 0.000909 39 14.014% 0.77807 0.77894 0.000865 11 2.627% 0.72216 0.72298 0.000817 26 5.263% 0.71008 0.71087 0.000790 21 3.023% 0.75581 0.75659 0.000779 27 2.906% 0.78081 0.78159 0.000777 5 16.628% 0.73334 0.73406 0.000712 14 16.216% 0.65280 0.65351 0.000709 48 2.979% 0.75003 0.75064 0.000614 36 7.217% 0.81351 0.81405 0.000542 3 0.332% 0.68906 0.68960 0.000533 45 4.153% 0.74434 0.74486 0.000520 19 0.544% 0.92525 0.9257 0.000456 53 5.684% 0.82716 0.82762 0.000454 42 4.709% 0.80454 0.80488 0.000337 32 2.139% 0.87929 0.87962 0.000324 29 5.239% 0.70350 0.70377 0.000269 37 12.353% 0.75539 0.75565 0.000260 54 3.178% 0.90534 0.90560 0.000259 40 6.464% 0.81074 0.81098 0.000239 23 3.527% 0.75664 0.75687 0.000229 1 0.608% 0.83399 0.83420 0.000218 51 11.458% 0.83695 0.83715 0.000204 4 1.369% 0.66986 0.67003 0.000167 43 9.412% 0.77166 0.77182 0.000164 22 7.830% 0.69711 0.69725 0.000148 34 3.143% 0.61097 0.61111 0.000146 38 7.353% 0.86055 0.86068 0.000129 18 22.415% 0.65946 0.65957 0.000109 50 7.521% 0.85530 0.85541 0.000107 47 11.271% 0.83205 0.83213 0.000079 35 3.510% 0.62090 0.62097 0.000074 49 3.908% 0.76668 0.76674 0.000054 31 5.818% 0.79890 0.79893 0.000037 62 CHAPTER 6 CONSISTENCY AND ASYMPTOTIC BEHAVIOR OF THE COEFFICIENT ESTIMATES FROM THE AUCRANKS OPTIMIZATION 6.1 Relationship to the Maximum Rank Correlation Estimator The use of the Wilcoxon statistic for maximizing the area under the ROC curve has been commonly referred to as a special case of the Maximum Rank Correlation (MRC) estimator [33, 39]. This connection has been mentioned due to the extensive research on the Maximum Rank Correlation Estimator, especially related to consistency and asymptotic behavior [9, 36]. To see the obvious connection, Han [14] assumed independent observations with outcome Y and regressors X and formulated equation 6.1 below. The Maximum Rank Correlation Estimator is the value of β that maximizes the function G, where [u] = I(u). G(β) = 1 n(n − 1) ∑ i̸=j [Yi > Yj][X T i β > X T j β] (6.1) When Y is a binary variable (as is the case in logistic regression), the term inside the sum of G(β) is the same as the Wilcoxon statistic used to calculate the area under the ROC curve. The factor of 1 n(n−1) is not the same as the Wilcoxon statistic, but it is independent of β so the maximization is not impacted. 6.1.1 Consistency and Distribution of the Maximum Rank Correlation Estimator The most straightforward proof of √n-consistency and asymptotic normal theory of the Maxi- mum Rank Correlation Estimator can be found in the works completed by Robert P. Sherman [36] and Aaron K. Han [14]. A brief outline of those works is given in the following sections as it is used later to show similar properties for the estimates resulting from the AUCRanks optimization. For notation of the “unique” maximum, Han used the normalized parameters (the approach in our estimator) while Sherman restricted the parameter space to a d − 1 dimensional subset of Rd. 63 Assumption 1 used by both Han and Sherman below was “speciﬁcally designed” to identify the unique parameter values [14]. Assumption 1: The support of the vector of k X regressors is not contained in any proper linear subspace of Rk. Additionally, there exists at least one component of X, xh with β0,h ̸= 0 and with everywhere positive Lebesgue density conditional on all the other components. This assumption is to assure that there is no co-linearity within any of the attributes in X and helps to provide continuous neighborhoods on an otherwise discontinuous step-function. Consistency of the Maximum Rank Correlation Estimator. The property of consis- tency is that the estimator converges to the “correct” value as the sample size approaches inﬁnity [8]. To think visually, a consistent estimator has the property that the distribution shrinks around the true value of the parameter as the sample size gets larger. To prove consistency, Han took a three step approach. First, he proved that there exists a unique maximum, β∗, to which the estimator will converge. Next, he showed uniform convergence of the otherwise discontinuous function G(β) to a continuous function within a small neighborhood of β∗. Using the continuous function and the identiﬁability of the unique maximum, Han was able to show consistency of the estimator. Distribution of the Maximum Rank Correlation Estimator. In the original paper, Han mentions that the “asymptotic distribution of the MRC estimator is not determined due to the diﬃculty that arises from the discontinuity of the maximand” [14]. However, in 1993, Robert P. Sherman was able to prove asympototic normality of the MRC estimator. He deﬁnes τ (z, θ) below in 6.2 as the “kernel of the empirical process that drives the asymptotic behavior of θn”. Note that z represents an observation of predictor and the response: x and y. τ (z, θ) = E[(y > Y )(x′β(θ) > X ′β(θ))] + E[(y < Y )(x′β(θ) < X ′β(θ))] (6.2) Recall Sherman uses the d − 1 approach to uniqueness, so β(θ) = (θ, 1). The other notation used is ∇m as the mth partial derivative with respect to θ. There is one additional assumption (Assumption 2) Sherman uses to prove asymptotic normality. Assumption 2: Let N denote a neighborhood of 0. (assuming 0 maximizes G(β)) 64 1. For each z in the support of the vector of regressors, all mixed partial derivatives of τ (z, θ) exist on N . 2. There is an integrable function M (z) such that for all z in the support of the vector of regressors and θ in N ∥∇2τ (z, θ) − ∇2τ (z, 0)∥ ≤ M (z)|θ| 3. E|∇1τ (·, θ)|2 < ∞ 4. E|∇2τ (·, 0)| < ∞ 5. The matrix of E∇2τ (·, θ) is negative deﬁnite The conditions set in this assumption are “standard regularity conditions suﬃcient to support an argument based on Taylor expansion of τ (z, ·) about 0”[36]. In order to estimate the covariance matrix of the asymptotic normal distribution, Sherman suggests using numerical derivatives – an approach computationally expensive and found to be unstable in practice by Sherman himself. 6.2 Other Rank Estimators In 1998, Cavanagh and Sherman [9] introduced a new class of rank estimators for semiparametric monotonic linear index models. For observations (X, Y ), an increasing function on R, M (y), and a ranking function, R(xi), as the rank of xi, the function they propose maximizing is shown in 6.3. βn = arg max β ∑ i M (Yi)R(X T β) (6.3) Many suggestions for the function M (y) are proposed by the authors including letting M (·) = R(·) or the identity function, M (y) = y. When the choice of M (y) is the identity function and Y is a binary variable, this semiparametric linear index model is identical to the AUCRanks function from section 5.2.3. 6.2.1 Consistency and Distribution of the AUCRanks Estimator Cavanagh and Sherman proved √n-consistency and asymptotic normality of βn in their pa- per and therefore the estimate that maximizes the AUCRanks function is also √n-consistent and asymptotically normal [9]. The formal proof follows a similar outline used for the Maximum Rank Correlation estimator. 65 To verify the consistency and asymptotic normality theory, the sampling distribution of the parameter estimates resulting from the AUCRanks optimization was analyzed. To do this, multiple samples of simulated data were generated and AUCRanks estimates found for each sample. The sample sizes (N ) considered for this study were 500, 1,000, 5,000 and 10,000 and for each sample size, 500 replicates were generated. Each sample had data generated using the logistic framework, similar to section 3.4.1. We conducted the simulations under two diﬀerent incidence rates (α) by controlling the intercept parameter: one close to 50% and one close to 2.5%. The true “normed” values of the parameters in the two simulations were 0.5547 for β1 and −0.8321 for β2. The results for the samples with an average incidence rate of about 50% are shown in the ﬁgures 6.1 through 6.8 and table 6.1 below. Although the histograms appear to ﬁt a normal distribution, the Kolmogorov–Smirnov test for normality indicates that only when the sample size is 10,000 does the sampling distribution not statistically diﬀer from the normal distribution (as seen in table 6.1). Figure 6.1: Histogram of ˆβ1, N = 500, ¯α = 0.500. Figure 6.2: Histogram of ˆβ1, N = 1, 000, ¯α = 0.500. Figure 6.3: Histogram of ˆβ1, N = 5, 000, ¯α = 0.500. Figure 6.4: Histogram of ˆβ1, N = 10, 000, ¯α = 0.500. 66 Figure 6.5: Histogram of ˆβ2, N = 500, ¯α = 0.500. Figure 6.6: Histogram of ˆβ2, N = 1, 000, ¯α = 0.500. Figure 6.7: Histogram of ˆβ2, N = 5, 000, ¯α = 0.500. Figure 6.8: Histogram of ˆβ2, N = 10, 000, ¯α = 0.500. Table 6.1: Results from Studies with Incidence Rate Near 50%. N Parameter Sample Mean of Parameter Estimates Sample Standard Deviation of Parameter Estimates K-S Statistic p-value 500 β1 0.5517 0.0519 0.0626 < 0.010 500 β2 −0.8317 0.0344 0.0651 < 0.010 1000 β1 0.5546 0.0382 0.0753 < 0.010 1000 β2 −0.8309 0.0256 0.0853 < 0.010 5000 β1 0.5542 0.0170 0.0421 0.029 5000 β2 −0.8321 0.0113 0.0485 < 0.010 10000 β1 0.5549 0.0117 0.0267 > 0.150 10000 β2 −0.8318 0.0078 0.0289 > 0.150 The results for the samples with an average incidence rate of about 2.6% are shown in the ﬁgures 6.9 through 6.16 and table 6.2 below. Again, as seen in the analysis with incidence rate 67 around 50%, although the histograms appear to ﬁt a normal distribution, the KolmogorovSmirnov test for normality indicates that only when the sample size is 10,000 does the sampling distribution not statistically diﬀer from the normal distribution (as seen in table 6.2). Figure 6.9: Histogram of ˆβ1, N = 500, ¯α = 0.0259. Figure 6.10: Histogram of ˆβ1, N = 1, 000, ¯α = 0.0259. Figure 6.11: Histogram of ˆβ1, N = 5, 000, ¯α = 0.0259. Figure 6.12: Histogram of ˆβ1, N = 10, 000, ¯α = 0.0260. Figure 6.13: Histogram of ˆβ2, N = 500, ¯α = 0.0259. Figure 6.14: Histogram of ˆβ2, N = 1, 000, ¯α = 0.0259. 68 Figure 6.15: Histogram of ˆβ2, N = 5, 000, ¯α = 0.0259. Figure 6.16: Histogram of ˆβ2, N = 10, 000, ¯α = 0.0259. Table 6.2: Results from Studies with Incidence Rate Near 2.5%. N Parameter Sample Mean of Parameter Estimates Sample Standard Deviation of Parameter Estimates K-S Statistic p-value 500 β1 0.5439 0.1838 0.0659 < 0.010 500 β2 −0.8099 0.1203 0.0778 < 0.010 1000 β1 0.5515 0.1299 0.0606 < 0.010 1000 β2 −0.8195 0.0856 0.0423 0.028 5000 β1 0.5581 0.0554 0.0578 < 0.010 5000 β2 −0.8294 0.0372 0.0439 0.020 10000 β1 0.5567 0.0394 0.0398 0.053 10000 β2 −0.8294 0.0262 0.0283 > 0.150 6.3 Estimating the Variation in the Estimators While asymptotic normality has been proven for the AUCRanks estimator, estimating the covariance matrix is important in order to apply the theory to real data. Sherman and Cavanagh supply methods to estimate the covariance matrix using numerical derivatives. However, due to the derivatives being “numerically unstable”, they also present kernel methods and suggest bootstrap approaches as alternatives. In the results of their real data analysis, the standard errors calculated using kernel methods and bootstrap samples were nearly identical [9]. To further investigate the asymptotic normality of the AUCRanks estimator, bootstrap samples of the data and a histogram plot of the estimates can be analyzed. If the theory holds, the estimates 69 should follow a normal distribution. We analyze both a simulated data set and use a real data set to show the distribution of the parameter estimates. The simulated data will be the same used in previous sections that assumes a logistic framework and two continuous parameters that arise from a normal distribution. For the speciﬁcs, reference section 5.3.1. The two histogram plots below are for the estimates found from 300 bootstrap samples of the simulated data. The true values for the two parameters are 0.5547 for β1 and −0.8321 for β2. Figure 6.17: Histogram of ˆβ1 that maximizes the AUC in the simulated data. Figure 6.18: Histogram of ˆβ2 that maximizes the AUC in simulated data. The results from the simulated data may not be completely convincing as the covariates x1 and x2 are generated using the normal distribution. To further examine the distribution of the parameter estimates, a real data set should be used. For this example, we will use the Framingham 70 Oﬀspring Data described in section 5.4.1 and look at the distribution of the parameter estimates for cholesterol, age and systolic blood pressure. As a reminder, there are a total number of 4,363 observations in the data set and the incidence rate is 2.12%. The histograms of the estimates from 300 bootstrap samples are shown in the ﬁgures below. Figure 6.19: Histogram of βchol that maximizes the AUC in the FOC data. Figure 6.20: Histogram of βage that maximizes the AUC in the FOC data. Figure 6.21: Histogram of βsbp that maximizes the AUC in the FOC data. 71 While not perfectly normal in the simulated or real data examples, the parameter estimates do seem to follow a normal distribution as the theory suggests. These results will be helpful in the next section where we attempt to compute standard errors for the coeﬃcient estimates and compare the results to logistic regression. 72 CHAPTER 7 DETERMINING THE UNCERTAINTY IN OPTIMIZATION RESULTS One desirable property of logistic regression is the ease of acquiring a measure of uncertainty in the coeﬃcient estimates - this is most commonly referred to as the standard error for the estimated coeﬃcient. When using maximum likelihood methods (as is done in logistic regression), the variance-covariance matrix of the estimated parameters is approximated by the inverse of the observed Fisher Information. The elements of the information matrix are the partial second derivatives of the log-likelihood function evaluated at the maximum likelihood estimates. However, optimization of the AUC and Brier Score do not rely on the likelihood and standard errors for the coeﬃcient estimates are not immediate. The theory presented in the previous chapter provided a framework to estimate standard errors for the estimates that maximize the AUCRanks function. There are three methods available to acquire standard errors for the estimates: numerical derivatives, kernel based methods or from bootstrap samples. Due to the diﬃculty and instability of the numerical derivatives, that method will not be considered. Results from Cavanagh and Sherman showed almost exactness between the kernel based estimates and bootstrap estimates and therefore, the bootstrap approach will be taken due to its ease of implementation [9]. The bootstrap is a re-sampling technique commonly used in statistics. Each bootstrap replicate is a random sample drawn with replacement from the original data of equal size to the original data. For each bootstrap sample, the estimate of the measure of interest can be calculated, and the bootstrap estimate of standard error for the measure of interest is the sample standard deviation of the bootstrap estimates [13]. The bootstrap approach will be taken to calculate the standard errors for all of the optimization routines. 7.1 Calculating Standard Errors on Simulated Data Using the same simulated data that was generated for the ﬁrst simulation in section 5.3.1, an estimate of the standard errors can be found for the estimated coeﬃcients found using the 73 optimization routines. First, the estimates and standard errors for each coeﬃcient found using standard logistic regression maximum likelihood techniques are shown in table 7.1. Table 7.1: Coeﬃcients and Standard Errors from Logistic Regression Model. Parameter Estimated Coeﬃcient Standard Error of Estimate β0 0.5786 0.1199 β1 2.1127 0.2738 β2 −3.1876 0.3162 For the optimization routines, minimizing the Log-Loss and Brier Score and maximizing the AUCRanks, the results of a bootstrap approach are shown in tables 7.2, 7.3 and 7.4 below. The estimates for the coeﬃcients are those found using the original data set as reported in section 5.3. The standard errors are the result of 100 bootstrap samples. For each sample, the parameter estimate was found, and the standard deviation of the 100 estimates is reported as the standard error in the tables below. Table 7.2: Coeﬃcients and Standard Errors from Optimizing the Log-Loss. Parameter Estimated Coeﬃcient Standard Error of Estimate β0 0.5786 0.1151 β1 2.1126 0.2527 β2 −3.1876 0.3246 Table 7.3: Coeﬃcients and Standard Errors from Optimizing the Brier Score. Parameter Estimated Coeﬃcient Standard Error of Estimate β0 0.5167 0.1144 β1 2.0670 0.2705 β2 −3.1493 0.4160 Table 7.4: Coeﬃcients and Standard Errors from Optimizing the AUCRanks. Parameter Estimated Coeﬃcient Standard Error of Estimate β1 0.5422 0.056 β2 −0.8402 0.038 74 The standard errors found using the bootstrap samples are quite similar for the Log-Loss and Brier Score. These estimates are also relatively close to the values found in the logistic regression procedure. At ﬁrst glance, the standard errors calculated for the AUCRanks estimates seem ex- tremely small in comparison to the other approaches. However, recall that the parameter estimates have been restricted to have a norm of 1. Since we were able to multiply the coeﬃcients by a con- stant and maintain the same ranks to compare the coeﬃcient estimates, the standard errors could be “corrected” for comparison as well. In the original exercise, the coeﬃcients were multiplied by 3.75 for comparison so the same approach will be taken here. Using the fact that se(αX) = αse(X), the standard errors for the coeﬃcient estimates found using the AUCRanks function are 0.2175 for β1 and 0.1431 for β2. It is not surprising to see that the standard errors for the AUCRanks solutions are smaller than the other two optimization techniques. The restriction of the norm of the β vector equaling 1 restricts the range of values that each element of β can take. Furthermore, the AUCRanks function is only considering two parameters in its optimization routine. The Log-Loss and Brier Score are including the estimation of the intercept term and that can inﬂuence the estimates of β1 and β2. 7.2 Calculating Standard Errors on FOC Data The same exercise can be completed on the FOC data from the previous section. Again, the estimates are those found on the original data set and the standard errors are calculated from the bootstrap samples. Table 7.5: Results from Logistic Regression Model on FOC Data. Parameter Estimated Coeﬃcient Standard Error p-value β0 −11.8705 0.8786 < 0.0001 βchol 0.0114 0.0023 < 0.0001 βsbp 0.0107 0.0054 0.0483 βage 0.0968 0.0144 < 0.0001 Again, the standard errors look signiﬁcantly diﬀerent, but correcting the coeﬃcients to be on the same magnitude as the other optimization results (dividing by 10), the standard errors are much closer to the standard errors found from the other optimization routines, with the exception of the coeﬃcient for age. 75 Table 7.6: Coeﬃcients and Standard Errors from Optimizing the Log-Loss on FOC Data. Parameter Estimated Coeﬃcient Standard Error of Estimate β0 −11.8705 0.7537 βchol 0.0114 0.0021 βsbp 0.0107 0.0048 βage 0.0968 0.0147 Table 7.7: Coeﬃcients and Standard Errors from Optimizing the Brier Score on FOC Data. Parameter Estimated Coeﬃcient Standard Error of Estimate β0 −9.5440 0.8306 βchol 0.0089 0.0040 βsbp 0.0060 0.0058 βage 0.0754 0.0241 Table 7.8: Coeﬃcients and Standard Errors from Optimizing the AUCRanks on FOC Data. Parameter Estimated Coeﬃcient Standard Error of Estimate βchol 0.1608 0.0449 βsbp 0.1146 0.0697 βage 0.9803 0.0168 76 CHAPTER 8 CASE STUDY: BOSTON HOUSING DATA 8.1 Boston Housing Data The Boston Housing data is a free, public data set available through the University of California Irvine Machine Learning Repository (http://archive.ics.uci.edu/ml/). The data set contains hous- ing attributes for various suburbs of Boston. The independent variables of interest for this case study are the pupil to teacher ratio (PTRATIO), the weighted distances to ﬁve Boston employ- ment centers (DIS) and the nitric oxides concentration in parts per 10 million(NOX). The response variable of interest is a binary indicator that the median value of owner-occupied homes is greater than $45,000 (Y). Three sample observations from the dataset are shown in table 8.1. Table 8.1: A subset of the Boston Housing Data. NOX DIS PTRATIO Y 0.401 6.2196 15.6 0 0.422 5.6484 14.4 1 0.404 7.3090 12.6 0 The total number of suburbs in the data set is 506 (N =506) and the number of suburbs with median value of owner-occupied homes greater than $45,000 is 22 (∑i yi = 22). This results in an incidence rate of 4.35%. 8.2 Two Parameter Model To demonstrate the beneﬁts of optimizing the AUC using the AUCRanks function over standard logistic regression using maximum likelihood, the results from ﬁtting a model using only DIS and PTRATIO as dependent variables will be compared. The evaluation measure used to compare the two models will be the area under the ROC curve. 77 For the ﬁrst model, a logistic regression framework will be used to ﬁnd the maximum likelihood estimates. The results for this model are found in table 8.2 and the resulting AUC for this model is 0.8526. Table 8.2: Results from Logistic Regression Model on Boston Housing Data. Parameter Estimated Coeﬃcient Standard Error p-value β0 5.5050 1.5522 0.0004 βDIS −0.3018 0.1330 0.0232 βP T RAT IO −0.4321 0.0901 < 0.0001 Using the estimates from the logistic regression to ﬁnd starting values, we use the AUCRanks optimization routine to ﬁnd the coeﬃcients for DIS and PTRATIO that maximize the area under the ROC curve. The estimates can be found in table 8.3 and the calculated AUC on the data is 0.8836. Table 8.3: Results from Maximizing the AUC on Boston Housing Data. Parameter Estimated Coeﬃcient βDIS −0.7593 βP T RAT IO −0.6507 It is clear that the ratio of the coeﬃcients is diﬀerent for the two models and that the AUC is larger for the AUCRanks model than the logistic regression model. In order to determine if the AUCRanks model is statistically signiﬁcantly better than the logistic regression model, a test of the AUCs can be performed. 8.3 Comparing Two AUCs DeLong, Delong and Clarke-Pearson provided a nonparametric framework to compare multiple areas under correlated ROC curves [12]. When two models (in our case one maximizing the AUC and the other maximizing the log-likelihood) are ﬁt on the same data and the resulting AUCs calculated on the same data, the correlation must be addressed. The approach taken by DeLong et al. is a nonparametric approach that relies on the well developed properties of the Mann-Whitney U Statistic. It is also the method used when the ROCCONTRAST statement is called in the Proc Logistic procedure in SAS. 78 Following this approach, the estimated diﬀerence between the AUCs for the two models above is 0.0311 with standard error 0.0158. A 95% conﬁdence interval for the diﬀerence between the two AUCs is (0.0602, 0.0002), which would lead us to believe that the diﬀerence between AUCs is signiﬁcantly diﬀerent using a signiﬁcance level of 0.05. We can conclude that the AUC from the model that maximizes the AUC is statistically signiﬁcantly greater than the AUC that results from maximizing the log-likelihood. 8.4 Evaluating the Impact of Adding a Variable There has been a signiﬁcant amount of research dedicated to the analysis of including an additional variable in a model [31, 30]. The following exercise will highlight the diﬀerence in conclusion regarding the addition of a variable when considering the evaluation criterion. Using the Boston Housing data and the previous models, the question of whether or not to include the variable NOX will be addressed. It is noteworthy that the AUC of the variable NOX alone is merely 0.5029. If we ﬁt the logistic regression model with NOX included the resulting coeﬃcient estimates are shown below in table 8.4. Table 8.4: Results from Logistic Regression Model w/NOX on Boston Housing Data. Parameter Estimated Coeﬃcient Standard Error p-value β0 19.4566 4.7351 < 0.0001 βDIS −1.2174 0.3340 0.0003 βP T RAT IO −0.5566 0.1094 < 0.0001 βN OX −16.0745 5.2273 0.0021 The likelihood ratio test yields a test statistic of 16.876 (152.580−135.704 = 16.876) on 1 degree of freedom, which results in a small p-value indicating the variable NOX should be included in the model. Similarly, the AUC for the new model including NOX is 0.8835, which is statistically signiﬁcantly diﬀerent from the AUC of the model without NOX (0.8526). If we ﬁnd the coeﬃcients that maximize the AUCRanks, the results are shown in table 8.5 below. The AUC for the new model including NOX is 0.8866, which is not statistically diﬀerent from the AUC of 0.8836 for the model that excluded NOX. 79 Table 8.5: Results from Maximizing the AUC with NOX variable included. Parameter Estimated Coeﬃcient βDIS −0.4167 βP T RAT IO −0.3090 βN OX −0.8549 What has been discovered here is a situation where maximizing the AUC can provide a diﬀerent solution than the logistic regression model. The preferred AUC model would only include DIS and PTRATIO while the logistic regression model would include DIS, PTRATIO and NOX. The choice of model will lie in the hands of the researcher and the contextual use of the model. If strictly for prediction, the use of the AUCRanks model would be suggested. If the model requires interpretation, the three parameter logistic regression model would be preferable. 80 CHAPTER 9 DISCUSSION AND FUTURE WORK 9.1 Discussion This work has provided a sound analysis and demonstration of the relationships among the predictive accuracy measures for a binary outcome. While known relationships were conﬁrmed, a previously undocumented relationship between the log-loss and Brier Score was presented and proven in section 3.3.1. The breakdown in linear relationships among all the measures was shown to be attributed in part to extreme incidence rates in the data. As the incidence rate nears extremes, the relationships among the unrelated measures deteriorate. This phenomenon is especially of interest when looking at the relationship between the Log-Loss and area under the ROC curve. The Log-Loss is intrinsically minimized when the logistic regression model is ﬁt by maximum likelihood methods. However, as mentioned previously, the area under the ROC curve is one of the most commonly reported measure for predictive accuracy in medical research and other ﬁelds. When a logistic regression model is ﬁt using maximum likelihood but then evaluated using the area under the ROC curve, a small incidence rate in the data can result in a disconnected, and sometimes adverse, relationship between two key elements of statistical models – overall ﬁt and predictive accuracy. This is an undesirable scenario and leads to the proposal of alternative maximization (or minimization) techniques when the incidence rate is extreme. Optimization of the continuous and diﬀerentiable measures such as the Brier Score can be completed easily using standard, well documented, derivative based optimization routines. The choice of optimization procedure for this paper was the Newton-Raphson algorithm and was shown to perform well on simulated and real data. Optimization of the area under the ROC curve, on the other hand, required algorithms that do not rely on derivatives. Additionally, the area under the ROC curve is a “rank” based measure and a true unique solution does not exist since a constant addition and/or multiplication of the ranks (or formula generating the ranks) yields the exact same area under the ROC curve. To maximize the area under the ROC curve, a Nelder-Mead Simplex 81 algorithm was implemented, and, to provide a “unique” solution, the estimated regression vector, β, was required to have a norm of 1. The maximization of the area under the ROC curve proposed in this research is simpler and computationally more eﬃcient than previous attempts in the literature to either complete a grid search or maximize the estimate using concordant pairs [33]. Our proposed routine optimizes the sum of the ranks of the true events, a term borrowed from the Mann-Whitney U statistic that is used to estimate the area under the ROC curve. In both simulated data and real data, maximizing the AUC resulted in higher AUCs than achieved from a traditional logistic regression model, especially in low incidence rate settings. The framework used in our optimization of the area under the ROC curve can be easily connected to research in economics related to rank estimators and index models. More speciﬁcally, our formula for AUCRanks (see equation 5.8) is a special case of the rank estimator proposed by Cavanagh and Sherman [9] where the response variable Y is binary and M (y) is the identity function. Because of this, the consistency and asymptotic theory developed for those estimators applies to our estimator. Lastly, we examined the impact of adding an additional variable to a model in a low incidence rate setting. Using the publicly available Boston Housing data, two important conclusions were made when comparing the logistic regression model and the AUCRanks model. First, in a two parameter model, the linear model resulting from AUCRanks yields a statistically signiﬁcant higher area under the ROC curve than the logistic regression model. Additionally, when considering the addition of a third variable into the model, conclusions are diﬀerent between the two approaches. In the logistic regression setting, all tests suggest including the variable in the model. However, the addition of the variable to the AUCRanks linear model would not be recommended. This highlights the impact of low incidence rate on the relationships among the measures. With extreme incidence rate comes a disconnect among the predictive accuracy measures. When dealing with data sets that have extreme incidence rates and a binary outcome of interest, one must seriously consider the context, methods of model building and measures of predictive accuracy. For example, let’s consider two groups interested in reducing the recidivism rates of adults. Group one is interested in providing services to prisoners immediately following their release. Group two, however, is interested in providing services to prisoners currently in prison prior to their release. For group one, the priority is accurate predictions of released prisoners. They need to correctly 82 identify those most likely to be imprisoned again and provide them services to prevent that event. If the incidence rate of recidivism is low, group one should implement the AUCRanks optimization as it will yield a higher area under the ROC curve and better identiﬁcation of the released prisoners at highest risk for recidivism, and thus those that should be provided services. For group two, the goal is to identify factors that will lower the odds of recidivism. For example, if group two found that substance abuse is a signiﬁcant factor impacting the odds of recidivism, they could provide services prior to release to reduce substance abuse issues. Clearly, group two should use a logistic regression approach as interpretation and “prescription” of services is more important than accurate predictions. In conclusion, we have provided an analysis of the relationships among predictive accuracy measures for binary outcomes. The impact of extreme incidence rates was shown to deteriorate the relationships and provide a basis for alternative methods to modeling data with a binary outcome. As with most scenarios in the real world, application of our method and use of optimization of the area under the ROC curve is very contextual and subjective. 9.2 Future Work There are multiple extensions of this research that can be considered for future work. The simplest extension would be to include additional predictive accuracy measures that require discrete predictions in 0,1, such as the Fβ score. The cutoﬀ values used to dichotomize the predictions could be ﬁxed upfront or optimized themselves prior to comparison. Based on our experience with the measures not requiring a cut-oﬀ value, similar, or more severe, results and impact of incidence rate would be expected for the measures requiring cutoﬀ values. Also, in regards to the predictive accuracy measures, the impact of missingness in the response and/or explanatory variables may yield interesting results. Recently, Jerez et al. compared various data imputation techniques and judged their performance using diﬀerences in the AUC [22], and Long et al. discussed potential bias in the estimation of the AUC in the presence of missing data [23]. Combining these ideas and including the incidence rate as a factor may provide suggested imputation routines based on the evaluation measure and incidence rate in the data. With respect to optimizing the area under the ROC curve, occasionally researchers are interested in very speciﬁc regions of the ROC curve, i.e. speciﬁcity greater than 80% [26, 42]. Modifying the 83 optimization to ﬁnd a linear combination of predictors to speciﬁcally maximize area under speciﬁc regions of the ROC curve could be useful in practice and certain settings. Additionally, an adaptive or penalized variable selection technique could be created to assist in ﬁnding the parameters that maximize the area under the ROC curve when the number of variables is large. In addition to our connection to economics, this work is relevant to speciﬁc areas of machine learning. In machine learning, an ensemble consists of a set of independently trained classiﬁers whose predictions are combined for ﬁnal classiﬁcation [24]. One of the most common and simplest ensembles is referred to as “bagging” and was ﬁrst introduced by Leo Breiman [5]. Bagging in a classiﬁcation setting is simply an aggregation of the votes from each of the independent classiﬁers. More advanced ensembling techniques have been developed, such as “stacking”, where instead of simply aggregating the output of each model, “the predictions of a collection of models are given as inputs to a second-level learning algorithm” [37]. While one of the standard choices of the second- level learning algorithm is logistic regression for a binary response, the usage of the AUCRanks optimization should outperform this standard. 84 APPENDIX A IRB CLEARANCE 85 Office of the Vice President for Research Human Subjects Committee Tallahassee, Florida 32306-2742 (850) 644-8673 · FAX (850) 644-4392 APPROVAL MEMORANDUM Date: To: Address: Dept.: From: Thomas L. Jacobson, Chair Re: Use of Human Subjects in Research The application that you submitted to this office in regard to the use of human subjects in the proposal referenced above have been reviewed by the Secretary, the Chair, and two members of the Human Subjects Committee. Your project is determined to be and has been approved by an expedited review process. The Human Subjects Committee has not evaluated your proposal for scientific merit, except to weigh the risk to the human participants and the aspects of the proposal related to potential risk and benefit. This approval does not replace any departmental or other approvals, which may be required. If you submitted a proposed consent form with your application, the approved stamped consent form is attached to this approval notice. Only the stamped version of the consent form may be used in recruiting research If the project has not been completed by you must request a renewal of approval for continuation of the project. As a courtesy, a renewal notice will be sent to you prior to your expiration date; however, it is your responsibility as the Principal Investigator to timely request renewal of your approval from the Committee. You are advised that any change in protocol for this project must be reviewed and approved by the Committee prior to implementation of the proposed change in the protocol. A protocol change/amendment form is required to be submitted for approval by the Committee. In addition, federal regulations require that the Principal Investigator promptly report, in writing any unanticipated problems or adverse events involving risks to research subjects or others. By copy of this memorandum, the chairman of your department and/or your major professor is reminded that he/she is responsible for being informed concerning research projects involving human subjects in the department, and should review protocols as often as needed to insure that the project is being conducted in compliance with our institution and with DHHS regulations. This institution has an Assurance on file with the Office for Human Research Protection. The Assurance Number is IRB00000446. Cc: HSC No. Daniel McGee <mcgee.dan41@gmail.com> 216 OSB 4330 STATISTICS DEPARTMENT THE RISK OF LIPIDS ON CORONARY HEART DISEASE:PROGNOSTIC MODELS AND META-ANALYSIS Exempt per 45 CFR § 46.101(b)4 02/12/2015 2014.12201 02/13/2014 Dan McGee <dmcgee@fsu.edu>, Advisor 86 Human Subjects Application For Full IRB and Expedited Exempt Review Revision(s) to an Approved Study Form Revisions may range from a request to change a typographical error in the consent form to a significant change in the study design. Federal regulations and University policy require that each change must be reviewed and approved by the IRB prior to initiation. Revisions include amendments, modifications, addenda, updates, and administrative changes, additions, and other labels identified with study changes. Minor revisions involve procedures that are no more than minimal risk, or risks to subjects are not increased, and/or the revision is not a significant alteration of the study design. Minimal risk means that the probability and magnitude of harm or discomfort anticipated in the research are not greater than those ordinarily encountered in daily life or during the performance of routine physical or psychological At FSU, the Chair is designated to review and approve minor revisions to approved studies. Examples may include changes in telephone numbers, addition or deletion of associates or staff, reduction in the Substantive (major) revisions : Any revision to a study that involves increased risk to subjects or significantly affects the nature of the study must be reviewed by the full IRB. Examples may include revisions to the recruitment plan, adding, revising, eligibility criteria, adding or changing a research site, changing the Principal Changes are requested to the followings: ● Pr ot ocol Describe the proposed revision(s) to the study and justification (rationale) for the revision. If changes are Add co- invest igat or s State whether the proposed revision(s) increases or decreases the risk to participants (thereby changing ● Sam e Description: Add co- invest igat or s Uploaded Documents ● GradStudentsToAddToExemptIrb.doc (22.5KB) Project Title THE RISK OF LIPIDS ON CORONARY HEART DISEASE:PROGNOSTIC -ANALYSIS View original application View revised application Protocol Number 2015.15444 Review Type Exempt Principal Investigator Daniel McGee Daniel McGee - 2015.15444 87 Human Subjects Application For Full IRB and Expedited Exempt Review 1. Project Title and Identification THE RI SK OF LI PI DS ON CORONARY HEART DI SEASE: PROGNOSTI C MODELS AND META- ANALYSI S Project is: Dissert at ion 1.2 Principal Investigator (PI) ● GradStudentsToAddToExemptIrb.doc (22.5KB) Go back Nam e( Last nam e, First nam e MI ) : McGee, Daniel L Highest Earned Degree: Doct or at e Mailing Address: 216 OSB 4330 Phone Num ber: Fax: Universit y Depart m ent : STATI STI CS DEPARTMENT The t r aining and educat ion com plet ed in t he pr ot ect ion of hum an subj ect s or hum an subj ect s records: FSU Training Module NI H Occupat ional Posit ion: Facu lt y Nam e( Last nam e, First nam e MI ) : McGee, Dan ; Chair Highest Earned Degree: Mailing Address: Phone Num ber: Fax: Universit y Depart m ent : STATI STI CS DEPARTMENT The t r aining and educat ion com plet ed in t he pr ot ect ion of hum an subj ect s or hum an subj ect s records: Occupat ional Posit ion: Daniel McGee - 2015.15444 88 ᾏᾫᾤᾠᾲᾤᾠᾣᾣᾳᾧᾤᾥᾮᾫᾫᾮᾷᾨᾭᾦᾒᾳᾠᾳᾨᾲᾳᾨᾢᾲᾃᾤᾯᾠᾱᾳᾬᾤᾭᾳᾆᾱᾠᾣᾒᾳᾴᾣᾤᾭᾳᾲᾠᾲᾢᾮὪᾨᾭᾶᾤᾲᾳᾨᾦᾠᾳᾮᾱᾲ ᾅᾤᾫᾨᾢᾨᾠᾆᾱᾨᾥᾥᾨᾭ ᾒᾧᾠᾱᾨᾥᾠᾧᾀᾫᾱᾠᾩᾧᾨ ᾓᾨᾭᾦᾳᾨᾭᾦᾇᾴ ᾑᾹᾠᾭᾒᾢᾮᾫᾭᾨᾪ ᾀᾭᾷᾤᾲᾧᾠᾌᾴᾪᾧᾤᾱᾩᾤᾤ ᾖᾤᾨᾌᾠ ᾒᾠᾱᾹᾤᾳᾊᾴᾢᾴᾪᾤᾬᾨᾱᾮᾦᾫᾴ Daniel McGee - 2015.15444 89 BIBLIOGRAPHY [1] Framingham heart study. http://www.framinghamheartstudy.org. Accessed: 2015-12-1. [2] Jason Abrevaya. Computation of the maximum rank correlation estimator. Economics Letters, 62:279–285, 1999. [3] Arlene Ash and Michael Shwartz. R2: A useful measure of model performance when predicting a dichotomous outcome. Statistics in Medicine, 18:375–384, 1999. [4] Gail Blattenberger and Frank Lad. Separating the brier score into calibration and reﬁnement compenents: A graphical exposition. The American Statistician, 39:26–32, 1985. [5] Leo Breiman. Bagging predictors. Machine learning, 24(2):123–140, 1996. [6] Glenn W. Brier. Veriﬁcation of forecasts expressed in terms of probability. Monthly Weather Review, 78:1–3, 1950. [7] Tianxi Cai and Chaya Moskowitz. Semi-parametric estimation of the binormal roc curve for a continuous diagnostic test. Biostatistics, 5:573–586, 2004. [8] George Casella and Roger L. Berger. Statistical Inference. Duxbury, 2nd edition, 2002. [9] Christopher Cavanagh and Robert Sherman. Rank estimators for monotonic index models. Journal of Econometrics, 84:351–381, 1998. [10] Samuel Daniel Conte and Carl W. De Boor. Elementary Numerical Analysis: An Algorithmic Approach. McGraw-Hill Higher Education, 3rd edition, 1980. [11] Nancy R. Cook. Use and misuse of the receiver operating characteristic curve in risk prediction. Circulation, 115:928–935, 2007. [12] Elizabeth R. DeLong, David M. DeLong, and Daneil L. Clarke-Pearson. Comparing the ar- eas under two or more correlated receiver operating characteristic curves: A nonparametric approach. Biometrics, 44:837–845, 1988. [13] Bradley Efron and Robert J. Tibshirani. An Introduction to the Bootstrap. Chapman & Hall, 1993. [14] A. K. Han. Non-parametric analysis of a generalized regression model. the maximum rank correlation estimator. Journal of Economics, 35:303–316, 1987. 90 [15] David J. Hand. Classiﬁer technology and the illusion of progress. Statistical Science, 21:1–15, 2006. [16] James A. Hanley and Barbara J. McNeil. The meaning and use of the area under a receiver operating characteristic (roc) curve. Radiology, 143:29–36, 1982. [17] David W. Hosmer Jr., Stanley Lemeshow, and Rodney X. Sturdivant. Applied Logistic Regres- sion. Third Edition. John Wiley & Sons, Inc., 2013. [18] George Hripcsak and Adam S. Rothschild. Agreement, the f-measure, and reliability in in- formation retrieval. Journal of the American Medical Informatics Association, 12:296–298, 2005. [19] Bo Hu, Mari Palta, and Jun Shao. Properties of r2 statistics for logistic regression. Statistics in Medicine, 25:1383–1395, 2006. [20] Mitsuru Ikeda, Takeo Ishigaki, and Kazunobu Yamauchi. Relationship between brier score and area under the binormal roc curve. Computer Methods and Programs in Biomedicine, 67:187–194, 2002. [21] SAS Institute Inc. SAS/IML 9.1 User’s Guide. SAS Institute Inc., 2004. [22] Jos´e M Jerez, Ignacio Molina, Pedro J Garc´ıa-Laencina, Emilio Alba, Nuria Ribelles, Miguel Mart´ın, and Leonardo Franco. Missing data imputation using statistical and machine learning methods in a real breast cancer problem. Artiﬁcial intelligence in medicine, 50(2):105–115, 2010. [23] Qi Long, Xiaoxi Zhang, and Brent A Johnson. Robust estimation of area under roc curve using auxiliary variables in the presence of missing biomarker values. Biometrics, 67(2):559– 567, 2011. [24] Richard Maclin and David Opitz. An empirical evaluation of bagging and boosting. AAAI/IAAI, 1997:546–551, 1997. [25] S. J. Mason and N. E. Graham. Areas beneath the relative operating characteristics (roc) and relative operating levels (rol) curves: Statistical signiﬁcance and interpretation. Quarterly Journal of the Royal Meteorological Society, 128:2145–2166, 2002. [26] Donna Katzman McClish. Analyzing a portion of the roc curve. Medical Decision Making, 9(3):190–195, 1989. [27] Charles E. Metz, Benjamin A. Herman, and Jong-Her Shen. Maximum likelihood estimation of receiver operating characteristic (roc) curves from continuously-distributed data. Statistics in Medicine, 17:1033–1053, 1998. 91 [28] Martina Mittlbock and Michael Schemper. Explained variation for logistic regression. Statistics in Medicine, 15:1987–1997, 1996. [29] J. A. Nelder and R. Mead. Maximum likelihood estimation of receiver operating characteristic (roc) curves from continuously-distributed data. The Computer Journal, 7:308–313, 1965. [30] Michael J. Pencina, Ralph B. D’Agostino, and Ewout W. Steyerberg. Extensions of net re- classiﬁcation improvement calculations to measure usefulness of new biomarkers. Statistics in Medicine, 30:11–21, 2011. [31] Michael J. Pencina, Ralph B. D ´Agostino Sr, Ralph B. D ´Agostino Jr, and Ramachandran S. Vasan. Evaluating the added predictive ability of a new marker: From area under the roc curve to reclassiﬁcation and beyond. Statistics in Medicine, 27:157–172, 2008. [32] M. S. Pepe, Z. Feng, and J.W. Gu. Comments on evaluating the added predictive ability of a new marker: From area under the roc curve to reclassiﬁcation and beyond. Statistics in Medicine, 27:173–181, 2008. [33] Margaret Sullivan Pepe, Tianxi Cai, and Gary Longton. Combining predictors for classiﬁcation using the area under the receiver operating characteristic curve. Biometrics, 62:221–229, 2006. [34] D.M.W Powers. Evaluation: From precision, recall and f-measure to roc, informedness, markedness & correlation. Journal of Machine Learning Technologies, 2:37–63, 2011. [35] E. Samoza. Classifying binormal diagnostic tests using separation-asymmetry diagrams with constant-performance curves. Medical Decision Making, 14:157–168, 1994. [36] Robert P. Sherman. The limiting distribution of the maximum rank correlation estimator. Econometrica, 61:123–137, 1993. [37] Joseph Sill, G´abor Tak´acs, Lester Mackey, and David Lin. Feature-weighted linear stacking. arXiv preprint arXiv:0911.0460, 2009. [38] H.C. van Houwelingen, Lidia R. Arends, and Theo Stijnen. Advanced methods in meta- analysis: multivariate approach and meta-regression. Statistics in Medicine, 21:589–624, 2002. [39] Hansheng Wang. A note on iterative marginal optimization: a simple algorithm for maximum rank correlation estimation. Computational Statistics & Data Analysis, 51:2803–2812, 2006. [40] Peter WF Wilson, Ralph B DAgostino, Daniel Levy, Albert M Belanger, Halit Silbershatz, and William B Kannel. Prediction of coronary heart disease using risk factor categories. Circulation, 97(18):1837–1847, 1998. [41] Tjalling J. Ympa. Historical development of the newton-raphson method. Society for Industrial and Applied Mathematics Review, 37:531–551, 1995. 92 [42] Dong D Zhang, Xia-Hua Zhou, Daniel H Freeman, and Jean L Freeman. A non-parametric method for the comparison of partial areas under roc curves and its application to large health care data sets. Statistics in Medicine, 21(5):701–715, 2002. [43] Kelly H. Zou, A. James O’Malley, and Laura Mauri. Receiver-operating characteristic analysis for evaluating diagnostic tests and predictive models. Circulation, 115:654–657, 2006. 93 BIOGRAPHICAL SKETCH Ryan Scolnik was raised in Tucson, Arizona and completed his bachelor’s degree in mathematics in 2010 from the University of Arizona. He continued his education at Florida State University and ﬁnished his master’s degree in statistics in 2012. After a brief stint in Columbus, Ohio, Ryan returned to Florida State in 2014 to continue his doctoral degree. While curious and interested in many topics in statistics, Ryan also ﬁnds enjoyment in running, cycling, adult softball, sporting events and spending time with friends and family. 94","libVersion":"0.3.1","langs":""}