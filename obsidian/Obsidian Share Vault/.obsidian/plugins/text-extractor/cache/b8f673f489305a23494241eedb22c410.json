{"path":"lit/lit_notes_OLD_PARTIAL/Ai24notAllDistShifsConform.pdf","text":"Not all distributional shifts are equal: Fine-grained robust conformal inference Jiahao Ai1 and Zhimei Ren 2 1School of Mathematical Sciences, Peking University 2Department of Statistics and Data Science, University of Pennsylvania February 27, 2024 Abstract We introduce a fine-grained framework for uncertainty quantification of predictive models under distributional shifts. This framework distinguishes the shift in covariate distributions from that in the conditional relationship between the outcome (Y ) and the covariates (X). We propose to reweight the training samples to adjust for an identifiable covariate shift while protecting against worst- case conditional distribution shift bounded in an f -divergence ball. Based on ideas from conformal inference and distributionally robust learning, we present an algorithm that outputs (approximately) valid and efficient prediction intervals in the presence of distributional shifts. As a use case, we apply the framework to sensitivity analysis of individual treatment effects with hidden confounding. The proposed methods are evaluated in simulation studies and three real data applications, demonstrating superior robustness and efficiency compared with existing benchmarks. 1 Introduction It has been widely observed that the performance of predictive models falls short of expectation when generalized to a population whose distribution differs from that of the training data (see e.g., Recht et al. (2019); Miller et al. (2020); Wong et al. (2021); Namkoong et al. (2023); Liu et al. (2023) and the references therein). As predictive models are increasingly employed in high-stakes settings, it is imperative to accompany the predicted outcomes with calibrated uncertainty quantification when deploying a model to new environments. A widely adopted approach to uncertainty quantification is to provide a prediction set that contains the true outcome with high probability. The prediction set informs the confidence we have in the predicted outcome. Among the tools for constructing prediction sets, conformal prediction (CP) (Vovk et al., 2005) is an attractive framework that generates valid prediction sets that are guaranteed to include the true outcome with pre-specified probability. The validity of CP holds for any predictive model, as long as the training and test data are exchangeable, e.g., when they are identically independently distributed (i.i.d.). In the presence of distributional shifts, however, the exchangeability/i.i.d. assumption breaks, and CP no longer delivers valid prediction sets. To address this challenge, prior work (Cauchois et al., 2023) proposes a robust CP method that outputs prediction sets that are valid when the target distribution ranges within a neighborhood of the training distribution. To be more specific, let X ∈ X denote the covariates and Y ∈ Y the outcome/response. Consider a training set of n samples (Xi, Yi) i.i.d. ∼ PX,Y and an independent test unit (Xn+1, Yn+1) ∼ QX,Y , where we only get to observe Xn+1 and wish to predict Yn+1. Cauchois et al. (2023) assumes that the f -divergence between QX,Y and PX,Y is bounded by a parameter ρ, and provides prediction sets that ensure guarantees even for the worst-case QX,Y . The method of Cauchois et al. (2023) provides robustness against the worst-case joint distributional shift of (X, Y ), but no distinction is made between the covariate shift and the conditional distributional shift. As pointed out by a recent line of research, different types of distributional shifts appear in different tasks and result in different consequences (Mu et al., 2022; Namkoong et al., 2023; Jin et al., 2023a; Liu et al., 2023). Without separating the sources of distributional shifts and taking specialized treatment, we will show that the joint modeling approach of Cauchois et al. (2023) can be overly conservative in practice. In this work, we take a closer look at distributional shift, and provide a fine-grained robust predictive inference approach with improved efficiency. 1arXiv:2402.13042v2 [stat.ME] 25 Feb 2024 1.1 Decomposing the distributional shifts We decompose the distributional shifts into two types: (1) The covariate shift: the marginal distribution of X is different in the training and target envi- ronment. For example, the age/gender structure in the new environment differs from that in the training environment. (2) The Y | X shift: the conditional relationship between the outcome and the the covariate is different in the training and target environment. This could happen when there are unobserved confounders, or when the training and target data are collected from different periods and the conditional relationship varies over time. The above two types of distributional shifts are different in nature — for one thing, the former type of distributional shift is identifiable but the latter is not. In most cases, the distributional shift is a mixture of the two. Instead of guarding against the worst-case joint distributional shift, we propose to tease apart the two types of shifts, reweighting the training samples according to the estimated covariate shift and adjusting the confidence level to account for the worst-case Y | X shift. Specifically, we assume the Y | X shift to be bounded in the f -divergence, i.e., Df (QY | X ∥ PY | X ) ≤ ρ, but posit no constraints on the covariate shift. For such distributional shifts, our proposed method aims to construct a prediction interval ̂Cf,ρ(Xn+1) with the training data, such that it covers the true outcome with high probability under the target distribution. 1.2 Our contributions This work introduces a new framework for calibrated uncertainty quantification in the presence of dis- tributional shifts. Toward this end, we make the following contributions: (1) We present Weighted Robust Conformal Prediction (WRCP), which treats the covariate shift and the Y | X shift differently. It (approximately) achieves the desired coverage under the proposed framework, with the miscoverage rate determined by the estimation error of the covariate likelihood ratio dQX /dPX . (2) In the case when estimating the covariate shift is challenging (e.g., when X is high-dimensional), we propose a debiased variant of WRCP, namely D-WRCP, which enjoys the double-robustness property — its miscoverage rate depends on the product of the estimation error of dQX /dPX and that of conditional quantiles of the residuals from predicting the outcomes. (3) As a special example, we show that our proposed methods can be adapted to conducting sensitivity analysis for individual treatment effects (ITEs) under the f -sensitivity model (Jin et al., 2022). (4) We empirically evaluate the proposed methods in simulations and three real data applications, demonstrating their validity and improved efficiency. 1.3 Related literature Conformal prediction beyond exchangeability. With exchangeable/i.i.d. data, there is a long list of works on the theoretical property, efficient implementation and application of conformal prediction (see e.g., Vovk et al. (2005); Papadopoulos et al. (2002); Lei et al. (2018); Romano et al. (2019); Barber et al. (2021); Angelopoulos et al. (2023)). Beyond exchangeability, Tibshirani et al. (2019); Park et al. (2022) consider the pure covariate shift setting, with the former focusing on the marginal coverage guarantee and the latter the training- conditional guarantee; also under the pure covariate shift setting, Qiu et al. (2022); Yang et al. (2022) builds upon semi-parametric theory to develop more efficient CP methods with asymptotic coverage guarantees. The de-biased version of our proposal draws inspiration from these two works, and we gener- alize them to the specific distributional shift model under consideration. Podkopaev and Ramdas (2021); Si et al. (2023) tackles the label shift setting, where the marginal distribution of Y is subject to changes but X | Y remains invariant in the training and target distribution. The work of Barber et al. (2023) addresses a general form of distribution shift by up-weighting training points whose distribution is closer to that of the target distribution (the weights need to be independent of the data). As mentioned earlier, Cauchois et al. (2023) is concerned with robust CP against the worst-case joint shift in (X, Y ). Gendler et al. (2021); Ghosh et al. (2023) investigate the robustness of CP under adversarial attacks. Another two closely related works on robust CP are Jin et al. (2023b); Yin et al. 2 (2022), which study sensitivity analysis of ITEs under the marginal Γ-selection model (Tan, 2006); the type of distributional shift (caused by hidden confounding) puts no requirements on the covariate shift and assumes that the shift in Y | X is uniformly bounded by constants, i.e., 1/Γ ≤ dQY | X dPY | X ≤ Γ. Compared with our model that assumes the Y | X shift to be bounded on average (the f -divergence takes the expectation over Y ), the point-wise bound requires the maximum shift to be bounded, which can sometimes be conservative in practice (see more discussion and examples in Jin et al. (2022)). Distributionally robust learning. Distributionally robust learning studies the broad topic of learn- ing from data with guarantees under the worst-case distributional shift within a specified set of distri- butions. Typical tasks in this field includes parameter estimation (Shafieezadeh Abadeh et al., 2015; Blanchet and Murthy, 2019; Duchi and Namkoong, 2021; Duchi et al., 2023), policy learning (Si et al., 2023; Mu et al., 2022; Zhang et al., 2023), among others. In particular, Mu et al. (2022) proposes learning a robust policy by separately considering covariate shifts and Y | X shifts, echoing the proposal in this paper. Compared with the existing literature, our work takes a different angle by studying the uncertainty quantification problem under distributional shifts. Sensitivity analysis. In causal inference, distributional shifts can arise due to unobserved confounders, and sensitivity analysis is a standard tool for assessing the robustness of causal effect estimates under such shifts. Under the aforementioned (marginal) Γ-selection model (Rosenbaum, 1987; Tan, 2006), a line of papers (Zhao et al., 2019; Yadlowsky et al., 2018; Kallus and Zhou, 2020; Sahoo et al., 2022) study the estimation of the average treatment effect (ATE) or the policy values, and the work of Kallus and Zhou (2021); Lei et al. (2023) consider learning the optimal policy. Recently, Jin et al. (2022) proposes the f -sensitivity model, and discusses how to estimate the ATE under the model. We shall show later in this paper that the distributional shift under the f -sensitivity model fits exactly in our framework, and hence our proposed method can be adopted there for the uncertainty quantification of ITEs. 2 Problem setup Consider a training data set Dtr = {(Xi, Yi)} n i=1, where (Xi, Yi) i.i.d. ∼ PX,Y . For a test unit (Xn+1, Yn+1) ∼ QX,Y , for which only the covariate is observed, we aim at using Dtr to construct an interval ̂C(Xn+1) such that P(Xn+1,Yn+1)∼QX,Y (Yn+1 ∈ ̂C(Xn+1) ) ≥ 1 − α, (1) where the probability is taken over the randomness of (Xi, Yi) i.i.d. ∼ PX,Y and (Xn+1, Yn+1) ∼ QX,Y , and α ∈ (0, 1) is the pre-specified mis-coverage level. Let s : X × Y ↦→ R denote a score function, and we define for each i ∈ [n] = {1, 2, . . . , n} the nonconformity score Si = s(Xi, Yi). For example, when ̂µ(x) is a fitted function of the conditional mean of Y | X, one can take s(x, y) = |y − ̂µ(x)|.1 For other types of nonconformity scores, see also Romano et al. (2019); Chernozhukov et al. (2021); Guan (2023); Gupta et al. (2022). In order to achieve (1), it suffices to find (an upper bound of) the (1 − α)-th quantile of s(Xn+1, Yn+1) under QX,Y . 2.1 Characterizing the distributional shifts As introduced earlier, the distributional shift between PX,Y and QX,Y can be originating from two sources: (1) the difference between PX and QX and (2) the difference between PY | X and QY | X . The two types of distribution shifts are different in nature: often the covariate shift is observable and estimable — since we have access to the covariates in the test set — while the Y | X shift is not identifiable. Based on this observation, we propose distinct treatments to these two types of distributional shift. The covariate shift is represented by the likelihood ratio w(x) = dQX dPX (x). We do not posit any assumption on w(x) (except that QX is absolutely continuous with respect to PX ), and shall use data to estimate this quantity. For the conditional distributional shift, we assume that the target distribution QY | X falls within a “neighborhood ball” of PY | X , whose radius is controlled by a parameter ρ. The neighborhood ball is formalized by the f -divergence. 1Strictly, we should write the score function as s(x, y; ̂µ) as it also depends on ̂µ. For notational simplicity, we suppress the dependence on ̂µ (or other predictive functions) in the score function when the context is clear. 3 Definition 1 (f -divergence). Let P and Q be two probability distributions over a space Ω such that P is absolutely continuous with respect to Q. For a convex function f such that f (1) = 0, the f -divergence of P from Q is defined as Df (P ∥ Q) = EQ[f (dP/dQ)], where dP/dQ is the Radon-Nikodym derivative. Throughout, we assume f to be closed and convex, with f (1) = 0 and f (x) < +∞ for x > 0. Common choices of f include f (x) = x log x, which yields the Kullback–Leibler (KL) divergence, f (x) = 1 2 |x − 1| that yields the total variation (TV) distance, and f (x) = (x − 1) 2 that yields the Pearson χ2-divergence. With the target conditional distribution of Y | X satisfying Df (QY | X=x ∥ PY | X=x) ≤ ρ, for PX - almost all x, we can define the set of possible QX,Y as P(ρ; P ) := { Q s.t. (Xn+1, Yn+1) ∼ Q : Df (QY | X=x ∥ PY | X=x) ≤ ρ, for PX -almost all x} . In what follows, we shall refer to P(ρ; P ) as the identification set. When Q ∈ P(ρ; P ), the task in (1) can be equivalently written as inf Q∈P(ρ;P ) P(Xn+1,Yn+1)∼Q(Yn+1 ∈ ̂C(Xn+1) ) ≥ 1 − α. 2.2 Split conformal prediction When PX,Y = QX,Y , the method of conformal inference offers an elegant solution for finding the quantile of s(Xn+1, Yn+1) by leveraging the exchangeability among {(Xi, Yi)} n+1 i=1 . In particular, the split con- formal inference (Vovk et al., 2005; Papadopoulos et al., 2002) is a computationally efficient variant of conformal inference that begins by randomly splitting the training data into two folds, D(0) tr and D(1) tr , where n0 = |D(0) tr | and n1 = |D(1) tr |. It then uses D(0) tr for fitting the prediction function ̂µ : X ↦→ R and D(1) tr for obtaining the estimated quantile. The prediction interval takes the form ̂C(Xn+1) = { y ∈ R : s(Xn+1, y) ≤ Quantile(1 − α, {Si}i∈D(1) tr ∪ {∞})}, (2) where Quantile(β, {Zi}n i=1) denotes the ⌈nβ⌉-th smallest element among Z1, Z2, . . . , Zn. The prediction interval (2) guarantees that P(Yn+1 ∈ ̂C(Xn+1)) ≥ 1 − α when PX,Y = QX,Y without any additional assumptions (Vovk et al., 2005); if the ties among the nonconformity scores happen with probability zero, then the coverage is also tight (Lei et al., 2018), i.e., P(Yn+1 ∈ ̂C(Xn+1)) ≤ 1 − α + 1/n1. 3 Methodology In this section, we describe how to generalize (split) conformal inference to efficiently handle distributional shift. To start, we fix the radius of the identification set ρ > 0. As in the standard split conformal prediction, we start by splitting the training set into two folds, D(0) tr and D(1) tr . The fitting fold D(0) tr is used for fitting the prediction function ̂µ (or other functions depending on the type of nonconformity score). The calibration fold D(1) tr is devoted to finding the largest quantile of Sn+1 for Q ∈ P(ρ; P ). To this end, we follow Cauchois et al. (2023) and define gf,ρ(β) := inf {z ∈ [0, 1] : βf ( z β ) + (1 − β)f ( 1 − z 1 − β ) ≤ ρ}, and its inverse g−1 f,ρ(τ ) := sup { β ∈ [0, 1] : gf,ρ(β) ≤ τ }. Recall that w(x) = dQX dPX (x). We construct our prediction set as ̂Cf,ρ(x) = {y ∈ R : s(x, y) ≤ Quantile(g−1 f,ρ(1 − α), ∑ i∈D(1) tr pi(x)δSi + pn+1(x)δ∞)}, (3) where pi(x) = w(Xi) ∑ j∈D(1) tr w(Xj) + w(x) , and pn+1(x) = w(x) ∑ j∈D(1) tr w(Xj) + w(x) . In words, we upper bound the (1 − α)-th quantile of Sn+1 under Q by a weighted quantile under P at a slightly inflated level. The validity of ̂Cf,ρ(Xn+1) is formalized by Theorem 1, whose proof is deferred to Appendix B.1. 4 Theorem 1 (Prediction interval with known covariate shift). Assume the training data {(Xi, Yi)} n i=1 i.i.d. ∼ PX,Y and (Xn+1, Yn+1) ∼ QX,Y is independent of {(Xi, Yi)} n i=1. Assume that Q is absolutely contin- uously continuous with respect to P , and denote w(x) = dQX dPX (x). For α ∈ (0, 1), the prediction set ̂Cf,ρ(Xn+1) defined in (3) satisfies that P (Yn+1 ∈ ̂Cf,ρ(Xn+1) ) ≥ gf,ρ(g−1 f,ρ(1 − α) ). Furthermore, if gf,ρ(1) ≥ 1 − α, then P (Yn+1 ∈ ̂Cf,ρ(Xn+1) ) ≥ 1 − α. The condition that gf,ρ(1) ≥ 1 − α holds for the KL divergence and the χ2 distance for any choice of ρ, α > 0; it holds for the TV distance for α ≥ ρ/2. Two remarks are in order. Remark 1. As shown in Cauchois et al. (2023, Lemma A.1), gf,ρ(β) is non-decreasing in β, which allows for efficient computation of g−1 f,ρ(τ ). For example, by binary search, we can get an estimate of g−1 f,ρ(τ ) with error ε within O(log((1 − τ )/ϵ)) runs. Remark 2. When there is no distributional shift in Y | X, i.e., ρ = 0, our method recovers split weighted conformal prediction (Tibshirani et al., 2019); when there is no covariate shift, i.e., w(x) ≡ 1, it recovers the method of Cauchois et al. (2023). Our procedure is therefore a generalization of both methods. We now have a general recipe for handling distributional shifts in P(ρ; P ). So far the recipe requires that the covariate shift w(x) to be specified a priori — this may be the case where the covariate shift is induced by a covariate-based selection rule that is known to the experimenter — but more often, we do not know the exact form of w(x). The following section discusses how to estimate w(x) with data and how the coverage depends on the estimation quality. 3.1 Estimating the covariate shift Consider a common scenario in prediction tasks: there are multiple test units denoted by Dtest = {(Xn+j, Yn+j)} m j=1, where (Xn+j, Yn+j) i.i.d. ∼ QX,Y . For each j ∈ [m], we aim to construct a prediction interval ̂Cf,ρ,n+j(Xn+j) satisfying (1). The multiple test units allow us to estimate w(x). In particular, we adopt the estimation approach introduced in Tibshirani et al. (2019), where we first randomly split Dtest into two folds: D(0) test and D(1) test, indexed by I (0) test and I (1) test, respectively. Without loss of generality, assume that n + j ∈ I (1) test. Recall that the training set Dtr is also divided into D(0) tr and D(1) tr . We set aside D(0) tr ∪ D(0) test for estimating w(·). Let A be a binary variable indicating whether the sample is from the training set or the test set, i.e., Ai = 0 for i ∈ I (0) tr and Ai = 1 for i ∈ I (0) test. For i ∈ I (0) tr ∪ I (0) test, by Bayes’ rule, P(Ai = 1 | Xi = x) P(Ai = 0 | Xi = x) = dQX dPX (x) · P(Ai = 1) P(Ai = 0) ∝ w(x). The above tells us that the likelihood ratio w(x) can be estimated by training a classifier on D(0) tr ∪ D(0) test: once we obtain ̂P(A = 1 | X = x), we can let ̂w(x) = ̂P(A=1 | X=x) 1−̂P(A=1 | X=x) — this is an estimator for w(x) (up to constants). We then construct the prediction interval by replacing w(x) with ̂w(x) in (3). The complete procedure is summarized in Algorithm 1, and the following theorem provides the coverage guarantee when the estimated w(x) is used. Theorem 2. Under the same assumptions of Theorem 1, suppose that EX∼PX [ ̂w(k)(X)] < ∞, for k ∈ {0, 1}. Then for any k ∈ {0, 1} and any n + j ∈ I (k) test, the prediction set of Algorithm 1 satisfies P (Yn+j ∈ ̂Cf,ρ,n+j(Xn+j) ) ≥ gf,ρ(g−1 f,ρ(1 − α) ) − 1 2 g′ f,ρ(g−1 f,ρ(1 − α) ) · EX∼PX [∣ ∣ ∣ ̂w(k)(X) E[ ̂w(k)(X)] − w(X) ∣ ∣ ∣] , where g′ f,ρ is the left derivative of gf,ρ. Furthermore, if gf,ρ(1) ≥ 1 − α, then P (Yn+j ∈ ̂Cf,ρ,n+j(Xn+j) ) ≥ 1 − α − 1 2 g′ f,ρ(g−1 f,ρ(1 − α)) · EX∼PX [∣ ∣ ∣ ̂w(k)(X) E[ ̂w(k)(X)] − w(X) ∣ ∣ ∣] . 5 The proof of Theorem 2 is based on the coupling technique used in Lei and Candès (2021), and can be found in Appendix B.2. Remark 3. If the number of test units m is small, one can replace D(1−k) test with Dtest\\{Xn+j} when estimating w(x), i.e., train the classifier on D(0) tr ∪Dtest\\{Xn+j}. This approach can improve the accuracy of the classifier but may be computationally intensive when m is large, so we present the sample-splitting version for simplicity. With estimated w(x), Theorem 2 suggests that the miscoverage rate inflation depends on the estima- tion error of ̂w(x). In general, when x is low-dimensional, we can obtain a relatively accurate estimator of w(x), and the resulting prediction interval is approximately valid. In other situations where high- dimensional covariates are present, estimating w(x) can be challenging. To handle this issue, we propose an alternative method that leverages the debiasing technique to construct efficient prediction intervals. We present it in detail in the following section. Algorithm 1: Weighted robust conformal prediction (WRCP) Input: Training set Dtr = {(Xi, Yi)}n i=1; test data Dtest = {Xn+j}m j=1; regression algorithm A; classification algorithm C; target miscoverage level α ∈ (0, 1); score function s(x, y; µ); robust parameter ρ. Optional input: likelihood ratio function w(x). Randomly split Dtr into two disjoint subsets of equal sizes, D(0) tr and D(1) tr , indexed by I (0) tr and I (1) tr , respectively; Apply A to D(0) tr and obtain the prediction function: ̂µ ← A(D(0) tr ); Compute the nonconformity score Si = s(Xi, Yi) for i ∈ I (1) tr ; if w(x) exists then for j = 1, . . . , m do Construct ̂Cf,ρ,n+j(Xn+j) according to (3); end else Split Dtest into two disjoint subsets of equal sizes, D(0) test and D(1) test, indexed by I (0) test and I (1) test, respectively; for k = 0, 1 do Train a classifier: ̂P(k)(A = 1 | X = x) ← C(D(0) tr , D(1−k) test ); Construct the estimator ̂w(k)(x) ← ̂P(k)(A=1 | X=x) 1−̂P(k)(A=1 | X=x) ; for ℓ ∈ I (k) test do Construct ̂Cf,ρ,ℓ(Xℓ) according to (3) with w(x) replaced by ̂w(k)(x); end end end Output: Prediction sets { ̂Cf,ρ,n+j(Xn+j)}j∈[m]. 3.2 Doubly robust prediction sets Continue focusing on the test unit n + j ∈ I (1) test. Recall that we fit ̂w(1)(x) on D(0) tr ∪ D(0) test; we now reuse D(0) tr to fit the function x ↦→ E [ 1{S(X, Y ) ≤ t} ∣ ∣ X = x] , denoting the estimator by ̂m (1)(x; t). Since our estimand is the conditional cumulative distribution function (CDF), we assume the estimator ̂m(x; t) to be bounded in [0, 1], non-decreasing in t, and right-continuous without loss of generality. To motivate the doubly robust prediction set, let us take another look at the coverage probability 6 under a pure covariate shift at a fixed threshold t, which can be written as P(X,Y )∼QX ×PY | X (S(X, Y ) ≤ t) = E(X,Y )∼QX ×PY | X [1{S(X, Y ) ≤ t} ] = E(X,Y )∼QX ×PY | X [(1{S(X, Y ) ≤ t} − ̂m (1)(X; t) )] + EX∼QX [ ̂m(1)(X; t) ] = E(X,Y )∼PX,Y [ w(X) · (1{S(X, Y ) ≤ t} − ̂m (1)(X; t) )] EX∼PX [w(X)] + EX∼QX [ ̂m (1)(X; t) ] . In the above decomposition, the first term can be estimated with the training data, and the second term with the test data. We therefore modify the coverage probability estimator at threshold t to be ̂p (1)(t) = ∑ i∈I(1) tr ̂w(1)(Xi) · (1{Si ≤ t} − ̂m (1)(Xi; t) ) ∑ i∈I(1) tr ̂w(1)(Xi) + 1 |I (1) test,j| ∑ i∈I(1) test,j ̂m(1)(Xj; t), where I (1) test,j = I (1) test\\{j}. Note that ̂p (1)(t) is no longer monotone in t; to obtain the quantile, we consider a “monotonized” version of ̂p (1)(t). The specific prediction interval is then constructed as ̂C DR f,ρ,n+j(Xn+j) = {y : s(Xn+j, y) ≤ ̂q}, where ̂q = inf { t ∈ R : inf t′≥t ̂p (1)(t ′) ≥ g−1 f,ρ(1 − α) } . (4) Algorithm 2: Debiased weighted robust conformal prediction (D-WRCP) Input: Training set Dtr = {(Xi, Yi)}n i=1; test data Dtest = {Xn+j}m j=1; regression algorithm A; classification algorithm C; conditional CDF fitting algorithm M; target miscoverage level α ∈ (0, 1); score function s(x, y; µ); robust parameter ρ. Randomly split Dtr into two disjoint subsets of equal sizes, D(0) tr and D(1) tr , indexed by I (0) tr and I (1) tr , respectively; Randomly split Dtest into two disjoint subsets of equal sizes, D(0) test and D(1) test, indexed by I (0) test and I (1) test, respectively; for k = 0, 1 do Obtain the prediction function: ̂µ (k) ← A(D(1−k) tr ); Compute the nonconformity score Si = s(Xi, Yi; ̂µ (k)) for i ∈ I (k) tr ; Train a classifier ̂P (k)(A = 1 | X = x) ← C(D(1−k) tr , D(1−k) test ); Construct the estimator for covariate shift ̂w(k)(x) ← ̂P(k)(A=1 | X=x) 1−̂P(k)(A=1 | X=x) ; Obtain the estimated conditional CDF of S: ̂m(k) ← M(D(k) tr ); for ℓ ∈ I (k) test do Construct ̂C DR f,ρ,ℓ(Xℓ) according to (4); end end Output: Prediction sets { ̂C DR f,ρ,n+j(Xn+j) } j∈[m]. The complete procedure for constructing the doubly robust prediction sets is described in Algorithm 2. Intuitively, when ̂p(1)(t) is sufficiently close to P(Xn+j ,Yn+j )∼QX ×PY | X (s(Xn+j, Yn+j) ≤ t), ̂q is close to the g−1 f,ρ(1 − α)-th quantile under QX × PY | X , thereby upper bounding the (1 − α)-th quantile of Sn+j under QX,Y . In the following, we let q∗(ξ) be the (g−1 f,ρ(1 − α) − ξ)-th quantile of s(X, Y ) under QX × PY | X . The validity of ̂C DR f,ρ,n+j(Xn+j) is established in the following theorem. Theorem 3. For any k ∈ {0, 1}, assume that (1) ̂w(k)(x) ≤ wmax · EPX [ ̂w(k)(X)]; 7 (2) ̂m (k)(x; t) ∈ [0, 1] is non-decreasing and right-continuous in t. Denote the product estimation error by EstErr (k)(t) = ∥ ∥1{s(X, Y ) ≤ t} − ̂m (1−k)(X; t) ∥ ∥ L2(P ) · ∥ ∥ ∥ ∥ ̂w(1−k)(X) E[ ̂w(1−k)(X)] − w(X) ∥ ∥ ∥ ∥ L2(P ), where ∥ · ∥L2(P ) denotes the L2-norm under P , and the expectation is taken conditional on D(1−k) tr and D(1−k) test . For a unit n + j ∈ I (k) test, there is P(Xn+j ,Yn+j )∼QX,Y (Yn+j ∈ ̂C DR f,ρ,n+j(Xn+j) ∣ ∣ D(1−k) tr , D(1−k) test ) ≥ gf,ρ(g−1 f,ρ(1 − α) ) − g′ f,ρ(g−1(1 − α) ) × { sup t∈T (α) 2 · EstErr (k)(t) + √ 16w2 max |I (k) tr | + 2 |I (k) test,j| }, where g′ f,ρ is the left derivative of gf,ρ, and T (α) = [q, ¯q] is a neighborhood around the g−1 f,ρ(1 − α)-th quantile under QX × PY | X with q = sup 0≤t≤q∗(0) EstErr(t) + √ 9w2 max |I (k) tr | + 1 |I (k) test,j| , ¯q = q∗(0). When gf,ρ(1) ≥ 1 − α, we further have P(Xn+j ,Yn+j )∼QX,Y (Yn+j ∈ ̂C DR f,ρ,n+j(Xn+j) ∣ ∣ D(1−k) tr , D(1−k) test ) ≥ 1 − α − g′ f,ρ(g−1(1 − α)) × { sup t∈T (α) 2 · EstErr(k)(t) + √ 16w2 max |I (k) tr | + 2 |I (k) test,j| }. The proof of Theorem 3 is deferred to Appendix B.3, where we prove a more general result that the prediction set is valid with high probability conditional on the training data; we then show how the general result implies Theorem 3. Theorem 3 implies that the miscoverage rate of ̂C DR(Xn+j) is the product of the local estimation error plus an O(n−1/2) term, where the product term is small if either ̂w is approximately proportional to w, or if ̂m(x; t) is close to PPY | X (s(X, Y ) ≤ t | X = x) in the neighborhood of the g−1 f,ρ(1 − α)-th quantile under QX × PY | X . Compared with the double robustness result of Yang et al. (2022), our dependence on the estimation error of ̂m(x; t) is local (around the g−1(1 − α)-th quantile) while that of Yang et al. (2022) is global (for all t). This is achieved through the “monotonization” step, an idea that also appears in Gui et al. (2023). 3.3 Choice of the robust parameter ρ Another important piece of our procedure is the robust parameter ρ. Choosing ρ is a common challenge in the distributionally robust learning literature (see e.g., Rahimian and Mehrotra (2019); Cauchois et al. (2023); Si et al. (2023); Mu et al. (2022) and the references therein). In certain applications, users can specify an appropriate ρ with context-dependent knowledge. When the choice of ρ is not clear a priori, we provide two solutions based on the proposal of Si et al. (2023): (1) If there is (a small amount of) supervised data from target distribution, i.e., QX,Y , one can estimate an upper bound of ρ, and use the estimator in place of ρ. (2) When no supervised data in the target distribution is available, we can apply the procedure with a sequence of ρ, obtaining a sequence of prediction sets. Each value of ρ corresponds to a certain level of robustness, and the user can trade off between the level of robustness and efficiency (e.g., the length of the prediction interval). In the case where ρ is estimated, Theorem 4 characterizes the coverage guarantee of WRCP. We only present the result for WRCP here for simplicity; the result extends also to D-WRCP. Theorem 4. Under the same assumptions of Theorem 2, suppose that ̂ρ is independent of (Dtr, Dtest). Denote ρ∗ := ess supx Df (QY | X=x ∥ PY | X=x). Then for k ∈ {0, 1} and any n + j ∈ I (k) test, the prediction interval produced by Algorithm 1 with the robust parameter taken to be ̂ρ satisfies P (Yn+j ∈ ̂Cf,̂ρ,n+j(Xn+j) ) ≥ gf,ρ∗ (g−1 f,̂ρ(1 − α) ) − 1 2 g′ f,ρ∗ (g−1 f,̂ρ(1 − α) ) · EX∼PX [∣ ∣ ∣ ̂w(k)(X) E[ ̂w(k)(X)] − w(X) ∣ ∣ ∣] , 8 where g′ f,ρ is the left derivative of gf,ρ. Furthermore, if gf,̂ρ(1) ≥ 1 − α and ̂ρ ≥ ρ ∗, then P(Yn+j ∈ ̂Cf,̂ρ,n+j(Xn+j)) ≥ 1 − α − 1 2 g′ f,ρ∗ (g−1 f,̂ρ(1 − α) ) · EX∼PX [∣ ∣ ∣ ̂w(k)(X) E[ ̂w(k)(X)] − w(X) ∣ ∣ ∣] , where g′ f,ρ is the left derivative of gf,ρ. 4 Application: sensitivity analysis of individual treatment effects Our framework can be applied to the sensitivity analysis of individual treatment effects in the presence of confounding factors. To set the stage, we follow the potential outcome framework (Neyman, 1923; Imbens and Rubin, 2015) and suppose that each sample is associated with a set of random variables (X, U, T, Y (0), Y (1)), where X ∈ X denotes the observed covariates, U ∈ U the unobserved confounders, T ∈ {0, 1} the binary treatment, and Y (1), Y (0) ∈ R the potential outcomes with and without being treated. Here, not all the quantities are observed — the observable variables are (X, T, Y ), where the realized outcome Y = T Y (1)+(1−T )Y (0) under the Stable Unit Treatment Value Assumption (SUTVA). Assume that the unobserved confounder U satisfies that2 (Y (1), Y (0))|=T | X, U, Imagine now there is a cohort of n i.i.d samples (Xi, Ui, Ti, Yi(1), Yi(0)) n i=1, where we observe D = (Xi, Ti, Yi) n i=1. For a new individual Xn+1, we are interested in a prediction interval ̂C(Xn+1) for individual treatment effect (ITE), Y (1) − Y (0), such that P (Y (1) − Y (0) ∈ ̂C(Xn+1)) ≥ 1 − α. (5) Without additional constraints on the unobserved confounders, it is hopeless to obtain an efficient prediction interval achieving (5), since the difference in the treated and control group can be entirely driven by the confounding factor. Previously, Lei and Candès (2021) studies this problem assuming that there are no observed confounders, i.e., (Y (1), Y (0))|=T | X; Jin et al. (2023b) adopts the marginal Γ- selection model (Tan, 2006), which allows for unobserved confounders but the influence of U — roughly speaking — is uniformly bounded by a constant Γ. The marginal Γ-selection model can be unsatisfactory in some cases, where the influence of U is limited only on average but is unbounded with small probability (the corresponding constant Γ is therefore +∞). Such a situation can however be well characterized by the f -sensitivity model (Jin et al., 2022): Definition 2 (The (f, ρ)-selection condition). Suppose f : R+ ↦→ R is a convex function such that f (1) = 0, and P is a distribution over (X, U, T, Y (1), Y (0)). P satisfies the (f, ρ)-selection condition if for P -almost all x, ∫ f ( e(X) 1 − e(X) 1 − ¯e(X, U ) ¯e(X, U ) ) dPU | X=x,T =1 ≤ ρ, and ∫ f ( 1 − e(X) e(X) ¯e(X, U ) 1 − ¯e(X, U ) ) dPU | X=x,T =0 ≤ ρ, where ¯e(x, u) = P (T = 1 | X = x, U = u) and e(x) = P (T = 1 | X = x). Can we construct a prediction interval achieving (5) under the f -sensitivity model? It turns out that this task is a special case of our proposed framework. To see this, we first reduce the problem to that of inference on the counterfactuals: if we can construct valid prediction intervals for Y (1) and Y (0), respectively, then combining these two intervals and taking a union bound yields a valid interval for the ITE. Without loss of generality, we focus on Y (1), aiming to construct an interval ̂Cf,ρ(Xn+1) such that P(Y (1) ∈ ̂Cf,ρ(Xn+1)) ≥ 1 − α. Since Y (1) can only be observed for the treated units, the training data follows the distribution PY (1),X | T =1 while our target distribution is PY (1),X — there exists a distributional shift. The covariate shift can be computed as follows w(x) = dPX dPX | T =1 (x) = P(T = 1) e(x) ∝ 1 e(x) , 2Such an assumption can always be achieved by taking U to be (Y (1), Y (0)). 9 which depends only on the observable propensity score and can be estimated with the data. Next, we consider the distributional shift in Y (1) | X. By Jin et al. (2022, Lemma 1), under the f -sensitivity model, Df (PY (1) | X,T =0 ∥ PY (1) | X,T =1) ≤ ρ almost surely. Consequently, Df (PY (1) | X ∥ PY (1) | X,T =1) = Df (e(X) · PY (1) | X,T =1 + (1 − e(X)) · PY (1) | X,T =0 ∥ PY (1) | X,T =1) ≤ (1 − e(X)) · Df (PY (1) | X,T =0 ∥ PY (1) | X,T =1) ≤ ρ, where the inequality follows from the convexity of the f -divergence. By now, it should be clear that the distributional shift in our task consists of an estimable covariate shift and a shift in Y | X bounded in f -divergence, and therefore fits into the framework of this paper. For completeness, we present the adaptation of our main proposal to this specific task of sensitivity analysis, as long as results for other types of estimands in Appendix C. 5 Numerical results 5.1 Simulation setup and evaluation metrics We empirically compare our proposed methods WRCP and D-WRCP with the following benchmarks: - CP: standard conformal prediction designed for exchangeable data (Vovk et al., 2005); - WCP: weighted conformal prediction (Tibshirani et al., 2019); - RCP: robust conformal prediction (Cauchois et al., 2023). For all the five candidate methods, we implement the split version, where half of the data is reserved for model fitting and the other half for calibration. The nonconformity score s(x, y) = |y − ̂µ(x)| is adopted, where we fit ̂µ(·) with cross-validated Lasso (Tibshirani, 1996) using the scikit-learn package in python (Pedregosa et al., 2011). For WCP, WRCP and D-WRCP, the covariate likelihood ratio w(x) is estimated via the random forest classifier (Breiman, 2001) in the scikit-learn package. For WRCP, D-WRCP, we use the KL divergence to quantify the distributional shift, i.e., f (t) = t log t, and consider a sequence of robust parameters ρ. For each ρ, the corresponding robust parameter of RCP is chosen as ρRCP = ρ + DKL(QX ∥ PX ) by the chain rule of KL divergence, where DKL(QX ∥ PX ) is estimated by plugging in the estimated ̂w. In the implementation of D-WRCP, the conditional CDF is estimated by random forest with the python package qosa-indices (Elie-Dit-Cosaque, 2020). For all methods, the target coverage rate is 0.9. In our simulations, we consider X ∈ R50 and Y ∈ R. For the training data, X ∼ N (0, I50), Y | X ∼ X ⊤β + N (0, 1) where ∥β∥0 = 10 and the nonzero entries take the value 0.47. The target covariate distribution has a shifted mean: QX = N (β0, I50), and β0 = (η, −η, 0, · · · , 0), where η is a tuning parameter controlling the amount of covariate shift; the target Y | X distribution is specified as follows, dQY | X dPY | X (x) = { 0.96 if ∣ ∣Y − X ⊤β∣ ∣ < 1.86; 1.59 if ∣ ∣Y − X ⊤β∣ ∣ ≥ 1.86. By construction, the ground truth ρ ∗ = DKL(QY | X ∥ PY | X ) = 0.01. We let η to be 0.1, 0.5, and 0.8 — corresponding to low, medium, and high levels of covariate shift respectively. For each run of under a simulation setting, a training set Dtr and a test set Dtest are generated, with |Dtr| = |Dtest| = 2000. We consider ρ ∈ {0.005, 0.01, . . . , 0.025}. For each ρ, the above experiment is repeated for N = 100 runs, and for each method, we compute the averaged coverage rate and prediction interval length averaged over the 100 runs and 50% of the test samples (1000 samples): ̂Coverage = 1 100 × 1000 100∑ i=1 1000∑ j=1 1{Yij covered}, ̂Length = 1 100 × 1000 100∑ i=1 1000∑ j=1 Lengthij. Ideally, a method should have ̂Coverage ≥ 0.9 and as small ̂Length as possible. 10 5.2 Simulation results Figure 1 presents the simulation results of all methods. As expected, CP and WCP fail to achieve the desired coverage level 0.9. RCP is overly conservative since it also considers the worst-case covariate shift. Our proposed method WRCP and D-WRCP achieve approximate validity for a wide range of ρ — in particular, WRCP and D-WRCP achieve almost exact coverage when ρ = ρ∗; as ρ increases, the coverage remains reasonably close to the target level. The prediction interval length tells a similar story: CP and WCP have short prediction intervals due to undercoverage; RCP often outputs prediction intervals of infinite length (for the purpose of illustration, we replace +∞ with 17 — an upper bound of all the realized lengths — when plotting the results); our methods provide valid and informative prediction intervals. Figure 1: Averaged coverage (top) and prediction interval length (bottom) over N = 100 independent runs as a function of the robust parameter ρ, when the amount of covariate shift is low (left), medium (middle), and high (right). The shaded bars correspond to the 95% confidence intervals. The horizontal dashed line corresponds to the target coverage rate 0.9, and the vertical dashed line is the true robust parameter ρ∗ = 0.01. 6 Real data applications In this section, we evaluate the performance of all methods on three real datasets: the national study of learning mindsets dataset (Carvalho et al., 2019), the ACS income dataset (Ding et al., 2021), and the covid information study datasets (Pennycook et al., 2020; Roozenbeek et al., 2021). For each task, we implement WRCP and D-WRCP, as well as the benchmarks CP, WCP, and RCP with the target coverage level 80%. For WRCP and D-WRCP, we choose f (t) = t log t (the KL-divergence), and consider a sequence of robust parameter ρ’s, reporting the averaged coverage rate and prediction set length/cardinality as a function of ρ. For RCP, the robust parameter is chosen as ρRCP = ρ + DKL(QX ∥ PX ), where DKL(QX ∥ PX ) = EQX [log(dQX /dPX )] is estimated with Monte Carlo with the set-aside training data. 6.1 National study of learning mindsets The National Study of Learning Mindsets (NSLM) (Yeager et al., 2019; Yeager, 2019) is a randomized study investigating the effect of instilling students with a growth mindset. Based on the results from NSLM, Carvalho et al. (2019) creates an observational study dataset with similar characteristics to the original study. The observational study dataset contains 10,391 students, where 3,384 received the intervention and 7,007 did not. For each student, the dataset records the treatment status T , the outcome Y , and ten covariates: S3, C1, C2, C3, XC, X1, X2, X3, X4, X5.3 We consider the task of predicting 3The detailed description of the covariates can be found in Carvalho et al. (2019, Table 1). The original dataset also contains the school id, but we do not include it in our analysis. 11 Y (1) in the control group, where we wish to construct a prediction interval ̂Cf,ρ(X) such that P(Y (1) ∈ ̂Cf,ρ(X) ∣ ∣ T = 0 ) ≥ 80%. Without observing the counterfactuals, the validity of a procedure cannot be evaluated. As an alter- native, we create a semi-synthetic data based on the NSLM dataset. Following the strategy of Carvalho et al. (2019), we generate synthetic potential outcomes from the following model: Y (t) = µ(x) + τ (x1, x2, c1) · t + ϵ, for t = 0, 1. Above, x denotes all the covariates for a student, and x1, x2, c1 corresponds to X1, X2 and C1, respec- tively. The baseline function µ is obtained by fitting a generalized additive model (Hastie, 2017) on the control arm of the original data, and ϵ is sampled with replacement from the sum of the residual from the fitted model on the original data and a noise term N (0, 0.025). The form of the treatment effect is: τ (x1, x2, c1) = 0.228 + 0.05 · 1{x1 < 0.07} − 0.05 · 1{x2 < −0.69} − 0.08 · 1{c1 ∈ {1, 13, 14}}. Confounding is introduced by removing two features, X1 and X2. We consider a sequence of ρ ∈ {0.001, 0.005, 0.01, 0.015, . . . , 0.04}. For each run, we randomly select half of the treated units and half of the control units for model fitting; the other half of the treated units are reserved for calibration, while the other half of the control units for evaluation. The nonconformity score function s(x, y) = |y − ̂µ(x)|. Both the regression function ̂µ(x) and the propensity score function e(x) are fitted with random forest. With each ρ, we repeat the above process for 100 random splits. Figure 2 plots the resulting coverage rate and prediction interval length as a function of ρ. CP and WCP fail to achieve the desired coverage level, while RCP is overly conservative, achieving a much higher coverage rate than the target level. Our methods WRCP and D-WRCP achieve approximate coverage for a wide range of ρ, and are much more efficient than RCP. Figure 2: Averaged coverage (left) and prediction interval length (right) over 100 runs as a function of the robust parameter ρ from experiments on the NSLM dataset. The dashed bar corresponds to the 95% confidence interval and the horizontal dashed line corresponds to the target coverage rate 80%. 6.2 ACS income dataset We further evaluate our procedure for a classification task with the ACS income dataset constructed from the US census data (Ding et al., 2021). The target is to predict whether an individual’s annual income is above 50,000 dollars. The specific dataset we use is the version pre-processed by Liu et al. (2023), where we choose the data from New York (NY) as the training set, and that from South Dakota (SD) as the tar- get — as discussed in Liu et al. (2023), both X-shift and Y | X-shift exist between the training and target population. The training and test set contain 103,021 and 4,899 samples, respectively. For each sample, 9 features are recorded, where 3 of them are continuous and 6 categorical. After introducing the dummy variables, the dimension of X comes to 76. The response variable Y = 1{income ≥ 50,000 dollars}. Since Y is binary, we adopt the generalized inverse quantile conformity score introduced by Romano et al. (2020), and the prediction set is a subset of {0, 1}. The weight function ̂w is estimated via 12 XGBoost (Chen and Guestrin, 2016) with the hyperparameters provided by Liu et al. (2023), and the outcome model ̂µ is fitted with random forest. The robust parameter ρ ∈ {0.005, 0.01, . . . , 0.04}. In each run, we randomly select 2000 samples from the source population, and the same number of samples from the target population. For each ρ, we repeat the above process over 100 random splits and report the averaged coverage and prediction set cardinality. Figure 3 presents the simulation results of all methods. Ae before, CP and WCP fail to achieve the desired coverage level 80%; WCP improves upon CP because it adjusts for the covariate shift. RCP is overly conservative, while our methods again deliver valid and efficient prediction intervals for a wide range of ρ’s. Figure 3: Averaged coverage (left) and prediction set cardinality (right) over 100 runs as a function of the robust parameter ρ from the experiment on ACS income dataset. The other details are the same as in Figure 2. 6.3 COVID information studies The covid information studies investigate how a “nudge” for thinking about the accuracy of informa- tion can affect the people’s ability to discern fake news when sharing COVID-related headlines. The original study of 856 participants (Pennycook et al., 2020) is first conducted, followed by a replication study (Roozenbeek et al., 2021) of 1,583 participants. The original study found a significant interaction term between the intervention and the validity of the headline, while the replication study also found a significant interaction, but with a much smaller magnitude (more details about the comparison between the two studies can be found in Jin et al. (2023a)). As discussed in Jin et al. (2023a), the discrepancy between the two results can be attributed to the distributional shift in the both the covariates and Y | X. Here, instead of estimating the treatment effect, we consider the task of predicting a participant’s rating for willingness to share a headline. Each sample in the dataset corresponds to a participant, where the outcome is the rating for their willingness to share a headline; the predictors include the treatment status (i.e., whether a nugde is sent), the validity of the news, and 10 other covariates. 4 After removing the samples with missing values, the training and test set consist of 811 and 1,583 samples, respectively. Each run splits the training and test sets into two halves for model fitting and calibration; The weight function ̂w and the outcome model ̂µ are both estimated via random forest. The robust parameter ρ ∈ {0.005, 0.01, . . . , 0.04}, and for each ρ We repeat the above process for 100 random splits. Figure 4 demonstrates the results of all methods. For the purpose of visualization, we replace the infinite prediction interval length with 2 (an upper bound of all the finite realized lengths) when plotting the averaged prediction interval length. In this example, we again see that CP and WCP fail to achieve the desired coverage level, with WCP being slightly better than CP due to the adjustment for covariate shift. The proposed methods WRCP and D-WRCP achieve approximate coverage for a wide range of ρ’s, and are much more efficient than RCP. 4In the original datasets, each participant was asked to rate 30 headlines. In our analysis, the outcome and the covariates are all averaged over the 30 headlines. 13 Figure 4: Averaged coverage (left) and prediction interval length (right) over 100 runs as a function of the robust parameter ρ from the experiment on covid study datasets. The other details are the same as in Figure 2. 7 Discussion In this paper, we provide a fine-grained approach to quantifying the uncertainty of predictive models by distinguishing sources of distributional shift and providing different treatments. We propose two new methods, WRCP and its debiased version D-WRCP, that achieve validity and efficiency under a wide range of distributional shifts, as demonstrated in the simulation and real data experiments. This paper opens up several interesting directions for future work. First, it would be interesting to investigate methods for identifying (an upper bound) of the robust parameter ρ when we have a small amount of supervised data from the target population. Second, can we extend this fine-grained approach to other distributional shift models and improves the efficiency of the corresponding methodologies? Last but not least, there can be other ways to decompose the distributional shifts — it remains to be understood the optimal decomposition in different settings and the corresponding treatments. Reproducibility All the numerical results in this paper can be reproduced with the code available at https://github. com/zhimeir/finegrained-conformal-paper. Acknowledgements The authors would like to thank Wharton High Performance Computing for the computational resources and the support from the staff members. The authors would also like to thank Ying Jin for the feedback on the manuscript. References Angelopoulos, A. N., Bates, S., et al. (2023). Conformal prediction: A gentle introduction. Foundations and Trends® in Machine Learning, 16(4):494–591. Barber, R. F., Candes, E. J., Ramdas, A., and Tibshirani, R. J. (2021). The limits of distribution-free conditional predictive inference. Information and Inference: A Journal of the IMA, 10(2):455–482. Barber, R. F., Candes, E. J., Ramdas, A., and Tibshirani, R. J. (2023). Conformal prediction beyond exchangeability. The Annals of Statistics, 51(2):816–845. Blanchet, J. and Murthy, K. (2019). Quantifying distributional model risk via optimal transport. Math- ematics of Operations Research, 44(2):565–600. Breiman, L. (2001). Random forests. Machine learning, 45:5–32. Carvalho, C., Feller, A., Murray, J., Woody, S., and Yeager, D. (2019). Assessing treatment effect variation in observational studies: Results from a data challenge. 14 Cauchois, M., Gupta, S., Ali, A., and Duchi, J. C. (2023). Robust validation: Confident predictions even when distributions shift. Journal of the American Statistical Association, (just-accepted):1–22. Chen, T. and Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785–794. Chernozhukov, V., Wüthrich, K., and Zhu, Y. (2021). Distributional conformal prediction. Proceedings of the National Academy of Sciences, 118(48):e2107794118. Cover, T. M. (1999). Elements of information theory. John Wiley & Sons. Ding, F., Hardt, M., Miller, J., and Schmidt, L. (2021). Retiring adult: New datasets for fair machine learning. Advances in neural information processing systems, 34:6478–6490. Duchi, J., Hashimoto, T., and Namkoong, H. (2023). Distributionally robust losses for latent covariate mixtures. Operations Research, 71(2):649–664. Duchi, J. C. and Namkoong, H. (2021). Learning models with uniform performance via distributionally robust optimization. The Annals of Statistics, 49(3):1378–1406. Elie-Dit-Cosaque, K. (2020). qosa-indices. Gendler, A., Weng, T.-W., Daniel, L., and Romano, Y. (2021). Adversarially robust conformal prediction. In International Conference on Learning Representations. Ghosh, S., Shi, Y., Belkhouja, T., Yan, Y., Doppa, J., and Jones, B. (2023). Probabilistically robust conformal prediction. In Uncertainty in Artificial Intelligence, pages 681–690. PMLR. Guan, L. (2023). Localized conformal prediction: A generalized inference framework for conformal prediction. Biometrika, 110(1):33–50. Gui, Y., Hore, R., Ren, Z., and Barber, R. F. (2023). Conformalized survival analysis with adaptive cutoffs. Biometrika, page asad076. Gupta, C., Kuchibhotla, A. K., and Ramdas, A. (2022). Nested conformal prediction and quantile out-of-bag ensemble methods. Pattern Recognition, 127:108496. Hastie, T. J. (2017). Generalized additive models. In Statistical models in S, pages 249–307. Routledge. Imbens, G. W. and Rubin, D. B. (2015). Causal inference in statistics, social, and biomedical sciences. Cambridge University Press. Jin, Y., Guo, K., and Rothenhäusler, D. (2023a). Diagnosing the role of observable distribution shift in scientific replications. arXiv preprint arXiv:2309.01056. Jin, Y., Ren, Z., and Candès, E. J. (2023b). Sensitivity analysis of individual treatment effects: A robust conformal inference approach. Proceedings of the National Academy of Sciences, 120(6):e2214889120. Jin, Y., Ren, Z., and Zhou, Z. (2022). Sensitivity analysis under the f -sensitivity models: a distributional robustness perspective. arXiv preprint arXiv:2203.04373. Kallus, N. and Zhou, A. (2020). Confounding-robust policy evaluation in infinite-horizon reinforcement learning. Advances in neural information processing systems, 33:22293–22304. Kallus, N. and Zhou, A. (2021). Minimax-optimal policy learning under unobserved confounding. Man- agement Science, 67(5):2870–2890. Lei, J., G’Sell, M., Rinaldo, A., Tibshirani, R. J., and Wasserman, L. (2018). Distribution-free predictive inference for regression. Journal of the American Statistical Association, 113(523):1094–1111. Lei, L. and Candès, E. J. (2021). Conformal inference of counterfactuals and individual treatment effects. Journal of the Royal Statistical Society Series B: Statistical Methodology, 83(5):911–938. Lei, L., Sahoo, R., and Wager, S. (2023). Policy learning under biased sample selection. arXiv preprint arXiv:2304.11735. Liu, J., Wang, T., Cui, P., and Namkoong, H. (2023). On the need for a language describing distribution shifts: Illustrations on tabular datasets. arXiv preprint arXiv:2307.05284. Miller, J., Krauth, K., Recht, B., and Schmidt, L. (2020). The effect of natural distribution shift on question answering models. In International conference on machine learning, pages 6905–6916. PMLR. Mu, T., Chandak, Y., Hashimoto, T. B., and Brunskill, E. (2022). Factored DRO: Factored distribu- tionally robust policies for contextual bandits. Advances in Neural Information Processing Systems, 35:8318–8331. Namkoong, H., Yadlowsky, S., et al. (2023). Diagnosing model performance under distribution shift. arXiv preprint arXiv:2303.02011. 15 Neyman, J. (1923). Sur les applications de la théorie des probabilités aux experiences agricoles: Essai des principes. Roczniki Nauk Rolniczych, 10(1):1–51. Papadopoulos, H., Proedrou, K., Vovk, V., and Gammerman, A. (2002). Inductive confidence machines for regression. In Machine Learning: ECML 2002: 13th European Conference on Machine Learning Helsinki, Finland, August 19–23, 2002 Proceedings 13, pages 345–356. Springer. Park, S., Dobriban, E., Lee, I., and Bastani, O. (2022). PAC prediction sets under covariate shift. In International Conference on Learning Representations. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Pretten- hofer, P., Weiss, R., Dubourg, V., et al. (2011). Scikit-learn: Machine learning in python. Journal of machine learning research, 12(Oct):2825–2830. Pennycook, G., McPhetres, J., Zhang, Y., Lu, J. G., and Rand, D. G. (2020). Fighting covid-19 mis- information on social media: Experimental evidence for a scalable accuracy-nudge intervention. Psy- chological science, 31(7):770–780. Podkopaev, A. and Ramdas, A. (2021). Distribution-free uncertainty quantification for classification under label shift. In Uncertainty in Artificial Intelligence, pages 844–853. PMLR. Qiu, H., Dobriban, E., and Tchetgen, E. T. (2022). Distribution-free prediction sets adaptive to unknown covariate shift. arXiv preprint arXiv:2203.06126. Rahimian, H. and Mehrotra, S. (2019). Distributionally robust optimization: A review. arXiv preprint arXiv:1908.05659. Recht, B., Roelofs, R., Schmidt, L., and Shankar, V. (2019). Do imagenet classifiers generalize to imagenet? In International conference on machine learning, pages 5389–5400. PMLR. Romano, Y., Patterson, E., and Candes, E. (2019). Conformalized quantile regression. Advances in neural information processing systems, 32. Romano, Y., Sesia, M., and Candès, E. J. (2020). Classification with valid and adaptive coverage. Roozenbeek, J., Freeman, A. L., and van der Linden, S. (2021). How accurate are accuracy-nudge interventions? a preregistered direct replication of pennycook et al.(2020). Psychological science, 32(7):1169–1178. Rosenbaum, P. R. (1987). Sensitivity analysis for certain permutation inferences in matched observational studies. Biometrika, 74(1):13–26. Sahoo, R., Lei, L., and Wager, S. (2022). Learning from a biased sample. arXiv preprint arXiv:2209.01754. Shafieezadeh Abadeh, S., Mohajerin Esfahani, P. M., and Kuhn, D. (2015). Distributionally robust logistic regression. Advances in Neural Information Processing Systems, 28. Si, N., Zhang, F., Zhou, Z., and Blanchet, J. (2023). Distributionally robust batch contextual bandits. Management Science. Tan, Z. (2006). A distributional approach for causal inference using propensity scores. Journal of the American Statistical Association, 101(476):1619–1637. Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society Series B: Statistical Methodology, 58(1):267–288. Tibshirani, R. J., Foygel Barber, R., Candes, E., and Ramdas, A. (2019). Conformal prediction under covariate shift. Advances in neural information processing systems, 32. Vovk, V., Gammerman, A., and Shafer, G. (2005). Algorithmic learning in a random world, volume 29. Springer. Wong, A., Otles, E., Donnelly, J. P., Krumm, A., McCullough, J., DeTroyer-Cooley, O., Pestrue, J., Phillips, M., Konye, J., Penoza, C., et al. (2021). External validation of a widely implemented propri- etary sepsis prediction model in hospitalized patients. JAMA Internal Medicine, 181(8):1065–1070. Yadlowsky, S., Namkoong, H., Basu, S., Duchi, J., and Tian, L. (2018). Bounds on the conditional and average treatment effect with unobserved confounding factors. arXiv preprint arXiv:1808.09521. Yang, Y., Kuchibhotla, A. K., and Tchetgen, E. T. (2022). Doubly robust calibration of prediction sets under covariate shift. arXiv preprint arXiv:2203.01761. Yeager, D. S. (2019). The National Study of Learning Mindsets,[United States], 2015-2016. Yeager, D. S., Hanselman, P., Walton, G. M., Murray, J. S., Crosnoe, R., Muller, C., Tipton, E., 16 Schneider, B., Hulleman, C. S., Hinojosa, C. P., et al. (2019). A national experiment reveals where a growth mindset improves achievement. Nature, 573(7774):364–369. Yin, M., Shi, C., Wang, Y., and Blei, D. M. (2022). Conformal sensitivity analysis for individual treatment effects. Journal of the American Statistical Association, pages 1–14. Zhang, Z., Zhan, W., Chen, Y., Du, S. S., and Lee, J. D. (2023). Optimal multi-distribution learning. arXiv preprint arXiv:2312.05134. Zhao, Q., Small, D. S., and Bhattacharya, B. B. (2019). Sensitivity analysis for inverse probability weighting estimators via the percentile bootstrap. Journal of the Royal Statistical Society Series B: Statistical Methodology, 81(4):735–761. 17 A Auxiliary lemmas Lemma 1 (Data processing inequality (Cover, 1999)). Let X, Y, Z denote random variables drawn from a Markov chain in the order (denoted by X → Y → Z) that the conditional distribution of Z depends only on Y and is conditionally independent of X. Then if X → Y → Z, we have I(X; Y ) ≥ I(X; Z), where I(X; Y ) is the mutual information between X and Y . Lemma 2 (Adapted from Lemma A.1 of Cauchois et al. (2023)). Let f : R ↦→ R be a closed convex function such that f (1) = 0 and f (t) < ∞ for all t > 0. The function gf,ρ(β) has the following properties. (a) (ρ, β) → gf,ρ(β) is a convex function and continuous in β ∈ [0, 1] and ρ ∈ (0, ∞). (b) gf,ρ(β) is non-increasing in ρ and non-decreasing in β. Moreover, for all ρ > 0, there exists β0(ρ) := sup {β ∈ (0, 1) | gf,ρ(β) = 0 }, and gf,ρ(β) is strictly increasing for β > β0(ρ). B Technical Proofs B.1 Proof of Theorem 1 For notional simplicity, let A := {Yn+1 ∈ ̂Cf,ρ(Xn+1)} . We aim to show that P(Xn+1,Yn+1)∼QX,Y (A) ≥ 1 − α. Denote by Bern(p) the Bernoulli distribution with success probability p. By data processing inequality (Lemma 1), we have that Df (QY | X ∥ PY | X ) ≥ Df (Bern(PYn+1∼QY | X (A | Xn+1, D) ) ∥ ∥ Bern (PYn+1∼PY | X (A | Xn+1, D) )). Recall that Q ∈ P(ρ; P ). We then have ρ ≥ Df (QY | X ∥ PY | X ) ≥ Df (Bern (PYn+1∼QY | X (A | Xn+1, D)) ∥ ∥ Bern (PYn+1∼PY | X (A | Xn+1, D) )) = PYn+1∼PY | X (A | Xn+1, D) · f ( PYn+1∼QY | X (A | Xn+1, D) PYn+1∼PY | X (A | Xn+1, D) ) + (1 − PY ∼PY | X (A | Xn+1, D) ) · f ( 1 − PY ∼QY | X (A | Xn+1, D) 1 − PY ∼PY | X (A | Xn+1, D) ), where the last step follows from the definition of the f -divergence. Combining the above and the definition of gf,ρ, one can obtain that almost surely gf,ρ(PY ∼PY | X (A) ) ≤ PY ∼QY | X (A). (6) Next, we take the expectation over the randomness of the training set D and Xn+1 PD, (Xn+1,Yn+1)∼QX,Y (A) = ED, Xn+1∼QX [ PYn+1∼QY | X (A | Xn+1, D)] ≥ ED,Xn+1∼QX [ gf,ρ(PY ∼PY | X (A | Xn+1, D) )], (7) where the last inequality is because of (6). Since gf,ρ is convex (Lemma 2), Jensen’s inequality implies ED,Xn+1∼QX [gf,ρ(PY ∼PY | X (A | Xn+1, D) )] ≥ gf,ρ(PD,(Xn+1,Yn+1)∼QX ×PY | X (A)). (8) By Tibshirani et al. (2019, Corollary 1) and the construction of ̂Cf,ρ(Xn+1), there is PD,(Xn+1,Yn+1)∼QX ×PY | X (A) ≥ g−1 f,ρ(1 − α). Again leveraging the monotonicity of gf,ρ(β) in β, we arrive at PD,(Xn+1,Yn+1)∼QX,Y (A) ≥ gf,ρ(g−1 f,ρ(1 − α)). When gf,ρ(1) ≥ 1 − α, we prove that gf,ρ(g−1 f,ρ(1 − α) ) ≥ 1 − α by contradiction. Suppose otherwise that gf,ρ(g−1 f,ρ(1 − α)) < 1 − α. Then g−1 f,ρ(1 − α) < 1. By the continuity of gf,ρ(β) in β, there exists a small ε > 0, such that gf,ρ(β) < 1 − α for all β ∈ [g−1 f,ρ(1 − α), g−1 f,ρ(1 − α) + ϵ], which contradicts the definition of g−1 f,ρ(1 − α). The proof is therefore completed. 18 B.2 Proof of Theorem 2 Throughout the proof, we condition on D(0) tr ∪ D(1−k) test , and for notational simplicity we do not explicitly write the conditional probability and expectation when the context is clear. We start by defining a new distribution ̃QX,Y = ̃QX × PY | X such that d ˜QX dPX (x) = ̂w(k)(x) EX∼PX [ ̂w(k)(X)] . Let A = {Yn+j ∈ ̂Cf,ρ,j(Xn+j)} . If (Xn+j, Yn+j) were indeed sampled from ̃QX,Y , then by Lemma 1 of Tibshirani et al. (2019), we have P D(1) tr ,(Xn+j ,Yn+j )∼ ̃QX,Y (A) ≥ g−1 f,ρ(1 − α). (9) Meanwhile, by the definition of the TV distance, ∣ ∣ ∣P(Xn+j ,Yn+j )∼ ̃QX ×PY | X (A | D(1) tr ) − P(Xn+j ,Yn+j )∼QX ×PY | X (A | D(1) tr )∣ ∣ ∣ ≤ DTV( ̃QX × QY | X ∥ QX × QY | X ) = DTV( ̃QX ∥ QX ) = 1 2 EX∼PX [∣ ∣ ∣ ̂w(k)(X) EX∼PX [ ̂w(k)(X)] − w(X) ∣ ∣ ∣] . The above inequality implies that P(Xn+j ,Yn+j )∼QX ×PY | X (A ∣ ∣ D(1) tr ) ≥ P(Xn+j ,Yn+j )∼ ̃QX ×PY | X (A ∣ ∣ D(1) tr ) − 1 2 EX∼PX [∣ ∣ ∣ ̂w(k)(X) EX∼PX [ ̂w(k)(X)] − w(X)∣ ∣ ∣ ]. Taking expectation over D(1) tr , we have P D(1) tr ,(Xn+j ,Yn+j )∼QX ×PY | X (A) ≥ P D(1) tr ,(Xn+j ,Yn+j )∼ ̃QX,Y (A) − 1 2 EX∼PX [∣ ∣ ∣ ̂w(k)(X) EX∼PX [ ̂w(k)(X)] − w(X)∣ ∣ ∣] ≥ g−1 f,ρ(1 − α) − 1 2 EX∼PX [∣ ∣ ∣ ̂w(k)(X) EX∼PX [ ̂w(k)(X)] − w(X) ∣ ∣ ∣] , where the last step follows from (9). Following the same argument as in the proof of Theorem 1 (Eqn. (7) and (8)), we have P D(1) tr ,(Xn+1,Yn+1)∼QX,Y (A) ≥ gf,ρ(P D(1) tr ,(Xn+j ,Yn+j )∼QX ×PY | X (A)) ≥ gf,ρ ( g−1 f,ρ(1 − α) − 1 2 EX∼PX [∣ ∣ ∣ ̂w(k)(X) EX∼PX [ ̂w(k)(X)] − w(X) ∣ ∣ ∣]) , (10) where the last inequality is because gf,ρ(β) is non-decreasing in β. Since gf,ρ(β) is convex in (0, 1), the left derivative exists and by the separating hyperplane theorem, we further have (10) ≥ gf,ρ(g−1 f,ρ(1 − α)) − 1 2 g′ f,ρ(g−1 f,ρ(1 − α) ) · EX∼PX [∣ ∣ ∣ ̂w(k)(X) EX∼PX [ ̂w(k)(X)] − w(X) ∣ ∣ ∣] . As shown in the proof of Theorem 1, when gf,ρ(1) ≥ 1 − α, gf,ρ(g−1 f,ρ(1 − α)) ≥ 1 − α, and we conclude the proof. B.3 Proof for the doubly robust prediction intervals We start by proving that the DDR f,ρ,n+j(Xn+j) is training-conditionally valid in Theorem 5, and then show that Theorem 3 is a direct consequence of Theorem 5. 19 Theorem 5. For any k ∈ {0, 1}, assume that (1) ̂w(k)(x) ≤ wmax · EPX [ ̂w(k)(X)]; (2) ̂m (k)(x; t) ∈ [0, 1] is non-decreasing and right-continuous in t. Denote the product estimation error by EstErr (k)(t) = ∥ ∥1{s(X, Y ; ̂µ (k)) ≤ t} − ̂m (k)(X; t) ∥ ∥ L2(P ) ∥ ∥ ∥ ∥ ̂w(k)(X) EX∼PX [ ̂w(k)(X)] − w(X)∥ ∥ ∥ ∥ L2(P ), where ∥ · ∥L2(P ) denotes the L2-norm under P , and the expectation is taken conditional on D(1−k) tr and D(1−k) test . Then for any δ > 0 and any unit n + j ∈ I (k) test, with probability at least 1 − δ, P(Xn+j ,Yn+j )∼QX,Y (Yn+j ∈ ̂C DR f,ρ,n+j(Xn+j) ∣ ∣ D(k) tr , D(k) test,j, D(1−k) tr , D(1−k) test ) ≥ gf,ρ(g−1 f,ρ(1 − α) ) − g′ f,ρ(g−1(1 − α) ) × { sup t∈T (α) EstErr (k)(t) + √ log ( 1 δ ) · ( 9w2 max |I (k) tr | + 1 |I (k) test,j| )} , where g′ f,ρ is the left derivative of gf,ρ. If gf,ρ(1) ≥ 1 − α, then with probability at least 1 − δ, P(Xn+j ,Yn+j )∼QX,Y (Yn+j ∈ ̂C DR f,ρ,n+j(Xn+j) ∣ ∣ D(k) tr , D(k) test,j, D(1−k) tr , D(1−k) test ) ≥ 1 − α − g′ f,ρ(g−1(1 − α) ) × { sup t∈T (α) EstErr (k)(t) + √ log ( 1 δ ) · ( 9w2 max |I (k) tr | + 1 |I (k) test,j| )} . Proof. Without loss of generality, assume k = 1. Throughout, we condition on D(0) tr ∪ D(0) test without explicitly writing the conditioning event when the context is clear. For notational simplicity, we define the normalized weight as ̃w(k)(x) = ̂w(k)(x) EX∼PX [ ̂w(k)(X)] . In the proof we leave out the dependence on k, writing ̂m(X; t) and ̃w(X) in place of ̂m (1)(X; t) and ̃w(1)(X); additionally, we refer to E(X,Y )∼PX,Y as EPX,Y , with the same rule applied to the expecta- tion/probability under other distributions, and let ntr = |I (1) tr | and ntest = |I (1) test,j|. For any t ∈ R, we define the oracle CDF F (t) = PQX ×PY | X (s(X, Y ) ≤ t), and for any ξ ∈ [0, g−1 f,ρ(1 − α)], the perturbed oracle quantile q∗(ξ) can be equivalently written as q∗(ξ) = inf {t ∈ R : F (t) ≥ g−1 f,ρ(1 − α) − ξ}. Consider the error of margin ∆ = sup κ·q∗( ¯∆)≤t≤q∗(0) EstErr(t) + √ log ( 1 δ ) · ( 9w2 max ntr + 1 ntest ), where κ ∈ (0, 1) is a constant that can be arbitrarily close to 1 and ¯∆ = { sup 0≤t≤q∗(0) EstErr(t) + √ log ( 1 δ ) · ( 9w2 max ntr + 1 ntest )} ∧ g−1 f,ρ(1 − α). Here, a ∧ b = min(a, b) and ∆ is fully deterministic conditional on D(0) tr ∪ D(0) test. The proof consists of two steps: (1) we show that, with high probability, ̂q ≥ q∗(∆). and therefore ̂q is no less than the (g−1 f,ρ(1 − α) − ∆)-th quantile under QX × PY | X , and (2) ̂q is approximately an upper bound of the (1 − α)-th quantile under QX,Y . Step (1). On the event {q∗(∆) ≤ ̂q}, P (s(Xn+j, Yn+j) ≤ ̂q | D(1) tr , D(1) test,j) = F (̂q) (i) ≥ F (q∗(∆)) (ii) ≥ g−1 f,ρ(1 − α) − ∆, 20 where step (i) follows from the monotonicity of F (t), and step (ii) is by the definition of q∗(∆) and that F (t) is right-continuous. It then suffices to control the probability of {q∗(∆) > ̂q}. Fixing δ ∈ [0, 1], we aim at showing that P(̂q < q∗(∆)) ≤ δ. The above is trivial when ∆ ≥ g−1 f,ρ(1 − α). We proceed assuming that ∆ < g−1 f,ρ(1 − α). For any ε > 0, we have that F (q∗(∆)−ε) < g−1 f,ρ(1−α)−∆ by the definition of q∗(∆). If ̂q ≤ q∗(∆)−ε, then the choice of ̂q implies that ̂p(q∗(∆) − ε) ≥ g−1 f,ρ(1 − α). In other words, P (̂q ≤ q∗(∆) − ε) ≤ P (̂p(q∗(∆) − ε) ≥ g−1 f,ρ(1 − α) ). (11) For better readability, we use ¯t to represent q∗(∆) − ε, and let Zi = 1{Si ≤ ¯t} − ̂m(Xi; ¯t) in the following. The right-hand side of (11) can be further upper bounded as P(̂p(¯t) ≥ g−1 f,ρ(1 − α) ) = P( ∑ i∈I(1) tr ̃w(Xi)Zi + ( ∑ i∈I(1) tr ̃w(Xi) )( 1 ntest ∑ i∈I(1) test,j ̂m(Xi; ¯t) − g−1 f,ρ(1 − α)) ≥ 0 ) ≤ E [ exp {η( ∑ i∈I(1) tr ̃w(Xi)Zi + ( ∑ i∈I(1) tr ̃w(Xi))( 1 ntest ∑ i∈I(1) test,j ̂m(Xi; ¯t) − g−1 f,ρ(1 − α)))}] , (12) where η > 0 is some constant to be determined and the last step follows from Markov’s inequality. Conditional on {Xi}i∈I(1) tr , Zi − E[Zi | Xi] are 1 4 -subgaussian random variables. Therefore, E [ exp { η( ∑ i∈I(1) tr ̃w(Xi) · (Zi − E[Zi | Xi]))} ∣ ∣ ∣ {Xi}i∈I(1) tr ] ≤ exp ( η2w2 maxntr 8 ). The above implies that (12) ≤ exp ( η2w2 maxntr 8 ) · E [ exp { η( ∑ i∈I(1) tr ̃w(Xi)E[Zi | Xi] + ( ∑ i∈I(1) tr ̃w(Xi) )( 1 ntest ∑ i∈Itest,j ̂m(Xi; ¯t) − g−1 f,ρ(1 − α) ))}] ≤ exp ( η2w2 maxntr 8 ) · E [ exp { 2η( ∑ i∈I(1) tr ( ̃w(Xi)E[Zi | Xi] + 1 ntest ∑ ℓ∈I(1) test,j ̂m(Xℓ; ¯t) − g−1 f,ρ(1 − α) ))}]1/2 × E [ exp (2η ∑ i∈I(1) tr ( ̃w(Xi) − 1 ) · ( 1 ntest ∑ ℓ∈I(1) test,j ̂m(Xℓ; ¯t) − g−1 f,ρ(1 − α) ))]1/2 , where the last inequality follows from the Cauchy-Schwarz inequality. Since D(1) test is independent of D(1) tr , conditional on D(1) test, there is E [ exp (2η ∑ i∈I(1) tr ( ̃w(Xi) − 1 )( 1 ntest ∑ ℓ∈I(1) test,j ̂m(Xℓ; ¯t) − g−1 f,ρ(1 − α) )) ∣ ∣ ∣ ∣ D(1) test ]1/2 ≤ exp (η2w2 maxntr), 21 where we use the sub-gaussianity of ̃w(Xi). Recalling that F (¯t) < g−1 f,ρ(1 − α) − ∆, we have that E [ exp { 2η( ∑ i∈I(1) tr ( ̃w(Xi)E[Zi | Xi] + 1 ntest ∑ ℓ∈I(1) test,j ̂m(Xℓ; ¯t) − g−1 f,ρ(1 − α) ))}]1/2 ≤ E [ exp { 2η( ∑ i∈I(1) tr ( ̃w(Xi)E[Zi | Xi] + 1 ntest ∑ ℓ∈I(1) test,j ̂m(Xℓ; ¯t) − F (¯t) − ∆))}]1/2 . By definition, F (¯t) = PQX ×PY | X (s(X, Y ) ≤ ¯t) = EPX,Y [w(X)Z] + EQX [ ̂m(X; ¯t)]. Therefore, ∣ ∣F (¯t) − EPX,Y [ ̃w(X)Z] − EQX [ ̂m(X; ¯t)] ∣ ∣ ≤ ∣ ∣ ∣ ∣EPX,Y [(w(X) − ̃w(X)) · (1{s(X, Y ) ≤ ¯t} − ̂m(X; ¯t) )]∣ ∣ ∣ ∣ ≤ ∥ ∥w(X) − ̃w(X)∥ ∥ L2(P ) · ∥ ∥1{s(X, Y ) ≤ ¯t} − ̂m(X; ¯t)∥ ∥ L2(P ) = EstErr(¯t). (13) The last inequality follows from the Cauchy-Schwarz inequality. Next, we focus on the following quantity: E [ exp {2η( ∑ i∈I(1) tr ( ̃w(Xi)E[Zi | Xi] − EPX,Y [ ̃w(X)Z] ) + ntr ntest ∑ i∈I(1) test,j ( ̂m(Xi; ¯t) − EQX [ ̂m(X; ¯t)] )))}] = E [ exp {2η ∑ i∈I(1) tr ( ̃w(Xi)E[Zi | Xi] − EPX,Y [ ̃w(X)Z])}] + E [ exp { 2η · ntr ntest ∑ i∈I(1) test,j ( ̂m(Xi; ¯t) − EQX [ ̂m(X; ¯t)] )}] ≤ exp (2η2w2 maxntr + η2n2 tr 2ntest ), (14) where the second step uses the independence between Dtest and Dtr. Combining (8), (13) and (14) leads to (8) ≤ exp { − ηntr(∆ − EstErr(¯t)) + η2(w2 maxntr + n2 tr 4ntest )}. Putting everything together, we conclude that P(̂p(q∗(∆) − ε) ≥ g−1 f,ρ(1 − α) ) ≤ exp { − ηntr(∆ − EstErr(¯t)) + η2( 17w2 maxntr 8 + n2 tr 4ntest )}. (15) We choose η to minimize the upper bound above and get η = ∆ − EstErr(¯t) 17w2 max 4 + ntr 2ntest , and correspondingly, (15) ≤ exp { − (∆ − EstErr(¯t))2 9w2 max ntr + 1 ntest }. Recall that ¯t = q∗(∆) − ε. Since ∆ ≤ ¯∆, ¯t ≥ q∗( ¯∆) − ε. For ε sufficiently small, we further have q∗(∆) − ε > q∗( ¯∆) · κ. By the definition of ∆, we have EstErr(¯t) + √ log ( 1 δ ) · ( 9w2 max ntr + 1 ntest ) ≤ sup κ·q∗( ¯∆)≤t≤q∗(0) EstErr(t) + √ log ( 1 δ ) · ( 9w2 max ntr + 1 ntest ) = ∆. Consequently, we arrive at P (̂q ≤ q∗(∆) − ε) ≤ δ. Taking ε → 0 and by the continuity of the probability measure, we have that P (̂q < q∗(∆)) ≤ δ. 22 Step (II). Let A = {Sn+j ≤ q∗(∆)}. As in the proof of Theorem 1, we have that PQX,Y (Sn+j ≤ q∗(∆)) ≥ gf,ρ(PQX ×PY | X (Sn+j ≤ q∗(∆))) ≥ gf,ρ(g−1 f,ρ(1 − α) − ∆). On the event {̂q ≥ q∗(∆)}, PQX,Y (Sn+j ≤ ̂q | D(1) tr , D(1) test,j) ≥ PQX,Y (Sn+j ≤ q∗(∆)) ≥ gf,ρ(g−1 f,ρ(1 − α) − ∆) ≥ gf,ρ(g−1 f,ρ(1 − α)) − g′ f,ρ(g−1 f,ρ(1 − α))∆, where the last step follows from the convexity of gf,ρ and the separating hyperplane theorem. As proved in Theorem 1, when gf,ρ(1) ≥ 1 − α, gf,ρ(g−1 f,ρ(1 − α)) ≥ 1 − α and we complete the proof. Proof of Theorem 3 In this proof, we write ∆(δ) instead of ∆ to emphasize the dependence of ∆ on δ. By Theorem 5, we know that for any δ ∈ (0, 1), P (̂q < q∗(∆(δ) )) ≤ δ. In the following, we shall consider a sequence of δ ∈ {2 −ℓ}∞ ℓ=0. For each ℓ ∈ N, we let qℓ = q∗(∆(2−ℓ)). PQX ×PY | X (Sn+j ≤ ̂q) − g−1 f,ρ(1 − α) (16) = ∞∑ ℓ=0 E [ 1{qℓ+1 ≤ ̂q < qℓ} · (PQX ×PY | X (Sn+j ≤ ̂q ∣ ∣ D(k) tr , D(k) test,j) − g−1 f,ρ(1 − α))] + E [ 1{̂q ≥ q0} · (PQX ×PY | X (Sn+j ≤ ̂q ∣ ∣ D(k) tr , D(k) test,j) − g−1 f,ρ(1 − α))] ≥ ∞∑ ℓ=0 E [ 1{qℓ+1 ≤ ̂q < qℓ} · (F (qℓ+1) − g−1 f,ρ(1 − α) )] + E [1 {̂q ≥ q0} · (F (q0) − g−1 f,ρ(1 − α))] ≥ − ∞∑ ℓ=0 ∆(2−ℓ−1) · P (qℓ+1 ≤ ̂q < qℓ) − ∆(0) · P(̂q ≥ q0), where the last step is due to the definition of qℓ. Since for any ℓ ∈ N, P(̂q < q∗(∆(2−ℓ))) ≤ 2 −ℓ, we further have (16) ≥ − ∞∑ ℓ=0 ∆(2−ℓ)P(̂q < q∗(∆(2−ℓ−1) )) − ∆(0) ≥ − ∞∑ ℓ=0 2−ℓ−1∆(2−ℓ−1) − ∆(0) ≥ sup κq∗ ¯∆≤t≤q∗(0) 2 · EstErr(t) + √ 16w2 max ntr + 2 ntest . We now return to the coverage under QX,Y . Again using the step in the proof of Theorem 1, we have PQX,Y (Sn+j ≤ ̂q) ≥ gf,ρ(PQX ×PY | X (Sn+j ≤ ̂q) ) ≥ gf,ρ (g−1 f,ρ − sup κq∗ ¯∆≤t≤q∗(0) 2 · EstErr(t) − √ 16w2 max ntr + 2 ntest ) ≥ gf,ρ(g−1 f,ρ(1 − α) ) − g′ f,ρ(g−1 f,ρ(1 − α)) · ( sup κq∗ ¯∆≤t≤q∗(0) 2 · EstErr(t) + √ 16w2 max ntr + 2 ntest ) When gf,ρ(1) ≥ 1 − α, gf,ρ(g−1 f,ρ(1 − α)) ≥ 1 − α. The proof is thus completed. B.4 Proof of theorem 4 Throughout, we condition on ̂ρ and D(1−k) tr ∪ D(1−k) test . Fix k ∈ {0, 1} and {n + j} ∈ I (k) test. Define A = {Yn+j ∈ ̂Cf,̂ρ,n+j(Xn+j)} . By the proof of Theorem 1, we have that P(Xn+j ,Yn+j )∼QXY (A) ≥ gf,ρ∗ (P(Xn+j ,Yn+j )∼QX ×PY | X (A) ). 23 Next, by the intermediate steps in the proof of Theorem 2, there is P(Xn+j ,Yn+j )∼QX ×PY | X (A) ≥ P(Xn+j ,Yn+j )∼ ˜QX ×PY | X (A) − 1 2 EX∼PX [∣ ∣ ∣ ̂w(k)(X) EX∼PX [ ̂w(k)(X)] − w(X)∣ ∣ ∣] ≥ g−1 f,̂ρ(1 − α) − 1 2 EX∼PX [∣ ∣ ∣ ̂w(k)(X) EX∼PX [ ̂w(k)(X)] − w(X) ∣ ∣ ∣] . Combining the above inequalities and since the monotonicity of gf,ρ∗ (β) in β, we have P(Xn+j ,Yn+j )∼QXY (Yn+j ∈ ̂Cf,̂ρ,n+j(Xn+j) ) ≥ gf,ρ∗ ( g−1 f,̂ρ(1 − α) − 1 2 EX∼PX [∣ ∣ ∣ ̂w(k)(X) EPX [ ̂w(k)(X)] − w(X) ∣ ∣ ∣]) ≥ gf,ρ∗ (g−1 f,̂ρ(1 − α)) − 1 2 g′ f,ρ∗ (g−1 f,̂ρ(1 − α)) · EX∼PX [∣ ∣ ∣ ̂w(k)(X) EPX [ ̂w(k)(X)] − w(X)∣ ∣ ∣ ] . When ̂ρ ≥ ρ∗, gf,ρ∗ (g−1 f,̂ρ(1 − α)) ≥ gf,̂ρ(g−1 f,̂ρ(1 − α)). The latter is greater or equal to 1 − α when gf,̂ρ(1) ≥ 1 − α, following the proof of Theorem 1. The proof is therefore completed. C Additional results of sensitivity analysis under the f sensitivity model This section collects additional results of adapting our method to the sensitivity analysis of ITE under the f -sensitivity model. Suppose that the inferential target is Y (t1) for t1 ∈ {0, 1}; and the target population is T = t2, where t2 ∈ {0, 1, ◦}, with ◦ denoting the whole population. The prediction interval ̂Cf,ρ(Xn+1) should satisfy P (Yn+1(t1) ∈ ̂Cf,ρ(Xn+1) ∣ ∣ T = t2) ≥ 1 − α. Given a set of training data Dtr = {(Xi, Ti, Yi)}n i=1, we start as before by randomly splitting the data into two folds D(0) tr and D(1) tr . The first fold D(0) tr is used for fitting the propensity score function ̂e(x) (if unknown); we also use the unit in D(0) tr such that T = t1 to fit a function ̂µ (t1) for predicting Y (t1). The form of the covariate shift weight function w(t1,t2)(x) is listed in Table 1. Next, for any j ∈ [m], the prediction interval is constructed as ̂C (t1,t2) f,ρ,n+j(x) = {y ∈ R : s(x, y) ≤ Quantile(g−1 f,ρ(1 − α), ∑ i∈D(1) tr ,Ti=t2 p (t1,t2) i (x) · δSi + p(t1,t2) n+1 (x) · δ∞)}, where p (t1,t2) i (x) = ̂w(t1,t2)(Xi) ∑ j∈D(1) tr ,Tj =t2 ̂w(t1,t2)(Xj) + ̂w(t1,t2)(x) , p (t1,t2) n+1 (x) = ̂w(t1,t2)(x) ∑ j∈D(1) tr ,Tj =t2 ̂w(t1,t2)(Xj) + ̂w(t1,t2)(x) . (17) Above, ̂w(t1,t2) is the estimator for w(t1,t2). The complete procedure can be found in Algorithm 3. t1 t2 1 0 ◦ 1 1 1−e(x) e(x) · p1 p0 p1 e(x) 0 e(x) 1−e(x) · p0 p1 1 p0 1−e(x) Table 1: The form of the covariate shift function w(t1,t2)(x). The function e(x) = P(T = 1 | X = x) is the observed propensity score function, p1 = P(T = 1), and p0 = P(T = 0). 24 Algorithm 3: Conformalized counterfactual inference under the f -sensitivity model Input: Training set Dtr = {(Xi, Ti, Yi)} n i=1; test data {Xn+j}m j=1; counterfactual type t1 ∈ {0, 1}, target population t2 ∈ {0, 1, ◦}; outcome fitting algorithm A; propensity score fitting algorithm E; target miscoverage level α ∈ (0, 1); score function s(x, y; µ); sensitivity parameter ρ. Randomly split Dtr into two subsets of equal sizes D(0) tr and D(1) tr , indexed by I (0) tr and I (1) tr ; Apply A to obtain the outcome regression functions: ̂µ (t1) ← A ({(Xi, Yi) : i ∈ I (0) tr , Ti = t1} ); Apply E to obtain the estimated propensity score function: ̂e ← E(D(0) tr ); Compute the nonconformity scores: Si = s(Xi, Yi; ̂µ (t1)) for i ∈ I (1) tr such that Ti = t1; for ℓ ∈ Itest do Construct ̂C (t1,t2) f,ρ,ℓ (Xℓ) according to (17); end Output: Prediction sets { ̂C (t1,t2) f,ρ,n+j(Xn+j)}j∈[m]. 25","libVersion":"0.3.2","langs":""}