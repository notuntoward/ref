{"path":"lit/lit_sources.backup/McNultyThreeMostCommon.pdf","text":"The Three Most Common Statistical Tests You Should Deeply Understand How to interpret the R/Python output Keith McNulty · Follow 9 min read · Aug 11, 2024 Hypothesis testing is one of the most fundamental elements of inferential statistics. In modern languages like Python and R, these tests are easy to conduct — often with a single line of code. But it never fails to puzzle me how few people use them or understand how they work. In this article I want to use an example to show three common hypothesis tests and how they work under the hood, as well as showing how to run them in R and Python and to understand the results. The general principles and process of hypothesis testing Hypothesis testing exists because it is almost never the case that we can observe an entire population when trying to make a conclusion or inference about it. Almost always, we are trying to make that inference on the basis of a sample of data from that population. Given that we only ever have a sample, we can never be 100% certain about the inference we want to make. We can be 90%, 95%, 99%, 99.999% certain, but never 100%. 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 1/13 Hypothesis testing is essentially about calculating how certain we can be about an inference based on our sample. The most common process for calculating this has several steps: 1. Assume the inference is not true on the population — this is called the null hypothesis 2. Calculate the statistic of the inference on the sample 3. Understand the expected distribution of the sampling error around that statistic 4. Use that distribution to understand the maximum likelihood of your sample statistic being consistent with the null hypothesis 5. Use a chosen ‘likelihood cutoff’ — known as alpha — to make a binary decision on whether to accept the null hypothesis or reject it. The most commonly used value of alpha is 0.05. That is, we usually reject a null hypothesis if it renders the maximum likelihood of our sample statistic to be less than 1 in 20. The salespeople data set To illustrate some common hypothesis tests in this article I will use the salespeople dataset which can be obtained here. Let’s download it in R and take a quick look at the first few rows. url <- \"http:://peopleanalytics-regression-book.org/data/salespeople.csv\" salespeople <- read.csv(url)head(salespeople) ## promoted sales customer_rate performance ## 1 0 594 3.94 2 ## 2 0 446 4.06 3 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 2/13 ## 3 1 674 3.83 4 ## 4 0 525 3.62 2 ## 5 1 657 4.40 3 ## 6 1 918 4.54 2 We see four columns of data: 1. promoted — a binary value indicating if the salesperson was promoted or not in the recent promotion round 2. sales — the recent sales made by the salesperson in thousands of dollars 3. customer_rate — the recent average rating by customers of the salesperson on a scale of 1 to 5 4. performance — the most recent performance rating of the salesperson where a rating of 1 is the lowest and 4 is the highest. Example 1 — Welch’s t-test Welch’s t-test is a hypothesis test for determining if two populations have different means. There are a number of varieties of this test, but we will look at the two sample version and we will ask if high performing salespeople generate higher sales than low performing salespeople in the population. We start by assuming our null hypothesis which is that the difference in mean sales between high performers and low performers in the population is zero or less. Now we calculate our difference in means statistic for our sample. library(dplyr) # data for high performers high_sales <- salespeople |> 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 3/13 filter(performance == 4) |> pull(sales) # data for low performers low_sales <- salespeople |> filter(performance == 1) |> pull(sales) # difference (mean_diff <- mean(high_sales) - mean(low_sales)) ## [1] 154.9742 So we see that in our sample, high performers generate around $155k more in sales than low performers. Now, we are assuming that sales is a random variable — that is, that the sales of one salesperson is independent of another. Therefore we expect the difference in mean sales between the two groups to also be a random variable. So we expect the true population difference to be on a t-distribution centered around our sample statistic, which is an estimate of a normal distribution based on our sample. To get the precise t-distribution, we need the degrees of freedom — which can be determined based on the Welch- Satterthwaite equation (100.98 in this case). We also need to know the standard deviation of the mean difference, which we call the standard error which we can calculate to be 33.48. See here for more details on these calculations. Knowing these parameters, we can create a graph of the t-distribution around our sample statistic. 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 4/13 t-distribution around sample statistic (Author generated) We can now see the expected probability distribution for our true population statistic. We can also mark the maximum position on this distribution that represents a difference of zero or less — which is our null hypothesis statement. By taking the area under this distribution to the left of the red line, we calculate the maximum probability of this sample statistic occurring if the null hypothesis were true. Usually this is calculated by working out the number of standard errors that are needed to get to the red line — known as the t-statistic. In this case it would be # standard error se <- 33.48 t_statistic <- (0 - mean_diff)/se round(t_statistic, 2) 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 5/13 ## [1] -4.63 So our red line is 4.63 standard errors away from the sample statistic. We can use some built-in functions in R to calculate the associated area under the curve for this t-statistic on a t-distribution with 100.98 degrees of freedom. This represents the maximum probability of our sample statistic occurring under the null hypothesis, and is known as the p-value of the hypothesis test. p_value <- pt(-4.63, 100.98) round(p_value, 6) ## [1] 5e-06 So we determine that the maximum probability of our sample statistic occurring under the null hypothesis is 0.000005 — much less than even a very stringent alpha. In most cases this would be considered too unlikely to accept the null hypothesis and we will reject it in favour of the alternative hypothesis — that high performing salespeople generate higher sales than low performing salespeople. To run this two sample t-test in R, you use the t.test function with an alternative hypothesis of \"greater\" . In the output below you’ll see the various statistics that we discussed above. t.test(high_sales,low_sales, alternative = \"greater\") ## Welch Two Sample t-test ## 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 6/13 ## data: high_sales and low_sales ## t = 4.6295, df = 100.98, p-value = 5.466e-06 ## alternative hypothesis: true difference in means is greater than ## 0 ## 95 percent confidence interval: ## 99.40204 Inf ## sample estimates: ## mean of x mean of y ## 619.8909 464.9167 To run this two sample t-test in Python you can use scipy.stats version 1.6.0 or later. import pandas as pd from scipy import stats # get data url = \"http://peopleanalytics-regression-book.org/data/salespeople.csv\" salespeople = pd.read_csv(url) # get sales for top and bottom performers perf1 = salespeople[salespeople.performance == 1].sales perf4 = salespeople[salespeople.performance == 4].sales # welch's independent t-test with unequal variance ttest = stats.ttest_ind(perf4, perf1, equal_var=False, alternative = \"greater\") print(ttest) ## Ttest_indResult(statistic=4.629477606844271, pvalue=5.466221730788519e-06) Example 2 — Correlation test Another common hypothesis test is a test that two numeric variables have a non-zero correlation. 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 7/13 Let’s ask if there is a non-zero correlation between sales and customer_rate in our salespeople data set. As usual we assume the null hypothesis — that there is a zero correlation between these variables. We then calculate the sample correlation: (sample_cor <- cor( salespeople$sales, salespeople$customer_rate, use = \"pairwise.complete.obs\" )) ## [1] 0.337805 Again, we expect the true population correlation to lie in a distribution around this sample statistic. A simple correlation like this is expected to observe a t-distribution with n-2 degrees of freedom (348 in this case) and the standard error is approximately 0.05. As before we can graph this and position our null hypothesis red line: 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 8/13 t-distribution for correlation between sales and customer ratings (Author generated) We see that the red line lies more than 6 standard errors away from the observed statistic and we can this calculate the p-value, which we again expect to be extremely small. Thus we can again reject the null hypothesis. To run this in R: cor.test( salespeople$sales, salespeople$customer_rate, use = \"pairwise.complete.obs\" ) ## Pearson's product-moment correlation ## data: salespeople$sales and salespeople$customer_rate ## t = 6.6952, df = 348, p-value = 8.648e-11 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.2415282 0.4274964 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 9/13 ## sample estimates: ## cor ## 0.337805 To run this in Python: import numpy as np # calculate correlation and p-value sales = salespeople.sales[~np.isnan(salespeople.sales)] cust_rate = salespeople.customer_rate[~np.isnan(salespeople.customer_rate)] cor = stats.pearsonr(sales, cust_rate) print(cor) ## (0.33780504485867796, 8.647952212091035e-11) Example 3 — Chi-square test of difference in proportion Unlike the previous two examples, data scientists often have to deal with categorical variables. A common question is whether there is a difference in proportion across different categories of a such a variable. A chi-square test is a hypothesis test designed for this purpose. Let’s ask the question: is there a difference in the proportion of salespeople who are promoted between the different performance categories? Again, we assume the null hypothesis, that the proportion of salespeople who are promoted is the same across all the performance categories. Let’s look at the proportion of salespeople who were promoted in each performance category by creating a contingency table or cross table for performance and promotion . 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 10/13 (contingency <- table(salespeople$promoted, salespeople$performance)) ## 1 2 3 4 ## 0 50 85 77 25 ## 1 10 25 48 30 Now let’s assume that there was perfect equality across the categories. We do this by calculating the overall proportion of promoted salespeople and then applying this proportion to the number of salespeople in each category. This would give us the following expected theoretical contingency table: ## 1 2 3 4 ## 0 40.62857 74.48571 84.64286 37.24286 ## 1 19.37143 35.51429 40.35714 17.75714 We then use this formula on each entry of the observed and expected contingency tables and sum up the results to form a statistic known as the chi-square statistic. In this case the chi-square statistic is calculated to be 25.895. 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 11/13 As with our t-statistic earlier, the chi-square statistic has an expected distribution which is dependent on the degrees of freedom. The degrees of freedom are calculated by subtracting one from the number of rows and the number of columns of the contingency table and multiplying them together — in this case the degrees of freedom is 3. So, as before, we can graph our chi-square distribution with 3 degrees of freedom, mark where our chi-square statistic falls in that distribution and calculate the area under the distribution curve to the right of that point to find the associated p-value. Chi-square distribution with df = 3 (Author generated) Again, we can see that this area is extremely small indicating that we are likely to reject the null hypothesis and confirm the alternative hypothesis that there is a difference in promotion rates between promotion categories. 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 12/13 To run this in R after calculating your contingency table: chisq.test(contingency) ## Pearson's Chi-squared test ## ## data: contingency ## X-squared = 25.895, df = 3, p-value = 1.003e-05 To run this in Python — the first three entries in the result represent the chi- square statistic, the p-value and the degrees of freedom respectively: # create contingency table for promoted versus performance contingency = pd.crosstab(salespeople.promoted, salespeople.performance) # perform chi-square test chi2_test = stats.chi2_contingency(contingency) print(chi2_test) ## (25.895405268094862, 1.0030629464566802e-05, 3, array([[40.62857143, 74.48571 ## [19.37142857, 35.51428571, 40.35714286, 17.75714286]])) I hope that you found these explanations and demonstrations useful. If you are interested in diving deeper into some of the underlying method and calculations of these tests, or to learn about other hypothesis tests, please visit my recent Handbook of Regression Modeling, where Chapter 3 focuses on foundational statistics. 10/22/24, 9:46 AM The Three Most Common Statistical Tests You Should Deeply Understand | by Keith McNulty | Medium chrome-extension://mpiodijhokgodhhofbcjdecpffjipkle/src/ui/pages/editor.html 13/13","libVersion":"0.3.2","langs":""}