{"path":"lit/lit_sources.backup/Owen23howPredictableLLMperf.pdf","text":"4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 1/16 Articles Paper How Predictable Is Language Model Benchmark Performance? We investigate large language model performance across five orders of magnitude of compute scaling, finding that compute-focused extrapolations are a promising way to forecast AI capabilities.How Predictable Is Language Model Benchmark Performance? 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 2/16 Published Jun 09, 2023 Last updated Jan 11, 2024 Authors David Owen 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 3/16 Resources Paper Cite Contents Executive summary Executive summary Background Results We investigate large language model performance across five orders of magnitude of compute scaling in 11 recent model architectures at 36 different model sizes. We present data on performance in BIG-Bench and MMLU, covering a range of model sizes and architectures. We examine trends in performance, showing a fairly smooth relationship between overall performance and scale, consistent with an S-curve. We outline an approach for predicting benchmark performance based on compute scaling. We back-test predictability of aggregate benchmark performance using this approach, showing that performance is moderately predictable from compute scaling. • • • • • 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 4/16 Background Scaling laws allow prediction of a model’s loss from model and dataset sizes. However, scaling does not directly predict a model’s performance on downstream tasks - as assessed through benchmarks. To bridge this gap, we build on pre-existing methods and fit model performance against scaling laws. We then use back-testing to evaluate how well these fits can predict benchmark performance. First, we use scaling laws to map models to loss according to model size, N, and dataset size, D. Loss can equivalently be expressed in terms of scaled compute - the compute required to achieve this loss under optimal scaling of N and D. This allows every model in our dataset to be associated with its scaled compute, as shown in Figure 1. We show that individual benchmark tasks are less predictable, but remain more predictable than chance or a simple per-task average baseline. We conclude that compute-based extrapolations are a promising way to forecast AI capabilities. • • Estimated loss values, parameter count and dataset sizes EPOCH Dataset size (tokens) 10 26 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 5/16 Figure 1: Different estimated loss values against model and training set sizes, for all models considered in this report. Loss is also expressed in terms of optimally scaled compute. Subsequently, we fit curves relating benchmark performance to loss. This leads to fits like those in Figure 2, predicting performance from loss (expressed as scaled compute). We favor simple forms with few parameters throughout this work, as we typically have small datasets on the order of tens of datapoints per task. To evaluate predictability, we perform back-tests: we hold out points to the right of the loss-performance curves when fitting, and then assess error in the predictions. We investigate fits for aggregate benchmark performance and individual benchmark tasks. PaLM-2PaLM-2PaLM-2 PaLMPaLMPaLM GPT-3GPT-3GPT-3 Falcon-7BFalcon-7BFalcon-7B BIG-G (17M)BIG-G (17M)BIG-G (17M) 1012 10 18 10 20 10 22 10 24 10Reducible loss (scaled FLOP) 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 6/16 Figure 2: Aggregate benchmark performance for BIG-Bench Hard and MMLU is fairly predictable from compute scaling. Sigmoid fits are shown in black for both plots, with bold lines showing data used for fitting and dashed lines showing extrapolation. Results BIG-Bench Hard performance vs scale EPOCH Performance (%) Fitted Held-out 30 40 50 60 70 80 PaLM-2 PaLM GPT-3 Yi-6B Scaled Compute (FLOP) 1020 1022 1024 1026 MMLU performance vs scale EPOCH Performance (%) Fitted Held-out 20 40 60 80 100 PaLM-2 PaLM GPT-3 GPT-4 Yi-6B Scaled Compute (FLOP) 1020 1022 1024 1026 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 7/16 Aggregate benchmark performance is fairly predictable from scaling, as shown in Figure 2. Using a sigmoid fit to predict across an OOM of scaling, mean absolute error is 6 percentage points (pp). Prediction requires some pre-existing progress: steep increases in performance make it difficult to predict far ahead using only data from low-performing models. Error gradually increases as one extrapolates further ahead, as shown in Figure 3. If current trends persist, our extrapolation suggests BIG-Bench could exceed human-level performance (80%) around 6e25 FLOP scaled compute, with ~90% chance of reaching this level by 5e26 FLOP. Absolute error of BIG-Bench Hard fits EPOCH Error (pp) Sigmoid Sigmoid Off. Clip Linear Offset 50 Absolute error of BIG-Bench per- task fits EPOCH Error (pp) Sigmoid Sigmoid Off. Clip Linear Offset EPOCH Menu 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 8/16 Figure 3: Absolute error versus how far ahead performance is extrapolated, for different fits. Errors are evaluated over the entire series of held out points, bars show 90% confidence intervals. Individual tasks are highly variable in their scaling, and the sharp emergence of capabilities can make it difficult to predict performance. Figure 4 shows qualitative examples - ranging from well- predicted tasks to those where scaling clearly deviates from a sigmoid. Nevertheless, performance on individual benchmark tasks is significantly more predictable than chance or a simple baseline, as shown in Figure 3. The distribution of errors across tasks is fat-tailed: over half of tasks can be predicted with less than 10% error, but some tasks have substantially higher error, particularly tasks using multiple choice as their preferred metric (discussed in more detail within the full report). Figure 4 also illustrates why previous analyses that examined a small number of models found performance was unpredictable from scaling, whereas a larger data series shows significant (but imperfect) predictability. 40 50 40 Decent extrapolation EPOCH Performance (NPM) Fitted Held-out Lower quality extrapolation EPOCH Performance (NPM) Fitted Held-out 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 9/16 0 25 50 75 0 25 50 75 Poor extrapolation EPOCH Performance (NPM) Fitted Held-out 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 10/16 Figure 4: There is a lot of variation in per-task fit quality. Example data and back-tested model fits for three BIG-Bench tasks showing performance versus loss (scaled compute). In conclusion, our results show that language benchmarks are fairly predictable from scaling, although prediction requires some pre-existing progress: steep increases in performance make it difficult to predict far ahead using only data from poorly-performing models. Furthermore, aggregate benchmarks are more predictable than individual tasks - for example comparing BIG-Bench Hard and individual BIG- Bench tasks. This supports the idea that higher-level model capabilities are predictable with scale, and gives support to a scaling-focused view of AI development. We hope that methods of this sort may eventually provide useful forecasts for guiding research and policy. Updates 50 75 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 11/16 About the authors David Owen is a researcher with a background in computer vision and machine learning. He is interested in analysing and predicting model capabilities, and using empirical data to explore AI deployment in the real world. Before joining Epoch, David worked in an industrial research lab developing AI models for surgical video. Share Twitter LinkedIn Tags Performance and benchmarks Scaling laws Related posts 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 12/16 REPORT · 6 MI N READ Scaling Laws Literature Review I have collected a database of scaling laws for different tasks and architectures, and reviewed dozens of papers in the scaling law literature. Jan 26, 2023 · By Pablo Villalobos 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 13/16 REPORT · 27 MI N READ Trading Off Compute in Training and Inference Some techniques allow to increase the performance of machine learning models at the cost of more expensive inference, or reduce inference compute at the cost of lower performance. This possibility induces a tradeoff between spending more resources on training or on inference. We explore the characteristics of this tradeoff and outline some implications for AI governance. Jul 28, 2023 · By Pablo Villalobos and David Atkinson 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 14/16 REPORT · 10 MI N READ The Direct Approach Empirical scaling laws can help predict the cross-entropy loss associated with training inputs, such as compute and data. However, in order to predict when AI will achieve some subjective level of performance, it is necessary to devise a way of interpreting the cross-entropy loss of a model. This blog post provides a discussion of one such theoretical method, which we call the Direct Approach. Apr 25, 2023 · By Matthew Barnett and Tamay Besiroglu 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 15/16 Excited about our work? Talk to us Support our research EPOCH Sign up for our newsletter to receive the latest updates on our research. RESEARCH Blog Publications Machine Learning Trends Visualization ORGANIZATION About Epoch Careers Support us Contact us Privacy NoticeYour email 4/11/24, 8:07 PM How Predictable Is Language Model Benchmark Performance? – Epoch https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance 16/16 Epoch is fiscally sponsored by .\u0000 2024 Rethink PrioritiesRethink Priorities","libVersion":"0.3.2","langs":""}