{"path":"lit/lit_notes_OLD_PARTIAL/Brusaferri24OnlineConformalizedNeural.pdf","text":"On-line conformalized neural networks ensembles for probabilistic forecasting of day-ahead electricity prices Alessandro Brusaferria,∗, Andrea Ballarino a, Luigi Grossi b, Fabrizio Laurinic aCNR, Institute of Intelligent Industrial Technologies and Systems for Advanced Manufacturing, via A. Corti 12, Milan, Italy bUniversity of Parma, Department of Industrial Engineering, Viale delle Scienze, Parma, Italy cUniversity of Parma, Department of Economics and Management, Via J.F. Kennedy 6, Parma, Italy Abstract Probabilistic electricity price forecasting (PEPF) is subject of increasing inter- est, following the demand for proper quantification of prediction uncertainty, to support the operation in complex power markets with increasing share of renew- able generation. Distributional neural networks ensembles have been recently shown to outperform state of the art PEPF benchmarks. Still, they require critical reliability enhancements, as fail to pass the coverage tests at various steps on the prediction horizon. In this work, we propose a novel approach to PEPF, extending the state of the art neural networks ensembles based meth- ods through conformal inference based techniques, deployed within an on-line recalibration procedure. Experiments have been conducted on multiple market regions, achieving day-ahead forecasts with improved hourly coverage and stable probabilistic scores. Keywords: Probabilistic Forecasting, Electricity price, Day-ahead market, Neural Networks, Ensembles, Conformal Prediction, Time series ∗Corresponding author Email address: alessandro.brusaferri@stiima.cnr.it (Alessandro Brusaferri)arXiv:2404.02722v2 [cs.LG] 10 Jun 2024 1. Introduction Trustworthy electricity price forecasting (EPF) systems represent fundamen- tal strategic tools for utilities, retailers, aggregators, and large consumers to achieve effective participation in liberalized energy markets. Beside being ex- ploited to anticipate price movements and perform bidding strategies, EPF is a key enabler of further crucial decision-making stages [1], such as optimal gener- ation and asset management [2] and energy-aware planning and scheduling [3]. In particular, hourly day-ahead EPF - i.e., the prediction of the hourly prices for the next day - is a challenging task subject of continuous interest in both academia and industry [4]. Compared to other traded commodities, electricity is still not economically storable on a large scale; thus, a constant balance be- tween demand and supply is essential to achieve overall system stability. Hence, the price profiles in liberalized power markets often exhibit quite peculiar char- acteristics [5]. Complex relationships with conditioning variables (such as load demand, fuel costs, electricity production and weather conditions) are typically involved, encompassing meshed short and long-term seasonalities, as well as considerable volatility, usually orders of magnitude larger than in other utility trading contexts [6], [7], [8], [9]. Critical deviations have been injected by the repercussions of the steep gas price variations on the power plants. The increasing penetration of renewable sources in the generation mix, fundamental to contrast the global warming, is introducing further short-term price fluctuations to be promptly tackled. Ad- ditional variables such as the CO2 certificate prices interact with the power price features [10]. Additional complex market dynamics arise from the increas- ing competition among a growing number of highly active participants, each pursuing innovative business models [11],[12]. Overall, forecasting is becoming harder to perform than ever before, and advances in this field are strongly requested to cope with such an evolving context [4], [13]. Undoubtedly, the EPF research community is devoting considerable effort to 2 addressing these key challenges, which is evident from the substantial amount of scientific studies developed in the literature, as detailed in the following sub- section. 1.1. Literature review Over the years, a broad set of approaches have been investigated to perform EPF. A non-exhaustive list includes auto-regressive models and related exten- sions, exponential smoothing, generalized additive models, Gaussian Process, gradient boosting, neural networks, support vector machines, random forest, fuzzy logic, wavelet ensembles, and hybrid models. More detailed descriptions and comparisons of these techniques can be found in [14], [15],[1], and refer- ences therein. According to the aforementioned reviews, the EPF literature was primarily dedicated to simple statistical models and small neural network architectures until the early 2010s, mainly due to computational constraints of the technologies available. Besides, they proved effective in addressing the more stable price series occurring during that period [16]. Following the demand for more enhanced modeling capabilities to properly tackle modern energy market dynamics, the EPF community has been investi- gated more flexible but computationally intensive machine learning approaches [17], [12], [18], [19]. Within this rapidly developing and fascinating field of research, much in- terest is being devoted to modern neural network architectures [20],[21]. Such research momentum is mainly propelled by the significant results achieved across a broad set of computer science applications, including natural language pro- cessing [22] and computer vision [23]. Several research studies have contributed to the exploration and development of neural networks (NN) in the EPF field (see e.g., [4], [24], [25] for recent reviews). To date, the most comprehensive experimental investigation of NN based approaches to EPF is provided by [26], including feed-forward, recurrent and convolutional models, as well as several more traditional statistical techniques (such as ARX, ARIMA-GARCH, etc.), primarily adopted in the literature. When tested on the EPEX (Belgium day- 3 ahead market benchmark), a deep feed-forward architecture (labeled DNN here- after) achieved the highest predictive accuracy, outperforming both the tradi- tional methods and the best recurrent neural networks with LSTM and GRU cells 1. Building upon the previous works, in [4] and [27] the authors have con- ducted a comparison betwee the DNN architecture and the recently proposed LASSO Estimated AutoRegressive model, which is arguably the most accurate approach within the broader statistical family. By deploying an extensive au- tomatic hyperparameter optimization and evaluating a set of benchmark EPF tasks covering five different day-ahead markets, they confirmed the performance gains provided by the more flexible DNN. Indeed, the latter paper has been en- titled “the dawn of machine learning” for EPF. Following these results, several NN-based techniques have been explored in recent years with the aim of reduc- ing prediction error (see e.g., [28] and references therein). In economic terms, even single percentage gains can lead to annual savings of up to millions of dollars for companies [13]. Although most of the available studies address point predictions (e.g., mean or median values) of day-ahead hourly prices, an increasing research momentum targets NN-based probabilistic EPF (PEPF). Specifically, PEPF is aimed to characterize the underlying uncertainty of the model in the target space, e.g., via prediction intervals, quantiles or full predictive distributions. This is essential for companies operating within power markets showing increasing volatility, e.g., to support extremely relevant business tasks, such as effective risk optimization, stochastic optimization and what-if scenario analysis before trading. Several recent studies investigate this topic from different perspectives, reporting both additional problems and opportunities insisting on the EPF approach (see e.g., [29], [30], [31], [32] and references therein for details). An thorough empirical comparison of deep learning architectures for multivariate probabilistic energy forecasting is performed in [24], including DeepAR, DeepTCN, DSANet and 1LSTM: Long short-term memory, GRU: Gated recurrent unit 4 LSTNet models. According to several research works (see e.g., [1],[33], [34] and references therein), Quantile Regression Average (QRA) represents the reference bench- mark to turn point NNs into a PEPF setup, following the ranking in the GEF- Com competition 2. Distributional NNs [24] and Bayesian Deep learning [25] techniques have been proposed approximating the conditional distribution of the hourly prices given the input features, through parametric forms. The Gaussian distribution is commonly employed for this purpose. However, it has been observed that the prices tend to exhibit complex patterns, including heterosckedasticity, sig- nificant skewness and fat tails [33] and [36]. Deep quantile regression (DQR) based methods have been introduced to support non-parametric uncertainty characterization (see e.g., [37] and references therein). Despite their asymp- totic properties, they inherit potential quantile overfitting and overconfidence on the extreme quantiles in finite samples. Hence, Ensembles of distributional NNs (i.e., Deep Ensembles) parameterizing flexible Johnson’s SU distributions have been recently proposed for this purpose, outperforming the state of the art PEPF benchmarks including both conventional Gaussian forms and the widely applied quantile regression on NN ensembles [33]. Despite the relevant im- provements, it has been observed that such models lack the required calibration capabilities - i.e., the statistical consistency between the probabilistic forecasts and the observations - failing to pass the coverage tests at various hours on the prediction horizon. Conformal Prediction (CP) provides a principled framework to attain distribution- free finite sample marginal calibration guarantees. Pioneered in the early 2000s, 2The Global Energy Forecasting Competition (GEFCom) began in August 2014, with a specific emphasis on probabilistic energy forecasting, including load, price, wind, and solar predictions. The price category drew interest from 287 participants globally, with the top- performing teams subsequently invited to contribute papers to a special 2016 edition of the International Journal of Forecasting [35] 5 CP has recently become subject of a renewed research interest within the sta- tistical and machine learning communities (see e.g., [38] and reference therein for a detailed review). However, CP has so far attracted minor attention in the EPF field. To date, only two papers have investigated CP-based approaches for this purpose. A first empirical study has been performed by [34] where the con- ventional split CP is compared to a normalized absolute deviation on LASSO, KNN, SVM models, achieving promising results. Later, [39] implemented an adaptive conformal inference procedure on Random Forest based point predic- tors. As this presents a relatively novel and still understudied research direction, further extensions are expected from the community in the near future. By looking beyond the EPF literature, last developments in the Conformal Prediction research domain provides a lot of compelling ideas to be further ex- plored for achieving sharp and calibrated probabilistic forecasts (see e.g., [40] and references therein). To the best of our knowledge, the state-of-the-art neu- ral network-based approaches for PEPF have not yet been compared with CP extensions to assess potential probabilistic performance gains. 1.2. Contributions and organization of the paper Leveraging the available state of the art and moving from reported open issues, the major scope of the present work is to contribute to the further in- vestigation of the CP framework within the PEPF field. Specifically, we target the approximation of the feature conditioned day- ahead prices distribution through a discrete set of quantiles (e.g., deciles), cou- pled in prediction intervals (PIs) of increasing coverage degree around the me- dian. Then, we propose a novel approach to PEPF, extending the Deep Ensembles based methods through conformal inference based techniques deployed within an on-line recalibration procedure. The developed method consists of the fol- lowing major ingredients. First of all, we leverage the asymmetric CP formu- lation introduced by [41] for regression tasks, here developed through a daily recalibrated multi-horizon time series setup to support flexible step-wise com- 6 pensations of each upper/lower band. Overall, this enhance local PIs reliability (i.e., sample-wise efficiency) beyond the CP marginal coverage. Beside, we de- ploy the adversarial conformal inference setup proposed in [42] for uncertainty quantification under non-exchangeable conditions, such as distribution shifts. Hence, the target prediction bands over the different coverage levels are dy- namically adjusted by tracking the related quantiles of the conformity score sequences, incorporating the running sum of the miscoverage events to sup- port a stable long-run calibration. To estimate the quantiles to be calibrated, we explore both a DQR setup and samples from different parameterized dis- tributional NNs to assess their potential impact on both sample efficiency and reliability. A uniform vincentization technique is exploited for ensembles aggre- gation, leading to sharper bounds than the alternative probability aggregation, beside marginalizing the different local minimizers reached by the training al- gorithm. Moreover, a post-hoc sorting operator is included before combination to achieve conditional quantile non-crossing. We structured an open GitHub repository with the datasets and code to reproduce the experiments, as well as to support the integration and comparison of further datasets and PEPF techniques 3. The experiments are performed following the established best practice guide- lines stated in [4] for EPF research. As case studies, we focused on the German market dataset (i.e., the benchmark application in the original Distributional NN paper [33]), as well as the different regional bidding zones constituting the Italian day-ahead markets made available by [43], providing a compelling setup for testing under heterogeneous conditions. A comparison against state of the art benchmarks is performed, including QRA, DQR, Distributional NNs, as well as conventional absolute score and normalized score based CP settings. The rest of the paper is structured as follows. Section II deepens the devel- oped PEPF approach, while articulating the techniques in mathematical form. Section III provides a detailed description of the experimental setups and reports 3https://github.com/bruale/PefCodeBench 7 the results achieved. Section IV summarizes the conclusions and the envisioned future works. 2. Methods In this section, we deepen the developed PEPF approach. We start by providing a brief introduction to the general conformal inference framework. Then, we address the local adaptivity issue by deepening the conformalized quantile regression technique. Subsequently, we describe the methods deployed to address the lack of robustness of CP under non-exchangeable conditions. Finally, we detail the prediction quantiles estimation procedures, the network archiectures employed, as well the deep ensemble combination techniques. 2.1. Conformal Prediction Conformal Prediction (CP) provides a general framework to obtain pre- diction intervals C(Dn, α, xt) ≡ C(xt), at any test point t, from black-box models with marginal coverage guarantees under finite sample settings. For- mally, this is stated as: P(yt ∈ C(xt)) ≥ 1 − α, with α-error probability, given a dataset Dn ≡ {(xi, yi)} n i=1, yi ∈ R response variable and features vector xi = [xi(1), ..., xi(d)] involving continuous or discrete components. Moreover, CP is fully distribution-free, as opposed to distributional neural networks tech- niques (parameterizing e.g. Gaussian, Student’s t, mixtures, etc.), thus retain- ing validity for arbitrary latent distributions. Clearly, this is trivial without efficiency requirement (e.g., C(xt) = R ⇒ P(.) = 1). Hence, the goal is to achieve a sharp interval closed to the equality P(yt ∈ C(xt)) ≈ 1 − α. Figure 1: Empirical quantiles of the conformity scores 8 The core concepts behind CP are the conformity scores, which are exploited to assess the degree of ”conformity” (thus the name of the approach) of the trained model prediction with reference to an held-out calibration bag (i.e., split CP). For continuous target values, the absolute score S(xi, yi) = |yi − f (xi)| is conventionally employed, where f (xi) represents the model sample prediction. Then, by computing the empirical quantiles of the order statistic obtained by ranking the conformity scores (depicted in Figure 1), it is easy to show that for any t-th test sample: P(|yt − f (xt)| ≤ S(⌈(n+1)(1−α)⌉)) = P(yt ∈ f (xt) ± S(⌈(n+1)(1−α)⌉) ︸ ︷︷ ︸ C1−α(xt) ) = ⌈(n + 1)(1 − α)⌉ n (1) Besides, using a random tie-breaking rule (to avoid ties in the absolute residuals ranking), it has been shown that: P(yt ∈ C1−α(xt)) ≤ 1 − α + 1/(n + 1). Further details on CP and related proofs are reported in [38] and references therein. 2.2. Improved local adaptivity by conformalized quantiles As apparent from the Eq.1, the conventional CP based on absolute scores results in symmetric average bands around the NN predictions, thus lacking the capability to adapt the PIs width on simpler/harder test conditions (e.g., heteroscedasticity). Since full conditional coverage (i.e., P(yt ∈ C(xt)|xt = χ) ≥ 1 − α, for almost all χ) is not reachable in finite samples under weak distribution-free assumption, the goal is to obtain sample-wise efficiency (local PIs adaptivity) with proven marginal validity. To this end, two major classes of methods have been recently proposed in the CP literature, namely normalized conformal inference-based, and conformal- ized quantile regression (CQR)-based approaches (see e.g., [40] and references therein). The former typically rescales the CP scores depending on the condi- tional spread of the observations, e.g., by paramaterizing the target variance via dedicated network outputs as in distributional NNs. Still, this procedure leads to symmetric bounds around the point predictions despite the underlying 9 distribution shape. Furthermore, it has been observed to suffer from critical PI inflation and systematic underestimation issues [40]. In consideration of these results in the literature, we deploy a CQR-based approach in the PEPF framework. Specifically, to compute the scores and the conformalized quantiles, we leverage the asymmetric form introduced by [41], which can be easily adapted to the multi-horizon forecasting setup proposed in [44] as follows: Ch 1−α(xt) = [qh α/2(xt) − lh 1−α/2(Ict), qh 1−α/2(xt) + u h 1−α/2(Ict)] (2) where Ch 1−α(xt) represents (1-α)-level PI at prediction step h = [1, ..., H] given the input features. lh 1−α/2 and u h 1−α/2 depict the (1-α/2)-th empirical quantiles of qh α/2(xi) − yh i : i ∈ Ict and yh i − qh 1−α/2(xi) : i ∈ Ict respectively, computed on the calibration subset Ict for test time t. {qh γ (xj)}γ∈Γ, qh γ (xj) ≤ qh γ′(xj) ∀γ < γ′ represent the discrete set Γ of the quantiles predicted by the NN ensemble (see section 2.4), while yh t are the observed values. The PI bounds at specific coverage levels are straight derived as the predicted quantiles in the set Γ are defined by balanced pairs (e.g., distribution deciles, percentiles, etc). Thanks to such formulation, upper/lower quantiles can be specifically ad- justed at each stage over the prediction horizon, considering the related cover- age on the calibration sets. Overall, this yields stronger coverage capabilities by enabling more efficient input features conditioned approximate PIs estimation beyond the CP marginal coverage. In fact, more flexibility in compensating for the predicted bands is deemed useful for addressing the complex shapes typi- cally involved in PEPF applications, such as heteroscedasticity, skewness and fat tails [33]. Besides, the asymptotic validity supported by quantile regression NNs (i.e., DQR) is extended to reach finite samples coverage guarantees, while compensating for potential quantile overfitting and overconfidence. 2.3. Addressing non-exchangeable conditions Still, the CQR-based formulation inherits the lack of robustness of CP to failures of the samples exchangeability assumptions. This simply states that the 10 target (arbitrary) joint distribution is invariant to observations permutation, thus representing a weaker assumption than the i.i.d. commonly employed in machine learning applications (see e.g., [45] for further details). In particular, covariates and concept shifts in the target series are recognized as critical issues impacting CP validity in practical time series applications, as it is the case for EPF. Three main classes of approaches have been recently investigated in the CP literature devoted to non-exchangeable time series tasks, namely online sequen- tial split CP (see e.g. [34]), bootstrapped estimators without underlying models refitting (as e.g., in [46],[47]) and adversarial CP settings (see e.g., [48],[39],[42]). In this work, we integrate the multi-step CQR-based compensations (re- ported in section 2.2) within an on-line NN ensemble (i.e., Deep Ensemble) recalibration procedure, including the quantiles tracking and coverage error in- tegration stages proposed in [42] (i.e., Conformal PI control). Specifically, the quantiles predicted by the Deep Ensemble (DE) are incrementally conformalized over the test set following a daily retraining (i.e., recalibration). Details about how prediction models recalibration is commonly employed in the EPF context can be found in [4]. Formally, the predicted quantiles are corrected as follows at each stage t (i.e., day) in the test set: ¯qh t+1 = ¯qh t + η∇ρ1−α/2 (s h t − ¯qh t ) + rt   t∑ j=1(1{¯qh j ≥ s h j } − α/2)   (3) rt(x) = KI tan ( xlog(t) tCsat ) (4) where s h t summarize the asymmetric CQR scores, 1{.} the indicator function, and ∇ρ1−α/2(.) denotes the subgradient of the quantile loss, with: ∇ρ1−α/2(s h t − ¯qh t ) =    1 − α/2 if: s h t > ¯qh t −α/2 otherwise (5) The operation is performed on both the (1-α/2)-th empirical quantiles of the asymmetric upper/lower scores qh α/2(xt) − yh t and yh t − qh 1−α/2(xt). We keep 11 rt(x) as the tangent integrator, leaving the investigation of alternative admis- sible saturation functions to future extensions. The constant Csat bounds the asymptotic guarantee of the integral action at a level of at least 1 − α − δ: Csat = 2/π [⌈log(T )δ⌉ − 1/log(T )] (6) with δ > 0 representing a small constant (e.g., 1e-2). η, KI > 0 are further tunable hyperparameters controlling the proportional and integral actions re- spectively(see section 3). The whole procedure is first executed across a sub-sequence of samples close to the first test date to acquire the initial bag of calibration scores. It then progresses in a rolling window fashion. The motivations behind such methodological choices are summarized here- after. First of all, while in principle CP yields marginal coverage despite the accuracy of the underlying model, the latter impacts the local reliability of the prediction intervals [40]. Hence, updating the DE by exploiting the last obser- vations can support probabilistic performances beside point accuracy. Besides, the ensemble combination (detailed in section 2.4) provides a simple but efficient technique to get rid of poor local minimizers in the network parameter space (see section), often leading to improved accuracy beyond single networks (see e.g., [4]). Despite more computationally demanding, online DE retraining is feasible for EPF applications (see e.g., [33]). For instance, it is commonly employed within the widely adopted Quantile Regression Averaging (QRA) technique, as well as for distributional NNs aggregations in the litarature. The investigation of conformalized quantile regression methods without DE recalibration (as e.g. in [47]) and further on-line adaptive CP wrappers (as e.g., [39]) is left to future works. Finally, the quantiles tracking and integration provides further mecha- nism to compensate coverage degradation and systematic errors occurring over the recalibration window, e.g., due to sensible short-term drifts. This support a principled long-run reliability, i.e., limT →+∞ 1/T ∑T t=1 1{yh t ̸∈ Ch 1−α(xt)} = α, for each target coverage degree 1 − α (see [42] for further details on long-run coverage and related proofs). The exploration of the derivative action (i.e., the 12 scorecasting component) is left to future works devoted to specific robust design for addressing the potential degrade in stability. 2.4. Prediction quantiles estimation and DE combination To first estimate the conditional quantiles to be calibrated, we exploit both a quantile regression setup and samples from distributional NNs. In principle, the former enables flexible non-parametric approximations, but suffers poten- tial quantiles overfitting and overconfidence in the extremes under finite date regimes [1]. The latter can mitigate such issues by leveraging the paramet- ric form, but requires a careful selection of the density for each task at hand. Therefore, a dedicated experimental comparison is deemed useful to assess their capabilities in practical conditions. The output layers of the NNs and the loss functions are specialized accord- ingly, i.e. providing the predicted quantiles averaged by the pinball score in the former, parameterizing the target distribution then passed through a negative log-likelihood in the latter. The next step in designing the PEPF framework regards the specification of the NN architectural form employed to compute the day-ahead predictions. Either single-step (i.e., using 24 hour specific models) and multi-step mapping forms can be considered for this purpose (see e.g., [26]). Besides, as introduced in section 1 a broad amount of architectures have been investigated in the EPF literature, including feed-forward, recurrent NNs and Transformers to cite a few (see e.g., [24] and references therein for further details). As the state-of-art Distributional NN for PEPF is based on multi-step feed- forward maps, we follow the same structural design in this work. This enables a proper comparison of the proposed PEPF technique under coherent settings (see section 3). The investigation of further NN architectural forms is left to future studies. Such NN configuration is labelled DNN hereafter (i.e., Deep Neural Network), following the naming convention in [33] [4]) Formally, each DE component is defined as a parameterized function pro- viding day-ahead price predictions over the whole horizon in a unique pass, 13 given the input conditioning set xi at time i. Considering two hidden layers of nu1, nu2 ∈ Z + units to lighten the notation, the feed-forward map is mathemat- ically expressed as: ℓ1 = g(xiW1 + b1) ℓ2 = g(ℓ1W2 + b2)W3 + b3 (7) where W1 ∈ Rnx×nu1 , W2 ∈ Rnu1 ×nu2 , W3 ∈ Rnu2 ×H·np , b1 ∈ Rnu1 , b2 ∈ Rnu2 , b3 ∈ RH·np represent the weight and bias parameters in each hidden layer and g(.) the nonlinear activation function (e.g., ReLU, LeakyReLU, GELU, etc.). The input feature xi can involve both past values of the target series and a set of exogenous variables (see 3 for the sets involved in each benchmark application). Hence, the learning machinery is aimed at identifying the latent relationships and patterns within the spreading information sources involved in the conditioning set [26]. The parameter np ∈ Z + is defined depending on the subsequent network setup. Specifically, it is set as: • np = 1 : to achieve point predictions at each hour, as employed e.g., in the QRA-based PEPF setup (see section 3); • np = #Γ : for quantile regression settings, with #Γ representing the number of estimated quantiles (e.g., #Γ = 10 for deciles approximation); • np = p : for distributional NN settings, where p represent the number of parameters of the approximated conditional distribution, e.g., p = 4 for the Johnson’s SU form (see section 3). For the Distributional NN configurations, the output of the last layer in 7 (i.e., ℓ2) are further processed before being passed to the succeeding distribu- tional layer in order to achieve valid parameterizations. For instance, in the case of the Johnson’s SU form: f h(χ) = τ h i σh i √2π 1 √ 1 + ( χ−λh i σh i )2 e− 1 2 [ ζh i +τ h i sinh −1( χ−λh i σh i )]2 (8) 14 the output of the last hidden layer is processed as: λ h i = ℓ [h] 2 (9) σh i = ϵ + γ Softplus (ℓ [H+h] 2 ) (10) τ h i = 1 + γ Softplus (ℓ [2·H+h] 2 ) (11) ζ h i = ℓ [3·H+h] 2 (12) Softplus(x) = log (1 + ex) (13) with λh i , σh i , τ h i , ζ h i defining the density location, scale, tailweight and skewness given by the feed-forward map, conditioned on the input feature xi. ℓ [j] 2 defines the element in the output vector ℓ2 at index j. ϵ = 1e−3 and γ = 3 are correction factors commonly introduced for computational purpose. As apparent by the formulations above, a specific distribution parameterization is computed at each stage over the prediction horizon. Similar transformations are employed for the other density forms, e.g., to constrain positive values for standard deviation and degrees of freedom in Normal and Student-t (see section 3). For the quantile regression setup, the predicted conditional quantiles (e.g., deciles) at each stage ˆqh γ (xi) are simply extracted by indexing the last layer ℓ2 in the feed-forward map by stage h and level γ. Then, the average Pinball loss across the discrete set γ ∈ Γ of target quantiles is computed as: ∑ i ∑ h ∑ γ (yh i − ˆqh γ (xi))γ1{yh i > ˆqh γ (xi)} + (ˆqh γ (xi) − yh i )(1 − γ)1{yh t ≤ ˆqh γ (xi)} (14) Still, the approximated conditional quantiles can be subject of critical cross- ing issues. To address this problem, the introduction of non-crossing constraints within the quantile loss function has been proposed in the literature. Despite providing a valuable solution, it results in a sensible increase of the computa- tional effort during learning. Besides, it does not provide non-crossing guar- antees for the whole conditioning space. Therefore, in this work we exploit a post-hoc sorting operator, formally defined as: {˜qh γ (xi)}γ∈Γ = Sort({ˆqh γ (xi)}γ∈Γ), ˜qh γ (xi) ≤ ˜qh γ′(xi) ∀γ < γ′ (15) 15 Beside providing a computationally cheap solution to achieve non-crossing ∀x during prediction by construction, it has been recently shown that such opera- tion can only improve the pinball loss in the post-processed forecasting model [49]. The last design stage regards the definition of the approach to combine the neural network components within the DE. To this end, a wide set of meth- ods have been studied in the time-series forecasting literature, from uniform marginal aggregations, to complex conditional weighting (see [50] for a recent detailed review). Still, the uniform aggregation (i.e., ensemble combination con- sidering equal weights) have been shown to provide a robust alternative difficult to beat in practical settings. Similar observations have been reported under both point [4] and probabilistic [33] DNN-based settings EPF studies. More- over, it constitute a widely adopted approach in the broader Deep Learning literature devoted to DE (see e.g., [51]) Therefore, we exploit a uniform ensem- ble combination for the present study, leaving the investigation of alternative techniques to future extensions. For point predictors (e.g., in the case of QRA and base CP in the next section), this results in a simple average between the DNN components. For Distributional NNs, both probability aggregation and vincentization techniques can be considered. We resort to the latter since it typically leads to sharper bounds, beside marginalizing the different local min- imizers reached by the training algorithm [50]. Formally, this is computed for each prediction stage and quantile as: qh γ (xi) = ne∑ j=1 ˜qh(j) γ (xi), ∀γ ∈ Γ, ∀h ∈ [1, ..., H] (16) where ne represents the number of neural networks constituting the ensemble, indexed by (j). The same approach is employed for forecasting combination in the quantile regression configuration. The overall DE components are trained end-to-end in parallel, starting from different random initializations, by passing evenly spaced batches of data includ- ing the whole set of conditioning features and the target price values. To form the batches from the input time series during daily recalibration, we employ a 16 common sliding window approach, as detailed in Section 3. 3. Applications and results 3.1. Case studies As case studies, we focused on both the German market (GE) from [33] and the different bidding zones constituting the Italian day-ahead markets (namely NOR, CNOR, CSOU, SOU, SARD, SICI) made available by [43], providing a compelling setup for comparative evaluations under heterogeneous conditions. The exogenous set for the GE market includes the day-ahead load and renewable generation forecast as well as the most recent gas closing prices. The Italian datasets comprise the hourly load and wind generation predictions. The German dataset spans observations from 1/1/2015 to 31/12/2020, with out-of-sample test starting on 27/6/2019. The last 364 days before the beginning of the recalibration warm-up (which starts on 27/12/2018) are employed as validation data for hyper-parameters tuning. As input features, we included the subset selected with frequency 100% during the experiments performed in [33] To summarize, we adopted: the price values over the previous 2 days t-1, t-2, i.e., 48 lags; the day-ahead load forecasts available at time t; the renewable energy sources predictions for the target date t as well as the previous day t-1; the most recent closing gas price available, i.e. at t-2; the weekday encoding. The motivation behind such choice is twofold. On the one hand, we aim to explore a group similar to the one employed in the previous work. On the other hand, we target the assessment of the different PEPF models under consistent input variables. 4 4In [33], the authors reported sensible variations both in terms of the hyper-parameters chosen (including NNs input features selection via indicator variables) and the consequent test performances (see [33] for further details). Still, a deepen dataset analysis and feature selection may lead to better average performances. We leave such investigation to future extensions. 17 The Italian datasets cover the period from 10/1/2015 to 31/8/2019. For each region, the test set starts from 31/8/2018 onwards, while the validation subset covers the last year of observations before the first test recalibration. Considering the analysis reported in [43], we have included in the input features the price settlements across the different hours of the last 7 days (hence 168 values), each of the 24 values for both day-ahead load and wind generation forecasts, as well as the weekday. The weekday input is represented by means of the cyclical feature encoding in sine-cosine form, computing the components in the vector: ct = [sin (2πdt/7) , cos (2πdt/7)] (17) where dt ∈ [0, ..., 6] indexes the day of the week for the predicted sample at time t. 5 The targets include the price values for each of the day-ahead 24 hours at stage t. The samples are generated from the time series through a moving window. A Z-Score normalization is applied within each recalibration run, fitted by in- volving only the past values. Besides, a batch normalization is inserted after the DNN input layer. 3.2. Benchmarks The proposed approach is compared to several state of the art DNN based PEPF methods, including QRA, Deep Quantile Regression (QR) and Distribu- tional NNs. In addition to the Johnson’s SU (Jsu) proposed in [33], we deploy a Student’s t (Stu) to investigate the impact of the different distributional setups on the case studies. Moreover, we implement CP techniques on both normal distributions and conventional absolute residuals (see [34]) to assess the benefit of the more flex- ible quantile-level corrections introduced. The former has been implemented following the same setup of the other distributional NN models to achieve a fair 5The investigation of alternative techniques (e.g., one-hot encoding) is left to future studies. 18 comparison. Hence, each NN in the ensemble parameterizes the mean and scale of the Gaussian distribution, followed by quantile vincentization. Although nor- malized conformity scores may be alternatively computed through the mean and variance of a mixture with uniform weights, probabilistic aggregation has been shown to perform worse than quantile ensembling (see [33], [52]). 6 The CP on absolute residuals is obtained from the average predictions of NNs trained by minimizing the Mean Absolute Error. To shorten notation, in the subsequent sections we employ the following labels for referring to the different PEPF methods: CQN for the parameterized Normal form (i.e.,Conformalized Quantile Normal); CQR for Conformalized Quantile Regression; CQJ for Conformalized Quantile Johnson’s SU; CQS for Conformalized Quantile Student’s t. The application of the quantiles tracking and coverage error integration stages is represented by stacking the label OCQ*, e.g., OCQJ for on-line conformal PI control on Jsu distributional NNs samples quantiles. 3.3. Experimental setup The experiments have been performed by leveraging Tensorflow, including the Tensorflow Probability library which provides several utilities to imple- ment distributional NNs. 7 In particular, we adopt a set of 4 DNNs including 2 hidden layers with softplus activations. Training is performed by means of Adam [53] with early- stopping, starting from different random initializations. The number of units in each layer and the learning rate are tuned by cross-validation. The CP calibration subset involve 182 samples (i.e., the preceding 6 months) as in the QRA benchmark to achieve comparable results. 6The exploration of conformal inference on further forecasting combination techniques represent an interesting direction of future research. 7To setup the backbone DE framework, the description of the configurations follows the one used in the analysis reported in [33] for the baseline distributional and quantile regression based methods. 19 Table 1: Hyperparameters selected by the grid-search procedure for each zone GE CP/QRA Norm/CQN/OCQN Jsu/CQJ/OCQJ Stu/CQS/OCQS QR/CQR/OCQR nh 768 896 896 640 640 lr 1e-3 1e-3 1e-3 1e-3 1e-4 NOR CP/QRA Norm/CQN/OCQN Jsu/CQJ/OCQJ Stu/CQS/OCQS QR/CQR/OCQR nh 512 768 640 640 896 lr 1e-3 1e-3 1e-3 1e-3 1e-4 CNOR CP/QRA Norm/CQN/OCQN Jsu/CQJ/OCQJ Stu/CQS/OCQS QR/CQR/OCQR nh 768 960 896 896 896 lr 1e-3 1e-3 1e-4 1e-3 1e-4 CSOU CP/QRA Norm/CQN/OCQN Jsu/CQJ/OCQJ Stu/CQS/OCQS QR/CQR/OCQR nh 640 960 896 768 960 lr 1e-3 1e-3 1e-4 1e-3 1e-4 SOU CP/QRA Norm/CQN/OCQN Jsu/CQJ/OCQJ Stu/CQS/OCQS QR/CQR/OCQR nh 768 896 896 960 960 lr 1e-4 1e-3 1e-4 1e-4 1e-4 SARD CP/QRA Norm/CQN/OCQN Jsu/CQJ/OCQJ Stu/CQS/OCQS QR/CQR/OCQR nh 896 960 960 640 896 lr 1e-3 1e-3 1e-3 1e-3 1e-3 SICI CP/QRA Norm/CQN/OCQN Jsu/CQJ/OCQJ Stu/CQS/OCQS QR/CQR/OCQR nh 768 768 512 960 896 lr 1e-4 1e-5 1e-3 1e-3 1e-5 In principle, a wide range of alternative configurations could be considered during the setup of the learning framework and the hyper-parameters experi- ments. Since our goal is not to obtain the best NNs architecture but to evaluate the introduction of the conformal inference framework under coherent backbone DE setups, we performed a restricted grid search based cross-validation proce- dure. The following arrangements have been adopted 8. The batch size has been set to 64. As the different output layer’s parameterizations and loss functions may require specific complexities and rates, the hidden unit size and the learn- 8Dropout and ℓ1/ℓ2 regularizations have not been included in the layers since almost never chosen by the hyper-parameter tuner in [33]. 20 ing tuning are searched in the discrete sets nh ∈ [64, 128, 512, 640, 768, 896, 960] and lr ∈ [1e-5, 1e-4, 1e-3, 1e-2] respectively. Clearly the selections equal in the subsequent conformal inference stages (as e.g. in Jsu/CQJ/OCQJ). NNs training is performed by a maximum number of 800 epochs, including an early stopping callback on the validation loss with a patience of 50 epochs. For the hy- perparameters of the OCQ* methods we have investigated a common set across the different datasets and coverage levels, defined as KI =10, η=1e-2, Csat=1.2 given T =1e9 and a burn-in of 7 steps. During the daily recalibration of out-of-sample test experiments, the oldest sample in the moving window is discarded, while leaving a 20% subset to eval- uate the loss for early stopping. The output quantiles of the distributional NNs are estimated by generating 10000 samples for each test prediction. Table 1 reports the hidden units and learning rate employed for the test set experiments, as selected by the grid search procedure for each bidding zones. Large nh have been chosen in most cases. We did not observe sensible differences in validation losses among closed configurations (e.g., 640 vs 896). Still, the specific selections may be influenced by local minimizers reached by the training algorithm. These are marginalized by the Deep Ensemble during testing.9 3.4. Evaluation metrics and tests To evaluate the probabilistic forecasting performances achieved on the test sets, we follow the common practices in the PEPF field (see e.g. [1] and refer- ences therein for further details). Calibration is first analyzed by means of the Kupiec test (with significance level 0.05) for unconditional coverage, on both extreme and central PIs, for each day-ahead hour. Then, the average Pinball loss across the deciles (see section 2) and the Winkler’s score for the related mis- coverage levels are employed as proper scoring rules. It is worth noting that the average Pinball score, computed over the distribution percentiles, is commonly employed in PEPF as a cheap discrete approximation to the continuous ranked 9Prediction with different model ensembling techniques is left for future extensions. 21 probability score (CRPS) (see e.g. [1]) Statistical significance is evaluated via the multivariate Diebold and Mariano (DM) test on the differences in the loss norms between competing models. Point prediction errors are evaluated beyond the probabilistic forecasting performances by means of the Mean Absolute Error (MAE): MAE = 1 N N∑ n=1 |yn − ˆyn| (18) 3.4.1. Kupiec test The Kupiec test is aimed to assess the unconditional coverage of the PIs to the nominal rate 1 − α. Defining the sequence of indicators: In = 1{yn ∈ [ ˆLn, ˆUn]}, with ˆLn, ˆUn lower and upper bounds respectively, it checks whether P(In = 1) = 1 − α, assuming independent violations. The test is performed on the likelihood ratio (LR) statistics for unconditional coverage, χ 2(1) asymptotically distributed, defined as: LRUC = αn0 (1 − α) n1 (1 − π)n0πn1 , with: π = n1/(n1 + n0) (19) where n1,n0 represent the number of hits and violations in the indicator series. We leave to previous reviews in the literature (see, e.g., [14]) for further details on the common exploitation of the Kupiec test within the PEPF field. 3.4.2. Winkler’s score The Winkler’s score (or interval score) is a proper scoring rule to assess probabilistic forecasts formed as Prediction Intervals (PI) at discrete coverage levels 1 − α (see [54, section 5.9]). Formally, it is defined as: W inklern =    δn, if: yn ∈ [ ˆLn, ˆUn] δn + 2 α ( ˆLn − yn), if: yn < ˆLn δn + 2 α (yn − ˆUn), if: yn > ˆUn (20) where δn = ˆUn − ˆLn is the width the 1 − α-PI. The first case in (20) rewards narrow PIs (i.e., sharpness), while the others penalizes the occurrence of test observations outside the predicted interval. 22 3.4.3. Diebold–Mariano (DM) test The model-free Diebold–Mariano (DM) test is widely adopted in the EPF literature to evaluate the statistical significance of the performance differences between the model’s predictions (see e.g., [12], [14] and references therein for further details). Rather than averaging the prediction scores over the dataset - as in con- ventional test set metrics analysis - the DM test is based on the computation of pairwise score differentials between the forecasts ˆyM i d and ˆyM j d provided by competing models Mi and Mj over the test days d = [1, ..., Nd], followed by an asymptotic z-test to assess the null hypothesis that the expected value of the differentials series is zero. Two versions of the DM test exist, namely the univariate (executed hour- wise), and multivariate (performed jointly across all day-ahead hours). Follow- ing the aforementioned research studies, we exploit the latter for the present work. Notably, besides being more fitted to multi-hour prediction frameworks and related cross-hour combinations in the overall training loss functions, it en- ables a more user-friendly summary representation of the test results by graph- ical heat maps. Formally, the forecasts score differentials are computed as follows: ∆Mi,Mj d = L [εMi d ] − L [ε Mj d ] , with: L [ε Mi d ] = ( 24∑ h=1 |εMi d,h| n)1/n (21) where εMi d,h = (yd,h − ˆyMi d,h) ∈ R, and the arbitrary loss function L is stated in common n-norm form. Then, the DM statistic is derived as: DM Mi,Mj = √Nd ˆµ Mi,Mj ˆσMi,Mj (22) with ˆµ Mi,Mj and ˆσMi,Mj depicting the sample mean and standard deviation of the differentials series ∆Mi,Mj d computed over an out-of-sample test period of length Nd. In practice, the p-values of two one-sided tests are often inves- tigated, framed on the null hypothesis H0 : E [ ∆Mi,Mj d ] ≤ 0 and alternative H1 : E [∆Mi,Mj d ] > 0. Hence, the H0 rejection suggests a statistically signifi- cant performance improvement in the predictions provided by model Mi with 23 Figure 2: Hourly Kupiec test on GE market test set reference to the one of model Mj. To this end, a p-value of 5% is conventionally adopted as the test threshold. 3.5. Results analysis The calibration tests of the benchmark methods, shown in Figure 2-8, ap- pear consistent with the results reported in previous studies. We observe worse coverage of Jsu and Stu on GE than other cases, which could be due to the reduced heterogeneity in the DE components impacting the quantification of forecast uncertainty [55]. It can be noted that the behaviour of the benchmarks differs between the regional markets, as shown e.g. in the Kupiec plots of NOR vs SICI. This could be related to task specific characteristics (e.g., volatility extent) and requires further investigations, e.g. by exploring alternative param- eterized densities and datasets. The introduction of conformal inference has lead 24 Figure 3: Hourly Kupiec test on NOR market test set to improved hourly reliability on both distributional and QR settings. While the conventional CP on absolute residuals already provides adequate coverage, the effect of a more flexible approach is observed by assessing sharpness beyond calibration through the scoring rules (reported below). In fact, the former re- sults in symmetric average bands around the model predictions, thus lacking the capability to adapt the PIs width on simpler/harder test conditions as required for sample-wise efficiency. Further insights are provided by the hourly Prediction Interval Coverage Probability (PICP) values, reported in Figure 9 and Figure 10 for α=0.2 and α=0.6 respectively, and the average PICPs for each coupled deciles in Table 2. To support graphical readability, we have structured three subplots aggregating: the benchmark methods in the left column; the different conformalized quantile 25 Figure 4: Hourly Kupiec test on CNOR market test set regression setups (CQ*) in the middle column; the on-line conformal PI control integration (OCQ*) in the right column. The QRA benchmark coverage is included in all subplots to provide a coherent base within the common y axis scale. The red dashed lines represent the target coverage value 1 − α10. The baseline Jsu and Stu have obtained hourly coverage below the targets on average, which could be related to different uncertainties quantified on the samples observed during NNs training. Conversely, the Norm distributional form has resulted under-confident in several cases (see e.g., NORD and CNOR in Figure 9). The hourly coverage of the CP approach on absolute residual agrees with the results of the Kupiec test reported above. The QR benchmark 10e.g., 1 − α = 0.8 for α = 0.2 26 Figure 5: Hourly Kupiec test on CSOU market test set exhibit excessively narrow PIs, that can be attributed to both underlying quan- tile over-fitting phenomena during learning and data/distribution shifts. The combination in the ensemble seems to provide a limited contribution in fixing such issues. Despite the marginal coverage degree, the QRA application on the DE shows sensible prediction step-specific coverage fluctuations. This can be motivated by the averaging effect of the backbone quantile regression per- formed across the hours. These observations worth further investigations, which is planned for future works. The introduction of the conformalized quantiles techniques has lead to im- proved PICPs throughout the different DE configurations. The comparison of the related columns in Figure 9-10, and Table 2 display the specific contribu- tions towards the compensation of the limited calibration in the baseline models 27 Figure 6: Hourly Kupiec test on SOU market test set (see, e.g., QR w.r.t. CQR/OCQR in GE). Overall, the OCQ* settings show slightly better results than the CQ*. Still, we observe performance variations in OCQ* between different markets and coverage degrees (see, e.g., GE vs SICI). A possible explanation for this behavior could lie in the specific tuning of the proportional/integral actions hyper-parameters (see section 2.3). For the pur- pose of this work, we have employed simple common settings. Finer regulations (e.g., for each target coverage degree) may lead to more stable results across the testing conditions11. Beside being more reliable, the conformalized models have preserved stable and in some cases improved scores, as shown in Table 3. Furthermore, the mul- 11This constitute a further interesting direction for future research. 28 Figure 7: Hourly Kupiec test on SARD market test set tivariate DM tests performed on the Pinball and Winkler’s score are displayed in Figure 11 and Figure 12 respectively, where the coloured cells highlight the p-value for the difference between model’s predictions (see Section 3.4.3). The test set Winkler’s scores are computed for each of the PI1−α obtained from the approximated distribution deciles. Among the alternative configurations, the parameterized Normal form has obtained the worst performances, while CQR shows slightly better capabilities than CQJ and CQS. Similar results can be observed for the respective OCQ* settings. Such observations may be motivated by the major adaptivity, beyond the predetermined distribution forms, in characterizing complex uncertainty patterns following the specific applications needs. Besides, from the inspection of the Winkler’s score, it appears that CP tends to contribute more to the cor- 29 Figure 8: Hourly Kupiec test on SICI market test set rection of the PIs closed to the tails, which could be related to the behaviour of the semi-parametric quantiles estimation stage in regions with limited obser- vations. This is visible e.g., in the DM plots of the Winkler’s PI with α = 0.2 vs α = 0.6 regarding NOR and CSOU regions. However, these are just initial explanations and worth further empirical analysis. Besides the probabilistic forecasting performances, Table 3 reports the point prediction Mean Absolute Errors, while the outputs of the related DM tests are depicted in Figure 13. We observe that conformal inference has lead to a slight improvement of the MAE in some cases (see e.g. CNOR), as the median prediction can be updated after quantiles correction by the sorting procedure. The impact on point prediction accuracy of more flexible distribution parame- terization have been reported also in [33]. The gap in the MAE on GE could 30 Figure 9: Hourly PICP of miscoverege degree α = 0.2 on the test sets be related to the reduced input features set. To provide further insights on the different price behaviours addressed by the models among the regional markets, we plot in Figure 14 extracts from GE, NOR and SICI. The deciles predicted by the CQR model are reported besides the 31 Figure 10: Hourly PICP of miscoverege degree α = 0.4 on the test sets target series. Clearly, the price in each zone assume specific shapes and values, which depends on the generation mix (e.g., share of wind power generation in the southern part of Italy) and the different power demands. We leave to [43] and references therein for further details on the specific characteristics of the 32 Table 2: Prediction Interval Coverage Probability computed for each 1-α coverage degree CP QRA Norm Jsu Stu QR CQN CQJ CQS CQR OCQN OCQJ OCQS OCQR PICPα=0.2 0.79 0.78 0.78 0.74 0.75 0.75 0.79 0.77 0.78 0.78 0.81 0.80 0.80 0.80 GE PICPα=0.4 0.59 0.59 0.60 0.54 0.54 0.54 0.60 0.57 0.57 0.57 0.61 0.60 0.61 0.60 PICPα=0.6 0.40 0.39 0.40 0.35 0.35 0.35 0.40 0.38 0.38 0.38 0.41 0.40 0.40 0.40 PICPα=0.8 0.20 0.20 0.20 0.17 0.18 0.18 0.20 0.19 0.19 0.19 0.22 0.21 0.21 0.21 PICPα=0.2 0.81 0.78 0.84 0.77 0.79 0.73 0.82 0.79 0.79 0.77 0.81 0.80 0.80 0.80 NOR PICPα=0.4 0.62 0.57 0.66 0.57 0.57 0.53 0.63 0.59 0.59 0.57 0.61 0.60 0.60 0.60 PICPα=0.6 0.43 0.38 0.45 0.38 0.37 0.34 0.42 0.39 0.39 0.38 0.41 0.40 0.40 0.40 PICPα=0.8 0.22 0.18 0.22 0.19 0.18 0.17 0.21 0.20 0.19 0.19 0.21 0.21 0.21 0.21 PICPα=0.2 0.79 0.76 0.85 0.78 0.79 0.75 0.82 0.78 0.79 0.77 0.81 0.79 0.79 0.78 CNOR PICPα=0.4 0.60 0.55 0.67 0.58 0.58 0.55 0.63 0.58 0.59 0.57 0.60 0.59 0.59 0.59 PICPα=0.6 0.41 0.35 0.47 0.38 0.38 0.36 0.42 0.38 0.39 0.38 0.40 0.39 0.39 0.39 PICPα=0.8 0.20 0.18 0.23 0.19 0.19 0.18 0.21 0.19 0.19 0.19 0.21 0.20 0.20 0.20 PICPα=0.2 0.79 0.77 0.83 0.77 0.78 0.75 0.81 0.76 0.78 0.77 0.81 0.78 0.79 0.78 CSOU PICPα=0.4 0.58 0.55 0.67 0.58 0.57 0.55 0.61 0.57 0.57 0.56 0.60 0.58 0.58 0.58 PICPα=0.6 0.39 0.36 0.46 0.38 0.38 0.37 0.42 0.37 0.37 0.37 0.40 0.38 0.39 0.39 PICPα=0.8 0.20 0.18 0.24 0.19 0.19 0.18 0.21 0.19 0.19 0.19 0.21 0.20 0.20 0.20 PICPα=0.2 0.78 0.79 0.81 0.75 0.74 0.74 0.80 0.76 0.76 0.76 0.79 0.78 0.77 0.78 SOU PICPα=0.4 0.57 0.58 0.64 0.56 0.54 0.55 0.60 0.56 0.56 0.57 0.59 0.57 0.58 0.58 PICPα=0.6 0.38 0.37 0.44 0.36 0.34 0.36 0.40 0.36 0.35 0.36 0.39 0.38 0.38 0.38 PICPα=0.8 0.19 0.18 0.22 0.18 0.17 0.18 0.20 0.18 0.18 0.18 0.21 0.21 0.20 0.20 PICPα=0.2 0.78 0.76 0.83 0.76 0.77 0.71 0.80 0.77 0.78 0.75 0.80 0.78 0.78 0.78 SARD PICPα=0.4 0.58 0.55 0.64 0.56 0.56 0.51 0.61 0.56 0.56 0.55 0.60 0.58 0.58 0.58 PICPα=0.6 0.38 0.35 0.45 0.37 0.36 0.33 0.41 0.37 0.37 0.36 0.40 0.39 0.39 0.38 PICPα=0.8 0.19 0.17 0.23 0.18 0.18 0.17 0.20 0.19 0.18 0.19 0.20 0.20 0.20 0.20 PICPα=0.2 0.79 0.79 0.70 0.72 0.71 0.75 0.75 0.76 0.76 0.77 0.79 0.78 0.77 0.78 SICI PICPα=0.4 0.59 0.58 0.54 0.52 0.52 0.56 0.58 0.56 0.56 0.57 0.62 0.59 0.59 0.60 PICPα=0.6 0.40 0.39 0.37 0.35 0.34 0.37 0.39 0.37 0.37 0.39 0.43 0.40 0.40 0.40 PICPα=0.8 0.20 0.20 0.19 0.18 0.17 0.19 0.20 0.20 0.19 0.20 0.23 0.22 0.22 0.22 different Italian bidding area, and to [10] for a recent detailed analysis of the German power market. 4. Conclusions and next developments The goal of PEPF, as probabilistic forecasting in general, is to maximize sharpness while respecting calibration requirements. In fact, efficient but relia- bile uncertainty quantifications are decisive in supporting decision making under stochastic conditions, as it is the case in modern day-ahead EPF applications. In this work, we addressed the limited hourly calibration of the state of the art 33 Table 3: Test set scores for each market and PEPF technique CP QRA Norm Jsu Stu QR CQN CQJ CQS CQR OCQN OCQJ OCQS OCQR Pinball 1.549 1.557 1.489 1.467 1.473 1.474 1.483 1.457 1.463 1.462 1.480 1.450 1.456 1.459 Winklerα=0.2 20.27 20.62 18.07 17.52 17.77 17.71 17.99 17.30 17.53 17.50 17.98 17.18 17.42 17.45 GE Winklerα=0.4 14.43 14.57 13.68 13.45 13.51 13.52 13.62 13.36 13.40 13.41 13.58 13.30 13.34 13.40 Winklerα=0.6 11.39 11.45 11.08 10.94 10.97 11.00 11.03 10.88 10.91 10.91 11.02 10.83 10.86 10.89 Winklerα=0.8 9.27 9.28 9.13 9.04 9.05 9.06 9.09 8.97 9.00 9.00 9.06 8.92 8.96 8.97 MAE 3.799 3.794 3.758 3.724 3.725 3.726 3.755 3.720 3.718 3.717 3.745 3.700 3.704 3.704 Pinball 1.847 1.861 1.855 1.823 1.809 1.806 1.852 1.827 1.810 1.804 1.850 1.822 1.804 1.803 Winklerα=0.2 22.64 23.07 22.36 22.08 21.94 22.07 22.25 22.16 21.84 21.89 22.21 22.07 21.80 21.79 NOR Winklerα=0.4 16.95 17.19 17.02 16.73 16.56 16.58 16.96 16.78 16.60 16.54 16.94 16.73 16.52 16.53 Winklerα=0.6 13.71 13.79 13.80 13.56 13.45 13.43 13.78 13.60 13.48 13.45 13.78 13.57 13.44 13.46 Winklerα=0.8 11.31 11.34 11.41 11.19 11.11 11.06 11.41 11.22 11.13 11.08 11.39 11.19 11.10 11.08 MAE 4.655 4.659 4.705 4.609 4.581 4.547 4.705 4.608 4.580 4.547 4.700 4.601 4.565 4.543 Pinball 1.963 1.979 2.007 1.925 1.952 1.927 1.989 1.920 1.943 1.922 1.981 1.913 1.935 1.918 Winklerα=0.2 24.30 24.64 24.65 23.60 24.18 23.87 24.30 23.59 23.94 23.70 24.20 23.48 23.82 23.57 CNOR Winklerα=0.4 18.13 18.32 18.50 17.71 17.97 17.79 18.25 17.68 17.88 17.74 18.22 17.62 17.82 17.69 Winklerα=0.6 14.56 14.66 14.90 14.29 14.46 14.29 14.75 14.23 14.39 14.26 14.71 14.20 14.34 14.25 Winklerα=0.8 11.96 12.03 12.27 11.78 11.91 11.75 12.18 11.72 11.87 11.72 12.11 11.69 11.82 11.70 MAE 4.918 4.952 5.047 4.851 4.908 4.830 5.046 4.848 4.906 4.828 5.025 4.825 4.886 4.815 Pinball 1.994 1.996 2.050 1.977 1.990 1.976 2.033 1.964 1.968 1.963 2.028 1.962 1.970 1.964 Winklerα=0.2 24.88 25.07 25.42 24.60 25.04 24.66 24.92 24.36 24.37 24.14 24.88 24.24 24.36 24.09 CSOU Winklerα=0.4 18.38 18.45 18.96 18.27 18.40 18.29 18.73 18.17 18.13 18.15 18.71 18.12 18.14 18.14 Winklerα=0.6 14.78 14.77 15.21 14.64 14.73 14.62 15.10 14.55 14.59 14.57 15.04 14.54 14.61 14.59 Winklerα=0.8 12.14 12.12 12.47 12.03 12.07 12.00 12.42 11.93 11.99 11.97 12.38 11.96 12.03 11.99 MAE 4.992 4.982 5.127 4.949 4.966 4.934 5.124 4.942 4.958 4.927 5.111 4.933 4.949 4.927 Pinball 2.176 2.170 2.209 2.164 2.178 2.130 2.184 2.138 2.152 2.110 2.185 2.136 2.150 2.109 Winklerα=0.2 27.48 27.21 27.37 26.62 27.18 26.00 26.86 26.18 26.60 25.45 26.76 26.07 26.45 25.26 SOU Winklerα=0.4 20.18 20.12 20.45 19.93 20.12 19.60 20.09 19.66 19.79 19.35 20.09 19.60 19.76 19.32 Winklerα=0.6 16.09 16.07 16.39 16.07 16.13 15.80 16.19 15.85 15.93 15.68 16.24 15.87 15.94 15.69 Winklerα=0.8 13.17 13.16 13.44 13.22 13.24 13.05 13.33 13.06 13.12 12.98 13.37 13.07 13.14 12.99 MAE 5.414 5.407 5.528 5.440 5.447 5.384 5.525 5.426 5.444 5.373 5.511 5.409 5.431 5.368 Pinball 2.258 2.261 2.282 2.262 2.234 2.275 2.266 2.252 2.218 2.255 2.267 2.254 2.221 2.251 Winklerα=0.2 28.14 28.53 27.92 28.46 28.09 28.58 27.56 28.26 27.61 27.89 27.55 28.21 27.54 27.66 SARD Winklerα=0.4 20.84 20.93 21.01 20.97 20.59 21.00 20.82 20.86 20.42 20.79 20.83 20.88 20.45 20.71 Winklerα=0.6 16.73 16.73 16.95 16.73 16.52 16.85 16.84 16.66 16.41 16.74 16.86 16.70 16.45 16.75 Winklerα=0.8 13.75 13.70 13.96 13.71 13.57 13.81 13.88 13.63 13.51 13.74 13.90 13.67 13.55 13.76 MAE 5.653 5.624 5.745 5.632 5.584 5.672 5.741 5.627 5.580 5.654 5.727 5.617 5.575 5.647 Pinball 4.433 4.440 4.646 4.396 4.428 4.341 4.581 4.346 4.362 4.295 4.584 4.348 4.360 4.302 Winklerα=0.2 56.78 57.86 60.44 54.65 56.10 53.78 58.37 53.63 54.33 52.71 58.14 53.55 54.23 52.74 SICI Winklerα=0.4 41.45 41.58 43.35 40.66 41.13 40.09 42.85 40.11 40.39 39.55 43.02 40.25 40.39 39.66 Winklerα=0.6 32.75 32.70 34.22 32.61 32.74 32.23 33.83 32.28 32.30 31.91 33.91 32.33 32.36 32.01 Winklerα=0.8 26.62 26.54 27.83 26.72 26.75 26.43 27.43 26.42 26.43 26.20 27.47 26.44 26.47 26.27 MAE 10.91 10.86 11.41 10.98 10.99 10.86 11.40 10.96 10.96 10.84 11.36 10.90 10.89 10.81 neural network (NN) ensemble based methods for PEPF by exploiting a flexible Conformal Prediction (CP) framework. To this end, the quantiles approximated by the NNs at each prediction step have been incrementally conformalized over 34 Figure 11: DM test on average Pinball scores Figure 12: DM test on Winkler’s scores Figure 13: DM test on MAE the test set following a daily retraining (i.e., recalibration). Both quantile re- gression and distributional NNs approaches have been exploited for estimating the conditional quantiles to be calibrated. A uniform vincentization technique 35 Figure 14: Probabilistic forecasts on a subset of the test samples: (t)-GE, (m)-NOR, (b)-SICI 36 has been employed to aggregate the quantiles produced by the underlying en- semble components, providing a simple but robust forecasting combination in practice. Besides, a post-hoc sorting operator has been included to achieve conditional quantile non-crossing. The asymmetric Conformalized Quantile Re- gression formulation, adjusted in a multi-horizon forecasting setup, have been deployed to compute the scores and the conformalized quantiles. This sup- ports a proper correction of both upper and lower bounds at each stage over the prediciton horizon, leading to a more efficient local overage in the features conditioned PIs estimation. Such capability is particularly crucial to tackle the complex distributional patterns typically observed in PEPF applications, such as sensible heteroskedasticity, skewness and fat tails. Besides, it compen- sates potential quantile overfitting of the conventional pinball loss based neural network training, enhancing the asymptotic validity with finite samples cover- age guarantees. To address the lack of robustness to failures of the samples exchangeability assumptions, we have exploited an adversarial setup. Quan- tiles tracking and coverage error integration stages have been included, aimed to compensate potential coverage degradation and systematic errors occurring over the recalibration window, e.g., due to sensible short-term drifts. The whole procedure have been started on a samples subset close to the first test date to acquire the initial bag of calibration scores, then proceeding in a rolling win- dow fashion. Indeed, updating the ensemble components by including the most recent observations support probabilistic performances beside point accuracy, as the underlying model quality impacts the local reliability of the prediction intervals despite the marginal coverage guarantees provided by the CP frame- work. Besides, the ensemble aggregation provides a further mechanisms for this purpose, by getting rid of poor local minimizers in the network parameter space reached by single trainings. The experiments have been executed on the German market dataset as well as on the different regional bidding zones constituting the Italian day-ahead mar- kets, providing a compelling setup for testing under heterogeneous conditions. A comparison against state of the art benchmarks have been performed, includ- 37 ing QRA, quantile regression NNs, distributional NNs, as well as conventional absolute score and normalized score based CP settings, showing the capability of the proposed approach to achieve day-ahead probabilistic forecasts with im- proved hourly coverage. Beside being more reliable, the conformalized models have been shown to preserve stable and in some cases improved probabilistic scores. Still, we envision several avenues of future research, including the integra- tion of further adaptive CP wrappers to hold coverage under data and concept drifts, mechanisms for fine-tuning of the coverage levels, CP on early-stopping for improving sample-efficiency, as well as further baseline models, ensembles ar- chitectures and datasets. The deployment of computationally cheaper deep en- semble approaches represents an important issue to be addressed, to reduce the resource consumption of multiple network training during recalibration. Fur- thermore, we plan to implement eXplainable AI techniques (e.g., SHAP) to investigate the major features affecting the probabilistic predictions. Further to this, despite the specific energy forecasting tasks addressed in this study, the de- veloped approach can also be extended to other applications, such as day-ahead electricity load forecasting. References [1] J. Nowotarski, R. Weron, Recent advances in electricity price fore- casting: A review of probabilistic forecasting, Renewable and Sustainable Energy Reviews 81 (2018) 1548–1568. doi:https: //doi.org/10.1016/j.rser.2017.05.234. URL https://www.sciencedirect.com/science/article/pii/ S1364032117308808 [2] S. Mitra, L. Sun, I. E. Grossmann, Optimal scheduling of industrial combined heat and power plants under time-sensitive electricity prices, Energy 54 (2013) 194–211. doi:https://doi.org/10.1016/j.energy. 2013.02.030. 38 URL https://www.sciencedirect.com/science/article/pii/ S0360544213001448 [3] D. Ramin, S. Spinelli, A. Brusaferri, Demand-side management via optimal production scheduling in power-intensive industries: The case of metal casting process, Applied Energy 225 (2018) 622–636. doi:https://doi.org/10.1016/j.apenergy.2018.03.084. URL https://www.sciencedirect.com/science/article/pii/ S0306261918304227 [4] J. Lago, G. Marcjasz, B. De Schutter, R. Weron, Forecasting day-ahead electricity prices: A review of state-of-the-art algorithms, best practices and an open-access benchmark, Applied Energy 293 (2021) 116983. doi:https://doi.org/10.1016/j.apenergy.2021.116983. URL https://www.sciencedirect.com/science/article/pii/ S0306261921004529 [5] A. Ciarreta, B. Martinez, S. Nasirov, Forecasting electricity prices using bid data, International Journal of Forecasting (2022). doi:https://doi.org/10.1016/j.ijforecast.2022.05.011. URL https://www.sciencedirect.com/science/article/pii/ S0169207022000711 [6] A. A. Loutfi, M. Sun, I. Loutfi, P. B. Solibakke, Empirical study of day-ahead electricity spot-price forecasting: Insights into a novel loss function for training neural networks, Applied Energy 319 (2022) 119182. doi:https://doi.org/10.1016/j.apenergy.2022.119182. URL https://www.sciencedirect.com/science/article/pii/ S0306261922005542 [7] A. Wagner, E. Ramentol, F. Schirra, H. Michaeli, Short- and long-term forecasting of electricity prices using embedding of calendar infor- mation in neural networks, Journal of Commodity Markets (2022) 100246doi:https://doi.org/10.1016/j.jcomm.2022.100246. 39 URL https://www.sciencedirect.com/science/article/pii/ S2405851322000046 [8] M. Lehna, F. Scheller, H. Herwartz, Forecasting day-ahead electricity prices: A comparison of time series and neural network models taking external regressors into account, Energy Economics 106 (2022) 105742. doi:https://doi.org/10.1016/j.eneco.2021.105742. URL https://www.sciencedirect.com/science/article/pii/ S0140988321005879 [9] R. Sgarlato, F. Ziel, The role of weather predictions in electricity price forecasting beyond the day-ahead horizon, IEEE Transactions on Power Systems (2022) 1–1doi:10.1109/TPWRS.2022.3180119. [10] S. Madadkhani, S. Ikonnikova, Toward high-resolution projection of electricity prices: A machine learning approach to quantifying the ef- fects of high fuel and co2 prices, Energy Economics 129 (2024) 107241. doi:https://doi.org/10.1016/j.eneco.2023.107241. URL https://www.sciencedirect.com/science/article/pii/ S0140988323007399 [11] M. Attar, S. Repo, P. Mann, Congestion management market design- approach for the nordics and central europe, Applied Energy 313 (2022) 118905. doi:https://doi.org/10.1016/j.apenergy.2022.118905. URL https://www.sciencedirect.com/science/article/pii/ S0306261922003300 [12] L. Tschora, E. Pierre, M. Plantevit, C. Robardet, Electricity price fore- casting on the day-ahead market using machine learning, Applied Energy 313 (2022) 118752. doi:https://doi.org/10.1016/j.apenergy.2022. 118752. URL https://www.sciencedirect.com/science/article/pii/ S0306261922002057 40 [13] M. Kezunovic, P. Pinson, Z. Obradovic, S. Grijalva, T. Hong, R. Bessa, Big data analytics for future electricity grids, Elec- tric Power Systems Research 189 (2020) 106788. doi:https: //doi.org/10.1016/j.epsr.2020.106788. URL https://www.sciencedirect.com/science/article/pii/ S0378779620305915 [14] R. Weron, Electricity price forecasting: A review of the state-of-the-art with a look into the future, International Journal of Forecasting 30 (4) (2014) 1030–1081. doi:https://doi.org/10.1016/j.ijforecast.2014. 08.008. URL https://www.sciencedirect.com/science/article/pii/ S0169207014001083 [15] H. Lu, X. Ma, M. Ma, S. Zhu, Energy price prediction using data-driven models: A decade review, Computer Science Review 39 (2021) 100356. doi:https://doi.org/10.1016/j.cosrev.2020.100356. URL https://www.sciencedirect.com/science/article/pii/ S1574013720304561 [16] A. Gianfreda, L. Grossi, Forecasting italian electricity zonal prices with exogenous variables, Energy Economics 34 (6) (2012) 2228–2239. doi:https://doi.org/10.1016/j.eneco.2012.06.024. URL https://www.sciencedirect.com/science/article/pii/ S0140988312001338 [17] T. Hong, P. Pinson, Y. Wang, R. Weron, D. Yang, H. Zareipour, Energy forecasting: A review and outlook, IEEE Open Access Journal of Power and Energy 7 (2020) 376–388. doi:10.1109/OAJPE.2020.3029979. [18] X. Lu, J. Qiu, G. Lei, J. Zhu, Scenarios modelling for forecasting day-ahead electricity prices: Case studies in australia, Applied Energy 308 (2022) 118296. doi:https://doi.org/10.1016/j.apenergy.2021.118296. 41 URL https://www.sciencedirect.com/science/article/pii/ S0306261921015555 [19] C. Fraunholz, E. Kraft, D. Keles, W. Fichtner, Advanced price forecasting in agent-based electricity market simulation, Applied Energy 290 (2021) 116688. doi:https://doi.org/10.1016/j.apenergy.2021.116688. URL https://www.sciencedirect.com/science/article/pii/ S0306261921002142 [20] D. Keles, J. Scelle, F. Paraschiv, W. Fichtner, Extended fore- cast methods for day-ahead electricity spot prices applying ar- tificial neural networks, Applied Energy 162 (2016) 218–230. doi:https://doi.org/10.1016/j.apenergy.2015.09.087. URL https://www.sciencedirect.com/science/article/pii/ S0306261915012039 [21] I. J. Goodfellow, Y. Bengio, A. Courville, Deep Learning, MIT Press, Cam- bridge, MA, USA, 2016, http://www.deeplearningbook.org. [22] I. Lauriola, A. Lavelli, F. Aiolli, An introduction to deep learning in natu- ral language processing: Models, techniques, and tools, Neurocomputing 470 (2022) 443–456. doi:https://doi.org/10.1016/j.neucom.2021. 05.103. URL https://www.sciencedirect.com/science/article/pii/ S0925231221010997 [23] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Un- terthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, N. Houlsby, An image is worth 16x16 words: Transformers for image recog- nition at scale, in: International Conference on Learning Representations, 2021. [24] A. Mashlakov, T. Kuronen, L. Lensu, A. Kaarna, S. Honkapuro, Assessing the performance of deep learning models for multivariate 42 probabilistic energy forecasting, Applied Energy 285 (2021) 116405. doi:https://doi.org/10.1016/j.apenergy.2020.116405. URL https://www.sciencedirect.com/science/article/pii/ S0306261920317748 [25] A. Brusaferri, M. Matteucci, P. Portolani, A. Vitali, Bayesian deep learning based method for probabilistic forecast of day- ahead electricity prices, Applied Energy 250 (2019) 1158–1175. doi:https://doi.org/10.1016/j.apenergy.2019.05.068. URL https://www.sciencedirect.com/science/article/pii/ S0306261919309237 [26] J. Lago, F. De Ridder, B. De Schutter, Forecasting spot elec- tricity prices: Deep learning approaches and empirical compari- son of traditional algorithms, Applied Energy 221 (2018) 386–405. doi:https://doi.org/10.1016/j.apenergy.2018.02.069. URL https://www.sciencedirect.com/science/article/pii/ S030626191830196X [27] A. Jedrzejewski, J. Lago, G. Marcjasz, R. Weron, Electricity price fore- casting: The dawn of machine learning, IEEE Power and Energy Magazine 20 (3) (2022) 24–31. doi:10.1109/MPE.2022.3150809. [28] K. G. Olivares, C. Challu, G. Marcjasz, R. Weron, A. Dubrawski, Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with nbeatsx, International Journal of Forecasting 39 (2) (2023) 884–900. doi:https://doi.org/10.1016/j.ijforecast.2022.03.001. URL https://www.sciencedirect.com/science/article/pii/ S0169207022000413 [29] J. Dumas, A. Wehenkel, D. Lanaspeze, B. Corn ˘A©lusse, A. Sutera, A deep generative model for probabilistic energy forecasting in power systems: normalizing flows, Applied Energy 305 (2022) 117871. doi:https://doi.org/10.1016/j.apenergy.2021.117871. 43 URL https://www.sciencedirect.com/science/article/pii/ S0306261921011909 [30] O. Grothe, F. K¨achele, F. Kr¨uger, From point forecasts to mul- tivariate probabilistic forecasts: The schaake shuffle for day-ahead electricity price forecasting, Energy Economics 120 (2023) 106602. doi:https://doi.org/10.1016/j.eneco.2023.106602. URL https://www.sciencedirect.com/science/article/pii/ S0140988323001007 [31] C. Zhang, Y. Fu, Probabilistic electricity price forecast with optimal predic- tion interval, IEEE Transactions on Power Systems 39 (1) (2024) 442–452. doi:10.1109/TPWRS.2023.3235193. [32] E. Cramer, D. Witthaut, A. Mitsos, M. Dahmen, Multivariate probabilistic forecasting of intraday electricity prices using nor- malizing flows, Applied Energy 346 (2023) 121370. doi:https: //doi.org/10.1016/j.apenergy.2023.121370. URL https://www.sciencedirect.com/science/article/pii/ S0306261923007341 [33] G. Marcjasz, M. Narajewski, R. Weron, F. Nov, Distributional neural networks for electricity price forecasting, Energy Economics 125 (2023) 106843. doi:https://doi.org/10.1016/j.eneco.2023.106843. URL https://www.sciencedirect.com/science/article/pii/ S0140988323003419 [34] C. Kath, F. Ziel, Conformal prediction interval estimation and applications to day-ahead and intraday power markets, Interna- tional Journal of Forecasting 37 (2) (2021) 777–799. doi:https: //doi.org/10.1016/j.ijforecast.2020.09.006. URL https://www.sciencedirect.com/science/article/pii/ S0169207020301473 44 [35] T. Hong, P. Pinson, S. Fan, H. Zareipour, A. Troccoli, R. J. Hyndman, Probabilistic energy forecasting: Global energy forecasting competition 2014 and beyond, International Journal of Forecasting 32 (3) (2016) 896–913. doi:https://doi.org/10.1016/j.ijforecast.2016.02.001. URL https://www.sciencedirect.com/science/article/pii/ S0169207016000133 [36] A. Brusaferri, M. Matteucci, D. Ramin, S. Spinelli, A. Vitali, Proba- bilistic day-ahead energy price forecast by a mixture density recurrent neural network, in: 2020 7th International Conference on Control, Deci- sion and Information Technologies (CoDIT), Vol. 1, 2020, pp. 523–528. doi:10.1109/CoDIT49905.2020.9263898. [37] X. Zhou, J. Wang, H. Wang, J. Lin, Panel semiparametric quan- tile regression neural network for electricity consumption fore- casting, Ecological Informatics 67 (2022) 101489. doi:https: //doi.org/10.1016/j.ecoinf.2021.101489. URL https://www.sciencedirect.com/science/article/pii/ S1574954121002806 [38] V. Balasubramanian, S.-S. Ho, V. Vovk, Conformal Prediction for Reliable Machine Learning: Theory, Adaptations and Applications, 1st Edition, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2014. [39] M. Zaffran, O. Feron, Y. Goude, J. Josse, A. Dieuleveut, Adaptive con- formal predictions for time series, in: K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, S. Sabato (Eds.), Proceedings of the 39th Interna- tional Conference on Machine Learning, Vol. 162 of Proceedings of Machine Learning Research, PMLR, 2022, pp. 25834–25866. URL https://proceedings.mlr.press/v162/zaffran22a.html [40] A. N. Angelopoulos, S. Bates, A gentle introduction to conformal pre- diction and distribution-free uncertainty quantification (2022). arXiv: 2107.07511. 45 [41] Y. Romano, E. Patterson, E. Candes, Conformalized quantile regression, in: H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch´e-Buc, E. Fox, R. Garnett (Eds.), Advances in Neural Information Processing Systems, Vol. 32, Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper_files/paper/2019/ file/5103c3584b063c431bd1268e9b5e76fb-Paper.pdf [42] A. N. Angelopoulos, E. J. Candes, R. J. Tibshirani, Conformal pid control for time series prediction (2023). arXiv:2307.16895. [43] S. Golia, L. Grossi, M. Pelagatti, Machine learning models and intra-daily market information for the prediction of italian electricity prices, Forecast- ing 5 (1) (2023) 81–101. doi:10.3390/forecast5010003. URL https://www.mdpi.com/2571-9394/5/1/3 [44] K. Stankeviciute, A. M. Alaa, M. van der Schaar, Conformal time-series forecasting, in: M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, J. W. Vaughan (Eds.), Advances in Neural Information Processing Systems, Vol. 34, Curran Associates, Inc., 2021, pp. 6216–6228. URL https://proceedings.neurips.cc/paper_files/paper/2021/ file/312f1ba2a72318edaaa995a67835fad5-Paper.pdf [45] M. Fontana, G. Zeni, S. Vantini, Conformal prediction: A unified review of theory and new challenges, Bernoulli 29 (1) (2023) 1 – 23. doi:10.3150/ 21-BEJ1447. URL https://doi.org/10.3150/21-BEJ1447 [46] C. Xu, Y. Xie, Conformal prediction for time series, IEEE Transactions on Pattern Analysis; Machine Intelligence 45 (10) (2023) 11575–11587. doi: 10.1109/TPAMI.2023.3272339. [47] V. Jensen, F. M. Bianchi, S. N. Anfinsen, Ensemble conformalized quantile regression for probabilistic time series forecasting, IEEE Transactions on Neural Networks and Learning Systems (2022) 1–12doi:10.1109/TNNLS. 2022.3217694. 46 [48] I. Gibbs, E. Candes, Adaptive conformal inference under distribution shift, in: M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, J. W. Vaughan (Eds.), Advances in Neural Information Processing Systems, Vol. 34, Curran Associates, Inc., 2021, pp. 1660–1672. URL https://proceedings.neurips.cc/paper_files/paper/2021/ file/0d441de75945e5acbc865406fc9a2559-Paper.pdf [49] R. Fakoor, T. Kim, J. Mueller, A. J. Smola, R. J. Tibshirani, Flexible model aggregation for quantile regression (2023). arXiv:2103.00083. [50] X. Wang, R. J. Hyndman, F. Li, Y. Kang, Forecast combinations: An over 50-year review, International Journal of Forecasting 39 (4) (2023) 1518– 1547. doi:https://doi.org/10.1016/j.ijforecast.2022.11.005. URL https://www.sciencedirect.com/science/article/pii/ S0169207022001480 [51] B. Lakshminarayanan, A. Pritzel, C. Blundell, Simple and scalable predictive uncertainty estimation using deep ensembles, in: I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, R. Garnett (Eds.), Advances in Neural Information Processing Systems, Vol. 30, Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/ 9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf [52] K. C. Lichtendahl, Y. Grushka-Cockayne, R. L. Winkler, Is it bet- ter to average probabilities or quantiles?, Management Science 59 (7) (2013) 1594–1611. arXiv:https://doi.org/10.1287/mnsc.1120.1667, doi:10.1287/mnsc.1120.1667. URL https://doi.org/10.1287/mnsc.1120.1667 [53] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization (2017). arXiv:1412.6980. [54] R. Hyndman, G. Athanasopoulos, Forecasting: Principles and Practice, 3rd Edition, OTexts, Australia, 2021. 47 [55] A. Brusaferri, M. Matteucci, S. Spinelli, A. Vitali, Probabilistic electric load forecasting through bayesian mixture density networks, Applied Energy 309 (2022) 118341. doi:https://doi.org/10.1016/j.apenergy. 2021.118341. URL https://www.sciencedirect.com/science/article/pii/ S0306261921015907 48","libVersion":"0.3.2","langs":""}