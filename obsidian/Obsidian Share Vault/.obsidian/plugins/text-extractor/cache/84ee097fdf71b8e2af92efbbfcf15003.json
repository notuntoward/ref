{"path":"lit/lit_sources.backup/BeknazarYuzbashev222socialMediaPolitAdsExprmnt.pdf","text":"Do Social Media Ads Matter for Political Behavior? A Field Experiment ∗ George Beknazar-Yuzbashev† Mateusz Stalinski‡ January 6, 2022 Click here for the latest version of this paper. Abstract We exploit Facebook’s introduction of a ﬁlter hiding ads from the feed as a unique opportunity to study the eﬀects of online ads on political behavior. In a pre-registered experiment, we randomly assigned participants to hide political ads (treatment) or alcohol ads (control) for several weeks preceding the 2020 US elections. While the overall modest eﬀect on turnout was insigniﬁcant, this masked important heterogeneity, with political ads making Democrats slightly more motivated to vote and Republicans – substantially less. We explore reasons for this eﬀect, such as natural variation in ad content: the majority of Facebook ads on users’ feeds skewed Democratic. Lastly, the eﬀect on measures of aﬀective polarization and informedness was negligible. JEL Classiﬁcation: D72, D83, L82, L86, M37, P16, Z13 Keywords: political advertisement, microtargeting, social media, Facebook, voter turnout, political polariza- tion, campaign spending ∗We would like to thank Benjamin Brooks, Leonardo Bursztyn, Donald Green, Andrew Guess, Sota Ichiba, Alex Imas, Jonas Lieber, John List, Jos´e Luis Montiel Olea, Andrea Prat, Konstantin Sonin, Alex Torgovitsky and numerous seminar participants for helpful comments and suggestions. We also thank Petr Martynov for his assistance on the voter ﬁles data. Finally, we are grateful to Alec Bernstein and Heather Rodgers from Catalist LLC for matching our records to voter ﬁles data and oﬀering excellent customer service. This study was approved by the University of Chicago Institutional Review Board and the Columbia University Institutional Review Board, and registered in the American Economic Association Registry for randomized control trials under trial number AEARCTR-0006703. †Columbia University gb2683@columbia.edu. ‡University of Chicago mstalinski@uchicago.edu. Electronic copy available at: https://ssrn.com/abstract=4003901 And I’ve looked through a lot of these campaigns that lost, and the fact of the matter is if you’re not spending $200,000 on Facebook ... you are not ﬁring on all cylinders. Alexandria Ocasio-Cortez, NYT 1 Introduction Advertisement is not just a key component of Facebook revenue, it is Facebook revenue, making up 98% in 2020.1 A part of that revenue comes from political ads, with almost 11 million purchased since May 2018, at the cost of $2.2 billion.2 In 2020, not spending $200,000 on political campaign ads on Facebook was lambasted as “criminal” by some members of the U.S. House of Representatives.3 Politicians are not alone in this conviction – even Russian trolls buy political ads,4 with multiple Congressional hearings ensuing.5 Are political ads on social media as inﬂuential as they are made out to be? We investigate this in a ﬁeld experiment, exploiting a unique opportunity presented in June 2020 by Facebook’s introduction of an ad ﬁlter which – as they claim – “turns oﬀ all social issue, electoral or political ads from candidates, Super PACs or other organizations”.6 We randomly incentivized participants to turn on the ﬁlter to hide political ads (treatment) or alcohol ads (control) during the key weeks of the 2020 US presidential campaign and collected a rich set of outcomes illuminating voters’ behavior, including turnout and measures of aﬀective polarization.7 Our results suggest that the overall modest but insigniﬁcant eﬀect of political ads on turnout masked important heterogeneity based on political ideology, with Repub- licans becoming substantially less motivated to vote (possibly due to the predominantly Democratic ad diet). The eﬀects on measures of aﬀective polarization and informedness were negligible. We recruited participants using Facebook ads and assigned a ﬁlter to enable in a 5-minute intake survey.8 Participants were speciﬁcally instructed not to change ad settings on topics other than the 1https://investor.fb.com/investor-news/press-release-details/2021/Facebook-Reports-Fourth-Quarter-and-Full-Ye ar-2020-Results/default.aspx, accessed 2021-03-03. 2https://www.businessinsider.com/zuckerberg-facebook-political-ad-revenue-2020-10, accessed 2021-08-06. 3https://www.nytimes.com/2020/11/07/us/politics/aoc-biden-progressives.html, accessed: 2021-03-21. 4https://www.cbsnews.com/media/russian-ads-on-facebook-a-gallery/, accessed: 2021-06-28. 5https://www.wired.com/story/congress- asks- tech- to- face- hard- truths- about- russian- meddling/, accessed: 2021-08-13. 6https://about.fb.com/news/2020/06/voting-information-center/, accessed 2021-03-03. 7Aﬀective polarization concerns disliking or distrusting members of other political parties or individuals advocating political views diﬀerent than ours. Iyengar et al. (2019) deﬁne the term by enumerating examples: “Democrats and Republicans both say that the other party’s members are hypocritical, selﬁsh, and closed-minded, and they are unwilling to socialize across party lines, or even to partner with opponents in a variety of other activities. This phenomenon of animosity between the parties is known as aﬀective polarization.” 8We provided participants with a link that took them directly to their ad settings. While there, enabling the ﬁlter 1 Electronic copy available at: https://ssrn.com/abstract=4003901 assigned one. In an eﬀort to minimize attrition, the topic assignment was preceded by pre-screening, in which we introduced the Facebook’s ad ﬁlter, and asked each person if they agree to hide ads on one selected “unsavory” topic for four weeks. In total, 1587 individuals from our main sample9 were given an encouragement during the intake survey, and 1044 people reported successfully changing the ad settings. In order to credibly examine compliance with the encouragements, we had a subset of participants install a browser extension that recorded all ads appearing in their feed. Using contact details and demographics collected during the intake survey, we matched participants to publicly available voter ﬁles to examine the eﬀects of the ad ﬁlter on turnout. The other outcomes were collected in a follow-up survey conducted shortly after the Election Day. This design poses an identiﬁcation challenge, as we do not observe the ad diet of most of the participants. To overcome this, we propose a consistent estimator of local average treatment eﬀect (LATE) which relies on the intent-to-treat (ITT) regression estimated on the full sample and uses a combination of noisy self-reports and the extension users’ ad diets to estimate the proportion of individuals who took up the treatment. As we expected, enabling ad ﬁlters was technically easier for the extension users, so we could not extrapolate from them directly. The key assumption for our identiﬁcation strategy – that allows us to address this problem – is that the proportion of users who lied in their self-reports among extension users and others is the same. The intervention signiﬁcantly reduced exposure to political ads. Looking at the key subsample of extension users,10 the median number of political ads recorded over the duration of the experiment was 18 in the control group and 0 in the treatment group. In fact, in the treatment group only 14.3% saw any political ads, versus 85.9% in the control. Our estimates indicate that LATE of the political ad ﬁlter (that reduced exposure to political ads) on turnout is negative yet insigniﬁcant, with estimates ranging from −1.2 to −7.2 pp., depending on speciﬁcation, with stronger eﬀects coming from those that were conservative in estimating the proportion of compliers. In other words, those who saw more political ads (control group) were more likely to vote. A limitation of this ﬁnding is insuﬃcient statistical power to detect small eﬀects. However, given the scarcity of results on the impact of political ads on social media, our contribution oﬀers an important next step in the academic and regulatory discussion on this topic. Of particular importance to us was the potential heterogeneity that could lead to diﬀerential eﬀects requires only a few seconds. An animated GIF with instructions was shown to ensure that everyone can easily perform the task (see Figure 6). 9In general, we recorded that 1639 individuals received an encouragement. Section 2.5.1 describes how we arrived at our main sample of 1587 people. 10It is informative to look at all users who saw more ads than the 10th percentile of the control: 21.2 ads. Details and other measures are provided in Section 2.6.1. Results regarding exposure to political ads are discussed in Section 2.7.2. 2 Electronic copy available at: https://ssrn.com/abstract=4003901 for participants on the two sides of the political divide.11 Using the sample of users who completed the follow-up survey,12 we estimate that the eﬀect of seeing more political ads (control group) is associated with a reduction in turnout by 14 pp. among Republicans and an increase in turnout among Democrats by 4.1 pp. While the heterogeneity ﬁnding should be treated with caution (see Section 3.2.1 for details), it suggests an important pattern. To investigate the possible mechanism behind this, we coded party aﬃliation of all ad sponsors identiﬁed by the browser extension.13 We found that ads from politically aﬃliated sponsors (classiﬁed as favoring either Democrats or Republicans) in the control group were overwhelmingly supportive of Democrats – the median proportion of such ads in users’ individual ad diets was 0.93.14 Given that the ad ﬁlter lowered exposure to political ads which were predominantly pro-Democratic, the correlation is consistent with the interpretation that seeing more ads supporting Democrats (control group) had a demobilizing eﬀect on Republicans but a mildly mobilizing eﬀect on Democrats. The point estimates of our survey measures are very close to zero and insigniﬁcant. For our preferred speciﬁcation,15 we estimate LATE on the dictator game oﬀer to an outgroup partisan to be 2.4 cents out of a dollar, on the feeling thermometer: −0.9 out of 100, partisan policy support index: −0.07 out of 100, prediction index about outgroup’s policy support: −2.4 out of 100, and partisan misconception index: −3 out of 100.16 During the design stage of the study, we anticipated that diﬀerential attrition could be an important threat to identiﬁcation for the survey outcomes. In particular, we worried that individuals asked to turn oﬀ political ads are more likely to drop out, as their interest in politics or the perceived importance of staying informed on electoral issues can increase their reluctance to enable the ﬁlter. To argue against the presence of such form of diﬀerential attrition, we asked randomly selected two-ﬁfths of our participants to answer political engagement questions during the intake survey.17 Overall, we found that a similar number of participants completed the follow-up survey in both experimental conditions: 372 responses in the treatment group and 386 in the control group.18 Furthermore, there 11We speciﬁed our intention to perform such analysis in our preregistration plan. 12We use the standard two-step process of eliciting political aﬃliation in the follow-up survey (see Appendix B.1). 13We employed two coders to perform this task and reviewed all cases in which they disagreed. See Figure 12 for a depiction of individual ad diets by political aﬃliation. 14The median proportion of ads supporting Democrats among ads from politically aﬃliated sponsors was equal to 0.98 among users who identiﬁed as Democrats in the follow-up survey, and 0.78 among Republicans. While the latter ﬁgure need to be treated with caution due to the small number of observations, it indicates that even the Republicans’ ad diet consisted mostly of ads supporting Democrats. 15Our preferred speciﬁcation corresponds to column (7) in Table 9. 16A higher value of the partisan policy support index means that a person’s policy views are closer to what the most ardent people in their political party support. A higher value of the partisan misconception index reﬂects more agreement with dubious statements which might be popular among Donald Trump’s supporters. See Section 2.6.3 for a discussion. 17We collected information on (i) which party they would support for Congress, (ii) what is their interest in politics on a scale, and (iii) what is their news consumption. 18Regressing completion of the follow-up survey on encouragement assignment reveals no statistically signiﬁcant eﬀect 3 Electronic copy available at: https://ssrn.com/abstract=4003901 were no signiﬁcant diﬀerences in any of the political engagement outcomes by assignment for people who dropped out. A detailed discussion of diﬀerential attrition is provided in Section 3.4. Our paper relates to several strands of literature. First, we contribute to the rich literature on the impact of political advertisement in general. Credible identiﬁcation of causal eﬀects in this area had been lacking (DellaVigna and Gentzkow (2010)), but recent years have seen a number of related ﬁeld experiments and quasi-experiments. The literature can be subdivided into categories: persuasion eﬀects and the impact on turnout. The latest results regarding persuasion suggest that the eﬀects of political advertisements – despite high expenditure – are surprisingly small, although evidence about the impact of online ads is limited. In a meta-analysis of 40 ﬁeld experiments, Kalla and Broockman (2018) found that the persuasive eﬀect of campaign contact and advertising (such as mail, phone calls, and canvassing) in the US general elections are negligible. Coppock et al. (2020) oﬀer evidence from 59 experiments on 34, 000 participants, exposing them to political ads at diﬀerent stages of the 2016 campaign. They found small average eﬀects on candidate favorability and vote. On the other hand, there is some inconsistency, because, for example, in a large-scale ﬁeld experiment that deployed television and radio ads worth $2 million, Gerber et al. (2011) estimated large (although short-lived) eﬀects on voting preferences. Papers investigating the eﬀects of advertisements on turnout often produce null results. Krasno and Green (2008) utilized a natural experiment oﬀered by geographic idiosyncrasies of media markets, and reported no eﬀects of attack ads on turnout. Using variation in the FCC regulations, Spenkuch and Toniatti (2018) investigated the eﬀects of political advertisement during the 2004-12 presidential campaigns. They also found no eﬀect on aggregate turnout, although the eﬀects on vote shares were positive and suggest that political ads aﬀect the composition of voters. The most prominent explanations for the small and inconsistent eﬀects of political ads are various dimension of heterogeneity (Coppock et al. (2020)), and the possibility that broadly-targeted political ads from competing sides may be simply canceling each other out. The paper mentions many sources of heterogeneity such as receiver’s partisanship, ad content and context. Partisanship was particularly discussed by Spenkuch and Toniatti (2018) who oﬀered evidence that the null eﬀect of television ads on turnout could be driven by heterogeneity, where the eﬀect of seeing more pro-Democratic ads on Democrats is positive, and negative for pro-Republican ads on Republicans. The former statement is consistent with our data. Importantly, we complement their ﬁndings by oﬀering evidence of a strong negative eﬀect of pro-Democratic ads on Republicans. Second, we contribute to a new topic of rising prominence: the eﬀects of political ads placed on (p-value of 0.525 in the two-sided test). 4 Electronic copy available at: https://ssrn.com/abstract=4003901 social media. They are special as they allow unprecedented nuance in selection of targeted properties of the electorate (see a comparison between online and oﬄine ads in Fowler et al. (2021)). Many have voiced concerns that such microtageted ads are a threat to democracy (Ribeiro et al. (2019), Ribeiro et al. (2019), Witzleb et al. (2019)). To our knowledge, only one paper has investigated this. Liberini et al. (2020) exploited variation in daily advertising prices on Facebook during the 2016 US presidential campaign and found that microtargeted ads have strong eﬀects on voting intentions and self-reported turnout, in particular, increasing turnout for targeted moderates. In contrast, our experimental results, relying both on voter ﬁles data and survey outcomes, suggest a more tempered approach to assessing the threat Facebook political ads pose to democracy. Third, our survey ﬁndings allow us to relate to the literature on the broader impact of social media on political outcomes (see Zhuravskaya et al. (2020) for review). An interesting example that uses Facebook ads is provided by Broockman and Green (2014), who found a positive eﬀect of Facebook ads on name recognition of political candidates but no eﬀect on their evaluation. Fujiwara et al. (2021) examined the eﬀect of Twitter as a social network on election outcomes using an early adoption event as an instrument. They found that an increase in the number of Twitter users in a county decreased the Republican vote share in 2016 and 2020 presidential elections. Of particular note is the evidence on the underlying mechanism: Twitter’s relatively liberal content may have persuaded moderates to vote against Donald Trump. The eﬀect of social media on polarization is attracting increasing attention, and the ﬁndings in recent studies have been quite striking. Levy (2021) encouraged Facebook users to subscribe to Facebook pages of liberal or conservative news outlets to induce variation in posts presented to users. Even such a subtle intervention resulted in diﬀerences in aﬀective polarization (although had no eﬀect on political opinions). In a pre-election study, Allcott et al. (2020) encouraged users to deactivate Facebook for four weeks before the 2018 US midterms and found drastic eﬀects both on factual knowledge and political polarization. Lastly, studying the eﬀects of ad ﬁlters within a platform that spans over a third of human popula- tion on the globe19 is important in and as of itself. There are further reasons why our results verifying that Facebook’s ad ﬁltering is highly eﬀective in achieving the purported goal of hiding all political ads from the feed are valuable. In a discouraging move, since the conclusion of our experiment, Facebook took action against researchers who collected ads via browser extensions.20 Citing its terms of ser- vice, in August 2021 it even “disabled the accounts, apps, pages, and platform access associated with 19https://investor.fb.com/investor-news/press-release-details/2021/Facebook-Reports-Fourth-Quarter-and-Full-Ye ar-2020-Results/default.aspx, accessed: 2021-07-25. 20https://about.fb.com/news/2021/08/research-cannot-be-the-justiﬁcation-for-compromising-peoples-privacy/, 2021-08-13. 5 Electronic copy available at: https://ssrn.com/abstract=4003901 NYU’s Ad Observatory”. We too seem to have fallen prey to this policy, with our Facebook accounts irrevocably restricted from advertisement. This poses a challenge for future research. We hope that thanks to our contribution, researchers will be able to use ad ﬁlters together with our estimates of the propensity to misreport enabling them to build similar designs without the need for an extension. We now proceed to the body of the paper. Section 2 discusses the setting and experimental design. In particular, we explain the nuances of our identiﬁcation strategy. Section 3 dives into the results. First, we discuss evidence showing that the ad ﬁlter does in fact reduce exposure to political ads. We then investigate its eﬀect on turnout and the survey measures. Lastly, we address potential concerns. 2 Experimental Setting and Design 2.1 Political Ads on Facebook On Facebook, ads are displayed to users in their feeds alongside other, non-sponsored, content. Ad slots are sold using an auction design to those wishing to advertise, including political actors, and, since May 2018, political ads brought in almost $2.7 billion as of August 2021.21 In June 2020, Facebook announced a number of upcoming changes related to the elections. Among them was the option – that we call the “ad ﬁlter” – to “turn oﬀ all social issue, electoral or political ads from candidates, Super PACs or other organizations that have the ‘Paid for by’ political disclaimer on them” – or, in plain language, to hide political ads.22 It was particularly convenient for us that political ads are labelled with the ‘Paid for by’ disclaimer as it allowed our browser extension to credibly identify them in user’s feed. We used this approach as our primary method of measuring exposure to political ads.23 We expected that the ad ﬁlter would not be easily accessible or well-known among Facebook users. In fact, Facebook hid the feature so deep into the web of settings that Mozilla Foundation even had to publish instructions on how to actually reach them.24 On mobile devices, starting from the main screen of the Facebook App, one has to click “Menu”, scroll down, click “Settings & Privacy”, click “Settings”, then scroll a long way down to “Ad Preferences”, and there select “Ad Topics”, where, among other options, there is a button “See Fewer” ads on the topic of “Social Issues, Elections or Politics” – and it’s not even clear to the user what “see fewer” means.25 This complexity reduces the 21https://www.facebook.com/ads/library/report, accessed 2021-27-08. 22https://about.fb.com/news/2020/06/voting-information-center/, accessed 2021-03-03. 23Section 2.6.1 discusses three alternative methods that we employed to measure exposure to political ads: manual categorization of sponsors by coders, textual analysis using keywords, and classiﬁcation using presidential campaign sponsors identiﬁed by the Wesleyan Media Project. 24https://foundation.mozilla.org/en/blog/how-turn-political-ads-facebook-and-instagram/, accessed 2021-06-28. 25The reasoning behind Facebook’s usage of “see fewer” term is unclear. Our data suggests that that it removes close to all political ads from user’s feed, so perhaps the particular phrasing was down to either the possibility of occasional 6 Electronic copy available at: https://ssrn.com/abstract=4003901 likelihood that people came into this study with ﬁlters already enabled. 2.2 Recruitment Using the very same Facebook ads, we recruited over 1, 500 to participate in our experiment (see Figure 3 for ad examples).26 We targeted users aged 18+, living the United States, whose language setting on Facebook was set to English. Facebook optimizes ads to target those who are more likely to click, thus there was a risk that through optimization we would not get a representative sample. To counteract this, we split the targeted population by gender and age (18-39 and 40+), and targeted them with separate campaigns. It was important for us to get a distribution of political views in our sample that would be repre- sentative of the general population. As Facebook determination of political views may not be reliable (Sances (2021)), in order not to over-sample the fringes of the political spectrum, we broadly tar- geted people who matched “Behaviors: Likely engagement with US political content (moderate)”. As expected, this resulted in a sample where individuals with diﬀerent strengths of political aﬃlia- tion were reasonably represented, with sizeable numbers of strong Democrats/Republicans as well as independents (see Figure 15). Upon clicking the ad, users were directed to a Qualtrics environment for the intake survey. Re- cruitment for the follow-up survey occurred largely by email (we sent personalized invitations) with some participants being recruited through additional ads on Facebook that speciﬁcally targeted users from our email list. We only contacted participants who reported that they successfully changed the ad settings (enabled the political ad ﬁlter in the treatment group or the alcohol ad ﬁlter in the control group), and thus fulﬁlled the requirements set during the intake survey. We account for this decision in our identiﬁcation strategy (see Section 2.7). Furthermore, we provide evidence that it did not result in diﬀerential attrition (see Section 3.4). All users who completed the intake survey were eligible to enter a lottery for a $100 Amazon gift card. Furthermore, all participants who completed both the intake survey and the follow-up survey were paid $5.27 Facebook oﬀers a more natural process of recruitment than existing survey platforms, as we focus directly on users who are being targeted with political ads. Recruiting survey participants on Facebook adds sifting through, or marketing reasons. 26Facebook users are overwhelmingly on mobile devices, so we were expecting a very low take-up of the browser extension. To tackle that, in addition to our main campaign, we ran a campaign that speciﬁcally targeted desktop users. See Figure 3 for more information. 27Even though the incentives promised in the ad campaigns varied from $2 to $5, when sending out invitations for the follow-up survey we oﬀered everyone $5 to further encourage participation. Moreover, irrespective of any requirements speciﬁed in the intake survey (the browser extension was mandatory in one of our campaigns), eligibility for the payment did not depend on whether a participant installed the extension, as we were unable to match all extension users to our intake survey data (some people used aliases as their Facebook names), and thus fairly verify that a given individual failed to install it. 7 Electronic copy available at: https://ssrn.com/abstract=4003901 is becoming increasingly popular in the ﬁeld (Allcott et al. (2020), Blattman et al. (2021), Levy (2021)). Notably, this method results in samples that are comparable to MTurk samples and the general populace of the United States (Boas et al. (2020)). 2.3 Browser Extension We developed a browser extension compatible with Chromium-based browsers (Chrome, Brave, and Edge) that account for over 82% of the global desktop market share.28 Extensions are commonplace in the modern browsing experience, and users are accustomed to using them. The installation process was very simple. First, users followed our URL which directed them to the Chrome Store page of the extension (see Figure 4). There, they could access a video and a text explaining how the extension works and, importantly, how we protect privacy. To complete the installation, users had to click the “add” button at the top of the page, after which the browser prompted them to conﬁrm adding the extension (see Figure 5). The browsing experience remained completely unchanged: the extension did not alter anything on the user’s feed. Each time the browser was loading a Facebook a page, the extension identiﬁed ads (marked as “Sponsored”) and recorded their key elements (title, text content, images, links) in our database. We did not store any other content from the user’s feed – only ads. Each ad was recorded under the name that could be found on the their Facebook page. We used that to match the extension data with the intake survey data. Given that some users had aliases as their Facebook names, matching by name was not possible for all extension users. In those cases we attempted to use other characteristics available on their proﬁles (such as year of birth or location). 2.4 Experimental Design 2.4.1 Design Overview There were challenges on the path to our goal – investigating the eﬀect of the Facebook ad ﬁlter. In an ideal world, we would have randomly manipulated the setting that turns it on or oﬀ, unbeknownst to the user. In reality, we were facing a number of problems: (i) we were not able to manipulate the setting – we could only encourage users to change it; (ii) we were not able to directly observe compliance with the encouragement; and (iii) the intervention could have led to diﬀerential attrition (a concern for survey outcomes). We designed the experiment to address or alleviate all of these issues. First, we carefully crafted our treatment and control groups to be similar in nature – in both conditions participants received an encouragement to enable the ad ﬁlter, but on diﬀerent topics. In the the treatment group, participants were asked to “hide ads related to Social Issues, Elections, or Politics”, while in the control group they were prompted to “hide ads related to Alcohol”. Thus, the 28https://kinsta.com/browser-market-share, accessed 2021-03-05. 8 Electronic copy available at: https://ssrn.com/abstract=4003901 tasks faced by individuals in both groups were almost identical and of equal complexity. This limits the threat of diﬀerential attrition. Furthermore, we worried that individuals asked to turn oﬀ political ads are more likely to drop out, as their interest in politics or the perceived importance of staying informed on electoral issues, can increase their reluctance to enable the ﬁlter. We asked two-ﬁfths of our sample to take a political engagement check for this type of issue. To address the challenge of not directly observing whether the participants changed the ad settings in response to the encouragement, we developed a browser extension that can track ads displayed on user’s Facebook feed. This allows us to credibly verify if the participants enabled the ad ﬁlter to hide political ads for the sample of extension users.29 We can use the extension data to estimate the proportion of users who enabled the ad ﬁlter among those who self-reported doing so.30 In Section 2.7, we demonstrate how to combine this with the intent-to-treat regression (ITT) and the ﬁrst stage regression using self-reported data, both estimated on the full sample, to arrive at a consistent LATE estimator and compute the standard errors. Lastly, we provided strong incentives to participants to enable the ad ﬁlter as requested. Individual bonus payment (though not eligibility for the gift card raﬄe) was contingent upon changing the settings as required. This was credible, as the consent form speciﬁed that we might request a screenshot of the ad settings as a conﬁrmation.31 2.4.2 Flow of the Study We started recruiting participants for the intake survey on October 2, 2020. The average duration of the intervention, deﬁned as the time between the intake survey and the election day, was 22.5 days, with the median equal to 22 days. The ﬂow of the intake survey is depicted in Figure 1. First, we collected contact details (name and email) and essential demographics (year of birth and zip code).32 Then, we introduced the concept of Facebook’s ad ﬁlter and asked participants if they agree to hide ads on a topic that we select for them. If they agreed, we randomly assigned them either alcohol ads or political ads. If they did not, the survey was terminated. To facilitate the process of changing the ad settings, we provided users with a URL that opened in a new tab and led directly to the ad settings page. Furthermore, we showed an animated GIF depicting the necessary steps (see Figure 6). Thanks to oﬀering the direct link to ad settings, enabling 29We used multiple ways of determining take up of the treatment (enabling the political ad ﬁlter) based on the extension data. Details are provided in Section 2.7.2 30In Section 3.4 we discuss how the fact that extension users may be diﬀerent from non-extension users aﬀects our identiﬁcation strategy. 31We initially planned to use this provision in the case of abnormally short time spent on the screen where the ad settings were changed, but we did not employ it. All participants who self-reported changing the ad settings and completed the follow-up survey were fully remunerated. 32To maximize our chances of recruiting a broad sample of participants, at this stage, we collected only key information needed for matching participants to voter ﬁles. This allowed us to keep the intake survey to be under 5 minutes. We collected a rich set of demographics in the follow-up survey. 9 Electronic copy available at: https://ssrn.com/abstract=4003901 the assigned ad ﬁlter was simple enough that most users could have performed it in under 30 seconds. Before proceeding, the participants had to report whether they successfully changed the ads settings. Figure 1: The Intake Survey During the study, we quickly found out that some users on mobile devices had trouble navigating from the Face- book ad settings tab back to the survey. In such cases, users attempted re-taking the survey, which could have led to a diﬀerent topic assignment. To prevent that, we started recording user’s randomized topic in a database, and as- signed users re-taking the survey the same topic as before. Approximately 98.5% of the intake survey responses were recorded after the change was made. We asked a randomly selected one-ﬁfth of the partic- ipants to take the political engagement survey before we introduced the ad ﬁlter and assigned topics. Additionally, we asked a further one-ﬁfth of the participants to complete the survey after they reported whether they changed the ad settings as requested. The survey elicited: (i) interest in politics on a scale from 0-10, (ii) weekly news consumption in hours,33 and (iii) the party that the participant would choose for Congress. At the end of the survey, we asked participants to in- stall our browser extension. They were informed about its purpose and our commitment to protect their privacy. As an extra perk to installation, all users were entitled to a personalized report on who targets them with ads. Lastly, we asked participants not to share the survey link with others.34 We also requested that, should they feel the need to do so, they use the special link provided by us on the screen. This allowed us to track which respondents were referred to by other participants. Our browser extension collected data on ads displayed to users who installed it throughout the 33The options were: “Less than 2”, “5-10”, “10-15”, and “More than 15”. Converting this to a numeric variable, we assigned the following numbers, respectively: 1, 7.5, 12.5, and 20. 34This screen was added to the intake survey at the same time as the feature that allowed assignment of the same topic to participants re-taking the survey. 10 Electronic copy available at: https://ssrn.com/abstract=4003901 period from the intake survey until November 2, 2020, which is the last day covered in our extension dataset. On November 5, we began collecting responses for the follow-up survey (89.7% of responses came in the ﬁrst two days). The process concluded on November 10, 2020. 2.5 Sample and Balance 2.5.1 Main Sample We recorded that 1639 individuals were assigned an encouragement during the intake survey: 820 were asked to hide alcohol ads, and 819 were requested to hide political ads. Below, we describe the cleaning procedure that led us to our main sample of 1587 people. We had to drop three categories of partici- pants from our sample. First, we removed responses from individuals who previously participated in one of the pilot runs that we conducted prior to pre-registration. We had little control over the way in which Facebook displays our recruitment ads to potential participants, hence we could not have ex-ante prevented anyone from taking part again. Second, we dropped individuals who were assigned diﬀerent encouragements as a result of re-taking the survey. Third, we discarded observations from people who received the link to the intake survey not through our recruitment on Facebook but by existing participants sharing the link (the results are robust to including this group). After performing the cleaning, we arrived at the sample of 1587 individuals, including 792 in the treatment group (hide political ads) and 795 in the control group (hide alcohol ads). 2.5.2 Extension Sample A subset of users from the main sample installed the browser extension which allowed us to observe their ad diet. The extension sample consists of 288 extension users whom we were able to match to our intake survey data and for whom we recorded at least one ad (see Section 2.3 for more details on the extension and the matching process). The extension sample includes 145 individuals from the treatment group, and 143 from the control group. 2.5.3 Survey Sample Out of 1587 people in the main sample, 1044 indicated that they were able to turn on the ad ﬁlter as required (67.3% in the treatment group and 64.3% in the control). These individuals received a link to the follow-up survey, either by email or via the targeted Facebook ad campaign. Our eﬀorts to maximize the take-up of the survey proved successful, as 72.6% of individuals who received the link completed the survey (758 people in total). There are no obvious signs of diﬀerential attrition, with 372 responses in the treatment and 386 in the control (see Section 3.4 for more discussion). 11 Electronic copy available at: https://ssrn.com/abstract=4003901 2.5.4 Balance Each of the samples appears to be well-balanced. During the intake survey, we focused on collecting data necessary for matching participants to their voter ﬁles.35 To that end, we obtained their age and zip code. Furthermore, we collected the device used and the time spent on the intake survey. Lastly, we have answers to the political engagement survey questions for a random subsample of 634 users. We present the analysis of these covariates by the assigned encouragement in Table 4. None of the diﬀerences are signiﬁcant. Moreover, we found that the distribution of participants’ geographical location is in line with population diﬀerences across states (see Figure 7). For the survey sample, we had at our disposal a rich set of traditional controls. These also appear well-balanced across the encouragements (see Table 5). 2.6 Outcomes Our outcome variables fall into three distinct categories. First, we were interested in measuring participants’ exposure to political ads and ads in general. This allows us to verify the eﬀectiveness of the ad ﬁlter, and that of our encouragement, in changing the ad diet. Secondly, we use voter ﬁles data to establish the eﬀects of the ad ﬁlter on voter turnout. Lastly, we focus on a range of survey-based outcomes, including measures of aﬀective polarization and informedness. We discuss each category of outcomes in turn. 2.6.1 Ad Diet To examine the eﬀects of the ﬁlter on exposure to political ads, we look at the ad data for partici- pants who installed our extension. Ads about social issues, elections, or politics on Facebook can be recognized by the fact that they state the sponsor who “paid for” the ad. Figure 8 shows an example of a political ad in contrast with a standard ad that does not disclose the payer. To check the robustness of our main classiﬁcation method, we relied on three additional types of categorization. First, we employed two coders who independently reviewed all sponsors from ads that indicated who paid for the campaign.36 This involved coding the political alignment of the sponsor, which was crucial for estimating the relative exposure to Republican vs. Democratic ads. Secondly, 35Most of the demographic questions were backloaded into the follow-up survey in order to shorten the intake survey, and lower the likelihood of attrition. In particular, the step reduced the strain on mobile users, which was important given that 71% of participants took the intake survey on a mobile device. In comparison, all individuals who completed the follow-up survey used a desktop device, a consequence of advertising it mostly via email. 36The coders were given speciﬁc instructions with questions that they had to answer about each sponsor. We also requested that they provide sources that they used. 12 Electronic copy available at: https://ssrn.com/abstract=4003901 we performed textual analysis of ad content, looking for keywords related to elections or politics.37 Thirdly, we used a list of main presidential campaign sponsors (top spenders) provided by the Wesleyan Media Project and matched it to our data.38 2.6.2 Voter Turnout At the beginning of the intake survey we collected each participant’s name, email, year of birth, and zip code. This allowed us to use the Catalist National Voter Database, a uniﬁed national voter ﬁle, and acquire the 2020 voting record for all individuals they were able to identify. The matching procedure used by Catalist LLC identiﬁed 1315 respondents (82.9%) out of 1587 individuals from the main sample with conﬁdence of at least 0.7.39 The likelihood of a match depends on the quality of the contact details that respondents provided during the survey. This occurred before random assignment of the ad ﬁlter, so whether an individual is matched is independent of their assignment. For each matched person, we received information on whether they voted at the polling station, by mail, were absentee voters, early voters, had unknown modality of voting, or do not have a voting record. 2.6.3 Survey Outcomes We collected a rich set of survey outcomes designed to shed light on how political ads shape important characteristics aﬀecting voter’s behavior. The relevant survey questions are provided in Appendix B. At the beginning of the follow-up survey, we collected information on political alignment using a two- step process (see Appendix B.1). As a result, we were able to assign each respondent “the opposing side”: either Republicans or Democrats. In order to estimate the eﬀect of the ad ﬁlter on aﬀective polarization, we collected three types of outcomes. First, participants were matched with an individual of opposite political alignment to play a dictator game, splitting $1. Second, we used the feeling thermometer (0-100 degrees) to elicit how they “feel toward Republican/Democrat supporters” (see Appendix B.3.2). Third, we provided participants with a list of ﬁve words: “open-minded”, “generous”, “honest”, “selﬁsh”, “intelligent”, and asked them to select all that apply to Republicans and Democrats.40 37We counted ads that contained at least one of the keywords: “Trump”, “vote”, “voting”, “Biden”, “sleepy Joe”, “president”, “ballots”, “judge”, “in oﬃce”, “politician”, “Congress”, “Senate”, “defund the police”, “election”, “Supreme Court”, “governor”, “Democratic party”, “Republican party”, “ballot”. 38The list of sponsors is available in Table 2 from https://mediaproject.wesleyan.edu/releases-102920/, accessed 2021-28-06. 39The proportion of matched users would have been even higher if we received permission to access California voter ﬁles (our application was rejected). Respondents from California constitute 37.1% of the unmatched observations. Go to Table 13 and Table 14 to see how individuals for whom we found a matching voter ﬁle diﬀer on covariates from those for whom we did not. Lastly, more details about data oﬀered by Catalist and the matching process can be found at https://catalist.us/data/, accessed 2021-31-07. 40See Appendix B.3.3 for the exact wording of the question. For each individual, we computed the summary index by adding one for selecting each positive trait and subtracting one for selecting “selﬁsh”. We did it separately for the 13 Electronic copy available at: https://ssrn.com/abstract=4003901 Aﬀective polarization is often modelled as proportional to the distance between the individual’s own set of views and the views held by members of the outgroup (as perceived by the individual). This suggests two main channels through which exposure to political ads could have an impact on aﬀective polarization: (i) it may change the individual’s policy views, or (ii) change the beliefs about the views of the political opponents. For example, political ads could be depicting the rival party as more extreme than the ad consumers previously thought. We collected outcomes to measure the relevance of both channel (i) and (ii). To elicit the impact of the ad ﬁlter on policy views we asked participants to describe what they think on ﬁve issues (see Appendix B.2) relevant to the Presidential election on a scale from 0 (strongly disagree) to 100 (strongly agree). We used these responses to calculate the partisan policy support index by computing the mean score across the ﬁve statements.41 A higher value of the partisan policy support index means that a person’s policy views are closer to what the most ardent people in their political party support. We also asked participants to predict the mean score for supporters of the rival party for each of the ﬁve statements. We calculated the cumulative index representing the beliefs in a similar way as for own views.42 Hence, a higher value of the index means that an individual perceives outgroup members as supporting more extreme positions. We incentivized respondents to correctly predict the averages by oﬀering a $10 bonus for each statement to the person whose answer is the closest to the sample mean. Finally, we were interested in measuring the impact of the ad ﬁlter on partisan misconceptions. To that end, we asked participants to what extent (on a scale from 0-100) they agreed with ﬁve dubious statements that might be popular among Donald Trump’s supporters (see Appendix B.6). We calculated the partisan misconception index by taking the mean score across these statements. 2.7 Identiﬁcation Strategy 2.7.1 Challenges to Identiﬁcation To exploit the unique opportunity presented by Facebook’s introduction of the political ad ﬁlter, we needed to overcome several challenges to identiﬁcation. In Section 2.4.1, we introduced the issues anticipated at the design stage, chieﬂy the diﬃculty in verifying take-up of the treatment. While we cannot directly measure it for everyone in the main sample, we can do better than relying on self-reported information. Speciﬁcally, we use the ad diet data to estimate the ﬁrst stage regressions. ingroup and the outgroup. 41When computing the mean, if a statement supported the position advocated by the individual’s own party, we added the score. For those that were aligned with the view promoted by the opposing party, we added 100 minus the score. 42Whenever the statement was aligned with the stance of the outgroup party, we added the score. In the opposite case, we added 100 minus the score. 14 Electronic copy available at: https://ssrn.com/abstract=4003901 The drawback of this approach is that we can directly use the Wald estimator only with the extension sample, which has a smaller size and might not necessarily be a random subsample of the main sample (see Section 3.4 for discussion). Therefore, we propose a strategy to consistently estimate LATE using the ITT eﬀect estimated on the entire sample and the proportion of compliers estimated using a combination of noisy self-reports and the extension users’ ad diets. The rest of the section proceeds as follows. We ﬁrst outline our baseline ﬁrst stage speciﬁcations. Subsequently, we discuss our main strategy for estimating LATE, separately for turnout and survey outcomes. 2.7.2 First Stage Speciﬁcations We begin by introducing the essential notation. First, Zi = 1 if individual i received the encouragement to hide political ads, and 0 otherwise. Di is a binary variable indicating if individual i was treated (enabled the political ad ﬁlter). We further deﬁne Dz i where z = 0, 1. Dz i = 1 means that person i takes up the treatment if Zi = z. We partition individuals into four groups: compliers (D1 i − D0 i = 1), always-takers (D1 i = D0 i = 1), never-takers (D1 i = D0 i = 0), and deﬁers (D1 i − D0 i = −1). The variable Ti speciﬁes the group, denoted c, a, n, and d respectively. The take-up decision by person i is given by Di = D1 i Zi + D0 i (1 − Zi). Lastly, Y d,z i where (d, z) ∈ (0, 1)2 denote the outcome if Di = d and Zi = z, and Yi is the observed outcome. Under the standard assumptions,43 including the absence of deﬁers, the slope coeﬃcient α1 in the ﬁrst stage regression Di = α0 + α1Zi + ui identiﬁes the proportion of compliers P r(Ti = c). As we do not directly observe if participants enabled the political ad ﬁlter (Di), we use several speciﬁcations to estimate the proportion of compliers: (i) minimal, (ii) best-case, (iii) conservative, and (iv) preferred. They are described below in detail as well as summarized in Table 1. The minimal approach is based on self-reported turning on the speciﬁed ﬁlter. Immediately after displaying the encouragement in the intake survey, we inquired whether the participants “were able to change the settings”. We chose this wording to normalize non-compliance, and hence elicit the most truthful responses. In the treatment group (hide political ads), we considered a person treated (Di = 1) if they reported changing the ad settings as requested. We regarded all individuals in the control group (hide alcohol ads) as not treated (Di = 0), regardless of whether they reported enabling the alcohol ad ﬁlter or not. This is justiﬁed if all participants who received the encouragement to hide alcohol ads kept the political ad ﬁlter oﬀ (no always-takers). This assumption is not entirely implausible. We explicitly asked participants not to “hide ads on other topics”. Furthermore, the ﬁlter was not widely used and was hard to access, hence it is unlikely that people had any ad ﬁlters enabled prior to the study. Lastly, with the way Facebook phrased the category, it was not immediately clear to the 43See Assumptions 1, 2, 5 in Appendix A.1 (identiﬁcation notes). 15 Electronic copy available at: https://ssrn.com/abstract=4003901 users what exactly the option “Social issues, elections and politics” covers and what “seeing fewer” entails, which makes it less attractive. The advantage of the minimal speciﬁcation is that we can estimate LATE using the entirety of the main/survey sample. Nonetheless, we are aware that taking the self-reported information at face value and assuming that there are no always-takers can lead to overestimation of the proportion of compliers. Hence, we give more weight to speciﬁcations (ii)-(iv). Approaches (ii)-(iv) rely on the browser extension data to determine take-up Di. These methods are more trustworthy, as they are based on the actual ad diet of our participants. For each user, we have the number of political ads they saw during the study period. Our ITT regression results show that the encouragement to hide political ads substantially reduced exposure to political ads (see Section 3.1), which means that the ad ﬁlter is eﬀective, and working as Facebook advertised. Consequently, we can use the presence of political ads in the feed of the treatment group as evidence of non-compliance (Di = 0). However, for participants in both groups, the absence of political ads does not necessarily mean that they turned on the ad ﬁlter: it could be that they were simply not targeted by political ads, or they did not log on to Facebook from their desktop device a lot. Therefore, we need a strategy to decide whether or not a user who saw zero political ads indeed took-up the treatment (Di = 1). The best-case scenario is meant to provide an upper bound for the proportion of compliers. First, similar to the minimal method, we assume that nobody in the control group enabled the political ad ﬁlter (Di = 0). Second, we take the number of political ads at face value and consider participants in the treatment group as treated (Di = 1) if they saw no political ads. Conversely, the conservative approach provides a lower bound for the proportion of compliers. Here, we consider everyone in the control who saw zero political ads as treated (Di = 1) – this gives a generous estimate of the proportion of always-takers. For the treatment group, we classiﬁed participants as treated (Di = 1) if they did not see any political ads and saw a suﬃcient number of ads in general. This is helpful, because seeing zero political ads given very low exposure to all types of ads is not a reliable signal of enabling the ﬁlter. Hence, including the cutoﬀ makes our estimate of the proportion of compliers more conservative. We speciﬁed the cutoﬀ at the 10th percentile of the number of ads in the control (equal to 21.2). Now, we proceed to discuss our preferred speciﬁcation. For users who saw more ads than the cutoﬀ (21.2), we deﬁne take-up Di in the same way as in the conservative approach. However, we propose a more precise way of understanding why users with low exposure to ads (below the cutoﬀ) did not see political ads. In particular, we wanted to better distinguish between cases where the user was not targeted with political ads and those where it was a consequence of their decision regarding the implementation of the encouragement. To that end, we utilized a measure of expected exposure that 16 Electronic copy available at: https://ssrn.com/abstract=4003901 Table 1: Comparing First Stage Specifications Speciﬁcation Treatment Group Control Group Always Takers Possible? (i) minimal Di = 1 if they reported enabling the political ad ﬁlter Di = 0 No (ii) best-case Di = 1 if they saw zero political ads Di = 0 No (iii) conservative Di = 1 if they saw zero political ads and at least 22 ads in general Di = 1 if they saw zero political ads Yes (iv) preferred Di = 1 if they saw at least 22 ads and zero political ads Di = 1 if they saw fewer than 22 ads and saw zero political ads but were expected (Facebook Ad Library) to see more Yes Note: For each of the speciﬁcations, the table describes how take-up Di is deﬁned, separately for the treatment group (hide political ads) and the control group (hide alcohol ads). The last column shows if the speciﬁcation allows for always-takers. When determining take-up, speciﬁcations (iii) and (iv) additionally take into account exposure to all types of ads, not just political ads. This is because seeing zero political ads given very low exposure to ads in general may not be a reliable signal of enabling the ad ﬁlter. Finally, speciﬁcation (iv) relies on the measure of expected exposure to political ads calculated using data from the Facebook Ad Library (see the text). In cases of users who saw fewer than 22 ads and for whom we could not compute the expected exposure due to missing demographics, Di = 1 if they saw zero political ads. we calculated from the Facebook Ad Library data.44 The computed number of expected impressions is maximal – it includes all political ads from sponsors identiﬁed by our extension that are consistent with the user’s characteristics, and does not take into account user activity. Luckily, we do have a proxy for user activity on Facebook in the form of the total number of ads seen. Hence, to get a realistic number of impressions we employed the control group sample above the cutoﬀ (21.2) to train a model of impressions on the expected exposure, the total number of ads seen, and their interaction, as well as covariates required to calculate exposure using the Facebook Ad Library (state, sex, and age). We were then able to look at the participants below the cutoﬀ and check whether we predicted them to see more than zero political ads or not. In both the treatment and the control, we considered those who saw no political ads but were expected to see more as treated (Di = 1). 44The library enabled us to download all ads associated with sponsors identiﬁed by our extension during the period of the experiment. For each ad, the Facebook Ad Library includes some targeting information: age cohort, sex, and state distribution for “impressions” of the ad, as well as the lower and the upper bound for the number of impressions for each ad. Knowing the demographic characteristics of individuals in our sample, we were able to calculate their expected maximal exposure. We did so by counting the number of impressions for respective ads adjusted by the probability of being shown to that speciﬁc combination of age, location, and sex. Use the following link to learn more about the Facebook Ad Library Report https://www.facebook.com/ads/library/report, accessed 2021-07-21. 17 Electronic copy available at: https://ssrn.com/abstract=4003901 2.7.3 Estimating LATE on Turnout Following Imbens and Angrist (1994) and Chab´e-Ferret (2021),45 under the typical assumptions,46 the Wald estimator identiﬁes LATE, E (Y 1 i − Y 0 i |Ti = c ), whereas the slope coeﬃcient β1 in the regression Yi = β0 + β1Zi + vi identiﬁes ITT, E (Y D1 i i − Y D0 i i ). We employ this approach to estimate LATE using the main sample by relying on the minimal ﬁrst stage speciﬁcation. We also estimate it using the extension sample by means of speciﬁcations (ii)-(iv), where Di is based on the ad diet data. Ideally, we want to ﬁnd a way to estimate LATE using the main sample without having to rely on the minimal speciﬁcation. A potential solution would be to estimate the ﬁrst stage using the extension sample, and estimate the ITT regression with the main sample. LATE, denoted q, is given by q = β1 θ , ITT scaled by the proportion of compliers, denoted θ. In essence, we want to estimate the numerator and the denominator separately using diﬀerent samples, and derive the asymptotic distribution of the ratio. The drawback of this approach is that it requires assuming that the proportion of compliers among extension users is the same as in the broader pool of subjects. This does not hold, as there are fewer compliers among mobile users, likely due to higher diﬃculty of navigating tabs. Fortunately, we can provide a solution that requires a diﬀerent assumption. First, we deﬁne Pi as a binary variable which equals 1 if the user reported enabling the political ad ﬁlter. Note that Pi diﬀers from Di in the treatment due to potential misreporting. What is more, Pi = 0 for everyone in the control, even though Di = 1 is possible, as users could only report enabling the ﬁlter which they were encouraged to turn on. In Proposition 3 of our identiﬁcation appendix (Appendix A.1), we show that the proportion of compliers θ can be written as follows: θ = P r(Di = 1|Zi = 1, Pi = 1) × P r(Pi = 1|Zi = 1) − P r(Di = 1|Zi = 0). We can estimate the second term of the product using the main sample, and use the extension data to estimate the ﬁrst term. Now, the key required assumption is that the proportion of users who reported enabling the political ad ﬁlter when in fact they did not is the same for the extension users as in the broader pool of subjects (see Assumption 8). This is a much more plausible claim. Lastly, note that the third term in the equation identiﬁes the proportion of always-takers, which we also estimate using the extension data. The above observations allow us to propose the following LATE estimator ˆq = ˆβ1 ˆγ × ˆκ − ˆδ (1) where ˆβ1 is the OLS estimator of the slope in the regression of the outcome variable on a dummy 45Throughout the paper and in the appendix we follow the naming conventions and notation developed in Section 3.4 of Chab´e-Ferret (2021). 46See Assumptions 1, 2, 3, 4, 5 in Appendix A.1 (identiﬁcation notes). 18 Electronic copy available at: https://ssrn.com/abstract=4003901 equal to one if an individual was assigned treatment, ˆγ = 1 N ∑N i=1 PiZi 1 N ∑N i=1 Zi , ˆκ = 1 nv ∑nv i=1 DiZiPiBi 1 nv ∑nv i=1 ZiPiBi , ˆδ = 1 nv ∑nv i=1 Di(1−Zi)Bi 1 nv ∑nv i=1(1−Zi)Bi , Bi is a dummy equal to one if a person is an extension user, N is the full sample size, and nv is the size of the extension sample. In Appendix A.1, we show that despite diﬀerences in sizes of samples used to estimate the separate components, ˆq is a consistent estimator of LATE (see Proposition 7). Moreover, we derive (Proposi- tion 8) the asymptotic distribution of ˆq under the null hypothesis q = 0, √N ˆq d −→ N (0, Ωβ θ2 ). Note that we can use this strategy to estimate LATE with take-up determined by each of the four approaches outlined in Section 2.7.2. 2.7.4 Estimating LATE on Survey Outcomes Estimating the eﬀects of the ad ﬁlter on survey outcomes requires some modiﬁcations of our identiﬁca- tion strategy. This is the case, because we sent links to the follow-up survey only to those participants who reported enabling the political ad ﬁlter (in the treatment group) or the alcohol ad ﬁlter (in the control group), and thus fulﬁlled the requirements outlined in the intake survey. Recall that Pi = 1 if person i reported enabling the political ad ﬁlter, and 0 otherwise. Suppose further that Ai = 1 if i reported enabling the alcohol ad ﬁlter, and 0 otherwise. We can use our data to estimate ν = E(Yi|Zi = 1, Pi = 1) − E(Yi|Zi = 0, Ai = 1). In Appendix A.2, we show how to recover ITT in the absence of diﬀerential attrition (Proposition 9): ∆Y IT T = pν where p = P r(Pi = 1|Zi = 1) = P r(Ai = 1|Zi = 0). Now, we deﬁne ˆq = ˆν ˆp ˆθ (2) where ˆν is the OLS estimator of ν, and ˆθ is the estimator of the proportion of compliers. In Ap- pendix A.2, we argue that estimator ˆq is consistent for LATE (see Proposition 13). Additionally, we demonstrate (Proposition 11) that under the assumption that there are no always takers, ∆Y LAT E = ν κ . In that case, we derive the asymptotic distribution under the null (Proposition 14). If self-reported information regarding enabling the ad ﬁlter were fully trustworthy (κ = 1), then ˆν is consistent for LATE. This provides a clear interpretation for raw survey outcomes reported in Section 3.3. For speciﬁcations which do not exclude the possibility of always-takers, we estimate the standard errors using the bootstrap method. 2.7.5 Use of Controls For all of our regressions we use two types of speciﬁcations: with and without controls. For the main sample, our controls are age, state, and a dummy for using a mobile device to access the intake 19 Electronic copy available at: https://ssrn.com/abstract=4003901 survey. For the survey sample, we add the demographics obtained in the follow-up survey: income, education level, race, and a dummy for Hispanic origin. All numbers referenced in the text of the paper come from analysis performed without controls (as speciﬁed in the pre-registration plan). However, in regression tables, for the beneﬁt of those who are interested, we also include results with the controls. 3 Discussion of Results 3.1 Does Facebook Ad Filter Decrease Exposure to Political Ads? To examine the eﬀects of the Facebook ad ﬁlter on exposure to political ads, we look at the ad data for participants who installed our extension. As outlined in Section 2.6.1, we employed multiple methods of categorizing ads as political. Since we observed only ads displayed to participants when they used a web browser (rather than Facebook’s mobile app), the variation in the number of political ads induced by the intervention is likely even larger than what this section provides. According to our main classiﬁcation (which relies on the presence of the “paid for” information), the median number of political ads per person in the control (hide alcohol ads) was equal to 18, and the third quartile was 65.5. In the treatment (hide political ads), both quantities were equal to 0, as 86% of users did not see any political ads throughout the study period. Figure 2 depicts the cumulative distributions for both groups.47 Overall, 10% of all ads displayed to users in the control were political, whereas in the treatment the proportion was 1.6%. Regression results presented in Table 6 demonstrate that, on average, assignment of the encouragement to hide political ads reduced the number of political ads shown to users by 54. The three alternative classiﬁcations that we used to check robustness of the main one produced similar patterns. Results from all methods, summarized in Figure 9 and Table 6, indicate that enabling the ﬁlter signiﬁcantly reduces users’ exposure to political ads. In consequence, the experimental intervention resulted in considerable variation in exposure to political ads between the treatment and the control in the run-up to the presidential election. To better understand the nature of the induced diﬀerence between the two conditions, it is useful to analyze patterns of daily user activity. First, we found that most users had their extension enabled and kept receiving ads for the duration of the study. The median number of days between the last and the ﬁrst time a user was shown an ad is 18.5 (see Figure 10 for the distribution of the range). Heat maps shown in Figure 11 provide a more in-depth look, depicting days on which individual extension users received ads on their feed as well as what was their daily dose of political ads. The 47Here, we drop individuals who are below the 10th percentile in total ads seen in the control group (21.2), because seeing 0 political ads out of very few ads in total is not particularly meaningful. Results are similar without such a restriction, with the median number of political ads in the control group being 14 and the third quartile equal to 54. In the treatment group, 87% of users did not see any political ads. 20 Electronic copy available at: https://ssrn.com/abstract=4003901 5 ads 18 ads 65.5 ads 0.00 0.25 0.50 0.75 1.00 0 25 50 75 100 Political ads shownECDFEncouragement a a Hide Alcohol, N = 128 Hide Political, N = 133 Figure 2: Distribution of Political Ads Note: The plot depicts empirical cumulative distribution functions of the number of political ads displayed to extension users, separately for the treatment and the control. An ad was classiﬁed as political if it contained information on the sponsor who paid for it, a feature that identiﬁes ads on social issues, elections, or politics on Facebook. We look at the sample of those users who saw more ads in total than the 10th percentile of the control group (which was 21.2 ads). ﬁgure indicates that the vast majority of users were exposed to political ads on multiple days spanning across the study period. Importantly, the heat maps demonstrate that in the treatment group, despite much lower exposure to political ads, the pattern and frequency of user activity (receiving ads) was similar to the control group. What is more, we used input from manual coders to analyze party aﬃliation of ad sponsors in our sample. If the coders concluded that a sponsor is a candidate, that its main purpose is to support candidates from one of the parties, or that it explicitly supports (or donates money to) candidates, then they were subsequently asked to record the sponsor’s political aﬃliation. Using this approach, we were able to assign a party (either Republican or Democratic) supported by the sponsor to 71.8% of political ads.48 We found that for the vast majority of extension users in the control group, the proportion of ads that come from sponsors that support Democrats (as opposed to Republicans) was very high (0.977 for Democrats and 0.779 for Republicans). For the median user who received at least 5 ads from sponsors aﬃliated with a political party, the proportion was 0.9 (Figure 12 depicts the full 48The authors manually reviewed all cases in which the coders disagreed or only one coder found information. 21 Electronic copy available at: https://ssrn.com/abstract=4003901 distribution). Thus, the experimental intervention resulted in the control group being relatively more exposed to political ads in general and ads supporting Democrats speciﬁcally. Table 2: Turnout Regressions Panel A: IV Regressions OLS instrumental variable ITT Minimal Conservative Best-Case Preferred (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) Assignment −.023 −.027 (.026) (.025) Treated −.037 −.044 −.018 −.062 −.012 −.042 −.016 −.055 (.041) (.041) (.098) (.106) (.065) (.071) (.086) (.094) Controls? No Yes No Yes No Yes No Yes No Yes N 1,315 1,305 1,315 1,305 233 232 233 232 233 232 Panel B: Estimates Based on Our Estimator (1) Minimal Conservative Best-Case Preferred (3) (4) (5) (6) (7) (8) (9) (10) Treated −.000 −.000 −.036 −.042 −.071 −.084 −.041 −.048 −.061 −.072 Assignment (.040) (.040) (.079) (.078) (.045) (.045) (.068) (.067) Controls? No Yes No Yes No Yes No Yes Note: Column 1 in Panel A presents an OLS regression of a dummy equal to one if the individual voted in the election (according to their voter ﬁle) on a dummy equal to one if the individual was assigned the encouragement to hide political ads. The regression was estimated using all observations in the main sample for whom we found a matching voter ﬁle. Column 2 in Panel A presents the same regression but with controls (age, state, and a dummy for using a mobile device to access the intake survey). Columns 3-10 in Panel A present regressions of a dummy variable equal to one if the individual voted in the election (according to their voter ﬁle) on a dummy equal to one if the individual was classiﬁed as treated (enabled the political ad ﬁlter). The latter was instrumentated with a dummy equal to one if the individual was assigned the encouragement to hide political ads. Regressions in Columns 3-4 in Panel A were estimated with the sample of all participants for whom we found a matching voter ﬁle. Regressions in Columns 5-10 in Panel A were estimated using the sample of extension users with a matching voter ﬁle. Columns 4, 6, 8, 10 additionally included the controls. Point estimates presented in Panel B correspond to estimator (1): ˆq = ˆβ1 ˆγ×ˆκ−ˆδ . We explain each variable in turn. First, ˆβ1 is the OLS estimator of the slope in ITT regression (Columns 1-2 in Panel A). Furthermore, ˆγ = 1 N ∑N i=1 PiZi 1 N ∑N i=1 Zi , ˆκ = 1 nv ∑nv i=1 DiZiPiBi 1 nv ∑nv i=1 ZiPiBi , ˆδ = 1 nv ∑nv i=1 Di(1−Zi)Bi 1 nv ∑nv i=1(1−Zi)Bi , where N = 1587 is the full sample size and nv = 288 is the size of the extension sample. In the case of both Panel A and Panel B, Columns 3-4 correspond to the minimal speciﬁcation. Individuals in the treatment group were classiﬁed as treated if they self-reported enabling the political ad ﬁlter. Columns 5-6 pertain to the conservative speciﬁcation. Individuals in the treatment were classiﬁed as treated if the extension data indicated that they saw zero political ads. All individuals in the control were considered as not treated. Columns 7-8 correspond to the best-case speciﬁcation. Individuals in the treatment were considered treated if they saw zero political ads and saw at least 22 ads in general. All individuals in the control group who saw zero political ads were also considered treated. Columns 9-10 pertain to the preferred speciﬁcation. All individuals who saw at least 22 ads and zero political ads were considered treated. Moreover, all individuals who saw fewer than 22 ads and saw zero political ads but were expected (Facebook Ad Library) to see more were classiﬁed as treated. Standard errors are provided in brackets. Standard errors for Panel B are based on the asymptotic distribution derived in Appendix A.1. ∗ signiﬁcant at 10%; ∗∗ signiﬁcant at 5%; ∗∗∗ signiﬁcant at 1%; 22 Electronic copy available at: https://ssrn.com/abstract=4003901 3.2 Does Facebook Ad Filter Aﬀect Turnout? We begin by reporting the ﬁrst stage regressions using all four speciﬁcations described in Section 2.7.2. Table 7 presents the results, with the estimates of the proportion of compliers ranging from 60% compliance (the most conservative) to 87% (the most optimistic). To examine the eﬀect of the ad ﬁlter on turnout, we estimated a series of regressions reported in Panel A of Table 2. These include the ITT regressions, and the IV regressions estimating LATE. Columns of the table correspond to diﬀerent ﬁrst stage speciﬁcations outlined in Section 2.7.2. All give negative point estimates, ranging from −1 to −6 pp. The intervention reduced exposure to political ads, which in turn lowered turnout, albeit insigniﬁcantly. In other words, those in the control group – who saw more political ads – were more likely to vote. In Panel B of Table 2 we report results based on our most reliable estimator of LATE, deﬁned in Equation 1 in Section 2.7.3, which allows us to utilize the ITT regression estimated on the full sample. They point in the same direction. In the best case speciﬁcation, which uses the upper bound for the proportion of compliers, we obtain the point estimate of −4.1 pp. Conversely, the conservative approach, relying on the lower bound for the proportion of compliers, gives the point estimate of −7.2 pp. Our preferred speciﬁcation, which is still quite conservative in classifying participants as compliers, results in the eﬀect of −6.2 pp., while the minimal approach estimates LATE to be −3.6 pp. Lastly, we found the distribution of modality of voting to be similar across treatment groups — see Figure 13.49 A natural extension of looking at the impact of the ad ﬁlter on turnout is to investigate its eﬀects on voting decisions. Using the survey sample, we estimated LATE of the ad ﬁlter on the likelihood of voting for the Trump/Pence presidential ticket to be 6.3 pp. according to our preferred speciﬁcation. Given that the participants’ ad diet was predominantly pro-Democratic, this indicates that seeing more such ads reduced the probability of voting for Trump, although the estimates are insigniﬁcant and based on self-reported data. 3.2.1 Turnout by Party Aﬃliation We continue analyzing the impact of the ad ﬁlter on turnout by exploring the possibility of a heteroge- neous eﬀect by party aﬃliation. We use party aﬃliation elicited in the follow-up survey to estimate the regression of a dummy variable equal to one if a person voted (Yi) on assignment (Zi), a dummy equal to one if a person is a Republican (Ri), and the interaction of assignment and the Republican dummy (Zi × Ri). Table 3 demonstrates the results (Columns 3-4), alongside with regressions of Yi on Zi estimated separately for Democrats (Columns 5-6) and Republicans (Columns 7-8). Using the survey 49It is insightful to compare this to the self-reported voting time shown in Figure 14. 23 Electronic copy available at: https://ssrn.com/abstract=4003901 Table 3: Effect on Turnout by Party Affiliation General Interaction Democrats Republicans (1) (2) (3) (4) (5) (6) (7) (8) Assignment .027 .004 −.041 −.066 −.041 −.071 .140∗∗ .128∗ (.072) (.037) (.047) (.047) (.048) (.049) (.060) (.068) Republican −.065 −.087 (.055) (.056) Assignment× Republican .181∗∗ .193∗∗ (.077) (.078) Controls? No Yes No Yes No Yes No Yes Observations 605 603 605 603 381 381 224 222 Note: Columns 1-2 present regressions of a dummy variable equal to one if the individual voted in the in the election (according to their voter ﬁle) on a dummy equal to one if the individual was assigned the encouragement to hide political ads. The regression was estimated on the sample of people who completed the follow-up survey. Columns 5-6 present the same regression estimated with the subset of the survey sample consisting of people who self-identiﬁed as Democrats. Columns 7-8 pertain to the same speciﬁcation but estimated with the subset of the survey sample consisting of people who self-identiﬁed as Republicans. Columns 3-4 present regressions of a dummy equal to one if the individual voted in the in the election on a dummy equal to one if the individual was assigned the encouragement to hide political ads, a dummy equal to one if the person self-identiﬁed as a Republican, and the interaction of the latter two dummy variables. These regressions were estimated with the survey sample. Regressions in Columns 2, 4, 6, 8 also included controls (age, state, a dummy for using a mobile device to access the intake survey, income, education level, race, and a dummy for Hispanic origin). We report heteroskedasticity-robust standard errors in brackets. ∗ signiﬁcant at 10%; ∗∗ signiﬁcant at 5%; ∗∗∗ signiﬁcant at 1%; sample, we estimate that the eﬀect of seeing more political ads (control group) is associated with a reduction in turnout by 14 pp. among Republicans and an increase in turnout among Democrats by 4.1 pp. We acknowledge the limitations in interpreting this ﬁnding, not least because the regressions were estimated using the survey sample, as they necessitated party aﬃliation.50 It is important to note that enabling the ad ﬁlter reduced exposure to political ads that were predominantly supporting Democrats. The extension data shows that this was the case even for Republicans (see Section 3.1). Thus, the result is consistent with the interpretation that seeing more ads supporting Democrats (control group) had a demobilizing eﬀect on Republicans but a mildly mobilizing eﬀect on Democrats. 3.3 Does Facebook Ad Filter Aﬀect Polarization and Beliefs? 3.3.1 Descriptive Statistics We now turn our attention to the measures obtained in the follow-up survey. Many of the survey questions referred to the outgroup political party, so we began by eliciting political alignment. About two-thirds of our sample self-identiﬁed as Democrats or were leaning Democrats. This is in line with 50As we discussed in Section 2.7.4, the regression of Yi on Zi using the survey sample identiﬁes LATE (Columns 1-2 of Table 3) in the absence of diﬀerential attrition, when there are no always-takers, and participants self-reports on changing the ad settings are truthful. 24 Electronic copy available at: https://ssrn.com/abstract=4003901 the fact that the population of Facebook users is “substantially more liberal than the representative sample” (Boas et al. (2020)). We also had a wide distribution within each group, as evidenced by Figure 15. The distribution of policy opinions followed our expectations (see Figure 16). Democrats were much more positive about the idea of introducing free healthcare and defunding the police. They were more critical of the response of the Federal Government to the pandemic. Furthermore, Republicans were much more likely to agree with the statement that abortion should be restricted in the ﬁrst trimester. Both groups seemed to be neutral on the issue of court packing, perhaps reﬂecting the fact that the outcome of such procedure is not immediately evident to the general public. We also looked at beliefs regarding these policy opinions: incentivized subjects tried to predict the opinions of people with the opposite political alignment (Figure 17). Interestingly, Republican respondents were much more accurate in their predictions than Democrats, with the median diﬀerence of 3 vs. 13 points. This is strikingly clear in Figure 18. The partisan misconception index (Figure 19) appears to be somewhat similar across the political divide. It is – with respect to statements about Biden’s intentions for the Supreme Court, support for defunding the Police, and advocating for radical left policies. Where Democrats and Republicans do diﬀer is in agreement with the statement about Biden’s poor health, and his plans to increase taxes.51 Lastly, the diﬀerence by political alignment in the splitting of one dollar in the Dictator game was at $0.47 (Democrats) and $0.5 (Republicans) and in the feeling thermometer – 42 (Democrats) and 50 (Republicans). 3.3.2 LATE Estimates There does not appear to be an eﬀect of the ad ﬁlter on any of the survey outcomes. Columns (1) and (2) in Table 8 show OLS estimates of the with/without comparison ν deﬁned in Section 2.7.4. Under the assumption that participants’ self-reported information regarding changing the ad settings is correct and in the absence of always takers, the estimator directly identiﬁes LATE. To relax both assumptions, we proposed the estimator deﬁned in Equation 2 in Section 2.7.4. Table 9 provides point estimates of LATE based on diﬀerent ﬁrst stage speciﬁcations, with bootstrapped standard errors. Furthermore, columns (3) and (4) in Table 8 give LATE estimates for the best-case ﬁrst stage with standard errors based on the asymptotic distribution derived in Appendix A.2. According to our preferred speciﬁcation in Table 9, for the dictator game split of one dollar, 51The last two statements are slightly more subjective. While a Democrat may argue that there is no hard evidence of Biden’s poor health in the form of a published medical opinion, a Republican could retort that there are other indications that can also be relied upon. Similarly, with taxes, while Biden may not be proposing a tax increase, a Republican could infer that his policies would require a tax hike. 25 Electronic copy available at: https://ssrn.com/abstract=4003901 the eﬀect of the ad ﬁlter (which reduced exposure to political ads) is at 2.4 cents, on the feeling thermometer: −0.9 out of 100, policy views index: −0.07 out of 100, prediction index about outgroup’s policy views: −2.4 out of 100, partisan misconception index: −3 out of 100, and the overall diﬀerence between ingroup and outgroup word associations is not signiﬁcant at 0.38 out of 5. 3.4 Robustness Checks and Potential Concerns A serious concern for survey outcomes is potential diﬀerential attrition. We recorded that 372 people completed the follow-up survey in the treatment group and 386 in the control. Regressing completion of the follow-up survey on encouragement assignment reveals no statistically signiﬁcant eﬀect (p-value of 0.525 in the two-sided test). What is more, we compare the predictive power of (i) a regression of the take-up of the follow-up survey on encouragement and its interactions with the set of available covariates (age, device type, time spent on the intake survey, and state) to (ii) a regression without the encouragement dummy or its interactions. The comparison, presented in Table 10, does not yield any indication of diﬀerential attrition. Additionally, we address the concern that after seeing the assigned encouragement, diﬀerent types, if not numbers, of participants may drop out of the study. To refute the most plausible channels that could result in such occurrence, we designed the political engagement survey. In Table 12, we demonstrate attrition balance by assignment. We show that people who dropped out of the study from from the treatment group and the control group are not signiﬁcantly diﬀerent from each other based on interest in politics, news consumption, hypothetical Congress vote, age, and time spent on the intake survey. Diﬀerences in mean outcomes are small, with all p-values above 0.46. Finally, we redo the F-test from Table 10 with the addition of variables from the political engagement survey. The results, presented in Table 11, do not change. Lastly, a question may be posed about how diﬀerent the extension users in our sample are from non-extension users and how this aﬀects our inference. We expected extension users to diﬀer on a number of correlated covariates from those who did not install it (see the breakdown for our sample in Table 15).52 To address this, our identiﬁcation strategy did not rely on the assumption that the proportion of compliers among extension users and non-extension users is the same. We only used the extension sample to estimate the proportion of people who enabled the ad ﬁlter conditional on self-reporting that they did. 52While to our knowledge there is no demographic data for extension use in general, our results are in line with what is known about using a popular type of extension, ad blocker: their users are younger and more likely to be male (https://backlinko.com/ad-blockers-users, accessed: 2021-09-19). 26 Electronic copy available at: https://ssrn.com/abstract=4003901 4 Conclusion Exploiting the introduction of an obscure feature that allows users to hide political ads from their Face- book feed, we attempted to shed light on the eﬀects of ads on political behavior. After demonstrating the eﬀectiveness of the ﬁlter in reducing exposure to political ads, we found the eﬀect on turnout to be negative yet insigniﬁcant, and the eﬀect on a number of survey measures related to aﬀective polarization and informedness – negligible. Furthermore, we discovered that the eﬀect on turnout was heterogeneous with respect to self-reported party aﬃliation. In particular, political ads – which in our sample were overwhelmingly pro-Democratic – were associated with a strong demobilizing eﬀect on Republicans and a more modest mobilizing eﬀect on Democrats. We hope that this observation will inspire future research exploring the complex relationship between political advertisement and voting behavior. Lastly, veriﬁcation of the ﬁrst stage – that the encouragement and the ad ﬁlter work – in and as of itself is a valuable contribution, which was made even more important with the recent moves by Facebook to restrict the ability of researchers to collect the ad diet of users. Our encouragement design remains a viable option for researchers, without having to risk a conﬂict with any of the social media platforms. References Allcott, H., L. Braghieri, S. Eichmeyer, and M. Gentzkow (2020): “The welfare eﬀects of social media,” American Economic Review, 110, 629–76. Boas, T. C., D. P. Christenson, and D. M. Glick (2020): “Recruiting large online samples in the United States and India: Facebook, mechanical turk, and qualtrics,” Political Science Research and Methods, 8, 232–250. Broockman, D. E. and D. P. Green (2014): “Do online advertisements increase political candi- dates’ name recognition or favorability? Evidence from randomized ﬁeld experiments,” 36, 263–289. Chab´e-Ferret, S. (2021): Statistical Tools for Causal Inference, https://chabefer.github.io/STCI, accessed 2021-09-25. Coppock, A., S. J. Hill, and L. Vavreck (2020): “The small eﬀects of political advertising are small regardless of context, message, sender, or receiver: Evidence from 59 real-time randomized experiments,” Science advances, 6, eabc4046. DellaVigna, S. and M. Gentzkow (2010): “Persuasion: empirical evidence,” Annu. Rev. Econ., 2, 643–669. 27 Electronic copy available at: https://ssrn.com/abstract=4003901 Fowler, E. F., M. M. Franz, G. J. Martin, Z. Peskowitz, and T. N. Ridout (2021): “Political advertising online and oﬄine,” American Political Science Review, 115, 130–149. Fujiwara, T., K. M¨uller, and C. Schwarz (2021): “The eﬀect of social media on elections: Evidence from the United States,” Tech. rep., National Bureau of Economic Research. Gerber, A. S., J. G. Gimpel, D. P. Green, and D. R. Shaw (2011): “How large and long-lasting are the persuasive eﬀects of televised campaign ads? Results from a randomized ﬁeld experiment,” American Political Science Review, 105, 135–150. Imbens, G. W. and J. D. Angrist (1994): “Identiﬁcation and Estimation of Local Average Treat- ment Eﬀects,” Econometrica, 62, 467–475. Iyengar, S., Y. Lelkes, M. Levendusky, N. Malhotra, and S. J. Westwood (2019): “The origins and consequences of aﬀective polarization in the United States,” Annual Review of Political Science, 22, 129–146. Kalla, J. L. and D. E. Broockman (2018): “The minimal persuasive eﬀects of campaign contact in general elections: Evidence from 49 ﬁeld experiments,” American Political Science Review, 112, 148–166. Krasno, J. S. and D. P. Green (2008): “Do televised presidential ads increase voter turnout? Evidence from a natural experiment,” The Journal of Politics, 70, 245–261. Levy, R. (2021): “Social media, news consumption, and polarization: Evidence from a ﬁeld experi- ment,” American Economic Review, 111, 831–70. Liberini, F., M. Redoano, A. Russo, A. Cuevas, and R. Cuevas (2020): “Politics in the Facebook Era-Evidence from the 2016 US Presidential Elections,” . Ribeiro, F. N., K. Saha, M. Babaei, L. Henrique, J. Messias, F. Benevenuto, O. Goga, K. P. Gummadi, and E. M. Redmiles (2019): “On microtargeting socially divisive ads: A case study of russia-linked ad campaigns on facebook,” in Proceedings of the conference on fairness, accountability, and transparency, 140–149. Sances, M. W. (2021): “Missing the Target? Using Surveys to Validate Social Media Ad Targeting,” Political Science Research and Methods, 9, 215–222. Spenkuch, J. L. and D. Toniatti (2018): “Political advertising and election results,” The Quarterly Journal of Economics, 133, 1981–2036. 28 Electronic copy available at: https://ssrn.com/abstract=4003901 Witzleb, N., M. Paterson, and J. Richardson (2019): Big data, political campaigning and the law: Democracy and privacy in the age of micro-targeting, Routledge. Zhuravskaya, E., M. Petrova, and R. Enikolopov (2020): “Political eﬀects of the internet and social media,” Annual Review of Economics, 12, 415–438. 29 Electronic copy available at: https://ssrn.com/abstract=4003901 Figures Figure 3: Examples of Ads from Different Campaigns Note: We ran two slightly diﬀerent ad campaigns: “Regular” and “Extension”. The former (see the left panel) was targeted at both mobile and desktop users and promised a chance to win $100 for completing the intake survey as well as a certain reward for participating in both the intake and the follow-up surveys. It did not mention learning about who targets the user with ads. The “Extention” campaign (see the right panel) was similar to the “Regular”, with the exception of (i) being targeted only at desktop users, and (ii) requiring them to install the extension as part of the study (instead of oﬀering it to them as an add-on). As an additional incentive for installing the extension, users in both campaigns were oﬀered a perk in the form of a personalized report on how the user was targeted with ads. 30 Electronic copy available at: https://ssrn.com/abstract=4003901 Figure 4: The Extension Page in the Chrome Store Figure 5: Extension Alert 31 Electronic copy available at: https://ssrn.com/abstract=4003901 Figure 6: A GIF Image Explaining How to Hide Political Ads Responses 1 to 20 21 to 40 41 to 60 61 to 80 81 to 100 101 to 120 121 to 141 Figure 7: Responses by State in the Main Sample Note: The map depicts the number of observations in the main sample (N = 1587) by state. 32 Electronic copy available at: https://ssrn.com/abstract=4003901 Figure 8: Distinguishing Between Types of Facebook Ads Note: For demonstrative purposes we highlighted three distinct elements of Facebook ads, as identiﬁed by our extension, in diﬀerent colors: (i) name, (ii) sponsor bar, and (iii) ad text. Political ads contrast with standard ads due to the unique structure of their sponsor bar. It contains additional information on who paid for the campaign. In the case of the ad displayed in the left panel, the name on the ad is Donald J. Trump and the speciﬁc sponsor is Trump Make America Great Again Committee. The sponsor bar for the non-political ad in the right panel contains only the word Sponsored. The browser extension does not alter user experience on Facebook. In particular, all ads are displayed in the same way for users who installed the extension and those who did not. 33 Electronic copy available at: https://ssrn.com/abstract=4003901 7033 960 9039 1330 4585 988 2016 248 Coders Facebook Keyword Wesleyan 0 2500 5000 7500 Ad classificationTotal political ads Encouragement Hide Alcohol Hide Political Figure 9: Total Number of Political Ads Note: The bar plot shows the total number of political ads per group identiﬁed according to four diﬀerent classiﬁcations. Starting from the left, the bar plots correspond to the following categorization methods: (i) Coder’s categorization which classiﬁes an ad as political if its sponsor was a candidate, explicitly supported (or donated money to) candidates, advocated for a policy issue, focused on encouraging turnout, or supported a particular ballot measure; (ii) Facebook’s categorization in which an ad was classiﬁed as political if it contained information on the sponsor who paid for it; (iii) Keyword categorization in which an ad was categorized as political if the ad text contained one of the speciﬁed keywords associated with elections and politics (see Footnote 37); (iv) Wesleyan categorization in which an ad was classiﬁed as political if the sponsor was on the list of the main presidential campaign sponsors (top spenders) provided by the Wesleyan Media Project. The graph is based on the extension sample data (N = 288), with N = 145 users assigned to the treatment group and N = 143 assigned to the control group. 0 10 20 0 10 20 30 Time RangeCount Figure 10: Number of Days Between the Last and the First Activity. Note: The plot depicts a histogram of the number of days between the last time and the ﬁrst time that a user received ads according to the browser extension data. The dashed line marks the median value. The graph is based on the extension sample data (N = 288). 34 Electronic copy available at: https://ssrn.com/abstract=4003901 Oct 05 Oct 12 Oct 19 Oct 26 Nov 02Users (arranged by # days online) Hide Alcohol Oct 05 Oct 12 Oct 19 Oct 26 Nov 02 Political ads Not active 0 1−4 5−9 10+ Hide Political Figure 11: Daily User Activity and Exposure to Political Ads. Note: Each horizontal segment represents one extension user and is divided into blocks corresponding to individual days (horizontal axis). The users are ordered by the number of days on which the extension detected their activity on Facebook (with more active users closer to the top). The colored blocks represent days on which at least one ad was displayed to the user. The color depends on the number of political ads shown on a given day. An ad was classiﬁed as political if it contained information on the sponsor who paid for it, a feature that identiﬁes ads on social issues, elections, or politics on Facebook. The graph is based on the extension sample data (N = 288), with N = 145 users assigned to the treatment group and N = 143 assigned to the control group. 35 Electronic copy available at: https://ssrn.com/abstract=4003901 0.00 0.25 0.50 0.75 1.00 UsersProportion of Ads from Sponsors Supporting Democrats Affiliated Ads 1−49 50−99 100−199 200+ Figure 12: Individual Diet of Ads From Politically Affiliated Sponsors Note: The graph is based on ads from politically aﬃliated sponsors — those which were paid for by sponsors coded to either support Democrats or Republicans. Each bar pertains to one individual from the control group (hide alcohol ads) and depicts the proportion of such ads that come from sponsors that support Democrats (rather than Republicans). The median proportion equals 0.928 (N = 107). The median for users who self-identiﬁed as Democrats in the survey is 0.977 (N = 59), whereas for Republicans it is 0.779 (N = 23). When taking into account only those users who saw at least 5 ads from politically aﬃliated sponsors, the median proportion equals 0.9 (N = 87). Absentee Early vote Mail No vote Polling Unknown 0 50 100 150 200 CountVoter File Record Encouragement Hide Alcohol Hide Political Figure 13: Distribution of Voter File Records Note: Individuals who did not vote in the election are recorded as “No vote”. All other categories correspond to diﬀerent modalities of voting. The category “Unknown” indicates that the person voted but the modality was not recorded. The graph is based on the voter ﬁles data (N = 1315), with N = 670 observations from the treatment group and N = 645 from the control group. 36 Electronic copy available at: https://ssrn.com/abstract=4003901 Did not vote More than two weeks before the Election Day Two weeks before the Election Day During the week before the Election Day On the Election Day 0 25 50 75 100 CountVote DateEncouragement Hide Alcohol Hide Political Figure 14: Distribution of Voting Dates Note: The graph depicts the distribution of responses to the survey question on whether and, if so, when the participants voted. The graph is based on the survey sample data (N = 763) with N = 388 observations from the treatment group and N = 375 from the control group. Republican (Strong) Republican (Not Strong) Independent (Leaning Republican) Independent (Leaning Democrat) Democrat (Not Strong) Democrat (Strong) 0 25 50 75 CountAlignmentEncouragement Hide Alcohol Hide PoliticalFigure 15: Distribution of Self-Reported Political Alignment Note: The graph depicts the self-reported political alignment elicited at the beginning of the follow-up survey. First, respondents were asked if they usually think of themselves as Republicans, Democrats, or Independents. If they chose either of the ﬁrst two options, they were asked if they would call themselves a strong Republican/Democrat or not a strong Republican/Democrat. If they selected the latter option, they were asked to indicate if they think of themselves as closer to Republicans or Democrats. The graph is based on the survey sample data (N = 763) with N = 388 observations from the treatment group and N = 375 from the control group. 37 Electronic copy available at: https://ssrn.com/abstract=4003901 Abortion Court Covid Healthcare PoliceDemocratRepublican 0 25 50 75 100 0 25 50 75 100AgreementEncouragement Hide Alcohol Hide Political Figure 16: Distribution of Policy Opinions Note: We asked respondents to what extent do they agree with the following statements: “Access to abortion during the ﬁrst trimester should be restricted”, “We should increase the number of Supreme Court justices”, “Response of the Federal Government to the Covid-19 pandemic was adequate”, “Free health care for everyone is a good policy”, “We need to reduce police funding”. The lower and upper hinges of the box plots refer to the ﬁrst and the third quartile respectively, whereas the horizontal segment within each box plot depicts the median. Outliers shown in the ﬁgure correspond to observations which were not within 1.5 interquartile range from hinges. The graph is based on the survey sample data (N = 763) with N = 388 observations from the treatment group and N = 375 from the control group. Abortion Court Covid Healthcare PoliceDemocratRepublican 0 25 50 75 100 0 25 50 75 100PredictionEncouragement Hide Alcohol Hide Political Figure 17: Distribution of Beliefs about Policy Opinions Note: The upper panel shows Democrats’ predictions of Republicans’ mean agreement with the statements listed in Figure 16, whereas the lower panel depicts Republicans’ predictions of the mean responses among Democrats. The lower and upper hinges of the box plots refer to the ﬁrst and the third quartile respectively, whereas the horizontal segment within each box plot depicts the median. Outliers shown in the ﬁgure correspond to observations which were not within 1.5 interquartile range from hinges. The graph is based on the survey sample data (N = 763) with N = 388 observations from the treatment group and N = 375 from the control group. 38 Electronic copy available at: https://ssrn.com/abstract=4003901 Abortion Court Covid Healthcare PoliceDemocratRepublican −50 0 50 −50 0 50DifferenceEncouragement Hide Alcohol Hide Political Figure 18: Distribution of Differences in Beliefs about Policy Opinions Note: This graph shows the distribution of the diﬀerence between predictions about the opposing party supporters’ mean agreement level with the statements listed in Figure 16 and the actual mean value. The lower and upper hinges of the box plots refer to the ﬁrst and the third quartile respectively, whereas the horizontal segment within each box plot depicts the median. Outliers shown in the ﬁgure correspond to observations which were not within 1.5 interquartile range from hinges. The graph is based on the survey sample data (N = 763) with N = 388 observations from the treatment group and N = 375 from the control group. Court Police Radical Stamina TaxesDemocratRepublican 0 25 50 75 100 0 25 50 75 100AgreementEncouragement Hide Alcohol Hide PoliticalFigure 19: Distribution of Factual Knowledge Note: We asked respondents to what extent do they agree with the following statements: “Joe Biden wants to increase the number of Supreme Court justices”, “Joe Biden and Kamala Harris support defunding the police”, “Joe Biden supports policies advocated by the radical left.”, “Joe Biden lacks stamina and has poor health”, “Raising taxes is a part of Joe Biden’s program”. The lower and upper hinges of the box plots refer to the ﬁrst and the third quartile respectively, whereas the horizontal segment within each box plot depicts the median. Outliers shown in the ﬁgure correspond to observations which were not within 1.5 interquartile range from hinges. The graph is based on the survey sample data (N = 763) with N = 388 observations from the treatment group and N = 375 from the control group. 39 Electronic copy available at: https://ssrn.com/abstract=4003901 Tables Table 4: Main Sample Balance Hide Alcohol (N=795) Hide Political (N=792) Mean Std. Dev. Mean Std. Dev. Diﬀ. in Means p Age 45.555 17.244 46.501 16.806 0.945 0.271 TimeOnSurvey1 563.635 3407.797 436.692 3955.404 -126.943 0.494 Mobile 0.712 0.453 0.715 0.452 0.003 0.906 CongressVoteDem 0.709 0.455 0.681 0.467 -0.027 0.490 InterestInPolitics 6.224 2.882 6.482 2.760 0.258 0.250 NewsConsumption 6.815 6.025 7.000 5.946 0.185 0.697 Note: The variables were collected during the intake survey. The political engagement survey (a dummy for hypothetically voting Democrats for Congress, interest in politics on a scale from 0 to 10, and average news consumption in hours) comes from a subset of the main sample consisting of 634 respondents. Time spent on the intake survey was measured in seconds. Table 5: Survey Sample Balance Hide Alcohol (N=386) Hide Political (N=372) Mean Std. Dev. Mean Std. Dev. Diﬀ. in Means p Male 0.33 0.47 0.37 0.48 0.04 0.23 Age 39.59 15.23 41.27 15.33 1.68 0.13 TimeOnSurvey1 540.67 3756.63 292.28 617.97 -248.39 0.20 TimeOnSurvey2 1007.22 6129.45 925.71 4196.59 -81.51 0.83 Mobile 0.66 0.48 0.58 0.49 -0.08 0.03 NewsConsumption 6.75 6.08 6.95 5.70 0.20 0.74 CongressVoteDem 0.69 0.46 0.62 0.49 -0.07 0.19 White 0.78 0.41 0.77 0.42 -0.02 0.59 IncomeLessThan50k 0.47 0.50 0.41 0.49 -0.06 0.08 AboveBachelor 0.49 0.50 0.53 0.50 0.04 0.27 Hispanic 0.05 0.21 0.08 0.28 0.04 0.04 Note: Age and the time spent on the intake survey (TimeOnSurvey1 ) were collected during the intake survey. The political engagement survey (a dummy for hypothetically voting Democrats for Congress, interest in politics on a scale from 0 to 10, and average news consumption in hours) was also conducted during the intake survey. Here, we report values for 368 respondents who took the political engagement survey and completed the follow-up survey. The remaining variables, including the time spent on the follow-up survey (TimeOnSurvey2 ), were collected during the follow-up survey. 40 Electronic copy available at: https://ssrn.com/abstract=4003901 Table 6: Effect of Encouragement on Ad Exposure Facebook Wesleyan Keyword Coders (1) (2) (3) (4) (5) (6) (7) (8) Assignment −54.04 ∗∗∗ −60.54 ∗∗∗ −12.39∗∗∗ −13.57∗∗∗ −25.25∗∗∗ −30.76∗∗∗ −42.56∗∗∗ −48.32∗∗∗ (12.12) (14.25) (3.54) (3.52) (6.69) (8.76) (9.67) (11.44) Controls? No Yes No Yes No Yes No Yes N 288 283 288 283 288 283 288 283 Note: The table presents regressions of the number of political ads recorded by the extension for a particular user on a dummy equal to one if the individual was assigned the encouragement to hide political ads, and in the case of regressions in Columns 2, 4, 6, and 8 also on a set of controls (age, state, a dummy for using a mobile device to access the intake survey). Columns 1-2 correspond to the speciﬁcation in which an ad was classiﬁed as political if it contained information on the sponsor who paid for it. For the purpose of regressions in Columns 3-4 an ad was classiﬁed as political if the sponsor was on the list of the main presidential campaign sponsors (top spenders) provided by the Wesleyan Media Project. Columns 5-6 pertain to the speciﬁcation in which an ad was categorized as political if the ad text contained one of the speciﬁed keywords associated with elections and politics (“Trump”, “vote”, “voting”, “Biden”, “sleepy Joe”, “president”, “ballots”, “judge”, “in oﬃce”, “politician”, “Congress”, “Senate”, “defund the police”, “election”, “Supreme Court”, “governor”, “Democratic party”, “Republican party”, “ballot”). Columns 7-8 present regressions in which an ad was classiﬁed as political if its sponsor was a candidate, explicitly supported (or donated money to) candidates, advocated for a policy issue, focused on encouraging turnout, or supported a particular ballot measure. We report heteroskedasticity-robust standard errors in brackets. ∗ signiﬁcant at 10%; ∗∗ signiﬁcant at 5%; ∗∗∗ signiﬁcant at 1%. Table 7: Proportion of Compliers Minimal Conservative Best-Case Preferred (1) (2) (3) (4) (5) (6) (7) (8) Assignment .643∗∗∗ .646 ∗∗∗ .597 ∗∗∗ .624∗∗∗ .869∗∗∗ .870 ∗∗∗ .653 ∗∗∗ .674 ∗∗∗ (.017) (.017) (.047) (.052) (.028) (.033) (.045) (.049) Controls? No Yes No Yes No Yes No Yes Observations 1,587 1,566 288 283 288 283 288 283 Note: The table presents regressions of a dummy equal to one if the individual was classiﬁed as treated (enabled the political ad ﬁlter) on a dummy equal to one if the individual was assigned the encouragement to hide political ads, and in the case of regressions in Columns 2, 4, 6, and 8 also on a set of controls (age, state, and a dummy for using a mobile device to access the intake survey). Columns 1-2 correspond to the minimal speciﬁcation which was estimated with the main sample. Individuals in the treatment group were classiﬁed as treated if they self-reported enabling the political ad ﬁlter. All individuals in the control were considered as not treated. Columns 3-4 pertain to the best-case speciﬁcations which was estimated with the extension sample. Individuals in the treatment were classiﬁed as treated if the extension data indicated that they saw zero political ads. All individuals in the control were considered as not treated. Columns 5-6 correspond to the conservative speciﬁcation, also estimated using the extension sample. Individuals in the treatment were considered treated if they saw zero political ads and saw at least 22 ads in general. All individuals in the control group who saw zero political ads were also considered treated. Columns 7-8 pertain to the preferred speciﬁcation estimated on the extension sample. All individuals who saw at least 22 ads and zero political ads were considered treated. Moreover, all individuals who saw fewer than 22 ads and saw zero political ads but were expected (Facebook Ad Library) to see more were classiﬁed as treated. ∗ signiﬁcant at 10%; ∗∗ signiﬁcant at 5%; ∗∗∗ signiﬁcant at 1%; 41 Electronic copy available at: https://ssrn.com/abstract=4003901 Table 8: The Effect on Survey Measures Using Estimator (2) Minimal Best-Case (1) (2) (3) (4) VoteTrump .037 .036 .042 .041 (.035) (.037) (.040) (.042) DictatorSplit .014 .010 .016 .011 (.022) (.022) (.024) (.025) Thermometer −.540 −1.445 −.614 −1.645 (1.625) (1.709) (1.850) (1.945) RelativePolicy −.042 −.575 −.048 −.654 (1.194) (1.213) (1.359) (1.381) RelativePrediction −1.432 −1.959 −1.630 −2.229 (1.260) (1.255) (1.435) (1.429) MisconceptionIndex −1.797 −1.961 −2.045 −2.232 (1.523) (1.569) (1.733) (1.786) WordIndexDiﬀ .225 .277 .256 .315 (.164) (.173) (.187) (.197) WordIndexIn .174 .250 ∗∗ .198 .285∗∗ (.114) (.120) (.129) (.137) WordIndexOut −.051 −.027 −.058 −.031 (.070) (.074) (.079) (.084) Controls? No Yes No Yes Note: Point estimates reported in the table were computed using the simpliﬁed version of estimator (2): ˆq = ˆν ˆκ . We explain each variable in turn. First, ˆν is the OLS estimator of the slope in a regression of an outcome variable on a dummy equal to one if the individual was assigned the encouragement to hide political ads. Second, ˆκ = 1 nv ∑nv i=1 DiZiPiBi 1 nv ∑nv i=1 ZiPiBi where nv is the size of the extension sample. For Columns 2 and 4, this regression also included a set of controls (age, state, a dummy for using a mobile device to access the intake survey, income, education level, race, and a dummy for Hispanic origin). ˆν was estimated using the sample of individuals who completed the follow-up survey (M = 758, but M = 750 with controls). nv = 288 is the size of the extension sample. Columns 1-2 correspond to the minimal speciﬁcation. Individuals in the treatment group were classiﬁed as treated if they self-reported enabling the political ad ﬁlter. Columns 3-4 correspond to the best-case speciﬁcation. Individuals in the treatment were considered treated if they saw zero political ads and saw at least 22 ads in general. All individuals in the control group who saw zero political ads were also considered treated. The outcome variables in the table are as follows (in order): a dummy equal to one if they voted for Trump/Pence (VoteTrump), the dictator game oﬀer to an outgroup partisan (DictatorSplit), feeling thermometer towards an outgroup partisan (Thermometer ), partisan policy support index (RelativePolicy), prediction index about out-group’s policy support (RelativePrediction), partisan misconception index (MisconceptionIndex ), the diﬀerence between index of ingroup and outgroup word associations (WordIndexDiﬀ ), index of ingroup word associations (WordIndexIn), index of outgroup word associations (WordIndexOut). Standard errors are provided in brackets. Standard errors are based on the asymptotic distribution derived in Appendix A.2. ∗ signiﬁcant at 10%; ∗∗ signiﬁcant at 5%; ∗∗∗ signiﬁcant at 1%; 42 Electronic copy available at: https://ssrn.com/abstract=4003901 Table 9: The Effect on Survey Measures Using Estimator (2) with Bootstrapped Errors Minimal Conservative Best-Case Preferred (1) (2) (3) (4) (5) (6) (7) (8) VoteTrump .037 .036 .073 .072 .042 .041 .063 .062 (.036) (.038) (.074) (.077) (.041) (.043) (.063) (.065) DictatorSplit .014 .010 .028 .019 .016 .011 .024 .017 (.022) (.023) (.045) (.047) (.025) (.026) (.038) (.040) Thermometer −.540 −1.445 −1.066 −2.855 −.614 −1.645 −.915 −2.451 (1.659) (1.789) (3.354) (3.620) (1.892) (2.040) (2.849) (3.077) RelativePolicy −.042 −.575 −.083 −1.135 −.048 −.654 −.071 −.975 (1.233) (1.286) (2.507) (2.619) (1.407) (1.467) (2.132) (2.228) RelativePrediction −1.432 −1.959 −2.829 −3.869 −1.630 −2.229 −2.429 −3.323 (1.303) (1.328) (2.678) (2.744) (1.488) (1.517) (2.262) (2.312) MisconceptionIndex −1.797 −1.961 −3.550 −3.873 −2.045 −2.232 −3.048 −3.326 (1.562) (1.666) (3.222) (3.427) (1.784) (1.902) (2.721) (2.900) WordIndexDiﬀ .225 .277 .445 .547 .256 .315 .382 .470 (.168) (.181) (.349) (.377) (.192) (.207) (.294) (.317) WordIndexIn .174 .250 ∗∗ .344 .494 ∗ .198 .285 ∗∗ .296 .424 ∗ (.118) (.127) (.245) (.267) (.135) (.145) (.207) (.223) WordIndexOut −.051 −.027 −.101 −.054 −.058 −.031 −.086 −.046 (.072) (.076) (.146) (.154) (.082) (.087) (.124) (.131) Controls? No Yes No Yes No Yes No Yes Note: Point estimates reported in the table were computed using estimator (2): ˆq = ˆν ˆp ˆc . We explain each variable in turn. First, ˆν is the OLS estimator of the slope in a regression of an outcome variable on a dummy equal to one if the individual was assigned the encouragement to hide political ads. For Columns 2 and 4, this regression also included a set of controls (age, state, a dummy for using a mobile device to access the intake survey, income, education level, race, and a dummy for Hispanic origin). ˆν was estimated using the sample of individuals who completed the follow-up survey (M = 758, but M = 750 with controls). Second, ˆp is the proportion of participants in the main sample (N = 1587) who reported enabling the required ad ﬁlter (either for alcohol ads or political ads). Third, ˆθ is the estimator of the proportion of compliers. It is deﬁned as follows: ˆθ = ˆγ × ˆκ − ˆδ. Note that ˆγ = 1 N ∑N i=1 PiZi 1 N ∑N i=1 Zi , ˆκ = 1 nv ∑nv i=1 DiZiPiBi 1 nv ∑nv i=1 ZiPiBi , ˆδ = 1 nv ∑nv i=1 Di(1−Zi)Bi 1 nv ∑nv i=1(1−Zi)Bi , where N is the main sample size and nv = 288 is the size of the extension sample. Columns 1-2 correspond to the minimal speciﬁcation. Individuals in the treatment group were classiﬁed as treated if they self-reported enabling the political ad ﬁlter. Columns 3-4 pertain to the conservative speciﬁcation. Individuals in the treatment were classiﬁed as treated if the extension data indicated that they saw zero political ads. All individuals in the control were considered as not treated. Columns 5-6 correspond to the best-case speciﬁcation. Individuals in the treatment were considered treated if they saw zero political ads and saw at least 22 ads in general. All individuals in the control group who saw zero political ads were also considered treated. Columns 7-8 pertain to the preferred speciﬁcation. All individuals who saw at least 22 ads and zero political ads were considered treated. Moreover, all individuals who saw fewer than 22 ads and saw zero political ads but were expected (Facebook Ad Library) to see more were classiﬁed as treated. The outcome variables in the table are as follows (in order): a dummy equal to one if they voted for Trump/Pence (VoteTrump), the dictator game oﬀer to an outgroup partisan (DictatorSplit), feeling thermometer towards an outgroup partisan (Thermometer ), partisan policy support index (RelativePolicy), prediction index about out-group’s policy support (RelativePrediction), partisan misconception index (MisconceptionIndex ), the diﬀerence between index of ingroup and outgroup word associations (WordIndexDiﬀ ), index of ingroup word associations (WordIndexIn), index of outgroup word associations (WordIndexOut). Bootstrapped standard errors are provided in brackets. ∗ signiﬁcant at 10%; ∗∗ signiﬁcant at 5%; ∗∗∗ signiﬁcant at 1%; 43 Electronic copy available at: https://ssrn.com/abstract=4003901 Table 10: Significance of Assignment for Predicting Attrition Res.Df RSS Df Sum of Sq F Pr(>F) 1 1508 331.27 2 1457 323.49 51 7.78 0.69 0.9550 Note: The ﬁrst row (model 1) corresponds to the regression of a dummy equal to one if the individual did not complete the follow-up survey on the set of available covariates (age, device type, time spent on the intake survey, and state). The second row (model 2) corresponds to the regression of a dummy equal to one if the individual did not complete the follow-up survey on a dummy equal to one if the individual was assigned the encouragement to hide political ads and its interactions with the above covariates. We report the F-statistic from comparing the two models and the associated p-value. Table 11: Significance of Assignment for Predicting Attrition With Political En- gagement Res.Df RSS Df Sum of Sq F Pr(>F) 1 475 108.62 2 429 96.80 46 11.82 1.14 0.2541 Note: The ﬁrst row (model 1) corresponds to the regression of a dummy equal to one if the individual did not complete the follow-up survey on the set of available covariates (age, device type, time spent on the intake survey, state) and variables from the political engagement survey (a dummy for hypothetically voting Democrats for Congress, interest in politics on a scale from 0 to 10, and average news consumption in hours). The second row (model 2) corresponds to the regression of a dummy equal to one if the individual did not complete the follow-up survey on a dummy equal to one if the individual was assigned the encouragement to hide political ads and its interactions with all of the above controls. We report the F-statistic from comparing the two models and the associated p-value. Table 12: Dropout Balance Hide Alcohol (N=138) Hide Political (N=128) Mean Std. Dev. Mean Std. Dev. Diﬀ. in Means p CongressVoteDem 0.728 0.447 0.764 0.427 0.036 0.543 NewsConsumption 6.902 5.979 7.070 6.309 0.168 0.824 Mobile 0.746 0.437 0.828 0.379 0.082 0.103 InterestInPolitics 6.174 2.859 6.430 2.850 0.256 0.466 TimeOnSurvey1 542.942 2394.931 398.555 1195.189 -144.387 0.530 Age 48.730 16.789 50.118 16.876 1.388 0.504 Note: Balance table for participants who completed the intake survey but did not complete the follow-up survey, by encouragement. The variables were collected during the intake survey. The political engagement survey (a dummy for hypothetically voting Democrats for Congress, interest in politics on a scale from 0 to 10, and average news consumption in hours) comes from a subset of the main sample consisting of 634 respondents. Time spent on the intake survey was measured in seconds. 44 Electronic copy available at: https://ssrn.com/abstract=4003901 Table 13: Voter File Identification Balance (Main Sample) FALSE (N=272) TRUE (N=1315) Mean Std. Dev. Mean Std. Dev. Diﬀ. in Means p Age 39.67 16.24 47.31 16.90 7.64 0.00 TimeOnSurvey1 786.98 6734.22 440.98 2658.35 -346.00 0.40 Mobile 0.69 0.46 0.72 0.45 0.03 0.31 CongressVoteDem 0.70 0.46 0.69 0.46 -0.01 0.91 InterestInPolitics 6.25 2.95 6.37 2.80 0.12 0.70 NewsConsumption 6.35 5.91 7.02 6.00 0.67 0.28 Note: Balance table for participants who completed the intake survey, by whether their voting record was identiﬁed. The variables were collected during the intake survey. The political engagement survey (a dummy for hypothetically voting Democrats for Congress, interest in politics on a scale from 0 to 10, and average news consumption in hours) comes from a subset of the main sample consisting of 634 respondents. Time spent on the intake survey was measured in seconds. Table 14: Voter File Identification Balance (Survey Sample) FALSE (N=153) TRUE (N=605) Mean Std. Dev. Mean Std. Dev. Diﬀ. in Means p TimeOnSurvey1 377.77 1288.90 429.14 2971.65 51.36 0.75 TimeOnSurvey2 734.89 2389.39 1025.97 5771.80 291.08 0.34 NewsConsumption 6.38 5.95 6.96 5.87 0.58 0.46 Age 36.13 14.44 41.47 15.32 5.34 0.00 CongressVoteDem 0.69 0.46 0.65 0.48 -0.04 0.52 White 0.61 0.49 0.82 0.39 0.21 0.00 IncomeLessThan50k 0.43 0.50 0.44 0.50 0.01 0.80 AboveBachelor 0.58 0.50 0.49 0.50 -0.08 0.07 Male 0.44 0.50 0.33 0.47 -0.11 0.02 Hispanic 0.09 0.28 0.06 0.24 -0.03 0.30 Note: Balance table for participants who completed the follow-up survey, by whether their voting record was identiﬁed. Age and the time spent on the intake survey (TimeOnSurvey1 ) were collected during the intake survey. The political engagement survey (a dummy for hypothetically voting Democrats for Congress, interest in politics on a scale from 0 to 10, and average news consumption in hours) was also conducted during the intake survey. Here, we report values for 368 respondents who took the political engagement survey and completed the follow-up survey. The remaining variables, including the time spent on the follow-up survey (TimeOnSurvey2 ), were collected during the follow-up survey. 45 Electronic copy available at: https://ssrn.com/abstract=4003901 Table 15: Extension Installation Balance (Main Sample) FALSE (N=1299) TRUE (N=288) Mean Std. Dev. Mean Std. Dev. Diﬀ. in Means p CongressVoteDem 0.69 0.46 0.74 0.44 0.05 0.30 InterestInPolitics 6.25 2.82 6.77 2.80 0.52 0.07 Age 47.34 16.80 40.07 16.82 -7.26 0.00 NewsConsumption 6.86 6.02 7.08 5.82 0.22 0.71 Note: Balance table for participants who completed the intake survey, by whether they installed the extension. The variables were collected during the intake survey. The political engagement survey (a dummy for hypothetically voting Democrats for Congress, interest in politics on a scale from 0 to 10, and average news consumption in hours) comes from a subset of the main sample consisting of 634 respondents. Time spent on the intake survey was measured in seconds. Table 16: Extension Installation Balance (Survey Sample) FALSE (N=530) TRUE (N=228) Mean Std. Dev. Mean Std. Dev. Diﬀ. in Means p TimeOnSurvey1 258.58 530.96 791.13 4873.84 532.55 0.10 TimeOnSurvey2 929.44 5078.66 1055.05 5691.28 125.61 0.77 NewsConsumption 6.72 5.90 7.21 5.85 0.49 0.47 Age 41.22 14.88 38.53 16.09 -2.69 0.03 CongressVoteDem 0.64 0.48 0.71 0.46 0.07 0.24 White 0.76 0.42 0.80 0.40 0.03 0.29 IncomeLessThan50k 0.48 0.50 0.34 0.48 -0.14 0.00 Male 0.30 0.46 0.48 0.50 0.18 0.00 AboveBachelor 0.42 0.49 0.71 0.45 0.29 0.00 Hispanic 0.08 0.27 0.04 0.20 -0.04 0.04 Note: Balance table for participants who completed the follow-up survey, by whether they installed the extension. Age and the time spent on the intake survey (TimeOnSurvey1 ) were collected during the intake survey. The political engagement survey (a dummy for hypothetically voting Democrats for Congress, interest in politics on a scale from 0 to 10, and average news consumption in hours) was also conducted during the intake survey. Here, we report values for 368 respondents who took the political engagement survey and completed the follow-up survey. The remaining variables, including the time spent on the follow-up survey (TimeOnSurvey2 ), were collected during the follow-up survey. 46 Electronic copy available at: https://ssrn.com/abstract=4003901 A Identiﬁcation Notes A.1 Identiﬁcation Strategy: Turnout A.1.1 Experimental Setup We randomly encouraged Facebook users to turn on a ﬁlter that hides political ads (treatment) or alcohol ads (control) from their feed. Users self-reported whether they were successful in turning on the designated ad ﬁlter (i.e., they answered the question “Were you able to successfully turn on the ad ﬁlter as we asked”). We do not observe the treatment status of participants. A nonrandom subset of users installed a browser extension that allowed us to see their ad diet and make inference about their treatment status. A.1.2 General Problem Consider a variation of a standard encouragement design in which take-up of the treatment is credibly veriﬁable only for a subset of individuals – we refer to it as the veriﬁcation subsample – whereas for others, the researcher has to rely on a noisy proxy, such as self-reported data. In this scenario, the traditional strategy of estimating LATE (Imbens and Angrist (1994)) is not applicable. We attempt to alleviate this problem by proposing a consistent estimator of LATE which relies on the ITT regression estimated on the full sample. We use the veriﬁcation subsample to estimate the proportion of individuals who took up the treatment conditional on self-reporting doing so and to estimate the proportion of always-takers. It is important to note that estimation of the proportion of compliers is not entirely dependent on the veriﬁcation subsample because of usefulness of the self- reported take-up. This is crucial in the context of our design as it is implausible to assume that the proportion of compliers among extension users is the same as for everyone else – it was easier to enable the ﬁlter on a desktop device. A.1.3 Notation We begin by introducing notation pertaining to a standard encouragement design.53 First, Zi = 1 if individual i received the encouragement to take up the treatment, and 0 otherwise. Di is a binary variable indicating if individual i was treated. We further deﬁne Dz i , where z = 0, 1. Dz i = 1 means that person i takes up the treatment if Zi = z, using which we partition the population into four groups: compliers (D1 i − D0 i = 1), always-takers (D1 i = D0 i = 1), never-takers (D1 i = D0 i = 0), and deﬁers (D1 i − D0 i = −1). The variable Ti speciﬁes the group, denoted c, a, n, and d respectively. Lastly, Y d,z i where (d, z) ∈ (0, 1)2 denotes the outcome if Di = d and Zi = z, and Yi is the observed outcome. Now, we focus on the particular features of our setup. First, we deﬁne Pi as a binary variable which equals 1 if the user self-reported taking up the treatment. Note that Pi diﬀers from Di in the treatment group due to potential misreporting. What is more, Pi = 0 for everyone in the control group, even though Di = 1 is possible, as individuals could only report taking up the treatment if they 53Throughout the text, we follow the notation and naming conventions adopted in Chab´e-Ferret (2021). 47 Electronic copy available at: https://ssrn.com/abstract=4003901 received the encouragement to take it.54 Finally, we deﬁne Bi which denotes whether (Bi = 1) or not (Bi = 0) we can verify if person i took up the treatment (i is in the veriﬁcation subpopulation). A.1.4 Minimal speciﬁcation This section focuses on estimating LATE using self-reported take-up of the treatment. We begin by listing ﬁve assumptions that enable identiﬁcation of LATE using Wald estimator in a typical encouragement design (Chab´e-Ferret (2021)). Assumption 1 (Encouragement Validity) The randomized allocation does not aﬀect the way in which potential outcomes and self-selection are generated: Di = D1 i Zi + D0 i (1 − Zi) Yi =    Y 11 i if Di = 1 and Zi = 1 Y 10 i if Di = 1 and Zi = 0 Y 01 i if Di = 0 and Zi = 1 Y 00 i if Di = 0 and Zi = 0 where Y 11 i , Y 10 i , Y 01 i , Y 00 i , D1 i , D0 i are the same as in a routine allocation of the treatment. Assumption 2 (Independence) (Y 11 i , Y 01 i , Y 10 i , Y 00 i ) ⊥ Zi. Assumption 3 (Exclusion Restriction) Y d,z i = Y d i , ∀(d, z) ∈ {0, 1}2. Assumption 4 (Relevance) P r(Di = 1|Zi = 1) > P r(Di = 1|Zi = 0). Assumption 5 (Monotonicity) Either ∀i D1 i ≥ D0 i or ∀i D1 i ≤ D0 i . Additionally, the following assumption holds by construction. Assumption 6 (No Report in Control) ∀i Pi = 0 if Zi = 0. With these, we can formulate our ﬁrst result. Proposition 1 Suppose that ∀i Di = Pi (i.e., self-reporting in the treatment group is truthful and there are no always-takers). Then, under Assumptions 1, 2, 3, 4, 5, 6 the Wald estimator ∆Y W ald = E(Yi|Zi=1)−E(Yi|Zi=0) P r(Pi=1|Zi=1)−P r(Pi=1|Zi=0) identiﬁes ∆Y LAT E = E(Y 1 i − Y 0 i |Ti = c). Proof. See Theorem 3.9 in Chab´e-Ferret (2021). 54This is a special feature of our design (Section A.1.1) – participants could only report enabling the ﬁlter (either alcohol ads ﬁlter or political ads ﬁlter) which they were encouraged to turn on. Our strategy can be easily modiﬁed to the cases where individuals in the control can report taking up the treatment. 48 Electronic copy available at: https://ssrn.com/abstract=4003901 A.1.5 Preferred approach Introduction and Assumptions To avoid relying on self-reported take-up (as in Proposition 1), we propose an alternative strategy which makes use of the fact that in the veriﬁcation subsample we can check if a person was treated.55 Our approach relies on the fact that LATE can be expressed as a ratio of ITT and the proportion of compliers. In subsequent sections, we discuss how we estimate the numerator and the denominator separately, and combine the estimators to consistently estimate LATE. Proposition 2 Under Assumptions 1, 3, 5, LATE is equal to the ratio of ITT and the proportion of compliers, i.e. ∆Y LAT E = ∆Y IT T P r(Ti=c) , where ∆Y LAT E = E(Y 1 i − Y 0 i |Ti = c) and ∆Y IT T = E(Y D1 i ,1 i − Y D0 i ,0 i ). Proof. See Theorem 3.11 in Chab´e-Ferret (2021). Below, we introduce additional assumptions which enable the new approach. Assumption 7 (Report on Success) No one who takes up the treatment fails to report so, i.e., ∀i (Di = 1 =⇒ Pi = 1). Assumption 8 (Same Propensity to Misreport) The proportion of individuals who reported tak- ing up the treatment when in fact they did not is the same in the veriﬁcation subpopulation and outside of it: P r(Di = 0|Zi = 1, Pi = 1, Bi = 1) = P r(Di = 0|Zi = 1, Pi = 1, Bi = 0). Assumption 9 (Same Proportion of Always-Takers) The proportion of always-takers is the same in the veriﬁcation subpopulation and outside of it: P r(Di = 1|Zi = 0, Bi = 1) = P r(Di = 1|Zi = 0, Bi = 0). Validity of Assumptions It is important to discuss validity of these assumptions in the context of our design (Section A.1.1). Unless the treatment is associated with negative stigma, we expect Assumption 7 to be satisﬁed. There is little reason to believe that an individual would not report taking up the treatment to the researcher who encouraged them take it. Assumptions 8 and 9 are key to relaxing the restrictive assumption that compliance rate is the same within and outside the veriﬁcation subpopulation. In fact, our data suggests that this is markedly not so: the veriﬁcation subsample by design had a larger proportion of desktop users, for whom it was easier to comply. Assumption 8 is less restrictive, as it depends only on propensity to misreport being uncorrelated with Bi. It would be violated, for example, if individuals, who are more likely to take up the extension, are also more prone to lie in their day-to-day aﬀairs and therefore would more easily 55In the case of our experiment (Section A.1.1), we used ad data for browser extension users to infer whether or not they enabled the political ad ﬁlter. 49 Electronic copy available at: https://ssrn.com/abstract=4003901 misreport in our study. Assumption 9 is also plausible given our eﬀorts to minimize the proportion of always-takers altogether. In particular, participants were instructed in the intake survey that they should not turn on an ad ﬁlter on any other topic than the one required. In the paper we also argued that the ad ﬁlters were diﬃcult to access for Facebook users, which reduces the chance that people enrolled in the study with any of the ﬁlters already enabled. Proportion of Compliers We propose to identify the proportion of compliers in the following way. Proposition 3 Under Assumptions 1, 2, 5, 6, 7, 8, 9, the proportion of compliers P r(Ti = c) can be identiﬁed by θ := P r(Di = 1|Zi = 1, Pi = 1, Bi = 1) × P r(Pi = 1|Zi = 1) − P r(Di = 1|Zi = 0, Bi = 1). Proof. Following Theorem 3.13 in Chab´e-Ferret (2021), we have that under Assumptions 1, 2, 5, P r(Ti = c) = P r(Di = 1|Zi = 1) − P r(Di = 1|Zi = 0). First, we will focus on the former term and show that P r(Di = 1|Zi = 1) = P r(Di = 1|Zi = 1, Pi = 1, Bi = 1) × P r(Pi = 1|Zi = 1). (3) By the law of total probability and Assumption 7, P r(Di = 1|Zi = 1) = P r(Di = 1|Zi = 1, Pi = 1) × P r(Pi = 1|Zi = 1) + P r(Di = 1|Zi = 1, Pi = 0) ︸ ︷︷ ︸ =0 ×P r(Pi = 0|Zi = 1) = P r(Di = 1|Zi = 1, Pi = 1) × P r(Pi = 1|Zi = 1). Furthermore, by Assumption 8, P r(Di = 1|Zi = 1, Pi = 1) = P r(Di = 1|Zi = 1, Pi = 1, Bi = 1) × P r(Bi = 1|Zi = 1, Pi = 1) + P r(Di = 1|Zi = 1, Pi = 1, Bi = 0) × P r(Bi = 0|Zi = 1, Pi = 1) = P r(Di = 1|Zi = 1, Pi = 1, Bi = 1). Combining the two observations, we obtain (3). We now focus on the second term. By Assumption 9, it holds that: P r(Di = 1|Zi = 0) = P r(Di = 1|Zi = 0, Bi = 1) × P r(Bi = 1|Zi = 0) + P r(Di = 1|Zi = 0, Bi = 0) × P r(Bi = 0|Zi = 0) = P r(Di = 1|Zi = 0, Bi = 1). Combining this with (3), we derive that P r(Ti = c) = θ. 50 Electronic copy available at: https://ssrn.com/abstract=4003901 Intent-to-Treat Eﬀect Proposition 4 Under Assumptions 1, 2, β1 = E(Yi|Zi = 1) − E(Yi|Zi = 0) identiﬁes ITT. Proof. See Theorem 3.12 in Chab´e-Ferret (2021). Estimation of LATE In this section we propose a LATE estimator that incorporates ITT regression estimated on the entire sample. We demonstrate that the estimator is consistent for LATE, and derive its asymptotic distribution. Deﬁnition 1 We deﬁne γ := E(PiZi) E(Zi) , κ := E(DiZiPiBi) E(ZiPiBi) , and δ := E(Di(1−Zi)Bi) E((1−Zi)Bi) . Note that θ = γκ − δ. Assumption 10 (Nontriviality) P r(Zi = 1, Pi = 1, Bi = 1) > 0 and P r(Zi = 0, Bi = 1) > 0. Proposition 5 Under Assumptions 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, q := β1 γκ−δ identiﬁes LATE, where β1 = E(Yi|Zi = 1) − E(Yi|Zi = 0). Proof. By Proposition 2, ∆Y LAT E = ∆Y IT T P r(Ti=c) . Applying Proposition 4 to the numerator and Proposition 3 to the denominator, we obtain that ∆Y LAT E = q. Deﬁnition 2 We propose the following LATE estimator: ˆq = ˆβ1 ˆγ×ˆκ−ˆδ where ˆβ1 is the OLS estimator of the slope in the regression of the outcome variable on a dummy equal to one if an individual was assigned treatment, ˆγ = 1 N ∑N i=1 PiZi 1 N ∑N i=1 Zi , ˆκ = 1 nv ∑nv i=1 DiZiPiBi 1 nv ∑nv i=1 ZiPiBi , ˆδ = 1 nv ∑nv i=1 Di(1−Zi)Bi 1 nv ∑nv i=1(1−Zi)Bi , where N is the full sample size and nv is the size of the veriﬁcation subsample. Deﬁnition 3 We propose the following estimator of the number of compliers: ˆθ = ˆγ × ˆκ − ˆδ where ˆγ, ˆκ, ˆδ are as speciﬁed in Deﬁnition 2. Assumption 11 (Boundedness) The ratio N nv is bounded, i.e. OP (1). Proposition 6 Under Assumption 10 and 11, ˆθ is an √N -consistent estimator of θ. Proof. By the delta method, we have that √nv(ˆκ − κ) d −→ N (0, Ωκ). We can re-write the LHS as √nv√N √N (ˆκ − κ). Given Assumption 11 and that the product converges to a normal random variable, √ N (ˆκ − κ) is bounded in probability, or OP (1). We can similarly show that √N (ˆδ − δ) is OP (1). Moreover, √N (ˆγ − γ) is OP (1) by a direct application of the delta method, and ˆγ is consistent for γ (ˆγ − γ is oP (1)). Now, we can use the following decomposition: √N (ˆθ − θ) = √ N [ˆγˆκ − ˆδ − (γκ − δ)] = ˆγ√N (ˆκ − κ) + κ √N (ˆγ − γ) − √N (ˆδ − δ). (4) Note that this expression is of the form oP (1)OP (1) + OP (1) − OP (1). Hence, √N (ˆθ − θ) is OP (1). 51 Electronic copy available at: https://ssrn.com/abstract=4003901 Proposition 7 Under Assumptions 10 and 11, ˆq is consistent for q. Proof. The OLS estimator ˆβ1 is consistent for β1, i.e. ˆβ1 p −−−−→ N →∞ β1. In addition, Proposition 6 implies that ˆθ p −−−−→ N →∞ θ. Thus, by the continuous mapping theorem ˆq p −−−−→ N →∞ q. Proposition 8 Under the null hypothesis q = 0 and Assumptions 10 and 11, the asymptotic dis- tribution of the estimator ˆq is given by √N ˆq d → N (0, Ωβ θ2 ), where Ωβ is the asymptotic variance of ˆβ1. Proof. Under the null hypothesis q = 0, which is equivalent to β1 = 0, √N ˆβ1 d −→ N (0, Ωβ). Furthermore, Proposition 6 implies that ˆθ p −−−−→ N →∞ θ. Thus, by the Slutsky Lemma: √N ˆq = √N ˆβ1 ˆθ d −→ N ( 0, Ωβ θ2 ) . (5) As a result of Proposition 8, we can use the following z-statistic to test the null hypothesis: z = √N ˆq ˆθ√ ˆΩβ , where ˆΩβ is a consistent estimator of asymptotic variance of ˆβ1. Thus, the standard error is given by SE = √ ˆΩβ √N ˆθ . 52 Electronic copy available at: https://ssrn.com/abstract=4003901 A.2 Identiﬁcation Strategy: Survey Outcomes A.2.1 Setup Immediately after the presidential election, we conducted a post-experimental survey, collecting a variety of outcomes. Every person who reported enabling the political ad ﬁlter (in the treatment group) or the alcohol ad ﬁlter (in the control group) – and thus fulﬁlled the requirements outlined in the intake survey – received a link to the follow-up survey. In this section, we describe our identiﬁcation strategy for the survey outcomes. A.2.2 Goal Recall from Section A.1.3, that Pi = 1 if individual i reported enabling the political ad ﬁlter in the treatment group, and 0 otherwise. Similarly, let Ai be 1 if individual i reported enabling the alcohol ﬁlter in the control group, and 0 otherwise. Given our experimental setup (Section A.2.1), we can use our data to estimate ν := E(Yi|Zi = 1, Pi = 1) − E(Yi|Zi = 0, Ai = 1). Our goal is to recover ITT and LATE using ν. We devote the next two sections to this issue. A.2.3 Recovering ITT We start by introducing the main identiﬁcation assumption. Assumption 12 (No Diﬀerential Attrition) The proportion of people who self-reported turning on the assigned ﬁlter is equal in the treatment group and the control group: p := P r(Pi = 1|Zi = 1) = P r(Ai = 1|Zi = 0). Furthermore, there was no diﬀerential attrition (regarding types of participants who dropped out): E(Y 0 i |Zi = 1, Pi = 0) = E(Y 0 i |Zi = 0, Ai = 0). We also need the following assumption, which extends Assumption 7. Assumption 13 (Report on Failure) No one who reported failure to enable the alcohol ad ﬁlter when asked to do so enabled the political ad ﬁlter i.e., ∀i : Zi = 0, Ai = 0 =⇒ Di = 0. Proposition 9 Under Assumptions 1, 2, 3, 7, 12, 13, pν identiﬁes ∆Y IT T = E(Y D1 i ,1 i − Y D0 i ,0 i ). Proof. The derivation is shown in Equation 6. Step (a) follows from Proposition 4. Step (b) follows from the ﬁrst part of Assumption 12. We can also replace Yi with Y 0 i in the second and fourth term thanks to Assumption 7 and 13. Lastly, step (c) follows from the second part of Assumption 12. 53 Electronic copy available at: https://ssrn.com/abstract=4003901 ∆Y IT T (a) = E(Yi|Zi = 1) − E(Yi|Zi = 0) = E(Yi|Zi = 1, Pi = 1)P r(Pi = 1|Zi = 1) + E(Yi|Zi = 1, Pi = 0)P r(Pi = 0|Zi = 1) − E(Yi|Zi = 0, Ai = 1)P r(Ai = 1|Zi = 0) − E(Yi|Zi = 0, Ai = 0)P r(Ai = 0|Zi = 0) (b) = pE(Yi|Zi = 1, Pi = 1) + (1 − p)E(Y 0 i |Zi = 1, Pi = 0) − pE(Yi|Zi = 0, Ai = 1) − (1 − p)E(Y 0 i |Zi = 0, Ai = 0) (c) = p[E(Yi|Zi = 1, Pi = 1) − E(Yi|Zi = 0, Ai = 1)] = pν. (6) A.2.4 Recovering LATE In this section we provide the building blocks for a consistent LATE estimator in Section A.2.5 (Propo- sition 10) and derive its asymptotic distribution (Proposition 11). Lastly, under more restrictive as- sumptions (Proposition 12), we are able to show that ν, which is estimated using OLS on the survey sample, identiﬁes LATE. Proposition 10 Under Assumptions 1, 2, 3, 4, 5, 7, 8, 9, 12, qs := pν θ identiﬁes LATE. Proof. First, by Proposition 2, ∆Y LAT E = ∆Y IT T P r(Ti=c) . By Proposition 9, ∆Y IT T = pν. Lastly, Proposition 3 gives P r(Ti = c) = θ. Combining the three statements we obtain that ∆Y LAT E = qs. Proposition 11 Suppose that there are no always-takers, i.e., P r(Di = 1|Zi = 0) = 0. Then, under Assumptions 1, 2, 3, 4, 5, 7, 8, 9, 12, 13, qss = ν κ identiﬁes LATE. Proof. ∆Y LAT E (a) = ∆Y IT T P r(Ti = c) (b) = ∆Y IT T P r(Di = 1|Zi = 1) − P r(Di = 1|Zi = 0) (c) = ∆Y IT T P r(Di = 1|Zi = 1) (d) = ∆Y IT T P r(Di = 1|Zi = 1, Pi = 1)P r(Pi = 1|Zi = 1) (e) = νp κp = ν κ . (7) Note that step (a) follows from Proposition 2. Step (b) is based on Theorem 3.13 in Chab´e-Ferret (2021). Step (c) makes use of the assumption that there are no always-takers. Step (d) follows from 54 Electronic copy available at: https://ssrn.com/abstract=4003901 the law of total probability and Assumption 7, P r(Di = 1|Zi = 1) = P r(Di = 1|Zi = 1, Pi = 1) × P r(Pi = 1|Zi = 1) + P r(Di = 1|Zi = 1, Pi = 0) ︸ ︷︷ ︸ =0 ×P r(Pi = 0|Zi = 1) = P r(Di = 1|Zi = 1, Pi = 1) × P r(Pi = 1|Zi = 1). Lastly, step (e) follows from Proposition 9 and Assumption 8. Proposition 12 Suppose that ∀i Di = Pi, (i.e., self-reporting in the treatment group is truthful and there are no always-takers). Then, under Assumptions 1, 2, 3, 4, 5, 7, 8, 9, 12, 13, ∆Y LAT E = ν. Proof. By Proposition 11, ∆Y LAT E = ν κ . Furthermore, if ∀i Di = Pi, then κ = P r(Di = 1|Zi = 1, Pi = 1, Bi = 1) = 1. A.2.5 Estimation Deﬁnition 4 We propose the following LATE estimator for survey outcomes: ˆqs = ˆν ˆp ˆθ , where ˆν is the OLS estimator of ν (sample size M ), ˆp = 1 N ∑N i=1(Ai + Pi), and ˆθ is the estimator of the proportion of compliers speciﬁed in Deﬁnition 3. Assumption 14 (Boundedness) The ratio N M is bounded, i.e. OP (1). Proposition 13 Under Assumptions 10, 11, 14, ˆqs is consistent for qs. Proof. By the central limit theorem, we have that √ M (ˆν − ν) d −→ N (0, Ων). We can re-write the LHS as √M√N √N (ˆν − ν). Given Assumption 14 and that the product converges to a normal random variable, √N (ˆν − ν) is bounded in probability, or OP (1). Moreover, √N (ˆp − p) is OP (1) by a direct application of the CLT, and ˆp is consistent for p (ˆp − p is oP (1)). Now, we can use the following decomposition: √N (ˆpˆν − pν) = ˆp√N (ˆν − ν) + ν√N (ˆp − p) (8) Note that this expression is of the form oP (1)OP (1) + OP (1). Hence, √N (ˆpˆν − pν) is OP (1). In particular, this implies ˆpˆν p −−−−→ N →∞ pν. We already know that ˆθ p −−−−→ N →∞ θ (Proposition 6). Thus, by the continuous mapping theorem ˆqs p −−−−→ N →∞ qs. Lastly, if we are willing to assume that there are no always-takers, the following simpliﬁed estimator is consistent for LATE. Deﬁnition 5 We propose the following simpliﬁed LATE estimator: ˆqss = ˆν ˆκ . Proposition 14 Under the null hypothesis qss = 0 and Assumptions 10, 11, 14, the asymptotic distribution of the estimator ˆqss is given by √M ˆqss d → N (0, Ων κ2 ), where Ων is the asymptotic variance of ˆν. 55 Electronic copy available at: https://ssrn.com/abstract=4003901 Proof. Under the null hypothesis qss = 0, which is equivalent to ν = 0, √M ˆν d → N (0, Ων). Furthermore, we can show that ˆκ p −−−−→ M →∞ κ using the same approach as we did to show consistency of ˆθ in Proposition 6 and ˆpˆν in Proposition 13. Then, by the Slutsky Lemma: √ M ˆqss = √M ˆν ˆκ d → N ( 0, Ων κ2 ) . (9) As a result of Proposition 14, we can use the following z-statistic to test the null hypothesis: z = √M ˆqˆκ√ ˆΩν , where ˆΩν is a consistent estimator of asymptotic variance of ˆν. Thus, the standard error is given by SE = √ ˆΩν√ M ˆκ . 56 Electronic copy available at: https://ssrn.com/abstract=4003901 B Survey Questions B.1 Political alignment 1.1. Generally speaking, do you usually think of yourself as a Republican, a Democrat, or an Inde- pendent? • Democrat • Republican • Independent If Independent is not selected in Q1.1. 1.2. Would you call yourself a strong Democrat/Republican or a not very strong Democrat/Republi- can? • Strong • Not very strong If Independent is selected in Q1.1. 1.3. As an Independent, do you think of yourself as closer to Republicans or Democrats? • Republicans • Democrats B.2 Policy views 2.1. Please describe what you think about the following issues: For each statement respondents could pick an integer from 0-100 using a slider. We used ﬁve labels: Strongly disagree (0), Disagree (25), Neither agree nor disagree (50), Agree (75), Strongly agree (100). • We should increase the number of Supreme Court justices. • Response of the Federal Government to the Covid-19 pandemic was adequate. • We need to reduce police funding. • Access to abortion during the ﬁrst trimester should be restricted. • Free health care for everyone is a good policy. B.3 Aﬀective polarization B.3.1 3.1. Dictator game You have been matched with a participant from a diﬀerent survey who is a Democrat/Republican. You and the other participant will split a bonus of $1. You alone will make the decision of how much of the $1 you will receive and how much of the $1 the other participant will receive. You 57 Electronic copy available at: https://ssrn.com/abstract=4003901 Leave a check mark if you would use such word (and don’t if you wouldn’t): Republican Democrat open-minded generous honest selﬁsh intelligent can choose to divide the $1 however you like, and you get to keep whatever you do not give to the other participant. For example, if you decide to give $0.3, then you will receive $0.7. This bonus will be added to your $5 payment. Note that the other participant did not know that they might be matched with anyone and we never asked them to split any bonus. Your decision about how much to give the other participant will be completely anonymous. How much would you like to give to the other participant? Participants could select any amount between $0 and $1 using a slider. B.3.2 3.2. Feeling thermometer We would like to ask you about your feelings toward Democrat/Republican supporters. Please rate them using the scale below. Ratings between 50 degrees and 100 degrees mean that you feel favorable and warm toward them in general. Ratings between 0 degrees and 50 degrees mean that you don’t feel favorable toward them and that you don’t care too much for them. You would rate the group at the 50 degree mark if you don’t feel particularly warm or cold toward it. Respondents could pick an integer from 0-100 using a slider. We used ﬁve labels: Very cold feeling (0), Quite cold feeling (25), No feeling at all (50), Quite warm feeling (75), Very warm feeling (100). B.3.3 3.3. Word associations Which of the words below best describe Republican/ Democrat supporters (in each row, you can select one box, neither, or both)? B.4 Voting behavior 4.1. Did you vote in the 2020 elections? • Yes • No If Yes is selected in Q4.1. 4.2. When did you vote? • On the Election Day 58 Electronic copy available at: https://ssrn.com/abstract=4003901 • During the week before the Election Day • Two weeks before the Election Day • More than two weeks before the Election Day 4.3. Did you donate to any campaigns? • Yes, Democrat’s campaign • Yes, Republican’s campaign • No / Other If Yes is selected in Q4.1. 4.4. Which presidential ticket did you vote for? • Trump and Pence • Biden and Harris • Other 4.5. Which party did you support for Congress? • The Republican Party • The Democratic Party • Other B.5 Beliefs about opponents’ policy views 5.1. We are asking a subset of participants to predict how other respondents answered the questions during this study. For each of the ﬁve questions below, we will award a $10 bonus to the individual who is the closest to the actual value. Among respondents who think of themselves as Democrats/Republicans, what what was the av- erage response to the question: Respondents were shown the ﬁve statements from Question B.2 with the same scale and labels. For each statement respondents could pick an integer from 0-100 using a slider. B.6 Misinformation 6.1. To what extent do you agree with the following statements? For each statement respondents could pick an integer from 0-100 using a slider. We used ﬁve labels: Strongly disagree (0), Disagree (25), Neither agree nor disagree (50), Agree (75), Strongly agree (100). • Joe Biden and Kamala Harris support defunding the police. • Joe Biden lacks stamina and has poor health. • Raising taxes is a part of Joe Biden’s program. 59 Electronic copy available at: https://ssrn.com/abstract=4003901 • Joe Biden wants to increase the number of Supreme Court justices. • Joe Biden supports policies advocated by the radical left. 60 Electronic copy available at: https://ssrn.com/abstract=4003901","libVersion":"0.3.2","langs":""}