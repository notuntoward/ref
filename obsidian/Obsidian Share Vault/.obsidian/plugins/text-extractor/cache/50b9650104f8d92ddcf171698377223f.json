{"path":"lit/sources/Joosten24ComparingIdeationQuality.pdf","text":"1 EMR-23-0172 Comparing the Ideation Quality of Humans With Generative Artificial Intelligence J. Joosten, V. Bilgram, A. Hahn and D. Totzek Abstract— Traditionally, ideating new product innovations is primarily the responsibility of marketers, engineers, and designers. However, a rapidly growing interest lies in leveraging generative artificial intelligence (AI) to brainstorm new product and service ideas. This study conducts a comparative analysis of ideas generated by human professionals and an AI system. The results of a blind expert evaluation show that AI-generated ideas score significantly higher in novelty and customer benefit, while their feasibility scores are similar to those of human ideas. Overall, AI-generated ideas comprise the majority of the top-performing ideas, while human-generated ideas scored lower than expected. The executive’s emotional and cognitive reactions were measured during the evaluation to check for potential biases and showed no differences between the idea groups. These findings suggest that, under certain circumstances, companies can benefit from integrating generative AI into their traditional idea-generation processes. Index Terms— AI-augmented innovation, artificial intelligence, ChatGPT, creativity, generative AI, idea generation, innovation, large language models. Date of submission, which is populated by IEEE. Corresponding author: J. Joosten J. Joosten is with the BeLab – Behavioral Studies and User Experience Laboratory, Nuremberg Institute of Technology, 90402 Nürnberg, Germany (e- mail: jan.joosten@th-nuernberg.de). V. Bilgram is a Professor of global innovation management with the Nuremberg Institute of Technology, 90402 Nürnberg, Germany (e-mail: volker.bilgram@th-nuernberg.de). I. INTRODUCTION HE innovation domain currently adopts large language models (LLMs) equipped with conversational interfaces, marking a transformative phase in which individuals and organizations increasingly turn to artificial intelligence (AI) systems as problem-solving agents. In particular, scholars and practitioners increasingly integrate generative AI into the ideation phase of the innovation process [1] [2]. Creativity is commonly defined as combining originality – novelty, uniqueness – and effectiveness – usefulness, fit, or appropriateness [3] [4] [5]. A critical aspect of this definition is the fact that “usefulness” is subjective. Thus, [6] defines creativity as “the production of novel, appropriate ideas in any realm of human activity, from science, to the arts, to education, to business, to everyday life”, thus the ideas have to be new and appropriate to the opportunity or problem presented [6, p. 40]. She defines innovation as “the successful implementation of creative ideas within an organization” [7, p. 126]. This paper uses these definitions of creativity and innovation. The innovation process involves identifying a problem, researching and gathering information, brainstorming ideas, prototyping and testing solutions, and implementing and scaling the solution. It is iterative and aligned with design thinking principles, emphasizing empathy, user experience, and understanding of user needs and context to drive innovative solutions [8]. Professionals with domain knowledge, such as in marketing, engineering, and design, are primarily responsible for creating innovative product and service ideas [9]. This traditional approach is valuable but may inadvertently lead to limitations in idea diversity and missing potential blind spots. Additionally, human creativity, though essential in innovation, often demands substantial time and effort [10]. Businesses often face several challenges when it comes to generating new ideas through human ideation. These include the need to constantly innovate due to global competition, which shortens innovation cycle times. Additionally, there is a A. Hahn is a Professor of user experience research and emotion artificial intelligence with the Nuremberg Institute of Technology, 90402 Nürnberg, Germany (e-mail: alexander.hahn@th-nuernberg.de). D. Totzek is a Professor of Marketing and Chair of Marketing and Services with the University of Passau, 94032 Passau, Germany (e-mail: dirk.totzek@uni-passau.de). T This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 2 EMR-23-0172 greater risk of encountering errors, setbacks, and failures due to increasing customer expectations [11] [12]. The introduction of AI has the potential to revolutionize innovation management, offering a range of new tools and methods for businesses [13]. Rather than simply enhancing existing products, AI facilitates the entire process of innovation [14]. With AI, companies can quickly gain insights and make informed decisions about where to focus their innovation efforts [15]. Additionally, natural language processing (NLP) – a rapidly expanding non-human intermediary – can identify innovative opportunities and trends [16], while AI can manage and evaluate crowdsourced ideas for creativity and novelty [17]. Moreover, AI can augment and participate in design thinking processes, providing valuable insights and support to businesses within the innovation process [18]. With the introduction of generative AI, popular models like OpenAI’s Generative Pre-trained Transformer (GPT) models and Google’s Pathways Language Model (PaLM) and their widely popular chat interfaces ChatGPT and Bard respectively, are piloting a paradigm shift in idea generation. While AI has previously been employed predominantly for analytical innovation tasks [19], generative AI also offers potential usage in the creative process through its ability to create content, such as text, image, video, and audio. As innovative techniques intentionally try to manipulate and divert thinking patterns to develop unconventional, out-of-the-box ideas [20], the probabilistic nature of LLMs appears conducive to this type of content generation that does not require fact-checking [2]. Recent research has shed light on the multifaceted impact of AI and the resulting debates surrounding its use, opportunities, and challenges. For instance, [21] has emphasized AI's potential role in digital sustainability in achieving Sustainability Development Goals, building on the systematic review of AI for sustainability research by [22]. Meanwhile, [23] has highlighted the opportunities of AI, such as high intelligence, as well as challenges like risks of bias and deceptive intelligence. They propose that although ChatGPT does not make decisions in matters pertaining to business and society, it serves as a valuable tool that can inspire fresh ideas among humans. By offering comprehensive summaries from different perspectives, AI tools can function as both a supporter and a challenger in the process of creating and ideating. The natural language capabilities of generative AI tools like ChatGPT can substantially impact business and society, surpassing previous technologies [23]. Additionally, [24] explores the transformative potential of LLMs in making the labor market more efficient. Finally, [25] has drawn attention to the nuanced interplay of substantive and rhetorical signals in market reactions that can be positive and negative in response to AI adoption announcements. Together, these studies underscore the complex dynamics of AI and emphasize the need for collaborative exploration and consideration of ethical, economic, and societal implications. [2] suggests that innovation methods such as design thinking must be updated to make use of the new opportunities brought about by generative AI. Furthermore, the advancements in AI have led [26] to define AI creativity as “the production of highly novel, yet appropriate, ideas, problem solutions, or other outputs by autonomous machines [26, p. 351]. This study delves into the generative AI and innovation field, seeking to address a fundamental research question through empirical investigation: How do new product ideas generated by human professionals compare to those generated by ChatGPT in terms of novelty, customer benefit, feasibility, and overall quality? This approach closely aligns with previous research that compared different idea generation sources, such as professional vs. crowdsourced ideas [27]. This study augments this body of knowledge by comparing ideas produced by professionals and a specific LLM, namely GPT-3.5 as used in ChatGPT. To compare ideation performances, professionals and ChatGPT were assigned identical tasks of generating innovative ideas for a European supplier of highly specialized packaging solutions. A total of 95 ideas were generated, 43 by humans and 52 by ChatGPT. The company's managing director, an innovation expert with over two decades of experience across multiple industries, evaluated the ideas in a blind review process. This process ensured an unbiased assessment as the evaluator remained unaware of the source of the ideas. The results of this study provide new insights on integrating generative AI into creative processes, especially during the ideation phase. By shedding light on the potential of AI usage within the ideation phase, this study empowers organizations to draw on a greater variety and quality of ideas to augment their innovation strategies. Specifically, this study shows that AI-generated ideas exhibit significantly greater novelty and customer benefit than human- generated ideas, whereas idea feasibility scores similarly to human-generated ideas. Analyzing the composite overall quality score, AI-generated ideas ranked significantly higher than human-generated ideas. This study offers several contributions to businesses striving to optimize their innovation strategies and processes: 1) It provides a data-driven, systematic comparison of professional and AI-generated ideas, examining their respective novelty, customer benefit, and feasibility. 2) The analysis explores the strengths and weaknesses of AI-generated and human-generated ideas, showing how AI can complement ideation processes to enhance innovation outcomes effectively. 3) The findings provide organizations with actionable insights to finetune their innovation strategies, guiding them on when and how to harness AI capabilities within the innovation process. 4) This study highlights the potential and limitations of generative AI within the innovation process. By comparing the strengths and weaknesses of both groups of idea generators, the authors emphasize where human creativity and judgment remain indispensable while also showing the value of harmonious human-AI collaboration within innovation processes. 5) This study serves as a blueprint for systematically evaluating the potential of AI in specific ideation tasks within the innovation process. It shows the transformative potential of generative AI in innovation. II. BACKGROUND AND RELATED WORK A. Company Innovation and Creativity Historically, companies have relied on human creativity to fuel new product innovations [7] [28]. The innovation process is multifaceted and the idea generation task is a pivotal early This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 3 EMR-23-0172 development phase, attempting to bridge the gap between the problem domain and the desired solutions [7]. Professionals are primarily responsible for generating new ideas for innovation [29]. Scholars and researchers have developed various models to research the factors influencing creativity and innovation within companies [9] [7]. They have also developed methods and frameworks to enhance creativity and innovation, such as workshops with clearly defined phases [20]. New sources for innovation ideas were identified: the users and consumers of products and services [29] [30]. This shift towards external sources of innovation gained further momentum with the introduction of crowdsourcing, crowdfunding, or the lead user method, which all harnessed the creativity of external contributors like end users [31] [32] [33] [34]. Open Innovation is defined as \"the use of purposive inflows and outflows of knowledge to accelerate internal innovation and expand the markets for external use of innovation\" [35, p. 1]. This concept involves integrating external ideas and technologies within a firm's boundaries for its innovation process (outside-in aspect) and leveraging unused or underutilized internal knowledge beyond the firm's boundaries (inside-out aspect). [36] substantiates the rationale for using external knowledge sources effectively. They highlight the importance of acquiring and integrating external innovations into existing systems and processes. A pivotal study [27] revealed that both professional and user- generated ideas could be innovative. Interestingly, user- generated ideas were significantly more novel and beneficial to customers, although they tended to be less feasible. A similar study corroborated these findings, proving that user-generated product ideas may also be more successful in the market as they generate significantly higher revenues [37]. Despite these research findings on the superiority of crowdsourced or user-generated ideas, this is still not the standard procedure in most companies. In high-tech industries, innovation is highly dependent on the expertise of skilled professionals, and internal talent remains a primary source of innovation for companies [38] [39]. With the continuous evolution of generative AI, a novel source of innovation potential for companies emerges, raising the question of how these AI systems can contribute to ideation compared to human professionals. B. Generative Artificial Intelligence and Creativity As the field of generative AI faces increasing interest and substantial developments, researchers have begun to assess the creative potential of AI systems. Research shows that in 2021 the perception of innovation managers regarding AI’s role in idea generation was adamant: AI was considered relatively less important than humans for idea generation than in other domains like data analytics. Furthermore, these managers believed humans would continue outperforming AI in creativity in the next 5-10 years [19]. In 2023, researchers tested knowledge extraction and idea generation on the GPT-3 algorithm [1]. They focused on integrating AI in human ideation sessions directly on a prompt- by-prompt engineering basis. Their findings identified limitations and suggested the potential benefits of hybrid intelligence in innovation teams, wherein AI systems and human professionals collaborate in synergy [1]. In contrast, this study has the LLM innovate independently. LLMs represent a significant milestone in generative AI, with newer iterations, such as GPT-3.5 and GPT-4, showcasing exceptional capabilities. These models have demonstrated proficiency in various tasks, including passing academic and professional exams, such as the Uniform Bar Exam and the SAT Math [40]. The growing capabilities of LLMs raise intriguing questions about their creative quality potential in innovative ideation compared to human professionals. III. STUDY METHOD A. Overview This section outlines the methodology used to address the primary research question of this study: How do the new product ideas generated by a company's professionals compare to those generated by ChatGPT in terms of their novelty, customer benefit, and feasibility? To thoroughly assess this question, a cross-group blind evaluation was conducted, where an executive expert in innovation rated each idea's novelty, customer benefit, and feasibility in a recorded session in randomized order. The ratings were recorded using Typeform and augmented with iMotions Online for webcam eye tracking and facial coding analysis to check for unconscious biases during the evaluation process. The ideas for assessment will be described in Section III-B and the executive responsible for the evaluation in Section III-C below. Subsequently, the analysis strategy is elaborated in Section III-D. Additionally, it is essential to note that informed consent was obtained from all participants in compliance with GDPR before data collection. This study explores the comparative quality of human- generated ideas versus those generated by generative AI in a blind evaluation setting. To acquire human-generated ideas, the authors sought out a suitable company that met specific criteria: 1) An intention to innovate within their core business innovation segment; 2) The usage of internal professionals for generating new product ideas; 3) A willingness to provide their human-generated ideas for this experiment to compare with AI- generated ideas in their specific segment; 4) A commitment to a blind evaluation of all ideas by their executive innovation expert, based on the three dimensions to assess idea quality [27]. The company, with over 2.200 employees, is a European supplier of specialized packaging solutions that operates in the food, aroma protection, pharmaceutical, and cosmetics industries, with an increasing emphasis on sustainability in their innovation efforts. The company has numerous research and development sites as well as cutting-edge research centers and hosts design thinking workshops for employees to generate many ideas. It then evaluates these ideas for further refinement in a standardized innovation process. B. Idea Generation In response to the market’s increasing emphasis on sustainability-driven regulations, the company initiated an internal idea-generation process to maintain its competitive edge by ideating new packaging solutions. Simultaneously, the authors embarked on an AI-driven idea-generation approach. This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 4 EMR-23-0172 During the ideation process, human professionals and ChatGPT were assigned two tasks. ChatGPT took on the role of an Innovator/Scientist and was given the context that [company name] is a leading European supplier of specialized flexible packaging solutions. Task 1 required generating creative and specific ideas for new packaging solutions that add value for the company's customers. For Task 2, participants were challenged to come up with sustainable packaging solutions or business models that align with Sustainable Development Goals (SDGs) or Environmental, Social, and Governance (ESG) regulations. Each idea length was limited to five sentences. ChatGPT was prompted for 5 ideas at a time, without improvement iterations. The company’s professionals engaged in idea generation through an online brainwriting platform. This ideation session generated 65 raw ideas. 43 ideas qualified for the evaluation phase after careful review by the authors based on predefined criteria. The authors similarly reviewed the AI-generated ideas, resulting in 52 ideas selected for evaluation. Only relevant and serious ideas were accepted in the ideation session, with off- topic or sarcastic suggestions being removed. Spelling errors were corrected, and abbreviations were expanded. Ideas were rephrased in the third person, changing \"we could\" to \"[The company] could.\" To maintain anonymity in ChatGPT's responses, the claim, colon, and elaboration format was altered by removing the colon and adjusting the sentence structure for grammatical coherence where necessary. C. Idea Evaluation The final set of 95 ideas (43 human-generated and 52 ChatGPT-generated) underwent evaluation by the managing director of the company’s innovation unit. This executive, a decision-maker in the company’s new product development process, possesses extensive technical and market knowledge. The evaluations were conducted blindly, with the order of ideas randomized to minimize potential bias. Before the evaluation, the executive received comprehensive training on the evaluation criteria, including their definitions and correct application. Following established research procedures [27], the assessment of idea quality involved measuring three key variables: 1) Novelty, evaluating the idea's distinctiveness in comparison to existing market norms; 2) Customer benefit, assessing the idea's capacity to address underlying problems effectively; and 3) Feasibility, determining the ease of transforming the idea into an actual commercial product. All three variables were measured using a 5-point Likert scale (1 – very low; 5 – very high). The composite quality measure was incorporated to comprehensively compare idea quality between the two sample groups [27]. This overall quality dimension considers the combined score of novelty, customer benefit, and feasibility, replicating the formula by [27] (quality = novelty × customer benefit × feasibility), enabling a holistic assessment of each idea's overall quality. Furthermore, three binary variables were calculated to compare the best ideas. Ideas with a rating of four to five were categorized as \"top ideas\" for each dimension, while those with a rating of less than or equal to three were grouped as \"other ideas.\" This classification differentiated the top-performing ideas and the remaining ones per quality dimension. D. Idea Evaluation Setup During the recorded sessions, the evaluator viewed the ideas in randomized order, ensuring unawareness of the idea's source. The authors employed the Typeform platform to facilitate this process, providing a seamless interface for reading and evaluating each idea. Additionally, the executive’s evaluations were recorded via a webcam and screen recordings to facilitate an ex-post analysis of emotions using facial coding (affective computing) and attention using eye tracking. These measures aim to detect cognitive or emotional biases during the evaluation process. Advancements in computing capabilities now enable the detection of human attention and emotions through cognitive algorithms [41]. Affective computing technologies encompass the analysis of facial expressions utilizing the Facial Action Coding System (FACS) based on the emotion model by [42], [43]. This study employs the AFFECTIVA algorithm for facial coding and the iMotions WebET 3.0 algorithm for eye tracking via webcam [44]. E. User Sample Professionals (Group 1): In the case of company professionals' idea generation, the participants in this group consisted of seven professionals from top to lower management levels who regularly participated in similar design thinking workshops. Five professionals were part of the company’s research and development department, of which four were application engineers. The remaining two professionals were from the company’s marketing department. Generative AI Tool (Group 2): For the second group, generative AI was harnessed as the idea-generation tool. Specifically, ChatGPT (March 2023 default version with GPT- 3.5) was used to generate ideas in April 2023. The AI system represents a competent generative AI technology, offering a unique perspective in comparing idea quality. IV. ANALYSIS AND RESULTS A. Evaluation Findings First, the Mann-Whitney U Test results in Table 1 show that human ideas scored significantly lower in novelty (M = 2.65) than those generated by ChatGPT (M = 3.42; U = 740, p = 0.0039). Second, human ideas scored significantly lower on customer benefit (M = 3.07) than ideas generated by ChatGPT (M = 3.60; U = 741, p = 0.0028). Third, no significant difference exists between the human ideas’ rated feasibility (M = 2.49) and that of ChatGPT ideas (M = 2.33; U = 1250, p = .2922). The relatively low means in comparison to novelty and customer benefit indicate that idea realization is a bottleneck for both groups. Finally, the composite measure of quality shows that human ideas’ overall ratings (M = 18.95) are significantly lower than ChatGPT ideas’ overall ratings (M = 26.75; U = 734, p = 0.0039). This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 5 EMR-23-0172 TABLE I AVERAGE NOVELTY, CUSTOMER BENEFIT, AND FEASIBILITY OF PROFESSIONAL HUMAN VS. CHATGPT IDEAS Dimension Human Ideas (n = 43) ChatGPT Ideas (n = 52) U (p-value)* Mean (SD) Mean (SD) Novelty 2.65 (1.21) 3.42 (1.24) 740.5 (0.0039) Customer Benefit 3.07 (0.94) 3.60 (0.80) 741 (0.0028) Feasibility 2.49 (0.91) 2.33 (0.88) 1250.5 (0.2922) Quality** 18.95 (10.75) 26.75 (13.18) 734.5 (0.0039) * Mann-Whitney U Tests were conducted because the dependent variables have no normal distribution. ** Three-way dimension (Novelty × Customer Benefit × Feasibility) TABLE II TOP IDEAS VS. THE REST IN TERMS OF NOVELTY Novelty Human ideas ChatGPT ideas Observed (Expected) Observed (Expected) Top* 11 (16.29) 25 (19.71) Other 32 (26.71) 27 (32.29) Chi-2 (p-value) 4.15 (0.0416) *Top ideas scored four or five per respective dimension. In a typical corporate innovation funnel, the advanced stages of the innovation process focus on the highest-performing ideas. They will undergo subsequent in-depth evaluation and potential testing. Therefore, in the next step of the analysis, ideas are split into two groups: “Top ideas,” which includes all ideas scoring four or five on the 5-point Likert scale per respective dimension, and “other ideas” (see Tables 2-4). First, 36 of the 95 ideas are considered highly novel compared to existing market norms. Of these 38%, ChatGPT generated 25 while company professionals only contributed 11. Table 2 portrays the results of a chi-squared test (χ^2(1) = 4.15, p = 0.0416), showing that significantly more ChatGPT ideas and fewer human ideas were rated four or five than expected in terms of novelty. Second, 40 of the 95 ideas are categorized as highly customer beneficial. Of these 42%, more were again generated by ChatGPT, with 29 ideas compared to 11. Table 3 portrays the results of a chi-squared test (χ^2(1) = 7.6, p = 0.0058), showing that ChatGPT scored significantly higher than expected, while human ideas scored worse than expected in terms of customer benefit. TABLE III TOP IDEAS VS. THE REST IN TERMS OF CUSTOMER BENEFIT Customer Benefit Human ideas ChatGPT ideas Observed (Expected) Observed (Expected) Top* 11 (18.11) 29 (21.89) Other 32 (24.89) 23 (30.11) Chi-2 (p-value) 7.60 (0.0058) *Top ideas scored four or five per respective dimension. TABLE IV TOP IDEAS VS. THE REST IN TERMS OF FEASIBILITY Feasibility Human ideas ChatGPT ideas Observed (Expected) Observed (Expected) Top* 6 (4.98) 5 (6.02) Other 37 (38.02) 47 (45.98) Chi-2 (p-value) 0.11 (0.7371) *Top ideas scored four or five per respective dimension. Third, 11 of the 95 ideas – only 12% of all – qualified as feasible, which is very low compared to the other two dimensions. Humans are responsible for six of these ideas and ChatGPT for five, with no significant differences between the observed and expected frequencies (χ^2(1) = 0.11, p = 0.7371) in Table 4. Finally, it is worth emphasizing that no idea achieved a “top” rating in all three dimensions, which aligns with the observed negative correlation of the feasibility dimension with novelty and customer benefit. B. Correlation Analysis Table 5 shows the correlations of the quality dimensions rated in the evaluation process for human-generated ideas and Table 6 for ChatGPT-generated ideas. The correlation tables compare the relationships between the dependent variables of the human idea group and the ChatGPT idea group. The analyses indicate that novelty in both human and ChatGPT ideas positively correlates with customer benefit (p < 0.05) and negatively with feasibility (p < 0.05). Notably, the negative correlation between customer benefit and feasibility is significant for ChatGPT ideas (p < 0.001). In contrast, human ideas show a weaker negative relationship between customer benefit and feasibility (p > 0.05). This suggests that ChatGPT ideas were potentially more “out-of-the-box” and less conventional than human ideas. This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 6 EMR-23-0172 TABLE V CORRELATION OF HUMAN IDEA RATINGS Measure 1. Novelty 2. Customer Benefit 3. Feasibility 1. Novelty 1 2. Customer Benefit 0.46 1 3. Feasibility -0.55 -0.24 1 N = 43; correlations above 0.31 are significant at p < 0.05 level TABLE VI CORRELATION OF CHATGPT IDEA RATINGS Measure 1. Novelty 2. Customer Benefit 3. Feasibility 1. Novelty 1 2. Customer Benefit 0.55 1 3. Feasibility -0.54 -0.45 1 N = 52; all correlations are significant at p < 0.001 level C. Emotion and Eye Tracking Data Recognizing the potential for unconscious biases to affect the expert’s evaluations, the authors employed several measures to assess these underlying emotional and cognitive reactions. Facial coding was used, analyzing the evaluator's valence and arousal reactions for each idea, and eye tracking was employed between idea Areas of Interest (AOIs) and idea rating AOIs. This addressed four key biases: 1) Attentional Bias [45], where longer or repeated gazes at certain ideas suggest subconscious preferences; 2) Emotion-based Decision-making Bias [46], highlighting the impact of emotions on decision-making; 3) Confirmation Bias [47], comparing attention to idea information between groups; and 4) Social Desirability Bias [48], comparing attention to the rating Likert scales between groups. The evaluator’s attention allocation is consistently distributed, regardless of whether humans or AI generated the ideas. Additionally, the results of the facial coding analysis reveal no statistically significant differences in emotional responses, such as valence or arousal, observed when the evaluator assessed ideas from the two groups. These findings suggest no noticeable emotional or cognitive differences related to the source of the idea present during the evaluation process. This supports the notion that the evaluation process was conducted impartially and underscores the robustness of this study’s evaluation procedures. V. DISCUSSION A. Summary Who can generate better ideas for new innovative products: the professionals employed for the task or an AI system based on engineered prompts? This research question was approached by comparing the novelty, customer benefit, feasibility, and overall quality of ideas generated by professionals in a real- world scenario and ChatGPT-generated ideas. The findings of this study demonstrate that ChatGPT can generate significantly better ideas in terms of novelty and customer benefit. However, the bottleneck is the relatively low feasibility score for both groups. It is important to recognize that the feasibility of very early ideas, which do not yet provide detailed solution information, might be unclear. Humans may struggle to demonstrate their superiority in integrating feasibility aspects into these initial ideas, such that they offer rather limited solution information that could have been evaluated for feasibility. Also, generic LLMs may be finetuned better to reflect specific market, product, or company requirements. These specialized LLMs may be capable of generating more feasible ideas that consider the technologies a company owns, the competence they have accrued, or the brand under which the product is supposed to be launched. The underlying reason for ChatGPT’s superior performance may be the vast informational database that the AI tool draws upon to generate ideas quickly. Furthermore, ChatGPT and similar LLMs can use their growing intelligence to foster ideas that humans have not yet thought about. Finally, it does not fall victim to cognitive bias when ideating but may risk ethical bias based on training data that is potentially biased [23]. While this study provides initial proof that AI-based idea generation may already outrival human idea generation regarding overall idea quality, the authors also experienced that the AI-based ideation process appeared more efficient. The AI idea generation process required 30 minutes based on the simple prompting strategy. Additionally, the authors spent 240 minutes screening, adapting, and selecting AI-generated ideas based on the predetermined criteria. In comparison, even brief ideation sessions consume at least half a day with a group of five to ten managers and professional preparation. The facilitation and post-processing of the workshop are cost- intensive. Further findings demonstrate that ChatGPT can generate significantly more “top ideas” in terms of novelty and customer benefit than expected (p < 0.05). These results not only challenge existing literature on the potential of generative AI in the future [19] but also mark a shift in the perceived scope of AI’s applicability. In the pre-generative AI era, AI was primarily associated with analytical tasks. However, the introduction of generative AI shows where AI’s capabilities extend into the creative domain, extending its potential fields of application. However, a bottleneck exists in the realization of these ideas, as indicated by the lower than anticipated feasibility scores. This emphasizes company professionals' irreplaceable role in assessing the possibilities and boundaries within the available resources. A strategic approach may be to bolster the ideation phases through collaboration with generative AI to efficiently produce various exceptionally intriguing ideas. Subsequently, in a secondary review stage, company professionals can analyze the generated ideas, focusing on refining the top-performing concepts. This iterative process aims to uncover common ground, fostering groundbreaking advancements in novel, customer-centric, feasible, and impactful innovations. The need for a hybrid approach throughout the entire innovation process, not just in the early idea phase, is crucial. This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 7 EMR-23-0172 This study does not cover the evaluation and further development of ideas. A possible approach is to employ AI as a stimulus and inspiration for ideation, followed by human review and elaboration for more effective innovation management. B. Theoretical contributions This study offers a systematic and data-driven comparison between professional and AI-generated ideas, comprehensively assessing their novelty, customer benefit, feasibility, and overall quality. This contributes to the academic understanding of AI's potential role in innovation, building on the study by [27], that compared professional and user-generated ideas. Furthermore, this study analyses the strengths and weaknesses of AI-generated and human-generated ideas, shedding light on how AI can complement ideation processes and enhance innovation outcomes. This analysis adds depth to the academic discourse on AI and innovation. Also, by comparing the strengths and weaknesses of both idea generator groups, this study highlights the areas where human creativity and judgment remain essential. It also emphasizes the value of collaborative human-AI approaches in innovation processes. Finally, this research serves as a blueprint for systematically evaluating the potential of AI in specific ideation tasks within the innovation process. It offers a framework for future research and experimentation in this transformative field. C. Practical Implications This study contributes valuable insights for businesses aiming to optimize their innovation strategies and processes: 1) The systematic quantitative evaluation compares professional and AI-generated ideas, comprehensively assessing their novelty, customer benefit, feasibility, and overall quality. This enables organizations to make data-driven decisions about future idea selection. 2) The findings provide actionable guidance for organizations to finetune their innovation strategies. They offer insights on when and how to integrate AI capabilities within the innovation process, helping businesses navigate this transformative landscape. This research identifies scenarios where human creativity and judgment remain indispensable in innovation. It also underscores the value of balanced human-AI collaboration. Organizations can use this understanding to make informed decisions about AI integration in their innovation processes. The study suggests the importance of balanced human-AI cooperation in innovation. Businesses can develop workflows that encourage collaboration between AI tools and human experts, fostering a dynamic creative environment that is highly productive. 3) Organizations can consider integrating generative AI tools like ChatGPT into their ideation processes, particularly when seeking novel and customer-beneficial ideas. This can lead to more efficient and diverse idea generation in early ideation phases to refine iteratively in later stages. [24] shows that LLMs encompass transformative potential in making the labor market more efficient. This study involved developing and implementing ChatGPT prompts, which generated 50 raw ideas in just 30 minutes of prompt writing and idea generation. Organizing a design thinking workshop to generate ideas from humans would require more time and resources, for example, one to two days. 4) Organizations should recognize that the capabilities of generative AI models evolve rapidly. Continuous learning and adaptation of AI integration strategies are essential to staying at the forefront of innovation. 5) As AI plays an increasing role in innovation, organizations must address ethical considerations, including transparency, bias mitigation, and data privacy, to ensure responsible and ethical AI use. 6) Given the potential of generative AI to generate innovative ideas, organizations may need to allocate resources for AI implementation, training, and maintenance as part of their innovation strategies. In a business context, the results of this study can help companies refine their innovation processes by integrating AI's potential, adapting a hybrid human-AI collaborative iteration that features idea generation and development together with AI, and then focusing on stronger feasibility development by human professionals as the ideas develop and become more specific. [49] has shown the short-term substitution effect of AI on human labor in certain industries like writing-related services. Thus, companies should strive to leverage AI integration's cost and time benefits. VI. LIMITATIONS AND FUTURE RESEARCH This study has identified several potential internal and external factors that may impact the validity of the research findings. As the study is based on the analysis of correlational data, it is essential to refrain from making causal inferences about the observed relationships. Furthermore, the evaluation of ideas was conducted by a single executive. To enhance the robustness of future research, it is recommended that multiple evaluators be involved. This approach ensures consistent ratings, interrater reliability and minimizing the variance of scores. Incorporating a broader range of evaluators can improve the reliability and validity of the ratings. While this study focuses on assessing professional ideas relative to AI-generated ideas, it is noteworthy that prior research, as demonstrated by [27], has highlighted the capability of user-generated ideas to compete with professional ideas. Future research may explore the comparative analysis between user-generated and AI-generated ideas. Furthermore, a three-way comparison may be of research interest, comparing user-generated, professional-generated, and AI-generated ideas. This will further advance the understanding of the idea generation dynamics. It is important to note that this research setting pertains explicitly to a \"first-round\" ideation scenario. This scenario involves initiating a creative task to stimulate group brainstorming but does not encompass a full-fledged ideation process, as typically undertaken in creative workshops or design thinking approaches. Here, AI serves as a potent “front- loading” tool. It rapidly generates numerous ideas with minimal time and resource investment, allowing humans to expedite their creative processes. Future research may delve deeper into how AI can assist in subsequent stages of the creative process, including clustering, challenging, enriching, and combining This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 8 EMR-23-0172 ideas. Furthermore, the integration can involve both ideation and iterative cycles of prototyping and improving in a design thinking approach. This exploration can provide a more comprehensive understanding of AI's role in innovation. The authors encourage further research into the tasks that generative AI may be able to execute besides idea generation. Specifically, the study of AI for idea evaluation, without relying on primary data collected through market research, has the potential to transform user-centric innovation approaches. As suggested by [2], generative AI may play a pivotal role in bridging the gap between idea generation and prototyping, particularly in digital innovation. Text-to-code generators, for instance, can enable teams without software engineering skills to rapidly develop initial prototypes, opening new avenues for innovation and efficiency. Furthermore, besides the quality perspective, researchers could investigate the cost dimension of AI-assisted ideation by comparing costs that accrue for conventional ideation formats such as workshops or design sprints with the efforts of AI-based processes. The necessary time and financial investment could serve as relevant dimensions for comparison. Thus, additional dimensions, such as cost, efficiency, and time effectiveness, may be included in future studies for rating ideas. Finally, expanding on quantitatively examining the ideation outcomes of generative AI, the authors highlight the importance of human ideation formats from an interpersonal social perspective. While the quality of ideas is certainly an important outcome dimension of ideation sessions, the joint development in a group of managers and the intensive discussions over an extended period may help avoid the not-invented-here syndrome [50] and build a momentum that helps in the following steps of the innovation process. Future research could investigate these 'soft’ benefits of human ideation and explore how AI-generated ideas lacking the human origination process perform in the subsequent phases of the innovation process. ACKNOWLEDGMENT The authors thank the collaborating company for their willingness to participate in the ideation phase of this study. The authors also thank the participating executive for evaluating the ideas in a real-world scenario. REFERENCES [1] S. G. Bouschery, V. Blazevic and F. T. Piller, \"Augmenting human innovation teams with artificial intelligence: Exploring transformer‐based language models,\" Journal of Product Innovation Management, vol. 40, no. 2, pp. 139-153, 2023. [2] V. Bilgram and F. Laarmann, \"Accelerating Innovation with Generative AI: AI-augmented Digital Prototyping and Innovation Methods,\" IEEE Engineering Management Review, vol. 51, no. 2, pp. 1-5, 2023. [3] F. Barron, \"The disposition toward originality.,\" The Journal of Abnormal and Social Psychology, vol. 51, no. 3, pp. 478-485, 1955. [4] M. A. Runco and G. J. Jaeger, \"The Standard Definition of Creativity,\" Creativity Research Journal, vol. 24, no. 1, pp. 92-96, 2012. [5] M. I. Stein, \"Creativity and Culture,\" The Journal of Psychology, vol. 36, no. 2, pp. 311-322, 1953. [6] T. M. Amabile, \"Motivating Creativity in Organizations: On Doing What You Love and Loving What You Do,\" California Management Review, vol. 40, no. 1, pp. 39-58, 1997. [7] T. M. Amabile, \"A model of creativity and innovation in organizations,\" Research in Organizational Behavior, vol. 10, no. 2, pp. 123-167, 1988. [8] S. L. Beckman and M. Barry, \"Innovation as a Learning Process: Embedding Design Thinking,\" California Management Review, vol. 50, no. 1, pp. 25- 56, 2007. [9] T. M. Amabile and M. G. Pratt, \"The dynamic componential model of creativity and innovation in organizations: Making progress, making meaning,\" Research in Organizational Behavior, vol. 36, pp. 157- 183, 2016. [10] P. Ritala, A. Baiyere, S. Kraus and M. Hughes, \"Digital strategy implementation: The role of individual entrepreneurial orientation and relational capital,\" Technological Forecasting and Social Change, vol. 171, p. 120961, 2021. [11] Y. Maaravi, B. Heller, Y. Shoham, S. Mohar and B. Deutsch, \"Ideation in the digital age: literature review and integrative model for electronic brainstorming,\" Review of Managerial Science, vol. 15, no. 6, pp. 1431-1464, 2021. [12] M. Weiss, M. Baer and M. Hoegl, \"The human side of innovation management: Bridging the divide between the fields of innovation management and organizational behavior,\" Journal of Product Innovation Management, vol. 39, no. 3, pp. 283-291, 2022. [13] N. Haefner, J. Wincent, V. Parida and O. Gassmann, \"Artificial intelligence and innovation management: A review, framework, and research agenda✰,\" Technological Forecasting and Social Change, vol. 162, p. 120392, 2021. [14] R. Verganti, L. Vendraminelli and M. Iansiti, \"Innovation and Design in the Age of Artificial Intelligence,\" Journal of Product Innovation Management, vol. 37, no. 3, pp. 212-227, 2020. [15] C. Kakatkar, V. Bilgram and J. Füller, \"Innovation analytics: Leveraging artificial intelligence in the innovation process,\" Business Horizons, vol. 63, no. 2, pp. 171-181, 2020. [16] J. Just, \"Natural language processing for innovation search – Reviewing an emerging non-human innovation intermediary,\" Technovation, vol. 129, p. 102883, 2024. This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 9 EMR-23-0172 [17] J. Just, T. Ströhle, J. Füller and K. Hutter, \"AI-based novelty detection in crowdsourced idea spaces,\" Innovation, pp. 1-28, 2023. [18] P. Micheli, S. J. S. Wilner, S. H. Bhatti, M. Mura and M. B. Beverland, \"Doing Design Thinking: Conceptual Review, Synthesis, and Research Agenda,\" Journal of Product Innovation Management, vol. 36, no. 2, pp. 124-148, 2019. [19] J. Füller, K. Hutter, J. Wahl, V. Bilgram and Z. Tekic, \"How AI revolutionizes innovation management – Perceptions and implementation preferences of AI- based innovators,\" Technological Forecasting and Social Change, vol. 178, p. 121598, 2022. [20] A. Brem, \"Creativity on Demand: How to Plan and Execute Successful Innovation Workshops,\" IEEE Engineering Management Review, vol. 47, no. 1, pp. 94-98, 2019. [21] S. L. Pan and R. Nishant, \"Artificial intelligence for digital sustainability: An insight into domain-specific research and future directions,\" International Journal of Information Management, vol. 72, p. 102668, 2023. [22] T. Schoormann, G. Strobel, F. Möller, D. Petrik and P. Zschech, \"Artificial Intelligence for Sustainability—A Systematic Review of Information Systems Literature,\" Communications of the Association for Information Systems, vol. 52, no. 1, 2023. [23] Y. K. Dwivedi et al., \"Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy,\" International Journal of Information Management, vol. 71, p. 102642, 2023. [24] T. Eloundou, S. Manning, P. Mishkin and D. Rock, \"GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models,\" arXiv preprint arXiv:2303.10130, 2023. [25] R. Nishant, T. Nguyen, T. Teo and P.-F. Hsu, \"Role of substantive and rhetorical signals in the market reaction to announcements on AI adoption: a configurational study,\" European Journal of Information Systems, pp. 1-43, 2023. [26] T. Amabile, \"Creativity, Artificial Intelligence, and a World of Surprises Guidepost Letter for Academy of Management Discoveries,\" Academy of Management Discoveries, vol. 6, no. 3, pp. 351-354, 2020. [27] M. K. Poetz and M. Schreier, \"The Value of Crowdsourcing: Can Users Really Compete with Professionals in Generating New Product Ideas?,\" Journal of Product Innovation Management, vol. 29, no. 2, pp. 245-256, 2012. [28] N. Anderson and K. Potočnik, \"Innovation and Creativity in Organizations: A State-of-the-Science Review, Prospective Commentary, and Guiding Framework,\" Journal of Management, vol. 40, no. 5, pp. 1297-1333, 2014. [29] E. von Hippel, The sources of innovation, New York: Oxford University Press, 1988. [30] E. von Hippel, \"Lead Users: A Source of Novel Product Concepts,\" Management Science, vol. 32, no. 7, pp. 791-805, 1986. [31] A. Brem, V. Bilgram and A. Gutstein, \"Involving Lead Users in Innovation: A Structured Summary of Research on the Lead User Method,\" International Journal of Innovation and Technology Management, vol. 15, no. 3, p. 1850022, 2018. [32] O. A. Acar, \"Motivations and solution appropriateness in crowdsourcing challenges for innovation,\" Research Policy, vol. 48, no. 8, p. 103716, 2019. [33] A. Brem, V. Bilgram and A. Marchuk, \"How crowdfunding platforms change the nature of user innovation – from problem solving to entrepreneurship,\" Technological Forecasting and Social Change, vol. 144, pp. 348-360, 2019. [34] J. Füller, \"Refining Virtual Co-Creation from a Consumer Perspective,\" California Management Review, vol. 52, no. 2, pp. 98-122, 2010. [35] H. Chesbrough, W. Vanhaverbeke and J. West, Open Innovation: Researching a New Paradigm, OUP Oxford, 2006, p. 392. [36] J. West and M. Bogers, \"Leveraging External Sources of Innovation: A Review of Research on Open Innovation,\" Journal of Product Innovation Management, vol. 31, no. 4, pp. 814-831, 2014. [37] H. Nishikawa, M. Schreier and S. Ogawa, \"User- generated versus designer-generated products: A performance assessment at Muji,\" International Journal of Research in Marketing, vol. 30, no. 2, pp. 160-167, 2013. [38] F. Alvino, A. Di Vaio, R. Hassan and R. Palladino, \"Intellectual capital and sustainable development: a systematic literature review,\" Journal of Intellectual Capital, vol. 22, no. 1, pp. 76-94, 2020. [39] M. Buenechea-Elberdin, A. Kianto and J. Sáenz, \"Intellectual capital drivers of product and managerial innovation in high-tech and low-tech firms,\" R&D Management, vol. 48, no. 3, pp. 290-307, 2018. [40] OpenAI, \"GPT-4 Technical Report,\" 13 September 2023. [Online]. Available: https://cdn.openai.com/papers/gpt-4.pdf. [Accessed 13 September 2023]. [41] S. Richardson, \"Affective computing in the modern workplace,\" Business Information Review, vol. 37, no. 2, pp. 78-85, 2020. [42] P. Ekman and W. V. Friesen, PsycTESTS Dataset, 1978. [43] A. El Bolock, Y. Abdelrahman and S. Abdennadher, Character Computing, Cham: Springer International Publishing, 2020. [44] iMotions, \"iMotions WebET 3.0 Webcam Based Eye Tracking - Whitepaper v3,\" 2023. [Online]. Available: This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10 EMR-23-0172 https://go.imotions.com/WebET3Whitepaper. [Accessed 13 September 2023]. [45] J. Yiend, \"The effects of emotion on attention: A review of attentional processing of emotional information,\" Cognition and Emotion, vol. 24, no. 1, pp. 3-47, 2010. [46] J. S. Lerner, Y. Li, P. Valdesolo and K. S. Kassam, \"Emotion and Decision Making,\" Annual Review of Psychology, vol. 66, no. 1, pp. 799-823, 2015. [47] T. Nelius, M. Doelken, C. Zimmerer and S. Matthiesen, \"The impact of confirmation bias on reasoning and visual attention during analysis in engineering design: An eye tracking study,\" Design Studies, vol. 71, p. 100963, 2020. [48] O. Kaminska and T. Foulsham, \"Eye-tracking Social Desirability Bias,\" Bulletin of Sociological Methodology, vol. 130, no. 1, pp. 73-89, 2016. [49] X. Hui, O. Reshef and L. Zhou, \"The Short-Term Effects of Generative Artificial Intelligence on Employment: Evidence from an Online Labor Market,\" SSRN Scholarly Paper, 2023. [50] D. Antons and F. T. Piller, \"Opening the Black Box of “Not Invented Here”: Attitudes, Decision Biases, and Behavioral Consequences,\" Academy of Management Perspectives, vol. 29, no. 2, pp. 193-217, 2015. Jan Joosten received a Bachelor of Science degree in business administration from Nuertingen-Geislingen University (HfWU), Nuertingen, Germany, in 2020, and a Master of Arts degree in international marketing from Nuremberg Institute of Technology, Nuremberg, Germany, in 2021. He is a Research Assistant in marketing with the Nuremberg Institute of Technology, Nuremberg, Germany, and a Doctoral Student at the University of Passau, Germany. Volker Bilgram received a diploma degree in international business law from Friedrich Alexander Universität Erlangen- Nürnberg, Erlangen, Germany, in 2008, and a Ph.D. degree in business and social sciences from RWTH Aachen University, Aachen, Germany, in 2017. He is a Professor of global innovation management with the Nuremberg Institute of Technology, Nuremberg, Germany, and a Partner of the innovation consultancy HYVE, Munich, Germany. His research focuses on AI-based innovation management, service design, digital business models, and sustainable product development. Alexander Hahn received a diploma and a Ph.D. degree in business administration from Friedrich University of Mannheim, Germany. He is a Professor of user experience research and emotion artificial intelligence with the Nuremberg Institute of Technology, Nuremberg, Germany. His research focus is on customer-centric innovation and user experience research. Dirk Totzek received a diploma and a Ph.D. degree in business administration from the University of Mannheim, Germany. He is a Professor of marketing and Chair of marketing and services at the University of Passau, Germany. His core research areas are pricing, service research, and business- to-business marketing. This article has been accepted for publication in IEEE Engineering Management Review. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/EMR.2024.3353338 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/","libVersion":"0.3.1","langs":""}