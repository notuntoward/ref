{"path":"lit/lit_notes_OLD_PARTIAL/Ghimire19irradFrcstCNN-LSTM.pdf","text":"Contents lists available at ScienceDirect Applied Energy journal homepage: www.elsevier.com/locate/apenergy Deep solar radiation forecasting with convolutional neural network and long short-term memory network algorithms Sujan Ghimirea, Ravinesh C. Deoa,⁎, Nawin Raja, Jianchun Mi b a School of Agricultural Computational and Environmental Sciences, Centre for Sustainable Agricultural Systems & Centre for Applied Climate Sciences, University of Southern Queensland, Springﬁeld, QLD 4300, Australia b Department of Energy & Resources Engineering, College of Engineering, Peking University, China HIG HLI GHTS • Deep learning hybrid model is pro- posed for solar radiation prediction. • Convolutional network is used to ex- tract features for solar radiation. • Long Short-Term Memory is used for prediction of solar radiation. • Deep learning hybrid model outper- forms all comparative models. • The model can be adopted as a deci- sion-support tool in solar energy si- mulation. GRAPHICAL ABSTRACT ARTIC L E I NF O Keywords: Energy security Solar energy monitoring system Short-term solar radiation prediction Convolutional neural network Long short term memory network Decision support system ABSTRAC T This paper designs a hybridized deep learning framework that integrates the Convolutional Neural Network for pattern recognition with the Long Short-Term Memory Network for half-hourly global solar radiation (GSR) forecasting. The Convolution network is applied to robustly extract data input features from predictive variables (i.e., statistically signiﬁcant antecedent inputs) while Long Short-Term Memory absorbs them for prediction. Half-hourly GSR for Alice Springs (Australia: 01 January 2006 to 31 August 2018) are extracted with stationarity checks applied via unit-root and mutual information test to capture antecedent GSR values required to forecast future GSR. The proposed hybrid model is benchmarked with standalone models as well as other Deep Learning, Single Hidden Layer and Tree based models. The results show that the benchmarked models are not able to generate satisfactory GSR predictions and the proposed hybrid model outperforms all other counterparts. The hybrid model registers superior results with over 70% of predictive errors lying below ± 10 Wm −2 and out- performs the benchmark model for 1-Day half-hourly GSR prediction with low Relative Root Mean Square Error (≈1.515%), Mean Absolute Percentage Error (≈4.672%) and Absolute Percentage Bias (≈1.233%). This study ascertains that a proposed hybrid model based on a convolution network framework can accurately predict GSR and enable energy availability to be regularly monitored over multi-step horizons when coupled with a low latency Long Short-Term Memory network. Furthermore, it also concludes that the proposed model can have practical implications in forecasting GSR, capitalizing its versatility as a stratagem in monitoring solar powered systems by integrating freely available solar radiation into a real power grid system. https://doi.org/10.1016/j.apenergy.2019.113541 Received 8 April 2019; Received in revised form 6 June 2019; Accepted 11 July 2019 ⁎ Corresponding author. E-mail addresses: sujan.ghimire@usq.edu.au (S. Ghimire), ravinesh.deo@usq.edu.au (R.C. Deo). Applied Energy 253 (2019) 113541 0306-2619/ © 2019 Published by Elsevier Ltd. T 1. Background According to the World Energy Outlook (WEO) 2017, with in- creasing the world’s population in coming decades, the global energy demand is likely to increase by an additional 30% from 2016 to 2040 with 40% alone coming from an expected increase in consumer elec- tricity usage [1]. Due to growing concerns about environmental pol- lution caused by greenhouse gases, the recommendations from United Nations Environment Program (UNEP) through Sustainable Develop- ment Goal # 7 aims to develop cleaner energy technologies [2], in- cluding the exploration of renewable energy sources (RES) is steadily increasing, and resulting in an expectation that governments will invest in the RES sector. WEO has projected that about two thirds of the future global investments for building new power plants will be focused on renewable energy sources by 2040, with the largest amount being de- rived from the Sun [1]. In Australia, the Federal Government aims to obtain 33,000 Gigawatt-hours of electricity from renewable sources by 2020. Consequently, at the end of 2018, two million homes in Australia already had rooftop solar systems, with an average of six solar panels per minute currently being installed for solar photovoltaic (PV) systems [3]. This clearly reveals a continuous growth of the global market share of solar energy. Therefore, a near real-time predictive model that monitors solar energy conversion eﬀectively, its performance and en- ergy throughput, is considered to be an ideal scientiﬁc contrivance to design a robust energy security platform. The design of a global solar radiation (GSR) based predictive model has been researched extensively where many previous studies em- ployed data-driven predictive approaches utilizing antecedent ﬂuctua- tions in solar radiation. The models capture statistically signiﬁcant re- lationships between solar intensity and meteorological variable(s). For example, Perez et al. [4] designed a forecast model using sky cover against ground and satellite-derived irradiance. Their method out- performed mesoscale models in all tested sites with a –2% relative bias and a 35% relative root-mean-squared error for less than 4-hour lead- times. Hejase and Assi [5] developed autoregressive integrated moving average (ARIMA) and artiﬁcial neural network (ANN) model to predict solar intensity for Al-Ain (United Arab Emirates). An ARIMA model was used to predict hourly and daily GSR using clearness index [6,7].A statistical model was used for short-term GSR predictions with a mean square error 0.04 to 0.4 [8,9] whereas a short-term study [10] utilized regression techniques on all-sky images to predict solar radiation at 5 min in advance with mean absolute error of 22%. Recently, GSR model was proposed using consecutive hours as a structured output [11] whereas Monjoly et al. [12] proposed a hybrid multiscale de- composition model for hourly GSR. Support vector regression (SVR) has been applied in the studies [13,14], ANN in [9,15] while Sharma et al. [16] proposed a mixed wavelet ANN for solar prediction at 1-hour and 15-minute lead times. Models based on satellite imageries and sky photographs that in- tegrate weather parameters, have also been employed with a forecast horizon of minutes to hours [17,18]. However, for short-term GSR predictions, the errors in such models can be relatively low; yet, the errors can also vary depending on the context of applications. For in- stance, see the studies [15,19] or consider [20] where the percentage error ranged from 30 to 40% while relative root mean square error was 23–28% [19]. While these studies have demonstrated good ability of data-driven models to generate short-term GSR predictions, the errors are outside a range of ‘excellent’ or ‘very good’ model. This can be veriﬁed from Mohammadi et al., [21,22] where less than 10% (ex- cellent) and 20% (very good model) are recommended. Hence it is an ongoing motivation and an open problem of interest to continue im- proving short-term forecast models, particularly for near-real time forecasts as a predictive tool for modern energy management system. In spite of a majority of data-driven models (e.g., ANN, SVR or ARIMA) generating acceptable result, their ability to attain accurate predictions over short-term, is constrained by the prevalence of con- voluted input(s) with intermittent or stochastic features caused by cloud cover and related factors. Some relevance may be drawn from the recent study [23] where a sophisticated Deep Learning (DL) algorithm was proposed for a PV system, primarily to enhance the accuracy of their short-term model. That study preferred a Convolutional Neural Network (instead of a conventional Single Hidden Layer Neural Net- work, SHLNN) to address short-term solar variability that was expected to cause instabilities in a PV output. Such changes were due to sudden Nomenclature List of acronyms ANN Artiﬁcial Neural Network APB Absolute Percentage Bias AR Autoregressive ARIMA Autoregressive Integrated Moving Average BOM Bureau of Meteorology CNN Convolutional Neural Networks CPU Central Processing Unit DBN Deep Belief Network DL Deep Learning DNN Deep Neural Network DT Decision Tree LM Legates & McCabe’s Index ELM Extreme Learning Machine ENS Nash–SutcliﬀeEﬃciency GA Genetic Algorithm GP Genetic Programming GRU Gated Recurrent Unit GSR Global Solar Radiation GSRobs Observed GSR GSRpred Predicted GSR IEA International Energy Agency KGE Kling-Gupta Eﬃciency L2 Lasso regularization LST Land Surface Temperature LSTM Long Short-Term Memory MAE Mean Absolute Error MAPE Mean Absolute Percentage Error MBE Mean Bias error MIR Mutual Information Regression ML Machine Learning MLP Multi-Layer Perceptron MLR Multi-Linear Regression MRA Multi-Resolution Analysis MSE Mean Squared Error N Length of dataset PACF Partial Auto-Correlation Function PE Prediction Error PV Solar Photovoltaic r Pearson’s Correlation coeﬃcient rcross Cross-Correlation Function ReLU Rectiﬁed Linear Unit RMAE Relative MAE RMSE Root-Mean-Square-Error RNN Recurrent Neural Network RRMSE Relative Root-Mean-Square Error SILO Scientiﬁc Information for Land Owners SLFN Single Layer Feed-forward Neural network SVR Support Vector Regression S. Ghimire, et al. Applied Energy 253 (2019) 113541 2 changes in meteorological conditions, but more importantly, they af- fected power outputs over timescales of minutes. In the context of fragmentarily available information, this paper proposes a new approach exploring the DL technology to improve a short-term (i.e., half-hourly) GSR prediction model. Many previous studies (e.g., [24,25]) show that DL can attain a greater accuracy compared to a SHLNN model, as it has a good ability to tackle problems with relatively complex function approximation because of its non- linear mapping capability, and enables the analysis of convoluted (i.e., intermittent, stochastic) data [26]. Despite their merits, only a handful of research has applied this technique broadly to the renewable energy, such as wind power (e.g., [27–29]) and solar energy (e.g., [15,30]). Recently, Torres et al. [31] utilized the Deep Neural Network (DNN) to predict GSR (6-hourly) for 25 locations in the Netherland, showing that the DNN model outperformed the traditional models with low Relative Root Mean Square Error (31.31%). Also, Srivastava and Stefan [32] and Qing and Niu [15] implemented Long Short-term Memory (LSTM) model for forecasting day-ahead global horizontal irradiance. However, to the best of the authors’ knowledge, no prior study has used Con- volution Neural Network integrated with LSTM (CLSTM) model to predict short-term (i.e., sub-hourly or hourly scale) solar radiation and to facilitate a model tailored for multiple forecasting horizons required in a practical hybrid energy management system. This paper adopts DL to capitalize its beneﬁts for short-term fore- casting; primarily, to overcome limitations of conventional data-driven models (e.g., SHLNN) since SHLNN is unable to capture short and long- term dependency between a target (e.g., future solar radiation) and the corresponding antecedent variable(s). In addition, SHLNN cannot be used directly with big data due to the issues of scalability, and they may not have suﬃciently sophisticated architecture to extract convoluted patterns. Notwithstanding these, conventional models are likely to have a high latency and, hence, to delay the transfer of information from a neuronal to a predictive output space [15,33]. By contrast, a LSTM- based DL model has the ability to resolve vanishing gradient issues by including 3 unique gates: input, forget and output. The gates attempt to explore relationships and interactions of sequential data, making it suitable to represent the learning data over diﬀerent temporal domains. Ma et al. [34] utilized remote microwave sensor data with LSTMs for traﬃc speed prediction, Zhao et al. [35] proposed destination correla- tion matrix reﬂecting correlations of links within a road and spatio- temporal correlation for traﬃc volume prediction. Several LSTMs were also tested [36,37], for example, Gensler et al. [38] used auto encoder realizing feature learning with LSTM to predict solar power, whereas Qing et al. [15] developed LSTMs to predict hourly day-ahead solar irradiance for Cape Verde. In this study, the LSTM model was developed to avoid issues of overﬁtting the inputs and target variables, and this model also attained a better generalization outcome when compared with conventional models (e.g., ANN). Importantly, root mean square error for LSTM algorithm was lower by 42.9% in respect to the ANN model. Other than LSTMs, the CNN algorithm, which has been adopted in this study, possesses excellent abilities in extracting nonlinear, intrinsic features using a convolutional process with the pooling operations put in place [39]. Consequently, if the CNN is used in real energy fore- casting device, it is possible that the pertinent issues associated to various forms of power reliability in a real-time energy monitoring system can be overcome by an integrated LSTM and CNN framework. This can help design a robust energy monitoring device for short-term (i.e. near real-time) forecasts that may be generally diﬃcult to attain. However, the potential integration of LSTM with CNNs for short-term GSR prediction is yet to be established in any study. To address gaps in knowledge that advocate a need for versatile energy management devices to assist in integrating solar energy variability behavior into real-time systems, the novelty of this paper is to design a new deep learning predictive model based on an integration of the CNN and LSTM algorithms tailored for short-term GSR predic- tions. This study also aims to emulate the CNN + LSTM model at multi- step forecast horizons. Following earlier works (e.g., [23]), the CNN algorithm is incorporated to extract intrinsic features of the GSR series, while in the second phase LSTM [32] is connected to CNN to utilize all relevant features for the purpose of prediction. This paper designs, and then evaluates CLSTM hybrid predictive model with nonlinear data pre- processing and mapping capability, seeded by a CNN, to obtain accu- rate GSR predictions. To achieve this, a time series model comprised of half-hourly GSR inputs at a solar-rich site (Alice Springs, Australia) is used. To validate the capability of DL models, the performance is compared with stan- dalone models: CNN, LSTM and other DL models (i.e., RNN; GRU; DNN) including a SHLNN (i.e., Multi-Layer Perceptron, MLP) and a regres- sion-based Decision Tree (DT). To also explore the eﬃcacy of the newly designed predictive framework, the half-hourly GSR model is evaluated at multiple time-step horizons: 1-Day, 1-Week, 2-Week and 1-Month forecasts, and it is benchmarked with statistical metrics and visual analysis of the forecasted and measured solar radiation. This study is designed to further advance other recent works in this area, particu- larly, developing data-driven models for solar radiation and energy demand predictions in Australia (e.g., [9,40–43], aiming to support ongoing research in renewable energy utilisation consistent with United Nations Sustainable Development Goal # 7. 2. Theoretical overviews For completeness, in this section we provide a brief overview of the objective model (i.e., LSTM & CNN). The theoretical explanations of RNN [44], GRU [45], DNN [46], MLP [47] and DT [48] are all eluci- dated elsewhere since they are well-known methodologies. The RNN Fig. 1. Topological structure of the objective predictive model designed for the prediction of short-term (i.e., half-hourly) global solar radiation: (a) Long Short-Term Memory (LSTM) Networks, and its comparison with (b–c) Recurrent Neural Networks (RNN) and Gated Recurrent Unit neural networks (GRU). Note: [xtis the new input, ht is the hidden state, −ht 1 is last hidden state, ∼ Ct is cell state, ∼ −Ct 1 is the previous cell state, tanh is the hyperbolic tangent function, ot is output gate and σ is the logistic sigmoid function]. S. Ghimire, et al. Applied Energy 253 (2019) 113541 3 predicts the random sequence of inputs due to internal memory that stores information on previous calculations whereas GRU similar to RNN but with additional gates (update gate and reset gate) (Fig. 1). Furthermore, DNN is more complex than SHLNN as it represents a fully connected MLP composed of more than one hidden layer where suc- cessive layers use outputs from previous layer as the potential input [49]. Although diﬀerent DL architectures are currently available, the popular ones are the feed-forward networks with back-propagation for the learning process [50], as adopted in this study for comparison with CLSTM model. Additionally, in this paper the ANN based on MLP conﬁguration [51] for benchmarking is developed. Detailed presentation of ANNs was given in other works [52,40] with recent applications also reporting ANN used for GSR prediction [9,49]. This study also adopts tree based model (DT) for benchmarking, a model used previously in solar radia- tion prediction problems [53]. DT is a recursive-partitioning regression with non-parametric hierarchical model that applies a sequence of re- cursive splits on observations to gather similar observations in smaller regions of the input space. 2.1. Feature extraction algorithm: Convolutional Neural Networks (CNN) CNN is adopted to construct a hybrid CLSTM predictive model for half-hourly GSR predictions. CNNs are Feed Forward Neural Networks [50]. However, very few studies (e.g., [23]) have applied CNN in energy applications, and in fact, there are none for short-term prediction. To increase its eﬀectiveness of modelling complex data, the CNN algorithm typically utilizes 3 mapping layers, namely the convolutional layer, pooling layer and the fully-connected (i.e., dense) layer. Convolutional layers are used to discover local relationships in inputs while pooling layer gradually reduces the dimension relative to a target variable. Typically, a CNN has several levels of convolutional-pooling layers and in each, several convolution runs are performed. The fully-connected layer is used to predict a target variable based on features in input variables. CNN has proven to be a reliable technology for extracting hidden features, used to automatically create ﬁlters for various data patterns [54]. In the same convolutional layer of a CNN framework, there are no connections between neurons and ﬁlter weights shared between each other. Compared with a conventional model (e.g., MLP) with the same layers and neurons, the CNN can be trained quite eﬃ- ciently. Each convolutional layer designed to extract patterns in GSR (i.e., target) and its related input variable (i.e., antecedent lagged matrix) is depicted as follows [55]: =∗ +hf W x b(( ) )ij k k ij k (1) where f denotes the activation function, W k is the weight of the kernel connected to kth feature map and the star ∗is an operator of the con- volutional process. In this paper, the 3 convolutional layers are considered as the channels selected by a grid search. They utilize rectiﬁed linear units (ReLU) and adaptive moment estimation (Adam) as the activation and optimization algorithms, respectively with the ReLU deﬁned as: =f xx() max(0, ) (2) To simplify the modelling processes and also to satisfy the real-time implementation of a short-term GSR predictive framework, a one-di- mensional (1-D) convolution operator has been used to directly predict the 1-D GSR dataset. 2.2. Time sequential predictive algorithm: Long Short-Term Memory Network (LSTM) As a signiﬁcant advantage, LSTMs that take into account depen- dence between consecutive events on a relevant time stamp (e.g., minutes or hours) of the same day or another forecast period are well suited for the sequential prediction of the short-term global solar ra- diation. This is a special type of RNN [56,57] that has found some applications in the renewable energy area [58,59]. As a distinctive type of RNN, LSTMs utilize special units (i.e., memory blocks) that take the place of a traditional neuron [60,61].In LSTMs, there exist units deﬁned as the input, output and forget gate in memory blocks that give LSTMs the ability to update and control in- formation ﬂow in separate blocks [62]. This capability of LSTMs can be relative advantageous for a short-term, near real-time forecast model for solar powered electricity since it is likely to enable a grid system to continuously update the next forecast through the use of its input, output and forget gate information in respective memory blocks. Basic calculations performed within LSTMs are exempliﬁed in Fig. 1, as described in 4 separate steps [63]: I. According to the last hidden state, −ht 1 and new input xt, LSTM is able to determine the information that is to be thrown away from the cell state represented by the “forget gate” ft: Fig. 2. Topological structure of feature extraction algorithm (Convolutional Neural Network, CNN) that has been integrated with the objective predictive algorithm (Long Short Term Memory Networks, LSTM) in this study used to construct CLSTM hybrid model in the GSR prediction problem. The forecasting horizon was up to n- months (n = 1, 2, 3, 4, 5, 6, 7, & 8) lead time-step based on half-hourly trained CLSTM model. S. Ghimire, et al. Applied Energy 253 (2019) 113541 4 =+−f σW h x b(·[ , ] )t ft t f1 (3) In Eq. (3), −ht 1 denotes the last previous state; xtis the new input; Wf is the weigh matrices; bf is the bias vector and ⋯σ () is the logistic sig- moid function. II. The next step is to decide what information will be stored in the cell state. This has a new candidate cell state ∼ Ct that is generated, scaled by the “input gate” it: =+ ∼ −CW h x btanh( ·[ , ] )tC t t C1 (4) =+−i σW h x b(·[ , ] )ti t t i1 (5) In Eq. (4), ⋯tanh( ) is the hyperbolic tangent function. III. The new cell state Ctis updated, through combining the previous cell state −Ct 1and the new candidate cell state ∼ Ct, where the former is aﬀected by the “forget gate” ft and the latter is scaled by “input gate” it .: =∗ + ∗− ∼ fi CC Ct t tt t1 (6) IV. Finally, the output process is divided into two steps. A new gate called “output gate” ot is built to decide what parts of the cell state are to be outputted. The cell state Ct activated by tanh function is ﬁltered through multiplying by ot. The multiplication result is the desired output ht: =+−o σW h x b(·[ , ] )to t t o1 (7) =ho ·tanh(C )tt t (8) Fig. 1 illustrates a topological structure of LSTM framework in- cluding its comparison with RNN and GRU. 2.3. Convolutional Long Short-Term Memory (CLSTM) neural network To construct a functional feature extraction and predictive model framework with deep learning technology, this research designs a CLSTM hybrid model (Fig. 2) where the CNN layers are employed to extract features related to the future solar radiation changes and the LSTM layer is used to incorporate these features for the low latency prediction of the time series data of GSR. Fig. 2 shows the topological structure of a CLSTM hybrid model used in GSR prediction. 3. Materials and method 3.1. Study area This study employs hour-hourly data from Alice Springs: a solar rich city that lies just south of the Tropic of Capricorn, Central Australia. Alice Springs has a modest population of 28,000 with a desert climate (BWh) as per the Köppen climate classiﬁcation occupying 9% of Northern Territory. The climate is reﬂective of semi-arid conditions with hot summer temperature, a mean daily maximum temperature exceeding 30 °C for 6 months in a year with 300 days of sunshine. A typical sunshine day for a 1.0 m 2 exposed area at the noon period, the solar radiation received is expected to yield about 1 kW of power from the Sun [64]. In Alice Springs, temperatures can vary by up to 28 °C [65]. In summer, the average maximum temperature lies in mid-30 s, whereas in winter the average minimum temperature is 5.5 °C, with an average of 12.4 nights that lie below the freezing point every year. The GSR data used to construct a CLSTM hybrid model are extracted from Australian Bureau of Meteorology (BOM) repository [53]. To ac- quire these data, BOM typically uses matched sensors for diﬀuse and global pyranometry in such a way that there is a 95% conﬁdence thatTable1ThesegregationofavailabledatafordesigningCLSTMhybridpredictivemodelintermsofthetraining,validationandtestingsubsetsusedforthehalfhourlyGSRpredictionproblem.PurposeofDataset&ForecastHorizonTrainingValidationTestingPeriodDatapointIntervalPercentageofTrainingDataPeriodDatapointIntervalPercentageofTrainingData1-Dayprediction01-Jan-06to26-Aug-1860,74330min10%27-Aug-182330min0.04%1-Week(1W)Prediction01-Jan-06to19-Aug-1860,74330min10%21-Aug-18to27-Aug-1816130min0.27%2-Week(2W)prediction01-Jan-06to12-Aug-1860,74330min10%14-Aug-18to27-Aug-1832230min0.53%1-Month(1M)Prediction01-Jan-06to31-Jul-1860,74330min10%01-Aug-18to27-Aug-1862130min1.02%2MonthsPrediction01-Jan-06to30-Jun-1860,74330min10%01-Jul-18to27-Aug-18128030min2.11%3MonthsPrediction01-Jan-06to30-May-1860,74330min10%01-Jun-18to27-Aug-18191330min3.15%4MonthsPrediction01-Jan-06to30-April-1860,74330min10%01-May-18to27-Aug-18253930min4.18%5MonthsPrediction01-Jan-06to30-Mar-1860,74330min10%01-Apr-18to27-Aug-18294130min4.84%6MonthsPrediction01-Jan-06to30-Feb-1860,74330min10%01-Mar-18to27-Aug-18359330min5.92%7MonthsPrediction01-Jan-06to30-Jan-1860,74330min10%01-Feb-18to27-Aug-18431530min7.10%8MonthsPrediction01-Jan-06to31-Dec-1760,74330min10%01-Jan-18to27-Aug-18507730min8.36% S. Ghimire, et al. Applied Energy 253 (2019) 113541 5 ensures a less than 1% change in the sensitivity of the instrument over a 12 month period due to any sensor degradations [66]. This study uti- lizes time series of GSR (over preceding 1 min intervals) from 01 Jan- uary 2006 to 27 August 2018 from BOM Station ID: 015,590 [Alice Springs airport; Lat.−23.79 S,0 Long. 133.89 E0 ]). Notably, GSR measure- ments have been performed simultaneously, 24 h a day, at equidistant time intervals of 1 min. Only the data from 07:00 AM to 06:00 PM over a 30-minute interval are used for designing CLSTM hybrid predictive model as these times represent a period of meaningful daylight hours. Due to equipment faults or site closure in a period, there have been some missing data, ﬁlled with mean value of previous years as a common practice. For instance, in BOM database, 20% of GSR data for March (2018) were missing and ﬁlled with mean values from March months of 2006 – 2017. 3.2. Design of the GSR predictive model In this study, the objective algorithm (i.e., CLSTM hybrid predictive model) and all of the other comparative algorithm (i.e., Deep Learning & Conventional Models) are developed under Intel core i7 @ 3.3 GHz and 16 GB memory computer. For the model construction, Python Software [67], owing to its freely available libraries based on deep learning (DL) abilities (i.e., Keras [68], Tensor Flow [69] & Sklearn [70]), have been used. It should be noted that the Keras library is a high level DL tool written in Python but it is also capable of running on Tensor Flow and Theano [71]. In particular, Keras allows users to fully capitalise on its easiness of installation and operation, including fast prototyping, user friendly, modular and extensible framework to in- tegrate CLSTM hybrid model as a real-time (e.g., web-based backend) running on both CPU and GPU (https://keras.io/). In context of a real- time forecast model, this tool can tailored for regular monitoring of solar-sourced energy. Other programming tools such as MATLAB [72] are used for plotting while Minitab [73] is used for statistical analysis of modelling data. The primary scope of this study is to design a CLSTM model that is able to forecast short-term GSR using half-hourly interval data, but the model is implemented over multi-step forecast horizons (i.e., 1-Day up to 8-Months). Hence, the primal task is to construct a matrix of training and testing set. To illustrate the model design procedure, Table 1 details of the forecast lead time in the training, validation and testing phases with data from 01-January-2006 to 27-August-2018. Thus, the CLSTM hy- brid model is constructed with large a relatively training set (60,743 points) spaced temporally at a 30-minute intervals with the 10% of all training data employed for the model validation purposes. Importantly, the CLSTM hybrid predictive model is tested for a 1-Day forecast hor- izon over a full diurnal cycle (i.e., 23 test points), 1-Week forecast horizon over a 7-day period (i.e., 21-August-2018 to 27-August-2018; (a) (b) Correlation Coeﬃcient, r Fig. 3. (a) Partial autocorrelation function (PACF) plot of the GSR time series showing antecedent behaviour in terms of the lag of GSR every 30 min. (b) Mutual information test used to validate PACF for the input matrix of 6 antecedent lagged GSR to design CLSTM hybrid model. The blue line in PACF is used to show the zone outside which GSR has statistically signiﬁcant correlations with its historical values, as also depicted by green circles. (For interpretation of the references to colour in this ﬁgure legend, the reader is referred to the web version of this article.) S. Ghimire, et al. Applied Energy 253 (2019) 113541 6 161 points), 2-Week forecast horizon over a 14 day period (i.e., 14-Aug- 18 to 27-Aug-18; 322 points) and 1-Month forecast horizon over a 30 day period (i.e., 01-Aug-18 to 27-Aug-18; 621 points). The model is also tested over 2, 3, 4, 5, 6, 7 and 8-Monthly horizons with the test phase data ranging from 2.11 to 8.36% of the total training set spaced over a 30 min interval. It is imperative to note that the CLSTM hybrid predictive model in this study is designed with an identical number of data points for various forecast horizons to ensure a universal, tempo- rally representative model is constructed for multi-step horizons. To design the CLSTM hybrid predictive model, the ﬁrst step in data preparation stage is to deduce whether the GSR series were stationary, so for this purpose, the Dicky–Fuller (DF) test has been utilized. The application of DF test indicates that the null-hypothesis, i.e., the con- sidered GSR time series are nonstationary, is false. The second step is the correlation analysis to identify the order of the model. For this, the autocorrelation function (ACF) analysis is adopted to determine the input of the GSR prediction model, i.e., determine the input values that have maximum correlation to the prediction values. The ACF analysis is widely used in prediction task (see [26] or [29]). Since GSR time series data is stationary, ACF is strongly periodic with the period of 24-hours. Furthermore, the autocorrelation function at 30-minute interval decays at values lower than 0.37 (Fig. 3a), the so-called correlation time (τc), in about 3 h (i.e., 6 lags of 30 min). Considering xtas the time series variable, the vector ( −− − − −xx x x x x,, , , ,tt t t t t54 3 2 1 ) is then used as the input to predict the value +xt 1at next step. Since the autocorrelation is a linear feature of the time series, while nonlinear processes are possibly involved with GSR changes, it is useful to estimate also the mutual information, as shown in Fig. 3(b). A popular rule, referred to as the ﬁrst minimum criterion, usually considered in evaluating the mutual information, is that two samples can be considered statistically independent if they are delayed by a number of samples equal to the time needed for the mutual in- formation to reach the ﬁrst minimum. By using this criterion at the half-hourly time scales, we note clearly that the two samples (i.e., inputs and target) can be considered to be statistically independent if they are delayed by about 6 antecedent lagged values on the time-scale (Fig. 3b). Thus, the mutual information analysis conﬁrms the results gleaned by the partial autocorrelation function at the 30-min interval to allow 6 antecedent lagged GSR series to be used as an input matrix for the CLSTM hybrid predictive model. All of the model input data (i.e., half- hourly lagged GSR matrix) as per Table 1, were normalized [9] to be in the range of [0–1]: = − − X XX XX n actual min max min (9) =− +XX X X X()actual n max min min (10) Subsequently, data are segregated into training and testing sets as Table 2 Architecture of CLSTM hybrid predictive model vs. standalone CNN, LSTM, DNN, MLP and DT models. Note: ReLU, Adam and lbfgs represent the Rectiﬁed Linear Units, Adaptive Moment Estimation and Limited Memory Broyden–Fletcher–Goldfarb–Shanno algorithm, respectively. Model Model Hyper-parameter Names Search Space for Optimal Hyper-Parameters CLSTM Filter1 [50, 80, 100, 200] Filter 2 [40, 50, 60, 70, 80] Filter 3 [20, 10, 30, 5] LSTM cell units [40, 50, 60, 100, 150] Epochs [1000, 1200, 300, 400, 700] Activation function [ReLU] Optimizer [Adam] Batch Size [400, 500, 800, 1000, 750] CNN Filter1 [50, 60, 100, 200] Filter 2 [40, 50, 60, 70, 130] Filter 3 [20, 10, 30, 5] Activation function [ReLU] Optimizer [Adam] Epochs [1000, 1200, 300, 400, 700] Batch Size [400, 500, 800, 1000, 750] LSTM LSTM cell 1 [50, 60, 100, 200] LSTM cell 2 [40, 50, 60, 70, 130] LSTM cell 3 [20, 10, 30, 5] LSTM Cell 4, 5 and 6 [Fixed as 30, 20, 10] Epochs [1000, 1200, 300, 400, 700] Activation function [ReLU] Optimizer [Adam] Drop rate [0.1, 0.2] Batch Size [400, 500, 800, 1000, 750] DNN Hiddenneuron 1 [100, 200, 300, 400, 50] Hiddenneuron 2 [20, 30, 40, 50, 60, 70] Hiddenneuron 3 [10, 20, 30, 40, 50] Hiddenneuron 4 [5, 6, 7, 8, 12, 15, 18] Activation function [ReLU] Optimizer [Adam] Epochs [1000, 1200, 1500, 1800, 2000] Batch Size [800, 1000, 1200, 1500, 1700, 400] MLP Activation [ReLU, logistic, tanh] Solver [Adam, lbfgs] Learning rate ['constant', 'invscaling', 'adaptive'] Maximum iteration [500, 1000, 1500, 2000] Hidden Layer Size [(100,), (150,), (50,),(200,),(40,),(75,)] Decision Tree Maximum depth of the tree. [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] Minimum samples to split internal node [2, 3, 5, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26] Number of features for best split ['auto', 'sqrt', 'log2′] S. Ghimire, et al. Applied Energy 253 (2019) 113541 7 demonstrated in Table 1 with half-hourly GSR predictive model tested for the year 2018 over a range spanning from 1-Day up to an n-Month forecasting horizon where n = 1 to 8 in increments of 1. Following the preparation of the model design data matrix, a three- layer CNN, a six-layer LSTM, a 4-layer hybrid CLSTM and a 6-layer DNN model have been designed whose theoretical details are already given in Section 2. The hyper-parameters (as stated in Table 2) for all re- spective models are selected based on a grid search procedure, as also illustrated in Table 3. The high computational cost associated with the learning procedure of ML models is a signiﬁcant issue; this cost is di- rectly linked with the dataset size used for training [74] and the algo- rithm used for the hyperparameter selection [75]. The hyperparameters for the objective model and benchmarked models are selected through a grid search for the optimal parameters; this is quite time-consuming: e.g., the search for each model takes about 10–11 hrs and, after ﬁnding the optimal parameters, the computational time for training and testing becomes much less (only < 20 min). The CLSTM hybrid predictive model utilizes pooling layer to control overﬁtting issue in training phase applied for input representations to be smaller and controllable [76] thus reducing the number of para- meters and computation of the network. In this study, a pool-size of 2 is used during the model development process. The outputs of the ﬂat- tening layer are given to the inputs of LSTM recurrent layer, and the LSTM recurrent layer is connected to the ﬁnal output. It must be stated that the inputs of the proposed hybrid network are the lagged matrix of the half-hourly GSR time series whereas the output is the half-hourly forecasted GSR series (Table 1). This is in contrast to a traditional pure (i.e., non-hybrid) CNN or a traditional pure (i.e., non- hybrid) LSTM architecture since the ﬁrst three layers of the hybrid CLSTM network include a 1-D convolution layer used to primarily ex- tract features. The fourth layer in the hybrid framework involves LSTM predictive stage that analyses the features and estimates the GSR value Table 3 The optimal architecture used in designing CLSTM hybrid vs. LSTM, GRU, RNN and DNN predictive model. Hyper-parameters are obtained through a grid search procedure (Table 2). Note: ReLU stands for Rectiﬁed Linear Units. Table 4 Evaluation of CLSTM hybrid predictive model over multiple forecast horizons: 1-Day, 1-Week, 2-Week and 1-Month, in respect to its counterpart models, as measured by correlation coeﬃcient (r), root mean square error (RMSE) and mean absolute error (MAE) in the testing phase. Note: GSR prediction is performed using 30-minute interval data, and the resulting model is emulated for 1-Day (1 D), 1-Week (1 W), 2-Week (2 W) and 1-Month (1 M) periods. The optimal model is highlighted. S. Ghimire, et al. Applied Energy 253 (2019) 113541 8 at the next point in time. While some of the hyper-parameters are model-speciﬁc, the four common hyper-parameters used in any deep learning model, also uti- lizes in this study are as follows: • Activation Function: Except for the output layer, all the layers within a network typically use the same activation function known as the Rectiﬁed Linear Unit (ReLU). • Dropout [61]: it is included as a regularization technique to reduce overﬁtting and to improve the training performance. To do so, at each iteration, dropout selects a fraction of the neurons and prevents them from training. This fraction of neurons is deﬁned as a real hyper-parameter between 0 and 1. In this study, this parameter was ﬁxed to a value of 0.1. • Least Absolute Deviations and Least Square Error (L1 and L2- regularization): In addition to the dropout, the L1 and L2 regular- ization parameter is also used such that L1 and L2 penalization parameter minimizes the sum of the absolute diﬀerences and the sum of the square of the diﬀerences between the target value (i.e., observed GSR) and the predicted GSR, respectively. In principle, adding a regularization term to the loss will encourage smooth network mappings (by penalizing large values of the parameters, which decreases the amount of nonlinearity that the network models). • Early Stopping: To eliminate the problem of overﬁtting, the early stopping (ES), criteria from Kera’s DL library [77,78] are im- plemented with the mode set to “minimum” and patience set to “45”. In this study, ES typically stops the training when the vali- dation loss has stopped decreasing for the number of epochs speciﬁed by the patience term. 3.3. Model performance criteria To enable rigorous evaluation of CLSTM hybrid model in respect to the counterpart models, a number of statistical score metrics are exploited. The commonly adopted model score metrics such as the Pearson’s Correlation Coeﬃcient (r), Root Mean Square Error (RMSE; Wm−2), Mean Absolute Error (MAE;Wm−2), including the relative error values: RMSE (RRMSE; %), MAE (RMAE; %), Mean Absolute Percentage Error (MAPE; %) and Absolute Percentage Bias (APB; %) are adopted as the popular metrics employed elsewhere (e.g., [79]. Ad- ditionally, this study also employs the Kling-Gupta Eﬃciency (KGE) [80] computed over the tested data. Mathematically, the metrics are stated as follows: = ⎛ ⎝ ⎜ ⎜ ∑ −< > −< > ∑ −< > ∑ −< > ⎞ ⎠ ⎟ ⎟ = == r GSR GSR GSR GSRp GSR GSR GSR GSRp ()( ) () ( ) i N mm p i N mm i N p 1 1 2 1 2 2 (11) ∑= ⎛ ⎝ ⎜ − ⎞ ⎠ ⎟ = MAE GSR GSR N|| / N t mp 1 (12) ∑= − × = RMAE N GSR GSR GSR 1( ) 100 i N mp m 1 (13) ∑=− = RMSE N GSR GSR 1 () i N mp 1 2 (14) Table 5 Identical to Table 4, except for the model performance being measured by relative root mean square error (RRMSE %), relative mean absolute error (RMAE, %) and the mean absolute percentage error (MAPE, %) in the testing phase. Table 6 Comparison of CLSTM hybrid predictive model’s performance with comparison models in the testing phase at multi-step forecasting horizons: 1-Day (1 D), 1-Week (1 W), 2-Week (2 W) and Month (1 M), as measured by the Kling Gupta Eﬃciency (KGE) and Absolute Percentage Bias (APB) error in the testing phase. S. Ghimire, et al. Applied Energy 253 (2019) 113541 9 = ∑ − ∑ × = = RRMSE II I () () 100 N i N FOR i OBS i N i N OBS i 1 1 ,, 2 1 1 , (15) ∑= ⎛ ⎝ ⎜ − ⎞ ⎠ ⎟ = MAPE GSR GSR GSR N|( )/ | / N t mp m 1 (16) = ⎡ ⎣ ⎢ ∑ −∗ ∑ ⎤ ⎦ ⎥ = = GSR GSR GSR APB ( ) 100 i N mp i N m 1 1 (17) ⎜⎟=− − + ⎛ ⎝ <> <> − ⎞ ⎠ + ⎛ ⎝ ⎞ ⎠ KGE r GSR GSR CV CV 1( 1) 1 p m p s 2 2 2 (18) To also compare diﬀerent models that have been applied in the GSR prediction problem, we adopt the Promoting Percentage of: Mean Absolute Percentage Error (λMAPE), Mean Absolute Error (λMAE) and Root Mean Square Error (λRMSE) [81], as per Eq. (25–27) in conjunction with the Nash–SutcliﬀeEﬃciency (ENS) [82] as the scaled version of the mean squared error along with Wilmot’s Index (d) [83] and the Legate- McCabe's index (LM) [84] as a robust statistical score metrics (Eq. 28–30). =−λ MAPE MAPE MAPE|( )/ |M APE 1 2 1 (19) =−λ MAE MAE MAE|( )/ |M AE 1 2 1 (20) =−λ RMSE RMSE RMSE|( )/ |RMSE 1 2 1 (21) Fig. 4. Half-hourly predicted vs. observed GSR and the model prediction error in terms the residual over a diurnal cycle in testing phase generated by: (a) CLSTM hybrid predictive model, against standalone models based on 7 diﬀerent comparative algorithms: (b) CNN, (c) LSTM, (d) RNN, (e) GRU, (f) DNN, (g) MLP and (h) DT. Interpretive Note: Errors (residuals) of each prediction is plotted on right-hand side and predictions are presented at every half hourly interval for the 1-day forecast horizon (i.e., 23 data points from 7:00 AM to 6:00 PM). S. Ghimire, et al. Applied Energy 253 (2019) 113541 10 =− ∑ − ∑ −〈 〉 = = E GSR GSR GSR GSR 1 [] [] NS i N mp i N mp 1 2 1 2 (22) =− ∑ − ∑ −〈 〉 + −〈 〉 = = WI GSR GSR GSR GSR GSR GSR 1 [] [|()| |()|] i N mp i N pm m p 1 2 1 2 (23) =− ∑ − ∑ −〈 〉 = = LM GSR GSR GSR GSR 1 || || i N mp i N mm 1 1 (24) = = = = 〈〉 = 〈〉 = = = = r correlation coeffecient CV coefficient of iation GSR measured GSR predicted GSR average value of the GSR GSR average value of the GSR Nnumber MAPE RMSE MAPE objective MAPE RMSE MAPE benchmark where var GSR GSR of actual values , & model performance metrics (CLSTM) , & model performance metrics (CNN, LSTM, DNN, MLP etc) m p mm pp 11 1 22 2 Fig. 4. (continued) S. Ghimire, et al. Applied Energy 253 (2019) 113541 11 4. Results and discussion To establish the robustness of the CLSTM hybrid model, this section provides an account of the empirical results of the modelling experi- ments carried out and the assessments of the performance of all models developed to forecast GSR at diﬀerent time horizon. For each modelling experiment, a total of eight GSR models, including the objective (i.e., CLSTM) and the counterpart models: CNN, LSTM, DNN, GRU, RNN, MLP and DT, are employed. To appraisal and demonstrate the merits of CLSTM hybrid model over both short and longer-term forecast hor- izons, the developed model is evaluated for 1-Day, 1-Week, 2-Week and n-Month half-hourly GSR prediction horizons (n = 1,2,3, 4,5, 6,7,8), using a plethora of model evaluation metrics, as described by Eqs. (17)–(30). Tables 4 and 5 show the predictive performance metrics for all involved models that are evaluated in the testing phase. For all of the modelling experiments capturing highest Pearson’s correlation coeﬃcient (r), the lowest root mean square error (RMSE) and the mean absolute error (MAE), the CLSTM hybrid model simulated over a 1-day forecast horizon outperforms all of the other developed models (r ≈ 1.000, RMSE ≈ 8.189 Wm−2 and MAE ≈ 6.666 Wm −2 vs. r ≈ [0.997, 1.000], RMSE ≈ [9.991, 20.177] Wm−2 and MAE ≈ [7.526, 18.206] Wm−2 where [,] is used to demonstrate the upper and lower bounds of the metrics for the various comparison models). Similarly, in terms of the normalised predictive score metrics, RRMSE (≈1.515%) and RMAE (≈6.3%) is attained to exhibit a superior per- formance of CLSTM hybrid model over all of the other models in the multi-step forecast horizon modelling experiments. The CLSTM hybrid model also shows a better performance in terms of the mean absolute percentage error (MAPE). This is signiﬁcantly lower than that of all other comparison models in all modelling sce- narios. For instance, for a 1-Day prediction, the MAPE ≈ 4.67% for the CLSTM hybrid model relative to MAPE ≈ 6.48% for the LSTM and a subsequently lower values for all other models. Importantly, although the magnitude of RRMSE and MAPE for all tested models as per Tables 4 and 5 are dramatically low and concur with the benchmark of an excellent model (< 10%) [21–22], these relative errors are between 1.520 and 6.388% and 4.672–7.347%, respectively, for both short- (1- Day) and long-term (1-Week, 2-Week and 1-Month) forecast horizons to clearly demonstrate the signiﬁcant merits of the CLSTM hybrid pre- dictive model. However, there appears to be an exception if the per- formance based on RMAE is computed. The CLSTM hybrid model generates 18.000% and 20.267% for 2-Weekly and 1-Monthly forecast horizon (i.e., the category of a good model with error less than 20% [21–22]). After considering correlation coeﬃcients between forecasted and observed GSR (including absolute and relative predictive errors), the eﬃcacy of the CLSTM model was veriﬁed using the Kling-Gupta eﬃ- ciency (KGE) [80], a metric that facilitates an analysis of relative im- portance of its diﬀerent components (i.e., correlations, bias error and variability of forecasted GSR) to ensure that both the bias and varia- bility ratios are not cross-correlated. Importantly, for the short-term forecast horizon (1-Day), it has been noted that the CLSTM model ap- pears to yield the best performance, as evidenced by a high KGE value of 0.996, although there are subtle variations in respect to 1-Week, 2- Week and 1-Month period. To explore this further, Table 6 lists the absolute percentage bias error (APB) where the performance of CLSTM model far exceeds that of the counterpart models in all scenarios (i.e., 1- Day, 1-Week, 2-Week, 1-Month). Hence, there is suﬃcient evidence that the CLSTM hybrid model is able to forecast short- and long-term GSR in respect to all other competing models. This seems to also pro- vide compelling evidence for the CLSTM hybrid model to be potentially used as a model for half-hourly GSR predictions if employed in a real- time energy management system integrating solar energy into a power grid. While the CLSTM model has already been veriﬁed to be superior relative to GRU, RNN, DNN, MLP and DT models using the averaged data over any given test period, the predictive model is also assessed by checking its performance with the actual predicted GSR series and its residuals. Fig. 4 illustrates this result for short-term horizon where a closer examination can be made by a curve ﬁtting performed between Fig. 4. (continued) S. Ghimire, et al. Applied Energy 253 (2019) 113541 12 observed and predicted GSR (i.e., GSRobs & GSRpred) over a 1-Day period from 07:30 AM to 06:00 PM) for objective and competing models. Evidently, the CLSTM model provides a perfect ﬁt between GSRobs and GSRpred with a relatively small residual error not exceeding 30 Wm −2 compared to the other tested models. Importantly, the results show that the CLSTM hybrid model is able to generate GSR values very close to the measured values, especially around the noon period where dis- crepancies GSRobs and GSRpred are more evident for the case of GRU, RNN, DNN, MLP and DT models. Based on this analysis, it can be de- duced that integrated CNN and LSTM predictive framework is able to enhance the accuracy of the 1-Day GSR prediction, indicating its po- tential utility for energy monitoring and forecasting in a solar powered grid system. In addition to 1-Day forecast horizon, it is also imperative to explore potential utility of the CLSTM hybrid predictive model to generate GSR values over a 1-Week ahead horizon. This information, if available, can be immensely useful in designing a robust solar powered system where key decisions around the sustainability and the future availability of solar energy can be made well ahead of time. Similar to a 1-Day pre- dictive model, Fig. 5 shows the predictions attained over a 1-Week (a) Two-phase hybrid CLSTM Model (b) RNN Model (c) GRU Model Fig. 5. Evaluation of: (a) half-hourly-based two-phase hybrid CLSTM model illustrating the predicted vs. the observed GSR generated over 1-weekly forecast horizon in respect to 5 other comparative algorithms: (d) RNN, (e) GRU, (f) DNN, (g) MLP and (h) DT. Interpretive Note: The relative percentage error is shown in each subplot at identical intervals for all models for the purpose of comparison, while the GSR is predicted with a model constructed at half-hourly interval data (i.e., 161 data points per day) but emulated over a 1-weekly period in the testing phase. S. Ghimire, et al. Applied Energy 253 (2019) 113541 13 horizon with the values of GSRobs and GSRpred plotted in along with their relative error values that are marked once a day over the weekly period. Note that in this case, the half-hourly CLSTM hybrid model, as employed in previous analysis, is now being emulated with a target data of 1-Week, to explore its predictive eﬃcacy over a longer-term forecast horizon. Fig. 5(a)–(f) shows the results of all 6 (i.e., CLSTM, GRU, RNN, DNN, MLP and DT) models. Consistent with earlier results, the CLSTM hybrid model exhibits a much better performance compared to the other competing models. This result has also been checked against other scenarios (i.e., 2-Week & 1-Month) (not presented here) to ascertain that, although the CNN and LSTM model were stable and accurate, the CLSTM model was more credible over a 1-Week, 2-Week and 10- Month forecast horizon. To gather a more thorough understanding of the prescribed CLSTM model accuracy, Fig. 6 shows the prediction error (GSRPE) presented in the testing phase, obtained in diﬀerent error brackets that span a maximum value of ± 10 Wm −2. Consistent with the results presented earlier, the best prediction, in respect to the competing models, is at- tained by CLSTM. Remarkably, about 71% of GSRPE values for CLSTM appear to lie within ± 10 Wm −2 error range, whereas the same range of errors for CNN, LSTM, RNN, DNN, MLP, GRU and DT models add up to 66%, 67%, 27%, 34%, 64%, 23% and 22%, respectively. The inter- pretation of this result is relatively straightforward: if CLSTM hybrid model produces more error instances in smallest bracket, it is likely to generate a much lesser instance of errors within the larger bracket ex- ceeding ± 10 Wm −2. Conversely, following this notion, the other (d) DNN Model (e) MLP Model (f) DT Model Fig. 5. (continued) S. Ghimire, et al. Applied Energy 253 (2019) 113541 14 competing models (i.e., CNN, LSTM, RNN, DNN, MLP, GRU and DT) are seen to produce a greater percentage of errors within the larger error bracket; for example, the RNN model registers 44% of all predictive errors vs. only a total of 7% of all predictive errors for the CLSTM model within ± (20–40) Wm −2). Accordingly, the predictive error analysis also conﬁrms the suitability of a CLSTM hybrid model improving the accuracy of GSR predictions. Admittedly, the performance of standa- lone CNN and LSTM model are also good, but that of the CLSTM hybrid model is even better, deducing that for half hourly GSR predictions it is beneﬁcial to ﬁrst perform feature extraction by employing CNN, and then, utilizing these input feature values into the ﬁnal LSTM archi- tecture to generate the ﬁnal GSR values. To investigate the predictive ability of CLSTM model, the results are employed to compare the Promoting Percentages, presented as incre- mental performance (λ) [81] of the objective model over competing approaches, where, for example, λ = MAPECLSTM – CNN, is evaluated to estimate the diﬀerence in relative mean absolute percentage error of CLSTM and CNN model. Note that here, we employ three diﬀerent re- lative errors, namely the MAPE, MAE and RMSE, in tandem with Eq. (19–21). Table 7 shows this result for the CLSTM hybrid model benchmarked against the other models in testing phase over 1-Day and 1-Week horizons. The better performance of CLSTM is obvious, as an improved performance attained over CNN, LSTM and all deep learning and Single Hidden Layer Neuronal Network models, including the de- cision tree. However, it is notable that the improvement of CLSTM over the CNN model for both forecasting horizons is relatively small (i.e., 3.62% & 11.78% based on λMAPE) whereas improvements attained over LSTM and the other models is relatively large. This shows that for a real-time short-term and weekly horizon, the convolutional neural network has a relatively good ability to model GSR, but CLSTM hybrid model (where CNN is integrated with LSTM) can further improve the Fig. 6. Histograms illustrating the frequency of absolute prediction error (|PE|) generated by two-phase hybrid CLSTM model in the testing phase in respect to the 5 other comparison models used for the half-hourly GSR prediction horizon. (a) CLSTM, (b) RNN, (c) DNN, (d) MLP, (e) GRU and (f) DT. Table 7 Evaluation of the Promoting Percentages (e.g., [1]) to explore incremental model performance improvement (λ) in terms of RMSE, MAE and MAPE gen- erated by CLSTM hybrid model relative to comparison models in testing phase at multi-step forecast horizons: 1-Day [1 D], 1-Week [1 W], 2-Week [2 W] and Month [1 M]. Note: each numerical value, λ is the percentage diﬀerence in model improvement over a corresponding comparison model. CLSTM vs. Competing Model Below λMAPE (%) λMAE (%) λRMSE (%) 1D 1W 1 D 1W 1D 1 W CNN 3.62 11.78 11.42 9.51 18.04 4.85 LSTM 25.29 23.23 63.65 13.05 61.11 15.19 GRU 34.66 19.14 41.11 37.38 42.69 25.40 RNN 37.37 8.05 63.39 13.90 59.42 11.60 DNN 26.20 44.17 50.41 50.82 49.35 38.36 MLP 18.94 36.72 38.63 59.70 36.66 52.10 DT 22.40 29.39 58.21 34.76 58.56 21.99 Fig. 7. Box plot exemplifying the veracity of the CLSTM hybrid predictive model in terms of the overall distribution of absolute value of the prediction error against 7 diﬀerent predictive models. S. Ghimire, et al. Applied Energy 253 (2019) 113541 15 Fig. 8. Comprehensive evaluation of the overall performance of the CLSTM hybrid model developed for the prediction of short term (half-hourly) GSR relative to 7 counterpart models: RNN, CNN, LSTM, DNN, MLP, GRU and DT. Interpretive Notes: This prediction was performed in a test period for 8 months (January – August 2018) in a 30-minute interval. The performance score metrics are: r = correlation coeﬃcient; WI = Willmott’s Index; ENS = Nash Sutcliﬀe Coeﬃcient; LM = Legates & McCabe’s Index; KGE = Kling-Gupta Eﬃciency; APB = Absolute Percentage Bias; RMSE = root mean square error; RRMSE = Relative Root Mean Square Error computed between predicted and measured values in the testing phase. S. Ghimire, et al. Applied Energy 253 (2019) 113541 16 predictive performance. In Fig. 7, CLSTM hybrid model evaluation is carried out by means of a box plot that illustrate the spread of GSR prediction error (GSRPE) with respect to quartile values, while the whiskers indicate the varia- bility outside of the 1st and 3rd quartile value. The boxplot provides justiﬁcation that the distributed GSRPE for the CLSTM hybrid model acquires a much lower spread with a correspondingly smaller magni- tude of the quartile statistics and medians compared to the other models under consideration. Hence, the forecasted error distributions also demonstrate that the integration of CNN with LSTM presents a major advantage for half-hourly GSR forecasting. To further validate the proposed hybrid model used to predict half- hourly GSR over longer-term periods, the prediction is conducted in test period for an 8 month horizon (January–August 2018) using data over a 30-minute interval (Fig. 8). Fig. 8 plots the model performances in terms of r, WI, ENS, LM, including RMSE, RRMSE and APB. Evidently, CLSTM hybrid model is seen to be the best performing model among all competing models when the data for the half-hourly GSR predictions is used but the model is simulated over the 8 month period. To verify whether CLSTM model is able attain high performance over diﬀerent prediction horizons (i.e., 1-Day to 8-Months), Fig. 9 is used to study the model’s behaviour over an increase in the time-steps. The performance deﬁned by RRMSE, MAPE and APB appears to be worse, although the maximum of these values remain less than 20% threshold, as recommended by previous studies [21–22]. For instance, the RRMSE /MAPE is about 1.515%/ 4.84% for the 1-Day prediction horizon, which increases to about 10.35% / 11.73% and 21.25% / 18.38% for the 4-Months and 8-Months horizons, respectively. To further evaluate the practical utility of CLSTM hybrid model for real applications, daily prediction of the GSR is performed using the daily data from 01-January-1989 to 27-August-2018. The data are ex- tracted from Scientiﬁc Information for Land Owners (SILO) portal de- veloped by Queensland Department of Environment and Resource Management (http://www.dnr.qld.gov.au/silo) [85]. To construct a forecast model, daily GSR from 01-January-1989 to 31-December-2017 are used for training and 01-January-2018 to 28-August-2018 are used for testing purposes where 10% of the testing data is used for in- dependent model validation. The comparison of the CLSTM hybrid model in terms of the RMSE, RRMSE, MAE and MAPE in respect to the RNN, GRU, MLP and DT models is shown in Fig. 10. Evidently, the Fig. 9. Evaluating the predictive skill of the half-hourly CLSTM hybrid model emulated over multiple forecast horizons in terms of RRMSE (%), MAPE (%), APB (%) and KGE over lead time intervals spanning from 1-day to 8 months. Interpretive Note: The performance metrics are: RRMSE = relative root mean square error; MAPE = Mean Absolute Percentage Error; ABP = Absolute Percentage Bias; KGE = Kling-Gupta Eﬃciency. S. Ghimire, et al. Applied Energy 253 (2019) 113541 17 results show low values of the absolute and relative errors, as high- lighted by the performance metrics: ≤RMSE ≤≤ ≤−Wm RRMSE MAPE andRMAE2.83 , 14.65%, 10.8% 1.34%2 , all of which concur with excellent model performance in accordance with literature [21–22]. In accordance with these results, there is no doubt that proposed CLSTM hybrid model outperforms all other comparable models, advocating it as a versatile tool for the prediction of GSR over daily time-steps. 5. Conclusion and future work This study, supporting ongoing eﬀorts to develop artiﬁcial in- telligence techniques for solar radiation and energy demand predictions [9,49,40–43,86], has proposed a newly designed, half-hourly time-step predictive model, denoted as CLSTM, which integrates deep learning Convolutional Neural Network (CNN) with Long Short-Term Memory Network (LSTM). The model has been evaluated through the predic- tions of half-hourly, daily and monthly solar radiations whose input elements are deﬁned by antecedent lagged GSR data. Essentially, for enhanced accuracy, the proposed model employs CNN to extract GSR data features and LSTM to encapsulate the features to generate a low latency-based time series GSR prediction. The ﬁndings clearly have shown the better performance of the proposed CLSTM model than other DL models as well as conventional models. A further elaboration of the study outcomes is provided below: 1. The standalone models CNN, LSTM and DNN are unable to generate as satisfactory results as does the proposed hybrid CLSTM in the GSR prediction. More speciﬁcally, the error metrics (e.g., MAPE) for these standalone models are all substantially larger than those of the CLSTM hybrid model; for instance, =MAPE vs4.84% . 6.48%, 5.84%, 6.56% for CLSTM vs. LSTM, CNN and DNN models, respectively, for all simulations over a 1-Day prediction time-step. 2. With no negative values registered in terms of the diﬀerence in percentage error among the CLSTM hybrid model in respect to other competing models, the integration of both CNN and LSTM algo- rithms appears to demonstrate the best predictive accuracy, as veriﬁed by the promoting percentage of MAPE, MAE and RMSE and(3.62%, 11.42%, 18.01%) for 1-Day prediction time-step. Similarly, the 1-Week time-step shows a signiﬁcant improvement when the model integrating CNN and LSTM algorithms is evaluated. 3. A holistic evaluation of the model through statistical metrics and diagnostic plots reveal that the hybrid CLSTM model generates su- perior prediction compared to the other benchmarked models. The prediction time-step comparison shows that the hybrid CLSTM model performs the best for the 1-Day half-hourly GSR prediction with == =RRMSE MAPE APB1.515%, 4.672%and 1.233%. 4. The predicted versus observed GSR shows that the CLSTM model is the optimal deep learning approach resulting in a low relative error compared with the other benchmark models (e.g., Fig. 5). Ad- ditionally, with a total of 71% of GSR prediction errors lying below the smallest range of ± −10Wm 2, the CLSTM hybrid model demon- strates more robust performance compared to 27%, 23%, 22% and 34% of errors within the smallest margin for RNN, GRU, DT and DNN respectively (e.g., Fig. 6). 5. When emulated over longer time-steps, the CLSTM model remains the optimal model for a long forecast horizon to outperform all the benchmark models, up to an 8-Month period ( << <MAPE RRMSE APB19%, 21.25%and 9.81%). 6. When the CLSTM hybrid model is trained and also tested with daily temporal scale data, it outperforms all other benchmark models, to remain in a ‘very good model’ category [21–22], as clearly ex- empliﬁed by <<MAPE RRMSE11%, 15% relative to MAPE > 11% and RRMSE > 17% for the latter. While this study (originating from earlier works e.g., [9,49,40,86]) has focused on the short-term prediction at one location in Australia, this methodology can be applied to construct the CLSTM model that is adapted to other solar-rich cities in Australia and other nations. Future research can also focus on the testing of CLSTM at diﬀerent time scales, for example, at a better temporal resolution of 1-minute, 5-minute or 10-minute prior to being implemented in energy management systems. Moreover, this study also sets new foundations for long-term evaluation of solar energy, for example, over monthly scales using more advanced techniques such as a wavelet-based model [41] and other types of deep learning techniques such as the deep belief network and the deep neural network models where the proposed LSTM model is then hybridised with these deep learning models [42]. Additionally, hybrid DL based predictive models, such as the CNN integrated with statistical models (e.g. Support Vector Regression [41]), extreme learning machines [86] or other Single Hidden Layer model (e.g. ANN) or deep neural network and deep belief networks [42], may yield better results. Moreover, the use of Multiresolution Analysis (MRA) technique (e.g. empirical mode decomposition (EMD), improved complete ensemble empirical mode decomposition with adaptive noise (ICEEDMAN)) [41,43] are more popular nowadays to extract relevant information in time–frequency domain without any loss of information. Therefore, the proposed CLSTM model should be worth comparing with a model formed by the integration of MRA with SHL for future research. Finally, CLSTM model operated at greater temporal resolutions can also be tested in several continental-wide locations in Australia to evaluate the applicability of the tool to meet energy demand predictions in more remote and Fig. 10. The root mean square error (RMSE) and the mean absolute error (MAE) generated by the CLSTM hybrid model for 1-day GSR prediction trained with daily GSR datasets. Interpretive Note: Daily GSR time series (1989–2018) were extracted from Scientiﬁc Information for Land Owners (SILO) repository and simulations performed and evaluated over the daily scale. S. Ghimire, et al. Applied Energy 253 (2019) 113541 18 regional locations, such as that explored in recent studies [49,86]. Acknowledgement The paper utilized minute level solar radiation data from the Bureau of Meteorology and daily radiation data from the Queensland Department of Environment and Resource Management that are duly acknowledged. Sujan Ghimire is supported by Research and Training Scheme (RTS) funding to USQ from the Australian Government. The authors declare that there is no conﬂict of interest. We are particularly grateful to all reviewers who provided very helpful comments how to improve the paper. References [1] IEA. World energy outlook 2017; 2019. [2] UNDP. UNDP strategic plan, 2018–2021. Special session (executive board of the united nations development programme, the united nations population fund and the united nations oﬃce for project services). New York: United Nations; 2017. [3] CEC. Clean energy Australia report. Melbourne, Australia; 2018. [4] Perez R, Lorenz E, Pelland S, Beauharnois M, Van Knowe G, Hemker Jr K, et al. Comparison of numerical weather prediction solar irradiance forecasts in the US, Canada and Europe. Solar Energy 2013;94:305–26. [5] Hejase HA, Assi AH. Time-series regression model for prediction of mean daily global solar radiation in Al-Ain, UAE. ISRN. Renew Energy 2012;2012. [6] Aguiar R, Collares-Pereira M, Conde J. Simple procedure for generating sequences of daily radiation values using a library of Markov transition matrices. Sol Energy 1988;40:269–79. [7] Aguiar R, Collares-Pereira M. TAG: a time-dependent, autoregressive, Gaussian model for generating synthetic hourly radiation. Sol Energy 1992;49:167–74. [8] Mora-Lopez L, Sidrach-de-Cardona M. Multiplicative ARMA models to generate hourly series of global irradiation. Sol Energy 1998;63:283–91. [9] Ghimire S, Deo RC, Downs NJ, Raj N. Global solar radiation prediction by ANN integrated with European Centre for medium range weather forecast ﬁelds in solar rich cites of queensland Australia. J Cleaner Prod 2019. [10] Fu C-L, Cheng H-Y. Predicting solar irradiance with all-sky image features via re- gression. Sol Energy 2013;97:537–50. [11] Ceci M, Corizzo R, Fumarola F, Malerba D, Rashkovska A. Predictive modeling of pv energy production: How to set up the learning task for a better prediction? IEEE Trans Ind Inf 2017;13:956–66. [12] Monjoly S, André M, Calif R, Soubdhan T. Hourly forecasting of global solar ra- diation based on multiscale decomposition methods: a hybrid approach. Energy. 2017;119:288–98. [13] Jiménez-Pérez PF, Mora-López L. Modeling and forecasting hourly global solar radiation using clustering and classiﬁcation techniques. Sol Energy 2016;135:682–91. [14] Eseye AT, Zhang J, Zheng D. Short-term photovoltaic solar power forecasting using a hybrid Wavelet-PSO-SVM model based on SCADA and Meteorological informa- tion. Renew Energy 2018;118:357–67. [15] Qing X, Niu Y. Hourly day-ahead solar irradiance prediction using weather forecasts by LSTM. Energy 2018;148:461–8. [16] Sharma V, Yang D, Walsh W, Reindl T. Short term solar irradiance forecasting using a mixed wavelet neural network. Renew Energy 2016;90:481–92. [17] Mayer D, Wald L, Poissant Y, Pelland S. Performance prediction of grid-connected photovoltaic systems using remote sensing. Int Energy Agency 2008. [18] Hammer A, Heinemann D, Hoyer C, Lorenz E. Satellite based short-term forecasting of solar irradiance—comparison of methods and error analysis. The 2001 EUMETSAT meteorological satellite data user’s conference; 2001. p. 677–84. [19] Voyant C, Paoli C, Muselli M, Nivet M-L. Multi-horizon solar radiation forecasting for Mediterranean locations using time series models. Renew Sustain Energy Rev 2013;28:44–52. [20] Reikard G. Predicting solar radiation at high resolutions: a comparison of time series forecasts. Sol Energy 2009;83:342–9. [21] Mohammadi K, Shamshirband S, Tong CW, Arif M, Petković D, Ch S. A new hybrid support vector machine–wavelet transform approach for estimation of horizontal global solar radiation. Energy Convers Manage 2015;92:162–71. [22] Mohammadi K, Shamshirband S, Anisi MH, Alam KA, Petković D. Support vector regression based prediction of global solar radiation on a horizontal surface. Energy Convers Manage 2015;91:433–41. [23] Sun Y, Szűcs G, Brandt AR. Solar PV output prediction from video streams using convolutional neural networks. Energy Environ Sci 2018;11:1811–8. [24] Qin Y, Wang X, Zou J. The optimized deep belief networks with improved logistic Sigmoid units and their application in fault diagnosis for planetary gearboxes of wind turbines. IEEE Trans Ind Electron 2019;66:3814–24. [25] Jiang G, He H, Yan J, Xie P. Multiscale convolutional neural networks for fault diagnosis of wind turbine gearbox. IEEE Trans Ind Electron 2019;66:3196–207. [26] Wang K, Qi X, Liu H, Song J. Deep belief network based k-means cluster approach for short-term wind power forecasting. Energy 2018;165:840–52. [27] Qolipour M, Mostafaeipour A, Saidi-Mehrabad M, Arabnia HR. Prediction of wind speed using a new Grey-extreme learning machine hybrid algorithm: a case study. Energy Environ 2019. 0958305X18787258. [28] Wang H, Wang G, Li G, Peng J, Liu Y. Deep belief network based deterministic and probabilistic wind speed forecasting approach. Appl Energy 2016;182:80–93. [29] Dalto M, Matuško J, Vašak M. Deep neural networks for ultra-short-term wind forecasting. In: 2015 IEEE international conference on industrial technology (ICIT). IEEE; 2015. p. 1657–63. [30] Wen L, Zhou K, Yang S, Lu X. Optimal load dispatch of community microgrid with deep learning based solar power and load forecasting. Energy 2019. [31] Torres JF, Troncoso A, Koprinska I, Wang Z, Martínez-Álvarez F. Deep learning for big data time series forecasting applied to solar power. The 13th international conference on soft computing models in industrial and environmental applications. Springer; 2018. p. 123–33. [32] Srivastava S, Lessmann S. A comparative study of LSTM neural networks in fore- casting day-ahead global horizontal irradiance with satellite data. Sol Energy 2018;162:232–47. [33] Alzahrani A, Shamsi P, Dagli C, Ferdowsi M. Solar irradiance forecasting using deep neural networks. Procedia Comput Sci 2017;114:304–13. [34] Ma X, Tao Z, Wang Y, Yu H, Wang Y. Long short-term memory neural network for traﬃc speed prediction using remote microwave sensor data. Transp Res Part C: Emerg Technol 2015;54:187–97. [35] Zhao Z-Z, Chen H-P, Huang Y, Zhang S-B, Li Z-H, Feng T, et al. Bioactive polyketides and 8,14-seco-ergosterol from fruiting bodies of the ascomycete Daldinia childiae. Phytochemistry 2017;142:68–75. [36] Greﬀ K, Srivastava RK, Koutník J, Steunebrink BR, Schmidhuber J. LSTM: A search space odyssey. IEEE Trans Neural Netw Learn Syst 2017;28:2222–32. [37] Jozefowicz R, Zaremba W, Sutskever I. An empirical exploration of recurrent net- work architectures. International conference on machine learning. 2015. p. 2342–50. [38] Gensler A, Henze J, Sick B, Raabe N. Deep Learning for solar power forecasting—an approach using AutoEncoder and LSTM neural networks. 2016 IEEE international conference on systems, man, and cybernetics (SMC). IEEE; 2016. p. 002858-65. [39] Higashiyama K, Fujimoto Y, Hayashi Y. Feature extraction of NWP data for wind power forecasting using 3D-convolutional neural networks. Energy Procedia 2018;155:350–8. [40] Ghimire S, Deo RC, Downs NJ, Raj N. Self-adaptive diﬀerential evolutionary ex- treme learning machines for long-term solar radiation prediction with remotely- sensed MODIS satellite and Reanalysis atmospheric products in solar-rich cities. Remote Sens Environ 2018;212:176–98. [41] Ghimire S, Deo RC, Raj N, Mi J. Wavelet-based 3-phase hybrid SVR model trained with satellite-derived predictors, particle swarm optimization and maximum overlap discrete wavelet transform for solar radiation prediction. Renewable Sustainable Energy Rev 2019;113:109247. [42] Ghimire S, Deo RC, Raj N, Mi J. Deep learning neural networks trained with MODIS satellite-derived predictors for long-term global solar radiation prediction. Energies 2019;12:2407. [43] Al-Musaylh MS, Deo RC, Adamowski JF, Li Y. Two-phase particle swarm optimized- support vector regression hybrid model integrated with improved empirical mode decomposition with adaptive noise for multiple-horizon electricity demand fore- casting. Appl Energy 2018;17:422–39. [44] Elsheikh AH, Sharshir SW, Abd Elaziz M, Kabeel AE, Guilan W, Haiou Z. Modeling of solar energy systems using artiﬁcial neural network: a comprehensive review. Sol Energy 2019;180:622–39. [45] Liu J, Wu C, Wang J. Gated recurrent units based neural network for time het- erogeneous feedback recommendation. Inf Sci 2018;423:50–65. [46] Wang K, Qi X, Liu H. A comparison of day-ahead photovoltaic power forecasting models based on deep learning neural network. Appl Energy 2019;251:113315. [47] Ghritlahre HK, Prasad RK. Exergetic performance prediction of solar air heater using MLP, GRNN and RBF models of artiﬁcial neural network technique. J Environ Manage 2018;223:566–75. [48] Ahmad MW, Reynolds J, Rezgui Y. Predictive modelling for solar thermal energy systems: A comparison of support vector regression, random forest, extra trees and regression trees. J Cleaner Prod 2018;203:810–21. [49] Deo RC, Sahin M. Forecasting long-term global solar radiation with an ANN algo- rithm coupled with satellite-derived (MODIS) land surface temperature (LST) for regional locations in Queensland. Renew Sustain Energy Rev 2017;72:828–48. [50] LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015;521:436. [51] Kalogirou S, Sencan A. Artiﬁcial intelligence techniques in solar energy applica- tions. Solar collectors and panels, theory and applications. InTech; 2010. [52] Deo RC, Ghimire S, Downs NJ, Raj N. Optimization of windspeed prediction using an artiﬁcial neural network compared with a genetic programming model. In: Handbook of research on predictive modeling and optimization methods in science and engineering. IGI Global; 2018. p. 328–59. [53] Imteaz MA, Ahsan A. Solar panels: real eﬃciencies, potential productions and payback periods for major Australian cities. Sustain Energy Technol Assess 2018;25:119–25. [54] Oehmcke S, Zielinski O, Kramer O. Input quality aware convolutional LSTM net- works for virtual marine sensors. Neurocomputing 2018;275:2603–15. [55] Núñez JC, Cabido R, Pantrigo JJ, Montemayor AS, Vélez JF. Convolutional Neural Networks and Long Short-Term Memory for skeleton-based human activity and hand gesture recognition. Pattern Recogn 2018;76:80–94. [56] Graves A, Jaitly N. Towards end-to-end speech recognition with recurrent neural networks. International conference on machine learning. 2014. p. 1764–72. [57] Cho K, Van Merriënboer B, Gulcehre C, Bahdanau D, Bougares F, Schwenk H, et al. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:14061078; 2014. [58] Wang Y, Shen Y, Mao S, Chen X, Zou HLASSO. LSTM integrated temporal model for short-term solar intensity forecasting. IEEE Int Things J 2018. S. Ghimire, et al. Applied Energy 253 (2019) 113541 19 [59] Zhang J, Yan J, Inﬁeld D, Liu Y. Lien F-s. Short-term forecasting and uncertainty analysis of wind turbine power based on long short-term memory network and Gaussian mixture model. Appl Energy 2019;241:229–44. [60] Sainath TN, Vinyals O, Senior A, Sak H. Convolutional, long short-term memory, fully connected deep neural networks. 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE; 2015. p. 4580–4. [61] Hochreiter S, Schmidhuber J. Long short-term memory. Neural Comput 1997;9:1735–80. [62] Chen J, Zeng G-Q, Zhou W, Du W, Lu K-D. Wind speed forecasting using nonlinear- learning ensemble of deep learning time series prediction and extremal optimiza- tion. Energy Convers Manage 2018;165:681–95. [63] Xingjian S, Chen Z, Wang H, Yeung D-Y, Wong W-K, Woo W-c. Convolutional LSTM network: a machine learning approach for precipitation nowcasting. Advances in neural information processing systems; 2015. p. 802–10. [64] Havas L, Ballweg J, Penna C, Race D. Power to change: analysis of household participation in a renewable energy and energy eﬃciency programme in Central Australia. Energy Policy 2015;87:325–33. [65] contributor W. Alice Springs. Wikipedia, the free encyclopedia; 2018. [66] Clifton J, Boruﬀ BJ. Assessing the potential for concentrated solar power develop- ment in rural Australia. Energy Policy 2010;38:5272–80. [67] Sanner MF. Python: a programming language for software integration and devel- opment. J Mol Graph Model 1999;17:57–61. [68] Ketkar N. Introduction to keras. Deep Learning with Python. Springer; 2017. p. 97–111. [69] Abadi M, Barham P, Chen J, Chen Z, Davis A, Dean J, et al. Tensorﬂow: a system for large-scale machine learning. OSDI2016. p. 265–83. [70] Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al. Scikit- learn: machine learning in python. J Mach Learn Res 2011;12:2825–30. [71] Kaba K, Sarıgül M, Avcı M, Kandırmaz HM. Estimation of daily global solar ra- diation using deep learning model. Energy 2018;162:126–35. [72] MathWorks I. MATLAB : the language of technical computing : computation, vi- sualization, programming: installation guide for UNIX version 5: Natwick : Math Works Inc., 1996.; 1996. [73] Ryan BF. Minitab handbook. Duxbury Resource Center; 1994. [74] Nawi NM, Atomi WH, Rehman MZ. The eﬀect of data pre-processing on optimized training of artiﬁcial neural networks. Procedia Technol 2013;11:32–9. [75] Yu R, Gao J, Yu M, Lu W, Xu T, Zhao M, et al. LSTM-EFG for wind power forecasting based on sequential correlation features. Future Gen Comput Syst 2019;93:33–42. [76] Sadaei HJ, de Lima e Silva PC, Guimarães FG, Lee MH. Short-term load forecasting by using a combined method of convolutional neural networks and fuzzy time series. Energy 2019. [77] Chollet F. Keras; 2015. [78] Zeng D. Workshop 3: deep learning with python; 2019. [79] Chai T, Draxler RR. Root mean square error (RMSE) or mean absolute error (MAE)? Arguments against avoiding RMSE in the literature. Geosci Model Dev 2014;7:1247–50. [80] Gupta HV, Kling H, Yilmaz KK, Martinez GF. Decomposition of the mean squared error and NSE performance criteria: implications for improving hydrological modelling. J Hydrol 2009;377:80–91. [81] Liu H, Mi X, Li Y. Smart deep learning based wind speed prediction model using wavelet packet decomposition, convolutional neural network and convolutional long short term memory network. Energy Convers Manage 2018;166:120–31. [82] Nash JE, Sutcliﬀe JV. River ﬂow forecasting through conceptual models part I—a discussion of principles. J Hydrol 1970;10:282–90. [83] Willmott CJ. On the evaluation of model performance in physical geography. Spatial statistics and models. Springer; 1984. p. 443–60. [84] Legates DR, McCabe GJ. Evaluating the use of “goodness-of-ﬁt” measures in hy- drologic and hydroclimatic model validation. Water Resour Res 1999;35:233–41. [85] Jeﬀrey SJ, Carter JO, Moodie KB, Beswick AR. Using spatial interpolation to con- struct a comprehensive archive of Australian climate data. Environ Modell Software 2001;16:309–30. [86] Deo RC, Şahin M, Adamowski JF, Mi J. Universally deployable extreme learning machines integrated with remotely sensed MODIS satellite predictors over Australia to forecast global solar radiation: A new approach. Renewable Sustainable Energy Rev 2019;104:235–61. S. Ghimire, et al. Applied Energy 253 (2019) 113541 20","libVersion":"0.3.2","langs":""}