{"path":"lit/lit_sources/Rusch13electInflLogRgrsTree.pdf","text":"The Annals of Applied Statistics 2013, Vol. 7, No. 3, 1612–1639 DOI: 10.1214/13-AOAS648 © Institute of Mathematical Statistics, 2013 INFLUENCING ELECTIONS WITH STATISTICS: TARGETING VOTERS WITH LOGISTIC REGRESSION TREES BY THOMAS RUSCH∗,ILRO LEE†,KURT HORNIK∗, WOLFGANG JANK‡ AND ACHIM ZEILEIS§ WU (Vienna University of Economics and Business)∗, University of New South Wales†, University of South Florida‡ and Universität Innsbruck§ In political campaigning substantial resources are spent on voter mobi- lization, that is, on identifying and inﬂuencing as many people as possible to vote. Campaigns use statistical tools for deciding whom to target (“mi- crotargeting”). In this paper we describe a nonpartisan campaign that aims at increasing overall turnout using the example of the 2004 US presidential election. Based on a real data set of 19,634 eligible voters from Ohio, we in- troduce a modern statistical framework well suited for carrying out the main tasks of voter targeting in a single sweep: predicting an individual’s turnout (or support) likelihood for a particular cause, party or candidate as well as data-driven voter segmentation. Our framework, which we refer to as LORET (for LOgistic REgression Trees), contains standard methods such as logistic regression and classiﬁcation trees as special cases and allows for a synthesis of both techniques. For our case study, we explore various LORET models with different regressors in the logistic model components and different par- titioning variables in the tree components; we analyze them in terms of their predictive accuracy and compare the effect of using the full set of available variables against using only a limited amount of information. We ﬁnd that augmenting a standard set of variables (such as age and voting history) with additional predictor variables (such as the household composition in terms of party afﬁliation) clearly improves predictive accuracy. We also ﬁnd that LORET models based on tree induction beat the unpartitioned models. Fur- thermore, we illustrate how voter segmentation arises from our framework and discuss the resulting proﬁles from a targeting point of view. 1. Introduction. “Decisions are made by those who show up,” said President Bartlet, a character from a popular TV show, The West Wing. The character in the show used the line to motivate a college audience to voice their opinion by showing up at the polls. Getting eligible voters to actually vote (“get-out-the-vote;” GOTV) is an important goal in countries with a democratic political system and a lot of resources are spent on achieving that goal. Take the 2012 US presidential race, for example. In that year, the world witnessed the amount of money raised and spent by the campaigns reaching unprecedented heights. By spending over Received March 2012; revised March 2013. Key words and phrases. Campaigning, classiﬁcation tree, get-out-the-vote, model tree, political marketing, voter identiﬁcation, voter segmentation, voter proﬁle, microtargeting. 1612 TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1613 USD 1.5 billion, the Obama and Romney campaigns tried to mobilize eligible voters to engage in the political process and cast their vote on November 6th. 1.1. Campaigning, mobilization and turnout. The impact of partisan cam- paigning or nonpartisan get-out-the-vote efforts on mobilization and turnout has been subject to numerous scientiﬁc investigations over the last 20 years. Examples include Whitelock, Whitelock and van Heerde’s (2010) survey on the effect of campaigning and turnout in the UK and Germany or Karp and Banducci (2007) who surveyed the relationship between party contacts and turnout in 23 coun- tries (old and new democracies). See also Holbrook and McClurg (2005)foran overview of recent studies. Starting from an early “minimal effect” hypothesis [Finkel (1993), i.e., the idea that political campaigns barely inﬂuence turnout], there is evidence in the literature that campaigning does indeed have a measur- able effect on persuasion or mobilization of the electorate [Holbrook and Mc- Clurg (2005)], which is supported by a number of experimental studies, for ex- ample, Nickerson, Friedrichs and King (2006), Gerber and Green (2000a, 2000b), Arceneaux and Nickerson (2009), Green, Gerber and Nickerson (2003), Hansen and Bowers (2009), Phillips, Urbany and Reynolds (2008).1 Reinforced by these results, campaigns are spending large amounts of money on mobilizing voters. However, one cannot simply equate higher spending with higher turnout. Take the United States, for example, where the “professionaliza- tion” [Muller (1999)] of campaigning had its origin [Plasser (2000)] and spread to many democratic countries all over the world [Sussman and Galizio (2003)]. Arguably, nowhere else is political campaigning a bigger business then in the US and nowhere else is more money being spent on convincing people to cast their ballots. Despite increased political consultancy, monumental campaign efforts and large out-laying of resources, the average voter turnout since 1980 during the Pres- idential election years has only been 56%; see also Table 1. This raises questions about the effectiveness of campaigns’ voter mobilization strategies. 1.2. How is targeting carried out? Voter mobilization is a two-step process [cf. Goldstein and Ridout (2002)]. In the ﬁrst step, campaigns need to identify people suitable to direct their mobilization efforts at (also known as voter target- ing). The second step involves crafting measures that best motivate these people to turn up at the polls, that is, to assure the effectiveness of mobilization. The latter step includes decisions on which tactics best translate to mobilization and has been investigated by researchers in the political and social sciences or marketing [for an overview of which measures to use see, e.g., Green and Gerber (2008)]. The ﬁrst step (identifying the “right” recipients for mobilization messages) has, to the best 1Although the literature seems to have not yet reached a consensus, especially with respect to partisan GOTV; see Cardy (2005), Gerber, Green and Green (2007), Panagopoulos (2009). 1614 T. RUSCH ET AL. TABLE 1 Individual and aggregated turnout rate (votes for highest ofﬁce divided by the voting-eligible population) for presidential elections in the United States and the money spent by all candidates (in million USD). The fourth column lists the real expenditures (inﬂation-adjusted at 2008 rates). Sources: McDonald (2012) and http:// www.opensecrets.org/ , accessed 11-21-2012 (all elections until 2008), Wikipedia (2012) and The New York Times (http:// elections.nytimes.com/ 2012/ campaign-ﬁnance, accessed 11-21-2012) (2012 election). Inﬂation-adjustment has been done with http:// www.bls.gov/ data/ inﬂation_calculator.htm at 11-21-2012 Expenditures Real expenditures Year Turnout (in %) (in mill. USD) (at 2008 rates) 2012 57.5 1605.2 1494.7 2008 61.7 1324.7 1324.7 2004 60.1 717.9 818.2 2000 54.2 343.1 429.0 1996 51.7 239.9 329.2 1992 58.1 192.2 295.0 1988 52.8 210.7 383.5 1984 55.2 103.6 214.7 1980 54.292.3 241.2 Mean 56.2 536.6 614.5 Sd 3.4 562.5 486.2 Min 51.792.3 214.7 Max 61.7 1605.7 1494.7 of our knowledge, been addressed rather infrequently in the scientiﬁc literature. Notable exceptions are Murray and Scime (2010), Parry et al. (2008), Wielhouwer (2003)or Imai and Strauss (2011). When identifying people to target, campaigns typically ﬁrst assess two impor- tant aspects for each eligible voter: (a) likelihood of support (for a particular cause, party or candidate) and (b) likelihood to turnout at the polls [Issenberg (2012b), Malchow (2008)]. Using these two assessments, each voter can be schematically classiﬁed into one of four possible categories (or “quadrants,” see Figure 1). For voters that are classiﬁed into quadrant 1 (likely to vote and likely to support), cam- paigns usually allocate few resources on mobilization (but these voters might be asked to help out with the campaign). Eligible voters assigned to quadrant 2 (likely to vote but unlikely to support) are “targeted for support” by the campaigns, as they can be persuaded to become supporters. In quadrant 3 (unlikely to vote but likely to support), the focus of the targeting effort will be on mobilization for turnout (“targeting for turnout”). For both quadrants 2 and 3 the campaigns will use tar- geted messages. The messages could be customized to individuals based on their demographic and behavioral data (“voter proﬁles”). Voters classiﬁed to belong to quadrant 4 (unlikely to vote and unlikely to support) will typically not be targeted by a campaign [see also Issenberg (2012b)]. TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1615 FIG.1. The usual partisan campaign classiﬁcation of targeting groups. In order to populate quadrants 1–4, campaigns need rich voter data and powerful data models that can predict, for each individual person, his/her probability of support or turnout with as high accuracy as possible. In some countries, voting data that can be used to explain and predict voting behavior is available as public data. In the US, for example, states collect and report voter registration information and make them publicly available. Collection is done at the county level and the data are only available in aggregated fashion. Individual voting data is usually not readily and easily accessible [US Election Assistance Commission (2010)]. Data for targeting also arrives in the form of proprietary information, offered by data vendors who supply individual-level data and add considerable details about voter behavior and demographics. In many countries, proprietary sources from market research companies are the only way to obtain data for targeting, as public data are scarce. For all data sources the most important predictor variables typically collected are records of the (individual) voting history. The ability of voting history as a predictor for future election attendance has long been recognized [e.g., Denny and Doyle (2009)] and, consequently, for targeting purposes voting history is heavily relied on [Goldstein and Ridout (2002), Malchow (2008)]. Additional predictive power has been found in sociodemographic or personality variables like age, in- come and party afﬁliation. 1616 T. RUSCH ET AL. While campaigns can collect an abundance of predictor variables with ease, collecting information on the target variable poses a more challenging problem. Supervised classiﬁcation methods require a known target (i.e., observations on the response variable) in order to train the model. In the case of an election, the target (i.e., whether a person will truly turnout or support) is not known until the elec- tion is over. Campaigns therefore have to rely on suitable proxy target variables which should most accurately resemble the true outcome. The usage of proxies renders the application of supervised classiﬁcation procedures during or before the election feasible. While many proxies (e.g., an earlier election) are imaginable and the choice may vary between campaigns, proxy variables often arrive in the form of carefully designed polls about voting intention. For example, the Obama 2012 campaign conducted short, parallel survey polls on random samples of 8000 to 9000 voters from “battleground states” every night during the ﬁnal phase of the campaign [Blumenthal (2012)]. For the rest of this paper we only consider the situation of either employing the true outcome or proxy variables derived from surveys, but we have also investigated the use of proxy variables derived from pre- vious election outcomes; see the supplementary material [Rusch et al. (2013b)]. Campaigns often have access to similar sources of information, but the way the information is processed, modeled and ultimately acted on can be very diverse. Traditionally, campaigns have relied on simple deterministic rules for choosing whom to target by, for example, using information from the last four comparable elections as the main predictors for future voting behavior. Intuitively, someone who voted in all four out of the last four elections is seen as a likely voter, whereas someone who did not vote in any of the four elections is considered unlikely to vote in the upcoming election. However, predicting the behavior of a person with a mixed voting pattern (i.e., voted in the last election but not in the previous three) by simple deterministic rules is ambiguous and can be suboptimal, as the procedure lacks the ability to learn structure from a data set. This has sparked interest in adopting probabilistic approaches in place of deter- ministic rules based solely on the voting history [Issenberg (2012b)]. For instance, Malchow (2008) promotes a linear probability model as well as tree-like mod- els such as CHAID [Kass (1980)] for political microtargeting. Murray and Scime (2010) suggest decision trees as well. Green and Kern (2012) advocate Bayesian additive trees [BART, Chipman, George and McCulloch (2010)] and Imai and Strauss (2011) propose to use classiﬁcation trees, which they embed in a decision theoretic framework for optimal planning of GOTV campaigns. Other state-of-the- art approaches that are used include logistic or probit regression. 1.2.1. Targeting for turnout. In the speciﬁc case of using probabilistic models for targeting for turnout, the two tasks of identifying likely voters and likely sup- porters from Figure 1 coincide. Here, campaigns are interested in assigning each voter an individual probability to show up at election day. Based on these estimated probabilities, Malchow (2008) reasons that using targeting plans on people with TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1617 values around 0.5 is worthwhile, whereas targeting people with predicted proba- bilities near 0 or 1 is considered a waste. Given a high accuracy of the predictions, a person with a predicted probability close to zero is unlikely to vote, regardless of how compelling the mobilization message is. A person with a predicted probabil- ity of 1 is going to turn out at the polls anyways, even without the need for extra persuasion. In both cases, targeting those people would not lead to an increase in turnout, yet it would consume resources and hence be wasteful. However, voters with a predicted probability in a “targeting range” around 0.5 may be “convinca- ble” to show up at the polls using the right incentive. Malchow (2008) suggests a targeting range of [0.3, 0.7]. Clearly, we can be hopeful to sway a person with a probability of voting of, say, 0.35, as long as we get the right message to her. Also, while a person with a probability of, say, 0.68 might be going to vote without being targeted speciﬁcally, it should not hurt to encourage her a bit more. 2. A new uniﬁed statistical framework for voter targeting. In this paper we introduce a ﬂexible statistical framework for the task of voter microtargeting and apply it to a (virtual) nonpartisan GOTV campaign that uses different sets of pre- dictor variables. The main contribution of this framework is that it allows predic- tion and segmentation in a single step. It generalizes two standard models currently used in political targeting: it encompasses logistic regression as well as classiﬁca- tion trees and also allows for a combination of both within the same model. We refer to the resulting framework as LOgistic REgression Tree (LORET) models. LORET models are very ﬂexible in that, in their simplest form, they reduce to a majority vote model; they also allow regression-like modeling with predictors (with small adjustment it works for all generalized models for binary data such as probit models) as well as hierarchical partitioning of the feature space under the same umbrella. Based on a novel data set of Ohio voters which is prototypical for what cam- paigns can buy from data providers, we investigate LORET models of varying de- grees of ﬂexibility and compare them with a particular focus on the beneﬁts they provide for targeting voters. While we illustrate LORET models for assessing the probability of turnout only, we are quick to point out that LORET models can also be used to gauge a voter’s probability of supporting a candidate or cause. We show that LORET models can have higher predictive accuracy than logistic regression alone, may lead to better interpretability compared to classiﬁcation trees, allow for automatic data-driven creation of voter proﬁles, conduct variable selection and al- low for inclusion of substantive knowledge and experience via the logistic model. This paper is organized as follows. In Section 3 we present a statistical frame- work for voter targeting that combines logistic regression models with recursive partitioning. Section 4 describes the case study of applying the methods to a (vir- tual) nonpartisan GOTV campaign in Ohio that set increasing overall turnout in the US presidential general election in 2004 as its goal. We illustrate using the LORET framework in a situation where we have labeled training data for a sample 1618 T. RUSCH ET AL. of eligible voters (Section 4.4). In Section 4.5 we discuss the creation of model- based voter proﬁles for targeting and illustrate how they arise naturally within the LORET framework. We ﬁnish with conclusions and some general remarks on the usage of LORET in Section 5. This paper is accompanied by supplementary ma- terial [Rusch et al. (2013a)]. 3. LORET: Modeling and predicting voting behavior. Logistic regression and tree-based methods are popular methods for turnout prediction and voter targeting [Malchow (2008)]. Using this as a backdrop, we introduce a general framework—logistic regression trees (LORET)—that encompasses and extends these methods. Brieﬂy, the idea is the following: Instead of ﬁtting a global logistic regression model to the whole data, one might ﬁt a collection of local regression models to subsets or segments of the data (i.e., a segmented logistic regression model) in order to obtain a better ﬁt and higher predictive accuracy. Since usually the “correct” segmentation is not known, it needs to be learned from the data, for example, by using recursive partitioning methods. In what follows we start with the general formulation of logistic regression mod- els for one or more segments and then show how for more than one segment the segmentation can be estimated with recursive partitioning. 3.1. Segmented logistic regression.Let yi ∈{0, 1} denote a Bernoulli ran- dom variable for the ith observation, i = 1,...,N ,and xi denote a (p + 1)- dimensional vector of p covariates and one intercept, (1,xi1,...,xip)⊤.Let us assume there are r (known or estimated) disjoint segments in the data. For each segment k = 1,...,r, we can then specify a logistic regression model for the rela- tionship between y and x1,...,xp within that segment, P (yi = 1|xi1,...,xip; β(k)) = πi = exp(x⊤ i β(k)) 1 + exp(x⊤ i β(k)) ,(3.1) where k = k(i) is the segment to which observation i belongs and πi denotes the probability to belong to class “1” (e.g., “vote = yes”). The segment-speciﬁc pa- rameter vector is β(k) and its estimates are referred to as ˆβ(k), which can be easily obtained (given the segmentation) via maximum likelihood [see, e.g., McCullagh and Nelder (1989)]. Based on the associated predicted probabilities, classiﬁcation can then be done by ˆyi(c0) = { 1, if ˆπi ≥ c0, 0, if ˆπi <c0, (3.2) where c0 ∈[0, 1] is a speciﬁc cutoff value (but could, in principle, also be speciﬁed to be different for different segments). If there is only a single segment (i.e., a root node and hence a known segmen- tation), LORET in (3.1) reduces to a standard logistic regression model. Here TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1619 FIG.2. A visualization of the different cases of LORET. In the upper left panel there is the y ∼ 1|1 LORET, ﬁtting a constant. In the upper right the y ∼ x|1 LORET (logistic regression) is displayed, which is a single function of x for the whole data set. The lower left panel displays a y ∼ 1|z LORET where the data set is partitioned based on the state of predictor variables z and in each partition a constant is ﬁtted. In the lower right panel, the y ∼ x|z LORET can be found. Here the data set is again partitioned based on z, but this time a logistic function of x is ﬁtted in the partitions. Hence, it combines the y ∼ 1|z and y ∼ x|1 LORET. the parameters of the linear decomposition of the conditional mean of the logit- transformed response variable y are estimated given the status of p covariates. Evaluation of the logistic model at the estimated parameter vector ˆβ yields the predicted probabilities, ˆπi . If the model uses no covariates as regressors, it further reduces to a majority vote model, that is, a logistic regression model with only an intercept or simply the relative frequency of class “1” transformed to the logit scale. The upper row in Figure 2 illustrates majority vote and logistic regression on an artiﬁcial set of data with a single continuous covariate x. The former ﬁts a single constant (the prevalence of “1”), the latter a single logistic function of x to the entire data set. If there were more than one segment and the segmentation were known, then LORET can still be simply seen as estimating a maximum likelihood model from a binomial likelihood in each segment. To estimate it, one needs to specify a lo- gistic regression model with additional main effects for the categorical covariates (factors) corresponding to the segments and the interactions between the segment- 1620 T. RUSCH ET AL. factors and the predictors, but this still falls into the standard theory of generalized linear models [McCullagh and Nelder (1989)]. If the segmentation is unknown, however, it needs to be learned from the data. Two popular approaches for achieving this are using mixture models (e.g., mix- tures of experts or latent class regression) or employing some type of algorithmic search method. Recursive partitioning is a popular example of the latter [with the result often called a “tree”, Zhang and Singer (2010)]. Trees are usually induced by splitting the data set along a function of the predictor variables into a number of partitions or segments. The segments are usually chosen by minimizing an objec- tive function (e.g., a heterogeneity measure or a negative log-likelihood) for each segment. The procedure is then repeated recursively for each resulting partition. This approach approximates real segments in the data and yields a segmentation for which maximum likelihood estimation of parameters in each segment can be carried out, as is done in LORET. 3.2. Recursive partitioning. Let us assume we have an additional, ℓ- dimensional covariate vector z = (z1,...,zℓ). Based on these covariates, we learn the segmentation, that is, we search for r disjoint cells that partition the predictor subspace. Depending on whether the logistic model used for y in each segment has any covariates or just a constant as regressors, there are two algorithmic ap- proaches we can use: classiﬁcation trees and trees with logistic node models. 3.2.1. Classiﬁcation trees. If the logistic model is an intercept-only model and we have a number of partitioning variables z1,...,zℓ, then LORET can be esti- mated as a classiﬁcation tree. An illustration of a classiﬁcation tree can be found in the lower left panel of Figure 2, where the data is ﬁrst partitioned into three subsets and an intercept-only model is ﬁtted to each subset separately. Hence, in each terminal node the model is a constant. A wide variety of algorithms have been developed to ﬁt classiﬁcation trees, among them are CHAID [Kass (1980)], CART [Breiman et al. (1984)], C4.5 [Quinlan (1993)], QUEST [Loh and Shih (1997)], CTree [Hothorn, Hornik and Zeileis (2006)] and many others. In this paper, we use CART and CTree which, respectively, are examples of tree algorithms that are biased or unbiased in variable selection. 3.2.2. Trees with logistic node models. If there are partitioning variables z = (z1,...,zℓ) as well as regressor variables x = (1,x1,...,xp) for the logis- tic node model, we get the most general type of LORET, which is a “model tree.” The situation is illustrated in the lower right panel in Figure 2. Like in a clas- siﬁcation tree, the data is ﬁrst partitioned into subsets. However, in contrast to a classiﬁcation tree, separate logistic regressions with regressors are employed in each terminal node. Thus, the resulting model tree essentially combines data- driven partitioning as done by classiﬁcation trees with model-based prediction in a single approach. Different algorithms have been proposed to estimate model trees TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1621 TABLE 2 Various instances of LORET Method Regressor variables Partitioning variables Schema Majority vote none none y ∼ 1|1 Logistic regression yes none y ∼ x|1 Classiﬁcation tree none yes y ∼ 1|z Model tree yes yes y ∼ x|z with logistic node models, including the following: SUPPORT [Chaudhuri et al. (1995)], LOTUS [Chan and Loh (2004)], LMT [Landwehr, Hall and Eibe (2005)] and MOB [Zeileis, Hothorn and Hornik (2008)]. In what follows, we will use the MOB algorithm with a logistic node model for estimating the most general version of LORET, as it proved to have good properties [Rusch and Zeileis (2013)]. To simplify notation and to stress the similarities, we will use a simple schema to refer to the different LORET types (cf. Table 2 and Figure 2): Majority vote models will be referred to as y ∼ 1|1, global logistic regression models as y ∼ x|1, classiﬁcation tree models as y ∼ 1|z and full LORET model as y ∼ x|z. The LORET framework can be employed for various tasks during a voter tar- geting or get-out-the-vote campaign. To illustrate the usage of LORET in a cam- paign’s voter targeting strategy, we use a unique, proprietary data set from the 2004 general presidential election in Ohio, USA. 4. Case study: Get-out-the-vote in Ohio. We apply our methodology to a (ﬁctional) nonpartisan get-out-the vote campaign in Ohio, USA, whose goal it is to increase voter turnout. We choose Ohio because it has proven to be a pivotal state in about every US presidential election since 1964. Also, in every US presi- dential election since 2000, the difference between the Republican and Democratic candidates has been equal or less than 4%, making it a top battleground state in ev- ery recent election. The campaign we describe pertains to the 2004 US presidential election. Our data set originates from a data vendor who adds value to public records by collecting, maintaining, updating and expanding upon public data. In the US, vendor voter data typically includes the name, address, phone, gender, party af- ﬁliation, age, vote history (elections that each voter voted) or ethnicity. US data vendors standardize the data by each state or county and by adding other poten- tially relevant behavioral information such as income, type of occupation, educa- tion, presence of children, property status (rental or owning) and charities that the person donated to. 1622 T. RUSCH ET AL. 4.1. Data description. For illustration we use a proprietary data set2 which was provided by one of the leading nonpartisan data vendors in the industry. The data set consists of records from 19,634 eligible and registered voters from Ohio. It includes a total of 77 variables, many of which are sociodemographic categorical variables like gender, job category or education level. The data set also contains records on past voting behavior from 1990 to 2004 in general elections, primary or presidential primary elections and other elections, all coded as binary variables— that is, voted (“yes”) or not (“no”). We added three composite or aggregate vari- ables: the raw count of elections a person attended, the number of elections a per- son attended since registering and the relative frequency of attended elections since registering. After removal of missing values and inconsistent entries (366 cases) thereare atotal of N = 19,634 records with 80 variables per record. The variable we want to predict is the individual turnout likelihood in the 2004 US presidential election. 4.2. Two sets of predictors: Voting history only vs. kitchen sink data. The data available to campaigns can vary vastly. Some campaigns have a huge number of variables on millions of eligible voters available, as was the case with President Obama’s re-election campaign in 2012 [Project “Narwhal”, Issenberg (2012a)]. Smaller campaigns may have more limited information available. For all cases, however, the literature on voter targeting suggests that the most commonly used piece of information is the person’s voting history [Malchow (2008)], although often taking into account a person’s age [Karp, Banducci and Bowler (2008), Malchow (2008)] is recommended. One of the goals of this case study is to in- vestigate whether including additional information (besides a person’s voting his- tory and age) into the targeting model is beneﬁcial. To that end, we compare and contrast two sets of predictors: • The ﬁrst set employs the standard information used by many campaigns, which is also recommended in the literature. These standard variables are a person’s voting history, recorded over the last four elections, and age. We call this set “s” for “standard.” • The second set contains all other variables available, that is, the “kitchen sink.” In our case this includes variables like gender, occupation, living situation, party afﬁliation, party makeup of the household (“partyMix”), position within the family (“hhRank” and “hhHead”), donations for various causes, education level, relative frequency of attended elections so far (“attendance”) and many others. These variables constitute a set of additional variables, labeled “e”for “extended.” 2We are not at liberty to share the whole data set but included a snapshot of 6544 anonymized records to make our results comprehensible and for further research, see the supplementary material [Rusch et al. (2013a)]. TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1623 TABLE 3 LORET versions combined with the two variable groups and the algorithms used to estimate the partition. The standard variable set of age and voting history is labeled “s” and the set of additional variables with “e” (hence all variables together are “s + e”) LORET Regressor variables Partitioning variables Partitioning algorithm y ∼ 1|1 none none – y ∼ s|1 s none – y ∼ s + e|1 s + e none – y ∼ 1|s none s CART, CTree y ∼ 1|s + e none s + e CART, CTree y ∼ s|es e MOB 4.3. Model speciﬁcation for the Ohio voters. The combination of the two vari- able sets with the different LORET models leads to model speciﬁcations as dis- played in Table 3. The models either employ only the standard set of variables or the combination of the standard and the extended set. For unpartitioned models, the parameters are estimated with maximum likelihood. If a partition is induced, we learn it with three different algorithms (CART, CTree and MOB), depending on the nature of the node model. Please note that if age is speciﬁed as a parame- ter in the logistic model part (i.e., for models y ∼ s|1, y ∼ s + e|1and y ∼ s|e), a quadratic effect will be used [based on goodness-of-ﬁt considerations; see also Parry et al. (2008)]. All recursive partitioning algorithms that we employ allow for tuning with meta- parameters. These tuning parameters can be used to avoid overﬁtting of the tree algorithms and control how branchy the tree becomes. Quite generally, it can be said that the less branchy a tree is, the less prone it is to overﬁtting. In the algo- rithms we can use a higher number of observations per node, a lower tree depth and a stricter split variable selection criterion that all lead to smaller trees. At the same time the speciﬁcation of metaparameters should grant enough ﬂexibility for the algorithm to approximate a complex nonlinear relationship in the data. For CART the maximal depth of the tree and the minimum number of obser- vation per node (minsplit) are available to control the tree appearance. We use a maximal tree depth of 7 and a minsplit of 100 (which corresponds to roughly 0.5% of the observations). For CTree and MOB the signiﬁcance level of the as- sociation or stability tests, respectively, and the minimum number of observation per node can be used to tune the algorithm and pre-prune the trees. We employ a global signiﬁcance level of α = 1 × 10−6. This is sensible since the high number of observations might easily lead to signiﬁcant results mainly due to the sample size. Hence, we reduce the chance of “false positive” selection of a split variable or split point by specifying a low signiﬁcance level. This also functions as “automatic reg- ularization,” as the test statistics used to decide whether to split a node have to become larger the larger the tree becomes. For minsplit we use 100 for CTree (the 1624 T. RUSCH ET AL. same as for CART) and 1000 for MOB which enables reliable estimation of the node model. Please note that the results were not sensitive to the choice of metapa- rameters. For CART, we explored depths from 3 to 20. For the global signiﬁcance levels of CTree and MOB, we explored values of 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05 and 0.1. For the minimum number of observations a node must contain we explored values of 20, 50, 100, 150, 200, 250 and 500 for all methods. For these choices of depth, number of observations per node and signiﬁcance level, the results were very similar. In what follows we illustrate targeting based on LORET. We start with voter targeting in a setting where proxy data about the voting behavior for a sample of individuals in the upcoming election is available (e.g., from a poll). We then highlight the use of LORET for the creation of voter proﬁles. 4.4. Predicting individual turnout. Typically the individual turnout is only known after the election is over. This makes the application of supervised pro- cedures like LORET during or before the election challenging, since supervised procedures rely on a labeled training set in order to derive predictions. It is there- fore imperative for campaigns to obtain labeled proxy data prior to closing of the election booths that most accurately resembles the true outcome. These data will often arrive from carefully designed, reliable, repeated polls about voting inten- tion. Information gathered this way can be turned into labels for training a super- vised classiﬁcation model. For our virtual campaign to mobilize Ohio voters, we simulate this by estimating LORET via a training set drawn randomly (see also further below) from the entire data. Other proxies that can be used are past elec- tion results. (We also investigated our method with using the previous presidential election as proxy variable. The predictive accuracy was low—around 0.72, with majority vote having an accuracy of 0.7. We concluded that this is no viable al- ternative to surveys of people’s voting intentions, so we refrained from presenting the results in the main paper. The supplementary material [Rusch et al. (2013b)] contains a thorough account of that analysis.) 4.4.1. Learning and test samples via bootstrapping. We simulate the targeting situation based on labeled training data by drawing a bootstrap sample [see, e.g., Hastie, Tibshirani and Friedman (2009)], that is, a learning set of size N which is sampled randomly (with replacement) from the entire set of data and use this as our training set. To the learning set we ﬁt a LORET model and use the model to predict the out-of-bag (oob) test set which consists of observations that were not part of the learning sample and thus basically treating them as having an unknown label. To evaluate and compare the different models, we employ the benchmarking framework of Hothorn et al. (2005). Ten folds of learning and test samples f = 1,..., 10 are used. To provide a further benchmark, we also train and evaluate all models on the whole data set. This allows us to gauge the tendency of a model to overﬁt as well as how close out-of-bag and in-sample performance are. TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1625 4.4.2. Measuring predictive accuracy. For each method, we assess the classi- ﬁcation accuracy (accf ) on each oob test set f at a given cutoff value c0 = 0.5 (for simplicity, we use the same cutoff value of 0.5 for all segments k). To esti- mate overall predictive accuracy, we use the average over all bootstrap samples acc. When using the full data set as training and test set (i.e., in-sample perfor- mance), we denote the accuracy by acc0. Furthermore, we use the ROC curve for model comparison. It displays the false positive rate vs. the true positive rate. For a given threshold value, we average the ROC curves across all bootstrap samples. The area under the ROC curve for oob set f , aucf , serves as a cutoff-independent measure of classiﬁcation accuracy and we calculate it via the Wilcoxon statistic [Wilcoxon (1945)]. Once again, we aver- age it over all bootstrap samples (auc) and use auc0 to denote the in-sample area under the curve. For all the classiﬁcation measures above, higher values imply better predictive capability. By using simultaneous pairwise conﬁdence intervals [using Tukey’s all-pairwise comparison contrasts and controlling for the family- wise error rate, cf. Hothorn, Bretz and Westfall (2008)] around the differences in predictive accuracy and AUC between two models, we assess whether the real dif- ferences can be judged to be different from zero (95% conﬁdence). To account for the dependency structure of bootstrap samples, we center the accuracies before- hand [see Hothorn et al. (2005)]. 4.4.3. Results. Looking at the upper part of Figure 3, which shows boxplots of the predictive accuracy for the bootstrap samples as well as the in-sample ac- curacy (denoted by a cross) at a cutoff value of 0.5, one can see quite clearly how the different models from Table 3 behave for our data. First, using both variable FIG.3. Accuracies for LORET models with different sets of predictors: Accuracy boxplots at a cutoff of 0.5 for all 10 out-of-bag samples for each LORET instance are displayed. The cross denotes the in-sample prediction accuracy of each of these models (acc0). 1626 T. RUSCH ET AL. sets (the standard set and the extended set together) leads to a large improvement in predictive accuracy as compared to just using the standard set. Interestingly, the improvement of using both the “s”and “e” variables over using only “s” is bigger than the improvement of using only “s” over using no covariates at all (cf. Fig- ure 3). Second, LORET versions that employ recursive partitioning perform better than global regression models alone. This holds for using only the standard vari- able set as well as the combination of the extended and standard sets. This can also be seen in Figure 4 which displays the average classiﬁcation accuracies as a function of different cutoff values in the upper panel and the mean ROC curves in the lower panel (averaged over the F = 10 out-of-bag samples). Table 4 gives a detailed summary of the different performance measures for all models. The benchmark of the naive model y ∼ 1|1 is an average prediction accuracy of acc = 70.36% and an AUC of auc = 0.5, averaged over all test sets. Global logistic regression models y ∼ s|1and y ∼ s +e|1 display improved per- formance (acc = 74.97% and auc = 0.740 for the standard set and acc = 84.57% and auc = 0.886 for the combined set) with a huge improvement of the model that uses both variable sets. Both classiﬁcation tree algorithms, CART and CTree, used to estimate y ∼ 1|s and y ∼ 1|s + e result in a generally better performance compared to logistic re- gressions, both on the standard set of predictors as well as for combining the stan- dard and the extended set. Their performance peaks for the combined set with val- ues of acc = 85.96% and auc = 0.878 for y ∼ 1|s + e (CART) and acc = 85.78% and auc = 0.898 for y ∼ 1|s + e (CTree). For the LORET that uses the standard set of predictors as the model in the terminal nodes of the tree and the extended set of predictors for partitioning, that is, y ∼ s|e result values of acc = 85.98% and auc = 0.906, respectively. The performance differences of models using only standard variables and mod- els employing both the standard and the extended variable sets are evident (see Table 4 and Figure 3). Making use of the additional variables leads to highly im- proved performance. However, the differences among the models employing the combined set them- selves (especially between the global logistic regression model and partitioned models) are not that strong. Therefore, to establish a region of performance differ- ences that could be expected if all models performed equally well, we calculated simultaneous 95%-conﬁdence intervals of all pairwise performance differences be- tween the models that use the combined set of variables based on their accuracy as well as AUC. The former can be found in the upper panel of Figure 5, the latter in the lower panel. We can see that the global logistic regression model performs sig- niﬁcantly worse than the partitioned models (α = 0.05). The tree methods perform best in terms of accuracy and their intervals overlap. In contrast, in terms of the cutoff free measure AUC, the y ∼ s|e LORET signiﬁcantly outperforms all other methods. TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1627 FIG.4. Performance indicators for different models. The upper panel features the average accura- cies for the range of different cutoffs for the various LORET instances (for majority vote the average accuracy is displayed as a constant). The lower panel features the averaged receiver operating char- acteristic (ROC) curve for the different models. Threshold averaging has been used for all methods except majority vote. 4.5. Voter segmentation (“Voter proﬁles”). “Voter proﬁles” are descriptions of a voter or set of voters that may include demographic, geographic and psycho- graphic characteristics, as well as voting patterns and voting history. Voter proﬁles are popular in targeting efforts by campaigns, as they allow to break the com- plexity of all the available data down into a small number of key characteristics that can easily be acted upon. Key demographic variables are gender, income, age 1628 T. RUSCH ET AL. TABLE 4 Summary of performance indicators for each LORET instance. For the bootstrap samples, auc means the area under the ROC curve averaged over all 10 out-of-bag test sets. acc is the overall classiﬁcation accuracy averaged over all test sets and se(acc) its standard error. Complexity is given as the number of estimated parameters per segment (terminal node) p + 1 and the median number of segments ˜r. For the full sample models (ﬁtted and evaluated on all observations), the accuracy is given by acc0, the AUC by auc0 and the number of terminal nodes and cofﬁcients in each node by r0 and p0 + 1, respectively Bootstrap samples Full sample Method acc se(acc) auc p + 1 ˜r acc0 auc0 p0 + 1 r0 y ∼ 1|1 0.704 0.004 0.500 1 1.0 0.703 0.500 1 1 y ∼ s|1 0.750 0.002 0.740 8 1.0 0.749 0.739 8 1 y ∼ 1|s (CTree) 0.759 0.004 0.765 1 15.0 0.761 0.762 1 14 y ∼ 1|s (CART) 0.760 0.005 0.745 1 28.5 0.768 0.746 1 27 y ∼ s + e|1 0.846 0.003 0.886 57 1.0 0.848 0.888 57 1 y ∼ 1|s + e (CTree) 0.858 0.003 0.898 1 18.0 0.857 0.898 1 18 y ∼ 1|s + e (CART) 0.860 0.004 0.878 1 23.5 0.863 0.886 1 23 y ∼ s|e 0.860 0.004 0.906 8 9.5 0.860 0.909 8 8 and education. A famous example of a voter proﬁle is the “soccer mom” [Susan (1999)]. Multivariate voter proﬁles arise naturally from the LORET framework and the resulting proﬁles have two distinct beneﬁts: On the one hand, the voter proﬁles are automatically created by a data-driven procedure, as tree-based methods al- gorithmically segment the data into mutually exclusive subsets. The segmenta- tion is based on predictor variables in a well-deﬁned fashion and the selection of important predictors is (usually) done automatically. On the other hand, logistic regression and trees with logistic node models are able to express an individual probability for each voter to turn up at the polls by including regressor variables in the logistic model and thus further differentiate the predicted probability between people in a segment. This way logistic regressions and model trees can provide individual predictions rather than a single prediction for a given proﬁle. Further- more, the estimates of the logistic model and/or the decision rules of the trees offer additional insight into the dynamics of voting behavior. As case in point, consider the most general LORET, y ∼ s|e.Wehaveshown in the previous section that it has high accuracy and AUC for this data set. To derive voter proﬁles based on this model, we ﬁt the logistic regression tree to the whole data set. The decision rules for building the segments and the coefﬁcients for the logistic regression model in each terminal node can be found in Table 5. We can see that the segmentation is driven by only four variables, the party composition of the household for each voter (“partyMix”), the relative frequency of attended elections (“attendance”), the rank of the individual in the household TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1629 FIG.5. Simultaneous pairwise conﬁdence intervals of the differences of mean accuracies at a cutoff 0.5 over the 10 out-of-bag samples (upper panel) and differences of the average area under the ROC curve (AUC) over the 10 out-of-bag samples (lower panel) for all methods employing the combination of the standard and extended variable set. (“hhRank,” with “1” being highest and “3+” being lowest) and whether the person is the head (“H”) or a member (“M”) of the household (“hhHead”). Hence, most partitioning variables are concerned with the household structure rather than with individual-level variables. This underlines a streak of literature that emphasizes the importance of the household for voting behavior [e.g., Cutts and Fieldhouse (2009)]. Note that none of the commonly used demographic variables like gender, education or income plays a role in our tree. We therefore have voter proﬁles that suggest to look at whether a person comes from a household where all members are Democrats, all members are Republican or Democrats or a combination of both, or unknown composition, and all with potentially unafﬁliated voters in the 1630 T. RUSCH ET AL.TABLE5Atabularrepresentationoftheterminalnodesforthey∼s|eLORETforthewholeOhiovoterdataset.Theﬁrstcolumnliststheterminalnodenumbers.Thenextfourcolumnslistthepartitioningvariables(partymix,attendance,householdrankandhouseholdhead)andthesplitpoint(ifany).Thelasteightcolumnslistthecoefﬁcients(upperrow)andstandarderrors(lowerrow)fortheﬁttedlogisticmodelsinthenodes.Pleasenotethatthevaluesforthequadraticeffectofagehavebeenmultipliedby100forreadability.PartitioningvariablesRegressorvariablesSegmentpartyMixattend.hhRankhhHeadconst.gen00gen01gen02gen03ppp04ageage2·1002unknown–––−∞0.0000.0000.0000.0000.0000.0000.000(–.–)(–.–)(–.–)(–.–)(–.–)(–.–)(–.–)(–.–)6allD≤0.48––0.5080.840−1.4740.287−0.7500.4420.054−0.038(0.623)(0.269)(0.212)(0.212)(0.212)(0.231)(0.024)(0.022)7allR,onlyRorD≤0.48––0.4270.740−0.4650.756−0.0750.7080.011−0.004(0.660)(0.239)(0.174)(0.185)(0.177)(0.169)(0.028)(0.027)8allR,allD,>0.48––2.7600.277−1.1640.352−1.890−0.9520.035−0.017onlyRorD(0.948)(0.339)(0.352)(0.379)(0.604)(0.354)(0.025)(0.021)10noneRorD,noneD,––3+4.0570.7810.5911.2491.5200.677−0.2500.272noneR,legal(0.797)(0.128)(0.203)(0.165)(0.214)(0.212)(0.052)(0.076)12noneRorD,noneD,–<3+H−3.6301.415−0.0101.5212.2181.6940.116−0.108noneR,legal(0.339)(0.079)(0.111)(0.105)(0.167)(0.223)(0.013)(0.012)13noneRorD,noneD,–<3+M−1.8681.2170.0861.0811.7001.6030.079−0.078noneR,legal(0.428)(0.113)(0.148)(0.133)(0.193)(0.262)(0.019)(0.021) TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1631 TABLE 6 An example for a targeting list based on predicted probabilities of 10 randomly selected individuals for the y ∼ s + e LORET of the Ohio voter data ﬁle Abs. freq. Rel. freq. ˆπi Segment Age Income Education votes votes Gender Party 1.00 13 60.02 D C 6.00 0.14 F R 0.95 12 44.54 E D 4.00 0.15 M U 0.93 7 63.42 D B 21.00 0.48 F R 0.92 13 51.30 I E 14.00 0.32 F U 0.88 8 22.97 C D 7.00 0.50 F D 0.52 14 27.03 C B 3.00 0.12 F U 0.44 14 30.24 E B 1.00 0.07 F U 0.41 13 25.64 F C 3.00 0.00 F U 0.18 12 23.69 D B 0.00 0.00 F U 0.00 2 47.39 F C 1.00 0.12 F U household. Additionally, our model suggests that one needs to consider the rank of each person in the household and how often the person went voting in the past. The segmentation then gives rise to different logistic models that provide additional targeting suggestions for a campaign based on the coefﬁcients (cf. Table 5 and the predicted probabilities of each individual person in Table 6). The results of the segmentation can be used to build more reﬁned voter pro- ﬁles by looking at the marginal distribution of different variables as displayed in Figure 6. These proﬁles also allow to derive strategic implications for a target- ing campaign. For instance, for all individuals for whom “partyMix” is unknown (segment 2), we ﬁnd the predicted probability to vote is near zero [actually a case where for a linear combination of predictors we have only one level of the out- come, or quasi-complete separation, Albert and Anderson (1984)]. We further see that people in this segment are mostly independent voters (78.6%), relatively of- ten between 19 and 36 year-old individuals (29%), have a secondary education (62.4%) and earn between 35,000 and 75,000 USD a year (47.2%). The most likely voters can be found in segment 7 (mean and median predicted voting probability of 0.908 and 0.925, resp.) and 13 (mean and median predicted probability of 0.861 and 0.939, resp.). Segment 7 has the highest percentage of likely voters (99%, see Figure 6) and consists of people who come from house- holds that either are comprised only of Republicans or of both Republicans and Democrats and who went voting less than 48% of the times. The people in this segment are most often between 36 and 46 years of age (33.7%) or older than 55 (29.4%), declared Republican voters (88.9%) and often head of a household (56.6%). With 32.2%, segment 7 has the highest proportion of people with high income (more than 75,000 USD a year) compared to all other segments. In Seg- ment 13 are people from households with at least one, but predominantely only 1632 T. RUSCH ET AL. FIG.6. Spineplots of the marginal distribution of important voter proﬁle variables for all segments (the segment number is on the x-axis). The variables are vote (a categorization of the predicted vot- ing probability: “likely” (0.7, 1], “undecided” (0.3, 0.7], “unlikely” [0, 0.3]), party afﬁliation (“D” for Democrat, “R” for Republican and “U” for unafﬁliated/independent), gender (“M” for male, “F” for female), education level (“primary,” “secondary,” “postsec”), yearly income (“<35k,” “35k–75k” and “>75k”) and age category. unafﬁliated voters in the household and whose household rank is 2. Roughly three quarters (72%) in this segment are women. Together with the household rank of 2 this points toward this being a segment of spouses or partners (typically wives). The most frequent age group in this segment is 46–54 (31.1%). Age has an interest- ing differential effect in these two segments of likely voters: When looking at the coefﬁcients of the logistic regression model—recall that we speciﬁed a quadratic effect—we see that for segment 7 the turning point is at a high age of 70, but for segment 13 it already appears at 51.1 years. With respect to the mobilization of voters who are undecided as to whether they will turnout, segments 10 and 8 are most interesting. As the top left panel in Fig- ure 6 shows, segment 10 is the segment with the highest proportion of “undecided” voters (56.04%). These voters are from a household with at least one independent or unafﬁliated member and have a household rank of 3 or more. This segment is special insofar as it contains nearly exclusively young people (between 19 and 26, 91.2%) that describe themselves as unafﬁliated voters (85.5%). This segment con- sists of the highest proportion of people with post-secondary education (16.3%). TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1633 It collects young, unafﬁliated voters whose predicted probabilities fall into the tar- geting range in more than 50% of the cases. In contrast, the second “undecided” segment, segment 8 (51.7% undecided), is characterized by people who are sup- porters of either the Republican or the Democratic Party in near equal numbers. Additionally, this segment has the highest proportion of elderly voters (44.7% are over 55). This segment would best be described as elderly, partisan voters who tend to be predicted as being undecided. As an alternative to the aggregated view with voter proﬁles, a campaign can also use the nonaggregated predicted probabilities by generating a turnout or support probability for each voter in the database. Table 6 shows an example with 10 ran- domly chosen individuals. We list their predicted probabilities together with the according realizations of some additional variables. With such a list it is up to the individual campaign to decide how they eventually want to rank the individuals based on the probabilities and how to slice-and-dice these lists. In our campaign, where we want to include only those people in the targeting range of [0.3, 0.7],we would consider persons 6, 7 and 8. If the campaigns would have plans to addition- ally target only those that were younger than 30, then persons 6 and 8 would be targeted. 5. Conclusions. In this paper a framework of statistical methods for tar- geting for turnout or targeting for support of eligible voters has been pro- posed. It combines ideas of trees with the idea of logistic regression which was coined LORET. The predictive accuracy performance of different speciﬁcations of LORET estimated with different algorithms has been investigated for an ex- emplary data set in a “targeting for turnout” setting for a typical situation that a campaign can face: having a reliable proxy for the target variable at its dis- posal. Furthermore, we illustrated how the creation of data-driven voter proﬁles arises naturally in the LORET framework and how this can be used for target- ing. The framework generalizes approaches used by campaigns and is easy to understand or communicate to people who are familiar with logistic regres- sion and/or trees. Furthermore, it allows to create a segmentation of the data which corresponds to automatically building data-driven voter proﬁles which can enhance the effectiveness of targeting measures. As such, the framework is well suited for the purpose of segmentation and identiﬁcation in voter target- ing. Regarding the special cases of LORET, a tree with a logistic node model may be the most useful default version. For our data, it has the best cutoff independent predictive accuracy (measured by AUC) and the highest predictive accuracy (at a cutoff of 0.5). Please note that in our study we had completely accurate labels available, so the accuracy to be expected when dealing only with a proxy from polls might easily be lower. The logistic model tree has the additional advantage of providing reﬁned voter proﬁles for targeting. As a result, decisions based on the 1634 T. RUSCH ET AL. y ∼ s|e LORET are easy to communicate to campaigns that already use logistic regression or trees. The other instances of LORET, however, are not without merit either. Specif- ically, a LORET of the y ∼ 1|s + e type is a good choice if it is not clear what the functional form in the nodes should look like or if there is no standard set of variables to be used in the terminal nodes. Here the nonparametric nature of classiﬁcation trees show their advantage. If the targeting situation is such that the proxies are generally not very reliable/typical for the real outcome of in- terest or there is a high degree of noise in these variables, the extra ﬂexibil- ity and tendency to overﬁt which trees exhibit can be a disadvantage. Here, lo- gistic regression may be more appropriate due to the strict functional relation- ship that it imposes and therefore exhibiting less variability in the predictions about the future. Therefore, even a LORET with just a root node can come in handy. We ﬁnd that if campaigns can use accurate proxy data for the outcome of in- terest, the ﬂexibility introduced by the tree structure may lead to higher predictive accuracy. In a situation where the campaign has to rely on historic proxy data for the outcome of interest, the predictive accuracy is generally low and there will probably be little difference between using a single logistic model or learning partitions as well (see the rejoinder in the supplementary material [Rusch et al. (2013b)]). We conclude that campaigns are generally best advised to make an ef- fort in collecting accurate proxies for the outcome of interest and enabling an anal- ysis as outlined in Section 4.4. We believe this is feasible by using well-designed, repeated polling to obtain the target variable. It is up to future research to es- tablish what the best proxies to be used as labels in the targeting stage actually are. With the beneﬁts mentioned above, one would consider how to incorporate this technique into the overall campaign strategy. The primary beneﬁt of using our framework is that campaigns can have accurate, interpretable, speciﬁc in- dividual level identiﬁcation of potential voters. This gives campaigns the abil- ity to customize communications to each individual. Once the campaigns have better knowledge of the potential voter proﬁles and the likelihood of them vot- ing, campaigns can maximize the return for the money spent on targeting po- tential voters by communicating on issues that matter to them and target voters who are likely to be mobilized. The bottom line here is that the LORET frame- work does not change the commonly used campaign tactics but adds a precise and ﬂexible tool that allows to segment and target the recipients of mobiliza- tion messages accurately. For example, in the decision theoretic framework of optimal campaigning by Imai and Strauss (2011), LORET models that employ segmentation could be used as the building block for estimating heterogenous treatment effects to yield the posterior distributions of the turnout proﬁles [i.e., TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1635 in steps 1 to 3 of Imai and Strauss (2011), page 9]. We believe that by em- ploying the LORET framework, campaigns have a ﬂexible and versatile tool- box at their disposal that can be customized to meet the campaign’s prevalent requirements and can easily be integrated in the overall strategy of GOTV tar- geting. For further research and practical application, it could be fruitful to improve aspects of particular interest in GOTV campaigns. For example, it might be beneﬁcial to use techniques such as artiﬁcial neural networks or ensembles of tree methods to improve predictive accuracy. Over the course of this study we used random forests, neural networks, support vector machines, Bayesian addi- tive regression trees and logistic model trees with boosting to check whether they outperform our tree models. On our data set their performance was not better than the performance of the LORET models, so we refrained from investigat- ing those techniques further and reporting them here (but see the supplementary material [Rusch et al. (2013b)]). Regularized logistic regression models might prove to be a sensible alternative to the tree approach, especially in terms of in- terpretability and variable selection. Regarding the node models, semi- or non- parametric models might be of interest as well, especially when the functional form for the logistic model component is not clear. For building voter proﬁles based on a predictive model, mixture models might also be an interesting alterna- tive. APPENDIX: COMPUTATIONAL DETAILS. All calculations have been carried out with the statistical software R 2.12.0– 2.15.2 [R Development Core Team (2012)], using glm() for logistic regres- sion. Recursive partitioning infrastructure was provided by the packages party for mob() [Zeileis, Hothorn and Hornik (2008)] (with safeGLModel from mobtools, Rusch et al. (2012)] and ctree() [Hothorn, Hornik and Zeileis (2006)], as well as rpart [Therneau and Atkinson (1997), Therneau, Atkinson and Ripley (2011)] for CART. We used the ROCR package [Sing et al. (2005), Sing et al. (2009)] for calculating and plotting performance measures and ROC curves and multcomp [Hothorn, Bretz and Westfall (2008)] for the simultaneous conﬁ- dence intervals. Acknowledgments. We would like to thank Aristotle, Inc. for lending us their data. We further thank Chad Gosselink, Allison Lee, Joel Rivlin, Hal Malchow and Brad Chism for valuable comments on earlier drafts of this paper. We also thank our Editor Susan Paddock, an anonymous Associate Editor and an anonymous re- viewer for valuable comments and suggestions that helped us to improve the paper greatly. 1636 T. RUSCH ET AL. SUPPLEMENTARY MATERIAL Supplement A: Data and Code (DOI: 10.1214/13-AOAS648SUPPA;.zip). A bundle containing the code used to produce the results of the paper and a snap- shot of the data set. Unfortunately we are not at liberty to share the whole original data set, but were allowed to include an anonymized, random sample (N = 6544) of the data. Supplement B: Rejoinder (DOI: 10.1214/13-AOAS648SUPPB; .pdf). A re- joinder containing additional analyses of LORET models with a historic proxy variable and a comparison of LORET models to high-performance methods like Support Vector Machines, Bayesian Additive Regression Trees, Artiﬁcial Neural Networks, Logistic Model Trees and Random Forests. REFERENCES ALBERT,A. and ANDERSON, J. A. (1984). On the existence of maximum likelihood estimates in logistic regression models. Biometrika 71 1–10. MR0738319 ARCENEAUX,K. and NICKERSON, D. W. (2009). Who is mobilized to vote? A re-analysis of 11 ﬁeld experiments. American Journal of Political Science 53 1–16. BLUMENTHAL, M. (2012). Obama campaign polls: How the internal data got it right. Hufﬁng- ton Post. Available at http://www.hufﬁngtonpost.com/2012/11/21/obama-campaign-polls-2012_ n_2171242.html?utm_hp_ref=tw [accessed 2012-12-09]. BREIMAN,L., FRIEDMAN,J. H., OLSEN,R.A. and STONE, C. J. (1984). Classiﬁcation and Regression Trees. Wadsworth, Paciﬁc Grove, CA. CARDY, E. A. (2005). An experimental ﬁeld study and persuasion effects of partisan direct mail and phone calls. Annals of the American Academy of Political and Social Science 601 28–40. CHAN,K.-Y. and LOH, W.-Y. (2004). LOTUS: An algorithm for building accurate and comprehen- sible logistic regression trees. J. Comput. Graph. Statist. 13 826–852. MR2109054 CHAUDHURI,P., LO,W.D., LOH,W.-Y. and YANG, C. C. (1995). Generalized regression trees. Statist. Sinica 5 641–666. MR1347613 CHIPMAN,H. A., GEORGE,E.I. and MCCULLOCH, R. E. (2010). BART: Bayesian additive re- gression trees. Ann. Appl. Stat. 4 266–298. MR2758172 CUTTS,D. and FIELDHOUSE, E. (2009). What small spatial scales are relevant as electoral contexts for individual voters? The importance of the household on turnout at the 2001 general election. American Journal of Political Science 53 726–739. DENNY,K. and DOYLE, O. (2009). Does voting history matter? Analysing persistence in turnout. American Journal of Political Science 53 17–35. FINKEL, S. (1993). Reexamining the “Minimal effects” model in recent presidential elections. Jour- nal of Politics 55 1–21. GERBER,A.S. and GREEN, D. P. (2000a). The effect of a nonpartisan get-out-the-vote drive: An experimental study of leaﬂeting. Journal of Politics 62 846–857. GERBER,A. S. and GREEN, D. P. (2000b). The effects of canvassing, telephone calls, and direct mail on voter turnout: A ﬁeld experiment. American Political Science Review 94 656–664. GERBER,A. S., GREEN,D.P. and GREEN, M. (2007). Partisan mail and voter turnout: Results from randomized ﬁeld experiments. Electoral Studies 22 563–579. GOLDSTEIN,K. and RIDOUT, T. N. (2002). The politics of participation: Mobilization and turnout over time. Political Behavior 24 3–29. TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1637 GREEN,D. P., GERBER,A. S. and NICKERSON, D. W. (2003). Getting out the vote in local elec- tions: Results from six door-to-door canvassing experiments. Journal of Politics 65 1083–1096. GREEN,D.P. and GERBER, A. S. (2008). Get Out the Vote: How to Increase Voter Turnout, 2nd ed. Brookings Institution, Washington DC. GREEN,D. P. and KERN, H. L. (2012). Modeling heterogeneous treatment effects in survey exper- iments with Bayesian additive regression trees. Public Opinion Quarterly 76 491–511. HANSEN,B.B. and BOWERS, J. (2009). Attributing effects to a cluster-randomized get-out-the-vote campaign. J. Amer. Statist. Assoc. 104 873–885. MR2562000 HASTIE,T., TIBSHIRANI,R. and FRIEDMAN, J. (2009). The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd ed. Springer, New York. MR2722294 HOLBROOK,T. M. and MCCLURG, S. D. (2005). The mobilization of core supporters: Campaigns, turnout and electoral composition in United States presidential elections. American Journal of Political Science 49 689–703. HOTHORN,T., BRETZ,F. and WESTFALL, P. (2008). Simultaneous inference in general parametric models. Biom. J. 50 346–363. MR2521547 HOTHORN,T., HORNIK,K. and ZEILEIS, A. (2006). Unbiased recursive partitioning: A conditional inference framework. J. Comput. Graph. Statist. 15 651–674. MR2291267 HOTHORN,T., LEISCH,F., ZEILEIS,A. and HORNIK, K. (2005). The design and analysis of bench- mark experiments. J. Comput. Graph. Statist. 14 675–699. MR2170208 IMAI,K. and STRAUSS, A. (2011). Estimation of heterogeneous treatment effects from randomized experiments, with application to the optimal planning of the get-out-the-vote campaign. Political Analysis 19 1–19. ISSENBERG, S. (2012a). Obama’s white whale: How the campaign’s top-secret project Narwhal could change this race, and many to come. Slate. Available at http://www.slate.com/articles/ news_and_politics/victory_lab/2012/02/project_narwhal_how_a_top_secret_obama_campaign_ program_could_change_the_2012_race_.html [accessed 2012-12-04]. ISSENBERG, S. (2012b). The Victory Lab: The Secret Science of Winning Campaigns. Crown Pub- lishers, New York. KARP,J.A. and BANDUCCI, S. A. (2007). Party mobilization and political participation in new and old democracies. Party Politics 13 217–234. KARP,J.A., BANDUCCI,S. A. and BOWLER, S. (2008). Getting out the vote: Party mobilization in a comparative perspective. British Journal of Political Science 38 91–112. KASS, G. V. (1980). An exploratory technique for investigating large quantities of categorical data. J. R. Stat. Soc. Ser. C. Appl. Stat. 29 119–127. LANDWEHR,N., HALL,M. and EIBE, F. (2005). Logistic model trees. Machine Learning 59 161– 205. LOH,W.-Y. and SHIH, Y.-S. (1997). Split selection methods for classiﬁcation trees. Statist. Sinica 7 815–840. MR1488644 MALCHOW, H. (2008). Political Targeting, 2nd ed. Predicted Lists, LLC, Sacramento, CA. MCCULLAGH,P. and NELDER, J. A. (1989). Generalized Linear Models, 2nd ed. Chapman & Hall, New York. MCDONALD, M. (2012). Turnout rates, 1980–2010. United States Election Project. Available at http://elections.gmu.edu/ [accessed 2012-02-16]. MULLER, M. G. (1999). Electoral campaigning as an occupation—The professionalization of polit- ical consultants in the United States. Politische Vierteljahresschrift 40 198–199. MURRAY,G.R. and SCIME, A. (2010). Microtargeting and electorate segmentation: Data mining the American national election studies. Journal of Political Marketing 9 143–166. 1638 T. RUSCH ET AL. NICKERSON,D.W., FRIEDRICHS,R. D. and KING, D. C. (2006). Partisan mobilization cam- paigns in the ﬁeld: Results from a statewide turnout experiment in Michigan. Political Research Quarterly 59 85–97. PANAGOPOULOS, C. (2009). Partisan and nonpartisan message content and voter mobilization ﬁeld experimental evidence. Political Research Quarterly 62 70–76. PARRY,J., BARTH,J., KROPF,M. and JONES, E. T. (2008). Mobilizing the seldom voter: Campaign contact and effects in high-proﬁle elections. Political Behavior 30 97–113. PHILLIPS,J. M., URBANY,J.E. and REYNOLDS, T. J. (2008). Conﬁrmation and the effects of valenced political advertising: A ﬁeld experiment. Journal of Consumer Research 34 794–806. PLASSER, F. (2000). American campaign techniques worldwide. Harvard International Journal of Press-Politics 5 33–54. QUINLAN, J. R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA. RDEVELOPMENT CORE TEAM (2012). R: A language and environment for statistical computing. R Foundation for Statstical Computing, Vienna, Austria. RUSCH,T. and ZEILEIS, A. (2013). Gaining insight with recursive partitioning of generalized linear models. J. Stat. Comput. Simul. 83 1301–1315. RUSCH,T., ZEILEIS,A., HOTHORN,T. and LEISCH, F. (2012). mobtools: A collection of statmod- els and of utilities for extending mob. R package version 0.0-1. RUSCH,T., LEE,I., HORNIK,K., JANK,W. and ZEILEIS, A. (2013a). Supplement to “Inﬂuenc- ing elections with statistics: Targeting voters with logistic regression trees.” DOI:10.1214/13- AOAS648SUPPA. RUSCH,T., LEE,I., HORNIK,K., JANK,W. and ZEILEIS, A. (2013b). Supplement to “Inﬂuenc- ing elections with statistics: Targeting voters with logistic regression trees.” DOI:10.1214/13- AOAS648SUPPB. SING,T., SANDER,O., BEERENWINKEL,N. and LENGAUER, T. (2005). ROCR: Visualizing clas- siﬁer performance in R. Bioinformatics 21 3940–3941. SING,T., SANDER,O., BEERENWINKEL,N. and LENGAUER, T. (2009). ROCR: Visualizing the performance of scoring classiﬁers. R package version 1.0-4. SUSAN, J. C. (1999). The disempowerment of the gender gap: Soccer moms and the 1996 elections. PS: Political Science & Politics 32 7–11. SUSSMAN,G. and GALIZIO, L. (2003). The global reproduction of American politics. Political Comunication 20 309–328. THERNEAU,T. M. and ATKINSON, E. J. (1997). An introduction to recursive partitioning using the rpart routine. Technical Report 61, Section of Biostatistics, Mayo Clinic, Rochester, NY. THERNEAU,T. M., ATKINSON,E.J. and RIPLEY, B. D. (2011). rpart: Recursive partitioning. R package version 3.1-50. US ELECTION ASSISTANCE COMMISSION (2010). The Impact of the National Voter Registration Act of 1993 on the Administration of Elections for Federal Ofﬁce 2009–2010. WHITELOCK,A., WHITELOCK,J. and VAN HEERDE, J. (2010). The inﬂuence of promotional ac- tivity and different electoral systems on voter turnout: A study of the UK and German Euro elections. European Journal of Marketing 44 401–420. WIELHOUWER, P. W. (2003). In search of Lincoln’s perfect list—Targeting in grassroots campaigns. American Politics Research 31 632–669. WIKIPEDIA (2012). United States presidential election, 2012. Available at http://en.wikipedia.org/ wiki/United_States_presidential_election,_2012 [accessed 2012-11-21]. WILCOXON, F. (1945). Individual comparisons by ranking methods. Biometrics Bulletin 1 80–83. ZEILEIS,A., HOTHORN,T. and HORNIK, K. (2008). Model-based recursive partitioning. J. Comput. Graph. Statist. 17 492–514. MR2439970 TARGETING VOTERS WITH LOGISTIC REGRESSION TREES 1639 ZHANG,H. and SINGER, B. H. (2010). Recursive Partitioning and Applications, 2nd ed. Springer, New York. MR2674991 T. RUSCH CENTER FOR EMPIRICAL RESEARCH METHODS WU (VIENNA UNIVERSITY OF ECONOMICS AND BUSINESS) AUGASSE 2-6 1090 VIENNA AUSTRIA E-MAIL: thomas.rusch@wu.ac.at I. LEE SCHOOL OF MANAGEMENT AUSTRALIAN SCHOOL OF BUSINESS UNIVERSITY OF NEW SOUTH WALES SYDNEY NSW 2052 AUSTRALIA E-MAIL: ilro.lee@unsw.edu.au K. HORNIK INSTITUTE FOR STATISTICS AND MATHEMATICS DEPARTMENT OF FINANCE,ACCOUNTING AND STATISTICS WU (VIENNA UNIVERSITY OF ECONOMICS AND BUSINESS) AUGASSE 2-6 1090 VIENNA AUSTRIA E-MAIL: kurt.hornik@wu.ac.at W. JANK DEPARTMENT OF INFORMATION SYSTEMS AND DECISION SCIENCES COLLEGE OF BUSINESS UNIVERSITY OF SOUTH FLORIDA 4202 E. FOWLER AVE., BSN 3403 TAMPA,FLORIDA 33620-5500 USA E-MAIL: wjank@usf.edu A. ZEILEIS DEPARTMENT OF STATISTICS FACULTY OF ECONOMICS AND STATISTICS UNIVERSITÄT INNSBRUCK UNIVERSITÄTSSTR.15 6020 INNSBRUCK AUSTRIA E-MAIL: Achim.Zeileis@R-project.org","libVersion":"0.3.2","langs":""}