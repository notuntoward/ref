{"path":"lit/lit_notes_OLD_PARTIAL/Google‚Äôs AI Boss Says Scale Only Gets You So Far _ WIRED.pdf","text":"3/4/24, 3:07 PM Google‚Äôs AI Boss Says Scale Only Gets You So Far | WIRED https://www.wired.com/story/deepmind-ceo-demis-hassabis-interview-artiÔ¨Åcial-intelligence-scale/ 2/13 WILL KNIGHT BUSINESS FEB 19, 2024 8:00 AM Google‚Äôs AI Boss Says Scale Only Gets You So Far In an interview with WIRED, DeepMind CEO Demis Hassabis says the biggest breakthroughs in AI are yet to come‚Äîand will take more than just chips. Demis Hassabis at the Wall Street Journal's Future of Everything Festival in May 2023. PHOTOGRAPH: JOY MALONE/GETTY IMAGES 3/4/24, 3:07 PM Google‚Äôs AI Boss Says Scale Only Gets You So Far | WIRED https://www.wired.com/story/deepmind-ceo-demis-hassabis-interview-artiÔ¨Åcial-intelligence-scale/ 3/13 FOR MUCH OF last year, knocking OpenAI off its perch atop the tech industry looked all but impossible, as the company rode a riot of excitement and hype generated by a remarkable, garrulous, and occasionally unhinged program called ChatGPT. Google DeepMind CEO Demis Hassabis has recently at least given Sam Altman some healthy competition, leading the development and deployment of an AI model that appears both as capable and as innovative as the one that powers OpenAI‚Äôs barnstorming bot. Ever since Alphabet forged DeepMind by merging two of its AI-focused divisions last April, Hassabis has been responsible for corralling its scientists and engineers in order to counter both OpenAI‚Äôs remarkable rise and its collaboration with Microsoft, seen as a potential threat to Alphabet‚Äôs cash-cow search business. Google researchers came up with several of the ideas that went into building ChatGPT, yet the company chose not to commercialize them due to misgivings about how they might misbehave or be misused. In recent months, Hassabis has overseen a dramatic shift in pace of research and releases with the rapid development of Gemini, a ‚Äùmultimodal‚Äù AI model that already powers Google‚Äôs answer to ChatGPT and a growing number of Google products. Last week, just two months after Gemini was revealed, the company announced a quick-fire upgrade to the free version of the model, Gemini Pro 1.5, that is more powerful for its size and can analyze vast amounts of text, video, and audio at a time. A similar boost to Alphabet‚Äôs most capable model, Gemini Ultra, would help give OpenAI another shove as companies race to develop and deliver ever more powerful and useful AI systems. Hassabis spoke to WIRED senior writer Will Knight over Zoom from his home in London. This interview has been lightly edited for length and clarity. SAVE 3/4/24, 3:07 PM Google‚Äôs AI Boss Says Scale Only Gets You So Far | WIRED https://www.wired.com/story/deepmind-ceo-demis-hassabis-interview-artiÔ¨Åcial-intelligence-scale/ 4/13 WIRED: Gemini Pro 1.5 can take vastly more data as an input than its predecessor. It is also more powerful for its size, thanks to an architecture called mixture of experts. Why do these things matter? Demis Hassabis: You can now ingest a reasonable-sized short film. I can imagine that being super useful if there's a topic you're learning about and there's a one-hour lecture, and you want to find a particular fact or when they did something. I think there's going to be a lot of really cool use cases for that. We invented mixture of experts‚Äî[Google DeepMind chief scientist] Jeff Dean did that‚Äîand we developed a new version. This new Pro version of Gemini, it‚Äôs not been tested extensively, but it has roughly the same performance as the largest of the previous generation of architecture. There‚Äôs nothing limiting us creating an Ultra- sized model with these innovations, and obviously that‚Äôs something we're working on. In the last few years, increasing the amount of computer power and data used in training an AI model is the thing that has driven amazing advances. Sam Altman is said to be looking to raise up to $7 trillion for more AI chips. Is vastly more computer power the thing that will unlock artificial general intelligence? Was that a misquote? I heard someone say that maybe it was yen or something. Well, look, you do need scale; that's why Nvidia is worth what it is today. That‚Äôs why Sam is trying to raise whatever the real number is. But I think we're a little bit different to a lot of these other organizations in that we've always been fundamental research first. At Google Research and Brain and DeepMind, we've invented the majority of machine learning techniques we're all using today, over the last 10 years of pioneering work. So that‚Äôs always been in our DNA, and we have quite a lot of senior research scientists that maybe other orgs don't have. These other startups and even big companies have a high proportion of engineering to research science. Are you saying this won‚Äôt be the only way that AI advances from here on? My belief is, to get to AGI, you‚Äôre going to need probably several more innovations as well as the maximum scale. There‚Äôs no let up in the scaling, we're not seeing an asymptote or anything. There are still gains to be made. So my view is you've got to push the existing techniques to see how far they go, but you‚Äôre not going to get new 3/4/24, 3:07 PM Google‚Äôs AI Boss Says Scale Only Gets You So Far | WIRED https://www.wired.com/story/deepmind-ceo-demis-hassabis-interview-artiÔ¨Åcial-intelligence-scale/ 5/13 capabilities like planning or tool use or agent-like behavior just by scaling existing techniques. It‚Äôs not magically going to happen. The other thing you need to explore is compute itself. Ideally you‚Äôd love to experiment on toy problems that take you a few days to train, but often you'll find that things that work at a toy scale don't hold at the mega scale. So there's some sort of sweet spot where you can extrapolate maybe 10X in size. Does that mean that the competition between AI companies going forward will increasingly be around tool use and agents‚ÄîAI that does things rather than just chats? OpenAI is reportedly working on this. Probably. We‚Äôve been on that track for a long time; that‚Äôs our bread and butter really, agents, reinforcement learning, and planning, since the AlphaGo days. [In 2016 DeepMind developed a breakthrough algorithm capable of solving complex problems and playing sophisticated games.] We‚Äôre dusting off a lot of ideas, thinking of some kind of combination of AlphaGo capabilities built on top of these large models. Introspection and planning capabilities will help with things like hallucination, I think. It's sort of funny, if you say ‚ÄúTake more care‚Äù or ‚ÄúLine out your reasoning,‚Äù sometimes the model does better. What's going on there is you are priming it to sort of be a little bit more logical about its steps. But you'd rather that be a systematic thing that the system is doing. This definitely is a huge area. We're investing a lot of time and energy into that area, and we think that it will be a step change in capabilities of these types of systems‚Äî when they start becoming more agent-like. We‚Äôre investing heavily in that direction, and I imagine others are as well. Won‚Äôt this also make AI models more problematic or potentially dangerous? I've always said in safety forums and conferences that it is a big step change. Once we get agent-like systems working, AI will feel very different to current systems, which are basically passive Q&A systems, because they‚Äôll suddenly become active learners. Of course, they'll be more useful as well, because they'll be able to do tasks for you, actually accomplish them. But we will have to be a lot more careful. 3/4/24, 3:07 PM Google‚Äôs AI Boss Says Scale Only Gets You So Far | WIRED https://www.wired.com/story/deepmind-ceo-demis-hassabis-interview-artiÔ¨Åcial-intelligence-scale/ 6/13 I've always advocated for hardened simulation sandboxes to test agents in before we put them out on the web. There are many other proposals, but I think the industry should start really thinking about the advent of those systems. Maybe it‚Äôs going to be a couple of years, maybe sooner. But it‚Äôs a different class of systems. You previously said that it took longer to test your most powerful model, Gemini Ultra. Is that just because of the speed of development, or was it because the model was actually more problematic? It was both actually. The bigger the model, first of all, some things are more complicated to do when you fine-tune it, so it takes longer. Bigger models also have more capabilities you need to test. Science Your weekly roundup of the best stories on health care, the climate crisis, genetic engineering, robotics, space, and more. Delivered on Wednesdays. By signing up you agree to our User Agreement (including the class action waiver and arbitration provisions), our Privacy Policy & Cookie Statement and to receive marketing and account-related emails from WIRED. You can unsubscribe at any time. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Hopefully what you are noticing as Google DeepMind is settling down as a single org is that we release things early and ship things experimentally on to a small number of people, see what our trusted early testers are going to tell us, and then we can modify things before general release. Speaking of safety, how are discussions with government organizations like the UK AI Safety Institute progressing? It‚Äôs going well. I'm not sure what I'm allowed to say, as it's all kind of confidential, but of course they have access to our frontier models, and they were testing Ultra, and we continue to work closely with them. I think the US equivalent is being set up Email address SIGN UP NOW Enter your email 3/4/24, 3:07 PM Google‚Äôs AI Boss Says Scale Only Gets You So Far | WIRED https://www.wired.com/story/deepmind-ceo-demis-hassabis-interview-artiÔ¨Åcial-intelligence-scale/ 7/13 now. Those are good outcomes from the Bletchly Park AI Safety Summit. They can check things that we don‚Äôt have security clearance to check‚ÄîCBRN [chemical, biological, radiological, and nuclear weapons] things. These current systems, I don't think they are really powerful enough yet to do anything materially sort of worrying. But it's good to build that muscle up now on all sides, the government side, the industry side, and academia. And I think probably that agent systems will be the next big step change. We'll see incremental improvements along the way, and there may be some cool, big improvements, but that will feel different. You Might Also Like ‚Ä¶ üìß Find the best bargains on quality gear with our Deals newsletter The one internet hack that could save everything Online reviews are being bought and paid for. Get used to it Apple TV+ is the New HBO Why RFK Jr. is suddenly everywhere online The city of tomorrow will run on your toilet water üåû See if you take a shine to our picks for the best sunglasses and sun protection Will Knight is a senior writer for WIRED, covering artificial intelligence. He writes the Fast Forward newsletter that explores how advances in AI and other emerging technology are set to change our lives‚Äî sign up here. He was previously a senior editor at MIT Technology Review, where he wrote about fundamental... Read more SENIOR WRITER","libVersion":"0.3.2","langs":""}