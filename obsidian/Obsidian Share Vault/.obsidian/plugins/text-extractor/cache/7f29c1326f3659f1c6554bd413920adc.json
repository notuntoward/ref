{"path":"lit/lit_sources/Mattes21canVotersDetectLIes.pdf","text":"Vol.:(0123456789) Political Behavior (2023) 45:395–418 https://doi.org/10.1007/s11109-021-09747-1 1 3 ORIGINAL PAPER Deception Detection in Politics: Can Voters Tell When Politicians are Lying? Kyle Mattes 1 · Valeriia Popova 1  · Jacqueline R. Evans 1 Accepted: 12 August 2021 / Published online: 20 August 2021 © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2021 Abstract In this study, we investigate voters’ unaided perceptions of whether politicians are lying. We conduct an experiment in which participants attempt to uncover politi- cians’ dishonesty by watching videos of their speeches. We find that verbal cues (specifically, the amount of detail in the speech) and general demeanor cues explain the success (failure) of veracity judgments far better than paraverbal and nonverbal cues. We also find evidence of a truth bias—people are more likely to judge state- ments to be true than false—despite the political setting, where voters might have been more skeptical. However, gender plays a deterministic role for veracity judg- ments in political context; female politicians are more likely to be judged as honest. Keywords Deception · Politics · Lying · Cues · Politicians · Veracity · Judgement · Voters One might say that dishonesty in politics is a long-standing tradition. Plato proposed a justification for politicians’ lying in “The Republic”: “Then if anyone at all is to have the privilege of lying, the rulers of the State should be the persons; and they, in their dealings either with enemies or with their own citizens, may be allowed to lie for the public good.” (Plato, 1901:70). As a detractor of democracy, he likely cared little whether the public would be able to detect such deception. While such a “royal lie” would be beneficial to philosopher kings, for actual politicians, the * Valeriia Popova vpopova@fiu.edu Kyle Mattes kmattes@fiu.edu Jacqueline R. Evans jacevans@fiu.edu 1 Florida International University, Miami, FL, USA 396 Political Behavior (2023) 45:395–418 1 3 “public good” casts a wide net. Many politicians have clearly benefitted from telling voters what they want to hear or what they want to believe, and history is filled with examples of politicians lying to cover up crime and corruption.1 What are the con- sequences? “The lie has long since lost its honest function of misrepresenting real- ity,” writes Theodor Adorno. “Nobody believes anybody, everyone is in the know” (Adorno, 2005: 30). Dishonesty in politics is important because it poses a threat to electoral account- ability. Citizens who can detect political lies are more safeguarded against attempted manipulation by elected officials. This in turn incentivizes politicians to avoid dis- seminating blatantly false information, lest they be punished by the electorate in the future. On the other hand, if the public largely fails to detect politicians’ mendac- ity, this poses challenges to the free and fair dissemination of ideas—and debate thereof—that comprise political discourse. Politicians who can convince a large swath of the public to believe their lies would have outsized impact in the shaping of public opinion. There is some evidence that voters have developed the ability to root out politi- cians’ lies. Woon (2017) finds that citizens can detect the truth from transcripts of political speeches. Rossini (2010) tested people’s ability to correctly identify politi- cal truth from politicians’ facial expressions and voices, rather than the content of the political speeches themselves. However, the political science literature about detecting deception is predominantly focused on fact-checking, which is the adjudi- cation of political statements by mass media outlets such as Politifact.com and the Washington Post. These studies examine whether fact-checks can ultimately change public opinion, and under which conditions they are most effective (e.g., Berinsky, 2017; Capella & Jamieson 1997; Fridkin et al., 2015). In this study, we conduct an experiment in which participants attempt to uncover dishonesty by watching videos of politicians who might be lying. Our research con- tributes to the literature on political deception in two ways. First, we draw upon the extant psychology literature on deception detection, examining fourteen specific cues across four categories (verbal, nonverbal, paraverbal, and general demeanor) that voters are most likely to draw upon when considering the veracity of political statements. To our knowledge, no previous study has systematically examined such a broad range of cues. We find that verbal cues (specifically, the amount of detail in the speech) and general demeanor cues explain the success (and failure, respec- tively) of veracity judgments far better than paraverbal and nonverbal cues. Second, we examine whether truth bias—that people are more likely to judge statements to be true than false—exists in a political setting, where voters may be more skeptical. We find evidence of a truth bias but also that gender plays a deterministic role for veracity judgments in political context; female politicians are more likely than their male counterparts to be judged as honest. 1 See Callander and Willkie (2007) for strategic calculations behind political deception. 397 1 3 Political Behavior (2023) 45:395–418 A Questionable Relationship with the Truth Though politicians may bear certain psychological costs of breaking trust (Battigalli et. al. 2013; Charness & Dufwenberg, 2006; Corazzini et al., 2014), we also know they lie strategically (Austen-Smith, 1992; Bucciol & Zarri, 2013) and attempt to avoid detection. Politicians face many situations for which lying is a potential solu- tion. For example, a politician in a marginal seat may feel compelled to lie about anything that, if admitted, will cost the election (Armstrong-Taylor, 2012). By some accounts, politicians’ lying is a rational response to the expectation that other can- didates will engage in deceptive behavior (Woon & Kanthak 2016). Furthermore, Davis and Ferrantino (1996) theorize that lying is incentivized by the lack of trans- ferrable property rights to political office—it’s easier and faster to return a faulty used car than a faulty politician. Furthermore, Janezic and Gallego (2020) find that politicians with a greater willingness to lie have a better chance of being re-elected. A recent study shows that politicians tend to be dishonest even when their pref- erences are aligned with those of their constituencies (Woon & Kanthak 2016). Lying is commonplace enough for researchers to develop taxonomies of political lies; Pfiffner (1999) delineates three types of lying by presidents: justifiable lies, lies to prevent embarrassment, and lies of policy deception, each having different consequences and effects on public trust. This propensity to compromise honesty is furthermore exacerbated by the structure and size of rewards from holding public office (Caselli & Morelli, 2004); the more lucrative the payoff looks for a decision- maker, the more likely she or he to lie to get that payoff (Gneezy, 2005; Gneezy et al., 2013). Some consider ambiguity to be a method of deception, such as when politicians have a policy preference but, for political gain, either attempt to obfuscate it or pre- tend they do not have a stance. Ambiguity serves well if a candidate is uncertain about the position of the median voter; being purposefully ambiguous about one’s policy positions allows a candidate more time to investigate voters’ preferences (Glazer, 1990). Such ambiguity can be harmful to voters; for one, it leaves voters uncertain about which candidate is more extreme (Schnakenberg, 2016). When mul- tiple politicians send competing messages to the same voters, they leave voters to wonder which messages are truthful and which are not (Minozzi, 2011). Surpris- ingly, ambiguity in political rhetoric does not always repel voters and even may, on the contrary, attract them. The preference for an ambiguous candidate is a function of an individuals’ risk orientation and preferences for candidates from one’s own party (Tomz & Houweling, 2009). While politicians are hesitant to tell complete (“black”) lies, they are strongly inclined to deliver partially true claims, or “grey lies” (Bucciol & Zarri, 2013), such as exaggeration. Candidates may exaggerate their messages because their communication with voters exists in a noisy environ- ment with many other actors and messages (Minozzi & Woon, 2016). In sum, politi- cians lie to voters in a variety of ways for a variety of reasons. Can voters figure out when they are lying? 398 Political Behavior (2023) 45:395–418 1 3 A Primer in Psychology Research on Deception Detection The ability to accurately assess the credibility of messages provided by another per- son has been well-studied in psychology (Bond & DePaulo, 2006; DePaulo et  al., 2003; Vrij, 2008), so it is important to draw upon that literature when investigat- ing voters’ abilities to assess the credibility of politicians. The literature provides a basis for predicting the types of behaviors voters will attend to, and the behaviors by politicians that will help them lie more (or less) successfully. Past research has examined messages in text form, audio form, and video form, and includes state- ments provided during one-on-one interactions, as well as statements recorded to be shown to observers at a later time (e.g., Bond & DePaulo, 2006). While some research focuses on the use of tools designed to facilitate deception detection (e.g., the polygraph; Statement Validity Analysis), the focus of this review is intuitive lie detection. In other words, we look at the ability of one person to assess the veracity of a message provided by another person, without any additional tools. Across this vast literature, there are two findings about these unaided assessments of truth that are arguably the most consistent. First, people have a truth bias. In other words, they are more likely to judge statements as true than false. Relatedly, they tend to have higher accuracy rates when assessing true statements than false state- ments (Bond & DePaulo, 2006). There are many potential reasons for this bias that have been proposed (Vrij, 2008). One, for example, is that it is not socially accept- able to go through life suspicious of what one is told and questioning the honesty of those around you. As such, people tend to accept what they are told at face value. In some cases, there may be a lack of motivation to learn the truth (e.g., catching a cheating spouse), sometimes referred to as the ostrich effect, again leading to accepting a message without question. However, an exception to this rule is that law enforcement may demonstrate a lie bias when evaluating suspect statements (Meiss- ner & Kassin 2002), possibly because they expect a high base rate of deception. The second consistent finding is that humans are not particularly skilled at detect- ing deception. In their meta-analysis, Bond and DePaulo (2006) report a 54% accu- racy rate across studies; while this is technically greater than chance at a statistically significant level, it is certainly not an impressive success rate. Further emphasizing that credibility assessment is not a task at which humans naturally excel, “experts” who must assess credibility regularly in their profession (e.g., law enforcement, judges) perform as the same low levels as novices (Bond & DePaulo, 2006). There are two commonly suggested explanations for why this may be the case. These have been referred to as the “wrong subjective cues hypothesis” and the “weak objective cues hypothesis” (Hartwig & Bond 2011). The wrong subjective cues hypothesis suggests that people rely on the wrong cues when attempting to identify deception. Indeed, there is much evidence to suggest this is the case. In 51/58 countries the most frequently reported cue to deception was gaze aversion (Global Deception Research Team, 2006) and generally speaking, many of the behaviors that deceptive individuals are expected to display are based in the assump- tion that liars are experiencing anxiety and shame (Bond & DePaulo, 2006). How- ever, these types of cues (e.g., fidgeting, blushing, gaze aversion) are, in fact, not 399 1 3 Political Behavior (2023) 45:395–418 associated with deception (DePaulo et al., 2003). Rather, some cues that were most strongly associated with veracity were impression of verbal/vocal immediacy (liars seem less immediate), ambivalence (liars seem more ambivalent), number of details provided (liars provide fewer details), and verbal/vocal uncertainty (liars seems less certain). The fact that the cues people expect to be associated with deceit are not diagnos- tic may account for poor deception detection accuracy. However, the research on cues to deception also indicates that not only are the stereotypical cues to deceit not useful, but that there are few useful cues, and these “useful” cues are of very limited value. This is the basis for the weak objective cues hypothesis. Only 12 of the 158 cues examined in the DePaulo et  al (2003) metanalysis met the effect size thresh- old of d > 0.2, and only four of those (verbal/vocal immediacy, ambivalence, num- ber of details provided, and verbal/vocal uncertainty) met the threshold of d ≥ 0.3.2 These findings suggest that even if people relied on the most useful cues, differences between liars and truthtellers would still be difficult to detect because those cues are quite weak. A lens model meta-analysis tested which of the two aforementioned hypotheses better account for the data (Hartwig & Bond 2011) and the findings indi- cate that the weak objective cues hypotheses best accounts for poor deception detec- tion accuracy. Deception Detection Cues In the current study we investigated several cues that might be relied on by vot- ers attempting to evaluate politicians’ credibility. These cues are either known to be commonly reported as indicative of deception by laypeople (“common cues”) and/or have been shown to be associated with statement veracity (“useful cues”). We classi- fied the cues based on various aspects of the speaker’s behavior, specifically a speak- ers’ verbal behaviors (e.g., content of statement), paraverbal (i.e., vocal) behavior (e.g., pitch), non-verbal behavior (e.g., fidgeting), and global demeanor impressions (e.g., nervousness). Verbal cues are generally considered to be the best cues to rely upon in the decep- tion literature (Bond & DePaulo, 2006; Vrij, 2019). Indeed, the most obvious cue that something is a lie is that it contradicts something that is known (or believed) to be true. Relatedly, statement plausibility is a commonly reported cue to deception (Hartwig & Granhag, 2015), and it is also a predictor of statement veracity (e.g., DePaulo et al., 2003). As such, we examined whether participants reported relying on statement content. We also included another useful verbal cue, and perhaps the most discriminating and well-studied cue in the literature: amount of detail (e.g., 2 Note that this excludes any cues that were examined by fewer than six studies. Their effect sizes are measured using Cohen’s d; a common rule of thumb for effect sizes in the psychological literature is that a d = .2 is small, a d = .5 is medium, and d = .8 is large, though we admit that these distinctions are some- what arbitrary. 400 Political Behavior (2023) 45:395–418 1 3 DePaulo et  al., 2003; Luke, 2019). Truthful statements generally are longer/more detailed that false statements. Paraverbal cues are auditory in nature, like verbal cues, but relate to how some- thing is said rather than what is said; one does not have to understand what is being said in order to pick up on paraverbal cues. While several of the most common cues are paraverbal in nature (e.g., hesitations), they are less reliably associated with veracity than verbal cues. In the current study we examined four paraverbal cues: hesitations, speech errors, voice pitch, and (un)certainty. The first three of those are commonly reported cues to deception (Hartwig & Granhag, 2015). The DePaulo et al. (2003) meta-analysis did in fact that find higher voice pitch is associated with deception. Also found to be associated with deception was uncertainty. The utility of hesitations and speech errors is less clear. In the DePaulo et al. meta-analysis these were generally not useful cues, regardless of the specific measure (e.g., filled vs. unfilled pauses). However, it is worth noting that in Vrij’s (2008) review more stud- ies had been done, and the utility of speech errors may be greater than indicated by DePaulo et al (2003). While most of the 43 studies summarized did not find signifi- cant differences in speech errors across veracity conditions, 17 studies did find liars had more speech errors (and only 3 found that liars had fewer speech errors). For non-verbal cues to deception, we focused on gaze/eye movement, fidgeting, and facial expressions. Eye contact/gaze aversion is the most universally reported cued to deception (Global Deception Research Team, 2006), although it does not actually correlate with deception (DePaulo et al., 2003). Fidgeting is also a common cue (Hartwig & Granhag, 2015), yet it has not been linked to deception (although there are different measures of fidgeting, and some may be more useful than others; DePaulo et  al., 2003; Vrij, 2008). We also included facial expressions, given that the concept of using microexpressions to detect deceit has to some extent reached the general population thanks to popular shows like Lie to Me. Unfortunately, the empirical literature has failed to find that attending to microexpressions is particu- larly useful when assessing credibility (e.g., Jordan et al., 2019). We examined global impressions of speaker demeanor in addition to the more specific behaviors described above. There seems to be a general belief that lying is morally wrong, which should leave liars feeling guilty/ashamed, and leave them nervous about the possibility of being caught in a lie (e.g., Bond & DePaulo, 2006). As such, we examined guilt/shame, nervousness, and the flip side of nervousness— calmness. DePaulo et  al. (2003) did in fact find that impressions that a speaker was nervous or tense were associated with deception. We also examined impres- sions that the speaker was thinking hard. This cue is consistent with the cognitive load approach to lie detection which posits that lying is more difficult a task than truth-telling and has support in the research literature. Vrij et al. (2001) in fact found that police officers’ impressions that a suspect was thinking hard better predicted deception than explicit deception judgments. Finally, we examined confidence, as this is broadly associated with credibility (e.g., Semmler et al., 2012; Tenney et al., 2011). In line with this, competence and ambivalence are cues that evaluators rely on (Hartwig & Bond 2011), and ambivalence and certainty are useful cues to decep- tion (DePaulo et al., 2003). 401 1 3 Political Behavior (2023) 45:395–418 Voters and Deception Detection When it comes to deceptive behavior and veracity judgments in politics, there is a dynamic between the sender (politician) and the receiver (voter) which is not typi- cal for ordinary interactions between individuals. If citizens think that politicians lie frequently, they may be reluctant to believe politicians’ words easily. Voters are in a particularly difficult situation when it comes to detecting the deception of politi- cians, because politicians often have the opportunity to plan their lies, as opposed to making them up on the spot. Research suggests that planned lies, as one might expect, are more difficult to detect than spontaneous lies (Bond & DePaulo, 2006). On the other hand, politicians may be especially motivated to get away with their lies, and a sender’s motivation to be believed is associated with higher deception detection accuracy (Bond & DePaulo, 2006). The public’s low knowledge of and inattentiveness to political issues (Carpini et al., 1996; Converse, 1964; Zaller, 1992) constitutes another peculiarity of political deception. Situational familiarity influences people’s veracity judgments in interper- sonal settings (Reinhard et  al., 2011; Reinhard et  al., 2012; Stiff et  al., 1989), So, while a politician has strong incentives to hide cues of deceptiveness, less knowl- edgeable voters may be increasingly likely to rely on ineffectual cues to judge politi- cians’ truthfulness. On the other hand, voters who are more knowledgeable about politics may be more confident in their own ability to spot political lies, and thus they would be less reliant on cues. However, we should note that an assumption underlying our study is that voters actually care whether politicians are lying to them, though we admit some evidence to the contrary. In addition to blatant deception, self-deception of both political lead- ers and the public is a common phenomenon in democratic politics (Cowen, 2005; Galeotti, 2015). Furthermore, inflated language (such as misrepresentation and cheap talk) naturally arises in any communication with an informed sender and an uninformed receiver due to incomplete information available to the latter (Kartik, 2009; Kartik & Weelden, 2019)—a description that can be applied to virtually every political campaign. If deceptive behavior is a norm rather than a deviation, politi- cians may not suffer much when their more routine lies are revealed. Our main hypotheses, informed by the literature of deception detection presented above, are as follows: H1 (Truth Bias): Respondents exhibit a truth bias in their assessments. H2 (Deception Detection Accuracy): Respondents can assess politicians’ lies with accuracy significantly above 50%. H3 (Detection Cues): The reported use of verbal cues increases accuracy at deception detection. The reported use of paraverbal cues, nonverbal cues, and gen- eral demeanor cues does not increase accuracy. Of course, as we have discussed, theories of deception detection may not apply to politics due to the unique dynamic between politicians and voters. We also use this opportunity to test a few hypotheses that are more specific to our political context. In general, we know that the accuracy of veracity judgments improves once peoples’ situational familiarity increases (Reinhard et  al., 2011; 402 Political Behavior (2023) 45:395–418 1 3 Reinhard et al., 2012; Stiff et al., 1989). We expect that those who are more informed about politics or pay more attention to politics to be more confident about assessing politicians’ veracity—and to be better at it. H4 (Confidence): The confidence respondents have in their own assessments is a positive predictor of detection accuracy. H5 (Political Interest): Greater political interest is associated with greater detec- tion accuracy. Finally, two recent studies (Houser et al., 2016; Mattes & Redlawsk, 2014) find that voters will make sub-optimal voting choices (e.g., vote for candidates with less favorable policy positions) if they face even a small probability of deception by the candidate(s). In other words, the mere possibility that candidates could be lying to them can greatly impair voters’ ability to assess candidates. In this case, we would expect that voters who are more cynical about politicians would be less able to determine whether specific politicians are lying to them. H6 (Suboptimal Choice): Cynicism about the trustworthiness of politicians is negatively associated with detection accuracy. Research Design To test these hypotheses, we distributed an original survey to two samples of adults (in February 2018 and March 2020), during which respondents were shown twelve videos of either politicians running for office or being interviewed about their jobs. Participants were informed these politicians may or may not be lying. After each video, we asked the respondents to (1) judge whether the politician was being truth- ful or deceptive, and (2) report their confidence level in each judgment. Stimuli In our videos, the politician’s potentially truthful/deceptive statement is presented with some contextual detail. The videos average 16 s in length, with a range from 10 to 27  s. Since we focus in-depth on cues of political deception, our videos are long enough to provide respondents with ample time for detecting such cues, but not long enough to induce respondent fatigue nor overwhelm them with excessive details. Other than editing video length and removing graphics identifying the media sources (e.g., logos), we kept the videos in their original state; the content of state- ments, intonations, and behavior of politicians were unaltered. We only included live speeches as opposed to taped speeches or advertisements, as the latter two would allow politicians to edit out or reshoot portions where they looked nervous, for instance. We intentionally chose videos of politicians who would be relatively unknown to our respondents to minimize the chances that the respond- ent already held a strong attitude toward the politician or already knew whether the statement was true. As further explained below, if a participant believed that they were familiar with a given politician, their responses regarding that politician were excluded. 403 1 3 Political Behavior (2023) 45:395–418 We balanced our videos by the politicians’ gender and the truthfulness/deceptive- ness of their statements. To exclude a possibility of a racial bias based on respond- ents’ own characteristics, we showed them videos of only white politicians. Six of the politicians were male, six were female, and three of each gender were being truthful. Of course, many would say that truth in politics can be subjective. To address this concern, we only chose video clips where the statement had been fact- checked by a reputable independent source. In some instances, we relied on state and local fact-checkers that were affiliated with major broadcasters such as NBC and NPR. In such cases, the facts were cross-checked in several reputable national news outlets. To qualify, the statements had to be decisively judged as truthful or deceitful by the fact-checker—for instance, rated “Pants on Fire” by Politifact or awarded at least two Pinocchios by the Washington Post. This limited the number of statements available to us, because fact-checks tend to be focus predominantly on national poli- tics, for which the major players are well-known. We classify the videos by three categories of statements: politicians talking about themselves, about their opponents, or about other relevant facts.3 We defined state- ments about relevant facts to be those which did not have a politician as the target. For example, one falsely claimed that, in the previous year, 307,000 veterans had died waiting for health care. Appendix Tables 2 and 3 summarize the videos in our study and provide links to the videos and fact-checks. However, we opted not to balance our selection in terms of politicians’ partisan- ship; eight of our twelve politicians are Democrats. Partisanship bias influences peo- ple’s veracity judgments, especially for polarizing topics (Woon, 2017). In contrast, we are interested in knowing what underlying factors influence people’s perception of political deception independent of their partisanship; this assessment is espe- cially important in primaries and nonpartisan contests. We carefully selected videos without overt partisan cues (such as party names and appeals to ideology or poli- cies endorsed predominantly by either Democrats or Republicans). Our attempt at nonpartisanship was ultimately successful, as respondents did not assess politicians from their own party as more truthful, nor the opposing party as more deceptive. Participants Participants in Sample 1 were 181 students recruited in February 2018 from the Psychology Department online participant pool at Florida International University, which is administered via Sona Systems. 4 We distributed our approximately 30-min survey online using Qualtrics. For compensation, participants received research credit in a psychology course. The study description indicated the study involved deception detection, and that only students who were U.S. citizens over the age of 3 We did our best to balance the videos by these topics, but we were limited by the availability of fact- checks for each category. Specifically, we could not find a good example of a female politician lying about herself. 4 At various points in the survey, we included four attention questions, each of which had an obviously correct answer. We excluded respondents who answered more than one of the four questions incorrectly. 404 Political Behavior (2023) 45:395–418 1 3 18 were eligible to participate. Subjects’ median age was 21. Thirteen percent of our respondents were male, and 87% were female. This gender disparity is typical of psychology studies at our institution. We did not find any evidence that it affected the nature of our results: for instance, both men and women rated the female politi- cians as less deceptive. Additionally, because of the specifics of the university in which we conducted our research, most of our respondents identified as Hispanic/ Latinx (72.5%), with White and Black respondents following in almost the same numbers (11 and 12 percent respectively). Asian Americans and others constituted less than 5 percent of our sample. In terms of partisanship, 61% of our respondents were Democrats, 20% Republicans, and 19% Independents. Participants in Sample 2 were 180 people recruited in March 2020 through Ama- zon’s Mechanical Turk Service with a HIT that requested participation in a study to understand how people detect deceptive statements from politicians. They were paid $1 for their time, through Amazon’s MTurk service. Participants were required to be U.S. citizens 18 years of age or older. After clicking on the HIT, they were directed to a copy of the Qualtrics survey used for Sample 1; it had the same questions but included MTurk integration. Subjects’ mean age was 34. Fifty-seven percent of our subjects were male, 42% were female, and 1% chose not to answer. Our respondents were 67% White, 17% Black, 7% Asian, and 7% Hispanic/Latinx; others constituted 2% of our sample. Regarding partisanship, 41% of our respondents were Democrats, 27% Republicans, and 32% Independents. Procedure Upon entering the study, respondents were asked to first complete a brief question- naire gathering information on demographics and political interest. Next, we pre- sented them with a series of brief videos of politicians making statements in vari- ous contexts (e.g., debates, TV interviews); the order of the videos was randomized across participants. For each video, respondents were required to choose whether the politician was being truthful or deceptive. We told them that “in some videos the speaker will be stating something that is true, in others the speaker will be stating something that is not true, i.e., being deceptive. After each video you will be asked if you believe the speaker was being truthful or deceptive.” Though there were thir- teen videos in total, we explained that the first was a “practice round” to get a sense of the task. Data from the practice round are not included in the analysis. After each video, we also asked participants to rate their confidence in their veracity assessment. Finally, we asked if they knew the politician in the video, with three choices: “No”, “Yes”, and “Yes, but don’t remember the name.” Respondents who answered “Yes” were asked the politician’s name as a follow-up. Interestingly, most people who submitted a name were wrong: only 23% were correct. Neverthe- less, we took the precautionary approach of excluding all data from a video when- ever the respondent chose “Yes” or “Yes, but don’t remember the name.” Overall, about 8% of our video-specific data were excluded by this criterion. 405 1 3 Political Behavior (2023) 45:395–418 After watching all the videos, respondents were asked how difficult they per- ceived the task to be overall. Then, we administered a questionnaire asking the extent to which respondents used specific verbal, nonverbal, paraverbal, and gen- eral demeanor cues when assessing the honesty of the politicians. Finally, we asked questions about political attitudes and behavior, such as voting history, party iden- tification, and the trustworthiness of politicians. As we were primarily interested in responses to the videos, we asked these questions post-treatment in order to prevent the latter from priming attitudes that could affect our respondents’ deception detec- tion. For example, we were concerned that respondents, especially those who were well-versed in political issues, might be primed to think about politicians in the vid- eos in partisan terms or to search for partisan cues. Design and Variables The study employed a 2 (statement veracity: truth vs. lie) × 2 (politician gender: male vs. female) within-subjects design, with three video stimuli presented in each of the four cells. As such, all participants viewed 12 videos. For testing H1 (Truth Bias), our dependent variable is the respondent’s binary assessment of whether the speaker was telling the truth (coded 1) or being deceptive (coded 0). Using both full and partial samples, we conduct a series of binomial and proportional tests for significant differences from 50% and significant differences across genders (respondents and candidates). For H2 (Deception Detection Accu- racy), we use a binary dependent variable for the veracity assessments, indicating whether the respondent was correct [1] or incorrect [0]. We conduct a binomial test for a significant difference from 50%. For testing our remaining four hypotheses, we conduct a logistic regression, again using the binary dependent variable indicating whether the respondent was correct [1] or incorrect [0]. We include both video-level, respondent-level, and individual choice-level independent variables. Our individual choice-level variables include the nature of each video assessment (“truthful” [1] or “deceptive” [0]) and respondents’ self-assessed confidence in each of their judgments. Confidence is measured on a scale from 0 to 100. For the videos, we use a binary variable for the politicians’ gender (with female coded 1). The baseline video topic is a politician talking about oneself, and so we include a dummy variable for talking about the opponent and another for talking about (other) facts. We also include a binary variable indicating whether the politi- cian’s party affiliation matched the respondent’s party identification. Our respondent-level variables include gender (binary, with female coded 1), political interest, measured on a 5-point scale from “not interested at all” [1] to “extremely interested” [5] and frequency of political discussion, also measured on a 5-point scale and ranges from “never” [1] to “every day” [5]. Respondents were asked how frequently politicians lie, which is measured on a five-point scale from “never” [1] to “always” [5]. On a 5-point scale, we asked whether, if a candidate tells a lie in a political ad, it would be “very easy” [1] to “very hard” [5] for them 406 Political Behavior (2023) 45:395–418 1 3 to find out. We also assessed respondents’ perceptions of the task difficulty via a 5-point scale from “very easy” [1] to “very difficult” [5]. As mentioned above, we asked respondents about which behavioral cues they had used to make their decisions. We listed fourteen different cues and asked whether each was influential, using a 5-point scale from “not at all influential” to “extremely influential.” We categorized each of the cues as either verbal, nonverbal, paraver- bal, or general demeanor. We then created equal-weighted indices for each category, across both samples, as follows: verbal cues (speech content, amount of detail; Cronbach’s scale reliability in our data was α = 0.64), nonverbal cues (eye move- ments, fidgeting, facial expressions; α = 0.83), paraverbal cues (hesitations, errors, certainty, voice pitch; α = 0.79, and general demeanor cues (calmness, confidence, nervousness, seems guilty, seems to be thinking hard; α = 0.82). The much-lower scale reliability of the verbal category led us to separate the two cues in the regres- sion analysis we report later. Figure 1 below indicates the percentage of respondents, across both samples, indicating that a given cue was very influential (i.e., 4 or 5 on the 5-point scale). Both of our verbal cues—speech content and level of detail—are among the four most-used. Three of the four least-used cues are general demeanor cues—seems guilty, nervousness, and calmness. 5 Note: Error bars represent 95% confidence intervals. 53.74 56.23 56.23 60.11 60.39 60.94 60.94 60.94 62.60 65.37 68.14 68.14 70.08 70.36 0.00 10.0020.00 30.0040.00 50.0060.00 70.0080.00 SPEECH ERRORS GUILTY OR ASHAMED CALMNESS NERVOSITY EYE MOVEMENTS THINKING HARD VOICE PITCH FIDGETING CERTAINTY HESISTATIONS AMOUNT OF DETAIL CONFIDENCE FACIAL EXPRESSIONS SPEECH CONTENT Paraverbal Behavior General Demeanor Verbal Behavior Non-verbal Behavior Fig. 1 Percentage of respondents using specific cues for deception detection. Error bars represent 95% confidence intervals 5 Replication codes and data are available at the Political Behavior Dataverse or at the following address: https:// doi. org/ 10. 7910/ DVN/ ESGRRS. 407 1 3 Political Behavior (2023) 45:395–418 Results Party Affiliation After excluding cases where respondents knew the person speaking in the video, we were left with data for 3812 decisions; going forward, we report our combined results across both samples, as the hypothesis tests and other results were very simi- lar. 6 Because two-thirds of the politicians in the videos were Democrats, we tested whether the truth assessments depended on the party affiliation of the respondent, again across both samples. As mentioned above, we had taken precautions to con- ceal the partisanship of our politicians. For each decision, we created a binary vari- able indicating whether the politician’s party affiliation matched the respondents’ party identification. If respondents were aware of a politician’s party (e.g., based on the content of the statement, participants might infer a party affiliation), they might judge in-party politicians as more honest and out-party politicians as more deceitful. In our data, respondents judged in-party politicians’ statements as truthful 57.0% of the time, and out-party politicians’ statements as truthful 55.0% of the time. This difference in proportions was not statistically significant (z = 1.29, p = 0.197). Thus, we have evidence that the politicians’ party affiliation did not greatly affect respond- ents’ assessments of the politicians’ veracity, likely because the speakers were unfamiliar to the respondents and the issues discussed in the videos were relatively non-partisan. Truth Bias The respondents’ assessments show they believed the speakers were telling the truth 56.0% of the time, supporting H1 (Truth Bias), as this is significantly differ- ent from 50% (binomial, p < 0.001). However, when we separate by the politicians’ gender, we find a truth bias exists only for female politicians (binomial, p < 0.001), who were judged as truthful 60.0% of the time. The difference between this and the assessments of male politicians, who were judged truthful 51.9% of the time, is highly significant (z = 5.06, p < 0.001). Both female (59.3%) and male respondents (61.4%) hold a truth bias for female politicians. 7 Respondents were slightly more confident in their assessments of truth as com- pared to their assessments of lies. The mean confidence level for respondents giving truth assessments was 63.8, as compared to 60.7 for lies, and this difference is sig- nificant (t = 4.17, p < 0.001). Respondents also perceived differences in honesty that depended upon the topic of the video, though these did not reach statistical signifi- cance. Statements the politicians made about themselves were judged truthful 54.1% 6 The one difference is apparent in our logistic regression. The verbal details cue, a significant predictor of accuracy, has the correct sign but does not meet the traditional threshold of significance in either Sam- ple 1 (p = .117) or Sample 2 (p = .058). 7 When judging male speakers, male respondents had a truth bias (57.3%), while female respondents (49.4%) did not. 408 Political Behavior (2023) 45:395–418 1 3 of the time, as compared to statements about the opponent (55.4%) and statements of fact (58.1%; χ2 = 3.77; p = 0.152). Near the end of the study, we asked respond- ents whether politicians lie more often about themselves, their opponents, or facts. Here, 31.6% said politicians lie more about themselves, as compared to opponents (30.8%), facts (29.0%) or something else (8.7%). We find these results to be a little surprising, since we expected a more dubious assessment of negative campaigns. However, our respondents may be correct, at least from a real-world perspective. Geer (2006) explains that in advertisements, politicians do tend to lie about them- selves more than about their opponents; furthermore, negative campaigns often refer to sources, while positive campaigns do not. Deception Detection Accuracy Were the respondents able to detect deception? After excluding data as explained above, the politician was telling the truth 48.9% of the time. 8 Our respondents’ judg- ments were correct 52.4% of the time, which was better than pure chance (bino- mial, p = 0.003).,910 Though this supports H2 (Accuracy), it is difficult to determine whether this conclusively represents an ability to detect politicians’ lies. Instead, it could reflect a trace amount of respondents’ prior knowledge that we were unable to eliminate by controlling for their recognition. Logistic Regression Next, we conducted a multivariate logistic regression with respondents’ accuracy as the dependent variable. We include independent variables measuring the frequency of using verbal, nonverbal, paraverbal, and general demeanor cues. Since respond- ents varied in their confidence for true and false statements, we chose to interact each judgment with the respondent’s confidence in that judgment. Results are shown in Table 1. In our first model, shown in the left-hand column of Table  1, we find no sig- nificant effect for verbal, nonverbal, or paraverbal cue usage. In our second model (right-hand column), we separated the two verbal cues (speech content and amount of detail), primarily because of the low reliability of the resultant verbal scale. We also ran the latter model including an indicator variable for the sample, but it was insignificant (p = 0.423). We focus on the second model in our analysis below. 8 The percentage of truth-telling politicians varied little by the gender of the politician (48.3% for male and 49.4% for female). 9 Separating the videos by topic (self, opponent, or facts), we find that people were most accurate in judging candidates’ statements of fact (58.2% correct) as opposed to candidates’ statements about them- selves (45.5%) or their opponents (52.0%). We include this for descriptive reasons, though we caution against reading much into this, primarily because our sample had only one video in which a candidate was lying about himself. Instead, we will simply use video topic as a control in the upcoming multivari- ate analysis of respondents’ accuracy. 10 For 8 of the 12 videos, the majority of respondents were accurate, though this is not significantly dif- ferent from pure chance (50%). 409 1 3 Political Behavior (2023) 45:395–418 Table 1 Explaining accuracy of respondents’ deception detection (logistic regression) Logit coefficients are shown with standard errors in parentheses, rounded to two decimal places. The standard errors are clustered by the individual respondent *p < 0.10 **p < 0.05 ***p < 0.01 Correct judgment (DV) se Correct judgment (DV) se Verbal cues 0.04 (0.03) –  Level of detail – 0.08** (0.03)  Content of speech – − 0.03 (0.03) General demeanor cues − 0.10** (0.05) − 0.10** (0.05) Nonverbal cues 0.02 (0.04) 0.01 (0.04) Paraverbal cues 0.04 (0.05) 0.03 (0.04) Confidence 0.01*** (0.00) 0.01*** (0.00) Judgment: truth 0.81*** (0.14) 0.81*** (0.14) Judgment × confidence − 0.02*** (0.00) − 0.02*** (0.00) Statement about opponent 0.27*** (0.09) 0.27*** (0.09) Statement about facts 0.54*** (0.10) 0.54*** (0.10) Female respondent 0.03 (0.07) 0.03 (0.07) Female candidate − 0.06 (0.07) − 0.06 (0.07) Party/party ID match 0.03 (0.06) 0.03 (0.06) Discuss politics 0.00 (0.03) 0.01 (0.03) Political interest 0.01 (0.03) 0.00 (0.03) Difficulty of task 0.05* (0.03) 0.05* (0.03) Need others to point out lies − 0.02 (0.03) − 0.01 (0.03) Politicians lie often − 0.04 (0.05) − 0.03 (0.05) Constant − 0.65** (0.29) − 0.62** (0.30) N 3812 3812 Fig. 2 Predictive margins by deceptive/truthful judgment and confidence in judgment 410 Political Behavior (2023) 45:395–418 1 3 We find partial support for H3 (Detection Cues), as one of the verbal cues (the amount of detail) is positively associated with successful lie detection (p = 0.020). On the other hand, speech content has no significant effect. In support of H3, there were no significant effects for paraverbal and nonverbal cues. Finally, increased reli- ance on general demeanor cues (e.g., confidence, nervousness) is related to detec- tion failure (p = 0.032). Regarding H4 (Confidence), we find that confidence, in general, is associated with increased detection accuracy. But we also find that this relationship is more nuanced than our hypothesis predicted, as we find a significant interactive relation- ship between respondents’ judgments (true or false) and their confidence in those judgments. This can be seen in Fig. 2. At the lowest levels of confidence, respond- ents’ judgments of truth are significantly more accurate than their judgments of deceit; the gap is nearly 20 percentage points. However, the relationship changes as respondents become more confident. The accuracy of truth judgments declines with confidence, while the accuracy of deceit judgments climbs with confidence. As a result, at the highest levels of confidence, the relationship is completely reversed: respondents’ judgments of deceit are significantly more accurate than their judg- ments of truth. The respondents’ political interest has no impact on lie detection capability in our study, nor does the frequency of political discussion, which is evidence against H5 (Political Interest). Those who thought the task was harder fare slightly better (p = 0.068). Finally, we do not find that cynicism is an impediment to lie detection, as respondents who believe that politicians lie frequently were just as accurate as respond- ents who were more trusting; thus, we do not find support for H6 (Suboptimal Choice). Discussion In this paper, we improve our understanding of voters’ decision making in situations when politicians might be lying to them, which has important implications for both voters’ candidate preferences and voters’ ability to accurately identify and select honest politicians. In search of a truth bias, we instead find some nuance, in that female politicians are more likely than male politicians to be perceived as telling the truth. Both male and female respondents are more likely to believe the women. Our results comport with previous literature suggesting that female politicians are perceived as more trustworthy than their male counterparts (e.g., Carroll, 1994). Considering that implicit sexism—where women are thought unsuited for political offices because they are too soft, irrational, and incompetent—is all too common among voters (Lawless, 2009; Milyo & Schosberg, 2000; Schaffner et  al., 2018), this gender-based truth bias creates a slight advantage for women, though it is by no means enough to level the playing field. Of course, our sample is not a representative sample of U.S. voters, and our poli- ticians were all from the U.S. Since our results are primarily a descriptive analysis of the judgments of our respondents to the environment in which they were participat- ing, generalizability has some limitations. Amazon’s Mechanical Turk subjects have been found to be more representative of the general population than other commonly 411 1 3 Political Behavior (2023) 45:395–418 used convenience samples, and their responses to stimuli are consistent with extant research (Berinsky, et al., 2012). As expected, we find that people are not very effective at detecting politicians’ lies. However, people who used the amount of detail in the politicians’ statements performed better than those using other types of cues, even though the politicians’ statements we used had little variability in length. This is especially noteworthy because the amount of detail is perhaps the most discriminating and well-studied cue in the deception detection literature (e.g., DePaulo et al., 2003; Luke, 2019), and despite the inherent uniqueness of political settings, it also proved useful in detect- ing lies of politicians. On the other hand, we should not overstate the usefulness of verbal cues, because even though focusing on speech details helps somewhat, the overall lack of effectiveness suggests that voters simply need better cues. Currently, voters need to look elsewhere (i.e., not internally) for help in lie detec- tion. The most credible sources for this type of monitoring are the political fact-check- ers, which as we noted earlier, are a subject of much recent literature. Much of that research focuses on the conditions in which fact-checks can effectively counter misin- formation; less is known about the extent to which voters are interested in seeking out such fact-checks (but see Mattes & Redlawsk, 2020). Most fact-check organizations are affiliated with traditional media, and trust in the media is not exactly robust. Fur- thermore, Cooper (2012) notes that partisans regularly defend their own politicians by questioning the accuracy of the fact-checkers. This turns the accuracy of fact-checks into yet another partisan disagreement; fact-checks that support my candidate are clearly correct, but fact-checks opposing my candidate are false, biased, and partisan. If fact-checking itself is called into question, then voters would be far less interested in and much less likely to be swayed by it. Indeed, in an age of “fake news,” fact-checks usually fail to reach news consumers (Guess et al., 2017). To avoid this, we would sug- gest that fact-checkers who wish to gain credibility and have more impact (as opposed to page views) should focus less attention on polarizing figures such as Donald Trump and place more emphasis on elections with a higher percentage of undecided voters, such as in the early stages of political primaries. This interplay between fact-checking and partisanship is particularly interesting in the context of American politics. Parti- sanship can explain why individuals would reject negative fact-checks on politicians from their own parties, but how do voters decide on the credibility of politicians’ state- ments when partisanship does not provide much of an explanatory ground—such as in primaries, when all politicians are from the same party? The results of our study sug- gest that in such cases voters are better off relying on verbal cues. Perhaps there will eventually be better options. A fairly recent wave of research, which focuses on maximizing the differences between liars’ and truth-tellers’ behaviors, may indeed be the best way to improve deception detection. This research is based in the cognitive approach to lie detection (which can be con- trasted with the more emotional approach, that assumes liars feel anxious and guilty, alluded to earlier). The cognitive approach starts with the fact that lying is more cognitively difficult than telling the truth (Vrij, 2008). While truth-tellers simply have to reflect on their own experiences, memories, and beliefs and report them as they are, liars must attempt to inhibit the truth, create a lie (or remember a prepared lie), keep track of what they said to who and keep their story consistent, 412 Political Behavior (2023) 45:395–418 1 3 engage in impression management, and monitor others’ reactions to their state- ment. Various methods for taking advantage of the differential cognitive load faced by liars and truth-tellers have been proposed and tested with a fair bit of success (Vrij et al., 2017). However, these interventions (e.g., providing a model statement that demonstrates the level of detail that should ideally be provided; requesting a story in reverse chronological order; asking unanticipated questions) require direct access to the target at the time that they provide their statement. As such, there are few contexts in which politicians may be subjected to them. Perhaps it is possible to organize political debates such that politicians are more accountable, but even then, it would only help citizens when elections are imminent. Predominately, citi- zens are left to rely on their intuitive lie detection when evaluating the trustwor- thiness of politicians’ statements, and as we have shown, they are not particularly good at doing so, even when they are not blinded by partisanship. Appendix See Tables 2 and 3 413 1 3 Political Behavior (2023) 45:395–418 Table 2 Video StimuliLinks to the candidate videos and associated fact-checks are provided in Appendix Table 3a Due to his COVID-19 updates, Cuomo had become more well-known nationally when we ran Study 2. As a result, we had to exclude over half of the respondents’ judg-ments about his video, because they had recognized him.PoliticianType of truth/liePIDGenderLength, secTopicTruthKatherine HannawayOpponentRF26The opponent’s main campaign contributor sexually abused a womanBruce RaunerOpponentRM12His opponent supports his views that the state’s workers’ compensation system needs to be reformedKay HaganSelfDF10She was named the most moderate senator in the country by a national non-partisan journalAndrew CuomoaSelfDM12His budget allocates more financial support for religious schools than ever before in the his-toryJerry BrownFactsDM182.1 million jobs were created in the state during the time of his governanceDianne FeinsteinFactsDF1040 million Californians use the same water infrastructure that was built for 16 million peopleLiesTodd YoungOpponentRM10His opponent voted four times to increase taxes on social security benefits and extend the latter to illegal immigrantsShelley AdlerOpponentDF27Her opponent voted to allow insurance companies to deny women’s access to birth control and preventive care, to cut off cancer screening for women, and to re-define rapeDoug JonesOpponentDM11His opponent voted to get the federal government out of health care altogetherKolin Van OsternSelfDM15He cast the deciding vote on extended Medicaid for 50,000 AmericansLoretta SanchezFactsDF21Proposition #57 on gun control lets people out of jail free for gun spread, drive-by shooting, and discharges of guns on school yardsCarly FiorinaFactsRF21A Veteran Affairs reports said that 307,000 veterans died in last year waiting for health care 414 Political Behavior (2023) 45:395–418 1 3Table 3 Links to all videos and fact-checksPoliticianFact-checkTruthKatherine HannawayFact check: https:// www. komu. com/ news/ target- 8- fact- checks- the- gop- guber nator ial- debate/ artic le_ a3155 023- f6bb- 50dd- 9935- e09da 9521e c1. html(NBC/CW + affiliated television station in Missouri)Video: https:// www. youtu be. com/ watch? v=_ 3kCHp xjnHk (30:33–31:20)Cross check: https:// www. kcur. org/ post/ misso uri- gop- conte nders- gover nor- mince- no- words- during- heated- debate (cites NPR) https:// news. stlpu blicr adio. org/ post/ misso uri- conte st- gover nor- roiled- lawsu it- again st- greit ens- donor- alleg ing- sexual- abuse# stream/0 (cites NPR) https:// www. bloom berg. com/ news/ artic les/ 2019- 09- 19/ ventu re- capit alist- defea ts- sex- abuse- suit- after- three- year- fight https:// www. washi ngton post. com/ news/ the- switch/ wp/ 2016/ 03/ 14/ promi nent- silic on- valley- inves tor- denies- he- kept-a- sex- slave- for- 13- years/ https:// themi ssour itimes. com/ 27745/ hanaw ay- quest ions- ties- greit ens- embat tled- ventu re- capit alist/Bruce RaunerFact check and video: https:// www. polit ifact. com/ illin ois/ state ments/ 2016/ oct/ 03/ bruce- rauner/ bruce- rauner- pits- father- again st- daugh ter- illin ois/Kay HaganFact-check: https:// www. wral. com/ fact- check- does- hagan- vote- with- obama- 95- perce nt- of- the- time-/ 13930 106/ https:// www. wral. com/ us- senate- debate- produ ces- some- quest ionab le- claims/ 13948 543/(NBC affiliated television station in North Carolina)Video: https:// www.c- span. org/ video/? 321893- 1/ north- carol ina- senate- debat e& start= 1321 (22:22–22:32)Cross check: https:// www. charl otteo bserv er. com/ news/ polit ics- gover nment/ artic le909 5351. html https:// www. theat lantic. com/ polit ics/ archi ve/ 2014/ 02/ the- most- polar ized- congr ess- ever- 2013- congr essio nal- vote- ratin gs/ 283635/ https:// www. natio naljo urnal. com/s/ 65685/ most- divid ed- congr ess- ever- least- until- next- year? mref= mos_1 https:// ballo tpedia. org/ Natio nal_ Journ al_ vote_ ratin gsAndrew CuomoFact check: https:// www. polit ifact. com/ new- york/ state ments/ 2017/ mar/ 06/ andrew- cuomo/ cuomos- budget- inclu des- more- money- priva te- schoo ls-/Video: https:// www. youtu be. com/ watch?v= 7VMUd Oq0W2E (14:45–14:57) 415 1 3 Political Behavior (2023) 45:395–418 Table 3 (continued)PoliticianFact-checkJerry BrownFact check: https:// www. polit ifact. com/ calif ornia/ state ments/ 2017/ mar/ 29/ jerry- brown/ fact- check ing- jerry- browns- claim- calif ornia- has- cr/Video: https:// www. nbcne ws. com/ meet- the- press/ video/ full- brown- inter view- you- don-t- want- to- mess- with- calif ornia- 90502 35555 99 (01:16–01:36)Dianne FeinsteinFact check and video: https:// www. polit ifact. com/ calif ornia/ state ments/ 2016/ may/ 31/ dianne- feins tein/ does- calif ornia- have- same- water- infra struc ture- it-/LiesTodd YoungFact check and video: https:// www. wthr. com/ artic le/ belie ve- it- or- not- fact- check ing- the- debate- for- us- sen-ate- evan- bayh- todd- young(NBC affiliated television station in Indiana)Archived version: http:// web. archi ve. org/ web/ 20161 10103 5504i f_/ http:// www. wthr. com/ artic le/ belie ve- it- or- not- fact- check ing- the- debate- for- us- senate- evan- bayh- todd- youngCross check: https:// www. wthr. com/ artic le/ belie ve- it- or- not- young- ad- accus es- bayh- of- faili ng- to- prote ct- senio rs https:// www. senate. gov/ legis lative/ LIS/ roll_ call_ lists/ roll_ call_ vote_ cfm. cfm? congr ess= 110& sessi on= 1& vote= 00263Shelley AdlerFact check and video: https:// www. polit ifact. com/ new- jersey/ state ments/ 2012/ oct/ 18/ shell ey- adler/ shell ey- adler- claims- jon- runyan- voted- redefi ne- rap/Doug JonesFact check and video: https:// www. polit ifact. com/ truth-o- meter/ state ments/ 2017/ oct/ 26/ doug- jones/ does- roy- moore- want- end- medic aid- and- medic are- his-/Kolin Van OsternFact check and video: https:// www. polit ifact. com/ new- hamps hire/ state ments/ 2016/ sep/ 08/ colin- van- ostern/ was- colin- van- ostern- decid ing- vote- medic aid- expans/Loretta SanchezFact check and video: https:// www. polit ifact. com/ calif ornia/ state ments/ 2016/ oct/ 07/ loret ta- sanch ez/ loret ta- sanch ez- misle ads- prop- 57- claim/Carly FiorinaFact check: https:// www. washi ngton post. com/ news/ fact- check er/ wp/ 2015/ 09/ 21/ carly- fiori nas- claim- that- 307000- veter ans- died- waiti ng- for- health- care/ https:// www. factc heck. org/ 2015/ 09/ fiori nas- unsup ported- claim- about- va- deaths/Video: https:// www.c- span. org/ video/? 328087- 1/ carly- fiori na- remar ks- chich ester- hamps hire (23:45–24:02) 416 Political Behavior (2023) 45:395–418 1 3 References Adorno, TW. (2005). Minima Moralia: Reflections on a Damaged Life, tran. E. F. N. Jephcott. London: Verso. Armstrong-Taylor, P. (2012). When do politicians lie? The Berkeley Electronic Journal of Economic Analysis & Policy, 13(3), 1–28. Austen-Smith, D. (1992). Strategic models of talk in political decision making. International Political Science Review, 13(1), 45–58. Battigalli, P., Charness, G., & Dufwenbergc, M. (2013). Deception: The role of guilt. Journal of Eco- nomic Behavior & Organization, 93, 227–232. Berinsky, A. J. (2017). Rumors and health care reform: Experiments in political misinformation. British Journal of Political Science, 47(2), 241–262. Berinsky, A. J., Huber, G. A., & Lenz, G. S. (2012). Evaluating online labor markets for experimental research: Amazon.com’s Mechanical Turk. Political Analysis, 20, 351–368. Bond, C. F., Jr., & DePaulo, B. (2006). Accuracy of deception judgments. Personality and Social Psy- chology Review, 10, 214–234. Bucciol, A., & Zarri, L. (2013) Lying in Politics: Evidence from the US. University of Verona Depart- ment of Economics Working Paper Series. Retrieved from http:// leona rdo3. dse. univr. it/ home/ worki ngpap ers/ wp201 3n22. pdf. Callander, S., & Willkie, S. (2007). Lies, damned lies, and political campaigns. Games and Economic Behavior, 60(2), 262–286. Cappella, J. N., & Jamieson, K. (1997). Spiral of Cynicism: The Press and the Public Good. Oxford Uni- versity Press. Carpini, M. X. D., & Keeter, S. (1996). What Americans know about Politics and Why it Matters. Yale University Press. Carroll, S. J. (1994). Women as Candidates in American Politics (2nd ed.). Indiana University Press. Caselli, F., & Morelli, M. (2004). Bad politicians. Journal of Public Economics, 88(3), 759–782. Charness, G., & Dufwenberg, M. (2006). Promises and partnership. Econometrica, 74(6), 1579–1601. Converse, P. E. (1964). The nature of belief systems in mass publics. In D. E. Apter (Ed.), Ideology and discontent. New York: Free Press. Cooper, M. (2012). Campaigns play loose with truth in a fact-check age. The New York Times. Corazzini, L., Kube, S., Maréchal, M. A., & Nicolo, A. (2014). Elections and deceptions: an experi- mental study on the behavioral effects of democracy. American Journal of Political Science, 58(3), 579–592. Cowen, T. (2005). Self-deception as the root of political failure. Public Choice, 124, 437–451. Davis, M. L., & Ferrantino, M. (1996). Towards a positive theory of political rhetoric: Why do politicians lie? Public Choice, 88(1–2), 1–13. DePaulo, B. M., Lindsay, J., Malone, B. E., Muhlenbruck, L., Charlton, K., & Cooper, H. (2003). Cues to deception. Psychological Bulletin, 129, 74–118. Fridkin, K., Kenney, P., & Wintersieck, A. (2015). Liar, liar, pants on fire: How fact-checking influences citizens’ reactions to negative advertising. Political Communication, 32(1), 127–151. Galeotti, A. E. (2015). Liars or self-deceived? Reflections on Political Deception. Political Studies, 63, 887–902. Geer, J. G. (2006). In defense of negativity: Attack ads in presidential campaigns. University of Chicago Press. Glazer, A. (1990). The strategy of candidate ambiguity. American Political Science Review, 84(01), 237–241. Global Deception Research Team. (2006). A world of lies. Journal of Cross-Cultural Psychology, 37, 60–74. Gneezy, U., Rockenbach, B., & Serra-Garcia, M. (2013). Measuring lying aversion. Journal of Economic Behavior & Organization, 93, 293–300. Gneezy, U. (2005). Deception: The role of consequences. The American Economic Review, 95(1), 384–394. Guess, A., Nyhan, B., & Reifler, J. (2017). Selective exposure to misinformation: Evidence from the consumption of fake news during the 2016 US presidential campaign. European Research Council. Retrieved from http:// www. dartm outh. edu/ ~nyhan/ fake- news- 2016. pdf 417 1 3 Political Behavior (2023) 45:395–418 Hartwig, M., & Bond, C. F., Jr. (2011). Why do lie-catchers fail? A lens model meta-analysis of human lie judgments. Psychological Bulletin, 137(4), 643–659. https:// doi. org/ 10. 1037/ a0023 589 Hartwig, M., & Granhag, P. A. (2015). Exploring the nature and origin of beliefs about deception: Implicit and explicit knowledge among lay people and resumed experts. In P. A. Granhag, A. Vrij, & B. Verschuere (Eds.), Detecting Deception: current challenges and cognitive approaches. Wiley. Houser, D., Ludwig, S., & Stratmann, T. (2016). Deception and political participation: Theory and labo- ratory evidence. Economic Inquiry, 54(1), 464–484. Janezic, K. A., & Gallego, A. (2020). Eliciting preferences for truth-telling in a survey of politicians. Pro- ceedings of the National Academy of Sciences. https:// doi. org/ 10. 1073/ pnas. 20081 44117 Jordan, S., Laure Brimbal, D., Wallace, B., Kassin, S. M., Hartwig, M., & Street, C. N. H. (2019). A test of the micro-expressions training tool: Does it improve lie detection? Journal of Investigative Psy- chology and Offender Profiling, 16(3), 222–235. Kartik, N. (2009). Strategic communication with lying costs. The Review of Economic Studies, 76(4), 1359–1395. Kartik, N., & Van Weelden, R. (2019). Informative cheap talk in elections. The Review of Economic Stud- ies, 86(2), 755–784. https:// doi. org/ 10. 1093/ restud/ rdy009. Lawless, J. L. (2009). Sexism and gender bias in election 2008: A more complex path for women in poli- tics. Politics & Gender, 5(1), 70–80. Luke, T. (2019). Lessons from Pinocchio: Cues to deception may be highly exaggerated. Perspectives on Psychological Science, 14, 646–671. Mattes, K., & Redlawsk, D. P. (2014). The positive case for negative campaigning. The University of Chicago Press. Mattes, K., & Redlawsk, D. P. (2020). Voluntary exposure to political fact-checks. Journalism and Mass Communication Quarterly, 97(4), 919–935. Meissner, C. A., & Kassin, S. M. (2002). “He’s guilty!”: Investigator bias in judgments of truth and deception. Law and Human Behavior, 26(5), 469–480. Milyo, J., & Schosberg, S. (2000). Gender bias and selection bias in House elections. Public Choice, 105(1–2), 41–59. Minozzi, W. (2011). A Jamming Theory of Politics. The Journal of Politics, 73(2), 301–315. Minozzi, W., & Woon, J. (2016). Competition, preference uncertainty, and jamming: A strategic commu- nication experiment. Games and Economic Behavior, 96, 97–114. Pfiffner, J. P. (1999). The contemporary presidency: presidential lies. Presidential Studies Quarterly, 29(4), 903–917. Plato. (1901). The Republic tran. Benjamin Jowett. New York: Wiley. Reinhard, M. A., Scharmach, M., & Sporer, S. L. (2012). Situational familiarity, efficacy expectations, and the process of credibility attribution. Basic and Applied Social Psychology, 34(2), 107–127. Reinhard, M. A., Sporer, S. L., Scharmach, M., & Marksteiner, T. (2011). Listening, Not Watching: Situ- ational Familiarity and the Ability to Detect Deception. Journal of Personality and Social Psychol- ogy., 101(3), 467–484. Rossini, N., et al. (2011). Deception cues in political speeches verbal and non-verbal traits of prevarica- tion. In A. Esposito (Ed.), Communication and Enactment 2010, LNCS 6800 (pp. 406–418). Berlin: Springer. Schaffner, B. F., MacWilliams, M., & Nteta, T. (2018). Understanding White Polarization in the 2016 vote for president: The sobering role of racism and sexism. Political Science Quarterly, 133(1), 9–34. Schnakenberg, K. E. (2016). Directional cheap talk in electoral campaigns. The Journal of Politics, 78(2), 527–541. Semmler, C., Brewer, N., & Douglass, A. B. (2012). Jurors believe eyewitnesses. In B. L. Cutler (Ed.), Conviction of the innocent: Lessons from psychological research; conviction of the innocent: Les- sons from psychological research (pp. 185–209). Washington: American Psychological Association. https:// doi. org/ 10. 1037/ 13085- 009 Chapter xiv, p. 370. Stiff, J. B., Miller, G. R., Sleight, C., Mongeau, P., Garlick, R., & Rogan, R. (1989). Explanations for visual cue primacy in judgments of honesty and deceit. Journal of Personality and Social Psychol- ogy, 56, 555–564. Tenney, E. R., Small, J. E., Kondrad, R. L., Jaswal, V. K., & Spellman, B. A. (2011). Accuracy, confi- dence, and calibration: How young children and adults assess credibility. Developmental Psychol- ogy, 47(4), 1065–1077. 418 Political Behavior (2023) 45:395–418 1 3 Tomz, M., & Van Houweling, R. P. (2009). The electoral implications of candidate ambiguity. American Political Science Review, 103(1), 83–98. Vrij, A. (2008). Detecting lies and deceit: Pitfalls and opportunities (2nd ed.). New York: Wiley. Vrij, A. (2019). Deception and truth detection when analyzing nonverbal and verbal cues. Applied Cogni- tive Psychology, 33, 160–167. Vrij, A., Edward, K., & Bull, R. (2001). Police officers’ ability to detect deceit: The benefit of indirect deception detection measures. Legal and Criminological Psychology, 6(2), 185–196. Vrij, A., Fisher, R. P., & Blank, H. (2017). A cognitive approach to lie detection: A meta-analysis. Legal and Criminological Psychology, 22(1), 1–21. Woon, J. (2017) Political Lie Detection. Paper prepared for the 2017 Toronto Political Behavior Work- shop. Retrieved from https:// sites. pitt. edu/ ~woon/ papers/ woon_ liede tecti on. pdf. Woon, J., & Kanthak, K. (2019). Elections, Ability, and Candidate Honesty. Journal of Economic Behav- ior and Organization, 157, 735–753. Zaller, J. (1992). The nature and origins of mass opinion. Cambridge University Press. Publisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.","libVersion":"0.3.2","langs":""}