{"path":"lit/lit_notes_OLD_PARTIAL/Nivarthi22UnifiedAutoencoderTask.pdf","text":"See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/369486218 Uniﬁed Autoencoder with Task Embeddings for Multi-Task Learning in Renewable Power Forecasting Conference Paper · December 2022 DOI: 10.1109/ICML A55696.2022.00240 CITATIONS 0 READS 5 3 author s, including: Some of the authors of this publication are also working on these related projects: Smart Energy Showcase - Digital Agenda for the Energy Transition (SINTEG) View project Collaborative Interactive Learning View project Chandana Priya Nivarthi Universität Kassel 6 PUBLICATIONS   3 CITATIONS    SEE PROFILE Bernhard Sick Universität Kassel 275 PUBLICATIONS   3,346 CITATIONS    SEE PROFILE All content following this page was uploaded by Chandana Priya Nivarthi on 17 April 2023. The user has requested enhancement of the downloaded file. Unified Autoencoder with Task Embeddings for Multi-Task Learning in Renewable Power Forecasting Chandana Priya Nivarthi, Stephan Vogt, Bernhard Sick University of Kassel Germany {chandana.nivarthi, stephan.vogt, bsick}@uni-kassel.de Abstract—Renewable power generation forecasts using machine learning are typically implemented as single-task learning models, where a separate model is trained for each photovoltaic or wind park. In recent years, transfer learning is gaining popularity in these systems, as it can be used to transfer the knowledge gained from source parks to a target park. However, for transferring the knowledge to a target park, there is a need to determine the most similar source park(s) among the existing parks. This similarity determination using historical power measurements is challenging when the target park has limited to no historical data samples. Therefore, we propose a simple multi-task learning architecture that initially learns a common representation of input weather features among the tasks, using a Unified Autoencoder (UAE) and then learns the task specific information utilizing a Task Embedding layer in a Neural Network (TENN). This proposed architecture, UAE-TENN, can be easily extended to new parks with or without historical data. An elaborate performance comparison of single and multi-task learning models is performed on six photovoltaic and wind farm datasets comprising a total of 529 parks. UAE-TENN significantly improves the performance of power forecasting by 10 to 19% for photovoltaic parks and 5 to 22% for wind parks compared to the baseline models. Even in the zero-shot learning scenario, when there is no historical data, we successfully demonstrate that the UAE-TENN improves the forecast accuracy for a new park by 19% for photovoltaic parks. I. INTRODUCTION The alarming rise in global surface temperatures calls for an urgent shift towards renewable sources for power generation. According to the 2021 global road map for Sustainable Devel- opment Goal (SDG) 7, i.e., affordable and clean energy, and the Paris agreement on climate change, there is a need to triple the global renewable power capacity by 2030 and reach net zero emissions by 2050 [1]. This increase in capacity also requires an improvement in the accuracy of renewable power forecasting. A reliable power forecast is essential to reduce operational costs and improve the power grid’s safety and maintenance. The day-ahead power forecast models in renewable energy usually consider Numerical Weather Prediction (NWP) data between 24 and 49 hours into the future as inputs. The weather features such as solar radiation and wind speed are crucial inputs for generating a day-ahead power generation prediction for photovoltaic (PV) and wind parks, respectively. Various models such as physical, statistical, and machine learning techniques have been developed to increase the forecast accuracy. There is also growing research on using deep learning methods for power forecast in recent past years [2]. Most of the models aim to improve the forecast accuracy of individual PV or wind parks by learning the typical characteristics of individual parks, i.e., a single model is trained for each park separately, which is termed as single-task learning (STL). However, a lot of computational power, effort, and time are needed to develop such models with the growing number of PV and wind parks. Training such a huge number of models causes substantial carbon footprint [3], which contradicts the purpose of using renewable energy systems in the first place. To address this challenge, Transfer Learning (TL) and Multi- task Learning (MTL) approaches offer possible solutions by utilizing the relationship among different renewable energy parks and transfer the existing knowledge between them and thereby reduce the carbon footprint. TL, especially inductive transfer from source parks to target parks, is beneficial when the target park has sufficient historical data to re-train the model and generate a power prediction [4]. However, there will be cases when the target parks have limited to no historical data. In such cases, MTL is helpful for making a power prediction. MTL aims to learn multiple tasks together so that knowledge contained in a task can be leveraged by other tasks [5]. There are two primary aspects of any MTL method - One is to learn the task independent common information, and the second is to learn the task dependent specific information. Autoencoders (AE) are proven useful for learning a common representation of multiple tasks [6]. Task embeddings are recently being used to encode the task specific information in MTL applications [7]. In this article, we propose an MTL method which combines Unified Autoencoder (UAE) and Task Embedding in a Neural Network (TENN) architecture. UAE refers to training an autoencoder on unified data of all tasks, to learn the task independent common information and TENN utilizes an embedding layer in neural network for encoding task id information. We aim to evaluate this proposed architecture, Unified Autoencoder- Task Embedding Neural Network (UAE-TENN) by comparing it with different STL and MTL methods. As this MTL method learns the representation of existing parks, we are interested in evaluating its performance in power forecasting for a new park, in the Zero-Shot Learning (ZSL) setting. This evaluation is essential, as we need reliable power forecasts for new parks which do not yet have any historical data, to ease the operational 1530 2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA) 978-1-6654-6283-9/22/$31.00 ©2022 IEEE DOI 10.1109/ICMLA55696.2022.002402022 21st IEEE International Conference on Machine Learning and Applications (ICMLA) | 978-1-6654-6283-9/22/$31.00 ©2022 IEEE | DOI: 10.1109/ICMLA55696.2022.00240 Authorized licensed use limited to: University Kassel. Downloaded on April 17,2023 at 19:13:08 UTC from IEEE Xplore. Restrictions apply. Fig. 1: Schematic overview of the proposed UAE-TENN archi- tecture. The green color elements correspond to tasks feature data, blue represents trainable layers of neural network, yellow for task specific embedding layer and white represents non- trainable layers. planning. This article attempts to answer the following research ques- tions Question 1: Does unified encoding of task independent fea- tures along with task embeddings decrease the forecast error for PV and wind parks compared to STL methods? Question 2: Can autoencoder based MTL architecture with TE perform better than using either UAE or TE in MTL architecture? Question 3: Are autoencoder based MTL architectures with TE capable of providing better forecasts in ZSL scenario for renewable power forecasts compared to the baseline model? The experimental evaluation of proposed architecture UAE- TENN, leads to the following contributions: • A simple MTL architecture, UAE-TENN is proposed which performs significantly better than STL and MTL baseline models. • We contribute to the early research of ZSL for renewable energy systems, by demonstrating that UAE-TENN per- forms significantly better than baseline in ZSL setting. • An extensive experimental evaluation on six PV and wind datasets covering a total of 529 parks is provided. • An ablation study of UAE and TE components is per- formed. It shows that ablation of either of these compo- nents decreased the performance and the component TE is contributing more to the performance improvement than UAE in UAE-TENN. • The proposed architecture can be easily extended to other domain applications. The remainder of this article is structured as follows. Sec- tion II describes related work and Section III introduces the proposed method. The data sets, experimental evaluation, and findings are described in Section IV followed by conclusion and outlook for future research in Section V. II. RELATED WORK To answer our research questions, we review related work in the field of STL, MTL, ZSL and their applications primarily focusing on renewable energy power forecasts. Typically, for renewable power forecasts, historical NWP data with weather related features is used as input and the corresponding power measurements of a park is considered as the target feature. Comprehensive surveys on TL [8], MTL [5] discuss various details on general concepts of TL and MTL respectively. Recent review [2] highlights the increased publication rate of deep learning architectures in renewable power forecasting. It also points out that AEs are under utilized for the same purpose. However, AEs have been extensively used in the literature on images and text data applications for classification tasks. AEs are proven to be versatile for representation learning in different applications [9]. The authors of [10], [11] propose AEs for TL and MTL applications on image datasets for classification tasks and [12] use AEs for learning sentence representations on unsupervised texts. It has been observed that AEs have not been much explored for regression tasks in general and also in the field of renewable energy systems. There are few works [13], [14], which propose the use of AEs for inductive transfer learning application to wind power forecasting. In [15], authors compare different deep learning algorithms in STL setting for solar power forecasting and evaluates the usage of AEs in a hybrid model for STL. However, they do not discuss about their application to MTL and ZSL and more over, none of them utilize a unified AE for representation learning in MTL tasks. For learning the task specific attributes in MTL, usually hard parameter sharing (HPS) architecture is utilized, where each task has one or more task-specific final layers in the architecture. However, such HPS architecture is difficult to extend to new parks when they are not closely related [16]. Embeddings have become more popular for representing categorical entities such as words, in language model applications [17] and a more general application of embeddings to different entity categories is given in [18]. Using such embeddings as Task Embeddings (TE) for learning the task specific features has been utilized in [7] for TL and a Bayesian variant of TE has been proposed in [19]. Although, AEs and TE are explored for renewable energy applications separately, this article attempts to highlight the effectiveness of their combination. There is also very limited research in ZSL [4] for renewable energy applications. More- over, to the best of our knowledge, there has been no research that compares STL, MTL methods for six datasets comprising of 529 PV and wind parks in total. III. PROPOSED METHOD In this section, we introduce the relevant definitions of STL, MTL and ZSL methods and then describe our proposed architecture. 1531 Authorized licensed use limited to: University Kassel. Downloaded on April 17,2023 at 19:13:08 UTC from IEEE Xplore. Restrictions apply. Fig. 2: The inference procedure using proposed UAE-TENN architecture for a task m. A. Definitions of STL, MTL and ZSL The general definition of MTL has been introduced in [5] and we adapted it to other definitions for consistent formulation, similar to the terminology in [4]. A domain is defined by D = {X , P (X)}, where X is the feature space and P (X) is the corresponding marginal distribution with X = {x | xi ∈ X , i = 1, . . . , N }. Given a specific domain, a task consists of a label space Y and a conditional probability distribution P (Y |X) and is represented as T = {Y, P (Y |X)}, where P (Y |X) is learned from the training instances (xi, yi) with xi ∈ X and yi ∈ Y, where Y = {y | yi ∈ Y, i = 1, . . . , N }. Here, xi denotes the NWP data as input features and yi denotes the historical power measurements of a park as the target feature. 1) Single-Task Learning: Given M tasks, each task T is learned separately on the specific training data (x m i , ym i ), where m ∈ {1, . . . , M }, i ∈ {1, . . . , N } and M ∈ N + tasks. 2) Multi-Task Learning: Given M tasks, when all tasks or a subset of them are related, MTL aims to learn all M tasks together improving the performance of each task, using the knowledge gained from other tasks. In MTL approaches, the domain Dm of each task has training instances (x m i , ym i ), i ∈ {1, . . . , N } where xm i ∈ X m, ym i ∈ Y m, m ∈ {1, . . . , M }, and M ∈ N + tasks. Here, typically a single model is built using training data from multiple tasks. 3) Zero-Shot Learning: Given a new task, which does not have any training data instances (x m i , ym i ), the metadata of such a task is used to select the prediction function f (·) from the already trained similar tasks models to do a prediction. In contrast to the typical inductive TL approach, where source task model is fine-tuned for target task on target data, ZSL task does not have any input or output data at target task, making the problem more challenging. B. Unified Autoencoder - Task Embedding Neural Network In MTL architectures using neural networks, typically there are two popular approaches, one is Hard Parameter Sharing (HPS) and the other is Soft-Paramter Sharing (SPS) of hidden layers [16]. In HPS architectures, there will be common task independent layers for all tasks and separate task-specific layers, where as in SPS, instead of sharing exact parameters among tasks, a constraint is introduced to penalize the distance between different tasks parameters. The principle behind both these popular approaches is same, which is learning common features of all tasks and learning task-specific features for performing MTL. Following the same idea, we propose an architecture of using a UAE in combination with a neural network comprising of TE layer, for MTL in renewable power forecasting. The UAE learns task independent shared representation, while the TE layer in a neural network learns task specific information. In this section we detail the two components, then discuss about the training and inference procedure. 1) Unified Autoencoder (UAE): Autoencoders aim to learn the latent representation of input by reconstructing it. We use UAE to learn the latent representation of input features from all PV or wind parks of a dataset as shown in Fig 1. In the context of MTL, an AE unifies the feature representation from all the training tasks, hence the name Unified Autoencoder (UAE). The AE network can be viewed as the composition of an encoding function fθ which projects inputs onto a latent space, and a decoding function hθ, which reconstructs the original in- put using the latent space representation. The objective function of AE is to minimize distance between the original input and the reconstructed input, as mentioned in Eq. (1). In this equation, X represents unified data of all tasks i.e., the concatenation of input features X m for m ∈ {1, . . . , M } and d is the mean squared error between input and reconstructed input and θ represents full set of parameters of an AE [9]. min θ ∑ d (X, hθ(fθ(X))) (1) 2) Task Embedding Neural Network (TENN): An embedding allows the mapping of discrete categorical values to a vector of continuous values. The embeddings such as word2vec are popular in NLP domain [17] and the usage of embeddings for representing general categories in vector representation is given in [18]. In neural networks, an embedding layer learns low dimensional, continuous vector representations of discrete vari- ables compared to possibly high dimensional one hot encodings of the same categories. Another advantage, compared to one-hot encoding in inductive TL scenario is that it is relatively easy to add more tasks to the network, by adding a new embedding vector for the new task. Here, we use such an embedding layer on different discrete task indices to map them to a task specific vector representation. This embedding layer maps each task index m to a vector representation as shown in the bottom portion of Fig 1. We refer to such a neural network architecture trained along with a task embedding layer as TENN. a) Mathematical representation of task embeddings: The mathematical representation of such an entity embedding layer is given by [18] which is adapted to task embeddings g(m) in [4] as follows: g(m) = M∑ α=1 wαβδmα = wmβ, (2) 1532 Authorized licensed use limited to: University Kassel. Downloaded on April 17,2023 at 19:13:08 UTC from IEEE Xplore. Restrictions apply. where wαβ is the learnable weight matrix and δmα is a Kronecker delta function, which is 1 if the values are equal and 0 otherwise. δmα = { 1, if m = α, 0, if m ̸= α. (3) Here δmα represents a vector of length M for M tasks, where only the entry with α = m is non-zero, like a one-hot encoding vector and where wαβ is a weight matrix of all task embeddings, thus function g(m) maps discrete value of a task index into a continuous real-valued vector. b) Practical interpretation of task embeddings: The TE layer can also be interpreted as a look-up table with vector values for each of the task indices. The elements of these vectors are the weights that are learned during neural network training. Consider, a two dimensional TE vector for each of the M tasks, thus making the TE look up table of M × 2 dimensions. For each training instance, depending on the task index of that instance, corresponding row from the look-up table is selected and concatenated with other input features of that instance. The TE for task m can be inferred as the dot product of one-hot encoding vector of tasks and the embeddings lookup table. For a task m, the mth row of look-up table i.e., [wm1, wm2] is the embedding vector. g(m) = [ 0, 0, · · · , 1, · · · , 0 ]           w11, w12 w21, w22 ... wm1, wm2 ... wM 1, wM 2           = [ wm1, wm2] C. Training UAE-TENN We consider the simplest architecture of UAE, by using one hidden encoding layer to learn the encoded representation of all tasks’ input features. The UAE is trained on NWP input features of all tasks i.e., on X. The encoder fθ, thus has learned a common representation of weather across all parks. An encoder encodes X consisting of k input features to fθ(X), which is a low-dimensional latent representation. The architecture of UAE is considered same for all datasets and trained with ReLU activation function and Adam optimizer. The other hyperparameters such as number of epochs, and batch size are tuned and the encoding dimension hyperparameter values are selected such that, the dimensionality of input k features is reduced to around k/2 dimensions for each dataset. In the next step, a TENN is trained on encoded inputs fθ(X) along with task specific information g(m) from TE layer as shown in Fig 1. An MTL function for all M tasks learns from training instances (xm i , ym i , g(m)) where m ∈ {1, . . . , M } tasks, xm i ∈ X, ym i ∈ Y. The TENN is trained jointly on multiple tasks, where training instances of multiple tasks are present in each batch. This leads to learning embedding vectors such that similar tasks have similar vectors. The learned TE can also be utilized for similarity determination among the tasks. For a reasonable comparison across datasets, the architecture of TENN is considered same for all experiments with six hidden layers, Leaky ReLU activation, Adam optimizer and a two- dimensional embedding vector. The other hyperparameters such as batch size and number of epochs are tuned and the details are provided in supplementary material. D. Inference UAE-TENN After training UAE-TENN, we derive inferences for each task separately, such that the results can be compared with STL approaches. During inference, as shown in Fig 2, the encoded task inputs fθ(x m i ) and respective TE vectors g(m) are concatenated and passed as input to TENN, to get the task specific power prediction ˆym i . IV. EXPERIMENTAL EVALUATION This section describes the datasets, experimental setup and evaluates the experiments to answer following research ques- tions. We conduct experiments to answer research questions by evaluating them on the datasets described in Sec. IV-A. The evaluation measures used for these experiments are detailed in Sec. IV-B. The experimental setup and findings for three experiments are described respectively in Sec. IV-C, Sec. IV-D, and Sec. IV-E. A. Datasets The experiments are conducted on six renewable energy power forecasting datasets with three pairs of PV and wind datasets from opensource, synthetic and real-world data sources. Typically any PV or wind park can have three types of data sources - NWP data, historical power generation data and meta- data [20]. The input features are NWP features for all datasets and target is day-ahead power generation. In synthetic and real- world data sources we additionally have metadata available for each park, which represents the physical characteristics of a park such as geographical locations, physical features such as tilt and azimuth angles of PV panels, turbine type, hub height, and rotor diameter, etc. for wind parks. The NWP data for PV parks comprises of features such as solar direct radiation, solar diffuse radiation, temperature, humidity, solar position, etc. and for wind parks, features such as wind speed, wind direction, air pressure, temperature, humidity, etc. The PV Open (PO) and Wind Open (WO) datasets have data corresponding to 21 and 45 parks respectively. The PV Synthetic (PS) dataset has 118 parks and to maintain the consistency, same number of parks are randomly chosen from Wind Synthetic (WS) data of 263 parks. The indices of considered parks are provided in supplementary material. The PV Real (PR) and Wind Real (WR) datasets have data corresponding to 42 and 185 parks respectively. 1533 Authorized licensed use limited to: University Kassel. Downloaded on April 17,2023 at 19:13:08 UTC from IEEE Xplore. Restrictions apply. In all datasets, 80/20 percentage split has been made into source parks and target zero-shot parks respectively. The source parks of all datasets are considered for STL and MTL experi- ments, where as the target zero-shot parks are used only for ZSL experiment evaluation. In synthetic dataset pair, PS and WS, a test flag is provided to determine the test data. For both open (PO, WO) and real dataset pairs (PR, WR), it has been observed that not all the source parks have equal amount of historical data, hence we considered a 75/25 percentage split in the historical data of each park for training and testing. The training data time span covers all the seasons such that the distribution changes in weather features are learnt by representation learning in UAE. B. Evaluation Measures In all experiments, we compare the performance measures of the proposed UAE-TENN with baseline models considered for respective experiments. The primary metric considered for evaluation is Root-Mean-Squared Error (RMSE) of each method for a park denoted by RMSEm as in below Eq. (4), where ym i , ˆym i refer to actual and predicted power generation values for park m with N data samples. The average RMSE of M parks for a dataset denoted by aRMSE as in Eq. (5). RMSEm = √ √ √ √ 1 N N∑ i=1 (ym i − ˆym i )2 (4) aRMSE = 1 M M∑ m=1 RMSEm (5) A Skillm metric for each park is calculated to compare the performance improvement from baseline model and the mean skill of all parks in a dataset is termed as Skill, as mentioned in Eq. (7). The skill values in results tables can be interpreted as percentage performance improvement compared to the baseline model. For example, Skill of 0.245 in Table I can be interpreted as 24.50% average performance improvement of UAE-TENN compared to the baseline model in a particular dataset PO. Skillm = 1 − ( RMSEreferencem RMSEbaselinem ) (6) Skill = 1 M M∑ m=1 Skillm (7) We also present standard deviation (Std) of RMSE values of all datasets in results tables. For aRMSE and std metrics, lower value indicates better performance and for skill metric, a higher value indicates better performance. The statistical significance between a reference model and the baseline is tested using wilcoxon one-sided signed rank test (with α = 0.05) [21]. It is indicated by an asterisk symbol (*) if reference model is significantly better than baseline in a dataset. C. Comparison with STL methods In this section, we conduct an experiment to answer the research question 1, by comparing the proposed method with STL methods. In this experiment, we consider five types of single task models - Physical (PHY), Linear Regression (LR), Gradient Boosting Regression Tree (GBRT), Neural Network (NN) and Autoencoder-Neural Network (AE-NN) for comparison. The PHY model generates power forecast for a PV or wind park based on the physical characteristics and the power curve of respective parks and does not depend on the historical data [22]. The physical model prediction is provided in the synthetic and real datasets but not in open source datasets. The STL models are hyperparameter optimized using grid search and the details are provided in supplementary material. These STL models are selected such that, each of the different modeling techniques like statistical modeling, tree-based methods and neural networks are represented for comparison. A NN model is a simple feed forward multi-layer neural network architecture. An AE-NN model represents training an AE on each park separately and then training a NN on the encoded lower dimensional inputs. An AE-NN model is considered here to evaluate if single task representation learning improves the performance compared to other STL models and the same is considered as baseline model for comparison. All STL methods are compared with proposed method UAE-TENN, evaluated on each task separately. To get an initial idea on how parks are related to each other in a dataset, we estimate the standard deviation of unified target data of all parks in each dataset separately. The standard deviation values for PO, WO, PS, WS, PR, WR datasets are 0.225, 0.242, 0.198, 0.256, 0.227, 0.244 respectively. This evaluation implies intrinsically the wind datasets have more variance in the power generation of parks compared to the PV datasets. Table I highlights the evaluation results of STL models with proposed UAE-TENN method for all datasets separately. It can be observed that proposed method achieves lowest aRMSE and performs significantly better in all PV datasets. Among wind datasets, the lowest aRMSE is achieved only in WR dataset, this is due to the intrinsic lesser similarity among wind parks compared to solar parks as mentioned before. The Skill metric shows on an average, the proposed method improves the performance by 19.5 % for PV parks and 5.7 % for wind parks respectively. The skill score is positive for all PV datasets and for two out of three wind datasets. The negative skill score for all methods in WS dataset indicates representation learning through AE-NN baseline in STL setting is performing better than other methods. It can be also observed that on an average the std values are lower for PV datasets compared to wind. The higher aRMSE values and negative skill scores for AE-NN, LR and NN methods in WR dataset is due to the presence of outliers and it is also evident from the corresponding higher std values of these methods in WR. 1534 Authorized licensed use limited to: University Kassel. Downloaded on April 17,2023 at 19:13:08 UTC from IEEE Xplore. Restrictions apply. TABLE I: Evaluation results of STL methods with UAE-TENN for six different datasets. The asterisk (*) symbol indicates significantly different aRMSE values of reference than baseline (AE-NN) tested through one-sided wilcoxon signed-rank test with α = 0.05. The bold values in a column indicates best performance. Model Type PV aRMSE Wind aRMSE PV Skill Wind Skill PV Std Wind Std PO PS PR WO WS WR PO PS PR WO WS WR PO PS PR WO WS WR AE-NN 0.112 0.094* 0.124 0.132 0.141 6.124 0.000 0.000 0.000 0.000 0.000 0.000 0.022 0.015 0.019 0.040 0.054 65.143 PHY NA 0.102 0.189 NA 0.255 0.201 NA -0.084 -0.587 NA -1.259 -0.181 NA 0.016 0.199 NA 0.095 0.069 LR 0.088* 0.104 0.116* 0.123 0.156 1.515* 0.218 -0.096 0.064 0.042 -0.355 -0.007 0.022 0.019 0.019 0.031 0.047 10.234 GBRT 0.085* 0.092 0.109* 0.112* 0.144 0.158* 0.239 0.023 0.120 0.133 -0.235 0.088 0.021 0.014 0.019 0.032 0.041 0.043 NN 0.087* 0.092* 0.112* 0.110* 0.137* 2.598* 0.221 0.021 0.094 0.145 -0.041 -0.037 0.023 0.013 0.020 0.031 0.039 18.377 UAE-TENN 0.084* 0.083* 0.095* 0.117* 0.142 0.142* 0.245 0.118 0.222 0.096 -0.078 0.153 0.020 0.013 0.011 0.032 0.041 0.029 Mean UAE-TENN 0.087 0.133 0.195 0.057 0.014 0.034 TABLE II: Evaluation results of MTL methods with UAE-TENN for six datasets with baseline UAE-NN as baseline model. Model Type PV aRMSE Wind aRMSE PV Skill Wind Skill PV Std Wind Std PO PS PR WO WS WR PO PS PR WO WS WR PO PS PR WO WS WR UAE-NN 0.088 0.107 0.105 0.156 0.199 0.175 0.000 0.000 0.000 0.000 0.000 0.000 0.024 0.021 0.020 0.036 0.083 0.045 TE-NN 0.087 0.091* 0.096* 0.115* 0.146* 0.148* -0.006 0.136 0.080 0.267 0.218 0.140 0.020 0.015 0.014 0.031 0.040 0.030 UAE-TENN 0.084* 0.083* 0.095* 0.117* 0.142* 0.142* 0.029 0.209 0.087 0.253 0.240 0.173 0.020 0.013 0.011 0.032 0.041 0.029 Mean UAE-TENN 0.087 0.133 0.108 0.222 0.014 0.034 TABLE III: Evaluation results of ZSL methods with UAE-TENN for four datasets with PHY as baseline model. Model Type PV aRMSE Wind aRMSE PV skill Wind skill PV Std Wind Std PS PR WS WR PS PR WS WR PS PR WS WR PHY 0.102 0.181 0.212 0.187 0.000 0.000 0.000 0.000 0.018 0.156 0.047 0.061 UAE-NN 0.103 0.104 0.213* 0.172* -0.009 0.226 -0.076 0.049 0.026 0.017 0.138 0.039 UAE-TENN 0.088* 0.101* 0.220 0.180 0.145 0.247 -0.110 -0.020 0.024 0.016 0.159 0.042 Mean UAE-TENN 0.094 0.200 0.196 -0.065 0.020 0.100 D. Comparison with MTL methods In this section, we conduct an experiment to answer the research question 2, by comparing proposed method with other related MTL methods of using either UAE or TE alone in a network. The first MTL method is UAE-NN in which, encoded inputs of multiple tasks are passed to a neural network and a single model is trained for all of the source tasks. The second is TE-NN method in which task embeddings are concatenated to the original inputs of respective tasks and a neural network is trained. The training and inference of UAE-NN and TE- NN architectures are similar to the UAE-TENN procedure. The UAE-NN architecture does not include TE component and TE- NN architecture does not include UAE component. Therefore, this experiment can also be considered as an ablation study of two components UAE and TE in the proposed UAE-TENN architecture. In this experiment, UAE-NN is considered as the baseline model for comparison. Table II highlights the proposed UAE-TENN is perform- ing significantly better than baseline UAE-NN in all datasets indicated by a positive skill value and also records highest skill in five out of six datasets. The proposed UAE-TENN is performing on an average about 10.80% and 22.1% better than baseline for PV and wind datasets respectively. From the ablation study perspective, it can be inferred that component TE is contributing more to the performance improvement than UAE as the aRMSE values are consistenly lower in TE-NN compared to UAE-NN across all PV and wind datasets. It can also be interpreted as component TE is contributing more to the performance improvement than UAE in proposed method and using them together as a combination is better than using either of these components in an architecture. E. Zero-Shot Learning Experiment In this section, we conduct an experiment to answer the research question 3, by evaluating the performance of proposed method in ZSL experimental setup. Typically, in ZSL scenario, as the target task historical data is not available, metadata of parks is utilized for making a prediction. The metadata generally consists of geographical location of park, tilt angle, azimuth angle, elevation, etc. for PV parks and hub height, diameter of wind turbine, number of generators in a park, elevation, etc. in addition to the geographical location for wind parks. In this experiment, the performance of proposed method is compared with PHY model and UAE-NN model, as these are the only models from the experiments in Sec. IV-C and Sec. IV-D, which can be extended to ZSL experimental setup, for predicting power generation of a new park, without target task data. In this experiment, PHY model is considered as the baseline model for comparison. The proposed UAE-TENN architecture described in previous sections is utilized in this experiment. However, as described in Sec. III-D, a task embedding vector for the task to be predicted is required to make a prediction using the UAE- TENN architecture. As the new target park does not have a task embedding vector, we substitute it with it’s most similar park’s task embedding for making a prediction. We evaluate three types of similarity metrics to determine the most similar source park to a new target park using metadata of parks. The similarity is 1535 Authorized licensed use limited to: University Kassel. Downloaded on April 17,2023 at 19:13:08 UTC from IEEE Xplore. Restrictions apply. calculated based on geographical distance between parks, cosine distance between the metadata features of parks and euclidean distance between the tsne embeddings of metadata features of parks. As stated earlier in Sec. IV-A, the two open source datasets (PO, WO) do not have any metadata information of parks to select an appropriate source task, hence this experiment is evaluated on the 20% parks considered as target zero-shot parks of two PV datasets (PS, PR) and two wind datasets (WS, WR). It can be seen from the results Table III that UAE-NN model is performing better than PHY baseline model in PR and WR datasets with positive skill values. The proposed method UAE- TENN is improving the baseline performance, on an average, by 19.60% for PV parks, where as for wind parks, the negative skill value is due to the fact that there is lesser similarity among the parks in a dataset and imputing the TE from most similar park is not beneficial. We can also infer that TE component is beneficial when there is a strong relationship between tasks. We also suspect that the intrinsic diurnal cycle of solar energy makes it easier to perform ZSL for a new park even when there is no historical solar radiation data based on the geographical location of park. However, it is challenging to perform ZSL for wind parks, as the wind speed has higher variance across all locations and power prediction for a new target park without historical wind speed data and using metadata alone is challenging. Another interesting observation on the similarity metrics is that on real dataset pair (PR, WR), using only geographical distance gave better performance results, where as for synthetic dataset pair, using all the metadata features including geographical information gave better results. V. CONCLUSION AND FUTURE WORK In this paper, we propose an MTL architecture with a combination of simple and effective UAE and TE methods, for learning task independent common representation and task dependent embeddings respectively. We successfully evaluate the applicability of the proposed UAE-TENN method for PV and wind day-ahead power forecasts for 529 parks across six datasets. Experimental results demonstrate that the proposed method can achieve better performance than STL and MTL baseline models. In ZSL scenario, the proposed method im- proves performance for PV parks, where the parks are highly correlated to each other with lesser variance. The higher std values in wind datasets compared to PV datasets is due to the presence of higher number of outliers in wind parks. It is also due to the strong temporal correlation of PV parks based on daily diurnal cycle of the sun’s course, which is absent in wind parks. We are interested in extending the proposed architecture to CNN and LSTM autoencoders to get the temporal representations of multiple tasks. Another possible direction for future work is to examine bayesian task embeddings in MTL architectures. We believe the proposed MTL architecture can be easily extended to other domains for STL, MTL and ZSL applications. ACKNOWLEDGEMENT This work is supported by the projects Transfer (01IS20020B) funded by the BMBF (German Federal Ministry of Education and Research) and Digital-Twin-Solar (03EI6024E) funded by the BMWi(German Federal Ministry for Economic Affairs and Energy). REFERENCES [1] “A global roadmap for accelerated sdg7 action in support of the 2030 agenda for sustainable development and the paris agreement on climate change,” https://www.un.org/sites/un2.un.org/files/hlde outcome - sdg7 global roadmap.pdf, accessed: 04-04-2022. [2] G. Alkhayat and R. Mehmood, “A review and taxonomy of wind and solar energy forecasting methods based on deep learning,” Energy and AI, vol. 4, 2021. [3] R. Schwartz, J. Dodge, N. A. Smith, and O. Etzioni, “Green ai,” Commu- nications of the ACM, vol. 63, no. 12, 2020. [4] J. Schreiber, S. Vogt, and B. Sick, “Task embedding temporal convolution networks for transfer learning problems in renewable power time series forecast,” in Joint European Conference on Machine Learning and Knowl- edge Discovery in Databases. Springer, 2021. [5] Y. Zhang and Q. Yang, “A survey on multi-task learning,” IEEE Transac- tions on Knowledge and Data Engineering, 2021. [6] R. Jiao, X. Huang, X. Ma, L. Han, and W. Tian, “A model combining stacked auto encoder and back propagation algorithm for short-term wind power forecasting,” Ieee Access, vol. 6, 2018. [7] J. Schreiber and B. Sick, “Emerging relation network and task embedding for multi-task regression problems,” in 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021. [8] F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, and Q. He, “A comprehensive survey on transfer learning,” Proceedings of the IEEE, vol. 109, no. 1, pp. 43–76, 2020. [9] D. Charte, F. Charte, M. J. del Jesus, and F. Herrera, “An analysis on the use of autoencoders for representation learning: Fundamentals, learning task case studies, explainability and challenges,” Neurocomputing, vol. 404, 2020. [10] M. Ghifary, W. B. Kleijn, M. Zhang, and D. Balduzzi, “Domain generaliza- tion for object recognition with multi-task autoencoders,” in Proceedings of the IEEE international conference on computer vision, 2015, pp. 2551– 2559. [11] F. Zhuang, D. Luo, X. Jin, H. Xiong, P. Luo, and Q. He, “Representation learning via semi-supervised autoencoder for multi-task learning,” in 2015 IEEE International Conference on Data Mining, 2015, pp. 1141–1146. [12] W. Xu, S. Li, and Y. Lu, “Usr-mtl: an unsupervised sentence represen- tation learning framework with multi-task learning,” Applied Intelligence, vol. 51, 2021. [13] J. Henze, J. Schreiber, and B. Sick, “Representation learning in power time series forecasting,” 2020. [14] X. Liu, Z. Cao, and Z. Zhang, “Short-term predictions of multiple wind turbine power outputs based on deep neural networks with transfer learning,” Energy, vol. 217, 2021. [15] A. Gensler, J. Henze, B. Sick, and N. Raabe, “Deep learning for so- lar power forecasting—an approach using autoencoder and lstm neural networks,” in 2016 IEEE international conference on systems, man, and cybernetics (SMC). IEEE, 2016. [16] S. Ruder, “An overview of multi-task learning in deep neural networks,” arXiv preprint arXiv:1706.05098. [17] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, “Distributed representations of words and phrases and their compositionality,” Advances in neural information processing systems, vol. 26, 2013. [18] C. Guo and F. Berkhahn, “Entity embeddings of categorical variables,” arXiv preprint arXiv:1604.06737, 2016. [19] S. Vogt, A. Braun, J. Dobschinski, and B. Sick, “Wind power forecasting based on deep neural networks and transfer learning,” in 18th Wind Integration Workshop, 2019. [20] C. P. Nivarthi, “Transfer Learning as an Essential Tool for Digital Twins in Renewable Energy Systems,” in Organic Computing. Kassel: Kassel University Press, 2022, ch. 4, pp. 47–59. [21] F. Wilcoxon, “Individual comparisons by ranking methods,” in Break- throughs in statistics. Springer, 1992. [22] S. Vogt and J. Schreiber, “Synthetic Photovoltaic and Wind Power Fore- casting Data,” CoRR, vol. arXiv:, 2022. 1536 Authorized licensed use limited to: University Kassel. Downloaded on April 17,2023 at 19:13:08 UTC from IEEE Xplore. Restrictions apply. View publication stats","libVersion":"0.3.2","langs":""}