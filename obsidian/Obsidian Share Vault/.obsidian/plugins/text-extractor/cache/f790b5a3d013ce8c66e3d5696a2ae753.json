{"path":"lit/lit_sources/Ghojogh21GenAdversNetsTutorial.pdf","text":"To appear as a part of an upcoming textbook on dimensionality reduction and manifold learning. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey Benyamin Ghojogh BGHOJOGH@UWATERLOO.CA Department of Electrical and Computer Engineering, Machine Learning Laboratory, University of Waterloo, Waterloo, ON, Canada Ali Ghodsi ALI.GHODSI@UWATERLOO.CA Department of Statistics and Actuarial Science & David R. Cheriton School of Computer Science, Data Analytics Laboratory, University of Waterloo, Waterloo, ON, Canada Fakhri Karray KARRAY@UWATERLOO.CA Department of Electrical and Computer Engineering, Centre for Pattern Analysis and Machine Intelligence, University of Waterloo, Waterloo, ON, Canada Mark Crowley MCROWLEY@UWATERLOO.CA Department of Electrical and Computer Engineering, Machine Learning Laboratory, University of Waterloo, Waterloo, ON, Canada Abstract This is a tutorial and survey paper on Generative Adversarial Network (GAN), adversarial autoen- coders, and their variants. We start with explain- ing adversarial learning and the vanilla GAN. Then, we explain the conditional GAN and DCGAN. The mode collapse problem is intro- duced and various methods, including minibatch GAN, unrolled GAN, BourGAN, mixture GAN, D2GAN, and Wasserstein GAN, are introduced for resolving this problem. Then, maximum like- lihood estimation in GAN are explained along with f-GAN, adversarial variational Bayes, and Bayesian GAN. Then, we cover feature match- ing in GAN, InfoGAN, GRAN, LSGAN, energy- based GAN, CatGAN, MMD GAN, LapGAN, progressive GAN, triple GAN, LAG, GMAN, AdaGAN, CoGAN, inverse GAN, BiGAN, ALI, SAGAN, Few-shot GAN, SinGAN, and interpo- lation and evaluation of GAN. Then, we intro- duce some applications of GAN such as image- to-image translation (including PatchGAN, Cy- cleGAN, DeepFaceDrawing, simulated GAN, in- teractive GAN), text-to-image translation (in- cluding StackGAN), and mixing image charac- teristics (including FineGAN and MixNMatch). Finally, we explain the autoencoders based on adversarial learning including adversarial au- toencoder, PixelGAN, and implicit autoencoder. 1. Introduction Suppose we have a generative model which takes a ran- dom noise as input and generates a data point. We want the generated data point to be of good quality; hence, we should somehow judge its quality. One way to judge it is to observe the generated sample and assess its quality vi- sually. In this case, the judge is a human. However, we cannot take derivative of human’s judgment for optimiza- tion. Generative Adversarial Network (GAN), proposed in (Goodfellow et al., 2014), has the same idea but it can take derivative of the judgment. For that, it uses a classiﬁer as the judge rather than a human. Hence, we have a generator generating a sample and a binary classiﬁer (or discrimina- tor) to classify the generated sample as a real or generated sample. This classiﬁer can be a pre-trained network which is already trained by some real and generated (fake) data points. However, GAN puts a step ahead and lets the clas- siﬁer be trained simultaneously with training the genera- tor. This is the core idea of adversarial learning with the classiﬁer, also called the discriminator, and the generator compete each other; hence, they make each other stronger gradually by this competition (Goodfellow et al., 2020). It is noteworthy that the term “adversarial” is used in two main streams of research in machine learning and theyarXiv:2111.13282v1 [cs.LG] 26 Nov 2021 Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 2 should not be confused. These two research areas are: • Adversarial attack, also called learning with adversar- ial examples or adversarial machine learning. This line of research inspects some examples which can be changed slightly but wisely to fool a trained learn- ing model. For example, perturbation of some speciﬁc pixels in the input image may change the decision of learning model. The reason for this can be analyzed theoretically. Some example works in this area are (Huang et al., 2011; Moosavi-Dezfooli et al., 2016; Kurakin et al., 2017a;b; Madry et al., 2018). • Adversarial learning for generation. This line of re- search is categorized as generative models (Ng & Jor- dan, 2002) and/or methods based on that. GAN is in this line of research. This paper focuses on this re- search area. Another good tutorial on GAN is (Goodfellow, 2016) but it does not cover most recent methods in adversarial learning. Also, an honorary introduction of GAN, by several main contributors of GAN, is (Goodfellow et al., 2020). Some other existing surveys on GAN are (Wang et al., 2017; Creswell et al., 2018; Gonog & Zhou, 2019; Hong et al., 2019; Pan et al., 2019). This paper is a tutorial and survey on GAN and its variants. Required Background for the Reader This paper assumes that the reader has general knowledge of calculus, probability, linear algebra, and basics of opti- mization. 2. Generative Adversarial Network (GAN) 2.1. Adversarial Learning: The Adversarial Game The original GAN, also called the vanilla GAN, was proposed in (Goodfellow et al., 2014). Consider a d- dimensional dataset with n data points, i.e., {xi ∈ Rd} n i=1. In GAN, we have a generator G which takes a p-dimensional random noise z ∈ Rp as input and outputs a d-dimensional generated point x ∈ Rd. Hence, it is the mapping G : z → x where: G(z) = x. (1) The random noise can be seen as a latent factor on which the generated data point is conditioned. The probabilistic graphical model of generator is a variable x conditioned on a latent variable z (see (Goodfellow, 2016, Fig. 13) for its visualization). Let the distribution of random noise be denoted by z ∼ pz(z). We want the generated ̂x to be very similar to some original (or real) data point x in the dataset. We need a module to judge the quality of the generated point to see Figure 1. The structure of GAN. how similar it is to the real point. This module can be a human but we cannot take derivative of human’s judgment for optimization! A good candidate for the judge is a clas- siﬁer, also called the discriminator. The discriminator (also called the critic), denoted by D : x → [0, 1], is a binary classiﬁer which classiﬁes the generated point as a real or generated point: D(x) := { 1 if x is real, 0 if x is generated (fake). (2) The perfect discriminator outputs one for real points and zero for generated points. The discriminator’s output is in the range [0, 1] where the output for real data is closer to one and the output for fake data is closer to zero. If the generated point is very good and closely similar to a real data point, the classiﬁer may make a mistake and outputs a value close to one for it. Therefore, if the classiﬁer makes a mistake for the generated point, the generator has done a good job in generating a data point. The discriminator can be pre-trained but we can make the problem more sophisticated. Let us train the discriminator simultaneously while we are training the generator. This makes the discriminator D and the generator G stronger gradually while they compete each other. On one hand, the generator tries to generate realistic points to fool the discriminator and make it a hard time to distinguish the generated point from a real point. On the other hand, the discriminator tries to discriminate the fake (i.e., generated) point from a real point. When one of them gets stronger in training, the other one tries to become stronger to be able to compete. Therefore, there is an adversarial game between the generator and the discriminator. This game is zero-sum because whatever one of them loses, the other wins. 2.2. Optimization and Loss Function We denote the probability distributions of dataset and noise by pdata(x) and pz(z), respectively. The structure of GAN is depicted in Fig. 1. As the ﬁgure shows, the discriminator is trained by real points from dataset as well as generated points from the generator. The discriminator and generator are trained simultaneously. The optimization loss function Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 3 for both the discriminator and generator is: min G max D V (D, G) := Ex∼pdata(x)[ log(D(x))] + Ez∼pz(z)[ log(1 − D(G(z)))], (3) where E[.] denotes the expectation operator and the loss function V (D, G) is also called the value function of the game. In practice, we can use the Monte Carlo approxi- mation (Ghojogh et al., 2020) of expectation where the ex- pectations are replaced with averages over the mini-batch. This loss function is in the form of a cross-entropy loss. The ﬁrst term in Eq. (3) is expectation over the real data. This term is only used for the discriminator while it is a constant for the generator. According to Eq. (2), D(x) outputs one (the larger label) for the real data; therefore, the discriminator maximizes this term because it assigns the larger label to the real data. The second term in Eq. (3) is expectation over noise. It inputs the noise z to the generator to have G(z). The out- put of generator, which is the generated point, is fed as input to the discriminator (see Fig. 1) to have D(G(z) ). The discriminator wants to minimize D(G(z) ) because the smaller label is assigned to the generated data, according to Eq. (2). In other words, the discriminator wants to maxi- mize 1 − D(G(z) ). As logarithm is a monotonic func- tion, we can say that the discriminator wants to maximize Ez∼pz(z)[log(1 − D(G(z)))] which is the second term in Eq. (3). As opposed to the discriminator, the generator minimizes Ez∼pz(z)[log(1 − D(G(z)))] which is the sec- ond term in Eq. (3). This is because the generator wants to fool the discriminator to label the generated data as real data. The Eq. (3) is a minimax optimization problem (Du & Pardalos, 2013) and can be solved using alternating opti- mization (Ghojogh et al., 2021c) where we optimize over D and over G iteratively until convergence (i.e., Nash equi- librium). The original GAN (Goodfellow et al., 2014) uses a step of stochastic gradient descent (Ghojogh et al., 2021c) for updates of each variable in the alternating optimization. If we denote the loss function in Eq. (3) by V (D, G), the alternating optimization is done as: D(k+1) := D(k) + η(k) ∂ ∂D (V (D, G(k)) ), (4) G (k+1) := G (k) − η(k) ∂ ∂G (V (D(k+1), G) ), (5) where k is the index of iteration and η(k) is the learning rate at iteration k. Throughout this paper, derivatives w.r.t. D and G mean the derivatives w.r.t. the parameters (weights) of D and G networks, respectively. Eqs. (4) and (5) are one step of gradient ascent and gradient descent, respectively. Note that the gradients here are the average of gradients in the mini-batch. Every mini-batch includes both real and generated data. The paper (Goodfellow et al., 2014) sug- gests that Eq. (4) can be performed for several times before performing Eq. (5); however, the experiments of that paper perform Eq. (4) for only one time before performing Eq. (5). Also note that another way to solve the optimization problem in GAN is simultaneous optimization (Mescheder et al., 2017b) in which Eqs. (4) and (5) are performed at the same time and not one after the other. Remark 1 (Minimax versus maximin in GAN (Goodfel- low, 2016, Section 5)). We saw in Eq. (3) that the opti- mization of GAN is a minimax problem: min G max D V (D, G). (6) By changing the order of optimization, one can see GAN as a maximin problem (Goodfellow, 2016): max D min G V (D, G). (7) In fact, under some conditions, Eqs. (6) and (7) are equiv- alent (Du & Pardalos, 2013). 2.3. Network Structure of GAN In practice, the discriminator and generator are two (deep) neural networks. The structure of GAN is depicted in Fig. 1. The ﬁrst layer of discriminator network is d-dimensional and its last layer is one dimensional with scalar output. In the original GAN, maxout activation function (Goodfellow et al., 2013) is used for all layers except the last layer which has the sigmoid activation function to output a probability to model Eq. (2). The closer the output of D to one, the more probable its input is to be real. The generator network has a p-dimensional input layer for noise and a d-dimensional output layer for generating data. In the generator, a combination of ReLU (Nair & Hinton, 2010) and sigmoid activation functions are used. The space of noise as the input to the generator is called the latent space or the latent factor. Each of the Eqs. (4) and (5) are performed using backpropagation in the neural networks. 2.4. Optimal Solution of GAN Theorem 1 ((Goodfellow et al., 2014, Proposition 1)). For a ﬁxed generator G, the optimal discriminator is: D∗(x) = pdata(x) pdata(x) + pg(x) , (8) where pdata(x) is the probability distribution of the real dataset evaluated at point x and pg(x) is the probability distribution of output of generator evaluated at point x. Proof. According to the deﬁnition of expectation, the loss Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 4 function in Eq. (3) can be stated as: V (D, G) = ∫ x pdata(x) log(D(x))dx + ∫ z pz(z) log(1 − D(G(z)))dz. According to Eq. (1), we have: G(z) = x =⇒ z = G −1(x) =⇒ dz = (G −1)′(x)dx, where (G −1)′(x) is the derivative of (G −1)(x) with re- spect to (w.r.t.) x. Hence: V (D, G) = ∫ x pdata(x) log(D(x))dx + ∫ z pz(G −1(x)) log(1 − D(x))(G −1) ′(x)dx. The relation of distributions of input and output of genera- tor is: pg(x) = pz(z) × G −1(x) = pz(G −1(x)) G −1(x), (9) where G −1(x) is the Jacobian of distribution at point x. Hence: V (D, G) = ∫ x pdata(x) log(D(x))dx + ∫ z pg(x) log(1 − D(x))dx = ∫ x (pdata(x) log(D(x)) + pg(x) log(1 − D(x)))dx. (10) For optimization in Eq. (3), taking derivative w.r.t. D(x) gives: ∂V (D, G) ∂D(x) (a) = ∂ ∂D(x) (pdata(x) log(D(x)) + pg(x) log(1 − D(x)) ) = pdata(x) D(x) − pg(x) 1 − D(x) = pdata(x)(1 − D(x)) − pg(x)D(x) D(x)(1 − D(x)) set = 0 =⇒ pdata(x) − pdata(x)D(x) − pg(x)D(x) = 0 =⇒ D(x) = pdata(x) pdata(x) + pg(x) , where (a) is because taking derivative w.r.t. D(x) consid- ers a speciﬁc x and hence it removes the integral (summa- tion). Q.E.D. Theorem 2 ((Goodfellow et al., 2014, Theorem 1)). The optimal solution of GAN is when the distribution of gener- ated data becomes equal to the distribution of data: pg∗ (x) = pdata(x). (11) Proof. Putting the optimum D∗(x), i.e. Eq. (8), in Eq. (10) gives: V (D∗, G) = ∫ x (pdata(x) log(D∗(x)) + pg(x) log(1 − D∗(x)))dx (8) = ∫ x [pdata(x) log ( pdata(x) pdata(x) + pg(x) ) + pg(x) log ( pg(x) pdata(x) + pg(x) )] dx = ∫ x [ pdata(x) log ( pdata(x) 2 × pdata(x)+pg(x) 2 ) + pg(x) log ( pg(x) 2 × pdata(x)+pg(x) 2 )]dx = ∫ x [ pdata(x) log ( pdata(x) pdata(x)+pg(x) 2 ) + pg(x) log ( pg(x) pdata(x)+pg(x) 2 )] dx + log( 1 2 ) + log( 1 2 ) = ∫ x [ pdata(x) log ( pdata(x) pdata(x)+pg(x) 2 ) + pg(x) log ( pg(x) pdata(x)+pg(x) 2 )] dx − log(4) (a) = KL(pdata(x)\r \r \r pdata(x) + pg(x) 2 ) + KL(pg(x) \r \r \r pdata(x) + pg(x) 2 ) − log(4), (12) where (a) is because of the deﬁnition of KL diver- gence. The Jensen-Shannon Divergence (JSD) is deﬁned as (Nielsen, 2010): JSD(P ∥Q) := 1 2 KL(P ∥ 1 2 (P + Q)) + 1 2 KL(Q∥ 1 2 (P + Q)), (13) where P and Q denote the probability densities. In con- trast to KL divergence, the JSD is symmetric. The obtained V (D∗, G) can be restated as: V (D∗, G) = 2 JSD(pdata(x) ∥ pg(x) ) − log(4), (14) According to Eq. (3), the generator minimizes V (D∗, G). As the JSD is non-negative, the above loss function is min- imized if we have: JSD(pdata(x) ∥ pg∗ (x) ) = 0 =⇒ pdata(x) = pg∗ (x). Q.E.D. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 5 Corollary 1 ((Goodfellow et al., 2014, Theorem 1)). From Eqs. (11) and (14), we conclude that the optimal loss func- tion in GAN is: V (D∗, G ∗) = − log(4). (15) It is noteworthy that one can generalize Eq. (13) in GAN to (Husz´ar, 2015): JSDπ(P ∥Q) := π KL(P ∥πP + (1 − π)Q ) + (1 − π) KL (Q∥πP + (1 − π)Q ), (16) with π ∈ (0, 1). Its special case is Eq. (13) with π = 0.5. Corollary 2. From Eqs. (8) and (11), we conclude that at convergence (i.e., Nash equilibrium), the discriminator cannot distinguish between generated and real data: D∗(x) = 0.5, ∀x ∼ pdata(x), D∗(x) = 0.5, x = G ∗(z), ∀z ∼ pz(z). (17) Lemma 1 (Label smoothing in GAN (Salimans et al., 2016, Section 3.4)). It is shown that replacing labels 0 and 1, re- spectively, with smoother values 0.1 and 0.9 (Szegedy et al., 2016) can improve neural network against adversarial at- tacks (Hazan et al., 2017). If we smooth the labels of dis- criminator D for real and generated data to be α and β, respectively, the optimal discriminator becomes (Salimans et al., 2016): D∗(x) = αpdata(x) + βpg(x) pdata(x) + pg(x) , (18) which generalizes Eq. (8). The presence of pg(x) causes a problem because, for an x with small pdata(x) and large pg(x), the point does not change generator well enough to get close to the real data. Hence, it is recommended to set β = 0 to have one-sided label smoothing. In this case, the optimal discriminator is: D∗(x) = αpdata(x) pdata(x) + pg(x) . (19) Proof (sketch). Using α and β in the proof of Theorem 1 results in Eq. (18). 2.5. Convergence and Equilibrium Analysis of GAN Theorem 3 ((Goodfellow et al., 2014, Proposition 2)). If the discriminator and generator have enough capacity and, at every iteration of the alternating optimization, the dis- criminator is allowed to reach its optimum value as in Eq. (8), and pg(x) is updated to minimize V (D∗, G) stated in Eq. (14), pg(x) converges to pdata(x) as stated in Eq. (11). Proof. The KL divergences in Eq. (12) are convex func- tions w.r.t. pg(x). Hence, with sufﬁciently small updates of pg(x), it converges to pdata(x). Note that Eq. (12), which we used here, holds if Eq. (8) holds, i.e., the discriminator is allowed to reach its optimum value. Q.E.D. The GAN loss, i.e. Eq. (3), can be restated as (Nagarajan & Kolter, 2017): min G max D V (D, G) := Ex∼pdata(x)[ f (D(x))] + Ez∼pz(z)[f ( −D(G(z) ))] , (20) where f is the negative logistic function, i.e., f (x) := − log(1 + exp(−x)). In fact, the function f (.) can be any concave function. This formulation is slightly different from the original GAN in the sense that, here, the discrimi- nator D outputs a real-valued scalar (without any activation function) while the discriminator of Eq. (3) outputs values in the range (0, 1) after a sigmoid activation function. If D outputs 0.5 and 0, it means that it is completely con- fused in Eqs. (3) and (20), respectively. The Eq. (20) is a concave-concave loss function in most of the domain of discriminator (Nagarajan & Kolter, 2017, Proposition 3.1). Theorem 4 ((Nagarajan & Kolter, 2017, Theorem 3.1)). After satisfying several reasonable assumptions (see (Na- garajan & Kolter, 2017) for details), a GAN with loss func- tion of Eq. (20) is locally exponentially stable. Lemma 2 (Nash equilibrium in GAN (Farnia & Ozdaglar, 2020)). Nash equilibrium is the state where no player can improve its gain by choosing a different strategy. At the Nash equilibrium of GAN, we have: V (D, G∗) ≤ V (D∗, G ∗) ≤ V (D∗, G), (21) which is obvious because we are minimizing and maximiz- ing V (G, D) by the generator and discriminator, respec- tively, in Eq. (3). Empirical experiments have shown that GAN may not reach its Nash equilibrium in practice (Farnia & Ozdaglar, 2020). Regularization can help convergence of GAN to the Nash equilibrium (Mescheder et al., 2018). It is shown in (Mescheder et al., 2018) that A effective regularization for GAN is noise injection (Ghojogh & Crowley, 2019) in which independent Gaussian noise is added to the training data points. Deﬁnition 1 (Proximal equilibrium (Farnia & Ozdaglar, 2020)). We can use the proximal operator (Ghojogh et al., 2021c) in the loss function of GAN: min G max D (Vprox(D, G) := max ̃D (V ( ̃D, G) − λ∥ ̃D − D∥ 2 2) ), where V (D, G) is deﬁned in Eq. (3) and λ > 0 is the reg- ularization parameter. The equilibrium of the game having this loss function is called the proximal equilibrium. Theorem 5 (Convergence of GAN based on the Jacobian (Mescheder et al., 2017b)). Let the updated solution of GAN optimization at every iteration be obtained by some operator F (D, G), such as a step of gradient descent. The Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 6 convergence of GAN can be explained based on the Jaco- bian of F (D, G) with respect to D and G. If the absolute values of some eigenvalues of the Jacobian are larger than one, GAN will not converge to the Nash equilibrium. If all eigenvalues have absolute values less than one, GAN will converge to the Nash equilibrium with a linear rate O(|λmax| k) where λmax is the eigenvalue with largest ab- solute eigenvalue and k is the iteration index. If all eigen- values have unit absolute value, GAN may or may not con- verge. The readers can refer to (Farnia & Tse, 2018) for duality in GAN, which is not explained here for brevity. Moreover, some papers have speciﬁcally combined GAN with game theory. Interested readers can refer to (Oliehoek et al., 2017; Arora et al., 2017; Unterthiner et al., 2018; Tembine, 2019). 2.6. Conditional GAN As was explained before, in the original GAN, we ran- domly draw noise z from a prior distribution pz(z) and feed it to the generator. The generator outputs a point x from the noise z. Assume that the dataset with which GAN is trained has c number of classes. The original GAN gen- erates points from any class and we do not have control to generate a point from a speciﬁc class. Although, note that after GAN is trained, the latent space for z is meaningful in the sense that every part of the latent space results in gen- eration of some speciﬁc points from some class. However, the user cannot choose speciﬁcally what class to generate points from. Conditional GAN (Mirza & Osindero, 2014), also called the conditional adversarial network, gives the user the op- portunity to choose the class of generation of points. For the dataset {xi ∈ Rd} n i=1, let the one-hot encoded class labels be {yi ∈ Rc} n i=1. In conditional GAN, we use the following loss function instead of Eq. (3): min G max D VC(D, G) := Ex∼pdata(x)[ log(D(x|y) )] + Ez∼pz(z)[ log(1 − D(G(z|y) ))], (22) where the discriminator and generator are both conditioned on the labels. In practice, for implementing the loss func- tion (22), we concatenate the one-hot encoded label y to the point x for the input to discriminator. We also concatenate the one-hot encoded label y to the noise z for the input to generator. For these, the input layers of discriminator and generator are enlarged to accept the concatenated inputs. In the test phase, the user choose the desired class label and the generator generates a new point from that class. 2.7. Deep Convolutional GAN (DCGAN) Deep Convolutional GAN (DCGAN), proposed in (Rad- ford et al., 2016), made GAN deeper and generated higher resolution images than GAN. It also showed that it is very hard to train a GAN. 2.7.1. NETWORK STRUCTURE In DCGAN, we use an all-convolutional network (Sprin- genberg et al., 2015) which replaces the pooling functions with strided convolutions. In this way, the network learns its own spatial downsampling. This network is used for both generator and discriminator. In DCGAN, we also have only convolutional layers in the input layer of generator and output layer of discriminator, without any fully-connected layer. This elimination of fully connected layers is inspired by (Mordvintsev et al., 2015). We also apply batch normalization (Ioffe & Szegedy, 2015) to all layers except the last layer of generative and the ﬁrst layer of discriminator. This is because batch normaliza- tion makes the mean of input to each neuron zero and its variance one; however, we should learn the mean and vari- ance of data in the ﬁrst layer of discriminator and the mean and variance of data should be reproduced by the last layer of generator. Batch normalization reduces the problem of mode collapse, which will be introduced later in Section 3 with the price of causing some ﬂuctuations and instability (Radford et al., 2016). Remark 2 (Virtual batch normalization (Salimans et al., 2016, Section 3.5)). Batch normalization has a problem; it makes the effect of every input x on network dependent on other inputs in the mini-batch. To not have this problem, Virtual Batch Normalization (VBN) ﬁxes the mini-batches initially once before start of training; these mini-batches are called the reference batches. Every reference batch is normalized by only its own statistics (i.e., mean and co- variance). vbn has been found to be effective in training of generator (Salimans et al., 2016). In DCGAN, the last layer of generator has the hyperbolic tangent activation function and its other layers have the ReLU activation function (Nair & Hinton, 2010). As in GAN, the one-to-last layer of discriminator is ﬂattened and connected to one neuron with the sigmoid activation func- tion. In contrast to GAN, which uses the maxout activation function (Goodfellow et al., 2013) for discriminator layers (see Section 2.3), DCGAN uses the leaky rectiﬁed action function for discriminator. 2.7.2. VECTOR ARITHMETIC IN LATENT SPACE DCGAN showed that we can generate images from a spe- ciﬁc domain if we train GAN on that domain. for exam- ple, bedroom images were generated by DCGAN after be- ing trained on a dataset of bedroom images. DCGAN also showed that the learned latent space is meaningful and we can do vector arithmetic in the latent space. Vector arith- metic in the latent space was previously used for showing the ability of Word2Vec (Mikolov et al., 2013). DCGAN Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 7 Figure 2. Vector arithmetic in the latent space on images by DCGAN. Credt of image is for (Radford et al., 2016). made it possible to do vector arithmetic in the latent space for images. An example of vector arithmetic by DCGAN is shown in Fig. 2. In the latent space, the latent variables cor- responding to man with glasses, man without glasses, and woman without glasses are used. Using one latent point for each of these does not work very well. An average of three latent vectors for each has worked properly in practice. As Fig. 2 shows, vector arithmetic works because “man with glasses” minus “man without glasses” plus “woman with- out glasses” results in “woman with glasses”. 3. Mode Collapse Problem in GAN 3.1. Mode Collapse Problem We expect from a GAN to learn a meaningful latent space of z so that every speciﬁc value of z maps to a speciﬁc generated data point x. Also, nearby z values in the latent space should be mapped to similar but a little different gen- erations. The mode collapse problem (Metz et al., 2017), also known as the Helvetica scenario (Goodfellow, 2016), is a common problem in GAN models. It refers to when the generator cannot learn a perfectly meaningful latent space as was explained. Rather, it learns to map several different z values to the same generated data point. Mode collapse usually happens in GAN when the distribution of training data, pdata(x), has multiple modes. An example of mode collapse is illustrated in Fig. 3 which shows training steps of a GAN model when the training data is a mixture of Gaussians (Metz et al., 2017). In dif- ferent training steps, GAN learns to map all z values to one of the modes of mixture. When the discriminator learns to reject generation of some mode, the generator learns to map all z values to another mode. However, it never learns to generate all modes of the mixture. We expect GAN to map some part, and not all parts, of the latent space to one of the modes so that all modes are covered by the whole latent space. Another statement of the mode collapse is as follows (Xiao et al., 2018, Fig. 1). Assume pdata(x) is multi-modal while the latent space pz(z) has only one mode. Consider two points x1 and x2 from two modes of data whose corre- sponding latent noises are z1 and z2, respectively. Accord- ing to the mean value theorem, there is a latent noise with the absolute gradient value ∥x2 −x1∥/∥z2 −z1∥ where ∥.∥ is a norm. As this gradient is Lipschitz continuous, when the two modes are very far resulting in a large ∥x2 − x1∥, we face a problem. In this case, the latent noises between z1 and z2 generate data points between x1 and x2 which are not in the modes of data and thus are not valid. There exist various methods which resolve the mode col- lapse problem in GAN and adversarial learning. Some of them make the latent space a mixture distribution to imi- tate generation of the multi-modal training data. Some of them, however, have other approaches. In the following, we introduce the methods which tackle the mode collapse problem. 3.2. Minibatch GAN One way to resolve the mode collapse problem is mini- batch discrimination (Salimans et al., 2016, Section 3.2). In this method, the discriminator considers multiple data points in combination rather than separately. This avoids the mode collapse in generator. Suppose f (xi) ∈ Ra is the feature vector of one of the intermediate layers, with a neurons, in the discriminator for the data point xi. The data point xi is either real or generated (fake). We multiply f (xi) by a tensor T ∈ Ra×b×c to obtain Rb×c ∋ M i := (T ⊤f (xi))⊤. If there are |B| points in the mini-batch B, we can calculate {M i}|B| i=1. Let (M i)l: denote the l-th row Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 8 Figure 3. An example of mode collapse in GAN. Image is from (Metz et al., 2017). of M i. We deﬁne (Salimans et al., 2016): R ∋ cl(xi, xj) := exp(−∥(M i)l: − (M j)l:∥1), ∀l ∈ {1, . . . , b}, R ∋ o(xi)l := |B|∑ j=1 cl(xi, xj), ∀i ∈ {1, . . . , |B|}, Rb ∋ o(xi) := [o(xi)1, . . . , o(xi)b] ⊤, ∀i, R|B|×b ∋ o(X) := [o(x1), . . . , o(x|B|)] ⊤. (23) For every point xi within the mini-batch, we concatenate o(xi) with f (xi) and feed it to the next layer, rather than feeding merely f (xi). In other words, the additional fea- tures o(xi) are side information for better training of dis- criminator (which makes the generator also stronger in the game). This procedure, in the discriminator, is performed for both mini-batches of real and generated data. 3.3. Unrolled GAN Unrolled GAN (Metz et al., 2017) uses ∆ levels of un- rolling of discriminator when updating the generator. The alternating optimization in unrolled GAN is: D(k+1) := D(k) + η ∂ ∂D (V (D, G(k))), (24)  ||| ||| D0 := D(k+1), D(δ+1) := D(δ) + η(δ) ∂ ∂D (V (D, G(k))), ∀δ ∈ {0, . . . , ∆ − 1}, V∆(D(k+1), G) := V (D(∆), G), (25) G (k+1) := G (k) − η ∂ ∂G (V∆(D(k+1), G)), (26) where Eq. (25) unrolls the parameters of discriminator for ∆ times before using it for updating the generator. The loss function V (D(∆), G) is called the surrogate loss. As was mentioned in Section 2.2, the original GAN can update the discriminator itself for several time before updating the generator (Goodfellow et al., 2014). Note that Eq. (25) is different from updating the discriminator for several times, as done in GAN, because it does not update the discrimina- tor but it is used in updating the generator in Eq. (26). The gradient for generator in Eq. (26) can be simpliﬁed as: ∂ ∂G (V∆(D(k+1), G) ) (25) = ∂ ∂G (V∆(D(∆), G) ) + ∂ ∂D(∆) (V∆(D(∆), G) ) ∂D(∆) ∂G . The gradient for generator in the original GAN has only the ﬁrst term. The second term in the above equation captures the information of changes of discriminator w.r.t. changes in the generator. This reduces the problem of mode col- lapse which exists in GAN. 3.4. Bourgain GAN (BourGAN) Bourgain GAN (BourGAN) (Xiao et al., 2018) learns a mixture distribution (Ghojogh et al., 2019) in the latent space to resolve the problem of mode collapse and learn to generate multi-modal data. If the size of dataset, n, is large, it samples m points from dataset {xi}n i=1 where m ≪ n. Let {̃xi}m i=1 denote the sampled data. The idea of BourGAN is based on the Bourgain embedding (Bourgain, 1985) which enables embedding a dataset of size m into a O(log2(m))-dimensional ℓ2 norm embedding space with high probability. An improved Bourgain embedding is as follows. Theorem 6 ((Xiao et al., 2018, Corollary 2)). For a dataset {̃xi} m i=1 in a space with norm ∥.∥, there exists a mapping f from the data space to a O(log(m))-dimensional embed- ding space which preserves the local distances: ∥̃xi − ̃xj∥ ≤ ∥f (̃xi) − f (̃xj)∥ ≤ α ∥̃xi − ̃xj∥, where α ≤ O(log(m)). This embedding is achieved by Bourgain embedding (Bourgain, 1985) followed by random projection (Johnson & Lindenstrauss, 1984; Ghojogh et al., 2021b). This combined embedding can be found in (Xiao et al., 2018, Appendix A). This embedding requires computing pairwise distances. The sampling of m points from the n data points is to make this embedding feasible. This sampling does not affect the characteristics of pairwise distances in data if m is sufﬁ- ciently large (Xiao et al., 2018, Theorem 4). We embed all sampled points to obtain {f (̃xi)} m i=1. The distance charac- teristics of data is preserved by this embedding (Xiao et al., 2018, Theorem 5). As the next step in BourGAN, we sample from the embed- ding points uniformly, i.e., µ ∼ {f (̃xi)} m i=1. Then, we Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 9 sample the latent noise from a multivariate Gaussian distri- bution with mean µ, i.e., z ∼ N (µ, 0.01I). This proce- dure models a multi-modal mixture of Gaussians in the la- tent space of GAN. Note that it does not imply a mixture of m modes because if several f (̃xi)’s are close to each other, they can be considered as one mode. The multi-modality of the latent space is preserved to be the same as the multi- modality of data (Xiao et al., 2018, Eq. 6). The loss function of BourGAN regularizes the cost of gen- erator so that the generator preserves the distances of gen- erated points compared to the distances of corresponding noises. In this way, the multi-modality of latent space will also appear in the distribution of generated data pg(x). max D VBourGAN(D) := V (D, G), min G VBourGAN(G) := V (D, G) + λ Ezi,zj ∼pz(z)[( log(∥G(zi) − G(zj)∥) − log(∥zi − zj∥) )2]. (27) where V (D, G) is deﬁned in Eq. (3), λ > 0 is the regular- ization parameter, and ∥.∥ is some norm such as ℓ2 norm. 3.5. Mixture GAN (MGAN) Mixture GAN (MGAN) (Hoang et al., 2018) overcomes the mode collapse issue by assuming that the distribution of la- tent space, from which noise is sampled, is a mixture distri- bution (Ghojogh et al., 2019) rather than a single distribu- tion. It also enlarges the divergence of latent distributions in the mixture so that each of them covers a different mode for generation of data. The structure of MGAN is shown in Fig. 4. It has k generators {Gj} k j=1, a discriminator D, and a classiﬁer C. In terms of having a classiﬁer, it is similar to triple GAN (Li et al., 2017a) (see Section 5.9). Every generator Gj takes care of the j-th latent distribution in the mixture. The difference of MGAN from BourGAN (see Section 3.4) is that MGAN associates a generator to every mode while BourGAN has one generator with a mixture latent distribution. Let πj be the mixing probability for the j-th component in the mixture. We denote the distribution of generated data from the mixture latent distribution and the j-th compo- nent in the mixture by pg(x) and pgj (x), respectively. The discriminator tries to judge whether a data point is real, x ∼ pdata(x), or generated from one of the modes in the mixture, i.e., x = Gj(z). At every iteration of the alternat- ing optimization, the index j of the selected Gj for feeding to discriminator D is sampled from a multinomial distribu- tion Mult(π) where π := [π1, . . . , πk]⊤. The classiﬁer C classiﬁes which one of the k generators has generated the generated data. The loss function of MGAN, as a multi- Figure 4. The structure of MGAN. player minimax game, is: min {Gj }k j=1,C max D V (D, C, G1, . . . , Gk) := Ex∼pdata(x)[ log(D(x) )] + Ex∼pg(x)[ log(1 − D(x) )] − λ k∑ j=1 πj Ex∼pgj (x)[ log(Cj(x) )] , (28) where λ > 0 is the regularization parameter and Cj(x) is the probability that x is generated by Gj. The last layer of the classiﬁer C has k neurons with softmax activation func- tion where Cj is the output of j-th neuron in classiﬁer after the activation function. The last term in the loss function maximizes the entropy of classiﬁcation so that, by compe- tition of generators and classiﬁer, the generated data from various generators become separated gradually. In this way, generators will cover different modes of data, resolving the mode collapse problem. Theorem 7 ((Hoang et al., 2018, Theorem 2)). After con- vergence (i.e., the Nash equilibrium) of MGAN, we have: pg∗ (x) = pdata(x), D∗(x) = pdata(x) pdata(x) + pg(x) , C ∗ j (x) = πj pg∗ j (x) ∑k l=1 πl pg∗ l (x) , G ∗ := arg min G (2 JSD(pdata∥pg) − λ JSDπ(pG1, . . . , pGk ) ), (29) where: JSDπ(pG1 , . . . , pGk ) := k∑ j=1 πjEx∼pgj [log( πj pgj (x) ∑k l=1 πl pgl (x) )] − k∑ j=1 πj log(πj). (30) The above theorem means that the JSD between the mix- ture distribution pg and the data distribution pdata is mini- mized; however, the JSD between the the components of Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 10 mixture is maximized so that the components capture vari- ous modes of data. The below theorem shows that if the distribution of data is actually a mixture distribution itself, the optimal generation distribution at the Nash equilibrium becomes exactly that mixture. Theorem 8 ((Hoang et al., 2018, Theorem 3)). If the data distribution is a mixture pdata = ∑k j=1 πj qj(x) where the components qj(x)’s are well-separated, the optimal gener- ation distribution in MGAN is: pg∗ j (x) = qj(x), ∀j = 1, . . . , k, pg∗ (x) = pdata = k∑ j=1 πj qj(x). (31) 3.6. Dual Discriminator GAN (D2GAN) It is empirically observed (Theis et al., 2016; Husz´ar, 2015; Goodfellow, 2016) that the JSD used in GAN (see Eq. (14)) has the same effect as reverse KL divergence KL(pg(x)∥pdata(x)). This reverse KL divergence has the problem of mode collapse because it covers a single mode very well but cannot cover multiple modes well. That is while the KL divergence KL(pdata(x)∥pg(x)) can cover multiple modes and does not have the mode collapse prob- lem; however, it can include potentially undesirable sam- ples (Nguyen et al., 2017b). Dual Discriminator GAN (D2GAN) (Nguyen et al., 2017b) combines the advantages of both KL divergence and reverse KL divergence by hav- ing both in its formulation. Therefore, it does not face a mode collapse while it prevents undesirable samples. In D2GAN, we have two discriminators D1 and D2 and one generator G. The discriminators do not share their weights. In contrast to the original GAN, the outputs of discrimina- tors are non-negative rather than being in range [0, 1]. The discriminator D1 gives high and low scores to real and gen- erated (fake) data, respectively. Conversely, the discrimi- nator D2 gives high and low scores to generated (fake) and real data, respectively. The generator G tries to fool both discriminators. D2GAN plays a three-player game whole loss function is: min G max D1,D2 V (D1, D2, G) := αEx∼pdata(x)[ log(D1(x) )] + Ez∼pz(z)[−D1(G(z))] + Ex∼pdata(x)[−D2(x) ] + βEz∼pz(z)[ log(D2(G(z)))], (32) where α, β ∈ (0, 1] are hyperparameters. Alternating opti- mization (Ghojogh et al., 2021c) between D1, D2, and G solves the problem. Theorem 9 ((Nguyen et al., 2017b, Proposition 1 and The- orem 2)). After convergence (i.e., Nash equilibrium) of D2GAN, we have: D∗ 1(x) = αpdata(x) pg(x) , D∗ 2(x) = βpg(x) pdata(x) , (33) The loss function at the optimal discriminators is: V (D∗ 1, D∗ 2, , G) := α(log(α) − 1) + β(log(β) − 1) + αKL(pdata(x)∥pg(x)) + βKL(pg(x)∥pdata(x)). (34) =⇒V (D∗ 1, D∗ 2, , G∗) := α(log(α) − 1) + β(log(β) − 1). Therefore, pg∗ (x) = pdata(x), D∗ 1(x) = α, D∗ 2(x) = β. (35) According to Eq. (34), the parameters α and β are for the KL divergence KL(pdata(x)∥pg(x)) and the reverse KL di- vergence KL(pg(x)∥pdata(x)), respectively. Therefore, in- creasing α results in generation several modes, resolving the mode collapsing issue, but may include some undesir- able samples. Increasing β results in generation of a single mode but might miss several modes. A balance should be kept between the parameters α and β. 3.7. Wasserstein GAN (WGAN) Wasserstein GAN (WGAN) was proposed in (Arjovsky et al., 2017), developed from (Arjovsky & Bottou, 2017). The Wasserstein-1 or Earth-Mover distance between two distributions pdata(x) and pg(x) is deﬁned as: W (pdata(x), pg(x)) := inf γ∈Π(pdata(x),pg(x)) E(xi,xj )∼γ[∥xi − xj∥], (36) where Π(pdata(x), pg(x)) is the set of all joint distri- butions whose marginals are pdata(x) and pg(x). By the Kantorovich-Rubinstein duality (Villani, 2009), the Wasserstein-1 distance is equivalent to: W (pdata(x), pg(x)) = sup ∥D∥L≤1 (Ex∼pdata(x)[D(x)] − Ex∼pg(x)[D(x)] ), (37) where ∥D∥L ≤ 1 is the 1-Lipschitz functions D : X → R. The gradient of the Wasserstein-1 distance w.r.t. the pa- rameters of generator G is (Arjovsky et al., 2017, Theorem 3): ∂W (pdata(x), pg(x)) ∂G = −Ez∼pz(z)[ ∂D(G(z)) ∂G ] . (38) The function D(.) plays the role of discriminator in WGAN. In an alternating optimization, we maximize the loss in Eq. (37) for the discriminator and minimize in a gradient descent step by the gradient of Eq. (38) for gener- ator. In other words, the loss function of WGAN is: min G max ∥D∥L≤1 Ex∼pdata(x)[D(x)] − Ex∼pg(x)[D(x)], (39) Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 11 where x ∼ pg(x) is generated from the generator, i.e., x = G(z) in which z is the latent noise. The weights of discriminator are clipped to [−0.01, 0.01]. The constraint ∥D∥L ≤ 1 can be implemented by regularization with a gradient penalty (Gulrajani et al., 2017): min G max ∥D∥L≤1Ex∼pdata(x)[D(x)] − Ex∼pg(x)[D(x)] − λ(∇̂xD(̂x)∥2 − 1) 2, (40) where λ > 0 is the regularization parameter and ̂x is uni- formly sampled as an interpolation between the real data and the generated data: ̂x := ρ x + (1 − ρ)G(z), (41) in which ρ ∼ U (0, 1). Experiments show that WGAN re- solves the mode collapse problem (Arjovsky et al., 2017). 4. Maximum Likelihood Estimation in GAN In the following, we introduce the methods which relate GAN and Maximum Likelihood Estimation (MLE). 4.1. Comparison of MLE and GAN GAN is related to Noise-Contrastive Estimation (NCE) (Gutmann & Hyv¨arinen, 2010) and MLE, in the sense that they all optimize a distinguishing game value function (Goodfellow, 2015): V (pc, pg) := Ex∼pdata[log(pc(y = 1|x))] + Ex∼pg [log(pc(y = 0|x))], (42) where pg and pdata denote the distributions of generated and real data, respectively, and pc(y|x) is the output probabil- ity of a classiﬁer which judges whether a data point x is generated or real. Let θ denote the parameters of pg(x) distribution. If f (x) := log(pc(y = 0|x)), GAN performs the following optimization for its generator (Goodfellow, 2015): min θ Ex∼pg [f (x)] (43) =⇒ ∂ ∂θ Ex∼pg [f (x)] = ∂ ∂θ ∫ f (x)pg(x)dx = ∫ f (x) ∂ ∂θ pg(x)dx = ∫ f (x)pg(x) 1 pg(x) ∂ ∂θ pg(x)dx = ∫ f (x)pg(x) ∂ ∂θ log(pg(x))dx. (44) On the other hand, MLE has the following optimization: max θ Ex∼pg [pdata(x)] =⇒ ∂ ∂θ Ex∼pg [pdata(x)] = ∫ pdata(x) ∂ ∂θ log(pg(x))dx. (45) Eqs. (44) and (45) are for minimization in GAN and max- imization in MLE, respectively. By their comparison, we can have MLE in GAN if we set: f (x) = − pdata(x) pg(x) . (46) The discriminator of GAN is modeled as a classiﬁer for x being real and not generated (fake); hence: D(x) = pc(y = 1|x) = σ(D′(x)), (47) where σ(.) is the sigmoid activation function and D′(x) denotes the discriminator network except the sigmoid func- tion at its last layer. Theorem 10 ((Goodfellow, 2015; 2016)). The loss func- tion for the generator of GAN can be stated as any of the following loss functions: min G Ez∼pz(z)[ log(1 − D(G(z) ))], (48) min G −Ez∼pz(z)[ log(D(G(z) ))], (49) min G −Ez∼pz(z)[ σ−1(D(G(z) ))] , (50) where σ(.) is the sigmoid function. Proof. Eq. (48) is the generator part of loss function (3). The generator wants to fool the discriminator so it wants D(G(z)) to be close to one (see Eq. (2)). Hence, rather than minimizing log(1 − D(G(z))) in Eq. (48), we can maximize log(D(G(z))), or minimize its negation, in Eq. (49) (Goodfellow, 2016). The proof of Eq. (50) is as fol- lows (Goodfellow, 2015). Assume the discriminator is op- timal for a given generator; hence, according to Eq. (8), we have: pc(y = 1|x) (8) = pdata(x) pdata(x) + pg(x) = 1 1 + pg(x) pdata(x) (47) = σ(D′(x)) = 1 1 + exp(−D′(x)) =⇒ pg(x) pdata(x) = exp(−D′(x)) (46) =⇒ f (x) = − exp(D′(x)) (47) = − exp (σ−1(D(x)) ). Hence, for the generated data x = G(z), from the latent noise sample z ∼ pz(z), the Eq. (43) becomes Eq. (50). Q.E.D. 4.2. f-GAN f-GAN (Nowozin et al., 2016) uses f-divergence in the for- mulation of GAN. The f-GAN computes divergence be- tween two distributions p(x) and q(x) by (Liese & Vajda, Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 12 2006): Df (P ∥Q) := ∫ q(x)f ( p(x) q(x) )dx, (51) where the convex so-called generator function f : R+ → R satisﬁes f (1) = 0. Two special cases of f-GAN are KL- divergence and JL-divergence. We denote the space of data by X . Lemma 3 ((Nguyen et al., 2010, Lemma 1)). A lower- bound on the f-divergence is as follows: Df (P ∥Q) ≥ sup T ∈T (Ex∼p(x)[T (x)] − Ex∼q(x)[f ∗(T (x))]), (52) where f ∗ is the convex conjugate of f and T : X → R is an arbitrary class of functions. Proof. The convex conjugate of function f is deﬁned as (Ghojogh et al., 2021c): f ∗(t) := sup u∈dom(f ) (ut − f (u)) =⇒ f (u) := sup t∈dom(f ∗) (tu − f ∗(t)). (53) We have: Df (P ∥Q) (53) = ∫ q(x) sup t∈dom(f ∗) (t p(x) q(x) − f ∗(t)) dx (a) ≥ sup T ∈T ( ∫ p(x)T (x)dx − ∫ q(x)f ∗(T (x))dx) = sup T ∈T (Ex∼p(x)[T (x)] − Ex∼q(x)[f ∗(T (x))]), where (a) is because the summation of maximums is greater than or equal to the maximum of summations. Q.E.D. Variational Divergence Minimization (VDM) (Nowozin et al., 2016) optimizes the f-divergence by optimizing the bound in Eq. (52). In this sense, it is similar to varia- tional inference (Ghojogh et al., 2021a). Suppose p(x) = pdata(x) and q(x) = pg(x) in Eq. (52), where pdata(x) and pg(x) are the distributions of real and generated data, re- spectively. Let T (x) = of (V (x)) where V : X → R is the mapping of network from its input to one output neuron (before activation) and of : R → dom(f ∗) is the output of activation function. VDM can be used for optimization of various f-divergences. Its loss function is: min G max V Ex∼pdata(x)[of (V (x))] + Ex∼pg(x)[−f ∗(of (V (x)))] . (54) The reader can refer to (Nowozin et al., 2016, Table 2) for a complete list of expressions for of (v) and f ∗ in dif- ferent special cases of f-divergence. A special case of VDM is f-GAN in which of (v) = − log(1 + exp(−v)), f ∗(t) = − log(1 − exp(t)) and the discriminator is the sig- moid function of V (x), i.e., D(x) = 1/(1+exp(−V (x))). Hence, in f-GAN, we have: of (V (x)) = − log(1 + exp(−V (x))) = log(D(x)), f ∗(of (V (x)) ) = − log(1 − exp(log(D(x)))) = − log(1 − D(x)). Putting these in Eq. (54) gives the loss of f-GAN: min G max D Ex∼pdata(x)[ log(D(x) )] + Ex∼pg(x)[ log(1 − D(x))]. (55) 4.3. Adversarial Variational Bayes (AVB) Adversarial Variational Bayes (AVB) (Mescheder et al., 2017a) combines the ideas of variational and adversar- ial training. Variational inference (Ghojogh et al., 2021a) maximizes an evidence lower bound deﬁned as: max θ max ϕ Ep(x)Eqϕ(z|x)[ log(p(z)) − log(qϕ(z|x)) + log(pθ(x|z)) ], (56) where θ and ϕ are parameters corresponding to pθ(x|z) and qϕ(z|x), respectively. On the other hand, adversarial learning uses a discriminator in training. AVB uses a dis- criminator D(x, z) with one output neuron having a sig- moid activation function in variational inference. The loss function for the discriminator is: max D Ep(x)Eqϕ(z|x)[ log(D(x, z))] + Ep(x)Epz(z)[ log(1 − D(x, z))] , (57) whose solution is D∗(x, z) = − log(p(z)) + log(qϕ(z|x)) (Mescheder et al., 2017a, Proposition 1). Therefore, Eq. (56) becomes: max θ max ϕ Ep(x)Eqϕ(z|x)[ − D∗(x, z) + log(pθ(x|z)) ] , (58) which is optimized by backpropagation, after the reparam- eterization trick (Ghojogh et al., 2021a). 4.4. Bayesian GAN (BGAN) Bayesian GAN (BGAN) (Saatci & Wilson, 2017) models GAN using Bayesian analysis. Let G and D denote the parameters of generator and discriminator, respectively, x Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 13 be the real data, z be the noise sample, and b be the mini- batch size. p(G|z, D) ∝ ( b∏ i=1 D(G(zi))) p(G), p(D|z, x) ∝ ( b∏ i=1 D(xi) )( b∏ i=1 (1 − D(G(zi)) )) p(D). We can marginalize these distributions: p(G|D) = ∫ p(G, z|D) dz = ∫ p(G|z, D) p(z|D) dz (a) = ∫ p(G|z, D) pz(z) dz (b) ≈ 1 b b∑ i=1 p(G|zi), (59) where zi ∼ pz(z), (a) is because the noise z is indepen- dent of the discriminator D, and (b) is because of the Monte Carlo approximation (Ghojogh et al., 2020). Similarly, we have: p(D|G) = 1 b b∑ i=1 p(D|zi, xi). (60) Sampling from the distributions in Eqs. (59) and (60) will converge to the joint distribution of generator and discrim- inator, based on Gibbs sampling (Ghojogh et al., 2020). Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) is a technique for training a neural network using the posteri- ors. The discriminator and generator of BGAN are trained alternatively using this technique and the posteriors in Eqs. (59) and (60). Note that another GAN model with vari- ational inference and Bayesian analysis is the variational Bayesian GAN (Chien & Kuo, 2019). 5. Other Variants of GAN 5.1. Feature Matching in GAN During training, the layers of discriminator D are trained to have discriminative features between the real and generated data. Therefore, for better training of the generator G and fooling the discriminator by it, we can use the features of an intermediate layer of discriminator (Salimans et al., 2016, Section 3.1). We train the generator to match the expected values of the intermediate features for inputs of real and generated data. Hence, the optimization of generator can be: min G \r \rEx∼pdata(x)[f (x)] − Ez∼pz(z)[ f (G(z) )]\r \r 2 2, (61) where f (x) and f (G(z)) are the features of an intermedi- ate layer of discriminator for inputs x (real data) and G(z) (generated data), respectively. The discriminator is trained as in the original GAN, i.e., maximization in Eq. (3). 5.2. InfoGAN Information maximizing GAN (InfoGAN), proposed in (Chen et al., 2016), is an information-theoretic approach to GAN. It maximizes the mutual information between la- tent variables and generated data. In InfoGAN, we have two sets of latent variables, i.e., z and c. The generator gets these two latent variables as input and outputs G(z, c). The optimization problem in InfoGAN is a regularized problem as: min G max D VI (D, G) := V (D, G) − λI(c; G(z, c)), (62) where V (D, G) is deﬁned in Eq. (3), the λ > 0 is the regularization parameter and I(.; .) is the mutual informa- tion deﬁned as I(c; G(z, c)) := H(c) − H(c|G(z, c)) in which H(.) is the entropy. Note that the added regulariza- tion term depends only on G and not D. The generator maximizes the mutual information I(c; G(z, c)). Computing this mutual information is difﬁcult in practice. The mutual information can be simpliﬁed as the following by introducing an auxiliary distribution Q(c|x). I(c; G(z, c)) := H(c) − H(c|G(z, c)) (a) = H(c) − (− Ex∼G(z,c)[log P (c|x)] ) = H(c) + Ex∼G(z,c)[ Ec′∼P (c|x)[log P (c′|x)] ] (b) = H(c) + Ex∼G(z,c)[ KL(P (.|x)∥Q(.|x)) + Ec′∼P (c|x)[log Q(c′|x)] ] (c) ≥ H(c) + Ex∼G(z,c)[ Ec′∼P (c|x)[log Q(c′|x)] ] (d) = H(c) + Ec∼P (c), x∼G(z,c)[log Q(c′|x)] (e) = LI (G, Q), where (a) is because of deﬁnition of entropy, (b) is because of the deﬁnition of KL divergence, (c) is be- cause the KL divergence is non-negative, (d) is because Ex∼X,y∼Y |X [f (x, y)] = Ex∼X,y∼Y |X,x′∼X|Y [f (x′, y)] (see (Chen et al., 2016, Lemma 5.1)), and (e) is because we deﬁne LI (G, Q) as that expression. Hence, LI (G, Q) is a lower-bound for I(c; G(z, c)). Using this lower-bound in Eq. (62) gives: min G,Q max D VI (D, G) := V (D, G) − λLI (G, Q), (63) where: LI (G, Q) := H(c) + Ec∼P (c), x∼G(z,c)[log Q(c′|x)], can be calculated by Monte Carlo approximation (Ghojogh et al., 2020). 5.3. Generative Recurrent Adversarial Network (GRAN) Generative Recurrent Adversarial Network (GRAN) (Im et al., 2016) has been inspired by the Deep Recurrent At- tentive Writer (DRAW) (Gregor et al., 2015). DRAW Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 14 uses variational inference for drawing images gradually on canvas by passing time. GRAN does the same but us- ing adversarial learning. Therefore, it is a combination of GAN and recurrent networks. In GRAN, the genera- tor G has a recurrent feedback loop whose inputs are a sequence of noise samples {zt}T t=1. The recurrent loop of generator generates a sequence of drawings on canvas, i.e., {∆C1, ∆C2, . . . , ∆CT }. Every recurrent loop, at time t ∈ {1, . . . , T }, is like an autoencoder with encoder f (.) and decoder g(.). The coding layer between the encoder and decoder gives the concatenation of latent coding hz,t and canvas coding hc,t. This coding concatenation is fed to the decoder f to result the canvas drawing ∆Ct. In every recurrent loop, at time t ∈ {1, . . . , T }, we have: zt ∼ pz(z), hc,t := g(∆Ct−1), hz,t := tanh(W zt + b), ∆Ct := f ([h ⊤ z,t, h ⊤ c,t] ⊤), (64) where W and b are the layer weights and bias weights for the latent variable zt. We use DCGAN (Radford et al., 2016) (see Section 2.7) for the encoder f and decoder g at every recurrent loop, where the canvas drawings {∆Ct} T t=1 are generated. The total canvas drawing is the summation of drawings at the time slots. We use a logistic function σ(.) to scale the drawing to (0, 1) for the sake of pixel vi- sualization: C = σ( T∑ t=1 ∆Ct). 5.4. Least Squares GAN (LSGAN) The GAN loss function has a problem. In the discriminator, the gradient vanishes for the generated data points which fall on the correct side of decision boundary but are still different from the real data. Least Squares GAN (LSGAN) (Mao et al., 2017; 2019) resolves this issue by using least squares cost in the adversarial loss function. For the dis- criminator D of LSGAN, we use two scalar labels a and b for generated (fake) and real data points. For the generator G of LSGAN, we use the scalar label c which the generator wants the discriminator to believe for in classiﬁcation. The loss functions in LSGAN are: min D VLSGAN(D) := 1 2 Ex∼pdata(x)[ (D(x) − b) 2] + 1 2 Ez∼pz(z)[(D(G(z)) − a) 2] , min G VLSGAN(G) := 1 2 Ez∼pz(z)[(D(G(z)) − c)2] . (65) Lemma 4 ((Mao et al., 2019, Proposition 1)). For a ﬁxed generator G, the optimal discriminator in LSGAN is: D∗(x) = bpdata(x) + apg(x) pdata(x) + pg(x) , (66) where pdata(x) is the probability distribution of real dataset evaluated at point x and pg(x) is the probability distribu- tion of output of generator evaluated at point x. Proof. VLSGAN(D) (65) = 1 2 Ex∼pdata(x)[ (D(x) − b)2] + 1 2 Ez∼pz(z)[ (D(G(z)) − a) 2] = ∫ x 1 2 pdata(x)(D(x) − b)2dx + ∫ x 1 2 pz(z)(D(G(z)) − a)2dx (9) = ∫ x 1 2 (pdata(x)(D(x) − b) 2 + pg(x)(D(x) − a) 2)dx For optimization in Eq. (65), taking derivative w.r.t. D(x) gives: ∂VLSGAN(D) ∂D(x) (a) = ∂ ∂D(x) ( 1 2 (pdata(x)(D(x) − b)2 + pg(x)(D(x) − a) 2)) = pdata(x)(D(x) − b) + pg(x)(D(x) − a) set = 0 =⇒ D(x) = bpdata(x) + apg(x) pdata(x) + pg(x) , where (a) is because taking derivative w.r.t. D(x) consid- ers a speciﬁc x and hence it removes the integral (summa- tion). Q.E.D. Theorem 11 ((Mao et al., 2019, Theorem 1)). Optimiza- tion of LSGAN is equivalent to minimizing the Pearson χ2 divergence between pdata(x) + pg(x) and 2pg(x), if we have: b − c = 1, b − a = 2. (67) Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 15 Proof. 2VLSGAN(G) (65) = Ex∼pz(z)[(D∗(G(z)) − c)2] (a) = Ex∼pdata(x)[ (D∗(x) − c)2] + Ez∼pz(z)[ (D∗(G(z)) − c) 2] (9) = Ex∼pdata(x)[ (D∗(x) − c)2] + Ex∼pg(x)[ (D∗(x) − c)2] (66) = Ex∼pdata(x)[ ( bpdata(x) + apg(x) pdata(x) + pg(x) − c) 2] + Ex∼pg(x)[( bpdata(x) + apg(x) pdata(x) + pg(x) − c) 2] (b) = ∫ x pdata(x) ( (b − c)pdata(x) + (a − c)pg(x) pdata(x) + pg(x) )2dx + ∫ x pg(x)( (b − c)pdata(x) + (a − c)pg(x) pdata(x) + pg(x) )2dx (c) = ∫ x ((b − c)pdata(x) + (a − c)pg(x) )2 pdata(x) + pg(x) dx = ∫ x ((b − c)(pdata(x) + pg(x)) − (b − a)pg(x) )2 pdata(x) + pg(x) dx (67) = ∫ x (2pg(x) − (pdata(x) + pg(x)) )2 pdata(x) + pg(x) dx (d) = χ 2(pdata(x) + pg(x) ∥ 2pg(x)), where (a) is because Ex∼pdata(x)[ (D∗(x) − c)2] is constant w.r.t. G, (b) is because of the deﬁnition of expectation, (c) is because of simpliﬁcation of terms, and (d) is because of deﬁnition of Pearson χ 2 divergence. Q.E.D. As we saw, the labels a, b, and c in LSGAN should satisfy Eq. (67). An options for satisfying these conditions is: a = −1, b = 1, c = 0, (68) which means the real and fake labels for discriminator are +1 and −1, respectively, while the generator fools the dis- criminator by label 0. In other words, the generator does not take it very hard on the discriminator and sets the fake label to 0 (some moderate value) rather than 1. Another possible option for the labels is: a = 0, b = c = 1, (69) which does not satisfy Eq. (67) but fools the discriminator completely (with more power) by the generator. Experi- ments have shown both of these options perform equally well in practice (Mao et al., 2017). 5.5. Energy-based GAN (EBGAN) In energy-based learning (LeCun et al., 2006), a function is learned which maps data points to some energy val- ues where the incorrectly labeled data points are assigned higher energy values. In unsupervised energy-based learn- ing, higher energy is assigned to data points away from the data manifold or data cloud. Energy-based GAN (EBGAN) (Zhao et al., 2017) uses energy-based learning in adversar- ial learning. The loss functions in EBGAN are: min D VEBGAN(D) := D(x) + [m − D(G(z))]+, min G VEBGAN(G) := D(G(z)), (70) where [.]+ := max(., 0) is the standard Hinge loss and m > 0 is the margin. The discriminator minimizes the er- ror of D(x) while maximizing D(G(z)) not to be fooled by the generator. The generator minimizes D(G(z)) to fool the discriminator. Theorem 12 ((Zhao et al., 2017, Theorem 1)). Let: Q(D, G) := ∫ x,z VEBGAN(D) pdata(x) pz(z) dx dz. (71) Optimization of EBGAN results in pg(x) = pdata(x) and Q(D∗, G ∗) = m after convergence (i.e., Nash equilib- rium). Proof. Q(D, G∗) (70) =∫ x,z (D(x) + [m − D(G ∗(z))]+) pdata(x) pz(z) dx dz = ∫ x D(x) pdata(x) dx ∫ z pz(z) dz | {z } =1 + ∫ x pdata(x) dx | {z } =1 ∫ z[m − D(G ∗(z))]+ pz(z) dz (9) = ∫ x (pdata(x) D(x) + pg∗ (x) [m − D(x)]+) dx. (72) The function inside the integral is at + b[m − t]+ whose minimum occurs if a < b. Hence, the minimum of Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 16 Q(D, G∗) is: Q(D∗, G ∗) = m ∫ x I(pdata(x) < pg∗ (x)) pdata(x)dx + m ∫ x I(pdata(x) ≥ pg(x)) pg∗ (x)dx = m ∫ x (I(pdata(x) < pg∗ (x)) pdata(x) + (1 − I(pdata(x) < pg∗ (x))) pg∗ (x)) dx = m ∫ x pg∗ (x)dx | {z } =1 + m ∫ x I(pdata(x) < pg∗ (x)) (pdata(x) − pg∗ (x) )dx. (73) As the probability of generated data pg∗ (x) is upper- bounded by the probability of data pdata(x), the second term is non-positive. Hence, Q(D, G) ≤ m. On the other hand, as pg∗ (x) ≤ pdata(x), we have: ∫ x pg∗ (x)D∗(x)dx ≤ ∫ x pdata(x)D∗(x)dx. Using this in Eq. (72) gives: Q(D∗, G ∗) ≥ ∫ x (pg∗ (x)D∗(x) + pg∗ (x) [m − D∗(x)]+) dx (a) = ∫ x pg∗ (x)D∗(x)dx + ∫ x pg∗ (x) (m − D∗(x)) dx = m ∫ x pg∗ (x) dx | {z } =1 = m, where (a) is because D∗(x) ≤ m almost everywhere at the Nash equilibrium (since discriminator is trained at the convergence to not violate the margin). We showed that m ≤ Q(D∗, G ∗) ≤ m so Q(D∗, G ∗) = m. From Q(D∗, G ∗) = m and Eq. (73), we have ∫ x I(pdata(x) < pg∗ (x))dx = 0. As we have pg∗ (x) ≤ pdata(x), this only holds when pdata(x) = pg∗ (x). Q.E.D. 5.6. Semi-supervised GAN In the following, we introduce the semi-supervised meth- ods in the GAN literature. 5.6.1. CATEGORICAL GAN (CATGAN) – Unsupervised CatGAN: In Categorical GAN (CatGAN) (Springenberg, 2016), the discriminator classiﬁes c classes (i.e., categories) rather than a binary classiﬁcation which we had in GAN’s discriminator. Hence, the last layer of discriminator has c neurons with softmax activation func- tions. Let Dk(x) denote the k-th logit, i.e., softmax output. The conditional probabilities, for the categories, are mod- eled as follows based on the logits of discriminator: p(y = k | x) = exp(Dk(x)) ∑c k=1 exp(Dk(x)) , ∀k = {1, . . . , c}. (74) Note that the dataset is unlabeled (unsupervised) and the categories are just made by our model in the logits of dis- criminator. The discriminator wants to be certain about classiﬁcation of real data into the c categories; hence, it should minimize the entropy H of conditional probabilities of real data which is: Ex∼pdata(x)[H(p(y = k | x))] (a) ≈ 1 n n∑ i=1 H(p(y = k | xi)) (b) = 1 n n∑ i=1 ( − c∑ k=1 p(y = k|xi) log (p(y = k|xi) )), (75) where n is number of real data points, (a) is because of the Monte Carlo approximation (Ghojogh et al., 2020), and (b) is because of the deﬁnition of entropy. We draw n noise samples, z ∼ pz(z), and feed to generator to generate data points G(z). The discriminator wants to be uncertain about classiﬁcation of generated (fake) data into the c categories; hence, it should maximize its corresponding entropy: Ez∼pz(z)[H(p(y = k | G(z)))] ≈ 1 n n∑ i=1 H(p(y = k | G(zi))). (76) The generator, on the other hand, wants to minimize the above entropy to fool the discriminator. We also assume uniform prior p(y) for categories so we want the discrimi- nator and generator use all categories equally. For that, they should maximize the entropy of marginal category distribu- tions: Hdata(p(y)) = H( 1 n n∑ i=1 p(y | xi) ), (77) Hg(p(y)) = H( 1 n n∑ i=1 p(y | G(zi))). (78) Overall, according to above explanations, the loss functions in CatGAN are: max D V (D) := Hdata(p(y)) − Ex∼pdata(x)[H(p(y = k | x))] + Ez∼pz(z)[H(p(y = k | G(z)))], (79) min G V (D) := −Hg(p(y)) + Ez∼pz(z)[H(p(y = k | G(z)))]. (80) Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 17 – Semi-supervised CatGAN: The above loss function for CatGAN is used for an unsupervised case. We can extend CatGAN to semi-supervised cases (Springenberg, 2016). Suppose we have nℓ labeled data points in addition to the n unlabeled data points. We set c (i.e., the number of cat- egories) equal to the number of classes of the labeled data. We denote the labeled dataset by XL := {(x ℓ i , yℓ i )} nℓ i=1 where yℓ i ∈ Rc is the one-hot encoded label for the i-th labeled data point. The discriminator should maximize the cross-entropy of the labeled data to be able to discriminate the actual classes in addition to discrimination of the cate- gories. This cross-entropy is: CE(y, p(y|x)) := − c∑ k=1 yi log(p(y = yi|x)), (81) where p(y = yi|x) is the logit of discriminator for the la- beled data input. We regularize this cross-entropy into the loss of discriminator: max D V (D) := Hdata(p(y)) − Ex∼pdata(x)[H(p(y = k | x))] + Ez∼pz(z)[H(p(y = k | G(z)))] + λCE(y, p(y|x)), (82) where λ > 0 is the regularization parameter. 5.6.2. GENERATED DATA AS A NEW CLASS We can consider the generated data to be data with an addi- tional label (c + 1). This idea has appeared in two indepen- dent papers which are (Salimans et al., 2016, Section 5) and (Odena, 2016). Here, we explain (Salimans et al., 2016, Section 5). The discriminator D classiﬁes which class the data point x has. This is in contrast to the discriminator in the original GAN which has a neuron with sigmoid ac- tivation function as its last layer. Here, the last layer of discriminator has (c + 1) neurons with softmax activation function where the j-th neuron outputs the probability for x belonging to the j-th class. The optimization of discrim- inator is minimization of summation of two cross-entropy costs: min D (Vsupervised(D) + Vunsupervised(D) ), (83) where: Vsupervised(D) := − Ex,y∼pdata(x,y)[ log(pd(y|x)) ] , ∀y < c + 1, Vunsupervised(D) := −Ex∼pdata(x)[ log(1 − pd(y|x)) ] + Ex∼pg(x)[ log(pd(y|x))] , for y = c + 1, (84) where pd(y|x) is the output of softmax at the last layer of discriminator. With with cost, discriminator learns to classify the generated (fake) data points as a new class so the generator should try to fool it to not correctly classify it as the new class. The cost of generator is the same as in Eq. (3). We can subtract a general function from every class label. Hence, we can subtract the output, corresponding to the la- bels of generated data, from all labels to make the label of fake data zero, ℓc+1 = 0. Hence, the softmax output of generated data becomes exp(ℓc+1 = 0) = 1. Therefore, according to Eq. (8) and the fact that probabilities are ob- tained by softmax outputs (in the form of logits), we have: D(x) (8) = ∑c j=1 exp(ℓj(x)) ( ∑c j=1 exp(ℓj(x))) + exp(ℓc+1(x)) = ∑c j=1 exp(ℓj(x)) ∑c j=1 exp(ℓj(x)) + 1 . (85) 5.7. MMD GAN MMD GAN (Li et al., 2017b) combines the ideas of mo- ment matching networks (Li et al., 2015) and GAN (Good- fellow et al., 2014) by using adversarial learning in Max- imum Mean Discrepancy (MMD). MMD (Gretton et al., 2006) is a measure of divergence of two distributions and it uses distance in the Reproducing Kernel Hilbert Space (RKHS) to measure the difference of moments of two dis- tributions (Ghojogh et al., 2021d). The MMD between two distributions p(x) and q(x) is: Mk(p, q) := Exi,xj ∼p(x)[k(xi, xj)] + Exi,xj ∼q(x)[k(xi, xj)] − 2Exi∼p(x),xj ∼q(x)[k(xi, xj)], where k(., .) is a kernel function such as the Gaussian ker- nel. If p(x) = pdata(x) and q(x) = pq(x) are the distri- butions of real and generated data, respectively, we want to minimize this MMD so that the generated data distribution becomes similar to the real data distribution. We can ﬁnd the best kernel, giving the largest MMD for the worst-case scenario, from a set of valid kernel functions K: min G max k∈K Mk(pdata(x), pg(x)). However, this optimization is difﬁcult. In MMD GAN, rather than using a ﬁxed kernel such as the Gaussian ker- nel, we train the kernel function by adversarial learning. We learn a function D(.) to deﬁne the kernel function as: kD(xi, xj) = exp(−∥D(xi) − D(xj)∥2). We use an autoencoder for D(.) with De(.) and Dd(.) as encoder and decoder, respectively. This autoencoder plays the role of discriminator in adversarial learning. The gen- erator is denoted by G(.). This autoencoder should recon- struct both real data, x ∈ X , and generated data from latent noise, x ∈ G(z). The loss function of MMD GAN is: min G max D MkD (pdata(x), pg(x)) − λEx∈X ∪G(z)[ ∥x − Dd(Dc(x))∥ 2 2], (86) Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 18 Figure 5. The structure of LapGAN for (a) training and (b) test, i.e., sampling. where λ > 0 is the regularization parameter. Both terms depend on the autoencoder D while the ﬁrst term depends on the generator G. Some theoretical analysis of MMD GAN can be found in (Mroueh & Nguyen, 2021). 5.8. Additive GANs In the following, we introduce the additive GAN models which have a hierarchical or additive approach. 5.8.1. LAPLACIAN GAN (LAPGAN) Laplacian GAN (LapGAN) (Denton et al., 2015) was one of the ﬁrst extensions of GAN. It generates higher resolu- tion images compared to GAN and conditional GAN. In- spired by the Laplacian pyramid for image (Burt & Adel- son, 1983), LapGAN uses a Laplacian pyramid. The struc- ture of LapGAN for training is illustrated in Fig. 5-a. Let the pyramid have k levels. We start with the image itself at level zero, i.e., I = I0. We downsample the image to I1 by a factor of two, i.e., we halve the rows and columns of im- age. Then, we upsample I1 to l0 by a factor of two, where l0 is the low-pass (low-resolution) version of I0. We use a conditional GAN (Mirza & Osindero, 2014) (see Section 2.6), denoted by G0, which gets the noise z0 as its input noise and the low-pass l0 as its conditional input. The gen- erator generates ̃h0. Let h0 := I0 − l0. We input h0, ̃h0, and l0 to a discriminator D0 whose last layer is a neuron with sigmoid activation function. The discriminator judges whether the image at this level is a real or fake (generated). This procedure is repeated for other levels until the level (k − 1). In each of these levels, a conditional GAN is used. In the last level k, a GAN (not conditional) is used which gets the noise zk as input and generates ̃Ik. This ̃Ik and the downsampled Ik are input to a discriminator Dk which judges the image at that level. The test or sampling phase of the LapGAN is depicted in Fig. 5-b. Like the training phase, all levels except the last level k have conditional GANs while the last level has a GAN. At the j-th level, the noise zj and the low-pass image lj are fed to generator Gj as its input and conditional input, respectively. The generator generates ̃hj. The generated image at the j-th level is obtained as ̃Ij := ̃hj + lj. The generated image at the level zero, i.e. ̃I0, is the generated image by the LapGAN. 5.8.2. PROGRESSIVE GAN Progressive GAN (Karras et al., 2018) starts with shal- low networks for generator G and discriminator D and in- creases new layers progressively to the networks. Initially, a small convolutional layer with low spatial resolution ex- ists in G and D. This generates a low-resolution image. During training of GAN, we gradually add convolution lay- ers with higher spatial resolutions to G and D so higher resolution images are generated. Training GAN and adding layers occur simultaneously. 5.9. Triple GAN Triple GAN (Li et al., 2017a) has a discriminator D, a clas- siﬁer C, and a generator G. In terms of having a clas- siﬁer, it is similar to MGAN (Hoang et al., 2018) (see Section 3.5). The generator models conditional distribu- tion of data on the label, pg(x|y), and the classiﬁer mod- Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 19 els the opposite conditional distribution, i.e., pc(y|x). The discriminator judges whether the data-label pair (x, y) is real or generated (fake). The classiﬁer predicts class la- bel y for the real or generated data x. Let pdata(x, y) de- note the joint distribution of real data and labels. The joint distributions for data-labels in generator and classiﬁer are pg(x, y) = pg(x|y)p(y) and pc(x, y) = pc(x|y)p(y), re- spectively, where p(y) is the marginal distribution of la- bels. The generator gets noise z ∼ pz(z) and label y as input and generates a data point x = G(z, y), where (G(z, y), y) ∼ pg(x, y). Triple GAN optimizes the loss function for a three-player game: min G,C max D V (D, C, G) := E(x,y)∼pdata(x,y)[ log(D(x, y))] + αE(x,y)∼pc(x,y)[ log(1 − D(x, y))] + (1 − α)Ez∼pz(z),y∼p(y)[ log(1 − D(G(z, y), y))] + E(x,y)∼pdata(x,y)[−log(pc(y|x))] , (87) where α ∈ (0, 1) is the regularization parameter (α = 0.5 is recommended). The last term of loss, in which pc(y|x) is the predicted label by classiﬁer, models the KL-divergence between pc(x, y) and pdata(x, y). The discriminator, clas- siﬁer, and generator get stronger gradually by alternating optimization (Ghojogh et al., 2021c). Theorem 13 ((Li et al., 2017a, Lemma 3.1 and Theorem 3.3)). The optimal discriminator of triple GAN is: D∗(x, y) = p(x, y) p(x, y) + (1 − α)pg(x, y) + αpc(x, y) . (88) After convergence (i.e., Nash equilibrium) of triple GAN, we have: pg∗ (x, y) = pc∗ (x, y) = p(x, y) (88) =⇒ D∗(x, y) = 0.5. (89) 5.10. Latent Adversarial Generator (LAG) Latent Adversarial Generator (LAG) (Berthelot et al., 2020) can generate high-resolution images by taking a cor- responding low-resolution image as an input cue. In terms of getting a cue, it can be related to the conditional GAN (see Section 2.6). Let z, x, and ̃x denote the noise sam- ple, the real data point, and the cue low-resolution data point, respectively. The generator G takes ̃x and z as input and generates the high-resolution image G(̃x, z). The dis- criminator D has two parts. First, by a projection operator Π, it projects data onto a low-dimensional space, named the perceptual latent space. The operator Π is a nonlin- ear neural network and gets the high and low dimensional data points as input. Then, by some other layers of net- work, denoted by the mapping F (.), the projected data onto the perceptual latent space is mapped to a scalar after the sigmoid activation function. Hence, the discriminator is D(x) = F (Π(x, ̃x)). We want to have Π(G(̃x, z = 0), ̃x) be similar to Π(x, ̃x) so we use a regularization term for it. LAG uses WGAN (see Section 3.7) whose loss is regularized. We regularize Eq. (40) as: min G max ∥D∥L≤1 D(x, ̃x) − D(G(̃x, z), ̃x) − λ1(∇̂xD(̂x)∥2 − 1)2 + λ2∥Π(G(̃x, z = 0), ̃x) − Π(x, ̃x)∥ 2 F , (90) where λ1, λ2 > 0 are the regularization parameters, ∥.∥F is the Frobenius norm, and ̃x is deﬁned in Eq. (41). 5.11. Ensembles of GAN Models In the following, we introduce some GAN models which have an ensemble of generators and/or discriminators. Some of them were already introduced, such as MGAN (see Section 3.5) and D2GAN (see Section 3.6). Here, we explain other ensemble GAN methods. 5.11.1. GENERATIVE MULTI-ADVERSARIAL NETWORK (GMAN) Generative Multi-Adversarial Network (GMAN) (Du- rugkar et al., 2017) accelerates training of GAN by using several discriminators. Assume we have nd discriminators. The loss function of GMAN is: max Di V (Di, G), ∀i ∈ {1, . . . , nd}, (91) min G F (V (D1, G), . . . , V (Dnd, G)), (92) where every V (Di, G) is deﬁned in Eq. (3) and the func- tion F (.) can be an aggregating function such as F (.) = max(.) or F (.) = mean(.). If F (.) is the maximum func- tion, generator is trained using the best discriminator at ev- ery iteration of the alternating optimization. If F (.) is the mean function, an average effect of all discriminators are used for training the generator. 5.11.2. ADAGAN: BOOSTING GANS Boosting refers to using weak models additively where ev- ery next model gives more weight to the points which were not correctly classiﬁed/regressed by the previous model (Ghojogh & Crowley, 2019). One of the most well-known boosting methods for classiﬁcation and regression is Ad- aBoost (Freund & Schapire, 1997). AdaGAN (Tolstikhin et al., 2017) is boosting the GAN models for generation of data points. Let n be the number of data points. We start with the ﬁrst GAN where the weights of points are all 1/n. Let the generator of the j-th GAN be denoted by Gj. We have one discriminator D only as the classiﬁer whose scalar output after sigmoid activation function is D(x). For the j-th GAN model, we use a discriminator D to discrimi- nate between the true data and the generated data Gj−1(z) Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 20 Figure 6. The structure of CoGAN. where z is the latent noise. The weights of points are up- dated as: wi,j := 1 nβj [ λ − (1 − βj)h(D(xi))] +, (93) where wi,j is the weight of xi for the j-th GAN, [.]+ := max(., 0), βj := 1/j (or a ﬁxed number in range [0, 1]), h(D(x)) := (1 − D(x))/D(x), and λ is obtained by iter- atively updating: λ := βj ∑k i=1(1/n) (1 + 1 − βj βj k∑ i=1(1/n)h (D(xi) )), in which k is the iteration of iterative updating. The gener- ator of j-th weak GAN, G ′ t, is trained by the weighted data points using the updated weights in Eq. (93). Finally, the j-th GAN is computed to be the linear combination of G′ t and the previous GAN: Gj := (1 − βj)Gj−1 + βjG ′ t. The proofs for the above formulas can be found in (Tol- stikhin et al., 2017). 5.11.3. BOOSTED GENERATIVE MODEL (BGM) Another similar method for boosting GAN models is the Boosted Generative Model (BGM) (Grover & Ermon, 2018). We brieﬂy introduce its idea here. Again, it starts with equal weights, all 1/n, for the points. It trains the ﬁrst generative model G1. For the j-th GAN, it uses the lower bound of the f-divergence in Eq. (52) to estimate the next generative model based on the previous model. The for- mulation is inspired by the AdaBoost (Freund & Schapire, 1997). 5.12. Coupled GAN (CoGAN) Coupled GAN (CoGAN) (Liu & Tuzel, 2016) is a genera- tive model for several domains, where several data points are generated each of which has a different domain but the data points are related. For example, one domain can be image and another domain can be text where an image and a related caption can be generated. Another example is gen- eration of two related images but from different domains, such as facial and nature images. If the tuples of corre- sponding data points are available, CoGAN can learn to generate corresponding and related images from different domains; otherwise, it can generate not-necessarily-related data points from the domains. Assume we have two domains. In this case, CoGAN has two coupled GAN structures as illustrated in Fig. 6. Let G1/D1 and G2/D2 denote the generators/discriminators of the ﬁrst and second GAN structures, respectively. In a gen- erator, the ﬁrst and last layers of network extract high-level and low-level features, respectively (Liu & Tuzel, 2016). Conversely, in a discriminator, the ﬁrst and last layers of network extract low-level and high-level features, respec- tively (Krizhevsky et al., 2012). We want the GAN struc- tures to share their high-level features but their low-level features should differ for capturing each domain’s charac- teristics. Therefore, as shown in Fig. 6, the ﬁrst layers of generators and the last layers of discriminators are shared. Let the datasets of the ﬁrst and second domains be denoted by pdata1(x) and pdata2(x), respectively. The loss function of CoGAN is: min G1,G2 max D1,D2 V (D1, D2, G1, G2) := Ex∼pdata1(x)[ log(D(x) )] + Ez∼pz(z)[ log( 1 − D1(G1(z) ))], + Ex∼pdata2(x)[ log(D(x) )] + Ez∼pz(z)[ log( 1 − D2(G2(z) ))], (94) subject to the fact that some layers of the generators and some layers of discriminators are shared, as shown in Fig. 6. Note that, although the paper (Liu & Tuzel, 2016) has focused on coupling two GAN structures, the CoGAN can be easily extended to any number of structures and thus any number of domains. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 21 5.13. Inverse GAN Models We can invert generation of data points in GAN. This refers to generating a latent noise sample z from some data point x. This latent noise is corresponding to the point x in the sense that if it is fed to the generator, x is generated. Some existing methods for inverse in GAN are adversar- ial autoencoder, BiGAN, ALI, and inverse technique. The adversarial autoencoder will be introduced later in Section 8.1. The other methods are explained in the following. 5.13.1. BIDIRECTIONAL GAN (BIGAN) In GAN, the generator gets a latent noise z and generates data point x. However, the inverse of this process, i.e. out- putting a latent variable from the data point x, does not ex- ist in GAN. Bidirectional GAN (BiGAN) (Donahue et al., 2017) is a version of GAN which also includes this inverse. Its structure is depicted in Fig. 7. In BiGAN, the generator G gets the noise z as input and generates G(z). The en- coder E, as the inverse of G, gets x as input and outputs E(x). Recall that the discriminator of GAN gets the data x and the generated data G(z) as input (see Fig. 1). How- ever, the discriminator of BiGAN gets all G(z), z, E(x), and x as input and judges whether the generated data G(z) is real or generated (fake). It assigns label one to each pair (x, E(x)) and label zero to each pair (z, G(z)). The loss function of BiGAN is: min G,E max D V (D, G, E) := Ex∼pdata(x)[Ez∼pE (.|x)[ log(D(x, z)) ]] + Ez∼pz(z)[Ex∼pG(.|z)[ log(1 − D(x, z)) ]] = Ex∼pdata(x)[ log(D(x, E(x)))] + Ez∼pz(z)[ log( 1 − D(G(z), z))]. (95) We use alternating optimization (Ghojogh et al., 2021c) by alternating between optimizing for D, G, and E. Theorem 14 ((Donahue et al., 2017, Theorem 2)). After convergence (i.e., Nash equilibrium) of BiGAN, the optimal encoder E and generator G are inverse of each other: E∗ = (G ∗)−1, G ∗(E∗(x)) = x, E∗(G ∗(z)) = z. (96) 5.13.2. ADVERSARIALLY LEARNED INFERENCE (ALI) Adversarially Learned Inference (ALI) (Dumoulin et al., 2017) is one of the methods for having inverse in GAN. The generator G of ALI is an autoencoder whose encoder Gx(z) and decoder Gz(x) are called the generator network and the inference network, respectively. The generator net- work Gx(z) maps latent noise sample z to a generated data point ̃x := Gx(z). The inference network Gz(x) maps a data point x to its corresponding latent noise sam- Figure 7. The structure of BiGAN. ple ̃z := Gz(x). The discriminator D(x, z) tries to distin- guish the pairs (̃x, z) and (x, ̃z), obtained from the genera- tor and inference networks, respectively. The loss function of ALI is: min G max D Ex∼pdata(x)[ log(D(x, Gz(x))) ] + Ex∼pdata(x)[ log(1 − D(Gx(z), z))] . (97) 5.13.3. THE INVERSION TECHNIQUE Another approach for having inverse in GAN is the inver- sion technique (Creswell & Bharath, 2018). For this, after training a GAN model, we ﬁnd a noise sample which re- sults in the generated data point: max z E [ log(G(z))] + λ log(pz(z)), (98) where pz(z) is the desired prior distribution of latent space (e.g., N (0, I)) and λ > 0 is the regularization parameter. This optimization can be performed using gradient descent. 5.14. Self-Attention GAN (SAGAN) Attention mechanism (Vaswani et al., 2017) is weighting the features of data in a way that machine attends to the more important features by giving them larger weights (Ghojogh & Ghodsi, 2020). The weights are calculated by measuring the similarity of features with respect to each other using inner product. In self-attention, the similarities of features of every data point with other features of the same data point are calculated. These inner produces are implemented within the convolutional layers of network. Self-Attention GAN (SAGAN) (Zhang et al., 2019) uses self-attention mechanism in the networks of both generator and discriminator. For the mathematical details of atten- tion mechanism and SAGAN, refer to (Ghojogh & Ghodsi, 2020) and (Zhang et al., 2019), respectively. 5.15. Few-shot GAN Models In the following, we introduce the GAN models which learn from few number of training data points. 5.15.1. TRANSFER LEARNING IN GAN Consider a GAN (Gs, Ds) which is already trained on some data in a source domain. Few-shot GAN (Ojha et al., Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 22 2021a) can do transfer learning where the trained GAN on the source domain also generates images from another tar- get domain. In this method, we have an adapted genera- tor Gs→t which is aimed to generate data points from the target domain. As the target domain has few data points in few-shot learning, it is prone to overﬁtting (Ghojogh & Crowley, 2019). Hence, we try to preserve the pairwise similarities before and after adaptation. For this, we draw a mini-batch of (b+1) noise samples {zi} b+1 i=1 from the latent space. We feed these to the generators Gs and Gs→t. At the ℓ-th layer, we calculate: yℓ s,i := softmax(sim(G ℓ s(zi), G ℓ s(zj))), yℓ s→t,i := softmax(sim(G ℓ s→t(zi), G ℓ s→t(zj))), for all i ̸= j, i, j ∈ {1, . . . , b + 1} where sim(.) denotes the cosine similarity. We want the adapted generator to have similar distributions across layers; hence we deﬁne the loss: V (Gs→t, Gs) := Ezi∼pz(z)[ ∑ ℓ ∑ i KL(yℓ s→t,i∥yℓ s,i)] , where KL(.) denotes the KL-divergence. We then sample k number of random noises and call them the anchor points Zanchor. This anchor space is a subset of the whole latent space Z. We have two discriminators which are Dimage for judging the whole image and Dpatch for judging an image patch. Let: V (Dimage, Dpatch, Gs→t) := Ex∼Dt[ Ez∼Zanchor[Dimage(Gs→t(z)) − Dimage(ximage)] + Ez∼pz(z)[Dpatch(Gs→t(z)) − Dpatch(xpatch)] ] , where Dt denotes the target domain. The overall loos func- tion is: min Gs→t max Dimage,Dpatch V (Dimage, Dpatch, Gs→t) + λV (Gs→t, Gs), (99) where λ > 0 is the regularization parameter. In this loss, the ﬁrst term gives freedom to the structure of patches in the image and the second term takes care of transfer learning. 5.15.2. GAN WITH SINGLE IMAGE (SINGAN) GAN with Single Image (SinGAN) (Shaham et al., 2019) learns to generate images by being trained on one image only. It generates images which are all related texture-wise to the training image. It learns the distributions of patches within the image in different scales and uses multi-scale adversarial learning. In the sens of using multiple scales in a Laplacian pyramid, it is similar to the LapGAN (Denton et al., 2015) (see Section 5.8.1). Assume we have (k + 1) levels {0, . . . , k} in the Laplacian pyramid where the level 0 is the image itself and the image is downsampled in other levels. At every j-th level, we have a GAN (Gj, Dj). Training is from the k-th to the 0-th level. If zj is the latent noise at level j, the generations are: xk = Gk(zk), xj = Gj(zj, x ′ j+1), ∀j < k, where x ′ j+1 is the upsampled version of the generated im- age xj+1. The GANs are trained sequentially and the pre- viously trained GANs are kept ﬁxed while training the next GAN. The loss function is regularized by a reconstruction error to make the model generate better images. 5.16. Training Triplet Network with GAN A Siamese network (Bromley et al., 1993) is a network composed of multiple networks sharing their weights. If the number of networks is three, the Siamese network is a triplet network. Adversarial learning can be used for training a triplet network (Zieba & Wang, 2017). Consider triplets (xa, xp, xn) where xa is the anchor point, xp is the positive point having the same class as anchor, and xn is the negative point having a different class from anchor. For this, the loss function can be: min θ − log ( exp(∥xa − xp∥2 2) exp(∥xa − xp∥2 2) + exp(∥xa − xn∥2 2) ) − V (D, G), (100) where θ is the weights of network, the ﬁrst term is the Neighborhood Component Analysis (NCA) (Goldberger et al., 2004), and the second term is the adversarial loss function. Paper (Zieba & Wang, 2017) uses Eq. (85) for the discriminator D. 6. Sampling and Interpolation in GAN After training a GAN, we can generate new data points by sampling noise from the latent space and feeding it to the generator. There may exist two problems in sampling from the latent space (White, 2016). First, we should avoid sampling from the locations in the latent space which are highly unlikely. Secondly, as the latent space is usually high dimensional, there often exist some dead-zone loca- tions in the latent space which are not trained during the training (Makhzani et al., 2015). In the following, we in- troduce some techniques for sampling and interpolation in the latent space. Note that these techniques can also be used for other generative models such as variational autoencoder (Kingma & Welling, 2014; Ghojogh et al., 2021a). 6.1. Interpolation in the Latent Space For showing that the GAN model has not memorized the training data and the latent space is meaningful for the trained GAN, we can traverse different locations in the la- tent space and see what data points are generated from the Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 23 Figure 8. (a) Interpolation in the latent space of VAE trained on MNIST data (image is from https://blog.keras.io/ building-autoencoders-in-keras.html), (b) MINE for VAE trained on the CelebA dataset (Liu et al., 2015), (c) J-diagram by interpolation in the latent space of a GAN trained on the CelebA dataset, and (d) traversal along the smile vector for a GAN trained on the CelebA dataset (Image for (b), (c), and (d) are from (White, 2016)). sampled noises. Traversing different locations in the la- tent space with some step is usually called interpolation in the latent space. A problem with linear interpolation, which has ﬁxed step size, is that we traverse some highly unlikely priors. This can result in strange generated data points. Therefore, rather than the linear interpolation, we can use spherical linear interpolation (White, 2016), called slerp, to traverse a path on a p-dimensional hypersphere in the p-dimensional latent space. Assume we want to sample noises between locations z1 and z2 in the latent space. The interpolated locations are obtained as (Shoemake, 1985): slerp(z1, z2, µ) := sin((1 − µ)θ) sin(θ) z1 + sin(µθ) sin(θ) z2, (101) where µ is swept in range [0, 1] and θ := cos −1(z⊤ 1 z2). We can have generated data points from the sampled noises by interpolation in the latent space. If we do interpolation across two perpendicular axes in the latent space, we can put the generations in a two dimensional table An example for linear interpolation is shown in Fig. 8-a. Interpolation shows how the latent space is covering generation of var- ious data points and what the shared features are between data points. 6.2. Manifold Interpolated Neighbor Embedding Rather than reporting the generated data points from the sampled latent vectors in interpolation, we can ﬁnd the nearest neighbor of the generated point among the training data points. The nearest neighbors for the generated points are then shown in a two dimensional grid. This is called the Manifold Interpolated Neighbor Embedding (MINE) (White, 2016). An example grid for MINE is shown in Fig. 8-b. 6.3. Analogy and J-Diagram We can have vector arithmetic in the latent space (see Sec- tion 2.7.2). The vector arithmetic shows analogy relation between vectors. Let a, b, c, and d be the latent vectors as- sociated with four generated data points by the generator. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 24 We want to ﬁnd the vector d to satisfy the analogy relation: a : b :: c : d =⇒ (b − a) = (d − c). (102) In the natural language processing models, a famous anal- ogy relation is “man : king :: woman : queen” (Mikolov et al., 2013). J-diagram (White, 2016) is a J-shape dia- gram whose top left corner, top right corner, bottom left corner, and bottom right corner are the generated images for the source vector a, analogy target vector b, analogy target vector c, and the result vector d, respectively. The other images inside the diagram are obtained by linear or slerp interpolation between these vectors. This diagram shows how an image is obtained from another by chang- ing its features. An example J-diagram, for a GAN trained on the CelebA dataset (Liu et al., 2015), is shown in Fig. 8-c. As can be seen, moving along an axis changes some speciﬁc features of generated images. In this ﬁgure, the vertical axis takes care of gender and the horizontal axis is responsible for hair color, hair type, and facial pose. 6.4. Attribute Vector We can obtain attribute vectors for an embedding space as follows (White, 2016). For example, a smile vector (Larsen et al., 2016) can be obtained by subtracting the latent vector for a neutral face from the latent vector for the smiling face of the same person. The resulted vector can be considered as the latent vector for smiling. Other attribute vectors can be obtained similarly. An attribute vector can be used to change a neutral image to an image having that attribute. For example, we can add the smiling latent vector, denoted by zs ∈ Rp, to the latent vector of a (neutral) face, denoted by zn ∈ Rp, to obtain a new latent vector which results in generation of a smiling face of that person, after being fed to the generator. Let η ∈ R be the weight for smiling. The vector zn + ηzn is the latent vector for face with dif- ferent levels of smiling. A negative η makes a smiling face neutral. An example of traversal along the smile vector is shown in Fig. 8-d. 6.5. Evaluation of Generated Images Remark 3 (The Inception score (Salimans et al., 2016, Sec- tion 4)). A score, named the Inception score, can be used to assess the quality of generated images by GAN models. For this, we feed the generated images x to the Inception network (Szegedy et al., 2016) which outputs predicted la- bels p(y|x) where y is the label. On one hand, we desire this conditional label distribution to have low entropy. On the other hand, we want the generator to generate vari- ous images; hence, the marginal p(y) = ∫ p(y|x)dz for x = G(z) should be large. The Inception score combines these two as: Inception score = exp (Ex[ KL (p(y|x)∥p(y) )]) . (103) The higher this score, the more quality the generated image has. It has been observed that this score is very similar to human’s evaluation of the generated images (Salimans et al., 2016). Note that there exists another method for quantitative anal- ysis of GAN results (Wu et al., 2017) which is based on the annealed importance sampling (Neal, 2001). 7. Applications of GAN We already saw that GAN can be used for data generation for any data type such as image. In the following, we intro- duce some other applications of GAN. 7.1. Image-to-Image Translation by GAN There exist some methods, based on GAN, for image-to- image translation where an image is generated correspond- ing to an input image. The correspondence can be any re- lation in different applications. In the following, we intro- duce these methods. 7.1.1. PATCHGAN PatchGAN (Isola et al., 2017) uses conditional GAN (Mirza & Osindero, 2014) (see Section 2.6) with a regu- larized loss function. It uses ℓ1 norm between data and generated data for regularization because ℓ1 norm encour- ages less blurring compared to ℓ2 norm. The loss is: min G max D V ′ C(D, G) + λ Ex,z,y[ ∥x − G(z, y)∥1] , (104) where λ > 0 is the regularization parameter and V ′ C(D, G) is a slightly modiﬁed version of Eq. (22): V ′ C(D, G) := Ex,y[ log(D(x, y) )] + Ez,y[ log(1 − D(G(z, y), y))] , (105) in which x is the data, y is the label of data, and z ∼ pz(z) is the noise. The generator G takes the noise z and label y as input and generates data denoted by G(z, y). The discriminator takes the data point x and its label y as input. It judges whether the data point x is real or generated. For the generator G, PatchGAN uses skips or connections between every layer ℓ and layer (L − ℓ) where L is the number of layers. This is inspired by the structure of U- Net (Ronneberger et al., 2015). Moreover, the ℓ1 norm, used in Eq. (104), takes care of the low-frequency features of generated image (Isola et al., 2017). Therefore, the dis- criminator should take care of the high-frequency features. For this, the discriminator D classiﬁes the image patch- wise rather than the whole image. Every patch is judged to be whether it is real or generated (fake). We average the judgments of patches to have model averaging for classify- ing the whole image. This patch-wise classiﬁcation of an image models the image as a Markov random ﬁeld because Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 25 Figure 9. Image-to-image translation: (a) coloring a sketch, (b) changing daylight to night darkness in image, (c) changing an aerial image to a map, (d) coloring a black-and-white image, (e) transforming zebra to horse and vice versa, and (f) generating a facial image from a facial sketch. Transformations in (a), (b), (c), and (d) are by PatchGAN whose credits are for (Isola et al., 2017). Transformations in (e) and (f) are by CycleGAN (credit: (Zhu et al., 2017)) and DeepFaceDrawing (credit: (Chen et al., 2020)), respectively. it assumes that every patch of pixels is independent of other patches. The PatchGAN has been used for image-to-image transla- tion I1 7→ I2, i.e., translating image I1 to image I2. For this, we use x = I2, y = I1, and noise z ∼ pz(z) in Eqs. (104) and (105). In other words, the image I1 is used as the label in conditional GAN, while the image I2 is the data point. The generator takes I1 and noise as the input, then generates a generated I2. The discriminator takes I1 and I2 as input and judges whether I2 is a real translation of I1 or a generated translation. The generator and dis- criminator make each other stronger gradually. For training PatchGAN, we need a dataset with pairs of (I1, I2) images. Some results of PatchGAN are shown in Figs. 9-a to 9-d. 7.1.2. CYCLEGAN CycleGAN (Cycle-Consistent Generative Adversarial Net- works) (Zhu et al., 2017) is a method for image-to-image translation without the need to pairs of training images (in contrast to PatchGAN which needs pairs of images). Let the two domains of image translation be X and Y . In cycleGAN, we have two generators G : X → Y and F : Y → X. Two discriminators also exist; one is DX for judging images in X and F (Y ) and the other is DY for judging images in Y and G(X). Hence, we have two GAN losses: V (DY , G, X, Y ) := Ey∼pdata(y)[ log(DY (y) )] + Ex∼pdata(x)[ log(1 − DY (G(x)))] , V (DX , F, X, Y ) := Ex∼pdata(x)[ log(DX (x) )] + Ey∼pdata(y)[ log(1 − DX (F (y) ))] . We also deﬁne the following cycle consistency loss to have F (G(x)) ≈ x and G(F (y)) ≈ y: Vcyc(G, F ) := Ex∼pdata(x)[∥F (G(x)) − x∥1] + Ey∼pdata(y)[ ∥G(F (y)) − y∥1]. The overall loss function of CycleGAN is: min G,F max DX ,DY V (DY , G, X, Y ) + V (DX , F, X, Y ) + λVcyc(G, F ), (106) where λ > 0 is the regularization parameter. A result of CycleGAN is shown in Fig. 9-e. 7.1.3. DEEP FACE DRAWING DeepFaceDrawing (Chen et al., 2020) generates high- quality facial images from input sketches of faces. For training data, automatic sketches have been created using the Canny edge detection (Canny, 1986). DeepFaceDraw- ing has three modules. The ﬁrst one is the component em- bedding module which takes different facial patches as in- put and learns embedding vectors for them. Then, these vectors are fed to the feature mapping module which trans- form the embedding vectors to 2D facial features patches. These feature patches are then fed to the image synthesis module which is a conditional GAN (see Section 2.6), gen- erating facial images from the feature patches. A result of DeepFaceDrawing is shown in Fig. 9-f. 7.1.4. SIMULATED GAN (SIMGAN) Simulated GAN (SimGAN) (Shrivastava et al., 2017) is an unsupervised method for transforming simulated images to real-world images while preserving the annotation infor- mation of images, such as image landmarks and pose of image. This transformation is performed by a reﬁner R(.). Let yj’s, xi’s, and ̃xi’s denote the training unlabeled real- world images, the training simulated images, and the trans- formation of the training simulated images to real world, i.e., ̃xi = R(xi). In SimGAN, we train a discriminator D by minimizing the loss: min D − ∑ i log(D(̃xi)) − ∑ j log(1 − D(yj)), Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 26 so D generates labels close to one and zero for the real- world and simulated images, respectively. After the dis- criminator is trained, we use it in the loss function of re- ﬁner. The reﬁner acts like the generator in GAN so it tries to confuse the discriminator; hence, the loss of reﬁner is: min R − ∑ i log(1 − D(R(xi))) + λ ∥ψ(R(xi)) − ψ(xi)∥1, where λ > 0 is the regularization parameter, ψ(.) is a map- ping from the pixel space to a feature space, and the second term tries to minimize the reconstruction error in the fea- ture space. 7.1.5. INTERACTIVE GAN (IGAN) Interactive GAN (iGAN) (Zhu et al., 2016) allows users to edit the image interactively while the edited image remains realistic. In iGAN, we ﬁrst project the image onto the man- ifold of image. The manifold of image is the manifold of latent noise in GAN. This projection is done by ﬁnding the closest latent noise which can generate the image: z∗ := arg min z ∥G(z) − x∥2 2. In this sense, this projection is similar to the approach of inverse GAN models (see Section 5.13). Then, we edit the projected image, i.e., z∗, by different brushing and editing tools. Then, we add back the geometric and color changes to re-obtain the image, but edited this time. 7.2. Text-to-Image Generation There exist several methods for text-to-image generation where an image is generated from some descriptive cap- tion. Some of these methods are (Reed et al., 2016a;b; Zhang et al., 2017; Reed et al., 2017; Nguyen et al., 2017a; Zhang et al., 2018). Here, we introduce Stacked GAN (StackGAN) (Zhang et al., 2017) for text-to-image genera- tion. In StackGAN, we ﬁrst generate embedding of texts by a pre-trained autoencoder. Let the text and the embedding of text be denoted by t and ϕt, respectively. We have a stack of two stages of adversarial learning where the ﬁrst stage generates a low-resolution image by drawing merely the shapes and colors. The loss function of the ﬁrst stage is: min D E(x,t)∼pdata(x,t)[log(D(x, ϕt))] + Et∼pdata(t),z∼pz(z)[log(1 − D(G(z), ϕt))], (107) min G Et∼pdata(t),z∼pz(z)[log(1 − D(G(z), ϕt))] + λ KL(qz(z)∥pz(z)), (108) where qz(z) is the distribution of the latent code from the encoder of an autoencoder and pz(z) is the prior on the latent noise. The next stage takes the low-resolution gen- erated image from the ﬁrst stage, denoted by s, as well as Figure 10. Text-to-image translation by StackGAN. Images are from (Zhang et al., 2017). the text embedding as input and generates a high-resolution image. The adversarial loss of the second stage is the same as Eqs. (107) and (108) but it has G(s) rather than G(z) be- cause the low-resolution image is fed to its generator. Some results of StackGAN are shown in Fig. 10. An improved version of StackGAN is StackGAN++ (Zhang et al., 2018). 7.3. Mixing Image Characteristics 7.3.1. FINEGAN FineGAN (Singh et al., 2019) is an unsupervised GAN model which disentangles the features of the generated im- age to background, shape, and color/texture. For this, we have three separate latent noise samples, i.e., the back- ground code b, the parent code p, and the child code c, responsible for the background, shape, and color/texture, respectively. We assume we have nb, np, and nc un- known categories (classes) for the background, shape, and color/texture, respectively, which will be learned by the FineGAN. The priors for the latent codes are categorical distribution where the probability of every class is 1/nb, 1/np, and 1/nc, respectively. As every shape of some ob- ject may have several various textures in different images, we take np < nc. FineGAN generates an image hierarchically. It starts with generating the background. For training data, we use a pre- trained detector to detect the background patches. We also use a continuous latent code zb which controls the back- ground details within every category of background. The generator Gb takes both b and zb as input and Db is the dis- criminator for judging the generated background. We also use another discriminator D′ b which is a binary classiﬁer to two classes of foreground and background. This discrimi- nator is pre-trained by cross entropy on the background and Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 27 foreground patches. The loss of the background stage is: min Gb max Db Ex[log(Db(x))] + Eb,zb [log(1 − Db(Gb(b, zb)))] + λ Eb,zb [log(1 − D′ b(Gb(b, zb)))], (109) where λ > 0 is the regularization parameter. In the parent stage, we have two generators Gp,m and Gp,f generating the mask and initial texture of the object, respec- tively. A network Gp takes the categorical p and continu- ous zp as input and outputs z′ p which is the input code for Gp,m and Gp,f . The zp controls the initial texture. The two generations of Gp,m and Gp,f are glued together to obtain the shape of object with some initial texture, which we de- note by xp. Then, we stitch it to the background obtained before. If the discriminator of this stage is Dp, the loss of this stage maximizes the mutual information between p and xp as: max Dp,Gp,m,Gp,f Ep,zp [log(Dp(p|xp))]. (110) In the child stage, we have two generators Gc,m and Gc,f generating the mask and color/texture of the object, respec- tively. A network Gc takes c and z′ p as input and outputs z′ c which is the input code for Gc,m and Gc,f . The two generations of Gc,m and Gc,f are glued together to obtain the shape of object with color/texture, which we denote by xc. Then, we stitch it to xp, obtained before, to have the ﬁnal generated image xf . The loss of the background stage is: min Gc max Dc Ex[log(Db(x))] + Ec,p,zp [log(1 − Dc(xf ))] + max Dc,Gc,m,Gc,f Eb,zb [log(1 − D′ c(c|xc))], (111) where the ﬁrst two terms are for adversarial learning and the last term is for maximizing the mutual information. Some results of FineGAN are illustrated in Fig. 11-a. 7.3.2. MIXNMATCH MixNMatch (Li et al., 2020) is built upon FineGAN in- troduced in Section 7.3.1. It gives the user the opportu- nity to choose the background, shape, and color/texture from three pictures and it generates an image with the cho- sen characteristics. For this, we need an encoder network E(x) which gets three images for their background, shape, and color/texture characteristics and outputs the three latent codes b, p, and c. These codes are then fed to FineGAN. In MixNMatch, we use the idea of inverse in GAN (see Section 5.13) to have the input of the encoder and Fine- GAN networks. The input/output pair of encoder is (x ∼ pdata(x), ̃y = E(x)) where ̃y is the codes b, p, and c. The output/input pair of the FineGAN is (̃x = G(y), y ∼ pcode(y)) where G(.) denotes the FineGAN and pcode(y) Figure 11. Mixing image characteristics using GAN: (a) Generat- ing an image with background, shape, and color characteristics by FineGAN, (b) generating an image by borrowing its characteris- tics from three images using MixNMatch, and (c) generating an image by borrowing its characteristics from different domains us- ing improved MixNMatch. Images are from (Singh et al., 2019), (Li et al., 2020), and (Ojha et al., 2021b), respectively. is the prior distribution of the latent codes b, p, and c. We have a discriminator D which takes an image-code pair and judges whether it is the pair of encoder or the FineGAN. The loss of MixNMatch is: min G,E max D Ex∼pdata(x)[ Ẽy=E(x)[log(D(x, ̃y))] ] + Ey∼pcode(y)[ Ẽx=G(y)[log(1 − D(̃x, y))] ] . (112) MixNMatch lets the user choose image characteristics from the same domain and the generated image is from that do- main. An example result of MixNMatch is shown in Fig. 11-b. Recently, an improved version of MixNMatch (Ojha et al., 2021b) can take the characteristics from multiple do- mains and generate a new image having those characteris- tics. An example result of this version is also shown in Fig. 11-c. 7.4. Other Applications There are some other applications for GAN. One of the applications is inpainting some lost parts of image with GAN (Pathak et al., 2016). GAN learns to inpaint the lost part based on the available pixels in the image. A medical application of GAN is generating histopathology images which can give insight into cancer diagnosis from pathology whole slide images (Levine et al., 2020). GAN has also been used for NLP (Li et al., 2018; Wang et al., 2019), speech processing (Pascual et al., 2017; Sriram et al., 2018), network embedding (Dai et al., 2018), logic (Nagisetty et al., 2021), and sketch retrieval (Creswell & Bharath, 2016). Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 28 8. Autoencoders Based on Adversarial Learning Previously, variational Bayes was used in an autoen- coder setting to have variational autoencoder (Kingma & Welling, 2014; Ghojogh et al., 2021a). Likewise, ad- versarial learning can be used in an autoencoder setting (Makhzani, 2018b). Several adversarial-based autoen- coders exist which we introduce in the following. 8.1. Adversarial Autoencoder (AAE) 8.1.1. UNSUPERVISED AAE Adversarial Autoencoder (AAE) was proposed in (Makhzani et al., 2015). In contrast to variational autoen- coder (Kingma & Welling, 2014; Ghojogh et al., 2021a) which uses KL divergence and evidence lower bound, AAE uses adversarial learning for imposing a speciﬁc distribution on the latent variable in its coding layer. The structure of AAE is depicted in Fig. 12. Each of the blocks B1, B2, and B3 in this ﬁgure has several network layers with nonlinear activation functions. AAE has an encoder (i.e., block B1) and a decoder (i.e., block B2). The input of encoder is a real data point x ∈ Rd and the output of decoder is the reconstructed data point ̂x ∈ Rd. One of the low-dimensional middle layers is the latent (or code) layer, denoted by z ∈ Rp, where p ≪ d. The encoder and decoder model conditional distributions p(z|x) and p(x|z), respectively. Let the distribution of the latent variable in the autoencoder be denoted by q(z). This is the posterior distribution of latent variable. The blocks B1 and B3 are the generator G and discriminator D of adversarial network, respectively. We also have a prior distribution, denoted by p(z), on the latent variable which is chosen by the user. This prior distribution can be a p-dimensional normal distribution N (0, I), for example. The encoder of the autoencoder (i.e., block B1) is the generator G which generates the latent variable from the posterior distribution: G(x) = z ∼ q(z). (113) The discriminator D (i.e., block B3) has a single output neuron with sigmoid activation function. It classiﬁes the latent variable z to be a real latent variable from the prior distribution p(z) or a generated latent variable by the en- coder of autoencoder: D(z) := { 1 if z is real, i.e., z ∼ p(z) 0 if z is generated, i.e., z ∼ q(z). (114) As was explained, the block B1 is shared between the au- toencoder and the adversarial network. This adversarial learning makes both autoencoder and adversarial network stronger gradually because the autoencoder tries to gener- ate the latent variable which is very similar to the real la- tent variable from the prior distribution. In this way, it tries Figure 12. The structure of unsupervised AAE. to fool the discriminator. The discriminator, on the other hand, tries to become stronger not to be fooled by the en- coder of autoencoder. In AAE, we have alternating optimization (Ghojogh et al., 2021c) where reconstruction and regularization phases are repeated iteratively. In the reconstruction phase, the mean squared error is minimized between the data x and the re- constructed data ̂x. In the regularization phase, the dis- criminator and generator are updated using the GAN ap- proach. For each of these updates, we use stochastic gradi- ent descent (Ghojogh et al., 2021c) with backpropagation. Overall, the two phases are performed as: B′ 1, B(k+1) 2 := arg min B1,B2 ∥̂x − x∥2 2, (115)    B(k+1) 3 := B(k) 3 − η(k) ∂ ∂B3 (V (B3, B′ 1)), B(k+1) 1 := B′ 1 − η(k) ∂ ∂B1 (V (B(k+1) 3 , B1) ), (116) where B1 = G and B3 = D (see Fig. 12). Eq. (115) is the reconstruction phase and Eq. (116) is the regularization phase. 8.1.2. SAMPLING THE LATENT VARIABLE There are several approaches for sampling the latent vari- able z from the coding layer of autoencoder with poste- rior q(z). In the following, we explain these approaches (Makhzani et al., 2015): • Deterministic approach: the latent variable is the out- put of encoder directly, i.e., zi = B1(xi). The stochasticity in q(z) is in the distribution of dataset, pdata(x). • Gaussian posterior: this approach is similar to what we have in variational autoencoder (Kingma & Welling, 2014; Ghojogh et al., 2021a). The encoder outputs the mean µ and covariance Σ and the latent variable is sampled from the Gaussian distribution, i.e., zi ∼ N (µ(xi), Σ(xi)). The stochasticity in q(z) is in both pdata(x) and the Gaussian distribution as output of encoder. • Universal approximator posterior: we concatenate the data point x and some noise η, with a ﬁxed dis- Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 29 Figure 13. Two structures for supervised AAE. tribution such as Gaussian, as input to the encoder. Hence, the latent variable is zi = B1(xi, ηi) where ηi ∼ N (0, I). The stochasticity in q(z) is in both pdata(x) and the noise η. 8.1.3. SUPERVISED AAE We have two variants for supervised AAE (Makhzani et al., 2015) where the class labels are utilized. These two struc- tures are illustrated in Fig. 13. Let c denote the number of classes. In the ﬁrst variant, we feed the one-hot encoded label y ∈ Rc to the discriminator, i.e. block B3, by con- catenating it to the the latent variable z. In this way, the discriminator learns the label of point x as well as discrim- ination of real and generated latent variables. This makes the generator or the encoder to generate the latent variables corresponding to the label of point for fooling the discrim- inator. In the second variant of supervised AAE, the one-hot en- coded label y is fed to the decoder, i.e. block B2, by con- catenating it to the latent variable z. In this way, the de- coder learns to reconstruct the data point by using the label of point. This also makes the encoder, which is also the generator, generate the latent variable z based on the label of point. Hence, the discriminator also gets stronger for competing the generator, in adversarial learning. Note that the two variants can also be combined, i.e., we can feed the one-hot encoded label can be fed to both the discriminator and the decoder. 8.1.4. SEMI-SUPERVISED AAE Consider a partially labeled dataset. The labeled part of data has c number of classes. AAE can be used for semi- supervised learning with partially labeled dataset. The structure for semi-supervised AAE is depicted in Fig. 14. This structure includes an autoencoder (blocks B1 and B2), an adversarial learning for generating latent variable (blocks B1 and B3), and an adversarial learning for gener- ating class labels (blocks B1 and B4). The encoder gener- ates both label y ∈ Rc and latent variable z ∈ Rp. The last layer of encoder for label has softmax activation func- tion to output a c-dimensional vector whose entries sum to one (behaving as probability). The last layer of encoder for latent variable has linear activation function. It has three phases which are reconstruction, regularization, and semi-supervised classiﬁcation. In the reconstruction phase, we minimize the reconstruction error. The regu- larization phase trains the discriminator and generator for generating the latent variable z. The semi-supervised clas- siﬁcation phase generates the one-hot encoded class label y for the point x. If the point x has a label, we use its la- bel for training B1 and B4. However, if the point x does not have any label, we randomly sample a label y ∈ Rc from a categorical distribution, i.e., y ∼ Cat(y). This cat- egorical distribution gives a one-hot encoded vector where the prior probability of every class is estimated by the pro- portion of class’s population to the total number of labeled points. An iteration of the alternating optimization for semi-supervised learning is: B′ 1, B(k+1) 2 := arg min B1,B2 ∥̂x − x∥2 2, (117)    B(k+1) 3 := B(k) 3 − η(k) ∂ ∂B3 (Vz(B3, B′ 1)), B′′ 1 := B′ 1 − η(k) ∂ ∂B1 (Vz(B(k+1) 3 , B1) ), (118)    B(k+1) 4 := B(k) 4 − η(k) ∂ ∂B4 (Vy(B4, B′′ 1 ) ), B(k+1) 1 := B′′ 1 − η(k) ∂ ∂B1 (Vy(B(k+1) 4 , B1)), (119) where Vz(D, G) and Vy(D, G) are the loss functions de- ﬁned in Eq. (3) in which the generated variables are the latent variable z and the one-hot encoded label y, respec- tively. 8.1.5. UNSUPERVISED CLUSTERING WITH AAE We can use the structure of Fig. 14 for clustering but rather than the classes, we assume we have c number of clusters. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 30 Figure 14. The structure of semi-supervised AAE. Figure 15. The structure of AAE for dimensionality reduction. We do not have a partially labeled part of dataset. All points are unlabeled and the cluster indices are sampled randomly by the categorical distribution. The cluster labels and the latent code are both trained in the three phases which were explained in Section 8.1.4. 8.1.6. DIMENSIONALITY REDUCTION WITH AAE The AAE can be used for dimensionality reduction and rep- resentation learning. The structure of AAE for this purpose is depicted in Fig. 15. The encoder generates both label y ∈ Rc and latent variable z ∈ Rp where p ≪ d. Ev- erything is similar to what we had before but a network layer W ∈ Rc×p is added after the generated label by the encoder. The low-dimensional representation ̃x ∈ Rp is obtained as: Rp ∋ ̃x = W ⊤y + z, (120) where z is the latent variable generated by the encoder. The three phases explained in Section 8.1.4 trains the AAE for dimensionality reduction. Figure 16. The structure of PixelGAN. 8.2. PixelGAN Autoencoder In variational inference (Ghojogh et al., 2021a), the Evi- dence Lower Bound (ELBO) can be restated as (Hoffman & Johnson, 2016): Ex∼pdata(x)[log(p(x))] > − Ex∼pdata(x)[Eq(z|x)[− log(p(x|z))]] − KL(q(z)∥p(z)) − I(z; x), (121) where I(.; .) denotes the mutual information. The ﬁrst and second terms in this lower bound are the reconstruction er- ror and the marginal KL divergence on the latent space. The PixelGAN autoencoder (Makhzani & Frey, 2017) uses this lower bound but ignores its third term which is the mu- tual information because optimization of that term makes z be independent of x. The reconstruction error is minimized in a reconstruction phase of training and the KL divergence part is taken care of by an adversarial learning. The structure of PixelGAN is shown in Fig. 16. The block B1 is the encoder which gets the data point x added with some noise n as input and outputs the latent code z ∼ q(z|x). The block B2 is the decoder which is a Pix- elCNN network (Oord et al., 2016) from which PixelGAN has borrowed its name. This decoder outputs the recon- structed data ̂x. The generated latent code z is used as the adaptive biases of layers in the PixelCNN. The blocks B1 and B3 are the generator and discriminator of adversarial learning, respectively, where we try to make the distribu- tion of the generated latent code z similar to some prior distribution p(z). In summary, blocks B1 and B2 are used for the reconstruction phase and blocks B1 and B3 are used for the adversarial learning phase. 8.3. Implicit Autoencoder (IAE) In variational inference (Ghojogh et al., 2021a), the Evi- dence Lower Bound (ELBO) can be restated as (Makhzani, 2018a): Ex∼pdata(x)[log(p(x))] ≥ − KL(q(x, z)∥q(̂x, z)) − KL(q(z)∥p(z)) − Hdata(x), (122) Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 31 Figure 17. The structure of IAE. where Hdata(x) is the entropy of data, ̂x is the reconstructed data, and z is some latent factor. The proof is straightfor- ward and can be found in (Makhzani, 2018a, Appendix A). The ﬁrst and second terms are the reconstruction and reg- ularization terms, respectively. The Implicit Autoencoder (IAE) (Makhzani, 2018a) implements the above distribu- tions in Eq. (122), implicitly using networks. The structure of IAE is shown in Fig. 17. The block B1 is the encoder which takes data x and noise n1 as input and outputs the latent code z ∼ q(z). The block B2 takes the generated la- tent code z as well as some noise n2 and outputs the recon- structed data ̂x. The blocks B1 and B3 are the generator G1 and discriminator D1 of the ﬁrst adversarial learning used for making the distribution of latent code z similar to some prior distribution p(z). The blocks B1 and B4 are the gen- erator G2 and discriminator D2 of the second adversarial learning used for making the distribution of reconstructed data ̂x similar to data x. The inputs of B4 are the pairs (x, z) and (̂x, z) to model the distributions q(x, z) and q(̂x, z) in Eq. (122). In summary, three phases of train- ing are performed which are the reconstruction phase and the two adversarial learning phases. 9. Conclusion This was a tutorial and survey paper on GAN, adversarial learning, adversarial autoencoder, and their variants. We covered various aspects and theories of the methods as well as applications of GAN. References Arjovsky, Martin and Bottou, L´eon. Towards principled methods for training generative adversarial networks. In International Conference on Machine Learning, 2017. Arjovsky, Martin, Chintala, Soumith, and Bottou, L´eon. Wasserstein generative adversarial networks. In Inter- national conference on machine learning, pp. 214–223, 2017. Arora, Sanjeev, Ge, Rong, Liang, Yingyu, Ma, Tengyu, and Zhang, Yi. Generalization and equilibrium in generative adversarial nets (GANs). In International Conference on Machine Learning, pp. 224–232, 2017. Berthelot, David, Milanfar, Peyman, and Goodfellow, Ian. Creating high resolution images with a latent adversarial generator. arXiv preprint arXiv:2003.02365, 2020. Bourgain, Jean. On Lipschitz embedding of ﬁnite metric spaces in Hilbert space. Israel Journal of Mathematics, 52(1-2):46–52, 1985. Bromley, Jane, Bentz, James W, Bottou, L´eon, Guyon, Isabelle, LeCun, Yann, Moore, Cliff, S¨ackinger, Ed- uard, and Shah, Roopak. Signature veriﬁcation us- ing a “siamese” time delay neural network. Interna- tional Journal of Pattern Recognition and Artiﬁcial In- telligence, 7(04):669–688, 1993. Burt, Peter J and Adelson, Edward H. The Laplacian pyra- mid as a compact image code. IEEE Transactions on Communications, 31(4):532–540, 1983. Canny, John. A computational approach to edge detection. IEEE Transactions on pattern analysis and machine in- telligence, (6):679–698, 1986. Chen, Shu-Yu, Su, Wanchao, Gao, Lin, Xia, Shihong, and Fu, Hongbo. DeepFaceDrawing: Deep generation of face images from sketches. ACM Transactions on Graphics (TOG), 39(4):72–1, 2020. Chen, Xi, Duan, Yan, Houthooft, Rein, Schulman, John, Sutskever, Ilya, and Abbeel, Pieter. InfoGAN: Inter- pretable representation learning by information maxi- mizing generative adversarial nets. In Proceedings of the 30th International Conference on Neural Informa- tion Processing Systems, pp. 2180–2188, 2016. Chien, Jen-Tzung and Kuo, Chun-Lin. Variational Bayesian GAN. In 2019 27th European Signal Process- ing Conference (EUSIPCO), pp. 1–5. IEEE, 2019. Creswell, Antonia and Bharath, Anil Anthony. Adversarial training for sketch retrieval. In European Conference on Computer Vision, pp. 798–809. Springer, 2016. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 32 Creswell, Antonia and Bharath, Anil Anthony. Inverting the generator of a generative adversarial network. IEEE transactions on neural networks and learning systems, 30(7):1967–1974, 2018. Creswell, Antonia, White, Tom, Dumoulin, Vincent, Arulkumaran, Kai, Sengupta, Biswa, and Bharath, Anil A. Generative adversarial networks: An overview. IEEE Signal Processing Magazine, 35(1):53–65, 2018. Dai, Quanyu, Li, Qiang, Tang, Jian, and Wang, Dan. Ad- versarial network embedding. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 32, 2018. Denton, Emily, Chintala, Soumith, Szlam, Arthur, and Fer- gus, Rob. Deep generative image models using a lapla- cian pyramid of adversarial networks. arXiv preprint arXiv:1506.05751, 2015. Donahue, Jeff, Kr¨ahenb¨uhl, Philipp, and Darrell, Trevor. Adversarial feature learning. In International Confer- ence on Learning Representations, 2017. Du, Ding-Zhu and Pardalos, Panos M. Minimax and appli- cations, volume 4. Springer Science & Business Media, 2013. Dumoulin, Vincent, Belghazi, Ishmael, Poole, Ben, Mas- tropietro, Olivier, Lamb, Alex, Arjovsky, Martin, and Courville, Aaron. Adversarially learned inference. In International Conference on Learning Representations, 2017. Durugkar, Ishan, Gemp, Ian, and Mahadevan, Sridhar. Generative multi-adversarial networks. In International Conference on Learning Representations, 2017. Farnia, Farzan and Ozdaglar, Asuman. Do GANs always have Nash equilibria? In International Conference on Machine Learning, pp. 3029–3039, 2020. Farnia, Farzan and Tse, David. A convex duality frame- work for GANs. In Advances in neural information pro- cessing systems, volume 31, 2018. Freund, Yoav and Schapire, Robert E. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55 (1):119–139, 1997. Ghojogh, Benyamin and Crowley, Mark. The the- ory behind overﬁtting, cross validation, regulariza- tion, bagging, and boosting: tutorial. arXiv preprint arXiv:1905.12787, 2019. Ghojogh, Benyamin and Ghodsi, Ali. Attention mecha- nism, transformers, BERT, and GPT: Tutorial and sur- vey. 2020. Ghojogh, Benyamin, Ghojogh, Aydin, Crowley, Mark, and Karray, Fakhri. Fitting a mixture distribution to data: tutorial. arXiv preprint arXiv:1901.06708, 2019. Ghojogh, Benyamin, Nekoei, Hadi, Ghojogh, Aydin, Kar- ray, Fakhri, and Crowley, Mark. Sampling algorithms, from survey sampling to Monte Carlo methods: Tutorial and literature review. arXiv preprint arXiv:2011.00901, 2020. Ghojogh, Benyamin, Ghodsi, Ali, Karray, Fakhri, and Crowley, Mark. Factor analysis, probabilistic princi- pal component analysis, variational inference, and vari- ational autoencoder: Tutorial and survey. arXiv preprint arXiv:2101.00734, 2021a. Ghojogh, Benyamin, Ghodsi, Ali, Karray, Fakhri, and Crowley, Mark. Johnson-Lindenstrauss lemma, linear and nonlinear random projections, random Fourier fea- tures, and random kitchen sinks: Tutorial and survey. arXiv preprint arXiv:2108.04172, 2021b. Ghojogh, Benyamin, Ghodsi, Ali, Karray, Fakhri, and Crowley, Mark. KKT conditions, ﬁrst-order and second- order optimization, and distributed optimization: Tu- torial and survey. arXiv preprint arXiv:2110.01858, 2021c. Ghojogh, Benyamin, Ghodsi, Ali, Karray, Fakhri, and Crowley, Mark. Reproducing kernel Hilbert space, Mer- cer’s theorem, eigenfunctions, Nystr¨om method, and use of kernels in machine learning: Tutorial and survey. arXiv preprint arXiv:2106.08443, 2021d. Goldberger, Jacob, Hinton, Geoffrey E, Roweis, Sam, and Salakhutdinov, Russ R. Neighbourhood components analysis. Advances in neural information processing sys- tems, 17, 2004. Gonog, Liang and Zhou, Yimin. A review: Generative ad- versarial networks. In 2019 14th IEEE Conference on In- dustrial Electronics and Applications (ICIEA), pp. 505– 510. IEEE, 2019. Goodfellow, Ian. On distinguishability criteria for estimat- ing generative models. In International Conference on Learning Representations, Workshop track, 2015. Goodfellow, Ian. NIPS 2016 tutorial: Generative adversar- ial networks. In Advances in neural information process- ing systems, Tutorial rack, 2016. Goodfellow, Ian, Warde-Farley, David, Mirza, Mehdi, Courville, Aaron, and Bengio, Yoshua. Maxout net- works. In International conference on machine learning, pp. 1319–1327, 2013. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 33 Goodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley, David, Ozair, Sherjil, Courville, Aaron, and Bengio, Yoshua. Generative adversarial nets. In Advances in neural information processing systems, volume 27, 2014. Goodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley, David, Ozair, Sherjil, Courville, Aaron, and Bengio, Yoshua. Generative adversarial net- works. Communications of the ACM, 63(11):139–144, 2020. Gregor, Karol, Danihelka, Ivo, Graves, Alex, Rezende, Danilo, and Wierstra, Daan. DRAW: A recurrent neural network for image generation. In International Confer- ence on Machine Learning, pp. 1462–1471, 2015. Gretton, Arthur, Borgwardt, Karsten, Rasch, Malte, Sch¨olkopf, Bernhard, and Smola, Alex. A kernel method for the two-sample-problem. Advances in neural infor- mation processing systems, 19:513–520, 2006. Grover, Aditya and Ermon, Stefano. Boosted generative models. In Proceedings of the AAAI Conference on Ar- tiﬁcial Intelligence, volume 32, 2018. Gulrajani, Ishaan, Ahmed, Faruk, Arjovsky, Martin, Du- moulin, Vincent, and Courville, Aaron. Improved train- ing of Wasserstein GANs. In Advances in neural infor- mation processing systems, 2017. Gutmann, Michael and Hyv¨arinen, Aapo. Noise- contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of the thirteenth international conference on artiﬁcial intelli- gence and statistics, pp. 297–304. JMLR Workshop and Conference Proceedings, 2010. Hazan, Tamir, Papandreou, George, and Tarlow, Daniel. Adversarial perturbations of deep neural networks. 2017. Hoang, Quan, Nguyen, Tu Dinh, Le, Trung, and Phung, Dinh. MGAN: Training generative adversarial nets with multiple generators. In International Conference on Learning Representations, 2018. Hoffman, Matthew D and Johnson, Matthew J. ELBO surgery: yet another way to carve up the variational evi- dence lower bound. In Workshop in Advances in Approx- imate Bayesian Inference, NIPS, 2016. Hong, Yongjun, Hwang, Uiwon, Yoo, Jaeyoon, and Yoon, Sungroh. How generative adversarial networks and their variants work: An overview. ACM Computing Surveys (CSUR), 52(1):1–43, 2019. Huang, Ling, Joseph, Anthony D, Nelson, Blaine, Rubin- stein, Benjamin IP, and Tygar, J Doug. Adversarial ma- chine learning. In Proceedings of the 4th ACM workshop on Security and artiﬁcial intelligence, pp. 43–58, 2011. Husz´ar, Ferenc. How (not) to train your generative model: Scheduled sampling, likelihood, adversary? arXiv preprint arXiv:1511.05101, 2015. Im, Daniel Jiwoong, Kim, Chris Dongjoo, Jiang, Hui, and Memisevic, Roland. Generating images with recurrent adversarial networks. arXiv preprint arXiv:1602.05110, 2016. Ioffe, Sergey and Szegedy, Christian. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning, pp. 448–456, 2015. Isola, Phillip, Zhu, Jun-Yan, Zhou, Tinghui, and Efros, Alexei A. Image-to-image translation with conditional adversarial networks. In Proceedings of the IEEE con- ference on computer vision and pattern recognition, pp. 1125–1134, 2017. Johnson, William B and Lindenstrauss, Joram. Extensions of Lipschitz mappings into a Hilbert space. Contempo- rary mathematics, 26, 1984. Karras, Tero, Aila, Timo, Laine, Samuli, and Lehtinen, Jaakko. Progressive growing of GANs for improved quality, stability, and variation. In International Con- ference on Learning Representations, 2018. Kingma, Diederik P and Welling, Max. Auto-encoding variational Bayes. In International Conference on Learning Representations, 2014. Krizhevsky, Alex, Sutskever, Ilya, and Hinton, Geoffrey E. Imagenet classiﬁcation with deep convolutional neural networks. Advances in neural information processing systems, 25:1097–1105, 2012. Kurakin, Alexey, Goodfellow, Ian, and Bengio, Samy. Ad- versarial machine learning at scale. In International Conference on Learning Representations, 2017a. Kurakin, Alexey, Goodfellow, Ian, Bengio, Samy, et al. Adversarial examples in the physical world. In Interna- tional Conference on Learning Representations, Work- shop Track, 2017b. Larsen, Anders Boesen Lindbo, Sønderby, Søren Kaae, Larochelle, Hugo, and Winther, Ole. Autoencoding be- yond pixels using a learned similarity metric. In Interna- tional conference on machine learning, pp. 1558–1566, 2016. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 34 LeCun, Yann, Chopra, Sumit, Hadsell, Raia, Ranzato, M, and Huang, F. A tutorial on energy-based learning. Pre- dicting Structured Data, 1, 2006. Levine, Adrian B, Peng, Jason, Farnell, David, Nursey, Mitchell, Wang, Yiping, Naso, Julia R, Ren, Hezhen, Farahani, Hossein, Chen, Colin, Chiu, Derek, et al. Syn- thesis of diagnostic quality cancer pathology images by generative adversarial networks. The Journal of pathol- ogy, 252(2):178–188, 2020. Li, Changliang, Su, Yixin, and Liu, Wenju. Text-to-text generative adversarial networks. In 2018 International Joint Conference on Neural Networks (IJCNN), pp. 1–7. IEEE, 2018. Li, Chongxuan, Xu, Kun, Zhu, Jun, and Zhang, Bo. Triple generative adversarial nets. In Advances in neural infor- mation processing systems, 2017a. Li, Chun-Liang, Chang, Wei-Cheng, Cheng, Yu, Yang, Yiming, and P´oczos, Barnab´as. MMD GAN: Towards deeper understanding of moment matching network. In Advances in neural information processing systems, 2017b. Li, Yuheng, Singh, Krishna Kumar, Ojha, Utkarsh, and Lee, Yong Jae. MixNMatch: Multifactor disentangle- ment and encoding for conditional image generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8039–8048, 2020. Li, Yujia, Swersky, Kevin, and Zemel, Rich. Genera- tive moment matching networks. In International Con- ference on Machine Learning, pp. 1718–1727. PMLR, 2015. Liese, Friedrich and Vajda, Igor. On divergences and in- formations in statistics and information theory. IEEE Transactions on Information Theory, 52(10):4394–4412, 2006. Liu, Ming-Yu and Tuzel, Oncel. Coupled generative ad- versarial networks. Advances in neural information pro- cessing systems, 29:469–477, 2016. Liu, Ziwei, Luo, Ping, Wang, Xiaogang, and Tang, Xiaoou. Deep learning face attributes in the wild. In Proceedings of the IEEE international conference on computer vision, pp. 3730–3738, 2015. Madry, Aleksander, Makelov, Aleksandar, Schmidt, Lud- wig, Tsipras, Dimitris, and Vladu, Adrian. Towards deep learning models resistant to adversarial attacks. In Inter- national Conference on Learning Representations, 2018. Makhzani, Alireza. Implicit autoencoders. arXiv preprint arXiv:1805.09804, 2018a. Makhzani, Alireza. Unsupervised representation learning with autoencoders. PhD thesis, University of Toronto, 2018b. Makhzani, Alireza and Frey, Brendan. PixelGAN autoen- coders. In Advances in neural information processing systems, 2017. Makhzani, Alireza, Shlens, Jonathon, Jaitly, Navdeep, Goodfellow, Ian, and Frey, Brendan. Adversarial autoen- coders. arXiv preprint arXiv:1511.05644, 2015. Mao, Xudong, Li, Qing, Xie, Haoran, Lau, Raymond YK, Wang, Zhen, and Paul Smolley, Stephen. Least squares generative adversarial networks. In Proceedings of the IEEE international conference on computer vision, pp. 2794–2802, 2017. Mao, Xudong, Li, Qing, Xie, Haoran, Lau, Raymond YK, Wang, Zhen, and Smolley, Stephen Paul. On the effec- tiveness of least squares generative adversarial networks. IEEE Transactions on Pattern Analysis & Machine Intel- ligence, 41(12):2947–2960, 2019. Mescheder, Lars, Nowozin, Sebastian, and Geiger, An- dreas. Adversarial variational Bayes: Unifying varia- tional autoencoders and generative adversarial networks. In International Conference on Machine Learning, pp. 2391–2400, 2017a. Mescheder, Lars, Nowozin, Sebastian, and Geiger, An- dreas. The numerics of GANs. In Advances in neural information processing systems, 2017b. Mescheder, Lars, Geiger, Andreas, and Nowozin, Sebas- tian. Which training methods for GANs do actually con- verge? In International conference on machine learning, pp. 3481–3490. PMLR, 2018. Metz, Luke, Poole, Ben, Pfau, David, and Sohl-Dickstein, Jascha. Unrolled generative adversarial networks. In International Conference on Learning Representations, 2017. Mikolov, Tomas, Sutskever, Ilya, Chen, Kai, Corrado, Greg S, and Dean, Jeff. Distributed representations of words and phrases and their compositionality. In Ad- vances in neural information processing systems, pp. 3111–3119, 2013. Mirza, Mehdi and Osindero, Simon. Conditional genera- tive adversarial nets. arXiv preprint arXiv:1411.1784, 2014. Moosavi-Dezfooli, Seyed-Mohsen, Fawzi, Alhussein, and Frossard, Pascal. DeepFool: a simple and accurate method to fool deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2574–2582, 2016. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 35 Mordvintsev, Alexander, Olah, Christopher, and Tyka, Mike. Inceptionism: Going deeper into neural networks. Google AI Blog, 2015. Mroueh, Youssef and Nguyen, Truyen. On the convergence of gradient descent in GANs: MMD GAN as a gradient ﬂow. In International Conference on Artiﬁcial Intelli- gence and Statistics, pp. 1720–1728, 2021. Nagarajan, Vaishnavh and Kolter, J Zico. Gradient descent GAN optimization is locally stable. In Advances in neu- ral information processing systems, 2017. Nagisetty, Vineel, Graves, Laura, Scott, Joseph, and Ganesh, Vijay. xAI-GAN: Enhancing generative adver- sarial networks via explainable AI systems. 2021. Nair, Vinod and Hinton, Geoffrey E. Rectiﬁed linear units improve restricted Boltzmann machines. In Interna- tional Conference on Machine Learning, 2010. Neal, Radford M. Annealed importance sampling. Statis- tics and computing, 11(2):125–139, 2001. Ng, Andrew Y and Jordan, Michael I. On discriminative vs. generative classiﬁers: A comparison of logistic re- gression and naive Bayes. In Advances in neural infor- mation processing systems, pp. 841–848, 2002. Nguyen, Anh, Clune, Jeff, Bengio, Yoshua, Dosovitskiy, Alexey, and Yosinski, Jason. Plug & play generative networks: Conditional iterative generation of images in latent space. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4467– 4477, 2017a. Nguyen, Tu Dinh, Le, Trung, Vu, Hung, and Phung, Dinh. Dual discriminator generative adversarial nets. Advances in neural information processing systems, 2017b. Nguyen, XuanLong, Wainwright, Martin J, and Jordan, Michael I. Estimating divergence functionals and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory, 56(11):5847–5861, 2010. Nielsen, Frank. A family of statistical symmetric diver- gences based on Jensen’s inequality. arXiv preprint arXiv:1009.4004, 2010. Nowozin, Sebastian, Cseke, Botond, and Tomioka, Ry- ota. f-GAN: Training generative neural samplers using variational divergence minimization. In Proceedings of the 30th International Conference on Neural Informa- tion Processing Systems, pp. 271–279, 2016. Odena, Augustus. Semi-supervised learning with genera- tive adversarial networks. In International conference on machine learning, Data Efﬁcient Machine Learning workshop, 2016. Ojha, Utkarsh, Li, Yijun, Lu, Jingwan, Efros, Alexei A, Lee, Yong Jae, Shechtman, Eli, and Zhang, Richard. Few-shot image generation via cross-domain correspon- dence. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10743– 10752, 2021a. Ojha, Utkarsh, Singh, Krishna Kumar, and Lee, Yong Jae. Generating furry cars: Disentangling object shape & ap- pearance across multiple domains. In International Con- ference on Learning Representations, 2021b. Oliehoek, Frans A, Savani, Rahul, Gallego-Posada, Jose, Van der Pol, Elise, De Jong, Edwin D, and Groß, Roderich. GANGs: Generative adversarial network games. arXiv preprint arXiv:1712.00679, 2017. Oord, Aaron van den, Kalchbrenner, Nal, Vinyals, Oriol, Espeholt, Lasse, Graves, Alex, and Kavukcuoglu, Koray. Conditional image generation with PixelCNN decoders. In Advances in neural information processing systems, pp. 4790–4798, 2016. Pan, Zhaoqing, Yu, Weijie, Yi, Xiaokai, Khan, Asifullah, Yuan, Feng, and Zheng, Yuhui. Recent progress on gen- erative adversarial networks (GANs): A survey. IEEE Access, 7:36322–36333, 2019. Pascual, Santiago, Bonafonte, Antonio, and Serra, Joan. SEGAN: Speech enhancement generative adversarial network. In Conference of the International Speech Communication Association (INTERSPEECH), 2017. Pathak, Deepak, Krahenbuhl, Philipp, Donahue, Jeff, Dar- rell, Trevor, and Efros, Alexei A. Context encoders: Fea- ture learning by inpainting. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2536–2544, 2016. Radford, Alec, Metz, Luke, and Chintala, Soumith. Unsu- pervised representation learning with deep convolutional generative adversarial networks. In International Con- ference on Learning Representations, 2016. Reed, Scott, Akata, Zeynep, Mohan, Santosh, Tenka, Samuel, Schiele, Bernt, and Lee, Honglak. Learning what and where to draw. Advances in neural informa- tion processing systems, 29:217–225, 2016a. Reed, Scott, Akata, Zeynep, Yan, Xinchen, Logeswaran, Lajanugen, Schiele, Bernt, and Lee, Honglak. Gener- ative adversarial text to image synthesis. In Interna- tional Conference on Machine Learning, pp. 1060–1069, 2016b. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 36 Reed, Scott, van den Oord, A¨aron, Kalchbrenner, Nal, Bapst, Victor, Botvinick, Matt, and De Freitas, Nando. Generating interpretable images with controllable struc- ture. In International Conference on Learning Represen- tations, Workshop track, 2017. Ronneberger, Olaf, Fischer, Philipp, and Brox, Thomas. U- net: Convolutional networks for biomedical image seg- mentation. In International Conference on Medical im- age computing and computer-assisted intervention, pp. 234–241. Springer, 2015. Saatci, Yunus and Wilson, Andrew. Bayesian GAN. In Advances in neural information processing systems, pp. 3624–3633, 2017. Salimans, Tim, Goodfellow, Ian, Zaremba, Wojciech, Che- ung, Vicki, Radford, Alec, and Chen, Xi. Improved tech- niques for training GANs. Advances in neural informa- tion processing systems, 29:2234–2242, 2016. Shaham, Tamar Rott, Dekel, Tali, and Michaeli, Tomer. SinGAN: Learning a generative model from a single nat- ural image. In Proceedings of the IEEE/CVF Interna- tional Conference on Computer Vision, pp. 4570–4580, 2019. Shoemake, Ken. Animating rotation with quaternion curves. In Proceedings of the 12th annual conference on Computer graphics and interactive techniques, pp. 245– 254, 1985. Shrivastava, Ashish, Pﬁster, Tomas, Tuzel, Oncel, Susskind, Joshua, Wang, Wenda, and Webb, Rus- sell. Learning from simulated and unsupervised images through adversarial training. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2107–2116, 2017. Singh, Krishna Kumar, Ojha, Utkarsh, and Lee, Yong Jae. FineGAN: Unsupervised hierarchical disentanglement for ﬁne-grained object generation and discovery. In Pro- ceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition, pp. 6490–6499, 2019. Springenberg, Jost Tobias. Unsupervised and semi- supervised learning with categorical generative adversar- ial networks. In International Conference on Learning Representations, 2016. Springenberg, Jost Tobias, Dosovitskiy, Alexey, Brox, Thomas, and Riedmiller, Martin. Striving for simplicity: The all convolutional net. In International Conference on Learning Representations, Workshop Track, 2015. Sriram, Anuroop, Jun, Heewoo, Gaur, Yashesh, and Satheesh, Sanjeev. Robust speech recognition using gen- erative adversarial networks. In 2018 IEEE international conference on acoustics, speech and signal processing (ICASSP), pp. 5639–5643. IEEE, 2018. Szegedy, Christian, Vanhoucke, Vincent, Ioffe, Sergey, Shlens, Jon, and Wojna, Zbigniew. Rethinking the in- ception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2818–2826, 2016. Tembine, Hamidou. Deep learning meets game theory: Bregman-based algorithms for interactive deep genera- tive adversarial networks. IEEE transactions on cyber- netics, 50(3):1132–1145, 2019. Theis, Lucas, Oord, A¨aron van den, and Bethge, Matthias. A note on the evaluation of generative models. In Inter- national Conference on Learning Representations, 2016. Tolstikhin, Ilya, Gelly, Sylvain, Bousquet, Olivier, Simon- Gabriel, Carl-Johann, and Sch¨olkopf, Bernhard. Ada- GAN: Boosting generative models. arXiv preprint arXiv:1701.02386, 2017. Unterthiner, Thomas, Nessler, Bernhard, Seward, Calvin, Klambauer, G¨unter, Heusel, Martin, Ramsauer, Hubert, and Hochreiter, Sepp. Coulomb GANs: Provably opti- mal Nash equilibria via potential ﬁelds. In International Conference on Learning Representations, 2018. Vaswani, Ashish, Shazeer, Noam, Parmar, Niki, Uszkoreit, Jakob, Jones, Llion, Gomez, Aidan N, Kaiser, Łukasz, and Polosukhin, Illia. Attention is all you need. In Advances in neural information processing systems, pp. 5998–6008, 2017. Villani, C´edric. Optimal transport: old and new, volume 338. Springer, 2009. Wang, Kunfeng, Gou, Chao, Duan, Yanjie, Lin, Yilun, Zheng, Xinhu, and Wang, Fei-Yue. Generative adver- sarial networks: introduction and outlook. IEEE/CAA Journal of Automatica Sinica, 4(4):588–598, 2017. Wang, William Yang, Singh, Sameer, and Li, Jiwei. Deep adversarial learning for nlp. In Proceedings of the 2019 Conference of the North American Chapter of the As- sociation for Computational Linguistics: Tutorials, pp. 1–5, 2019. White, Tom. Sampling generative networks. In Advances in neural information processing systems, 2016. Wu, Yuhuai, Burda, Yuri, Salakhutdinov, Ruslan, and Grosse, Roger. On the quantitative analysis of decoder- based generative models. 2017. Xiao, Chang, Zhong, Peilin, and Zheng, Changxi. Bour- GAN: Generative networks with metric embeddings. Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey 37 In Advances in neural information processing systems, 2018. Zhang, Han, Xu, Tao, Li, Hongsheng, Zhang, Shaoting, Wang, Xiaogang, Huang, Xiaolei, and Metaxas, Dim- itris N. StackGAN: Text to photo-realistic image synthe- sis with stacked generative adversarial networks. In Pro- ceedings of the IEEE international conference on com- puter vision, pp. 5907–5915, 2017. Zhang, Han, Xu, Tao, Li, Hongsheng, Zhang, Shaoting, Wang, Xiaogang, Huang, Xiaolei, and Metaxas, Dim- itris N. StackGAN++: Realistic image synthesis with stacked generative adversarial networks. IEEE transac- tions on pattern analysis and machine intelligence, 41 (8):1947–1962, 2018. Zhang, Han, Goodfellow, Ian, Metaxas, Dimitris, and Odena, Augustus. Self-attention generative adversarial networks. In International conference on machine learn- ing, pp. 7354–7363, 2019. Zhao, Junbo, Mathieu, Michael, and LeCun, Yann. Energy- based generative adversarial network. In International Conference on Learning Representations, 2017. Zhu, Jun-Yan, Kr¨ahenb¨uhl, Philipp, Shechtman, Eli, and Efros, Alexei A. Generative visual manipulation on the natural image manifold. In European conference on computer vision, pp. 597–613. Springer, 2016. Zhu, Jun-Yan, Park, Taesung, Isola, Phillip, and Efros, Alexei A. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Proceedings of the IEEE international conference on computer vision, pp. 2223–2232, 2017. Zieba, Maciej and Wang, Lei. Training triplet networks with GAN. In International Conference on Learning Representations, Workshop track, 2017.","libVersion":"0.3.1","langs":""}