{"path":"lit/lit_sources.backup/Chien23GenAIGigaTeraWattHours.pdf","text":"AUGUST 2023 | VOL. 66 | NO. 8 | COMMUNICATIONS OF THE ACM 5 chien’s vantage GenAI: Giga$$$, TeraWatt-Hours, and GigaTons of CO2 F OR MORE THAN a decade, we have speculated about the impact of artificial intelli- gence (AI)/machine learning (ML) on the environmen- tal sustainability of computing (see ACM2). It has become clear that AI’s carbon emissions (scope 2), lifecycle carbon (scope 3), and other negative environmental impacts are growing explosively. Generative AI capabili- ties and applications exemplified and popularized in ChatGPT, DALL-E 2, Stable Diffusion, and Copilot, are the drivers. The evidence: Giga$$$s of increased spending on AI computing equipment and infra- structure is driving a dramatic increase in infrastructure: AI computing silicon and datacenters. Nvidia. From May 2022 to April 2023 (12 months), Nvidia’s datacenter group sold $15.5B of GPUs. During a May 24 conference call earlier this year, the firm doubled guidance for the next quarter, increasing quarterly datacen- ter GPU sales forecasts from $4B to $8B (to an annual rate of $32B). 3 Dramatic growth in GPU demand for generative AI was the cited reason. Amazon, Microsoft, and Google. The growth of GPUs for AI comes on top of 12% per year cloud growth and is re- flected in large capital investments in datacenters (CPUs, networks, cooling, power, buildings, and so on). The three largest hyperscalers (Amazon, Micro- soft, and Google) have reported large increases in datacenter CapEx invest- ment from $78B in 2022 to $120B in 2023, a 54% increase. 8 Evidence of excess demand. En- demic reports of “GPU shortages” indicate the cloud cannot satisfy the compute demands of well-funded AI developers in both new ventures and existing companies. Terawatt-Hours (TWh) of increased datacenter power consumption will re- sult from the growing investment in AI hardware. The most accurate retrospec- tive estimates of datacenter power con- sumption are based on worldwide com- puting equipment sales: processors, networking, and storage. These back- ward-looking studies outlined the rapid growth of hyperscalers as the key driver of datacenter power consumption (30% per year). 5 We apply similar methodol- ogy to these massive GPU investments. Estimating the annual power con- sumption of $32B of GPUs involves GPU prices, operational parameters, and as- sociated server and datacenter power. Using A100 prices ($10k) and 300W aver- age incremental load (GPU at 50% of TDP, server balance of 50%, and PUE of 1.0: 3.2M GPUs → 960MW → 8.4 TWh/year. To put this into perspective, 8.4 TWh/year was 54% of Google’s total datacenter power in 2020. Nvidia’s sales-rate increase alone corresponds to 27% of Google’s total 2020 fleet. A more complete comparison is difficult as several hyperscalers have stopped disclosing total power consumption due to growing public outcry. 7 8.4 TWh corresponds to 0.25% of the USA’s an- nual electric power consumption. Gigatons of CO2 emissions will result from the growth in datacenter power consumption and perhaps threaten the reliability of the power grid. Datacenter carbon emissions should be computed based on the average grid emissions at the time power is consumed or worse, since some studies suggest that data- center loads harm grid decarboniza- tion. 4 Using 2021 U.S. average grid emis- sions, 8.4 TWh is 3.25 gigatons of CO2, the equivalent of five billion U.S. cross- country flights. In high-penetration ar- eas, cloud datacenters already exceed 20% of grid power; their further growth is being limited by grid reliability risks. Summary This analysis is based on economic data, and the conclusion of major growth was validated by industry leaders at Google’s recent “Future of Data Center Work- shop” (June 1, 2023), where I served as a panelist. The growth analyzed is just one year. With the boom in generative AI, the situation is now far different than recent reports. 6 The growing technical power and economic drivers make it improbable the AI juggernaut can be stopped. This means the sustainability of comput- ing/AI must be a concern for all com- puting researchers. 1 References 1. Fostering Responsible Computing Research: Foundations and Practices. The National Academies Press, Washington, DC (2022). 2. Knowles, B. ACM Technology Policy Council TechBrief: Computing and Climate Change. ACM (2021). 3. Leswing, K. Nvidia shares spike 26% on huge forecast beat driven by A.I. chip demand. CNBC (May 24, 2023). 4. Lin, L., Zavala, V., and Chien, A.A. Evaluating coupling models for cloud datacenters and power grids. In Proceedings of the 12 th ACM Intern. Conf. on Future Energy Systems (2021). 5. Masanet, E. et al. Recalibrating global data center energy-use estimates. Science 367, 6481 (Feb. 2020). 6. Patterson, D. et. al. The carbon footprint of machine learning training will plateau, then shrink. Computer 55, 7 (July 2022). 7. Synek, G. Amazon is one of the largest consumers of electricity but is offloading costs onto others. Techspot (Aug. 2018). 8. There’s AI in them thar hills. The Economist (May 29, 2023). Andrew A. Chien is the William Eckhardt Distinguished Service Professor in the Department of Computer Science at the University of Chicago, Director of the CERES Center for Unstoppable Computing, and a Senior Scientist at Argonne National Laboratory. He leads the Zero- carbon Cloud project, and is a former Editor-in-Chief of Communications. Copyright held by author/owner. DOI:10.1145/3606254 Andrew A. Chien","libVersion":"0.3.2","langs":""}