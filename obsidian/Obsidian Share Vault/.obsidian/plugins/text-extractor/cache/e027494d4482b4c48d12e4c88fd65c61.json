{"path":"lit/lit_sources.backup/Shalevska24politAImediaEduc.pdf","text":"Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 50 Copyright © 2024 The author/s This work is licensed under the CC BY 4.0 license (*) Corresponding author Peer review method: Double-blind Original scientific article DOI: https://www.doi.org/10.47305/JLPE2411050sh Received: 28.05.2024 • Accepted after revision: 06.07.2024 • Published: 12.07.2024 Pages: 50-61 The Future of Political Discourse: AI and Media Literacy Education Elena Shalevska 1* 1Faculty of Education - Bitola, University “St. Kliment Ohridski” - Bitola, North Macedonia  elena.shalevska@uklo.edu.mk Abstract: The rise of Artificial Intelligence (AI) has significantly impacted the political landscape, introducing novel challenges alongside opportunities for all involved. However, one of the most significant impacts can be found in its ability to manipulate information and shape public opinion, which has led to numerous concerns about the integrity of political discourse. Recognizing this issue, this paper explores the challenges posed by AI-powered disinformation and misinformation in political discourse, focusing on deepfakes, microtargeting, and weaponized bots and how they manipulate public opinion. Using a qualitative approach, the paper analyzes existing media literacy handbooks to develop a comprehensive framework for enhancing media literacy education. Aligned with the study‟s objectives, this framework aims to equip students with the critical thinking skills necessary to navigate this „tangled web‟ and engage more effectively in democratic processes. The study argues that robust media literacy education is essential in mitigating the negative impacts of AI-powered disinformation and misinformation in political contexts. Keywords: Media Literacy; Artificial Intelligence; Disinformation; Misinformation; Political Discourse; Education INTRODUCTION A healthy democracy thrives on an informed citizenry engaged in constructive political discourse. This discourse is the foundation for policy decisions and a strong sense of civic duty (Ahmadov 2022). However, the rise of Artificial Intelligence (AI) has cast a long shadow over the integrity of political discourse. Malicious actors can now misuse generative AI models to generate deepfakes and other forms of synthetic media, deliberately manipulating information and swaying public opinion (Tiernan et al. 2023). As a sub-field of AI, generative AI - easily produces novel text, images, music, and software by analyzing enormous collections of digitized material (Kaplan 2024). Thus, generative AI can produce different types of content within seconds. Depending on the person prompting the generative AI model, this content can vary from harmless to malicious. This troubling trend may mean that we must radically reevaluate our approach to media literacy education, as AI has significantly simplified the process of creating misleading content. Recognizing this issue, this paper proposes a framework for media literacy education within the broader context of political education, specifically designed for the age of AI. This framework equips students with the critical thinking skills necessary to distinguish fact from fiction in an increasingly complex information landscape. By empowering students to be made more media literate, the future can be safeguarded, ensuring democracy based on informed political decisions. Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 51 LITERATURE REVIEW AI-Powered Deception: A New Era of Political Disinformation The digital age has produced a potent new weapon for political manipulation: AI. Generative AI models are on the rise, fundamentally altering the landscape of political discourse and creating a breeding ground for both disinformation and voter manipulation. Some of the most troubling instances include deepfakes and synthetic media, microtargeting, and weaponized bots. Deepfakes and Synthetic Media One of the most concerning advancements in the field of generative AI is the rise of deepfakes and synthetic media. According to OED (2023), deepfakes are “any of various media, esp. a video, that has been digitally manipulated to replace one person‟s likeness convincingly with that of another, often used maliciously to show someone doing something that he or she did not do.” Deepfakes are a subset of synthetic media which “is an all-encompassing term to describe any type of content whether video, image, text or voice that has been partially or fully generated using AI or machine learning” (Askari 2023). These AI-generated videos and audio recordings can realistically portray individuals saying or doing things they never did. This technology can be used to fabricate political scandals, which are proven to dissuade voters (Maier 2011), sow discord amongst opposing factions, and erode trust in legitimate media sources, thus manipulating voters and significantly impacting the political landscape. If left unchecked, the deepfakes could have serious consequences for how journalists report the news, people‟s ability to make informed decisions, and the overall health of democracy (Flynn et al. 2017; Bennett and Livingston 2018; Chadwick et al. 2018). (Political) Microtargeting Beyond fabricating content, AI excels at personalizing it. Microtargeting, defined as “creating customized winning messages, proof points and offers, accurately predicting their impact, and delivering them directly to individuals” (Agan 2007, 2), is widely used in advertising and politics. It is a technique that nowadays leverages technology for best results. Technology is particularly useful in advanced political microtargeting to single out the potential voters, donors, and supporters (Aagard and Marthedal 2023; Cacciotto 2017; Bennett 2015; Bimber 2014), and AI is just the next iteration of tech-based microtargeting. Political microtargeting (PMT) “is a way to capture the attention of citizens who are on the one hand very reachable, because they carry their phones with them at all times, because their whereabouts are tracked, and because their personal data such as home addresses are collected on a large scale” (Dobber 2020, 9). The year 2016 marked a significant shift in how people viewed the use of digital tools in PMT political campaigns, in general. The unexpected results of the Brexit vote and the US presidential election of Donald Trump, both of which heavily utilized PMT tactics, drew widespread attention and proved that PMT is a powerful persuasion tool capable of swaying voters‟ opinions (Mahboob 2019). Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 52 AI can simplify the PMT process as it uses vast datasets to build detailed profiles of voters. This allows political campaigners to tailor messages that resonate with individual preferences, biases, and anxieties. Understandably, this can be a powerful tool for voter suppression (Mie Kim 2018), discouraging individuals from voting or swaying their opinions with emotionally charged content that bypasses critical thinking. Weaponized Bots and Algorithmic Amplification Social media platforms are rife with automated accounts, often called bots. A bot, “a computer program that performs automatic repetitive tasks” (Merriam-Webster 2024), can be easily programmed to spread misinformation and propaganda. Such a bot can create the illusion of widespread support for a particular political candidate or viewpoint, drowning out legitimate voices in a sea of automated noise (Howard et al. 2018). Recent developments in AI technology have made bots-creation significantly easier. As a result, somewhat capable, custom-made AI-powered bots have been on the rise. However, it is important to note that even ready-made AI algorithms that curate social media feeds can amplify misinformation by prioritizing content likely to generate clicks and engagement, regardless of its truthfulness. This confluence of all the aforementioned AI-powered manipulation techniques creates a “perfect storm” for political manipulation. For instance, a recent picture collage, shared by Republican presidential candidate Ron DeSantis, portrayed President Donald Trump hugging Anthony Fauci, the former Covid czar. Three of the six images in the collage were found to be AI-generated. And while the line between fact and fiction was indeed blurred, the goal of the collage itself was clear: to spread misinformation and sway voters. In April, the Republican National Committee also released an ad featuring AI-generated content. Their goal was to illustrate hypothetical crises that could occur if President Joe Biden were to secure a second term (Bond 2023). These examples best show how easily generative AI models can be misused during political campaigns to produce realistic-looking content that appears reliable and credible. Media Literacy in the Age of AI Digital literacy is “the ability to search for, evaluate, understand, and integrate information found online” (Ng 2012), and by extension, media literacy has never been so critical. People are bombarded with all kinds of content every waking moment, and their ability to critically assess this information is becoming more crucial in this digital era. In the face of AI-powered manipulation, media literacy, and by extension, media literacy education have become the only reliable weapon against potential disinformation, political or otherwise. AI is everywhere, and thus, the impact of AI on media literacy has become an even more complex issue that continues to evolve, especially in post-ChatGPT frenzy times (Tiernan et al. 2023; Valtonen et al. 2019). Voice-clonning, deepfakes, and AI-generated images are posted and shared online daily. And they are becoming increasingly difficult to identify. A cornerstone of media literacy is the ability to assess information sources. This involves checking websites for credibility and asking basic questions to determine reliability: Who Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 53 publishes the content? Are there clear author attributions and affiliations? Does the site exhibit transparency about its funding and potential biases? Similarly, faced with increasing AI-generated content, students must be adept at detecting manipulated content. Deepfakes and synthetic media require a critical eye for inconsistencies, unnatural movements, or audio glitches - skills that numerous students lack. Additionally, AI systems are trained on vast datasets, and these datasets can reflect the biases present in the real world. This means that AI-powered recommendations and search results may unconsciously favor certain political viewpoints or perspectives - which students, who are also voters, need to understand. Bykov and Medvedeva (2024) advocate for heightened media literacy efforts in the age of AI, suggesting that improved media literacy can even help people understand and use AI more effectively. As stated, AI poses significant challenges to media literacy, and some educational initiatives are already underway to meet these challenges. Programs like MIT‟s “Media Literacy in the Age of Deepfakes” aim to equip students and the broader public with the tools necessary to navigate content in the era of highly believable deepfakes. MIT‟s course incorporates case studies, such as the deepfake of President Nixon‟s speech in “In Event of Moon Disaster”, to illustrate the perils of AI in media. These educational efforts further emphasize the need for an up-to-date media literacy curriculum that will include AI aspects, ensuring students are prepared to critically assess AI-generated content in whichever scenario (Harvard Graduate School of Education 2024). METHODOLOGY For the purposes of this research, a qualitative analysis of the existing media literacy handbooks and curricula was conducted with a specific focus on the three most popular options in North Macedonia. The analysis followed the qualitative content analysis (QCA) approach by Schreier (2012) and the following steps: handbook selection, definition of a research question, data collection, coding frame development, and data analysis and interpretation. The three handbooks chosen were: 1. Handbook for Teachers for Studying Media Literacy in Mother Language Teaching: for Primary and Secondary Education (2010). 2. Media Literacy: Trainers‟ Handbook (USAID n.d.). 3. Media Literacy Handbook for Youth, Media, and Youth Organizations (2018). The research question was then defined as: “How do media literacy handbooks in North Macedonia introduce/discuss the concept of artificial intelligence?”. Initial categories, or codes, were then set as part of the coding framework:  Code 1: AI Definitions and Explanations  Code 2: Ethical Considerations  Code 3: Fake News and AI The handbooks were then fragmented into units (sections) and analyzed according to the coding framework. Drawing on the insights from the analysis of the chosen handbooks, a 5- module framework for enhancing media literacy skills was developed by the author, focusing on Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 54 AI. This framework aims to provide a practical and adaptable approach that educators can utilize to equip students with the critical thinking skills necessary to navigate the complexities of AI- powered political (dis)information. RESULTS Analysis of Existing Media Literacy Handbooks For the purposes of this study, a comprehensive analysis of three media literacy handbooks was conducted. The chosen handbooks are all highly regarded, easily accessible, and written in Macedonian. The analysis revealed a significant gap in addressing the challenges posed by AI- powered manipulation in media, in general, but also in the political sphere:  Code 1: AI Definitions and Explanations None of the handbooks provided comprehensive definitions or explanations of AI and its applications in media and/or political news.  Code 2: Ethical Considerations The ethical implications of AI in media were notably absent in all three handbooks. As mentioned above, AI technologies raise several ethical concerns, so the lack of such content seems noteworthy.  Code 3: Fake News and AI While the proliferation of fake news is a well-documented issue in media literacy, the role of AI in generating and spreading misinformation was not addressed in any of the handbooks. Although all three handbooks provide precious insights and excellent, reliable information for critical thinking and source evaluation, they do not explicitly address the emerging threats posed by deepfakes, algorithmic bias, and weaponized bots. This has further highlighted the urgent need for a framework specifically tailored to equip students with the skills necessary to navigate the evolving landscape of AI-powered (political) discourse. Proposed Framework for Media Literacy in the Age of AI The following five-module framework has been developed to address the abovementioned critical gap. This framework focuses specifically on AI and its challenges regarding modern media literacy. The framework designed and proposed by the author is as follows: Module 1: Demystifying AI  Define AI and its role in shaping online information environments.  Explore the concept of algorithmic bias and its potential impact on search results and social media feeds.  Discuss the importance of recognizing diverse perspectives and mitigating echo chambers. Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 55 Module Objectives: After completing this module, students will:  Gain a basic understanding of AI and how it works.  Identify common uses of AI in everyday life.  Understand how AI systems can exhibit biases based on the data they are trained on.  Learn about the potential impacts of algorithmic bias on search results.  Recognize the importance of consuming information from a variety of sources.  Develop strategies to mitigate the effects of echo chambers in online environments in a political context. Module 2: Deepfakes and the Art of Deception  Analyze the technology behind deepfakes and synthetic media in general.  Develop techniques for identifying potential manipulation in videos and audio recordings.  Discuss the ethical implications of deepfakes and their potential to erode trust in media sources. Module Objectives: After completing this module, students will:  Comprehend the basic technology behind deepfakes and other forms of synthetic media.  Learn how AI creates realistic but fake videos, images, and audio recordings.  Develop skills to detect potential manipulation in videos and audio recordings.  Utilize tools and techniques to verify the authenticity of media content.  Understand the potential consequences of deepfakes on trust in media and society. Module 3: Evaluating Websites and Information Sources  Refine website evaluation skills by identifying credible news organizations and academic sources.  Explore tools for fact-checking and verifying information online.  Discuss techniques for lateral reading, consulting multiple sources to gain a comprehensive understanding of an issue, political or otherwise. Module Objectives: After completing this module, students will:  Learn how to distinguish between credible news outlets and less reliable sources.  Understand the characteristics of reputable academic and peer-reviewed sources.  Know about various online tools and resources for fact-checking and verifying information.  Practice using these tools to evaluate the accuracy of online content.  Adopt lateral reading techniques to cross-check information from multiple sources.  Apply these skills to comprehensively and accurately understand political issues in their countries. Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 56 Module 4: Understanding Social Media Manipulation  Analyze the tactics employed in social media manipulation, including fake political accounts and bots.  Develop strategies for critically evaluating social media content and identifying potential misinformation.  Explore concepts like political microtargeting and understanding how online behavior can be exploited. Module Objectives: After completing this module, students will:  Identify common tactics used in social media manipulation, such as fake accounts and bots.  Analyze real-life examples of manipulation campaigns.  Develop skills to assess the authenticity and credibility of social media content critically.  Learn to identify red flags that may indicate misinformation.  Comprehend how political campaigns use data to target specific demographics with tailored messages.  Discuss the ethical implications and potential impact of microtargeting on democratic processes. Module 5: Building a Culture of Verification  Equip students with skills for utilizing reliable fact-checking resources.  Discuss the importance of open discourse and respectful debate in a healthy democracy.  Encourage students to actively participate in the information ecosystem, sharing credible sources and fostering critical thinking amongst peers. Module Objectives: After completing this module, students will:  Learn to utilize reliable fact-checking resources effectively.  Understand the importance of open and respectful debate in a healthy democracy.  Develop skills for engaging in productive and evidence-based discussions.  Understand the importance of sharing credible information on their networks.  Improve their critical thinking skills. It is important to note that this framework is rather general, so it can be adapted to fit the specific needs of different educational settings. The ultimate goal is to help educators develop students‟ media literacy skills in an age where AI-generated content, in both political and non-political contexts, is becoming increasingly realistic and challenging to identify. Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 57 CONCLUSION AI is now part of the media sphere. The analysis conducted for this study revealed a concerning gap in existing media literacy curricula: a lack of explicit focus on the challenges posed by AI in the political sphere. This study addresses the identified gap by proposing a comprehensive framework for media literacy that focuses on AI specifically. This 5-module framework aims to help students become discerning information consumers: individuals who can assess content critically and engage responsibly with political discourse. As AI technologies evolve, so must our approach to media literacy education. The race between technological innovation and media literacy education is continuous. While this framework provides a solid foundation, ongoing research, and adaptation will ensure that future generations are equipped to participate meaningfully in a healthy democracy. All in all, the emergence of AI has undoubtedly altered the landscape of political discourse. AI-powered tools now produce deepfakes, facilitate political microtargeting, and spread false information. Consequently, they pose a significant threat to informed participation in democracy. AI has created a breeding ground for misinformation and manipulation, eroding trust in media sources and politicians. Herein lies the critical importance of media literacy education within the broader context of political education. Equipping students with the skills necessary to critically analyze information, identify potential manipulation, and verify sources is truly paramount. Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 58 COMPLIANCE WITH ETHICAL STANDARDS Acknowledgments: Not applicable. Funding: Not applicable. Statement of Human Rights: This article does not contain any studies with human participants performed by any authors. Statement on the Welfare of Animals: This article does not contain any studies with animals performed by any authors. Informed Consent: Informed consent was obtained from all individual participants included in the study. Disclosure statement: No potential conflict of interest was reported by the author/s. Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 59 PUBLISHER‟S NOTE The Institute for Research and European Studies remains neutral concerning jurisdictional claims in published maps and institutional affiliations. Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 60 REFERENCES 1. Aagaard, Peter, and Selma Marthedal. 2023. “Political Microtargeting: Towards a Pragmatic Approach.” Internet Policy Review 12, no. 1. https://doi.org/10.14763/2023.1.1690 2. Ahmadov, Anar, and Floris Holstege. 2023. “Does Schooling Promote Democracy? A Meta-Analysis.” Democratization 30, no. 1: 57-77. doi:10.1080/13510347.2022.2109016. 3. Askari, Javahir. “Deepfakes and Synthetic Media: What Are They and How Are TechUK Members Taking Steps to Tackle Misinformation and Fraud.” TechUK. August 18, 2023. https://www.techuk.org/resource/synthetic-media-what-are-they-and-how-are-techuk- members-taking-steps-to-tackle-misinformation-and-fraud.html 4. Bennett, Colin J. 2016. “Voter Databases, Micro-targeting, and Data Protection Law: Can Political Parties Campaign in Europe as They Do in North America?” International Data Privacy Law 6(4): 261-275. https://doi.org/10.1093/idpl/ipw021 5. Bennett, W. Lance, and Steven Livingston. 2018. “The Disinformation Order: Disruptive Communication and the Decline of Democratic Institutions.” European Journal of Communication 33, no. 2: 122-139. 6. Bimber, Bruce. 2014. “Digital Media in the Obama Campaigns of 2008 and 2012: Adaptation to the Personalized Political Communication Environment.” Journal of Information Technology & Politics 11(2): 130-150. https://doi.org/10.1080/19331681.2014.895691 7. Bond, S. 2023. “DeSantis Campaign Shares Apparent AI-Generated Fake Images of Trump and Fauci.” NPR. https://www.npr.org/2023/06/08/1181097435/desantis-campaign- shares-apparent-ai-generated-fake-images-of-trump-and-fauci 8. Bykov, Ilya A., and Mariia V. Medvedeva. 2024. “Media Literacy and AI-technologies in Digital Communication: Opportunities and Risks.” In 2024, Communication Strategies in Digital Society Seminar (ComSDS). DOI: 10.1109/ComSDS61892.2024.10502053 9. Cacciotto, Marco M. 2017. “Is Political Consulting Going Digital?” Journal of Political Marketing 16(1): 50-69. https://doi.org/10.1080/15377857.2016.1262224 10. Chadwick, Andrew, Cristian Vaccari, and Ben O‟Loughlin. 2018. “Do Tabloids Poison the Well of Social Media? Explaining Democratically Dysfunctional News Sharing.” New Media & Society 20, no. 11: 4255-4274. 11. Chu-Ke, C., & Dong, Y. 2024. “Misinformation and Literacies in the Era of Generative Artificial Intelligence: A Brief Overview and a Call for Future Research.” Emerging Media 0(0). https://doi.org/10.1177/27523543241240285 12. Flynn, D. J., Brendan Nyhan, and Jason Reifler. 2017. “The Nature and Origins of Misperceptions: Understanding False and Unsupported Beliefs about Politics.” Political Psychology 38: 127-150. 13. Handbook for Teachers for Studying Media Literacy in Mother Language Teaching: for Primary and Secondary Education. 2010. Macedonian Institute for Media and Institute for Democracy “Societas Civilis“ [Македонски институт за медиуми и Институт за демократија “Societas Civilis“]. Available at: https://idscs.org.mk/wp- content/uploads/2009/08/priracnik_za_nastavnici_za_izucuvanje_na_mediumskata_pisme nost_vo_nastavata_po_majcin_jazik.pdf Journal of Legal and Political Education · Volume 1 · Number 1 · 2024 · eISSN: 2955-2389 Published online by the Institute for Research and European Studies at www.iies.mk/jlpe 61 14. Howard, Philip N., Samuel Woolley, and Ryan Calo. 2018. “Algorithms, Bots, and Political Communication in the US 2016 Election: The Challenge of Automated Political Communication for Election Law and Administration.” Journal of Information Technology & Politics 15, no. 2: 81-93. doi:10.1080/19331681.2018.1448735. 15. Kaplan, J. 2024. Generative Artificial Intelligence: What Everyone Needs to Know. Oxford University Press. 16. Kim, Young Mie. 2018. “Voter Suppression Has Gone Digital.” Brennan Center for Justice, November 20, 2018. https://www.brennancenter.org/our-work/analysis-opinion/voter- suppression-has-gone-digital. 17. Mahboob, Tehseen. 2019. “How Facebook Wins Elections.” CBC, October 19, 2019. https://www.cbc.ca/passionateeye/m_features/how-facebook-was-harnessed-to-micro- target-voters-and-promote-donald-trump. 18. Maier, Jürgen. 2011. “The Impact of Political Scandals on Political Support: An Experimental Test of Two Theories.” International Political Science Review 32, no. 3: 283- 302. https://doi.org/10.1177/0192512110378056. 19. Media Literacy Education and AI. Harvard Graduate School of Education. 2024. Accessed May 21, 2024. https://www.gse.harvard.edu/ideas/education-now/24/04/media-literacy- education-and-ai 20. Media Literacy Handbook for Youth, Media, and Youth Organizations. 2018. Higher School of Journalism and Public Relations [Висока школа за новинарство и за односи со јавноста]. https://www.medium.edu.mk/attach/Priracnik-za-mediumska-pismenost- MK.pdf?5c1a6b78 21. Media Literacy in the Age of Deepfakes. 2021, October 18. Media Literacy in the Age of Deepfakes. MIT. https://deepfakes.virtuality.mit.edu/ 22. Media Literacy: Trainers‟ Handbook. n.d. USAID. Available at: https://www.irex.org/files/l2d-trainers-manual-n-macedonia.pdf 23. Merriam-Webster.com Dictionary, s.v. “bot”, accessed May 21, 2024, https://www.merriam-webster.com/dictionary/bot. 24. Ng, Wan. 2012. “Can we teach digital natives digital literacy?” Computers & Education 59(3): 1065-1078. 25. Oxford English Dictionary, s.v. “deepfake (n.),” September 2023, https://doi.org/10.1093/OED/9547101155. 26. Schreier, Margrit. 2012. Qualitative Content Analysis in Practice. London: Sage. 27. Tiernan, Peter, Eamon Costello, Enda Donlon, Maria Parysz, and Michael Scriney. 2023. “Information and Media Literacy in the Age of AI: Options for the Future.” Education Sciences 13, no. 9: 906. https://doi.org/10.3390/educsci13090906 28. Tiernan, Peter, Eamon Costello, Enda Donlon, Maria Parysz, and Michael Scriney. 2023. “Information and Media Literacy in the Age of AI: Options for the Future.” Education Sciences. 29. Valtonen, Teemu, Matti Tedre, Kati Mäkitalo, and Henriikka Vartiainen. 2019. “Media Literacy Education in the Age of Machine Learning.” Journal of Media Literacy Education 11, no. 2: 20-36.","libVersion":"0.3.2","langs":""}