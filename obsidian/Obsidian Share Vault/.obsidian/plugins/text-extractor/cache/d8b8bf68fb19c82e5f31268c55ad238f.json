{"path":"lit/lit_sources.backup/Xia20loadDisaggLSTM.pdf","text":"Non-intrusive load disaggregation based on composite deep long short-term memory network q Min Xia a,b,⇑,1, Wan’an Liu a,b,1, Ke Wang c, Wenzhu Song a,b, Chunling Chen a,b, Yaping Li c a Jiangsu Key Laboratory of Big Data Analysis Technology, Nanjing University of Information Science and Technology, Nanjing 210044, China b Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing 210044, China c China Electric Power Research Institute, Nanjing 210003, China article i nfo Article history: Received 3 June 2019 Revised 18 May 2020 Accepted 14 June 2020 Available online 24 June 2020 Keywords: Non-intrusive load disaggregation Long short-term memory network Cross-layer connection Time series abstract Non-invasive load monitoring (NILM) is a vital step to realize the smart grid. Although the existing var- ious NILM algorithms have made signiﬁcant progress in energy consumption feedback, there are still some problems need to further addressed, such as the exponential growth of state space with the increase of the number of multi-state devices, which leads to the dimension disaster; and it is difﬁcult to capture the power ﬂuctuation information effectively because of the neglect of time-dependency prob- lem load disaggregation; traditional disaggregation involves a process of one sequence to one sequence optimization, which is inefﬁcient. In our study, a composite deep LSTM is proposed for load disaggrega- tion. The proposed algorithm considers the process of load disaggregation as a signal separation process and establishes regression learning from a single sequence to multiple sequences to avoid dimension dis- aster. In addition, an encoder-separation-decoder structure is introduced for load disaggregation. Encoder completes the effective encoding of the mains power and differential power information, the time- dependency of the encoding process implemented by a deep LSTM, separation realizes the disaggregation process by separating the encoded information, and decoder decode the separated signal into the sequences of corresponding electrical appliances. Compared with the one sequence to one sequence dis- aggregation method, the proposed method simpliﬁed disaggregation complexity and improves the efﬁ- ciency of disaggregation. The experimental results on WikiEnergy and REDD datasets show that the proposed method can reduce the disaggregation error and improve the comprehensive performance of event detection. Besides, our study can provide conditions for the realization of the bidirectional interac- tion of the smart grid and the improvement of the smart grid scheduling. \u0001 2020 Elsevier Ltd. All rights reserved. 1. Introduction Load monitoring technology, as one of the key technologies of advanced metering infrastructure (AMI), is a key step to realize smart grids. Traditional load monitoring adopts an intrusive way, that is, sensors are installed on the users’ electrical appliances to record the usage. The advantage of the intrusive method is that the monitoring data is accurate and reliable, and the disadvantages are poor operability, high implementation cost and low user acceptance (Ridi, Gisler, & Hennebert, 2014; Froehlich et al., 2010). Therefore, non-intrusive load monitoring (NILM) technology is urgently needed to achieve load monitoring. NILM proposed by Hart (1992) is a feasible system to implement appliance-level load monitoring. That is, only a single monitoring device is installed to obtain the energy consumption data of the whole household with- out increasing the marginal cost, the running state of each electri- cal equipment in the household can be accurately identiﬁed. The key to the implementation of NILM is to estimate the appliance- level power consumption by utilizing the energy consumption data obtained from the single monitoring device, and non-intrusive load disaggregation (NILD) is the main technical means of the imple- mentation of the estimation process. NILD disaggregates the mains power information into the information of each electrical appli- ance, and then the appliance-level power consumption can be obtained to track the power consumption behavior with the aim of providing accurate power consumption feedback to consumers https://doi.org/10.1016/j.eswa.2020.113669 0957-4174/\u0001 2020 Elsevier Ltd. All rights reserved. q This document is the results of the research project funded by the State Grid Corporation of China Project ‘Fundamental Theory of Dynamic Demand Response Control Based on Large-Scale Diversiﬁed Demand Side Resources’. ⇑ Corresponding author at: Jiangsu Key Laboratory of Big Data Analysis Technol- ogy, Nanjing University of Information Science and Technology, Nanjing 210044, China. E-mail addresses: xiamin@nuist.edu.cn (M. Xia), wanan@nuist.edu.cn (W. Liu). 1 Min Xia and Wan’an Liu contributed equally to this work. Expert Systems with Applications 160 (2020) 113669 Contents lists available at ScienceDirect Expert Systems with Applications journal h omepag e: www.elsevier.com/locate/eswa (Evora, Hernandez, & Hernandez, 2015). The realization of NILD has high application value, which can bring beneﬁts to the power com- pany and users (Paterakis, Erdinc, Bakirtzis, & Catalao, 2015). Com- pared with intrusive load monitoring, the remarkable advantages of NILD mainly manifested in its economic investment is small and its practicability is strong (Belley, Gaboury, Bouchard, & Bouzouane, 2015). Therefore, since the NILD was put forward, it has attracted wide attention. At present, mathematical optimization and pattern recognition are the two major methods of addressing NILD problems, and these two methods must be analyzed based on load signatures (LS) (Hassan, Javed, & Arshad, 2013). LS is deﬁned as unique informa- tion that reﬂects the state of power consumption in the operation of an electrical appliance. LS includes the operating characteristics of the load, which are determined by the working conditions of the electrical appliance. LS is divided into three types of steady state, transient and running mode, in which the steady-state and tran- sient depend on the characteristics of the components inside the equipment, and the running mode is determined by the operation control strategy of the equipment (Lee, Fung, Lam, Chan, & Lucente, 2004). The characteristics of LS are repeatable, so the load types and their usage status can be identiﬁed based on LS characteristics, which are the realization principle of NILD (Rahimpour, Qi, Fugate, & Kuruganti, 2017). Combinatorial optimization (CO) transforms the NILD problem into 0–1 planning problem (Zoha, Gluhak, Imran, & Rajasegarar, 2012). Chang, Lin, Chen, and Lee (2013) used a heuristic algorithm to realize load disaggregation based on the steady current. How- ever, in the case study of Chang’s work, only two induction motors with different power and one load with switch state are tested, the multi-state devices and continuously variable electrical appliances are not involved, which is not representative. Besides, there is a large room for improvement of the disaggregation error in Chang’s work. The model used by Lin and Tsai (2013) is similar to that of the literature (Chang et al., 2013), which could handle the simulta- neous events and considered the use of electrical appliance to be close to the active power consumption, but the recognition accu- racy was not high. Piga, Cominola, Giuliani, Castelletti, and Rizzoli (2015) proposed a sparse optimization method to solve the NILD problem and improved the disaggregation accuracy. Ahmadi and Marti (2015) proposed a load disaggregation method based on feature matching (also called LS matching), the objective of which is to ﬁnd and detect the electrical equipment with the highest similarity of load characteristics in the feature library. Because of the simplicity and easy to implement of CO algorithm, it has been widely applied for load disaggregation since it was put forward, however, CO methods mainly have the following problems (Batra, Dutta, & Singh, 2013): (1) The model is essentially a complete problem of NP-hard, the efﬁciency of disaggregation is a challenge; (2) Accurate identiﬁcation needs a complete load fea- ture library, which is often difﬁcult to meet in practice; (3) The method based on the optimization theory is a discrete method, which can only be used to analyze the discrete state of the electri- cal appliances, so the load with very strong load ﬂuctuation is dif- ﬁcult to be modeled. The essence of load disaggregation based on pattern recognition is to identify the electrical appliances by studying the LS character- istic mode of each electrical equipment. Unsupervised learning based load disaggregation does not require labeled data for electri- cal appliance, thereby reducing manual intervention (Munshi & Mohamed, 2017). Shao, Marwah, and Ramakrishnan (2013) pro- posed a pattern mining method to realize unsupervised energy dis- aggregation. Through the steady state characteristics of the mains power, the scene sequence was generated, and the scene of the applied electrical appliance was screened out, then the usage of each equipment was obtained by using the pattern mining technology. Martins, Pinto, and Bittencourt (2018) disaggregated six different industrial machines of a Brazilian factory with facto- rial hidden Markov model (FHMM). The disaggregation results are compared on normalized disaggregation error (NDE), normal- ized signal aggregated error (SAE), and F1 score. The results show that FHMM can realize the prediction of on/off of electrical appli- ances. However, when the number of electrical appliances increases, the complexity of FHMM for load disaggregation increases exponentially, resulting in the ﬁnal disaggregation per- formance is far from good. Parson, Ghosh, Weal, and Rogers (2014) proposed an approach which combines a one-off supervised learning process over existing labeled appliance data sets, with an unsupervised learning method over unlabeled household aggre- gate data. Kolter, Batra, and Ng (2010) used a sparse coding algo- rithm to learn the power consumption models of each device and used these models to predict the power consumption of different devices. Johnson and Willsky (2013) used the hierarchical Dirichlet hidden semi-Markov model to achieve unsupervised power disag- gregation. The algorithm was fast and ﬂexible, but the accuracy was low. Compared with the supervised learning algorithm, the load disaggregation algorithm based on unsupervised learning is with lower accuracy and lacks the ability to identify complex con- tinuous state loads because of lack of prior supervision information (Esa, Abdullah, & Hassan, 2016). Zaen, Achkar, Carrillo, and Hutter (2018) compared the performance of unsupervised clustering and neural network on detection and classiﬁcation of refrigeration units of display cabinet, under counter fridge and right fridge. Although unsupervised clustering algorithm can effectively detect the power cycle, it cannot precisely estimate the power consump- tion of refrigeration units. In comparison, the precision rate and recall rate of a supervised neural network algorithm in electrical appliances are all over 90% which indicates neural network can achieve accurate power disaggregation. Due to the reliability of supervised learning method, there are many researches in this ﬁeld such as K-nearest neighbor algorithm (Tsai & Lin, 2012), neural network (Chang, Chen, Tsai, & Lee, 2011; Chang, Lian, Su, & Lee, 2013; Park, Baker, & Franzon, 2019; Martinez, Pacheco, & Robergs, 2018), support vector machine (Saitoh, Osaki, Konishi, & Sugahara, 2010), Adaboost algorithm (Hassan, 2012), fuzzy system (Lin & Tsai, 2014; Welikala, Dinesh, Ekanayake, Godaliyadda, & Ekanayake, 2019; He, Du, Yang, Harley, & Habetler, 2012), etc. Cominola, Giuliani, Piga, Castelletti, and Rizzoli (2017) combines FHMM and iterative subse- quence dynamic time warping (ISDTW) to conduct supervised NILM and semi-supervised NILM to track the power consumption of multiple devices running at the same time. Their work solved the problems of intrusive data sampling, the inconsistency of NILM metrics and the difﬁculty of identifying states of devices operating at the same time. The performance on AMPds dataset (Makonin, Popowich, Bartram, Gill, & Baji, 2013) evaluated by power contri- bution error (PCE), F1 score and R2 score show the effectiveness of supervised and semi-supervised algorithms. Compared with Kolter’s work (Kolter & Johnson, 2011), reduced the average PCE from over 50% to 4%. Du, Restrepo, Yang, Harley, and Habetler (2013) integrated supervised self-organizing mapping and Baye- sian hybrid identiﬁer to make a probabilistic judgment on the cat- egory of a device, but this method fails to consider the problem of load classiﬁcation for multi-state transfer. Lin and Tsai (2014) com- bined Fuzzy C-Means based on particle swarm optimization (PSO) with neural fuzzy classiﬁcation was used to identify household appliances and could effectively deal with the LS similarity of household appliances. Pereira and Nunes (2018) makes a compre- hensive comparison of supervised event detection algorithms in the NILM on 23 evaluation metrics, which includes True positive rate (TPR), False positive rate (FPR), Area under roc curve (AUC), accuracy, precision, recall rate et al. The results demonstrate that 2 M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 under the circumstance of data imbalance, the selection of perfor- mance metrics is vital. Guo, Wang, and Kashani (2014) used the modiﬁed implicit Markov model based on differential observation to solve the overlap of active signals between target electrical appliances and other electrical equipment. Non-parametric classi- ﬁcation was ﬁrstly done by Wang and Zheng (2011) based on the number of events and occurrence time, and then linear discrimi- nant analysis was used to identify the categories of electrical appli- ance. Park et al. (2019) proposed an appliance identiﬁcation algorithm based on a cogent confabulation neural network, which did not require multiplications during the identiﬁcation phase and improved the speed of load disaggregation. Welikala et al. (2019) invested a NILD method which incorporates appliance usage pat- terns (AUPs) to improve performance of active load identiﬁcation and forecasting. Although supervised NILM generally achieved better load disag- gregation performance than that of unsupervised NILM, however, there are still some deﬁciencies in the above supervised NILM methods: (1) Most of the above supervised methods require hand- craft feature extraction (Basu, Debusschere, Bacha, Maulik, & Bondyopadhyay, 2014), which is a time-consuming and laborious work. Besides, in the presence of multi-state devices, the manually extracted features cannot guarantee the disaggregation perfor- mance of devices under various running states. (2) Traditional methods usually modeled NILM task as a classiﬁcation problem to detect the running states of individual appliances. However, such methods cannot capture the ﬂuctuation information of power consumption, fail to provide some valuable information such as how the working patterns and operating efﬁciency of a device impacts the power consumption. (3) Some methods such as denoising AutoEncoder (DAE) (Kelly & Knottenbelt, 2015), CNN (Martinez et al., 2018; Xia, Liu, Wang, Zhang, & Xu, 2019) modeled the load disaggregation problem as a regression problem, their work are based on the assumption that the power consumption information is time-independency. However, the current state of the a load may have a certain dependency on the previous opera- tion state (for example, the washing cycle of the washing machine may occur after the pre-washing cycle), time dependency usually exists especially in the load disaggregation of multi-state equip- ments, which the power consumption curve often presents peri- odic operation pattern. (4) Generally, the current methods (such as hidden Markov model (HMM) based methods (Kim, Marwah, Arlitt, Lyon, & Han, 2011)) do energy disaggregation by establish- ing one-to-one (one input to multiple output) mapping from the mains power sequence to the target sequence. When the number of electrical equipment is large (especially for multi-state equip- ment), the time complexity of model training increases as well. To address the above limitations in current supervised NILD, we propose a composite long short-term memory network (CD-LSTM) for load disaggregation. The proposed CD-LSTM satisﬁes some out- standing characteristics, making it superior to the previously supervised NILD algorithms. The arising limitations and drawbacks motivated CD-LSTM equipped with the following features: (1) Automatic load feature extraction ability which beneﬁts from the deep learning framework (Singh & Majumdar, 2017; Singhal, Maggu, & Majumdar, 2018) allows CD-LSTM to conduct end-to- end load disaggregation to simplify the feature extraction process. (2) CD-LSTM modeled load disaggregation problem as a regression learning process, which not only distinguish the state of electrical appliances but also realized precise appliance-level load disaggre- gation. (3) The time-dependency problem in multi-state appliances is solved by the design of deep LSTM framework (Kim, Le, & Kim, 2017; Mauch & Yang, 2015). The power disaggregation of each time step takes the power ﬂuctuation information of the previous time steps into account to improve the disaggregation performance. (4) Load disaggregation process is regarded as a signal separation process, driving CD-LSTM designed as an encoder-separation-decoder and one-to-many (one input, multiple outputs) structure. Compared with one-to-one structure, CD-LSTM avoided repeated model training and improved the disaggregation efﬁciency. Experimental results on two open NILD datasets show CD-LSTM can reduce the disaggregation error and improve the disaggrega- tion efﬁciency over existing benchmark models, providing more robust bidirectional feedbacks to both smart grid and power consumers. 2. Proposed composite deep long short-term memory network 2.1. Review of long short-term memory network Long short-term memory network (LSTM) is a special recurrent neural network (RNN), which can learn long-term dependence. LSTM was ﬁrst proposed by Hochreiter and Schmidhuber (1997), and then improved by Graves (2012), which has been widely applied in time series correlation analysis. LSTM can overcome the long-term dependencies problem in RNN (Williams & Zipser, 1989; Huang, Xu, & Yu, 2015; Bao, Yue, & Rao, 2017; Zhu et al., 2016). Although RNN (You, Park, & Oh, 2017) is designed to be able to process the whole time sequence information, the ﬁnal input data can be well memorized, the memory for the earlier input data is insufﬁcient. LSTM solves the problem of long term dependence, which makes it possible to memorize long term data without com- plex parameter adjustment. In all recurrent neural network, there is a chain form of dupli- cate neural network modules. In RNN, the structure of duplicate modules is very simple, which contains only one tanh layer (Chemali, Kollmeyer, Preindl, Ahmed, & Emadi, 2017). Compared with RNN, the duplicate module structure of LSTM is more compli- cated. The schematic diagram of the LSTM structure is shown in Fig. 3, in which the duplication modules are represented by the small rectangles. Each small rectangle represents a neural network, and LSTM contains 4 layers of neural networks. \u0001 and \u0003 represent element-wise addition and multiplication. r is the sigmoid activa- tion function, and tanh represents the tanh activation function. 2.1.1. The cell state of LSTM As showed in Fig. 1a, there is a straight line running through all the elements in LSTM, which represents the state of LSTM. In the process of information transfer, each unit can increase or decrease the information of a state. These operations allow information to selectively affect the state of each moment through the ‘‘gate‘ structure. The gate structure contains an operation of sigmoid func- tion r and a vector dot product \u0003. The output of the sigmoid acti- vation function is a value between 0; 1ðÞ, which directly controls the proportion of the information transfer. If the output value C is 0, the neuron does not allow the message to be transmitted, while the output value C of 1 means all the information can pass through the neuron (Kong et al., 2017). 2.1.2. Forget gate In the LSTM structure, the ﬁrst step is to decide which informa- tion needs to be discarded, which is determined through the ‘‘For- get gate”. The ‘‘Forget gate” will decide which part of the state unit Ct\u00041 should be forgotten based on the current input value xt and the output value ht\u00041 at the last time. The structure of the ‘‘Forget gate” is shown in Fig. 1b, and its formula is as follows: f t ¼ r W f \u0005 ht\u00041; xt½\u0006 þ bf \u0001\u0003 ; ð1Þ where W f ; bf are the connection weights and bias values of sigmoid layer in ‘‘Forget gate” respectively. M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 3 2.1.3. Input gate After LSTM ‘‘forgot” part of the previous status information, the current state also learns new information from the current input, which is achieved through the ‘‘Input gate”. As showed in Fig. 1c, the ‘‘Input gate” contains two parts: the tanh layer and the sigmoid layer. The tanh layer is used to create a new candidate value vector. The sigmoid layer is used to control which information of the tanh layer is added to the current state. The tanh layer and the sigmoid layer are described as: it ¼ r Wi \u0005 ht\u00041; xt½\u0006 þ biðÞ; ð2Þ C \u0007 t ¼ tanh WC \u0005 ht\u00041; xt½\u0006 þ bCðÞ; ð3Þ where Wi; bi are the connection weights and bias values of sigmoid layer in ‘‘Input gate” respectively, WC; bC are the connection weights and bias values of tanh layer in ‘‘Input gate” respectively. Through the operation of ‘‘Forget gate” and ‘‘Input gate”, LSTM can effectively ﬁlter out which information should be forgotten and which new information is worth learning (Cortez, Carrera, Kim, & Jung, 2018). Therfore, current cell state Ct can be updated as: Ct ¼ f t \u0003 Ct\u00041 þ it \u0003 C \u0007 t; ð4Þ the updating process is shown in the blue thick lines in Fig. 1c. 2.1.4. Output gate After getting the updated state, LSTM needs to determine the output value of the current time, and the output value is deter- mined through the ‘‘Output gate”. As showed in Fig. 1d, the ‘‘Out- put gate” controls the output of the current state through a sigmoid function, which is described as follows. Ot ¼ r W O \u0005 ht\u00041; xt½\u0006 þ bOðÞ; ð5Þ ht ¼ Ot \u0003 tanh CtðÞ; ð6Þ where W O; bO are the connection weights and bias values of sigmoid layer in ‘‘Output gate” respectively. In Eq. (6),‘‘\u0003” is the dot product of vectors. 2.2. Deep LSTM network Deep LSTM is a variant of LSTM, which can enhance the expres- sive ability of the model. Compared with LSTM, deep LSTM dupli- cates the structural morphology many times. The parameters in the same layer are consistent, and the parameters in different lay- ers are different. Fig. 2 shows the time step expansion structure of deep LSTM networks, each of which represents a structural mor- phology. In designed deep LSTM, dropout operation (Srivastava, Hinton, Krizhevsky, Sutskever, & Salakhutdinov, 2014) is added to LSTM, which can make the network more robust. When training neural network models, the use of dropout can prevent over-ﬁtting (Dahl, Sainath, & Hinton, 2013). In the deep LSTM of this work, dropout operations are used only between different levels of mod- ules, rather than in the same level of modules. As showed in Fig. 2, the solid line part indicates that no dropout is used, and the dashed line indicates the use of dropout. 2.3. Design of composite deep LSTM network Researches of load disaggregation based on deep learning meth- ods often trains a network model for every target appliance, and the model inputs the mains power data and outputs the power of a target electrical appliance. This leads to a lot of repetitive model training, which is cumbersome and more time-consuming. For load disaggregation, CD-LSTM is proposed in this study, the input mains power data can be simultaneously decomposed into the power of multiple target electrical appliances, thus avoiding tanh tanh tanh tanh tanh tanh 1th th +1th +1tx tx1tx tanh tanh tf 1th tx tanh ~ tC ti tf tanh 1th 1tC tC tx tanh tanh th 1th tO tx th Fig. 1. Schematic diagram of LSTM structure. 4 M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 repeated training of models. The network structure is shown in Fig. 3. Since the input data integrates the original mains power data with the differential data which obtained through the mains power differential operation (see differential processing in Sec- tion 3.1.2 for details), a convolution layer with ﬁlter size 1 \b 2is ﬁrstly used to extract the mains power and differential information (Ting, Tan, & Sim, 2019), and the output of the convolution layer can be denoted as xconv 2 R1\bL, where L is the length of a sample. In this way, we not only extract the integrated mains power and differential information through a convolution operation, but also transfer the disaggregation target to the single-channel signal sep- aration, then the NILM task can be described as estimating the power consumption information Y 1 tðÞ; Y 2 tðÞ; .. . ; Y M tðÞ of M target electrical appliances by using a given discrete total power data XtðÞ: Xconv tðÞ ¼ XM i¼1 Y i tðÞ; ð7Þ In the window sliding phase, we describe how to divide the mains power sequence into K segments of length L. We can get xconv 2 R1\bL after performing convolution, where: x conv a ¼ XtðÞ; yi;a ¼ Y i tðÞ; ( ð8Þ where t 2 aL; a þ 1ðÞL½\u0006; a ¼ 1; 2; ... ; K; a denotes ath sequence seg- ment. Each mains power segment and the power segment of the individual appliance can be represented as a weighted summation of the basis signals B ¼ b1; b2; .. . ; bN½\u0006 while B 2 RN\bL, and b 2 R1\bL: x conv a ¼ caB; yi;a ¼ di;aB; ( ð9Þ where c 2 R1\bN is the weight vector of mains power segment, di;a 2 R1\bN represents the weight vector of the ath power segment of the ith electrical appliance, and ca satisﬁes the following conditions: ca ¼ XM i¼1 di;a ð10Þ from Eq. (10), we can further know: ca ¼ XM i¼1 di;a ¼ XM i¼1 ca \t di;aøca \u0001\u0003 ¼ ca \t XM i¼1 mi;a ð11Þ Among them, it can be seen from Eq. (11) that mi;a ¼ di;aøca, obvi- ously, mi;a represents the relative proportion of the ith power seg- ment of target electrical appliance to the mains power segment weight vector ca. \t and ø represent element-wise multiplication and division respectively. Consequently, a load disaggregation prob- lem can be converted into utilizing xconv c to estimate the weight vec- tor di;a task for each appliance. Fig. 3 shows the structure of the CD-LSTM network. CD-LSTM consists of three main parts: encoder, separation, decoder. The encoder is used to get the weight vector ca of the ath mains power segment, separation part is designed for obtaining the ath mask vector mi;a of ith individual appliances, ﬁnally, the decoder can decode the mask vector into its corresponding weight vector di;a of power segment of individual appliances. In the encoder structure, it can be seen from Eq. (9) that xconv a ¼ caB, where xconv a 2 R1\bL, ca 2 R1\bN; B 2 RN\bL, encoder vector ca can be implemented by a fully connected layer, which can be obtained by a fully connected layer with N hidden nodes, thus, we can get ca 2 R1\bN. Combined with the structure of LSTM in 0h 1h 2h th 0x 1x 2x tx Fig. 2. Structure of deep LSTM network. Fig. 3. Structure of composite deep LSTM network. M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 5 Fig. 1, the structure of deep LSTM in Fig. 2 and the mechanism anal- ysis of ‘‘Forget gate”, ‘‘Input gate” and ‘‘Output gate” in LSTM struc- ture, it can be seen that in the encoding process of load disaggregation at each time step, deep LSTM-based NILD task effec- tively utilizes the information of previous time steps to adequately solve the long-dependency problem in multi-state load disaggregation. The separation network produces for each target source M ¼ m1; m2; ... ; mK½\u0006 2 RK\bN. Such a mask matrix or vector is widely used in deep learning applications. In the image ﬁeld, it can be regarded as high-level feature maps, and in the analysis of sequence data, the dimension vector with size 1 \b N is known as mask vector. Let mi;a ¼ mi j; 1ðÞ; mi j; 2ðÞ; ... mi j; NðÞ½\u0006 2 R1\bN be the mask vector for ath sequence of target appliance s, thus the mask matrix for all K segments of target appliances s can be deﬁned as M ¼ mi;1; mi;2; ... ; mi;K \u0004\u0005 2 RK\bN. The goal of our study is to ﬁnd an estimate M using a deep learning model f C; UðÞ ¼ M. Because LSTM has obvious advantages in time series analysis, we take advantage of a LSTM with N hidden nodes to separate the encoded vectors in our separation network. The separation network takes encoded sequential vector ca 2 R1\bN as input, where ca can be speciﬁcally expressed as ca ¼ ca 1ðÞ; ca 2ðÞ; ... ; ca NðÞ½\u0006. Therefore, the function between c and m can be modeled by Eqs. (1)–(6). In addition, because of the deep LSTM structure used in the sep- aration stage, the problem of vanishing gradient is inevitable. In order to slightly alleviate the effect of vanishing gradient, skip con- nection is introduced in disaggregation network, which borrows the idea of ResNet (He, Zhang, Ren, & Sun, 2016) and DenseNet (Huang, Liu, Van Der Maaten, & Weinberger, 2017) to operate infor- mation ﬂow and solve the problem of vanishing gradient. ResNet skip connection, the implementation can be simply expressed as skip ca; mi;a \u0001\u0003 ¼ ca þ mi;a, and skip connection in DenseNet can be easily realized as channel fusion: skip ca; mi;a \u0001\u0003 ¼ concat ca; mi;a \u0001\u0003. In our experiment, DenseNet-type skip connection operation is adopted to transfer information ﬂow. Another advantage of such skip connection is that it combines encoding vector with mask mi;a, which is helpful for reconstructing electrical power segments. Besides, dropout (Srivastava et al., 2014; Dahl et al., 2013) skill is applied in LSTM which helps to avoid overﬁtting. In the decoding part, the mask vectors we separate from encoded mains vector can be regarded as the feature vector of tar- get sequence, thus, separation network can be regarded as the encoder network of decoder network. In other words, separation network as both separation function and encoding ability. If we consider the separation network as a encoder network of decoder network, in the separation network, we adopt LSTM to ﬁnish the separation and encoding process, therefore, in order to accurately reconstruct the power consumption sequence of each electrical appliance, M LSTM with L hidden node is combined together to jointly decode the corresponding mask. The whole architecture of CD-LSTM is designed as one-to-many (one input and multiple out- puts). Compared with the traditional NILM algorithm, the advan- tage of such design is that it can simultaneously disaggregate the power consumption of multiple running devices, and avoid redun- dant repeated inference processes. 3. Expermental settings 3.1. NILD datasets and preprocessing 3.1.1. NILD dataset According to the sampling frequency, NILD can classiﬁed into high-frequency NILD and low-frequency NILD. The low-frequency indicate the sampling rate is lower than 1 Hz (sampling period higher than 1 second), high-frequency sampling refers to the sam- pling rate is higher than 50 Hz (sampling period lower than 0.02 s), although high-frequency NILD can extract richer features from high-order harmonics to improve the performance of NILD, main- taining high frequency sampling often requires the installation of custom expensive monitoring devices. In contrast, low-frequency NILD is much more economical. However, the experimental data sampled with a low-frequency contains less information, which makes low-frequency NILD a challenge. Therefore,in this study, we focus on low-frequency NILD. The experimental data in this study are derived from open data- sets WikiEnergy and REDD (Kolter & Johnson, 2011). WikiEnergy dataset is the power dataset released by the Pecan Street Inc com- pany through the WikiEnergy project (Pecan Street Inc, 2013), which already contain more than 600 household electrical data, including household mains power and data from each independent household electrical source monitored at intervals of one minute. The WikiEnergy began in January 2011 and is still collecting data from most buildings. REDD dataset is a public dataset created by Kolter and Johnson (2011) for energy disaggregation research, which contains low-frequency with sampling period 3 s of power data from 6 different households and high-frequency current and voltage data of two households. According to different working conditions, electrical equipment is mainly divided into three categories: (1) electrical appliance with a single state. In the course of oper- ation, the service rating and power rating of these appliances are basically the same. (2) electrical appliance with limited multi-state. This type of electrical appliances usually has a limited number of dis- crete working states, the electrical power of each state is dis- crete, and the different power values are different working states. (3) electrical appliance with continuous change state. The elec- trical power of such appliances has no constant mean value, but ﬂuctuates continuously within a certain range. In the data selection of this experiment, above three kinds of electrical appliances should be selected. Therefore, 5 electrical appliances are selected from household No. 18, No. 20, and No. 25 in WikiEnergy dataset, the No. 3 household with low- frequency data in REDD is selected for our study. In WikiEnergy dataset, air conditioner, refrigerator, washing machine, microwave oven, and dish washer are selected for exper- iment. Four electrical appliances of the third household in the REDD data set are used for testing: LITE, MICR, BATH, and DIFF. The speciﬁc reasons for selecting the above electrical appliances for load disaggregation experiment are: (1) The cost of supervised learning experiments on every elec- trical appliance in each household is tremendous and impractical, while the experiments on some common and representative electrical appliances are necessary. (2) Our research does not involve the power consumption disag- gregation of some low-power electrical appliances, because of such appliances in the data set are easy to be interfered by noise, and the noise information sometimes triggers the event detection of low-power electrical appliances, resulting in the wrong classiﬁcation. The research of load disaggrega- tion on low power consumption devices is still one of the challenges in NILD, we leave this for future exploration. (3) The power consumption of above selected electrical appli- ances accounts for over 70% of the total consumption of the entire household, we conduct load disaggregation exper- iments on commonly used electrical appliances. 6 M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 (4) The historical power consumption of the selected electrical devices includes mode disaggregation from simple to complex. 3.1.2. Differential processing In load disaggregation, mains power of the instantaneous load is used as the sequence of characteristic observation values. The differential signal is a numerical representation of the difference between two physical quantities. Mains power values of adjacent time points after ﬁltering are subtracted, and the differential wave- forms of mains power are obtained. The consumption of mains power and its differential waveform are shown in Fig. 4. After dif- ferential processing, each non-zero value indicates that the state of the electrical appliance has changed. The formula for calculating the difference waveform is as follows: DXt ¼ Xt \u0004 Xt\u00041; ð12Þ where Xt represents the mains power consumption at time point t, and Xt\u00041 is the mains power consumption at time point t \u0004 1; DXt is the results of differential processing. 3.1.3. Data normalization Different time series data often have different basic physical properties, which will affect the result of data analysis. In order to eliminate such inﬂuence between characteristics of the data, data normalization is performed on original power data. After nor- malizing, all the raw data can be mapped into the same order of magnitude, which is suitable for the comprehensive comparison and evaluation (Affonso, Rossi, Vieira, & de Leon Ferreira, 2017). Normalization methods usually include min–max standardization, Z-score standardization, decimal scaling standardization and so on. The min–max is used for normalization in our study. Min–max standardization, also called deviation normalization, is a linear change to the original data, and the result is mapped to 0; 1½\u0006. The conversion formula is as follows: X t ¼ Xt \u0004 XminðÞ= Xmax \u0004 XminðÞ; ð13Þ where Xmax is the maximum value of mains power sequence or power consumption sequence of target appliances, and Xmin is the minimum value sequence, Xt denote unnormalized power value consumed at time point t, and X t is the normalized results. 3.1.4. Input data with sliding window In this work, the original mains power data and the differential processing data are used as the input data of the network, and the real power of each electrical appliance is used as the target sequences. Deep learning relies on large amounts of training data, thus, in our study, ﬁrst 80% of the mains power sequence and tar- get sequence are used as a training sequence, where the training sequence contains the mains power sequence and the power sequence of individual appliances, the remaining 20% of mains sequence and target sequence are regarded as the test sequence. The input of CD-LSTM requires to be a ﬁxed size, which a sliding window is performed on training sequence and testing sequence. Fig. 5a shows the different window sliding strategy applied on the training sequence and testing sequence, as showed in Fig. 5a, overlapping sliding process of the training sequence is adopted to increase the training samples, such data augmentation skill has been widely used in image processing and sequence domain to improve the performance of deep learning algorithms. Assume that the length of the training sequence is z, a sliding window with window size n and stride l performed sliding operation on training sequence, z \u0004 nðÞ=l þ 1 can be obtained. Similarly, as showed in Fig. 5b, h=n test samples can be obtained by non-overlapping slid- ing on test sequence with length h and both window size and strides are n. CD-LSTM maps the mains power samples Xm:mþn\u00041 into the power samples Y m:mþn\u00041 of the respective individual appli- ances. Where m represents the time at which the data begins to slide, n represents the size of the sliding window, and m : m þ n \u0004 1 represents the time segment from m to m þ n \u0004 1. Mains power samples and the samples of individual appliances are paired into x; yðÞ for training, where x; y represents the samples sliding from mains power sequence X and target power sequence Y. 3.2. Benchmark models In this work, other four methods are compared with the pro- posed method. FHMM, CO, K-nearest neighbors (KNN) are classic methods for load disaggregation. Kelly and Knottenbelt (2015) indicated that the performance of DAE is better than traditional LSTM. Thus, the proposed model will be compared with FHMM, CO, KNN, and DAE. In the above method, FHMM and CO generate discrete data, which can only decompose electrical appliances into discrete values but cannot achieve continuous power value representation. The FHMM model clusters the historical power data of each electrical appliance to get the cluster center for each electrical appliance, which can indicate the power values of each electrical appliance in different states. Then the HMM of a single appliance is obtained based on the number of clusters (i.e. the number of states). The parameters of a hidden Markov model include mean value, covariance value, initial probability, and state transition probability. The parameters of each hidden Markov chain for dif- ferent appliances are different. Then the Kronecker product is used to obtain the initial probability, state transition probability, mean value and covariance of combined hidden Markov model. Each state of the combined hidden Markov model represents the state combination of various electrical appliances. With each input of a mains power data, the combined hidden Markov model will get a state, which represents the state combination of the electricalFig. 4. Mains power consumption and differential power of mains power.Sliding Fig. 5. Different sliding pattern on training sequence and testing sequence. M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 7 appliances, and decodes the combined state to get the state of each electrical appliance. Consistent with FHMM’s model assumptions, the CO model ﬁrst realizes the discrete state representation of each electrical appli- ance by clustering. Given a mains power data, the mains power of all possible combinations of electrical appliances is calculated. Then the optimal combination of load disaggregation can be obtained by ﬁnding the minimum residual error between the power of all possible appliances combination and real mains power. KNN is a classical machine learning algorithm, which can not only applied for event detection in NILM but also predict the power consumption of individual electrical appliances by establishing regression learning, and carry out load disaggregation task. The principle of KNN algorithm is to use the target values of K nearest training samples to determine the value of testing samples. It pre- dicting target load power consumption according to the similarity of the trained mains power sequence and target sequence. DAE is an encode-decode structure algorithm based on neural network technology. Kelly and Knottenbelt (2015) modeled the process of load disaggregation as the process of denoising. DAE seeks to recover the clean power consumption information of tar- get appliance from the mains power signal with noise. The classic DAE is an unsupervised algorithm which can reconstruct the input signal. Kelly and Knottenbelt (2015) trains the DAE with the mains power and the power consumption information of the individual appliance as the target, trying to ﬁnd the mapping pattern between the mains power with noise and the power consumption informa- tion of the target appliances. 3.3. Evaluation measures In order to compare the proposed method with other methods on all the data series, adequate evaluation indexes should be selected to identify the performance. In this work, two kinds of load disaggregation evaluation indexes are used: mean absolute error and signal aggregate error. The mean absolute error (MAE) is used to evaluate the error of forecast value and real value: MAE ¼ 1=TXT i¼1 jpt \u0004 gtj; ð14Þ where gt is a true power of an electrical appliance at time t, pt is the forecast value at time t; T is the number of predicted points. In this study, SAE is used to evaluate the error in a period of time: SAE ¼j^e \u0004 ej=e; ð15Þ where ^e and e represent the predicted total energy consumption and real total energy consumption respectively. This measurement is very meaningful because it is helpful to the daily power report. When the load power is disaggregated, the on/off state of the electrical appliance can be distinguished by thresholding, which can also reﬂect the accuracy of the disaggregation problem. The thresholds of Air conditioner, Fridge, Washing machine, Micro- wave, Dish washer are 100 W, 50 W, 20 W, 200 W and 100 W respectively. In terms of judging the on/off state of electrical appli- ances, this work uses four indexes: recall rate, precision, accuracy and F1 measure. Recall is the ratio of correctly predicted positive observations to all observations in the actual class. Recall ¼ TP= TP þ FNðÞ; ð16Þ where True Positives (TP) – The number of both predicted electrical state and the real state are ‘‘on”, False Negatives (FN) – The number of predicted state is ‘‘on” when the real state is ‘‘off”. There are two possibilities: one is to predict the original positive class into a pos- itive class (TP), and the other is to predict the original positive class as a negative class (FN). Precision is the proportion of the number that is correctly pre- dicted to be ‘‘on” state to the state that is predicted as ‘‘on” state. Precision ¼ TP= TP þ FPðÞ; ð17Þ where False Positives (FP)-Real state is ‘‘off” when the predicted state is ‘‘on”. Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. Accuracy ¼ TP þ TNðÞ= P þ NðÞ; ð18Þ where P is the number of positive samples in real samples, N is the number of negative samples in real samples. F1 Score is the weighted average of Precision and Recall. There- fore, this score takes both false positives and false negatives into account. F1 ¼ 2 \b Precision \b RecallðÞ= Precision þ RecallðÞ: ð19Þ Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially the data set has imbalance class distribution. The on/off classiﬁcation of electrical appliances in this work has imbalance class distribution. 4. Result Load disaggregation as well as to the electrical on/off state judg- ment are two important aspects of load identiﬁcation. To accom- plish both aspects, we ﬁrstly use CD-LSTM to achieve load disaggregation, and then utilize the disaggregation results to iden- tify the state of an electrical appliance. Fig. 6 shows the disaggregation results of No. 18 household of WikiEnergy. As can be seen from Fig. 6, FHMM and CO have bad disaggregation results. The load disaggregation in FHMM and CO can only be roughly expressed by the combination of discrete states. Therefore, Fig. 6 shows that the predicted power is discrete for FHMM and CO. Therefore, optimization technologies such as FHMM and CO can provide consumers with operable power con- sumption feedback, showing which electrical appliances are on and which of them are off, but these methods cannot accurately offer the detailed power consumption information of each appli- ance. By contrast, KNN, DAE, and CD-LSTM can achieve good results in appliances with high frequency of use such as Air condi- tioner and refrigerator. However, the effect of KNN in Washing machines, Microwave, and Dish washer with low usage appliances is not as good as DAE and CD-LSTM. The effect of DAE depends in part on the adjustment of parameters, and each electrical appliance has to train a separate model. Therefore, in order to achieve good results for each appliance, it will take more experience in adjusting parameters for DAE. In this study, only a simple parameter adjust- ment is needed for CD-LSTM, and CD-LSTM can output several decomposed values of electrical appliances at the same time with good performance. Table 1 shows the disaggregation performance on No. 18 house- hold of WikiEnergy. As can be seen from Table 1, KNN has the min- imum error in the Air conditioner in the MAE index. The proposed CD-LSTM method is better than other methods in the MAE index of four kinds of electrical appliances such as Fridge, Washing machine, Microwave, and Dish washer. In the SAE index, the DAE is with the smallest error in the dishwasher, but CD-LSTM method has made the smallest error in the other four electrical appliances. It can be seen from Table 1 that the results of method CO and FHMM are not good, while the KNN, DAE, and CD-LSTM methods have better results. Therefore, we focus on comparing the three methods of KNN, DAE, and CD-LSTM. In addition, for the Air condi- 8 M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 tioner, the above three methods are very effective, so here we only consider the comparison of the other four kinds of appliances. Fig. 7 shows the ﬁner grained load disaggregation comparison of three methods of DAE, KNN, and CD-LSTM for No. 18 household. The comparison results in Fig. 7 are time segments from Fig. 6.It can be seen from Fig. 7 that the proposed CD-LSTM can achieve the good ﬁtting of various electrical appliances, which is superior to the DAE in the disaggregation of Fridge, Microwave, and dish washer. For the disaggregation of Washing machine, these two methods have different performances for different data points, but the difference of MAE is very small. The Fig. 7 also shows that the prediction results of KNN ﬂuctuate greatly, and the results are worse than that of DAE and CD-LSTM. Table 2 shows the comparison of evaluation indexes of electri- cal appliances on/off of No. 18 household. As can be seen from Table 2, the recall rate of the CO method for the Microwave is the highest, and the recall rate of the FHMM method is the highest for the dish washer. However, the precision of these two methods is very low, which indicates that these two methods classify too many negative samples into positive samples, and they prefer to divide the samples into positive samples. From the simulation results, it can be seen that the appliance with the greater the fre- quency of use or the longer the state of use, the more accurate the classiﬁcation. Fig. 8 shows the comparison of load disaggregation between ﬁve kinds of electrical appliances of No. 20 household. It can be seen from the simulations that the disaggregation results of FHMM and CO are very poor, and KNN is not ideal for sparse and abrupt data (Washing machine, Microwave, and Dish washer). The good results of Air conditioner and Fridge can be obtained by DAE and the proposed model. For the appliance with sparse and abrupt data, the ﬁtting effect of DAE and CD-LSTM is not good enough, but it is better than the methods of FHMM, CO, and KNN. Fig. 9 shows the load disaggregation comparison of three meth- ods of DAE, KNN, and CD-LSTM for No. 20 household. The compar- ison results in Fig. 9 are from time segments of Fig. 8. Fig. 9 shows that the performances of CD-LSTM and DAE are better than that of KNN, and the results of CD-LSTM are superior to DAE. As seen in Fig. 9a, Fridge is a multi-state device whose state is on in a long run, the disaggregation effect of DAE on Fridge is better in the area with higher power consumption, but the disaggregation error in the area with lower power consumption is signiﬁcantly greater than that of CD-LSTM. Same conclusion can be drawn from the dis- aggregation results of Washing machine and Microwave. The above four disaggregation results show that although KNN has the ability of load disaggregation, the disaggregation error is large. Generally, the disaggregation curve of CD-LSTM is the closest to the real power consumption curve. In conclusion, the simulations demonstrate the effectivity of the proposed method. Table 3 is the comparison of disaggregation error on No. 18 household of WikiEnergy dataset. Table 3 shows that the MAE of DAE is superior to CD-LSTM in the disaggregation of Air condi- tioner, but is inferior to CD-LSTM in the disaggregation of Fridge, Washing machine, Microwave, and Dish washer. For the SAE index, KNN has the best results in Air conditioner and Fridge. This is because KNN is not very good at ﬁtting for the high frequency used Table 1 Comparison of load disaggregation evaluation indexes of household 18. Index Method Air-C Fridge Wash Micr Dish MAE FHMM 153.594 96.120 267.563 144.714 232.219 CO 330.280 161.521 225.114 243.283 213.127 KNN 38.232 24.678 34.331 7.745 20.380 DAE 83.287 18.823 18.058 5.226 26.618 CD-LSTM 59.115 18.122 21.145 5.076 10.562 SAE FHMM 0.140 0.022 7.881 60.335 14.001 CO 0.276 0.664 6.352 107.287 12.600 KNN 0.010 0.019 0.185 1.925 0.301 DAE 0.013 0.036 0.187 1.285 0.008 CD-LSTM 0.003 0.016 0.161 1.224 0.262 Bold item represents the best value for each column. Fig. 6. Load disaggregation comparison of household 18 in WikiEnergy data set. M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 9 electrical appliances, but it has good performs in overall trend tracking. Table 4 shows the comparison of the evaluation indexes of on/ off judgement of No. 20 household. It can be seen from Table 4 that the CD-LSTM method proposed in this study has obvious advan- tages over other methods, especially in the disaggregation of the following four kinds of electrical appliances: Fridge, Washing machine, Microwave, and Dish washer. The CO method has a good recall rate in the disaggregation of Washing machine, but the pre- cision, accuracy, and F1 values are very low, which indicates that the CO method misclassiﬁes of too many negative samples into positive samples. Fig. 10 shows the comparison results of the ﬁve electrical load disaggregation of No. 25 household. Similar to the results of No. 18 and No. 20 household, the proposed method and DAE method are better than FHMM, CO, and KNN. The comparison results in Fig. 11 are time segments from Fig. 10. Fig. 11 shows that the CD-LSTM has the best curve approximation ability. As viewed from Fig. 11a that the disaggregation results of Fridge presents three stages of change in this time period, the power ﬂuctuates back and forth around 0 watts, 180 watts, 700 watts. The disaggregation results of KNN are comparatively unstable and the curve ﬂuctuates sharply. Although KNN can approximately draw the trend of power consumption of Fridge, it has not yet achieved accurate disaggrega- tion results. In contrast, the disaggregation curves of DAE and CD- LSTM are closer to the real power consumption curves. However, by further comparison, compared with CD-LSTM, DAE seems difﬁ- cult to capture the time points when the power ﬂuctuate greatly, similar phenomena are also reﬂected in the power disaggregation of the Washing machine in No. 25 household of WikiEnergy. This Table 2 Comparison of evaluation indexes of electrical appliances on/off of No. 18 household. Index Method Air-C Fridge Wash Micr Dish Rec FHMM 0.944 0.645 0.664 0.216 0.775 CO 0.902 0.683 0.580 0.690 0.676 KNN 0.987 0.989 0.856 0.111 0.544 DAE 0.997 0.994 0.969 0.296 0.767 CD-LSTM 0.998 0.994 0.976 0.279 0.631 Prec FHMM 0.977 0.661 0.067 0.015 0.042 CO 0.829 0.689 0.075 0.004 0.040 KNN 0.945 0.886 0.382 0.039 0.303 DAE 0.827 0.914 0.550 0.423 0.255 CD-LSTM 0.979 0.922 0.464 0.530 0.412 Acc FHMM 0.974 0.540 0.433 0.947 0.375 CO 0.904 0.580 0.551 0.462 0.423 KNN 0.976 0.906 0.899 0.989 0.932 DAE 0.930 0.934 0.945 0.995 0.903 CD-LSTM 0.992 0.939 0.924 0.996 0.949 F1 FHMM 0.960 0.653 0.122 0.029 0.080 CO 0.864 0.686 0.133 0.007 0.076 KNN 0.965 0.935 0.529 0.058 0.390 DAE 0.906 0.953 0.702 0.348 0.382 CD-LSTM 0.989 0.957 0.630 0.367 0.498 Bold item represents the best value for each column. Fig. 7. Load disaggregation comparison of three methods of DAE, KNN, and CD-LSTM for No. 18 household. 10 M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 Table 3 Comparison of load disaggregation evaluation index of number No. 20 household. Index Method Air-C Fridge Wash Micr Dish MAE FHMM 426.230 59.695 333.501 405.658 388.749 CO 865.723 246.275 405.168 525.447 390.098 KNN 54.491 45.156 14.096 4.223 17.217 DAE 38.547 21.608 14.773 12.306 9.860 CD-LSTM 45.433 20.588 6.532 4.061 6.803 SAE FHMM 0.210 0.034 32.004 125.261 35.516 CO 0.433 2.984 39.709 162.512 35.758 KNN 0.0007 0.017 0.490 0.292 1.103 DAE 0.010 0.029 0.156 2.341 0.580 CD-LSTM 0.007 0.071 0.055 0.028 0.046 Bold item represents the best value for each column. Fig. 8. Load disaggregation comparison for No. 20 household. Fig. 9. Load disaggregation comparison of three methods of DAE, KNN, and CD-LSTM for No. 20 household. M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 11 is mainly due to DAE are designed based on the assumption of the time-independency of power consumption data. On the contrary, because CD-LSTM combines the power ﬂuctuation information of the previous time points in the disaggregation process of each time step, its ability to capture the time point when the electrical state transforms is stronger, and the disaggregation error is lower. Table 5 shows the MAE and SAE index of different methods in most cases. It can be seen that the MAE of KNN and DAE is smaller than that of CD-LSTM in the disaggregation of Fridge. This is because in 1520–1580 min and 1880–1920 min, the CD-LSTM method failed to respond well to the closure of an electrical appli- ance. From the simulation results of above three households, it can be seen that the proposed method CD-LSTM is better than the other methods on the MAE index, and the performance on the SAE index is better than the other methods in most cases. If we pay attention to the ﬁtting of electrical power curves, the CD- LSTM method is the best choice. If we only focus on the overall power consumption of an electrical appliance in a certain period of time, KNN and CD-LSTM method are both good choices. Table 6 shows the comparison of appliances’ state prediction of No. 25 household of WikiEnergy. It can be seen from Table 6 that CD-LSTM performs best in Air conditioner, Washing machine and Microwave, DAE performs best in Fridge and Dish washer. Although the recall rate of FHMM is very high, its comprehensive performance is very poor. To verify the reliability and stability of the proposed method, REDD dataset is used for comparative experiments. Because of the poor effect of FHMM and CO in the experimental comparison of Wikienergy data set, the FHMM method and CO method are removed in the REDD data set experiment. The sampling period of REDD low-frequency data is 3 s. Four appliances were selected from No. 3 household for further experiment: LITE, MICR, BATH, and DIFF. Fig. 12 shows the load disaggregation result for REDD data set with the method of DAE and CD-LSTM. It can be seen from the Fig. 12 these two methods have good disaggregation results on four kinds of electrical appliances. Due to the lower sampling period of REDD data set, the data of the time series are larger, and more Table 4 Comparison of evaluation indexes of electrical appliances on/off of No. 20 household. Index Method Air-C Fridge Wash Micr Dish Rec FHMM 0.973 0.676 0.623 0.500 0.615 CO 0.850 0.739 0.740 0.618 0.650 KNN 0.997 0.803 0.290 0.324 0.333 DAE 0.9990 0.949 0.333 0.735 0.608 CD-LSTM 0.9997 0.953 0.293 0.588 0.683 Prec FHMM 0.998 0.571 0.030 0.006 0.020 CO 0.942 0.564 0.034 0.003 0.023 KNN 0.985 0.676 0.230 0.275 0.046 DAE 0.992 0.907 0.437 0.556 0.130 CD-LSTM 0.994 0.926 0.481 0.998 0.175 Acc FHMM 0.977 0.545 0.386 0.733 0.296 CO 0.838 0.546 0.364 0.378 0.356 KNN 0.986 0.679 0.943 0.994 0.899 DAE 0.993 0.918 0.963 0.996 0.940 CD-LSTM 0.995 0.932 0.966 0.998 0.952 F1 FHMM 0.985 0.619 0.057 0.012 0.039 CO 0.894 0.640 0.065 0.007 0.045 KNN 0.991 0.734 0.256 0.297 0.082 DAE 0.996 0.927 0.378 0.633 0.214 CD-LSTM 0.997 0.939 0.364 0.741 0.278 Bold item represents the best value for each column. Fig. 10. Load disaggregation comparison for No. 25 household. 12 M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 Table 5 Comparison of load disaggregation evaluation index of number No. 25 household. Index Method Air-C Fridge Wash Micr Dish MAE FHMM 255.611 178.454 244.388 283.516 503.941 CO 325.053 270.758 228.088 467.880 422.668 KNN 42.366 36.859 5.846 6.366 9.873 DAE 53.802 37.105 9.548 17.015 12.172 CD-LSTM 35.687 37.854 3.232 5.217 6.468 SAE FHMM 0.0321 0.967 40.811 50.039 61.031 CO 0.0430 1.769 38.028 82.509 51.004 KNN 0.0002 0.0224 0.277 0.048 0.159 DAE 0.001 0.0792 1.359 1.979 0.037 CD-LSTM 0.006 0.168 0.111 0.435 0.270 Bold item represents the best value for each column. Table 6 Comparison of evaluation indexes of electrical appliances on/off of number No. 25 household. Index Method Air-C Fridge Wash Micr Dish Rec FHMM 0.983 0.743 0.949 0.806 0.814 CO 0.961 0.747 0.917 0.613 0.748 KNN 0.998 0.983 0.595 0.194 0.595 DAE 0.995 0.945 0.632 0.354 0.435 CD-LSTM 0.999 0.997 0.861 0.387 0.870 Prec FHMM 0.895 0.716 0.019 0.008 0.016 CO 0.918 0.709 0.019 0.006 0.015 KNN 0.990 0.864 0.141 0.429 0.143 DAE 0.991 0.942 0.207 0.275 0.606 CD-LSTM 0.993 0.853 0.372 0.800 0.295 Acc FHMM 0.918 0.612 0.238 0.683 0.277 CO 0.923 0.606 0.244 0.664 0.368 KNN 0.992 0.877 0.964 0.996 0.942 DAE 0.991 0.920 0.975 0.995 0.987 CD-LSTM 0.995 0.876 0.986 0.998 0.968 F1 FHMM 0.937 0.729 0.037 0.015 0.031 CO 0.939 0.727 0.036 0.011 0.030 KNN 0.994 0.919 0.228 0.267 0.231 DAE 0.993 0.944 0.312 0.309 0.507 CD-LSTM 0.996 0.920 0.519 0.522 0.440 Bold item represents the best value for each column. Fig. 11. Load disaggregation comparison of three methods of DAE, KNN, and CD-LSTM for No. 25 household. M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 13 training samples can be provided to improve the training effect. It can be seen from Fig. 12 that the disaggregation ability of the CD- LSTM method on DIFF is better than that of DAE. The comparison results in Fig. 13 are time segments of Fig. 12. Fig. 13 shows that CD-LSTM method can perfectly match the actual power of the appliances, it has better performance than DAE method, which indicates that the learning ability and generalization ability of CD-LSTM model is better than that of DAE. Table 7 shows the comparison of load disaggregation evaluation indexes for REDD data sets. From the simulation results, in terms of the two indicators, CD-LSTM model is superior to DAE in four elec- trical appliances. From the practical experience, with the increase of samples, the results obtained by CD-LSTM model will be better. Table 8 shows the comparison of on/off indices of REDD data sets. As can be seen from Table 8, except the recall rate of LITE, CD-LSTM is superior to DAE. Table 8 indicates that when there are enough samples to train the network, CD-LSTM can also get good results for sparse power data. 5. Conclusion Load monitoring is an important part of household intelligent power consumption. In this study, NILD under low-frequency data is studied, which avoids the high cost of hardware and a large amount of high-frequency sampling data in the study of intrusive load disaggregation. Firstly, the mains active power is processed by the differential processing, then the original active power data Fig. 12. Load disaggregation comparison for REDD data set. Fig. 13. Predicted versus actual energy signal for two appliances with two different methods of DAE and CD-LSTM. Table 7 Comparison of load disaggregation evaluation index in REDD data set. Index Method LITE MICR BATH DIFF MAE DAE 34.951 19.318 9.357 18.174 CD-LSTM 11.035 7.439 7.422 10.025 SAE DAE 0.191 0.389 8.247 0.311 CD-LSTM 0.087 0.209 6.616 0.121 Bold item represents the best value for each column. Table 8 Comparison of evaluation indexes of electrical appliances on/off in REDD data set. Index Method LITE MICR BATH DIFF Rec DAE 0.9995 0.292 0.977 0.220 CD-LSTM 0.972 0.921 0.999 0.713 Prec DAE 0.939 0.831 0.079 0.258 CD-LSTM 0.999 0.857 0.091 0.478 Acc DAE 0.979 0.995 0.993 0.997 CD-LSTM 0.991 0.998 0.996 0.998 F1 DAE 0.968 0.432 0.146 0.237 CD-LSTM 0.985 0.887 0.168 0.572 Bold item represents the best value for each column. 14 M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 and the differential data are used simultaneously as the input of the network, thus enriching the ﬂuctuation information of NILD. The proposed method is designed as an encoder-separation- decoder structure, while the encoder and the decoder are consists of deep LSTMs for solving the problem of time-dependency in multi-state devices; and the disaggregation the process is simu- lated as a signal separation process which implemented by a sep- aration structure. The multi-branch output network model in this study can simultaneously disaggregate the active power value into multiple target appliances and avoid the problem that each electri- cal appliance should train a single model separately, thus reduces the complexity of the model. Finally, the cross-layer connection is introduced in the network to enhance the transmission of net- work information, thus improving the accuracy of model training. In the simulation experiments of two public data sets in Wikie- nergy and REDD, the method of this paper is compared with sev- eral load disaggregation methods studied previously, and the method of this method has a better disaggregation effect, and the accuracy and other indexes are obviously improved. We applied the proposed model on two data sets such as Wikienergy and REDD. Results on two benchmark data sets show that our method outperforms the advanced model, and the proposed CD-LSTM model can be a robust and efﬁcient way to deal with NILD’s issues, providing favorable technical support for realizing the bidirec- tional interaction of the smart grid and power consumers, and improving the scheduling level of the smart grid. Although our model improves the performance of NILD, there are still some problems that need to be further discussed: (1) In our study, the design of deep LSTM only considers uni-directional dependency, while the real load disaggregation may have a bidi- rectional dependency. For example, there are multiple operation cycles (pre-washing, washing, drying) in the operation state of the Washing machine. Each cycle may interrelate in a long time. The current power consumption reasoning not only beneﬁts from the previous power consumption information but also has a certain correlation with future power consumption. Therefore, in future work, we will consider the bidirectional dependency in load disag- gregation, and some necessary improvements can be introduced to solve this problem, such as designing a deep bidirectional LSTM (Kiperwasser & Goldberg, 2016; Zeyer, Doetsch, Voigtlaender, Schlöter, & Ney, 2017) to capture the bidirectional dependency relationship (2) It is noted that in our experiment, some electrical appliances are in the ‘‘off” state in a long time, and the power con- sumption of such appliances in the ‘‘on” state is difﬁcult to get accurate disaggregation. The reason for this phenomenon is that if NILM is regarded as a classiﬁcation process based on event detec- tion, the number of ‘‘on” of some electrical appliances in a period is far less than the number of ‘‘off”, which makes the ﬁnal prediction results tend to ‘‘off”. In other words, there is a high degree of imbalance in the disaggregation data. Based on the above limita- tion, we will introduce some imbalance learning methods into our future work. Feasible data re-sampling methods such as syn- thetic minority oversampling technique (SMOTE) (Fernandez, Garcia, Herrera, & Chawla, 2018), a generative model such as a gen- erative adversarial network (GAN) (Goodfellow, 2016; Antoniou, Storkey, & Edwards, 2017) to generate some ‘‘on” power consump- tion data would be a good choice. (3) In this study, a deep learning algorithm is proposed for NILD, but its black-box attribute is widely criticized. In our experiment, although the performance and efﬁciency of CD-LSTM have been improved, how the mains power ﬂuctuation affects the power output of electrical appliances remains unknown. Thus, in future work, we will gradually tend to open the black box. Some interesting skills will be considered, such as introducing attention mechanism (Vaswani et al., 2017; Xia, Liu, Xu, Wang, & Zhang, 2019) to capture the time point of state change, and some model-agnostic methods would also be helpful for us to open the black-box model, such as local interpretable model-agnostic explanations (LIME) (Ribeiro, Singh, & Guestrin, 2016) and SHapley Additive exPlanations (SHAP) (Lundberg & Lee, 2017). Declaration of Competing Interest The authors declare that they have no known competing ﬁnan- cial interests or personal relationships that could have appeared to inﬂuence the work reported in this paper. CRediT authorship contribution statement Min Xia: Conceptualization, Methodology. Wan’an Liu: Writing - original draft, Formal analysis. Ke Wang: Data curation, Investi- gation. Wenzhu Song: Visualization, Investigation. Chunling Chen: Validation, Writing - review & editing. Yaping Li: Data curation. References Affonso, C., Rossi, A. L. D., Vieira, F. H. A., & de Leon Ferreira, A. C. P. (2017). Deep learning for biological image classiﬁcation. Expert Systems with Applications, 85, 114–122. Ahmadi, H., & Marti, J. R. (2015). Load decomposition at smart meters level using eigenloads approach. IEEE transactions on Power Systems, 30(6), 3425–3436. Antoniou, A., Storkey, A., & Edwards, H. (2017). Data augmentation generative adversarial networks. arXiv preprint arXiv: 1711.04340. Bao, W., Yue, J., & Rao, Y. (2017). A deep learning framework for ﬁnancial time series using stacked autoencoders and long-short term memory. PloS one, 12(7). Basu, K., Debusschere, V., Bacha, S., Maulik, U., & Bondyopadhyay, S. (2014). Nonintrusive load monitoring: A temporal multilabel classiﬁcation approach. IEEE Transactions on Industrial Informatics, 11(1), 262–270. Batra, N., Dutta, H., & Singh, A. (2013). Indic: improved non-intrusive load monitoring using load division and calibration. 2013 12th international conference on machine learning and applications (Vol. 1, pp. 79–84). IEEE. Belley, C., Gaboury, S., Bouchard, B., & Bouzouane, A. (2015). Nonintrusive system for assistance and guidance in smart homes based on electrical devices identiﬁcation. Expert Systems with Applications, 42(19), 6552–6577. Chang, H. H., Chen, K. L., Tsai, Y. P., & Lee, W. J. (2011). A new measurement method for power signatures of nonintrusive demand monitoring and load identiﬁcation. IEEE Transactions on Industry Applications, 48(2), 764–771. Chang, H. H., Lin, L. S., Chen, N., & Lee, W. J. (2013). Particle-swarm-optimization- based nonintrusive demand monitoring and load identiﬁcation in smart meters. IEEE Transactions on Industry Applications, 49(5), 2229–2236. Chang, H. H., Lian, K. L., Su, Y. C., & Lee, W. J. (2013). Energy spectrum-based wavelet transform for non-intrusive demand monitoring and load identiﬁcation. In 2013 IEEE Industry Applications Society Annual Meeting (pp. 1–9). IEEE. Chemali, E., Kollmeyer, P. J., Preindl, M., Ahmed, R., & Emadi, A. (2017). Long short- term memory networks for accurate state-of-charge estimation of Li-ion batteries. IEEE Transactions on Industrial Electronics, 65(8), 6730–6739. Cominola, A., Giuliani, M., Piga, D., Castelletti, A., & Rizzoli, A. E. (2017). A hybrid signature-based iterative disaggregation algorithm for non-intrusive load monitoring. Applied Energy, 185, 331–344. Cortez, B., Carrera, B., Kim, Y. J., & Jung, J. Y. (2018). An architecture for emergency event prediction using LSTM recurrent neural networks. Expert Systems with Applications, 97, 315–324. Dahl, G. E., Sainath, T. N., & Hinton, G. E. (2013). Improving deep neural networks for LVCSR using rectiﬁed linear units and dropout. In 2013 IEEE international conference on acoustics, speech and signal processing (pp. 8609–8613). IEEE. Du, L., Restrepo, J. A., Yang, Y., Harley, R. G., & Habetler, T. G. (2013). Nonintrusive, self-organizing, and probabilistic classiﬁcation and identiﬁcation of plugged-in electric loads. IEEE Transactions on Smart Grid, 4(3), 1371–1380. Esa, N. F., Abdullah, M. P., & Hassan, M. Y. (2016). A review disaggregation method in non-intrusive appliance load monitoring. Renewable and Sustainable Energy Reviews, 66, 163–173. Evora, J., Hernandez, J. J., & Hernandez, M. (2015). A MOPSO method for direct load control in smart grid. Expert Systems with Applications, 42(21), 7456–7465. Fernandez, A., Garcia, S., Herrera, F., & Chawla, N. V. (2018). SMOTE for learning from imbalanced data: progress and challenges, marking the 15-year anniversary. Journal of Artiﬁcial Intelligence Research, 61, 863–905. Froehlich, J., Larson, E., Gupta, S., Cohn, G., Reynolds, M., & Patel, S. (2010). Disaggregated end-use energy sensing for the smart grid. IEEE Pervasive Computing, 10(1), 28–39. Goodfellow, I. (2016). NIPS 2016 tutorial: generative adversarial networks. arXiv preprint arXiv: 1701.00160. Graves, A. (2012). Supervised sequence labelling. In Supervised sequence labelling with recurrent neural networks (pp. 5–13). Berlin, Heidelberg: Springer. M. Xia et al. / Expert Systems with Applications 160 (2020) 113669 15 Guo, Z., Wang, Z. J., & Kashani, A. (2014). Home appliance load modeling from aggregated smart meter data. IEEE Transactions on Power Systems, 30(1), 254–262. Hart, G. W. (1992). Nonintrusive appliance load monitoring. Proceedings of the IEEE, 80(12), 1870–1891. Hassan, T. (2012). Bi-level characterization of manual setup residential non- intrusive demand disaggregation using enhanced differential evolution. In Proc. 1st Int. Workshop Non-Intrusive Load Monitoring. Hassan, T., Javed, F., & Arshad, N. (2013). An empirical investigation of VI trajectory based load signatures for non-intrusive load monitoring. IEEE Transactions on Smart Grid, 5(2), 870–878. He, D., Du, L., Yang, Y., Harley, R., & Habetler, T. (2012). Front-end electronic circuit topology analysis for model-driven classiﬁcation and monitoring of appliance loads in smart buildings. IEEE Transactions on Smart Grid, 3(4), 2286–2293. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770–778). Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9(8), 1735–1780. Huang, G., Liu, Z., Van Der Maaten, L., & Weinberger, K. Q. (2017). Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4700–4708). Huang, Z., Xu, W., & Yu, K. (2015). Bidirectional LSTM-CRF models for sequence tagging. arXiv preprint arXiv: 1508.01991. Johnson, M. J., & Willsky, A. S. (2013). Bayesian nonparametric hidden semi-Markov models. Journal of Machine Learning Research, 14(Feb), 673–701. Kelly, J., & Knottenbelt, W. (2015). Neural NILM: deep neural networks applied to energy disaggregation. In Proceedings of the 2nd ACM international conference on embedded systems for energy-efﬁcient built environments (pp. 55–64). ACM. Kim, H., Marwah, M., Arlitt, M., Lyon, G., & Han, J. (2011). Unsupervised disaggregation of low frequency power measurements. In Proceedings of the 2011 SIAM international conference on data mining (pp. 747–758). Society for Industrial and Applied Mathematics. Kim, J., Le, T. T. H., & Kim, H. (2017). Nonintrusive load monitoring based on advanced deep learning and novel signature. Computational Intelligence and Neuroscience, 2017. Kiperwasser, E., & Goldberg, Y. (2016). Simple and accurate dependency parsing using bidirectional LSTM feature representations. Transactions of the Association for Computational Linguistics, 4, 313–327. Kolter, J. Z., Batra, S., & Ng, A. Y. (2010). Energy disaggregation via discriminative sparse coding. In Advances in neural information processing systems (pp. 1153–1161). Kolter, J. Z., & Johnson, M. J. (2011). REDD: A public data set for energy disaggregation research. Workshop on data mining applications in sustainability (SIGKDD), San Diego, CA (vol. 25, pp. 59–62). Kong, W., Dong, Z. Y., Jia, Y., Hill, D. J., Xu, Y., & Zhang, Y. (2017). Short-term residential load forecasting based on LSTM recurrent neural network. IEEE Transactions on Smart Grid. Lee, W. K., Fung, G. S. K., Lam, H. Y., Chan, F. H. Y., & Lucente, M. (2004). Exploration on load signatures. International conference on electrical Engineering (ICEE) (Vol. 152). Lin, Y. H., & Tsai, M. S. (2013). Development of an improved time-frequency analysis-based nonintrusive load monitor for load demand identiﬁcation. IEEE Transactions on Instrumentation and Measurement, 63(6), 1470–1483. Lin, Y. H., & Tsai, M. S. (2014). Non-intrusive load monitoring by novel neuro-fuzzy classiﬁcation considering uncertainties. IEEE Transactions on Smart Grid, 5(5), 2376–2384. Lundberg, S.M., & Lee, S.I. (2017). A uniﬁed approach to interpreting model predictions. Advances in Neural Information Processing Systems, 2017-Decem (Section 2), 4766–4775. Makonin, S., Popowich, F., Bartram, L., Gill, B., & Baji, I. V. (2013). AMPds: a public dataset for load disaggregation and eco-feedback research. In 2013 IEEE electrical power & energy conference (pp. 1–6). IEEE. Mauch, L., & Yang, B. (2015). A new approach for supervised power disaggregation by using a deep recurrent LSTM network. In 2015 IEEE global conference on signal and information processing (GlobalSIP) (pp. 63–67). IEEE. Martinez, R., Pacheco, D., & Robergs, D. (2018). NILM power disaggregation via artiﬁcial neural networks. In Proceeding of the 4th international workshop on non- intrusive load monitoring (pp. 1–4). Martins, P. B. de M., Pinto, R. G. D., & Bittencourt, S. P. (2018). Load disaggregation of industrial machinery power consumption monitoring using factorial hidden markov models. The international workshop on non-intrusive load monitoring (NILM), 6. Munshi, A. A., & Mohamed, Y. A. R. I. (2017). Extracting and deﬁning ﬂexibility of residential electrical vehicle charging loads. IEEE Transactions on Industrial Informatics, 14(2), 448–461. Pecan Street Inc, (2013).http://DataPort.Cloud. Park, S. W., Baker, L. B., & Franzon, P. D. (2019). Appliance identiﬁcation algorithm for a non-intrusive home energy monitor using cogent confabulation. IEEE Transactions on Smart Grid, 10(1), 714–721. Parson, O., Ghosh, S., Weal, M., & Rogers, A. (2014). An unsupervised training method for non-intrusive appliance load monitoring. Artiﬁcial Intelligence, 217, 1–19. Paterakis, N. G., Erdinc, O., Bakirtzis, A. G., & Catalao, J. P. (2015). Optimal household appliances scheduling under day-ahead pricing and load-shaping demand response strategies. IEEE Transactions on Industrial Informatics, 11(6), 1509–1519. Pereira, L., & Nunes, N. J. (2018). An experimental comparison of performance metrics for event detection Algorithms in NILM. In Proceedings of the 2016 workshop on smart grids at the 2016 IEEE international conference on big data (BigData ’16). https://doi.org/10.1145/2674061.2675037. Piga, D., Cominola, A., Giuliani, M., Castelletti, A., & Rizzoli, A. E. (2015). Sparse optimization for automated energy end use disaggregation. IEEE Transactions on Control Systems Technology, 24(3), 1044–1051. Shao, H., Marwah, M., & Ramakrishnan, N. (2013). A temporal motif mining approach to unsupervised energy disaggregation: Applications to residential and commercial buildings. In Twenty-seventh AAAI conference on artiﬁcial intelligence. Tsai, M. S., & Lin, Y. H. (2012). Modern development of an adaptive non-intrusive appliance load monitoring system in electricity energy conservation. Applied Energy, 96, 55–73. Rahimpour, A., Qi, H., Fugate, D., & Kuruganti, T. (2017). Non-intrusive energy disaggregation using non-negative matrix factorization with sum-to-k constraint. IEEE Transactions on Power Systems, 32(6), 4430–4441. Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). Why should i trust you? Explaining the predictions of any classiﬁer. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining (pp. 1135–1144). Ridi, A., Gisler, C., & Hennebert, J. (2014). In A survey on intrusive load monitoring for appliance recognition In 2014 22nd International Conference on Pattern Recognition (pp. 3702–3707). IEEE. Saitoh, T., Osaki, T., Konishi, R., & Sugahara, K. (2010). Current sensor based home appliance and state of appliance recognition. SICE Journal of Control, Measurement, and System Integration, 3(2), 86–93. Singh, S., & Majumdar, A. (2017). Deep sparse coding for non-intrusive load monitoring. IEEE Transactions on Smart Grid, 9(5), 4669–4678. Singhal, V., Maggu, J., & Majumdar, A. (2018). Simultaneous detection of multiple appliances from smart-meter measurements via multi-label consistent deep dictionary learning and deep transform learning. IEEE Transactions on Smart Grid. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overﬁtting. The Journal of Machine Learning Research, 15(1), 1929–1958. Ting, F. F., Tan, Y. J., & Sim, K. S. (2019). Convolutional neural network improvement for breast cancer classiﬁcation. Expert Systems with Applications, 120, 103–115. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998–6008). Wang, Z., & Zheng, G. (2011). Residential appliances identiﬁcation and monitoring by a nonintrusive method. IEEE Transactions on Smart Grid, 3(1), 80–92. Welikala, S., Dinesh, C., Ekanayake, M. P. B., Godaliyadda, R. I., & Ekanayake, J. (2019). Incorporating appliance usage patterns for non-intrusive load monitoring and load forecasting. IEEE Transactions on Smart Grid, 10(1), 448–461. Williams, R. J., & Zipser, D. (1989). A learning algorithm for continually running fully recurrent neural networks. Neural Computation, 1(2), 270–280. Xia, M., Liu, W., Wang, K., Zhang, X., & Xu, Y. (2019). Non-intrusive load disaggregation based on deep dilated residual network. Electric Power Systems Research, 170, 277–285. Xia, M., Liu, W., Xu, Y., Wang, K., & Zhang, X. (2019). Dilated residual attention network for load disaggregation. Neural Computing and Applications, 31(12), 8931–8953. You, G. W., Park, S., & Oh, D. (2017). Diagnosis of electric vehicle batteries using recurrent neural networks. IEEE Transactions on Industrial Electronics, 64(6), 4885–4893. Zaen, J. Van, Achkar, C. El, Carrillo, R., & Hutter, A. (2018). Detection and classiﬁcation of refrigeration units in a commercial environment: comparing neural networks to unsupervised clustering.Nilmworkshop.Org. Zeyer, A., Doetsch, P., Voigtlaender, P., Schlöter, R., & Ney, H. (2017). A comprehensive study of deep bidirectional LSTM RNNs for acoustic modeling in speech recognition. In 2017 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 2462–2466). IEEE. Zoha, A., Gluhak, A., Imran, M., & Rajasegarar, S. (2012). Non-intrusive load monitoring approaches for disaggregated energy sensing: a survey. Sensors, 12 (12), 16838–16866. Zhu, W., Lan, C., Xing, J., Zeng, W., Li, Y., Shen, L., & Xie, X. (2016). Co-occurrence feature learning for skeleton based action recognition using regularized deep LSTM networks. In Thirtieth AAAI conference on artiﬁcial intelligence. 16 M. Xia et al. / Expert Systems with Applications 160 (2020) 113669","libVersion":"0.3.2","langs":""}