{"path":"lit/lit_sources.backup/Shwartz-Ziv21deepVsTreeTabData.pdf","text":"Introduction — Solar Resource Assessment in Python 2 Solar Components — Solar Resource Assessment in Python 3 Solar Position — Solar Resource Assessment in Python 4 Manipulating Time-series — Solar Resource Assessment in Python 11 Ground-based solar irradiance data — Solar Resource Assessment in Python 21 Solar Decomposition Models — Solar Resource Assessment in Python 22 Baseline Surface Radiation Network (BSRN) — Solar Resource Assessment in Python 26 Solar Radiation Monitoring Laboratory (SRML) — Solar Resource Assessment in Python 30 Quality assessment of solar irradiance data — Solar Resource Assessment in Python 32 Solar Power Modelling — Solar Resource Assessment in Python 40 Site Adaptation — Solar Resource Assessment in Python 47 Glossary — Solar Resource Assessment in Python 51 Solar Resource for High Penetration and Large Scale Applications - IEA- PVPS 52 Introduction Contents !\"How to contribute !\"Feedback AssessingSolar is a practical guide to solar resource assessment in Python, aiming to make it easy to obtain solar radiation data, apply radiation models, and make accurate forecasts. The development of this guide is a collaborative effort within the IEA Photovoltaic Power Systems Programme (PVPS) Task 16. Contrary to traditional textbooks or scientific articles, this guide presents the various topics of solar resource assessment with interactive plots and documented how-to examples using Python code. This is achieved using Jupyter Notebooks, which permits seamless integration of explanatory text, code examples, figures, mathematical equations, and references. The Python programming language was chosen as it is open-source, easy to learn, and the primary choice for the majority of open-source solar and PV libraries, including pvlib python, which will be used extensively in this guide. How to contribute We happily welcome contributions! You can either make a pull request, open an issue, or write to assessingsolar@gmail.com with any comments or suggestions. Feedback We’re always looking for ways to improve this website, so we hope that you will help us out by filling out this 1-min user survey. You can write any suggestions for improvements or corrections. Even if you don’t have any comments, we would highly appreciate getting some statistics on our users to target our content. By The Assessing Solar Community © Copyright 2022. Introduction — Solar Resource Assessment in Python https://assessingsolar.org/intro.html 1 of 1 9/28/22, 5:59 PM Solar Components This site is under construction. By The Assessing Solar Community © Copyright 2022. Solar Components — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_components.html# 1 of 1 9/28/22, 6:00 PM Solar Position Contents !\"Solar position system !\"Solar position algorithms !\"Applications of solar position !\"Summary !\"References Solar position is a fundamental aspect of solar resource assessment. The different angles used in the reference system to locate the sun at a particular time and location are probably the most common input in solar resource modelling and assessment. In this section, we cover: !\"Solar position system; !\"Solar position algorithms; and !\"Applications of solar position. Content by Jesus Polo & Javier Lopez Lorente Solar position system The reference solar position system used for solar systems is usually a horizontal coordinate system focused on the observer. In this system, any observed placed at a given latitude and longitude is completeley determined by the zenith ( ) and azimuth angles (see Figure). The solar elevation angle ( ) is the complementary of the zenith solar angle ( = 90 - ). In Python, the solar position angles can be easily calculated at any site using the solar position algorithm (SPA) of pvlib, which has implemented by default with NREL’s SPA algorithm (Reda and Andreas, 2003). We will show and compare the different solar position algorithms available in pvlib and show how solar position angles can be estimated in several ways. θ ϕ α α θ Solar Position — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_position.html 1 of 7 9/28/22, 6:00 PM Let’s import the required libraries and see an example: A way to estimate the solar position is through the object pvlib.location.Location in the library pvlib, which helps defining its particular geographic location (e.g., latitude, longitude, timezone, and altitude). apparent_zenith zenith apparent_elevation elevation azimuth equation_of_time 2018-01-01 00:00:00-01:00 160.468395 160.468395 -70.468395 -70.468395 29.900075 -3.346090 2018-01-01 01:00:00-01:00 152.396698 152.396698 -62.396698 -62.396698 58.528284 -3.365720 2018-01-01 02:00:00-01:00 141.889229 141.889229 -51.889229 -51.889229 75.239601 -3.385340 2018-01-01 03:00:00-01:00 130.627975 130.627975 -40.627975 -40.627975 86.856662 -3.404951 2018-01-01 04:00:00-01:00 119.234764 119.234764 -29.234764 -29.234764 96.389095 -3.424553 Alternatively, the function pvlib.solarposition.get_solarposition() can be used to obtain the same result: apparent_zenith zenith apparent_elevation elevation azimuth equation_of_time 2018-01-01 00:00:00-01:00 160.468395 160.468395 -70.468395 -70.468395 29.900075 -3.346090 2018-01-01 01:00:00-01:00 152.396698 152.396698 -62.396698 -62.396698 58.528284 -3.365720 2018-01-01 02:00:00-01:00 141.889229 141.889229 -51.889229 -51.889229 75.239601 -3.385340 2018-01-01 03:00:00-01:00 130.627975 130.627975 -40.627975 -40.627975 86.856662 -3.404951 2018-01-01 04:00:00-01:00 119.234764 119.234764 -29.234764 -29.234764 96.389095 -3.424553 We observe that both lines of code return the same output. After the solar angles are estimated, these can be visualized: # Libraries import numpy as np import pandas as pd import matplotlib.pyplot as plt import pvlib from pvlib.location import Location # Definition of Location oject. Coordinates and elevation of Madrid Ciemat Headquarters (Spain) site = Location(40.456, -3.73, 'Etc/GMT+1', 651, 'Ciemat (Madrid, ES)') # latitude, longitude, time_zone, altitude, name # Definition of a time range of simulation times = pd.date_range('2018-01-01 00:00:00', '2018-12-31 23:59:00', closed='left', freq='H', tz=site.tz) # Estimate Solar Position with the 'Location' object solpos = site.get_solarposition(times) # Visualize the resulting DataFrame solpos.head() # Alternative method using the 'solarposition.get_solarposition' function solpos = pvlib.solarposition.get_solarposition(times, site.latitude, site.longitude, site.altitude) solpos.head() Solar Position — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_position.html 2 of 7 9/28/22, 6:00 PM Solar position algorithms In the example above, we used the default SPA available in pvlib. However, there are several algorithms for estimating the solar position implemented in pvlib. You can use your preferred algorithm by defining the argument method when calling the function get_solarposition(). The 5 avaiable SPAs are: !\"nrel_numpy: based on NREL SPA method where pvlib uses the function ‘spa_python()’. !\"nrel_numba: simular to ‘nrel_numpy’, but the code is compiled first. !\"pyephem: based on the PyEphem package, pvlib uses the function ‘pyephem()’. !\"ephemeris: based on the pvlib ephemeris code, uses the function ‘ephemeris()’. !\"nrel_c: based on NREL SPA code in C language: spa_c() There are other solar position algorithms available in the literature, for example, the Solar Geometry 2 (SG2) model (Blanc and Wald, 2012), which is available in Matlab and C language. Below, we will compare some of these methods, namely: NREL SPA (‘nrel_numpy’), PyEphem (‘pyephem’) and Ephemeris (‘ephemeris’). We can visualize the differences in the estimations of the solar zenith angle: import matplotlib.dates as mdates # Plots for solar zenith and solar azimuth angles fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) fig.suptitle('Solar Position Estimation in ' + site.name + ' 21st June') # plot for solar zenith angle ax1.plot(solpos.loc['2018-06-21'].zenith) ax1.set_ylabel('Solar zenith angle (degree)') ax1.set_xlabel('Time (hour)') ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H')) # plot for solar azimuth angle ax2.plot(solpos.loc['2018-06-21'].azimuth) ax2.set_ylabel('Solar azimuth angle (degree)') ax2.set_xlabel('Time (hour)') ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H')) # Estimate the solar position with a specific SPA defined with the argument 'method' solpos_nrel = pvlib.solarposition.get_solarposition(times, site.latitude, site.longitude, site.altitude, method='nrel_numpy') solpos_pyephem = pvlib.solarposition.get_solarposition(times, site.latitude, site.longitude, site.altitude, method='pyephem') solpos_ephemeris = pvlib.solarposition.get_solarposition(times, site.latitude, site.longitude, site.altitude, method='ephemeris') Solar Position — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_position.html 3 of 7 9/28/22, 6:00 PM We can visualize the differences in the estimations of the solar azimuth angle: The absolute differences between methods can then be computed: fig, axs = plt.subplots(1,3, figsize=(15, 6), facecolor='w', edgecolor='k') fig.subplots_adjust(hspace = .5, wspace=.001) # Wrap the axes axs = axs.ravel() # Plot axs[0].plot(solpos_nrel['zenith']-solpos_pyephem['zenith']) axs[1].plot(solpos_nrel['zenith']-solpos_ephemeris['zenith']) axs[2].plot(solpos_pyephem['zenith']-solpos_ephemeris['zenith']) # Add characteristics to each subplot in a loop plots = [\"NREL SPA ('nrel_numpy') & PyEphem\", \"NREL SPA ('nrel_numpy') & Ephemeris\", \"PyEphem & Ephemeris\"] for i in range(3): axs[i].set_xlabel('Month') axs[i].set_ylabel('Difference (degree)') axs[i].set_title(plots[i]) axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%b')) plt.tight_layout() plt.show() fig, axs = plt.subplots(1,3, figsize=(15, 6), facecolor='w', edgecolor='k') fig.subplots_adjust(hspace = .5, wspace=.001) # Wrap the axes axs = axs.ravel() # Plot axs[0].plot(solpos_nrel['azimuth']-solpos_pyephem['azimuth']) axs[1].plot(solpos_nrel['azimuth']-solpos_ephemeris['azimuth']) axs[2].plot(solpos_pyephem['azimuth']-solpos_ephemeris['azimuth']) # Add characteristics to each subplot in a loop plots = [\"NREL SPA ('nrel_numpy') & PyEphem\", \"NREL SPA ('nrel_numpy') & Ephemeris\", \"PyEphem & Ephemeris\"] for i in range(3): axs[i].set_xlabel('Month') axs[i].set_ylabel('Difference (degree)') axs[i].set_title(plots[i]) axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%b')) plt.tight_layout() plt.show() Solar Position — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_position.html 4 of 7 9/28/22, 6:00 PM We observe that the differences among methods are small in the range of 0.01 degree. Applications of solar position The use of solar position algorithms in solar resource can have several direct applications. For example, the visualization of sun path diagrams or the estimation of sunrise, sunset and solar transit time. The solar analemma One of the applications of solar position can creating the solar analemman. An analemma is a diagram showing the position of the Sun in the sky as seen from a fixed location on Earth at the same mean solar time. In Python, we could implement the analemma as follows: # compute the absolute difference in Solar Zenith Angle between SPA methods nrel_pyephem = np.abs(solpos_nrel['zenith']-solpos_pyephem['zenith']).max() nrel_ephemeris = np.abs(solpos_nrel['zenith']- solpos_ephemeris['zenith']).max() pyephem_ephemeris = np.abs(solpos_pyephem['zenith']- solpos_ephemeris['zenith']).max() # list of variables spa_methods_sza = [nrel_pyephem, nrel_ephemeris, pyephem_ephemeris] # Solar Zenith Angle # compute the absolute difference in Solar Zenith Angle between SPA methods nrel_pyephem = np.abs(solpos_nrel['azimuth']- solpos_pyephem['azimuth']).max() nrel_ephemeris = np.abs(solpos_nrel['azimuth']- solpos_ephemeris['azimuth']).max() pyephem_ephemeris = np.abs(solpos_pyephem['azimuth']- solpos_ephemeris['azimuth']).max() # list of variables spa_methods_azi = [nrel_pyephem, nrel_ephemeris, pyephem_ephemeris] # Solar Azimuth Angle spa_names = ['NREL & PyEphem','NREL & Ephemeris','PyEphem & Ephemeris'] print(\"Absolute differences between solar position algorithms:\\n\" + \"-\"*55) print(\"Solar Zenith Angle\") for i in range(len(spa_names)): print(\"-\", spa_names[i], \": {:.5f}\".format(spa_methods_sza[i])) print(\"\\nSolar Azimuth Angle\") for i in range(len(spa_names)): print(\"-\", spa_names[i], \": {:.5f}\".format(spa_methods_azi[i])) Absolute differences between solar position algorithms: ------------------------------------------------------- Solar Zenith Angle - NREL & PyEphem : 0.00014 - NREL & Ephemeris : 0.00835 - PyEphem & Ephemeris : 0.00844 Solar Azimuth Angle - NREL & PyEphem : 0.00049 - NREL & Ephemeris : 0.01666 - PyEphem & Ephemeris : 0.01715 Solar Position — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_position.html 5 of 7 9/28/22, 6:00 PM Sun path diagrams throughout the day are another application of the solar angles. There are some well documented examples availabe for sun path diagrams in the documentation of pvlib. Other applications Solar position angles can also be used to estimate the sunrise, sunset and solar transit time. pvlib has specific functions to estimate these times with different methods: NREL’s SPA, PyEphem package and geometric calculation. The Equation of Time can also be estimated using the available pvlib functions related to solar position. In fact, it is one of the available outputs when using the NREL’s SPA method. The equation of time is the difference apparent solar time minus mean solar time. In other words, if the sun is ahead of the clock the sign is positive, and if the clock is ahead of the sun the sign is negative. Let’s see how the equation of time looks: # Definition of a times (noon) times = pd.date_range('2020-01-01 12:00:00', '2021-01-01 12:00:00', closed='left', freq='W', tz='UTC') # Solar Position Estimation for the object 'site' (CIEMAT, Madrid (Spain)) solpos = site.get_solarposition(times) # Plotting the Analemma plt.scatter(solpos['azimuth'], solpos['apparent_elevation'], marker=\"*\", c=times.isocalendar().week, cmap='plasma') cbar = plt.colorbar() cbar.set_label('Week of Year') plt.xlabel('Solar Azimuth Angle (degree)') plt.ylabel('Solar Elevation Angle (degree)') plt.title('Solar Analemma in ' + site.name + ' at noon (UTC)') plt.grid() plt.show() fig, ax1 = plt.subplots() ax1 = solpos_nrel['equation_of_time'].plot(zorder=2) ax1.hlines(0, solpos_nrel.index[0], solpos_nrel.index[-1], color='black', zorder=1) ax1.set_ylabel('Minutes') plt.title('Equation of Time') plt.show() Solar Position — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_position.html 6 of 7 9/28/22, 6:00 PM Summary This section has introduced the basics of solar position and how to estimate in Python the characteristic angles used in solar energy applications. Particularly, the following examples have been covered: !\"The estimation of solar angles using function-based and object-oriented code. !\"The estimation solar angles attending to several solar position algorithms currently available in pvlib. Comparison of the methods: NREL SPA, PyEphem and Ephemeris. !\"Several applications in the use of solar angles (e.g., solar analemma) have been shown. Solar angles are typically used as input to multiple solar resource modelling techniques and you will find in other sections of AssessingSolar.org. References Blanc, P.; Wald, L. (2012). The SG2 algorithm for a fast and accurate computation of the position of the Sun for multi-decadal time period. Solar Energy, Elsevier, 88 (10), pp. 3072-3083. doi:10.1016/j.solener.2012.07.018 Reda, I.; Andreas, A. (2003). Solar Position Algorithm for Solar Radiation Applications. 55 pp.; NREL Report No. TP-560-34302, Revised January 2008. https://www.nrel.gov /docs/fy08osti/34302.pdf Rhodes B. C. (2011). PyEphem: Astronomical Ephemeris for Python (ascl:1112.014) https://ui.adsabs.harvard.edu/abs/2011ascl.soft12014R By The Assessing Solar Community © Copyright 2022. Solar Position — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_position.html 7 of 7 9/28/22, 6:00 PM Manipulating Time-series Contents !\"1 Time-series handling !\"2 Down and up-sampling time-series data !\"3 Interpolating time-series data !\"4 Visualizing time-series data !\"Section summary !\"References Time-series are a key element when assessing solar resource data. In this section, we present several examples to learn how to deal with different formats in the data and few common tasks to prepare our time-series for later analysis, such as down and up-sampling data when we need different temporal resolution than that initially available or interpolating missing values in the data. The dataset used in the examples of this section is a customized dataset using solar radiation measurements from the Measurement and Instrumentation Data Center (MIDC) of the U.S. National Renewable Energy Laboratory (NREL). The station selected is located at the University of Nevada - Las Vegas (UNLV) and the data used are 1-minute GHI, DHI and DNI measurements for the year 2020 []. In this section, we cover: !\"1 Time-series handling !\"2 Down and up-sampling time-series data !\"3 Interpolating time-series data !\"4 Visualizing time-series data Content by Javier Lopez Lorente 1 Time-series handling Datasets often come in different formats depending on the source. Those formats sometimes cannot be used straightaway to build a time-series and may require additional processing steps before building the time-series. For example: !\"What if date and time are in different columns? !\"What if the year, month, day and time are in separate columns? !\"How to the define the timestamp format for a particular dataset? !\"How to deal with timestamp issues, local vs. universal (UTC) time? This subsection presents several examples to deal with different formats in which time-series data could come and shows how to build a time-series or datetime series, as known in Python, for later analysis. The processing steps to build time-series are based on pandas library. Let’s get started! 1.1 Build our customized dataset In order to build the customized dataset for this section, we make use of the I/O tools of the Python library pvlib to retrieve the data from the UNLV station in the MIDC. Data from other stations from the MIDC can be also retrieved using this method by adapting the station ID in the query. The different station IDs are available in the MIDC raw data page. Unnamed: 0 year DOY PST dni ghi Global UVA [W/m^2] Global UVE [W/m^2] Global UVE [Index] Dry Bulb Temp [deg C] ... Avg Wind Direction @ 30ft [deg from N] Peak Wind Speed @ 30ft [m/s] UVSAET Temp [deg C] Logger Temp [deg C] Logger Battery [VDC] Wind Chill Temp [deg C] dhi Zenith Angle [degrees] 2020-01-01 00:00:00-08:00 0 2020 1 0 -1.67051 -2.53035 -0.005 0.0 0.002 6.004 ... 17.67 0.098 24.9 22.25 13.28 6.004 0.0 166.494 2020-01-01 00:01:00-08:00 0 2020 1 1 -1.64962 -2.53035 -0.007 0.0 0.003 6.210 ... 8.79 1.176 24.9 22.26 13.28 6.210 0.0 166.435 2 rows × 21 columns Unnamed: 0 year DOY PST dni ghi Global UVA [W/m^2] Global UVE [W/m^2] Global UVE [Index] Dry Bulb Temp [deg C] ... Avg Wind Direction @ 30ft [deg from N] Peak Wind Speed @ 30ft [m/s] UVSAET Temp [deg C] Logger Temp [deg C] Logger Battery [VDC] Wind Chill Temp [deg C] dhi Zenith [degrees] 2020-12-31 23:58:00-08:00 0 2020 366 2358 0.000000 -3.09366 -0.016 0.0 0.003 10.45 ... 4.834 7.546 24.75 18.97 13.34 8.06 0.0 166.558 2020-12-31 23:59:00-08:00 0 2020 366 2359 0.473466 -3.09367 -0.015 0.0 0.003 10.46 ... 7.997 6.664 24.81 18.97 13.35 8.24 0.0 166.507 2 rows × 21 columns # Importing the needed libraries import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import pvlib # Dictionary to rename certain variables from the raw data var_map = {'Global Horiz [W/m^2]': 'ghi', 'Direct Normal [W/m^2]':'dni', 'Diffuse Horiz (calc) [W/m^2]':'dhi', 'Year':'year'} # Retrieving the raw data from the station df_ref = pvlib.iotools.read_midc_raw_data_from_nrel('UNLV', # Station id pd.Timestamp('20200101'), # Start date YYYYMMDD pd.Timestamp('20201231'), # End date YYYYMMDD variable_map=var_map) # Variable Map # Let's have a look to the first 2 rows of the dataset df_ref.head(2) # Let's have a look to the last 2 rows of the dataset df_ref.tail(2) Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 1 of 10 9/28/22, 6:01 PM The dataset is 1-minute resolution data with 21 variables related to meteorological and other relevant data: ambient temperature, wind speed, wind direction, global horizontal irradiance (GHI), direct normal irradiance (DNI), diffuse horizontal irradiance (DHI), zenith and azimuth angles, airmass, among other. For the examples in this section we will use GHI, DNI and DHI measurements and time-related data. Let’s visualize the first rows of the customized reference dataframe: ghi dni dhi year month day hour minute date time timestamp epoch 0 -2.53035 -1.670510 0.0 2020 1 1 0 0 2020-01-01 00:00:00 2020-01-01 00:00:00-0800 1.577866e+09 1 -2.53035 -1.649620 0.0 2020 1 1 0 1 2020-01-01 00:01:00 2020-01-01 00:01:00-0800 1.577866e+09 2 -2.53035 -0.856135 0.0 2020 1 1 0 2 2020-01-01 00:02:00 2020-01-01 00:02:00-0800 1.577866e+09 Now that we have our customized reference dataset of 1-minute irradiance measurements for 2020 and temporal data, we can start building the timeseries in different ways. 1.2 Time-series when timestamps are available: When timestamps are available, the most straightforward way to build the DataFrame with a datetime index is to convert the column with the timestamp into datetime format and set it as index. Let’s see how! ghi dni dhi year month day hour minute date time timestamp epoch timestamp 2020-01-01 00:00:00-08:00 -2.53035 -1.670510 0.0 2020 1 1 0 0 2020-01-01 00:00:00 2020-01-01 00:00:00-08:00 1.577866e+09 2020-01-01 00:01:00-08:00 -2.53035 -1.649620 0.0 2020 1 1 0 1 2020-01-01 00:01:00 2020-01-01 00:01:00-08:00 1.577866e+09 2020-01-01 00:02:00-08:00 -2.53035 -0.856135 0.0 2020 1 1 0 2 2020-01-01 00:02:00 2020-01-01 00:02:00-08:00 1.577866e+09 The format of the timestamp is specified in the argument ‘format’ as a string and can be adapted to any case. The available options in Python can be checked in this link. Universal Time Coordinated (UTC) is usually the timestamp provided for many solar radiation data networks and platforms like the BSRN, PVGIS, etc. However, data can be also reported in local time like in our example. Timestamps can be converted to other timezones with the funcion tz_convert, which can be useful when dealing with data from different databases and locations worldwide: ghi dni dhi year month day hour minute date time timestamp epoch timestamp_utc timestamp 2020-01-01 00:00:00-08:00 -2.53035 -1.670510 0.0 2020 1 1 0 0 2020-01-01 00:00:00 2020-01-01 00:00:00-08:00 1.577866e+09 2020-01-01 08:00:00+00:00 2020-01-01 00:01:00-08:00 -2.53035 -1.649620 0.0 2020 1 1 0 1 2020-01-01 00:01:00 2020-01-01 00:01:00-08:00 1.577866e+09 2020-01-01 08:01:00+00:00 2020-01-01 00:02:00-08:00 -2.53035 -0.856135 0.0 2020 1 1 0 2 2020-01-01 00:02:00 2020-01-01 00:02:00-08:00 1.577866e+09 2020-01-01 08:02:00+00:00 The valid timezone strings for other timezones can be found in this link. When the timezone is not provided as part of the timestamp, the function tz_localize can be used to localize the values in a timezone-naive series. tz_localize will be used in the next example. 1.3 Time-series when date and time are available: When date and time are available in separate columns, a timestamp can be created in a new column and the new column can then be set as index and localized. Let’s have a look how to do that: # Slice desired variables out of the 21 variables provided in the raw data. df_ref = df_ref[['ghi', 'dni', 'dhi', 'year']] # Add multiple temporal data to the dataset df_ref['month'] = df_ref.index.month df_ref['day'] = df_ref.index.day df_ref['hour'] = df_ref.index.hour df_ref['minute'] = df_ref.index.minute df_ref['date'] = df_ref.index.strftime('%Y-%m-%d') df_ref['time'] = df_ref.index.strftime('%H:%M:%S') df_ref['timestamp'] = df_ref.index.strftime('%Y-%m-%d %H:%M:%S%z') # Epoch format df_ref['epoch'] = df_ref.index.astype('int64')//1e9 # Reset the Index of the DataFrame df_ref = df_ref.reset_index(drop=True) # Let's have a look to the resulting columns of the dataset df_ref.columns /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /ipykernel_launcher.py:14: FutureWarning: casting datetime64[ns, Etc/GMT+8] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead. Index(['ghi', 'dni', 'dhi', 'year', 'month', 'day', 'hour', 'minute', 'date', 'time', 'timestamp', 'epoch'], dtype='object') # First 3 rows in the dataframe df_ref.head(3) # A new dataframe copy of the reference dataset df = df_ref.copy() # Convert the timestamp string into datetime format df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S%z') # Set timestamp column as index df = df.set_index(df['timestamp']) # See the first 3 rows of the DataFrame with Datetime Index df.head(3) # Add UTC timestamp from the local time (Pacific Summer Time) df['timestamp_utc'] = df.index.tz_convert('UTC') # See the first 3 rows df.head(3) Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 2 of 10 9/28/22, 6:01 PM ghi dni dhi year month day hour minute date time timestamp epoch datetime datetime 2020-01-01 00:00:00-08:00 -2.53035 -1.670510 0.0 2020 1 1 0 0 2020-01-01 00:00:00 2020-01-01 00:00:00-0800 1.577866e+09 2020-01-01 00:00:00 2020-01-01 00:01:00-08:00 -2.53035 -1.649620 0.0 2020 1 1 0 1 2020-01-01 00:01:00 2020-01-01 00:01:00-0800 1.577866e+09 2020-01-01 00:01:00 2020-01-01 00:02:00-08:00 -2.53035 -0.856135 0.0 2020 1 1 0 2 2020-01-01 00:02:00 2020-01-01 00:02:00-0800 1.577866e+09 2020-01-01 00:02:00 1.4 Time-series when the time data is split in multiple columns: If time-related data are split across multiple columns, a timestamp can be created in a new column similarly than in the previous case. Let’s imagine our dataset would have the year, month, day, hour, and minute in separate columns. In that case, we could build our time-series as follows: ghi dni dhi year month day hour minute date time timestamp epoch datetime datetime 2020-01-01 00:00:00-08:00 -2.53035 -1.670510 0.0 2020 1 1 0 0 2020-01-01 00:00:00 2020-01-01 00:00:00-0800 1.577866e+09 2020-01-01 00:00:00 2020-01-01 00:01:00-08:00 -2.53035 -1.649620 0.0 2020 1 1 0 1 2020-01-01 00:01:00 2020-01-01 00:01:00-0800 1.577866e+09 2020-01-01 00:01:00 2020-01-01 00:02:00-08:00 -2.53035 -0.856135 0.0 2020 1 1 0 2 2020-01-01 00:02:00 2020-01-01 00:02:00-0800 1.577866e+09 2020-01-01 00:02:00 1.5 Time-series when the timestamp is given as epoch (Unix Time) If the dataset has epoch timestamps, note that the data will have UTC time. However, it can be converted to any timezone using the function tz_convert. If there are epoch timestamps, a datetime series can be formed as follows: ghi dni dhi year month day hour minute date time timestamp epoch datetime datetime 2020-01-01 00:00:00-08:00 -2.53035 -1.670510 0.0 2020 1 1 0 0 2020-01-01 00:00:00 2020-01-01 00:00:00-0800 1.577866e+09 2020-01-01 08:00:00+00:00 2020-01-01 00:01:00-08:00 -2.53035 -1.649620 0.0 2020 1 1 0 1 2020-01-01 00:01:00 2020-01-01 00:01:00-0800 1.577866e+09 2020-01-01 08:01:00+00:00 2020-01-01 00:02:00-08:00 -2.53035 -0.856135 0.0 2020 1 1 0 2 2020-01-01 00:02:00 2020-01-01 00:02:00-0800 1.577866e+09 2020-01-01 08:02:00+00:00 We have seen how the same DataFrame with datetimeindex can be obtained in multiple ways depending on the format of time data provided. 2 Down and up-sampling time-series data When assessing solar resource, you may need a different time-resolution than your data for a particular part of the analysis. In those cases, it is possible to down-sample and up-sample the data at different temporal resolutions using two different methods within pandas library called resample and asfreq. Depending on your needs, you will opt for one or the other. Regardless of the method, both of them require a DataFrame with datetimeindex either time- aware (localized) or time-naive (not localized). 2.1 Method ‘asfreq’ vs. ‘resample’ Let’s first create a new DataFrame with only the columns with solar data and see the differences between both methods with examples. ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.53035 0.0 -1.670510 2020-01-01 00:01:00-08:00 -2.53035 0.0 -1.649620 2020-01-01 00:02:00-08:00 -2.53035 0.0 -0.856135 Let’s try to obtain a DataFrame down-sampled with the maximum monthly data with both methods and see the differences. With asfreq, it would be the following: # A new dataframe copy of the reference dataset df = df_ref.copy() # New column with the date and time df['datetime'] = df['date'] + 'T' + df['time'] # Convert the new column into datetime format df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%dT%H:%M:%S') # Set the column 'datetime' as index and localize it to its timezone df = df.set_index(df['datetime']).tz_localize('Etc/GMT+8') # See the first 3 rows df.head(3) # A new dataframe copy of the reference dataset df = df_ref.copy() # Let's reduce the code lines and define the new string within the 'to_datetime' function df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']], format = '%Y-%m-%d%H:%M') # Set the column 'datetime' as index df = df.set_index(df['datetime']) # Localize the datetime series df.index = df.index.tz_localize('Etc/GMT+8') # See the first 3 rows df.head(3) # A new dataframe copy of the reference dataset df = df_ref.copy() # Convert epoch timestamps to datetime format and localize df['datetime'] = pd.to_datetime(df['epoch'], unit='s', utc=True) # Set datetime as index and convert UTC time to local time df = df.set_index(df['datetime']).tz_convert('Etc/GMT+8') # See the results df.head(3) # New DataFrame with 1-minute data and solar data df_1min = df[['ghi', 'dhi', 'dni']] # See our new DataFrame df_1min.head(3) df_1min.asfreq(\"1M\").max() Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 3 of 10 9/28/22, 6:01 PM With resample the result would be: ghi dhi dni datetime 2020-01-31 00:00:00-08:00 802.383 386.083 972.789 2020-02-29 00:00:00-08:00 956.928 582.715 1024.650 2020-03-31 00:00:00-08:00 1237.910 632.961 1011.700 2020-04-30 00:00:00-08:00 1370.180 705.203 999.360 2020-05-31 00:00:00-08:00 1253.240 590.468 983.210 2020-06-30 00:00:00-08:00 1340.240 943.659 999.233 2020-07-31 00:00:00-08:00 1260.490 1056.520 1015.320 2020-08-31 00:00:00-08:00 1114.410 659.908 1010.130 2020-09-30 00:00:00-08:00 1081.750 670.886 959.591 2020-10-31 00:00:00-08:00 1047.400 895.895 2758.840 2020-11-30 00:00:00-08:00 902.913 411.350 973.702 2020-12-31 00:00:00-08:00 793.258 393.958 985.791 It is obvious that the outputs are not the same and that is because the methods work differently. asfreq takes the value at the simultaneous stamps given by the frequency argument. See below: ghi dhi dni datetime 2020-01-31 00:00:00-08:00 -3.65348 0.0 -1.669830 2020-02-29 00:00:00-08:00 -3.09137 0.0 -1.669820 2020-03-31 00:00:00-08:00 -2.52933 0.0 -0.834917 2020-04-30 00:00:00-08:00 -3.61963 0.0 -1.669340 2020-05-31 00:00:00-08:00 -3.22207 0.0 -1.669590 2020-06-30 00:00:00-08:00 -3.65326 0.0 -0.834868 2020-07-31 00:00:00-08:00 -4.21426 0.0 -1.857120 2020-08-31 00:00:00-08:00 -5.14251 0.0 -1.620990 2020-09-30 00:00:00-08:00 -4.21555 0.0 -1.690710 2020-10-31 00:00:00-08:00 -3.65348 0.0 -1.669830 2020-11-30 00:00:00-08:00 -3.09265 0.0 -1.670510 2020-12-31 00:00:00-08:00 -2.53110 0.0 -1.176670 Then .max() has returned the maximum of each of the columns. In contrast, resample does return the maximum value within the period of time at the specified frequency. resample method requires a mathematical operation to perform in the resampled data (the maximum value in our case). Otherwise, it would return a DatetimeIndexResampler object without showing any data. See below: The resample method accepts multiple mathematical and statistical operations. For example: maximum (max), minimum (min), arithmetic mean (mean), standard deviation (std), median (median), mode (mode), addition (sum), among others. Both methods allow for multiple frequencies options, the available frequency tags within Python can be found here. 2.2 Down-sampling the data in a time-series Down-sampling permits turning more frequent values into less frequent. In the context of solar resource and considering our 1-minute resolution dataset, down-sampling can be used for: !\"Producing a timeseries of hourly/daily average irradiance. !\"Producing a timeseries of maximum daily irradiance. !\"Estimating the hourly/daily/monthly sums of irradiation. !\"And many more! Let’s implement some of these listed examples! Producing hourly average irradiance from minutely observations There are 8760 hours in a year. Yet, we can have a look to the first few rows of the DataFrame: ghi -2.529330 dhi 0.000000 dni -0.834868 dtype: float64 df_1min.resample(\"1M\").max() df_1min.asfreq(\"1M\") df_1min.resample(\"1M\") <pandas.core.resample.DatetimeIndexResampler object at 0x7f381bf94450> # Resampling to hourly mean values df_hourly = df_1min.resample(\"1H\").mean() # Showing the shape of the new DataFrame df_hourly.shape # returns Rows, Columns (8784, 3) df_hourly.head(12) Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 4 of 10 9/28/22, 6:01 PM ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.576505 0.000000 -0.764837 2020-01-01 01:00:00-08:00 -2.508561 0.000000 -0.631080 2020-01-01 02:00:00-08:00 -1.943371 0.000000 -0.374704 2020-01-01 03:00:00-08:00 -2.023108 0.000000 -0.379228 2020-01-01 04:00:00-08:00 -1.683542 0.000000 -0.013457 2020-01-01 05:00:00-08:00 -1.891827 0.000000 -0.006960 2020-01-01 06:00:00-08:00 0.116990 0.351740 1.146154 2020-01-01 07:00:00-08:00 42.787289 42.289485 3.388552 2020-01-01 08:00:00-08:00 128.938495 114.490610 50.297509 2020-01-01 09:00:00-08:00 303.623558 163.197578 371.458155 2020-01-01 10:00:00-08:00 327.718433 248.435667 171.612487 2020-01-01 11:00:00-08:00 345.318217 304.172200 80.353128 A time-series with the maximum irradiance would be similar replacing ‘mean()’ with ‘max()’. Producing time-series of monthly total GHI, DHI, DNI irradiation from minutely observations ghi dhi dni datetime 2020-01-31 00:00:00-08:00 100.817440 29.251020 175.754908 2020-02-29 00:00:00-08:00 129.220507 30.514029 206.374110 2020-03-31 00:00:00-08:00 164.224723 59.140048 179.448458 2020-04-30 00:00:00-08:00 200.459859 59.307923 217.186189 2020-05-31 00:00:00-08:00 255.336215 54.922454 294.929842 2020-06-30 00:00:00-08:00 254.262295 62.085767 277.856782 2020-07-31 00:00:00-08:00 257.105784 48.821531 305.900237 2020-08-31 00:00:00-08:00 223.419662 56.213721 251.208590 2020-09-30 00:00:00-08:00 181.248566 58.956766 199.959672 2020-10-31 00:00:00-08:00 153.368877 51.432641 195.650044 2020-11-30 00:00:00-08:00 105.726263 25.099434 190.355946 2020-12-31 00:00:00-08:00 88.972596 25.698295 165.691623 It could be done in similar way for other resolutions (e.g. daily or annual irradiation). 2.3 Up-sampling the data in a time-series Up-sampling permits obtaining more frequent values from less frequent. For solar data, depending on the application up to sub-minutely data could be required and up-sampling is a technique that provides a manner to increase the temporal resolution to adapt it to our needs. For example, turning an hourly time-series into a half-hourly. Let’s see an example using both resample and asfreq. Producing half-hourly irradiance series from hourly observations Using the DataFrame df_hourly created previously, it can be up-sample as follows: ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.576505 0.0 -0.764837 2020-01-01 00:30:00-08:00 NaN NaN NaN 2020-01-01 01:00:00-08:00 -2.508561 0.0 -0.631080 2020-01-01 01:30:00-08:00 NaN NaN NaN 2020-01-01 02:00:00-08:00 -1.943371 0.0 -0.374704 2020-01-01 02:30:00-08:00 NaN NaN NaN 2020-01-01 03:00:00-08:00 -2.023108 0.0 -0.379228 2020-01-01 03:30:00-08:00 NaN NaN NaN 2020-01-01 04:00:00-08:00 -1.683542 0.0 -0.013457 2020-01-01 04:30:00-08:00 NaN NaN NaN # Resampling to monthly aggregated values monthly_energy = df_1min[['ghi', 'dhi', 'dni']].resample(\"1M\").sum()*(1/60) # See the results expressed in kWh·sqm monthly_energy/1000 # Using 'resample' method: df_hourly.resample(\"30Min\").mean().head(10) # Using 'asfreq' method: df_hourly.asfreq(\"30Min\").head(10) Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 5 of 10 9/28/22, 6:01 PM ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.576505 0.0 -0.764837 2020-01-01 00:30:00-08:00 NaN NaN NaN 2020-01-01 01:00:00-08:00 -2.508561 0.0 -0.631080 2020-01-01 01:30:00-08:00 NaN NaN NaN 2020-01-01 02:00:00-08:00 -1.943371 0.0 -0.374704 2020-01-01 02:30:00-08:00 NaN NaN NaN 2020-01-01 03:00:00-08:00 -2.023108 0.0 -0.379228 2020-01-01 03:30:00-08:00 NaN NaN NaN 2020-01-01 04:00:00-08:00 -1.683542 0.0 -0.013457 2020-01-01 04:30:00-08:00 NaN NaN NaN Contrary to the case of down-sampling, both asfreq and resample provide similar results when up-sampling. However, asfreq provides additional functionalities to treat the new timestamps without data, i.e. NaN values. By passing the argument ‘method’ with the string ‘backfill’ or ‘bfill’ uses the next valid observation to fill the NaN value (back filling). If instead, the string ‘pad’ or ‘ffill’ is given, the method assigns the last valid observation forward to the next valid (forward filling). Let’s see the same example adding this argument: ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.576505 0.0 -0.764837 2020-01-01 00:30:00-08:00 -2.508561 0.0 -0.631080 2020-01-01 01:00:00-08:00 -2.508561 0.0 -0.631080 2020-01-01 01:30:00-08:00 -1.943371 0.0 -0.374704 2020-01-01 02:00:00-08:00 -1.943371 0.0 -0.374704 2020-01-01 02:30:00-08:00 -2.023108 0.0 -0.379228 2020-01-01 03:00:00-08:00 -2.023108 0.0 -0.379228 2020-01-01 03:30:00-08:00 -1.683542 0.0 -0.013457 2020-01-01 04:00:00-08:00 -1.683542 0.0 -0.013457 2020-01-01 04:30:00-08:00 -1.891827 0.0 -0.006960 We see that the DataFrame now contains the next valid hourly value in the newly obtained half-hourly timestamps of the previous hour. It would take the previous valid hourly value if we used forward filling. For example: ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.576505 0.0 -0.764837 2020-01-01 00:30:00-08:00 -2.576505 0.0 -0.764837 2020-01-01 01:00:00-08:00 -2.508561 0.0 -0.631080 2020-01-01 01:30:00-08:00 -2.508561 0.0 -0.631080 2020-01-01 02:00:00-08:00 -1.943371 0.0 -0.374704 2020-01-01 02:30:00-08:00 -1.943371 0.0 -0.374704 2020-01-01 03:00:00-08:00 -2.023108 0.0 -0.379228 2020-01-01 03:30:00-08:00 -2.023108 0.0 -0.379228 2020-01-01 04:00:00-08:00 -1.683542 0.0 -0.013457 2020-01-01 04:30:00-08:00 -1.683542 0.0 -0.013457 The forward filling option provides the same value for o’clock and half past timestamps within the same hour. In addition to these two ways to complete the NaN values, the method asfreq can replace the NaN values with a constant. See below: ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.576505 0.0 -0.764837 2020-01-01 00:30:00-08:00 0.000000 0.0 0.000000 2020-01-01 01:00:00-08:00 -2.508561 0.0 -0.631080 2020-01-01 01:30:00-08:00 0.000000 0.0 0.000000 2020-01-01 02:00:00-08:00 -1.943371 0.0 -0.374704 2020-01-01 02:30:00-08:00 0.000000 0.0 0.000000 2020-01-01 03:00:00-08:00 -2.023108 0.0 -0.379228 2020-01-01 03:30:00-08:00 0.000000 0.0 0.000000 2020-01-01 04:00:00-08:00 -1.683542 0.0 -0.013457 2020-01-01 04:30:00-08:00 0.000000 0.0 0.000000 The use of the methods asfreq or resample will depend on your dataset and the analysis you aim to undertake. 3 Interpolating time-series data When up-sampling the data series, it can happen that back-filling, forward-filling and constant replacement does not necessarily work for your analysis/application. An alternative approach is interpolating the replacing the NaN values with an interpolated result. Interpolation in Pandas DataFrames # Half-hourly up-sample with back filling function df_hourly.asfreq(\"30Min\", method='bfill').head(10) # Half-hourly up-sample with forward-filling function df_hourly.asfreq(\"30Min\", method='ffill').head(10) # Half-hourly up-sample filling the new timestamps with a constant df_hourly.asfreq(\"30Min\", fill_value=0).head(10) Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 6 of 10 9/28/22, 6:01 PM with DatetimeIndex is done with the interpolate method. The mathematical interpolation method in interpolate is defined with the argument called ‘method’. Pandas permits several interpolation methods, such as ‘linear’, ‘cubic’, ‘quadratic’, ‘spline’, ‘polynomial’ and others. All the interpolation options can be found in the documentation of the interpolate method. Following the previous example, let’s implement interpolation in the missing values of the half-hourly timestamps using ‘linear’, ‘cubic’ and ‘polynomial’ methods: ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.576505 0.0 -0.764837 2020-01-01 00:30:00-08:00 -2.542533 0.0 -0.697958 2020-01-01 01:00:00-08:00 -2.508561 0.0 -0.631080 2020-01-01 01:30:00-08:00 -2.225966 0.0 -0.502892 2020-01-01 02:00:00-08:00 -1.943371 0.0 -0.374704 2020-01-01 02:30:00-08:00 -1.983240 0.0 -0.376966 2020-01-01 03:00:00-08:00 -2.023108 0.0 -0.379228 2020-01-01 03:30:00-08:00 -1.853325 0.0 -0.196342 2020-01-01 04:00:00-08:00 -1.683542 0.0 -0.013457 2020-01-01 04:30:00-08:00 -1.787684 0.0 -0.010209 Similarly, it can be implemented to other methods: ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.576505 0.000000 -0.764837 2020-01-01 00:30:00-08:00 -2.708668 0.015477 -0.754314 2020-01-01 01:00:00-08:00 -2.508561 0.000000 -0.631080 2020-01-01 01:30:00-08:00 -2.184142 -0.015477 -0.477191 2020-01-01 02:00:00-08:00 -1.943371 0.000000 -0.374704 2020-01-01 02:30:00-08:00 -1.929019 0.046430 -0.371559 2020-01-01 03:00:00-08:00 -2.023108 0.000000 -0.379228 2020-01-01 03:30:00-08:00 -2.027425 -0.170243 -0.284694 2020-01-01 04:00:00-08:00 -1.683542 0.000000 -0.013457 2020-01-01 04:30:00-08:00 -1.097302 0.634542 0.333660 With polynomial interpolation, the degree or order of the polynomial function needs to be defined as an argument: ghi dhi dni datetime 2020-01-01 00:00:00-08:00 -2.576505 0.000000 -0.764837 2020-01-01 00:30:00-08:00 -1.992626 0.512587 0.655667 2020-01-01 01:00:00-08:00 -2.508561 0.000000 -0.631080 2020-01-01 01:30:00-08:00 -2.485236 -0.214189 -1.068238 2020-01-01 02:00:00-08:00 -1.943371 0.000000 -0.374704 2020-01-01 02:30:00-08:00 -1.619687 0.201377 0.199990 2020-01-01 03:00:00-08:00 -2.023108 0.000000 -0.379228 2020-01-01 03:30:00-08:00 -2.535919 -0.346026 -1.263387 2020-01-01 04:00:00-08:00 -1.683542 0.000000 -0.013457 2020-01-01 04:30:00-08:00 -0.233498 0.762150 2.341007 The interpolation of NaN values when up-sampling time-series data can help overcome the issues of using back or forward filling, specially if you aim to up-sample at higher frequencies than the example shown (e.g. 1-hour to 15-minute resolution series). The mathematical methods available for interpolation within Pandas are diverse and cover beyond the most common interpolation functions. 4 Visualizing time-series data It is often useful to visualize the data to grasp insighs and observe trends about the data. This section shows few examples to visualize time-series data. 4.1 Plotting a time-series for a day of interest Below there is an example to visualize a single day of interest. With DataFrames using DatetimeIndex it is easy to select a particular day and Pandas interacts with Matplotlib.Pyplot library to plot straight-away. # Up-sample using the 'asfreq' method df_30min = df_hourly.asfreq(\"30Min\") # Interpolate missing values (NaN) with linear interpolation df_linear = df_30min.interpolate(method='linear') # See the results: df_linear.head(10) # Interpolate missing values (NaN) with cubic interpolation df_cubic = df_30min.interpolate(method='cubic') # See the results: df_cubic.head(10) # Interpolate missing values (NaN) with polynomial interpolation df_polynomial = df_30min.interpolate(method='polynomial', order=5) # See the results: df_polynomial.head(10) # Plotting GHI for a given day in the time-series df_1min['2020-06-01']['ghi'].plot(label='GHI') plt.ylabel('Irradiance [W/m$^2$]') plt.xlabel('Local Time [HH:MM]') plt.legend(loc='best') plt.show() # Not needed in Jupyter Notebooks but usually required in other IDEs. Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 7 of 10 9/28/22, 6:01 PM We can visualize the effect of using average (resample) vs. instantaneous (asfreq) measurements when down-sampling our data. 4.2 Plotting a time-series for a few consecutive days of interest Below there is an example to visualize a few consecutive days (e.g. 5 days) of interest. By using [‘start date’]:[‘end date’] it is possible to select time ranges easily with a DataFrame having a DatetimeIndex. 4.3 Plotting a time-series for a few non-consecutive days of interest Below there is an example to visualize a few non-consecutive days of interest, which could be the case when we would like to observe several days scattered throughout the year a single plot. In order to do this, we need to select the day of interest from the DataFrame and then reset its DatetimeIndex. For example: /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /ipykernel_launcher.py:2: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead. # Plotting GHI for a given day in the time-series df_1min['2020-06-01']['ghi'].plot(label='1-min data', alpha=0.4) # Reference data df_1min.asfreq('30Min')['2020-06-01']['ghi'].plot(label='30-min instant.') # Instantaneous 30-min values df_1min.resample('30Min').mean()['2020-06-01']['ghi'].plot(label='30-min average') # Average 30-min values plt.title('Average vs. Actual GHI Measurements') # title of the figure plt.ylabel('Irradiance [W/m$^2$]') # y-axis label plt.xlabel('Local Time [HH:MM]') # x-axis label plt.legend(loc='upper left') # insert legend plt.show() # Not needed in Jupyter Notebook but usually required in other IDEs. /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /ipykernel_launcher.py:2: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead. /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /ipykernel_launcher.py:3: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead. This is separate from the ipykernel package so we can avoid doing imports until /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /ipykernel_launcher.py:4: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead. after removing the cwd from sys.path. # Variables to plot vars = ['ghi', 'dni', 'dhi'] # Create 3 subplots, with shared X and Y axis fig, axs = plt.subplots(3, sharex=True, sharey=True, figsize=(9,6)) # Add title to the plot fig.suptitle('Average Hourly Solar Radiation Observations', fontsize=14) for i in range(3): axs[i].plot(df_1min.resample('1H').mean()['2020-06-01':'2020-06-05'][vars[i]], label='Average') # Average hourly axs[i].plot(df_1min.resample('1H').max()['2020-06-01':'2020-06-05'][vars[i]], label='Maximum') # Max. hourly axs[i].plot(df_1min.resample('1H').min()['2020-06-01':'2020-06-05'][vars[i]], label='Minimum') # Min. hourly axs[i].set_title(vars[i].upper()) # Title for each subplot fig.subplots_adjust(hspace=0.3) # Adjust the white space between the subplots titles fig.text(0.04, 0.5, 'Irradiance [W/m$^2$]', va='center', rotation='vertical', fontsize=12) # Common Y Axis fig.text(0.51, 0.04, 'Local Time', ha='center', fontsize=12) # Common X Axis plt.legend(loc='upper center', ncol=3) # Legend for the last subplot or 'axs[i].legend()' in the loop to a legend to each. plt.show() Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 8 of 10 9/28/22, 6:01 PM 4.4 Daily insolation throughout the year With time-series data, the hourly/daily/monthly insolation (i.e. the sum of accumulated energy) can also be analysed throughout the year with time-series data. For example, below an example to visualize the daily insolation is shown: Time-series data can also be visualized in other ways, for instance, as a heat map. Section summary # List of days of interest days = ['2020-01-01', '2020-03-01', '2020-06-01', '2020-09-01'] # Iterate over the days and plot each of them for day in days: df_day = df_1min.resample('1H').mean()[day]['ghi'].to_frame() # average hourly of GHI for current day df_day = df_day.reset_index(drop=True) # reset its Index to numeric (i.e. 0,1,2,3...) plt.plot(df_day, label=day) # plot the current day plt.title('Average Hourly GHI Measurements for Days of Interest') # title of the figure plt.xticks(np.arange(0, 25, step=3), np.arange(0, 25, step=3)) # set labels positions and names plt.ylabel('Irradiance [W/m$^2$]') # y-axis label plt.xlabel('Local Time') # x-axis label plt.legend(loc='best') # insert legend plt.show() /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /ipykernel_launcher.py:5: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead. \"\"\" # Calculate the daily insolation expressed in kWh·sqm from GHI measurements daily_energy = (df_1min['ghi'].resample(\"1D\").sum()*(1/60))/1000 # selecting only GHI returns a Pandas Series # Create time-series plot daily_energy.plot(figsize=(9,6), legend=False) # plot timeseries plt.title('Time-series of Daily Insolation') # add title plt.ylabel('Energy [kWh/m$^2$]') # add Y-axis label plt.xlabel('Time') # add X-axis label plt.show() # Prepare the data for heat map of hourly insolation energy_array = pd.DataFrame() # empty DataFrame for the results for i in range(1,13): # iterate over months # select the data in the month and eliminate the datetimeindex df_month = daily_energy[daily_energy.index.month==i].reset_index(drop=True) # rename the column with the number of the month df_month.columns = [str(i)] # Append results to the DataFrame energy_array = pd.concat([energy_array, df_month], axis=1) # Transpose to have months in y-axis and days in x-axis energy_array = energy_array.transpose() # Rename the columns of the days energy_array.columns = np.arange(1, 32) # Plot heat map of daily insolation months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', # month labels 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] plt.figure(figsize=(10, 5)) ax = sns.heatmap(energy_array, cmap='CMRmap', linewidths=0.2, # plot heatmap with Seaborn (sns) library xticklabels=2, annot=False, cbar_kws={'label': 'Daily Energy [kWh/m$^2$]'}) ax.set_title('Heat Map of Daily Insolation') # add title ax.set_yticklabels(months,rotation=0) # add the months as tick-labels for the y-axis ax.set_xticklabels(ax.get_xticklabels(),rotation=0) # add the days as tick-labels for the x-axis ax.set_xlabel('Day of the Month') plt.show() By The Assessing Solar Community © Copyright 2022. Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 9 of 10 9/28/22, 6:01 PM This section has shown how to build and work with a time-series in Python with multiple examples: !\"We have seen how to prepare a DataFrame with DatatimeIndex to be used as a time-series when the timestamps are given in multiple formats in the temporal data and local/UTC time. !\"Changes in the temporal resolution of the data can be applied by down and up-sampling the data and the differences between 2 available methods (asfreq and resample) have been shown with examples and different sampling frequencies. !\"The interpolation of missing data in time-series can be used to up-sample the resolution of the data and examples with some methods have been shown. !\"Finally, several ideas to visualize data have been presented. Overall, the possibilities with time-series of solar resource are many. The most useful and suitable analysis and visualizations will be determined by the application and scope of the study. References Andreas, A.; Stoffel, T.; (2006). University of Nevada (UNLV): Las Vegas, Nevada (Data); NREL Report No. DA-5500-56509. http://dx.doi.org/10.5439/1052548 Manipulating Time-series — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/manipulating_time_series.html 10 of 10 9/28/22, 6:01 PM Ground-based solar irradiance data Contents !\"Major radiation station networks Conducted ground-based solar irradiance measurements is useful for obtaining information on the local solar resource, but also extremely for determining the accuracy of sattelite and reanalysis solar irradiance methods and validating solar radiation models. In this section, the major ground-based solar radiation monitoring network will be introduced and it will be demonstrated how data can be obtained from these sources. Content by Adam R. Jensen Major radiation station networks There exists a number of ground-based solar radiation monitoring networks, of which most are operated by national weather services or research organizations: !\"Baseline Surface Radiation Network - BSRN (global) !\"SURFRAD by NOAA (US) !\"SOLRAD by NOAA (US) !\"ESMAP - World Bank !\"SRML by the University of Oregon (Northwestern US) !\"NREL (US) !\"Enermena !\"SMHI (Sweden) !\"BoM (Australia) !\"SAURAN (South Africa) !\"MeteoSwiss (Switzerland) By The Assessing Solar Community © Copyright 2022. Ground-based solar irradiance data — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/ground_measurements.html 1 of 1 9/28/22, 6:02 PM Solar Decomposition Models Contents !\"The role of solar decomposition models !\"Data preparation !\"DISC model !\"DIRINT model !\"DIRINDEX model !\"Erbs model !\"Comparison and evaluation of decomposition models !\"Section summary !\"References Knowing the direct or beam normal irradiance (DNI) is useful for many solar and energy applications, e.g., calculating the yield of solar concetrating power systems or determining the irradiance on an inclined surface. However, often only global horizontal irradiance (GHI) is available, as it is much cheaper to measure than the individual components and most satelitte radiation models only calculate GHI. Many applications, therefore, require applying solar radiation decomposition models to obtain the direct beam irradiance. The majority of decomposition models work by applying an empirical correlations between GHI, diffuse horizontal irradiance (DHI) and DNI. In this section, we present the implementation in Python of several solar decomposition models. Content by Javier Lopez Lorente and Adam R. Jensen The role of solar decomposition models Solar decomposition models are some of the most frequently used algorithms, and are often used during the first part of a larger analysis. As described earlier, decomposition models permit estimating the beam or direct normal irradiance (DNI) from GHI measurements, often using relationships between the clearness index ( ) and the diffuse fraction of solar irradiance ( ). The clearness index is defined as: where is the extraterrestrial irradiance, and is the solar zenith angle. The diffuse fraction is defined as: The role of decomposition models can be graphically illustrated in the diagram below: Multiple models have been proposed for the decomposition of global horizontal radiation/irradiance into its direct normal and diffuse horizontal components in the scientific literature. Below, the implementation in Python of some of these methods will be shown. The following methods will be modelled and compared: !\"DISC model (Maxwell, 1987) !\"DIRINT model (Pérez et al., 1992) !\"DIRINDEX model (Pérez et al., 2002) !\"Erbs model (Erbs et al., 1982) The four decomposition models, among some others, are implemented in the open-source library pvlib python. Before applying the models in practice, an example irradiance data set will be retrieved. Data preparation To illustrate the implementation of each of these models, we will use real irradiance observations. The decomposition models will be used to calculate DNI and DIh from measured GHI, and the results will then be compared to measurements of DNI and DHI. The first step is getting and preparing the measurement data to be used. Retrieving weather data The irradiance data used is from the BSRN Cabauw station operated by the Royal Netherlands Meteorological Institute (KNMI). The data is retrieved from the BSRN FTP server using the get_bsrn function from pvlib-python. The Cabauw station is located at latitude 51.9711° and longitude 4.9267°, at an elevation of 0 m AMSL. The reason for choosing the Cabauw station is that the data has already been extensively quality checked, hence in this example this step is skipped. The data used are 1-minute global, direct, and diffuse irradiance measurements between January and July 2021, which are resampled to hourly observations. ghi ghi_std ghi_min ghi_max dni dni_std dni_min dni_max dhi dhi_std dhi_min dhi_max lwd lwd_std lwd_min lwd_max 2021-01-01 00:00:00+00:00 -1.150000 0.076667 -1.366667 -1.033333 1.000000 0.008333 1.000000 1.133333 -1.000000 0.050000 -1.000000 -1.000000 242.133333 0.288333 241.666667 242.633333 2021-01-01 01:00:00+00:00 -1.000000 0.078333 -1.000000 -1.000000 1.150000 0.005000 1.050000 1.550000 -1.000000 0.051667 -1.000000 -1.000000 243.666667 0.253333 243.216667 244.100000 2021-01-01 02:00:00+00:00 -1.000000 0.081667 -1.016667 -0.900000 1.266667 0.016667 1.050000 1.516667 -0.600000 0.051667 -0.683333 -0.500000 265.950000 0.603333 264.983333 267.066667 2021-01-01 03:00:00+00:00 -1.000000 0.075000 -1.000000 -1.000000 1.583333 0.006667 1.383333 1.616667 -0.533333 0.065000 -0.833333 -0.333333 271.800000 0.578333 270.800000 272.733333 2021-01-01 04:00:00+00:00 -0.966667 0.076667 -1.000000 -0.850000 1.316667 0.005000 1.233333 1.500000 0.000000 0.061667 -0.350000 0.000000 291.933333 0.231667 291.500000 292.266667 Besides GHI, DNI and DHI, this station has additional weather-related variables available (e.g., air temperature, humidity, and wind speed), as well as sensor-specific data. The details of the sensors and measurements available in each station can be found under the section “Instrument history and meta data” of each MIDC’s station webpage. Let’s list the variables available and then subset those that we will use in this example: kt kd kt = GHI Ea ⋅ cos(θZ) Ea θZ kd = DHI GHI # Import all the necessary libraries import numpy as np import pandas as pd import matplotlib.pyplot as plt import pvlib # Retrieving the measurement data df, meta = pvlib.iotools.get_bsrn( station='CAB', start=pd.Timestamp('2021-01-01'), end=pd.Timestamp('2021-07-31'), username=bsrn_username, password=bsrn_password) # Resample the 1-minute data to hourly df = df.resample('1h').mean() # Display the first five rows of the dataset df.head() Solar Decomposition Models — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/decomposition_models.html 1 of 4 9/28/22, 6:01 PM It is often helpful to visualize the data in order to check that the measurements are within the expected ones. For example, a plot for a single day (18th July 2021): For an overall representation of the data, it’s useful to inspect the the key statistical metrics for the data: ghi dni dhi temp_air relative_humidity pressure count 5088.000000 5021.000000 5006.000000 5088.000000 5088.000000 5088.000000 mean 150.154482 129.608143 78.730762 9.613794 81.598316 1016.147409 std 223.501191 244.733398 109.759797 7.098631 14.189124 10.043831 min -2.033333 -0.316667 -1.827586 -8.151667 32.516667 981.450000 25% -1.000000 1.000000 -0.783333 4.133750 72.566667 1009.945833 50% 21.075000 1.316667 18.233333 8.776667 84.843333 1016.675000 75% 234.120833 117.466667 125.820833 15.312083 93.289167 1023.575000 max 926.033333 958.500000 568.216667 29.330000 100.000000 1042.000000 Estimating other input variables: The 3 solar decomposition models that we will implement in this section (i.e., DISC, DIRINT and Erbs models) have different inputs to be implemented. Solar position data is a common input for the 3 models. The DISC and DIRINT models accept as a possible input the dew (wet-bulb) temperature ( ). This variable is not directly available from our weather observations; however, it can be easily estimated using a simple conversion that has relative humidity ( ) and the ambient temperature ( ) as input. This simple approximation is given by the equation below (Lawrence, 2005): In Python, this equation could be implemented as follows: The solar position for the entire period can be calculated using the pvlib.solarposition.get_solarposition function which supports a number of different solar position algorithms. The default algorithm is an implementation of the NREL SPA algorithm. apparent_zenith zenith apparent_elevation elevation azimuth equation_of_time 2021-01-01 00:00:00+00:00 149.693651 149.693651 -59.693651 -59.693651 21.451575 -3.441097 2021-01-01 01:00:00+00:00 144.585022 144.585022 -54.585022 -54.585022 45.257706 -3.460697 2021-01-01 02:00:00+00:00 137.059810 137.059810 -47.059810 -47.059810 63.685127 -3.480288 2021-01-01 03:00:00+00:00 128.334219 128.334219 -38.334219 -38.334219 78.296833 -3.499870 2021-01-01 04:00:00+00:00 119.152361 119.152361 -29.152361 -29.152361 90.721936 -3.519442 DISC model The DISC model (Maxwell, 1987) requires the following inputs: GHI, solar zenith angle, and the atmospheric pressure, which is used to estimate the absolute (pressure-corrected) airmass. The functoin returns the DNI, the clearness index ( ) and the airmass estimation: DIRINT model An implementatin of the DIRINT model (Pérez et al., 1992) is also available in pvlib-python. The model requires the following inputs: GHI, solar zenith angle, atmospheric pressure, and dew (wet-bulb) temperature. DIRINDEX model The DIRINDEX model (Pérez et al., 2002) was found to be one of the two best decomposition models in an extensive study by Gueymard and Ruiz-Arias (2016). The model is an enhancement of the DIRINT model by considering clearsky data. # Visualize variables avilable df.columns Index(['ghi', 'ghi_std', 'ghi_min', 'ghi_max', 'dni', 'dni_std', 'dni_min', 'dni_max', 'dhi', 'dhi_std', 'dhi_min', 'dhi_max', 'lwd', 'lwd_std', 'lwd_min', 'lwd_max', 'temp_air', 'relative_humidity', 'pressure'], dtype='object') df.loc['2021-07-18', ['ghi','dhi','dni']].plot() plt.title('Solar irradiance components, 18th July 2021') plt.ylabel('Irradiance [W/m$^2$]') plt.legend() <matplotlib.legend.Legend at 0x7f2751209f50> df[['ghi','dni','dhi', 'temp_air', 'relative_humidity', 'pressure']].describe() Td RH Ta Td = Ta(∘C) − 100 − RH(%) 5 df['temp_dew'] = df['temp_air']-((100-df['relative_humidity'])/5) # Define a pvlib location object for the site location = pvlib.location.Location(latitude=51.9711, longitude=4.9267, altitude=0, name='Cabauw') # Calculate the solar position for each index in the datarame for the specific location # The 30 minute shift is applied in order to calculate the solar position at the middle of the hour! solpos = location.get_solarposition(df.index+pd.Timedelta(minutes=30)) solpos.index = solpos.index - pd.Timedelta(minutes=30) # Let's have a look to the output solpos.head() # DISC method estimated with absolute airmass as input disc = pvlib.irradiance.disc( ghi=df['ghi'], solar_zenith=solpos['apparent_zenith'], datetime_or_doy=df.index, pressure=df['pressure']*100) # Site pressure in Pascal kt disc.columns Index(['dni', 'kt', 'airmass'], dtype='object') # Estimation of the DIRINT model dirint = pvlib.irradiance.dirint( ghi=df['ghi'], solar_zenith=solpos['apparent_zenith'], times=df.index, pressure=df['pressure']*100, # atmospheric pressure in Pascal temp_dew=df['temp_dew']) # Dew temperature in Degree Celsius Solar Decomposition Models — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/decomposition_models.html 2 of 4 9/28/22, 6:01 PM Erbs model The Erbs model (Erbs et al., 1982) is a simple and very popular model that only requires GHI and the solar zenith angle. This model is also available in pvlib and the implementation is equally straight-forward: Comparison and evaluation of decomposition models Once the 4 models are estimated, we can evaluate the results of the models against the actual DNI measurements available. For example, below we visualize the results of the models a single day and a week in July: The correlation between the obtained models and the measured observations can be also presented in scatter plots: The evaluation cannot be only based on a visual inspection. For solar resource assessment, there are a number of common metrics to evaluate the error and performance, which we will use below. These metrics are the mean bias error (MBE) and the root mean square error (RMSE). The MBE is the average error representing a systematic error to under- or overestimate and the RMSE is a measure of the dispersion of the deviations. where is the size of the sample or dataset, is each of the predicted values and are the observed or true values. In Python, each of these evaluation metrics can be defined as # Retrieve clear-sky irradiance from CAMS McClear clearsky, meta = pvlib.iotools.get_cams( latitude=location.latitude, longitude=location.longitude, altitude=location.altitude, start=df.index[0], end=df.index[-1], email=sodapro_username) # Estimation of the DIRINDEX model dirindex = pvlib.irradiance.dirindex( ghi=df['ghi'], ghi_clearsky=clearsky['ghi_clear'], dni_clearsky=clearsky['dni_clear'], zenith=solpos['zenith'], times=df.index, pressure=df['pressure']*100, # atmospheric pressure in Pascal temp_dew=df['temp_dew']) # Dew temperature in Degree Celsius erbs = pvlib.irradiance.erbs( ghi=df['ghi'], zenith=solpos['apparent_zenith'], datetime_or_doy=df.index) erbs.columns Index(['dni', 'dhi', 'kt'], dtype='object') # Plot of models for a single day date = '2021-07-18' disc.loc[date, 'dni'].plot(label='DISC', alpha=0.7) dirint.loc[date].plot(label='DIRINT', alpha=0.7) dirindex.loc[date].plot(label='DIRINDEX', alpha=0.7) erbs.loc[date, 'dni'].plot(label='Erbs', alpha=0.7) df.loc[date, 'dni'].plot(c='k', label='Reference') plt.ylim(0, 1200) plt.ylabel('Direct Normal Irradiance [W/m$^2$]') plt.xlabel('Time [HH:MM]') plt.title('Comparison of decomposition models\\n(July 18th 2021)') plt.legend(loc='upper left') <matplotlib.legend.Legend at 0x7f2755128250> # Plot of models for several days on an hourly basis disc.loc['20210709':'20210718', 'dni'].resample('1h').mean().plot(label='DISC', alpha=0.5) # format of date YYYYMMDD dirint.loc['20210709':'20210718'].resample('1h').mean().plot(label='DIRINT', alpha=0.5) dirindex.loc['20210709':'20210718'].resample('1h').mean().plot(label='DIRINDEX', alpha=0.5) erbs.loc['20210709':'20210718', 'dni'].resample('1h').mean().plot(label='Erbs', alpha=0.5) df.loc['20210709':'20210718', 'dni'].resample('1h').mean().plot(label='Reference') plt.ylim(0,1200) plt.ylabel('Direct Normal Irradiance [W/m$^2$]') plt.title('Comparison of decomposition on an hourly basis\\n (9th-18th July 2021)') plt.legend(ncol=2, loc='upper center') plt.tight_layout() # Create multiple plots fig, axes = plt.subplots(ncols=4, figsize=(15, 4), facecolor='w', edgecolor='k', sharey=True) # Plot axes[0].scatter(df['dni'], disc['dni'], s=4, c='k') axes[1].scatter(df['dni'], dirint, s=4, c='k') axes[2].scatter(df['dni'], dirindex, s=4, c='k') axes[3].scatter(df['dni'], erbs['dni'], s=4, c='k') # Add characteristics to each subplot in a loop axes[0].set_ylabel('Modelled DNI [W/m$^2$]') axes[0].set_ylim(0, 1200) for ax, model in zip(axes, ['DISC', 'DIRINT', 'DIRINDEX', 'ERBS']): ax.plot([0,1200], [0,1200], c='r') ax.set_xlim(0, 1200) ax.set_title(model) ax.set_xlabel('Observed DNI [W/m$^2$]') plt.tight_layout() plt.show() MBE = 1 n n ∑ i=1 Mi − Oi RMSE = 1 n n ∑ i=1 (Mi − Oi)2   ⎷ n Mi Oi Solar Decomposition Models — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/decomposition_models.html 3 of 4 9/28/22, 6:01 PM function. For the comparison of evaluation metrics, only measurement for periods where the solar elevation is greater than 5 degrees are used: For the DISC method: For the DIRINT method: For the DIRINDEX method: For the Erbs method: The performance metrics show that, in this example, the DIRINDEX method reports the lowest error metrics, followed by the Erbs model, the DISC, and the DIRINT methods, respectively. Section summary This section has presented the solar radiation decomposition methods, which are a common type of technique to estimate the direct normal or beam irradiance from global horizontal irradiance observations. Particularly, the following examples have been covered: !\"The Python implementation of three solar radiation decomposition methods have been presented using real data, namely the models used are the DISC, DIRINT, DIRINDEX and Erbs models. !\"Time-series visualization and scatter plots have been introduced to evaluate differences in the models. !\"Two common error metrics to evaluate the performance, i.e. MBE and RMSE, have been introduced. Within solar resource assessment, decomposition methods are used as means to estimate the direct irradiance or irradiation for further analysis in particular applications. For example, in solar concentrating power where direct irradiance is essential for power generation availability. There are multiple decomposition methods available in the literature. However, the Python functions for these 4 methods are available in the Python library pvlib. References Andreas, A., and Wilcox, S., (2010). ‘Observed atmospheric and solar information system (OASIS)’, Tucson, Arizona (Data), NREL Report No. DA-5500-56494. http://dx.doi.org/10.5439 /1052226 Erbs, D. G., Klein, S. A., and Duffie, J. A., (1982). ‘Estimation of the diffuse radiation fraction for hourly, daily and monthly-average global radiation’, Solar Energy 28(4), pp 293-302. Gueymard, C. A and Ruiz-Arias, J. A., (2016). ‘Extensive worldwide validation and climate sensitivity analysis of direct irradiance predictions from 1-min global irradiance’, Solar Energy 128, pp 1-30. https://doi.org/10.1016/j.solener.2015.10.010 Lawrence, M. G. (2005). ‘The relationship between relative humidity and the dewpoint temperature in moist air: A simple conversion and applications’, Bulletin of the American Meteorological Society, 86(2), pp. 225-234. https://doi.org/10.1175/BAMS-86-2-225 Maxwell, E. L., (1987). ‘A quasi-physical model for converting hourly global horizontal to direct normal insolation’, Technical Report No. SERI/TR-215-3087, Golden, CO: Solar Energy Research Institute. Perez, R., Ineichen, P., Maxwell, E., Seals, R., and Zelenka, A., (1992). ‘Dynamic global-to-direct irradiance conversion models’. ASHRAE Transactions-Research Series, pp. 354-369 Perez, R. et al. (2002) ‘A new operational model for satellite-derived irradiances: Description and validation’, Solar Energy, 73(5), pp. 307–317. https://doi.org/10.1016 /S0038-092X(02)00122-6 # Mean Bias Error def mbe(predictions, observed): return (predictions - observed).mean() # Root Mean Square Error def rmse(predictions, observed): return np.sqrt(((predictions - observed)**2).mean()) df = df[solpos['elevation']>5] erbs = erbs[solpos['elevation']>5] disc = disc[solpos['elevation']>5] dirint = dirint[solpos['elevation']>5] dirindex = dirindex[solpos['elevation']>5] mbe_disc = mbe(disc['dni'], df['dni']) rmse_disc = rmse(disc['dni'], df['dni']) print(\"DISC Decomposition Method:\") print(\"MBE \" + \"%.2f\" % mbe_disc + \" W/m\\u00b2\") print(\"RMSE \" + \"%.2f\" % rmse_disc + \" W/m\\u00b2\") DISC Decomposition Method: MBE 41.68 W/m² RMSE 90.00 W/m² mbe_dirint = mbe(dirint, df['dni']) rmse_dirint = rmse(dirint, df['dni']) print(\"DIRINT Decomposition Method:\") print(\"MBE \" + \"%.2f\" % mbe_dirint + \" W/m\\u00b2\") print(\"RMSE \" + \"%.2f\" % rmse_dirint + \" W/m\\u00b2\") DIRINT Decomposition Method: MBE 18.26 W/m² RMSE 76.04 W/m² mbe_dirindex = mbe(dirindex, df['dni']) rmse_dirindex = rmse(dirindex, df['dni']) print(\"DIRINDEX Decomposition Method:\") print(\"MBE \" + \"%.2f\" % mbe_dirindex + \" W/m\\u00b2\") print(\"RMSE \" + \"%.2f\" % rmse_dirindex + \" W/m\\u00b2\") DIRINDEX Decomposition Method: MBE -3.45 W/m² RMSE 68.51 W/m² mbe_erbs = mbe(erbs['dni'], df['dni']) rmse_erbs = rmse(erbs['dni'], df['dni']) print(\"Erbs Decomposition Method:\") print(\"MBE \" + \"%.2f\" % mbe_erbs + \" W/m\\u00b2\") print(\"RMSE \" + \"%.2f\" % rmse_erbs + \" W/m\\u00b2\") Erbs Decomposition Method: MBE 14.06 W/m² RMSE 81.79 W/m² By The Assessing Solar Community © Copyright 2022. Solar Decomposition Models — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/decomposition_models.html 4 of 4 9/28/22, 6:01 PM Baseline Surface Radiation Network (BSRN) Contents !\"Baseline Surface Radiation Network (BSRN) !\"References The Baseline Surface Radiation Network (BSRN) is a global network of high-quality solar radiation monitoring stations under the World Climate Research Programme (WCRP) []. According to the World Radiation Monitoring Center (WRMC): The data [from the BSRN stations] are of primary importance in supporting the validation and confirmation of satellite and computer model estimates of these quantities. At a small number of stations (currently 74 in total, 58 active) in contrasting climatic zones, covering a latitude range from 80°N to 90°S, solar and atmospheric radiation is measured with instruments of the highest available accuracy and with high time resolution. All BSRN stations are required to meet the basic station requirements. A list of activate, inactive, and candidate BSRN stations can be retrieved from the SolarStations station listing and are shown below. import pandas as pd stations = pd.read_csv('solarstations.csv', sep=';', encoding='latin1') stations = stations[stations['Network'].str.contains('BSRN')] stations['Time period'] = stations['Time period'].astype(str).replace('nan','') stations Baseline Surface Radiation Network (BSRN) — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/bsrn.html 1 of 4 9/28/22, 6:02 PM ------------------------------------------------------------------------ --- FileNotFoundError Traceback (most recent call last) /tmp/ipykernel_1835/303006015.py in <module> 1 import pandas as pd 2 ----> 3 stations = pd.read_csv('solarstations.csv', sep=';', encoding='latin1') 4 stations = stations[stations['Network'].str.contains('BSRN')] 5 stations['Time period'] = stations['Time period'].astype(str).replace('nan','') /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /pandas/util/_decorators.py in wrapper(*args, **kwargs) 309 stacklevel=stacklevel, 310 ) --> 311 return func(*args, **kwargs) 312 313 return wrapper /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /pandas/io/parsers/readers.py in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options) 584 kwds.update(kwds_defaults) 585 --> 586 return _read(filepath_or_buffer, kwds) 587 588 /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /pandas/io/parsers/readers.py in _read(filepath_or_buffer, kwds) 480 481 # Create the parser. --> 482 parser = TextFileReader(filepath_or_buffer, **kwds) 483 484 if chunksize or iterator: /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /pandas/io/parsers/readers.py in __init__(self, f, engine, **kwds) 809 self.options[\"has_index_names\"] = kwds[\"has_index_names\"] 810 --> 811 self._engine = self._make_engine(self.engine) 812 813 def close(self): /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /pandas/io/parsers/readers.py in _make_engine(self, engine) 1038 ) 1039 # error: Too many arguments for \"ParserBase\" -> 1040 return mapping[engine](self.f, **self.options) # type: ignore[call-arg] 1041 1042 def _failover_to_python(self): /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /pandas/io/parsers/c_parser_wrapper.py in __init__(self, src, **kwds) 49 50 # open handles ---> 51 self._open_handles(src, kwds) 52 assert self.handles is not None 53 /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /pandas/io/parsers/base_parser.py in _open_handles(self, src, kwds) 227 memory_map=kwds.get(\"memory_map\", False), 228 storage_options=kwds.get(\"storage_options\", None), --> 229 errors=kwds.get(\"encoding_errors\", \"strict\"), 230 ) 231 Baseline Surface Radiation Network (BSRN) — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/bsrn.html 2 of 4 9/28/22, 6:02 PM Station metadata Click the plus symbol above to see a table of the stations and their metadata. Station requirements As a mimimum a BSRN station is required to measure global horizontal irradiance (GHI), direct normal irradiance (DNI), diffuse horizontal irradiance (DHI), Additional metadata may be found at the BSRN website and in the individual data files (e.g., horizon profile). Unlike the majority of solar radiation monitoring networks, the BSRN website does not have a subpage for each station (with photos, etc.). This would have been very useful when assessing the usage of the station, for example in regards to the potential impact of nearby structures, etc. Note a few photos of the BSRN stations can be found here. There station log books are also not available. It should also be noted that the files on the FTP server do not include wind speed and direction. Data retrieval Data from the BSRN stations is stored in monthly files for each station and can be freely downloaded either via FTP or Pangea. Credentials for accessing the BSRN FTP server can be obtained as described in the data release guidelines. Please read the BSRN data release guidelines before using any data and make sure to properly cite the BSRN. /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages /pandas/io/common.py in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options) 705 encoding=ioargs.encoding, 706 errors=errors, --> 707 newline=\"\", 708 ) 709 else: FileNotFoundError: [Errno 2] No such file or directory: 'solarstations.csv' Make this Notebook Trusted to load map: File -> Trust Notebook ! !! !! ! ! ! !!! !! !!! !! !!! ! !!!!! !!!!!! ! !! !! ! !! ! ! !! !!!! !! ! !! !! !! ! !! ! !!! !! !!! ! ! ! !! !! ++ −− 5000 km 3000 mi Leaﬂet (https://leaﬂetjs.com) | Data by © OpenStreetMap (http://openstreetmap.org), under ODbL (http://www.openstreetmap.org/copyright).  Station markers  \" Active  \" Inactive  \" Candidate Note! Data release guidelines! Baseline Surface Radiation Network (BSRN) — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/bsrn.html 3 of 4 9/28/22, 6:02 PM Available parameters Click the plus symbol above to see the first 12 data entries. WRMC highly recommends that all users do their own quality checks of the data after extracting BSRN-data! The data can also be downloaded programmatically using the pvlib-python library, specifically the get_bsrn function. An example of how to use pvlib to download two months of data from the Cabauw (CAB) station is shown below: For a description of the input parameters, see the pvlib documentation. R users can find similar functionality in the SolarData R package. The data retrieved from all BSRN stations includes measurements of the three irradiance components, as well as longwave downwelling irradiance, temperature humidity, etc. A few of the parameters in the datasets for the month of data are visualized below. Notice how that they are multiple periods where there is gaps in the irradiance data. Warning\" import pvlib df, meta = pvlib.iotools.get_bsrn( station='CAB', # three letter code for the Cabauw station start=pd.Timestamp(2018,6,1), end=pd.Timestamp(2018,7,14), username=bsrn_username, # replace with your own username password=bsrn_password, # replace with your own password ) df.head(12) Retrieving BSRN data in R! axes = df[['ghi','dni','dhi','lwd','temp_air']].plot( subplots=True, legend=False, rot=0, figsize=(8,8), sharex=True) # Set y-labels and y-limits axes[0].set_ylabel('GHI [W/m$^2$]'), axes[0].set_ylim(-10,1300) axes[1].set_ylabel('DNI [W/m$^2$]'), axes[1].set_ylim(-10,1300) axes[2].set_ylabel('DHI [W/m$^2$]'), axes[2].set_ylim(-10,1300) axes[3].set_ylabel('LWD [W/m$^2$]'), axes[4].set_ylim(200,500) _ = axes[4].set_ylabel('Temperature [°]'), axes[4].set_ylim(0,40) By The Assessing Solar Community © Copyright 2022. Baseline Surface Radiation Network (BSRN) — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/bsrn.html 4 of 4 9/28/22, 6:02 PM Station metadata Click the plus symbol above to see a table of the stations and their metadata. Solar Radiation Monitoring Laboratory (SRML) Contents !\"Data retrieval The Solar Radiation Monitoring Laboratory (SRML) at the University of Oregon has been providing solar radiation data for the Northeastern United States since 1975. The SRML monitoring station network consists of both high-quality stations that measure all three irradiance components at a 1-minute resolution, as well as stations with low quality instruments that only log measurements hourly. A full list of the 42 stations (including discontinued stations) can be found on the SRML website. The high-quality SRML stations can be retrieved from the SolarStations’ station listing and are shown below. Data retrieval Data from the SRML stations is stored in monthly files for each station and can be freely downloaded from their website. The data can also be downloaded programmatically using the pvlib-python library, specifically the read_srml_month_from_solardat function. If you find the data useful, please consider donating to support the SRML. An example of how to use pvlib to download data from the Hermiston station for June 2020 is shown here: import pandas as pd stations = pd.read_csv('solarstations.csv', sep=';', encoding='latin1') stations = stations[stations['Network'].str.contains('SRML')] stations --------------------------------------------------------------------------- FileNotFoundError Traceback (most recent call last) /tmp/ipykernel_2114/1924085883.py in <module> 1 import pandas as pd 2 ----> 3 stations = pd.read_csv('solarstations.csv', sep=';', encoding='latin1') 4 stations = stations[stations['Network'].str.contains('SRML')] 5 stations /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/pandas /util/_decorators.py in wrapper(*args, **kwargs) 309 stacklevel=stacklevel, 310 ) --> 311 return func(*args, **kwargs) 312 313 return wrapper /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/pandas /io/parsers/readers.py in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options) 584 kwds.update(kwds_defaults) 585 --> 586 return _read(filepath_or_buffer, kwds) 587 588 /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/pandas /io/parsers/readers.py in _read(filepath_or_buffer, kwds) 480 481 # Create the parser. --> 482 parser = TextFileReader(filepath_or_buffer, **kwds) 483 484 if chunksize or iterator: /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/pandas /io/parsers/readers.py in __init__(self, f, engine, **kwds) 809 self.options[\"has_index_names\"] = kwds[\"has_index_names\"] 810 --> 811 self._engine = self._make_engine(self.engine) 812 813 def close(self): /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/pandas /io/parsers/readers.py in _make_engine(self, engine) 1038 ) 1039 # error: Too many arguments for \"ParserBase\" -> 1040 return mapping[engine](self.f, **self.options) # type: ignore[call-arg] 1041 1042 def _failover_to_python(self): /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/pandas /io/parsers/c_parser_wrapper.py in __init__(self, src, **kwds) 49 50 # open handles ---> 51 self._open_handles(src, kwds) 52 assert self.handles is not None 53 /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/pandas /io/parsers/base_parser.py in _open_handles(self, src, kwds) 227 memory_map=kwds.get(\"memory_map\", False), 228 storage_options=kwds.get(\"storage_options\", None), --> 229 errors=kwds.get(\"encoding_errors\", \"strict\"), 230 ) 231 /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/pandas /io/common.py in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options) 705 encoding=ioargs.encoding, 706 errors=errors, --> 707 newline=\"\", 708 ) 709 else: FileNotFoundError: [Errno 2] No such file or directory: 'solarstations.csv' Make this Notebook Trusted to load map: File -> Trust Notebook ! ! ! ! ++ −− 300 km 200 mi Leaﬂet (https://leaﬂetjs.com) | Data by © OpenStreetMap (http://openstreetmap.org), under ODbL (http://www.openstreetmap.org/copyright). Help support the SRML! import pvlib df = pvlib.iotools.read_srml_month_from_solardat( station='HE', year=2020, month=6) df.head(12) # print the first 12 rows of data Solar Radiation Monitoring Laboratory (SRML) — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/srml.html 1 of 2 9/28/22, 6:03 PM Available parameters Click the plus symbol above to see the first 12 data entries. ghi_0 ghi_0_flag dni_0 dni_0_flag dhi_3 dhi_3_flag ghi_2 ghi_2_flag dni_2 dni_2_flag ... relative_humidity_1 relative_humidity_1_flag 9151 9151_flag wind_dir_1 wind_dir_1_flag wind_speed_1 2020-06-01 00:00:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.3 12 0.0 11 172.5 11 2020-06-01 00:01:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.5 12 0.0 11 180.7 11 2020-06-01 00:02:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.6 12 0.0 11 128.9 11 2020-06-01 00:03:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.4 12 0.0 11 141.6 11 2020-06-01 00:04:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.6 12 0.0 11 186.3 11 2020-06-01 00:05:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.4 12 0.0 11 188.7 11 2020-06-01 00:06:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.1 12 0.0 11 170.8 11 2020-06-01 00:07:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.5 12 0.0 11 122.4 11 2020-06-01 00:08:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.7 12 0.0 11 236.5 11 2020-06-01 00:09:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.2 12 0.0 11 201.3 11 2020-06-01 00:10:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.8 12 0.0 11 186.7 11 2020-06-01 00:11:00-08:00 0 12 0 12 0 12 0 12 0 12 ... 55.9 12 0.0 11 192.1 11 12 rows × 30 columns The data retrieved from the Hermiston station includes measurements of the three irradiance components, as well as additional weather parameters such as temperature and humidity. A few of the parameters in the datasets for the month of data are visualized below. axes = df[['ghi_0','dni_0','dhi_3','temp_air_1','wind_speed_1']].plot( subplots=True, legend=False, rot=0, figsize=(8,8), sharex=True) # Set y-labels and y-limits axes[0].set_ylabel('GHI [W/m$^2$]'), axes[0].set_ylim(-10,1400) axes[1].set_ylabel('DNI [W/m$^2$]'), axes[1].set_ylim(-10,1400) axes[2].set_ylabel('DHI [W/m$^2$]'), axes[2].set_ylim(-10,1400) axes[3].set_ylabel('Temperature [°]'), axes[3].set_ylim(0,40) _ = axes[4].set_ylabel('Wind\\nspeed [m/s]'), axes[4].set_ylim(0,15) By The Assessing Solar Community © Copyright 2022. Solar Radiation Monitoring Laboratory (SRML) — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/srml.html 2 of 2 9/28/22, 6:03 PM Quality assessment of solar irradiance data Contents !\"Load data !\"Visual inspection !\"Checking for missing data !\"Two-dimensional visual inspection !\"Limit checks !\"Comparison checks It is virtually impossible to make continuous solar irradiance measurements without some amount of missing and erroneously data. While data providers often conduct a basic quality check, users of irradiance data are strongly urged to conduct their own quality assessment, as the necessary level of quality control depends on the application. There exists numerous methods for quality assessment of irradiance time- series. However, there is no commonly agreed upon methodology within the scientific community and hence, each user often ends up with his or her own method of quality assessing data and flagging/removing questionable data. This section aims at giving an introduction to the most commonly used quality assessment methods and a practical guide in how to apply them. Content by Adam R. Jensen & Yves-Marie Saint-Drenan Load data In order to demonstrate the quality assessment methods which will be introduced in this notebook, some sample data is needed. In the following code block, a one year dataset of GHI, DHI, and DNI from the Technical University of Denmark is read into a pandas DataFrame. The data file can be downloaded here. It is important to note, that in order to correctly calculate solar angles and sunrise/sunset times, the index must be made timezone aware. import pandas as pd import numpy as np import matplotlib.pyplot as plt import matplotlib.dates as mdates import datetime as dt import pvlib data_path = 'data/solar_irradiance_dtu_2019.csv' df = pd.read_csv(data_path, index_col=[0], parse_dates=[0]) df.index = df.index.tz_localize('UTC') # Make the index timezone aware original_entries = df.shape[0] df.head() # Print the first five lines of the DataFrame Quality assessment of solar irradiance data — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/quality_asessment.html 1 of 8 9/28/22, 6:03 PM GHI DHI DNI zenith azimuth Time(utc) 2019-01-01 00:00:00+00:00 -0.2 -0.2 -0.1 146.1 19.6 2019-01-01 00:01:00+00:00 -0.2 -0.2 -0.1 146.1 20.0 2019-01-01 00:02:00+00:00 -0.1 -0.2 -0.0 146.0 20.4 2019-01-01 00:03:00+00:00 -0.1 -0.2 -0.1 146.0 20.8 2019-01-01 00:04:00+00:00 -0.2 -0.2 -0.1 145.9 21.2 Visual inspection As a first check it is important to visualize the data, in order to ensure that the data has been loaded as expected and to detect major issues. For this purpose, the different measurements have been plotted as a function of time, as well as a histogram. Generally, this first qualitative analysis allows detecting major issues in the data set. Nevertheless, it is not possible to judge their plausibility at this stage of the data analysis. Checking for missing data Depending on the source of the data, there may be significnatly amount of missing data or gaps in the time series. This is typicaly for ground measurements, where cleaning events and periods of instrument malfunction have often been removed. fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12,8), gridspec_kw= {'width_ratios':[3,1]}) for i, c in enumerate(['GHI','DHI','DNI']): df[c].plot(ax=axes[i,0], c='C{}'.format(i), title=c) df[c].plot.hist(ax=axes[i,1], logy=True, bins=50, facecolor='C{}'.format(i)) axes[i,0].set_xlabel('') axes[i,0].set_ylabel('Irradiance [W/m$^2$]') axes[i,1].set_xlabel('Irradiance [W/m$^2$]') fig.tight_layout() Quality assessment of solar irradiance data — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/quality_asessment.html 2 of 8 9/28/22, 6:03 PM Preferably the timestamps for these periods should still be present in the dataset with a corresonding nan entry, though sometimes the time stamp entries have been entirely omitted. Therefore, it is important to first ensure that the time series has a consistent frequency, e.g. that that there are no missing time entries. This can easily be achieved using the asfreq function, which converts the time-series to a consistent frequency (e.g. 1 min., 15 min., or 1 h), by adding missing rows. First then can the amount of missing data be quantified and the subsequent 2D plots be generated in the next section. Two-dimensional visual inspection In the visualization of the raw data in Section 5.2, it was possible to detect large gaps, extreme values, and seasonal variations. However, the daily variations was smothered and pratically indistinguisable due to the large amount of data. To overcome this limitation, a two-dimensional visualization method is presented in this section, where the x-axis coresponds to the day, the y-axis corresponds to the time of day, and the pixel color corresponds to the measurement value. The strength of this two- dimensional method is that each data point is visible, allowing for both intra-day and seasonal trends to be observe. This is particularly useful for detecting errors over time, such as time shifts, missing data, and possibly shading. To add structure to the 2D plots, we will plot the sunrise and sunset times, which are calculated as: df = df.asfreq('1min') # Convert TimeSeries to specified frequency print('Missing rows added: {:.1f} %'.format((df.shape[0]- original_entries)/df.shape[0]*100)) axes = df[['GHI', 'DHI', 'DNI']].isna().astype(float).resample('1h').sum().divide(60/100).plot(su bplots=True, figsize=(8,4), rot=0) # Plot missing data axes[1].set_ylabel('Missing data [%/hour]') for c in ['GHI', 'DHI', 'DNI']: print('Missing data {}: {:.1f} %'.format(c, df[c].isna().sum()/df.shape[0]*100)) Missing rows added: 1.0 % Missing data GHI: 1.0 % Missing data DHI: 1.0 % Missing data DNI: 1.0 % Quality assessment of solar irradiance data — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/quality_asessment.html 3 of 8 9/28/22, 6:03 PM Next, the 2D DataFrame is created and plotted: days = pd.date_range(df.index[0], df.index[-1]) # List of days for which to calculate sunrise/sunset sunrise_sunset = pvlib.solarposition.sun_rise_set_transit_spa(days, latitude=55.791, longitude=12.525) # Convert sunrise/sunset from Datetime to hours (decimal) sunrise_sunset['sunrise'] = sunrise_sunset['sunrise'].dt.hour + sunrise_sunset['sunrise'].dt.minute/60 sunrise_sunset['sunset'] = sunrise_sunset['sunset'].dt.hour + sunrise_sunset['sunset'].dt.minute/60 # Creation of the 2D DataFrame, with time-of-day as rows and days as columns df_2d = df.set_index([df.index.date, df.index.hour+df.index.minute/60]).unstack(level=0) # Calculate the extents of the 2D plot, in the format [x_start, x_end, y_start, y_end] xlims = mdates.date2num([df.index[0].date(), df.index[-1].date()]) extent = [xlims[0], xlims[1], 0, 24] xticks = pd.date_range('2019-01-01', periods=13, freq='MS') # Generate subplots and plot 2D DataFrame and sunrise/sunset line fig, axes = plt.subplots(nrows=3, figsize=(10,10), sharex=True) for i, c in enumerate(['GHI','DHI','DNI']): im = axes[i].imshow(df_2d[c], aspect='auto', origin='lower', cmap='nipy_spectral', extent=extent, vmax=df[c].quantile(0.999)) axes[i].set_title(c) axes[i].xaxis_date() axes[i].set_yticks(np.arange(0,25,3)) axes[i].set_ylabel('Time of day [h]') axes[i].plot(mdates.date2num(sunrise_sunset.index), sunrise_sunset[['sunrise', 'sunset']], 'm--') cbar = fig.colorbar(im, ax=axes[i], orientation='vertical', label='Irradinace [W/m$^2$]') axes[-1].set_xticks(mdates.date2num(xticks)) axes[-1].set_xticklabels(xticks.strftime('%b')) fig.tight_layout() Quality assessment of solar irradiance data — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/quality_asessment.html 4 of 8 9/28/22, 6:03 PM Limit checks To verify the validity of the measurements, we apply the test proposed by Long and Dutton and recommened by the BSRN. This first quality control consists in a set of two tests for each physical quantity: the physically possible limit and the extremely rare limit tests. These are detailed for the GHI, the DHI and the BNI below: Physical possible limits Physically Possible Limits (PPL) check the maximum and minimum limits that can be reached by irradiance, the upper limits depend on the solar zenith angle, the minimal value of solar irradiance must be 0 W/m², but because of the radiative cooling at night the limit is set at -4 W/m², the test applies independently to each of the three components as follows: Extremely rare limits The limits of the “Extremely Rare Limits”(ERL) procedure are more strict than those of the “Physically Possible” test. ERL differs from the PPL test in that the measurements rarely reach these limits, and even if the case is only for short periods of a few seconds −4 W/m^2 < GHI < Sa ⋅ 1.5µ1.2 0 + 100 W/m^2 −4 W/m2 < DHI < Sa ⋅ 0.95µ1.2 0 + 50 W/m^2 −4 W/m2 < DNI < Sa Quality assessment of solar irradiance data — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/quality_asessment.html 5 of 8 9/28/22, 6:03 PM to one or two minutes, and also in those measurements violating these limits are not necessarily incorrect but their plausibility should be checked more specifically. The ERL limits are defined as follows: A graphical representation of these two tests is possible by representing the 10-minute averages of GHI, DHI or DNI as a function of the irradiance received at the top of the atmosphere (TOA). This representation is shown in Fig. 7 where the one-component PPL and ERL tests are represented by green and red lines respectively. In view of the QC equations, it might have been simpler to use the cosine of the zenith solar angle for the graphical representation of the QC. However, we opted for the irradiance at the top of the atmosphere because we judged this quantity to be more intuitive. Finally, another quantity would have been more suitable to represent the quality control of the DNI but we chose to keep the same quantity between the different representations for consistency reasons. First, it is necessary to calculate the extraterrestrial radiation I as used in the equations above: −2 W/m2 < GHI < Sa ⋅ 1.2µ1.2 0 + 50 W/m2 −2 W/m2 < DHI < Sa ⋅ 0.75µ1.2 0 + 30 W/m2 −2 W/m2 < DNI < Sa ⋅ 0.95µ0.2 0 + 10 Wm−2 0 df['extra_radiation'] = pvlib.irradiance.get_extra_radiation(df.index) df['mu0'] = np.cos(np.deg2rad(df['zenith'])).clip(lower=0) df_limits = pd.DataFrame(index=df.index, data={'zenith':df['zenith']}) # Physical possible limits df_limits['ppl_upper_GHI'] = 1.5 * df['extra_radiation'] * df['mu0']**1.2 + 100 df_limits['ppl_upper_DHI'] = 0.95 * df['extra_radiation'] * df['mu0']**1.2 + 50 df_limits['ppl_upper_DNI'] = 1 * df['extra_radiation'] # Extremely rare limits df_limits['erl_upper_GHI'] = 1.2 * df['extra_radiation'] * df['mu0']**1.2 + 50 df_limits['erl_upper_DHI'] = 0.75 * df['extra_radiation'] * df['mu0']**1.2 + 30 df_limits['erl_upper_DNI'] = 0.95 * df['extra_radiation'] * df['mu0']**0.2 + 10 # Plot measured data and limits fig, axes = plt.subplots(nrows=3, figsize=(8,8), sharex=True) for i, c in enumerate(['GHI','DHI','DNI']): df_limits[df_limits['zenith']<90].plot.scatter(ax=axes[i], x='zenith', y='ppl_upper_{}'.format(c), s=1, c='g', label='Physical possible limit') df_limits[df_limits['zenith']<90].plot.scatter(ax=axes[i], x='zenith', y='erl_upper_{}'.format(c), s=1, c='r', label='Extremely rare limit') df[df_limits['zenith']<90].plot.scatter(ax=axes[i], x='zenith', y=c, s=0.1, alpha=0.1, xlim=[None,93], label='Measurement') axes[i].set_title(c) # Configure legend legend = axes[i].legend(loc='upper right') for handle in legend.legendHandles: handle.set_sizes([10]) handle.set_alpha(1) fig.tight_layout() Quality assessment of solar irradiance data — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/quality_asessment.html 6 of 8 9/28/22, 6:03 PM Comparison checks Diffuse ratio test Another test recommended by BSRN is the two-component test where the consistency of independent measurements is tested. Where GHI and DHI measurements are available, a comparison of these two measures can be checked for consistency by applying, for GHI>50 W/m², the following two-component tests: These tests are not possible for GHI values below 50 W/m². For the visual representation of this test, we have chosen to represent the ratio DHI/GHI as a function of the solar zenith angle. In the plot below, all values of GHI< 50 W/m² are represented by grey dots and the values for which GHI>50 W/m² are represented by blue dots. The limits defined by the two equations above are represented by red lines. 0.92 < GHI DHI + DNI cos(θz) < 1.08 # Calculation of diffuse ratio df['K_t'] = df['DHI'] / df['GHI'] df.loc[df['zenith']>93, 'K_t'] = np.nan # Plot diffuse ratio and limit (red) fig, ax = plt.subplots(figsize=(8,5)) df[df['GHI']>50].plot.scatter(ax=ax, x='zenith', y='K_t', c='k', s=0.05, alpha=0.75, ylim=[0,1.4], xlim=[20,93]) ax.plot([0,75,75,93], [1.05,1.05,1.10,1.10], c='r') [<matplotlib.lines.Line2D at 0x7f374d9d3ad0>] Quality assessment of solar irradiance data — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/quality_asessment.html 7 of 8 9/28/22, 6:03 PM Closure-equation test The three-component test is intended to compare the GHI measured by the pyranometer and calculated from the measured DHI and DNI: This test only applies for GHI>50 W/m . Here again, we propose a data visualization corresponding to this test. For this, we can note that the three-component test consists in comparing the GHI measured with the pyranometer with an estimate of the GHI obtained with the DNI measured with a pherilyometer and the DHI measured with a shaded pyranometer using the equation linking the GHI with two other components and the zenith solar angle . Ideally, the ratio of measured and estimated GHI should be 1.0, but instruments characteristics often produce values far from unity. 2 df['sumsw'] = df['DHI'] + df['DNI']*np.cos(np.deg2rad(df['zenith'])) df['sumsw_ratio'] = df['GHI'] / df['sumsw'] fig, ax = plt.subplots(figsize=(8,5)) df[(df['zenith']<93)&(df['GHI']>50)].plot.scatter(ax=ax, x='zenith', y='sumsw_ratio', alpha=0.76, s=1, c='k', xlim=[20,93], ylim=[0.5,1.5]) ax.plot([0,75,75,93], [1.08,1.08,1.15,1.15], c='r') ax.plot([0,75,75,93], [0.92,0.92,0.85,0.85], c='r') [<matplotlib.lines.Line2D at 0x7f3754148390>] By The Assessing Solar Community © Copyright 2022. Quality assessment of solar irradiance data — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/quality_asessment.html 8 of 8 9/28/22, 6:03 PM Solar Power Modelling Contents !\"1 Defining PV System Components !\"2 I-V Characteristic Curve !\"3 Irradiance to DC power conversion !\"4 DC to AC power conversion (inverter models) !\"5 Whole System Irradiance to Power Conversion !\"Section Summary !\"References The conversion of solar irradiance to electric power output as observed in photovoltaic (PV) systems is covered in this chapter of AssessingSolar.org. Other chapters facilitate best practices in how to obtain solar radiation data, how to apply certain quality checks to the data or how to manipulate and assess timeseries of solar data for solar resource assessment. However, for PV applications it is important that we consider the conversion from irradiance to power output occuring between the different components of a PV system and of the PV system as a whole. The several sections of this chapter aim to illustrate the conversion from irradiance to power step by step: !\"1 Defining PV system components; !\"2 I-V characteristic curve; !\"3 Irradiance to DC power conversion; !\"4 DC to AC power conversion (inverter models); !\"5 Whole System Irradiance to Power Conversion. The code in this chapter is mainly based on the Python libraries pvlib and other general purpose libraries, such as numpy, pandas and matplotlib. Content by Javier Lopez Lorente 1 Defining PV System Components In this section we cover how to define or obtain the different characteristics and specifications of several components of PV systems, such as PV modules and PV inverters. These components can be defined manually, for example, in Python dictionary or can be retrieved from existing databases. Definition of PV module The characteristics of PV modules in Python can be retrieved by using pvlib. The 2 main databases for PV modules that can be imported are: (1) the Sandia Laboratories PV module database; and (2) the CEC PV module database. Below, we present an example to how the databases can be accessed. There are over 21,500 modules in that version of the CEC PV module database. Each module has 25 parameters that are technical information of the module and metadata. The database is returned as a pandas DataFrame, so each of the modules can be accessed with integer-location based indexing using iloc. Let’s have a look to the parameters of one of them selected randomly: The parameters of the CEC database include technology (string), bifacial (boolean), STC power (float), PTC power (float), dimensions of the panel, open-circuit and short- circuit specifications, and other technical characteristics including the 5-parameter needed for the single diode equation to estimate the DC power under certain conditions. Similarly, the Sandia Laboratories PV module database can be accessed: # Import the particular module of the pvlib library from pvlib import pvsystem # CEC PV Module Database cec_mod_db = pvsystem.retrieve_sam('CECmod') # Size of the database print(cec_mod_db.shape) (25, 21535) import numpy as np print(cec_mod_db.iloc[:, np.random.randint(0, high=len(cec_mod_db))]) Technology Multi-c-Si Bifacial 0 STC 269.919 PTC 244.4 A_c 1.94 Length 1.956 Width 0.992 N_s 72 I_sc_ref 8.42 V_oc_ref 44.5 I_mp_ref 7.69 V_mp_ref 35.1 alpha_sc 0.007098 beta_oc -0.161579 T_NOCT 45.4 a_ref 1.895729 I_L_ref 8.454391 I_o_ref 0.0 R_s 0.511279 R_sh_ref 125.177597 Adjust 3.655345 gamma_r -0.4335 BIPV N Version SAM 2018.11.11 r2 Date 1/3/2019 Name: Aavid_Solar_ASMS_270P, dtype: object # Sandia PV Module Database sandia_mod_db = pvsystem.retrieve_sam('sandiamod') # Dimensions print(sandia_mod_db.shape) (42, 523) # Accessing the characteristics of one of the modules randomly print(sandia_mod_db.iloc[:, np.random.randint(0, high=len(sandia_mod_db))]) Solar Power Modelling — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_power_modeling.html 1 of 7 9/28/22, 6:04 PM We observe that the database of PV modules from Sandia Laboratories includes more technical parameters and information than the CEC module database. However, it contains less modules. Alternatively, you can define a dictionary with the characteristics of the PV module as found in a typical datasheet. Definition of a PV inverter Similarly to the database of PV modules, it is possible to access the CEC database of PV inverters. There over 3,200 inverters available and each of them has 16 parameters. As in the case of the PV modules, you can define your own PV inverter using a dictionary. Let’s have a look to one of those solar inverters. 2 I-V Characteristic Curve The I-V curve of a PV module is one of the typical technical characteristics often available in datasheets. In this section, we are going to build the I-V characteristic curve of a PV module from the data available in the technical specification sheet. We will use the dictionary ‘module_data’ that we have just created in the previous section. In order to build the I-V curve, we will need several steps until we estimate the 5 input parameters needed to perform the single diode equation that will return the I and V values for given values of effective irradiance and cell/module temperature. We observe that the output of the function are 6 float elements. The documentation of pvlib indicates that these correspond to reference conditions values for: 1. Light-generated current (i_l_ref) in Amps; 2. Diode reverse saturation current (i_o_ref) in Amps; 3. Series resistance (r_s) in Ohms; 4. Shunt resistance (r_sh_ref) in Ohms; 5. The product of the diode ideality factor, number of cells in series and cell thermal voltage (a_ref); and 6. The adjustment to the temperature coefficient for short-circuit current in percentage (adjust). Vintage 2001 Area 1.12 Material c-Si Cells_in_Series 42 Parallel_Strings 1 Isco 7.35 Voco 25.07 Impo 6.57 Vmpo 19.46 Aisc 0.000201 Aimp -0.000423 C0 0.995 C1 0.005 Bvoco -0.0954 Mbvoc 0 Bvmpo -0.0984 Mbvmp 0 N 1.549 C2 -0.0665 C3 -11.4245 A0 0.918 A1 0.068713 A2 -0.010438 A3 0.000725 A4 -0.00002 B0 1 B1 -0.002438 B2 0.00031 B3 -0.000012 B4 0.0 B5 -0.0 DTC 3.0 FD 1 A -3.56 B -0.075 C4 0.989 C5 0.011 IXO 7.26 IXXO 4.59 C6 1.118 C7 -0.118 Notes Source: Sandia National Laboratories Updated 9... Name: AstroPower_AP_130___2001_, dtype: object # PV module data from a typical datasheet (e.g. Kyocera Solar KD225GX LPB) module_data = {'celltype': 'multiSi', # technology 'STC': 224.99, # STC power 'PTC': 203.3, # PTC power 'v_mp': 29.8, # Maximum power voltage 'i_mp': 7.55, # Maximum power current 'v_oc': 36.9, # Open-circuit voltage 'i_sc': 8.18, # Short-circuit current 'alpha_sc': 0.001636, # Temperature Coeff. Short Circuit Current [A/C] 'beta_voc': -0.12177, # Temperature Coeff. Open Circuit Voltage [V/C] 'gamma_pmp': -0.43, # Temperature coefficient of power at maximum point [%/C] 'cells_in_series': 60, # Number of cells in series 'temp_ref': 25} # Reference temperature conditions invdb = pvsystem.retrieve_sam('CECInverter') print(invdb.shape) (16, 3264) # Accessing the characteristics of one of the modules randomly inverter_data = invdb.iloc[:, np.random.randint(0, high=len(invdb))] print(inverter_data) Vac 208 Pso 18.166279 Paco 3000.0 Pdco 3142.30127 Vdco 310.0 C0 -0.000008 C1 -0.000011 C2 0.000999 C3 -0.000287 Pnt 0.1 Vdcmax 480.0 Idcmax 10.136456 Mppt_low 100.0 Mppt_high 480.0 CEC_Date NaN CEC_Type Utility Interactive Name: ABB__PVI_3_0_OUTD_S_US__208V_, dtype: object # Import the pvlib library import pvlib # 1st step: Estimating the parameters for the CEC single diode model \"\"\" WARNING - This function relies on NREL's SAM tool. So PySAM, its Python API, needs to be installed in the same computer. Otherwise, you can expect the following error: 'ImportError if NREL-PySAM is not installed.' \"\"\" cec_fit_params = pvlib.ivtools.sdm.fit_cec_sam(module_data['celltype'], module_data['v_mp'], module_data['i_mp'], module_data['v_oc'], module_data['i_sc'], module_data['alpha_sc'], module_data['beta_voc'], module_data['gamma_pmp'], module_data['cells_in_series'], module_data['temp_ref']) # Let's have a look to the output print(cec_fit_params) (8.202934969951475, 1.0116474863781549e-10, 0.357990198237105, 127.6810002117698, 1.4711220130107323, 1.0522776754347636) Solar Power Modelling — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_power_modeling.html 2 of 7 9/28/22, 6:04 PM After this step, we have an extended set of technical characteristics of the PV module. We could skip this step if we had these data at the beginning, e.g. by using a PV module from the CEC or Sandia databases. We will now define several reference conditions of effective irradiance and average cell temperature values for which to estimate the I-V curve. Then, the second step is estimating the 5 input parameters to be used in the Single Diode Equation: Finally, we can estimate the I-V characteristic of the PV module: We can then visualize the I-V characteristic of our PV module and the given reference conditions: Following on the assessment of the I-V curve of a PV module, it is possible to analyse the effect of temperature in the PV module performance. Below, an example of I-V curve is shown for an effective irradiance of 800 W/m with different average cell temperatures: # Effective irradiance values (W/m2) irrad = np.array([200,400,600,800,1000]) # Average cell temperature (degrees Celsius) temp_cell = np.array([40, 40, 40, 40, 40]) # 2nd step: Apply model to estimate the 5 parameters of the single diode equation using the CEC model diode_params = pvlib.pvsystem.calcparams_cec(irrad, temp_cell, module_data['alpha_sc'], cec_fit_params[4], cec_fit_params[0], cec_fit_params[1], cec_fit_params[3], cec_fit_params[2], cec_fit_params[5]) # The result of the function returns a Tuple of 5 parameters to be used in the single diode equation print('Number of elements returned: ', len(diode_params)) Number of elements returned: 5 # Let's have a look to the tuple: print(diode_params) (array([1.64544335, 3.2908867 , 4.93633004, 6.58177339, 8.22721674]), array([1.11964914e-09, 1.11964914e-09, 1.11964914e-09, 1.11964914e-09, 1.11964914e-09]), 0.357990198237105, array([638.40500106, 319.20250053, 212.80166702, 159.60125026, 127.68100021]), array([1.54513452, 1.54513452, 1.54513452, 1.54513452, 1.54513452])) # Estimate I-V characteristic using the Single Diode Equation iv_values1 = pvlib.pvsystem.singlediode(diode_params[0], diode_params[1], diode_params[2], diode_params[3], diode_params[4], ivcurve_pnts=25, # Number of points of the I-V curve (equally distributed) method='lambertw') # I-V using the Lambert W. function # The result is a large ordered dictionary with the IV-curve characteristics of our example. print(iv_values1.keys()) odict_keys(['i_sc', 'v_oc', 'i_mp', 'v_mp', 'p_mp', 'i_x', 'i_xx', 'v', 'i']) # Importing our library for plotting and visualization import matplotlib.pyplot as plt # We iterate over voltage for i in range(len(irrad)): plt.plot(iv_values1['v'][i], iv_values1['i'][i], label=str(irrad[i])+' W/m$^2$') plt.scatter(iv_values1['v_mp'][i], iv_values1['i_mp'][i]) # Add the title, axis labels and legend: plt.title('I-V characteristic curve with maximum power at 40$^\\circ$C') plt.xlabel('Voltage [V]') plt.ylabel('Current [A]') plt.ylim(0, 10) plt.legend(bbox_to_anchor=(1.05, 1), ncol=1) <matplotlib.legend.Legend at 0x7f477e6a7210> 2 # Effective irradiance values (W/m2) irrad = np.array([800, 800, 800, 800, 800, 800]) # Average cell temperature (degrees Celsius) temp_cell = np.array([10, 20, 30, 40, 50, 60]) # Repeating the process from before: # Estimate the 5 parameters of the single diode equation using the CEC model diode_params = pvlib.pvsystem.calcparams_cec(irrad, temp_cell, module_data['alpha_sc'], cec_fit_params[4], cec_fit_params[0], cec_fit_params[1], cec_fit_params[3], cec_fit_params[2], cec_fit_params[5]) # Estimate I-V characteristic using the Single Diode Equation iv_values2 = pvlib.pvsystem.singlediode(diode_params[0], diode_params[1], diode_params[2], diode_params[3], diode_params[4], ivcurve_pnts=25, # Number of points of the I-V curve (equally distributed) method='lambertw') # I-V using the Lambert W. function # Plotting the results for i in range(len(irrad)): plt.plot(iv_values2['v'][i], iv_values2['i'][i], label=str(temp_cell[i])+'$^\\circ$C') plt.scatter(iv_values2['v_mp'][i], iv_values2['i_mp'][i]) # Add the title, axis labels and legend: plt.title('Effect of module temperature in the I-V curve (800 W/m$^2$)') plt.xlabel('Voltage [V]') plt.ylabel('Current [A]') plt.ylim(0, 7) plt.legend(ncol=1) <matplotlib.legend.Legend at 0x7f477a51dd10> Solar Power Modelling — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_power_modeling.html 3 of 7 9/28/22, 6:04 PM 3 Irradiance to DC power conversion The production of DC power output of the PV module given by certain conditions of effective irradiance and cell temperature can be estimated in a straight-away manner by using NREL’s PVWatts DC power model (pvwatts_dc), which is available within pvlib. An example is presented below: We can observe the linear relationship between incident effective irradiance and DC power, and how cell temperature has a negative impact on the performance of the PV module. Overall, the lower the module’s temperature, the higher the PV output for a given irradiance level. 4 DC to AC power conversion (inverter models) Once the DC power is available, the AC power output can be estimated. The inverter is the PV element that implementes the power conversion from DC to AC. An example is shown below where we will use the DataFrame ‘inverter_data’ and the dictionary ‘iv_values1’ resulted from sections 1 and 2, respectively. Let’s recall and have a look to the keys available in those elements: The result is an array of 5 elements expressed in Watts. It is worth noting that the inverter requires starting power, which is denoted by ‘Pso’ in the dictionary. 5 Whole System Irradiance to Power Conversion The previous section have shown the conversion irradiance to power step-by-step. The library pvlib has an alternative method to estimate the AC power output in a more straight-forward way by using the pvlib classes PVSystem and ModelChain. This section presents an example to estimate the AC power directly using real weather data. The example below uses weather data from a station located at the University of Oregon, which belongs to the Measurement and Instrumentation Data Center (MIDC) of the U.S. National Renewable Energy Laboratory (NREL). The data used are 1-minute GHI, DHI, DNI, ambient temperature and wind speed measurements for one day in June 2021 (Vignola and Andreas, 2013). Retrieving real weather data: Unnamed: 0 Year DOY PST Unnamed: 4 Direct NIP [W/m^2] Diffuse Schenk [W/m^2] Global LI-200 [W/m^2] Relative Humidity [%] Air Temperature [deg C] ... CHP1 Temp [deg K] CMP22 Temp [deg K] Avg Wind Direction @ 10m [deg from N] Zenith Angle [degrees] Azimuth Angle [degrees] Airmass Solar Eclipse Shading SAMPA/Bird 2021-06-01 00:00:00-08:00 0 2021 152 0 -7999 -0.453 -1.129 0.157 58.95 19.89 ... 292.8 294.6 41.59 113.81644 357.43310 -1.0 0 2021-06-01 00:01:00-08:00 0 2021 152 1 -7999 -0.482 -1.150 0.154 59.13 19.79 ... 292.8 294.6 64.06 113.82399 357.68613 -1.0 0 2021-06-01 00:02:00-08:00 0 2021 152 2 -7999 -0.575 -1.174 0.134 59.76 19.70 ... 292.7 294.5 63.20 113.83076 357.93921 -1.0 0 3 rows × 29 columns # Randomly define a set of Effective Irradiance and cell temperature values: # Global plane-of-array effective irradiance between 200 and 1000 W/m2 g_poa_effective = np.random.uniform(low=200, high=1000, size=(80,)) # Mean cell temperature values between 10 and 50 degrees Celsius temp_cell = np.random.uniform(low=10, high=50, size=(80,)) # Definition of PV module characteristics: pdc0 = 250 # STC power gamma_pdc = -0.0045 # The temperature coefficient in units of 1/C # Estimate DC power with PVWatts model dc_power = pvlib.pvsystem.pvwatts_dc(g_poa_effective, temp_cell, pdc0, gamma_pdc, temp_ref=25.0) # Let's visualize the DC power output as function of the effective irradiance plt.scatter(g_poa_effective, dc_power, c=temp_cell, vmin=10, vmax=50, cmap='Reds') cbar = plt.colorbar() cbar.set_label('Cell Temperature [$^\\circ$C]') plt.title('PV Module DC Output vs. Plane-of-Array Irradiance') plt.xlabel('Effective Global Plane-of-Array Irradiance ($G_{POA}$) [W/m$^2$]') plt.ylabel('DC Power Output [W]') plt.show() # The DataFrame with the technical characteristics of the PV inverter inverter_data.keys() Index(['Vac', 'Pso', 'Paco', 'Pdco', 'Vdco', 'C0', 'C1', 'C2', 'C3', 'Pnt', 'Vdcmax', 'Idcmax', 'Mppt_low', 'Mppt_high', 'CEC_Date', 'CEC_Type'], dtype='object') # The dictionary with the current and voltage values iv_values1.keys() odict_keys(['i_sc', 'v_oc', 'i_mp', 'v_mp', 'p_mp', 'i_x', 'i_xx', 'v', 'i']) # Estimate AC power from DC power using the Sandia Model ac_power = pvlib.inverter.sandia(iv_values1['v_mp'], # DC voltage input to the inverter iv_values1['p_mp'], # DC power input to the inverter inverter_data) # Parameters for the inverter # Estimated Power Output ac_power array([ 28.16133774, 70.58616218, 112.54344311, 153.62860514, 193.65563637]) # Let's check the start DC power required for the inversion process (or self- consumption of the inverter) inverter_data['Pso'] 18.166279 import pandas as pd # Let's read the weather data from the MIDC station using the I/O tools available within pvlib df_weather = pvlib.iotools.read_midc_raw_data_from_nrel('UOSMRL', # Station id pd.Timestamp('20210601'), # Start date YYYYMMDD pd.Timestamp('20210601')) # End date YYYYMMDD # Let's see the head, shape and columns of the data df_weather.head(3) df_weather.shape (1437, 29) Solar Power Modelling — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_power_modeling.html 4 of 7 9/28/22, 6:04 PM The DataFrame of weather data provides more many variables (29 variables) than those needed (i.e., irradiance components, ambient temperature and wind speed) to estimate the equivalent AC power of a PV system. ghi dhi dni temp_air wind_speed 2021-06-01 00:00:00-08:00 -0.391 -1.129 0.425 19.89 0.200 2021-06-01 00:01:00-08:00 -0.391 -1.150 0.411 19.79 0.312 2021-06-01 00:02:00-08:00 -0.401 -1.174 0.425 19.70 0.250 For the example, the surface tilt will be 30 , and a surface_azimuth of 180 (south orientation). Let’s define the basics parameters within the PVSystem and ModelChain classes: Definining the characteristics of the PV system: Running the model with the weather data: Accessing the results of the model: After running the model with the weather data, the results can be accessed with the method ‘results’. There are multiple sets of results that can be accessed, some of them are: the weather data ‘weather’; the solar position ‘solar_position’; the plane-of-array irradiance components ‘total_irrad’; the DC power output ‘dc’; or the AC power output ‘ac’. Let’s have a look how that can be done: ghi dhi dni wind_speed temp_air 2021-06-01 00:00:00-08:00 -0.391 -1.129 0.425 0.200 19.89 2021-06-01 00:01:00-08:00 -0.391 -1.150 0.411 0.312 19.79 2021-06-01 00:02:00-08:00 -0.401 -1.174 0.425 0.250 19.70 2021-06-01 00:03:00-08:00 -0.414 -1.185 0.425 0.375 19.67 2021-06-01 00:04:00-08:00 -0.420 -1.182 0.425 0.300 19.59 ... ... ... ... ... ... 2021-06-01 23:55:00-08:00 -0.299 -0.849 0.425 0.200 22.74 2021-06-01 23:56:00-08:00 -0.295 -0.838 0.425 0.200 22.75 2021-06-01 23:57:00-08:00 -0.300 -0.865 0.425 0.200 22.74 2021-06-01 23:58:00-08:00 -0.299 -0.952 0.425 0.200 22.77 2021-06-01 23:59:00-08:00 -0.275 -0.974 0.425 0.200 22.81 df_weather.columns Index(['Unnamed: 0', 'Year', 'DOY', 'PST', 'Unnamed: 4', 'Direct NIP [W/m^2]', 'Diffuse Schenk [W/m^2]', 'Global LI-200 [W/m^2]', 'Relative Humidity [%]', 'Air Temperature [deg C]', 'Avg Wind Speed @ 10m [m/s]', 'Station Pressure [mBar]', 'Downwelling IR PIR [W/m^2]', 'Instrument Net PIR [W/m^2]', 'PIR Case Temp [deg K]', 'PIR Dome Temp [deg K]', 'Logger Battery [VDC]', 'Direct CHP1 [W/m^2]', 'Global CMP22 [W/m^2]', 'CHP1 Temp [deg K]', 'CMP22 Temp [deg K]', 'Avg Wind Direction @ 10m [deg from N]', 'Zenith Angle [degrees]', 'Azimuth Angle [degrees]', 'Airmass', 'Solar Eclipse Shading', 'Direct SAMPA/Bird (calc) [W/m^2]', 'Global SAMPA/Bird (calc) [W/m^2]', 'Diffuse SAMPA/Bird (calc) [W/m^2]'], dtype='object') # Subset variables needed df_weather = df_weather[['Global CMP22 [W/m^2]', 'Diffuse Schenk [W/m^2]', 'Direct CHP1 [W/m^2]','Air Temperature [deg C]', 'Avg Wind Speed @ 10m [m/s]']] # Rename the columns df_weather.columns = ['ghi', 'dhi', 'dni', 'temp_air', 'wind_speed'] # See the first columns of our weather dataset df_weather.head(3) ∘ ∘ # Coordinates of the weather station at University of Oregon (SRML) latitude = 44.0467 longitude = -123.0743 altitude = 133.8 # Define the location object location = pvlib.location.Location(latitude, longitude, altitude=altitude) # Define Temperature Paremeters temperature_model_parameters = pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass'] # Define the PV Module and the Inverter from the CEC databases (For example, the first entry of the databases) module_data = cec_mod_db.iloc[:,0] # Define the basics of the class PVSystem system = pvlib.pvsystem.PVSystem(surface_tilt=30, surface_azimuth=180, module_parameters=module_data, inverter_parameters=inverter_data, temperature_model_parameters=temperature_model_parameters) # Creation of the ModelChain object \"\"\" The example does not consider AOI losses nor irradiance spectral losses\"\"\" mc = pvlib.modelchain.ModelChain(system, location, aoi_model='no_loss', spectral_model='no_loss', name='AssessingSolar_PV') # Have a look to the ModelChain print(mc) ModelChain: name: AssessingSolar_PV clearsky_model: ineichen transposition_model: haydavies solar_position_method: nrel_numpy airmass_model: kastenyoung1989 dc_model: cec ac_model: sandia_inverter aoi_model: no_aoi_loss spectral_model: no_spectral_loss temperature_model: sapm_temp losses_model: no_extra_losses # Pass the weather data to the model \"\"\" The weather DataFrame must include the irradiance components with the names 'dni', 'ghi', and 'dhi'. The air temperature named 'temp_air' in degree Celsius and wind speed 'wind_speed' in m/s are optional. \"\"\" mc.run_model(df_weather) ModelChain: name: AssessingSolar_PV clearsky_model: ineichen transposition_model: haydavies solar_position_method: nrel_numpy airmass_model: kastenyoung1989 dc_model: cec ac_model: sandia_inverter aoi_model: no_aoi_loss spectral_model: no_spectral_loss temperature_model: sapm_temp losses_model: no_extra_losses # Access the weather data mc.results.weather Solar Power Modelling — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_power_modeling.html 5 of 7 9/28/22, 6:04 PM 1437 rows × 5 columns This returns the same DataFrame ‘df_weather’ that we had passed to the model. apparent_zenith zenith apparent_elevation elevation azimuth equation_of_time 2021-06-01 00:00:00-08:00 113.816399 113.816399 -23.816399 -23.816399 357.431855 2.157534 2021-06-01 00:01:00-08:00 113.823961 113.823961 -23.823961 -23.823961 357.684892 2.157427 2021-06-01 00:02:00-08:00 113.830729 113.830729 -23.830729 -23.830729 357.937970 2.157321 2021-06-01 00:03:00-08:00 113.836705 113.836705 -23.836705 -23.836705 358.191084 2.157214 2021-06-01 00:04:00-08:00 113.841887 113.841887 -23.841887 -23.841887 358.444229 2.157107 ... ... ... ... ... ... ... 2021-06-01 23:55:00-08:00 113.634624 113.634624 -23.634624 -23.634624 356.135134 2.000772 2021-06-01 23:56:00-08:00 113.646251 113.646251 -23.646251 -23.646251 356.387404 2.000661 2021-06-01 23:57:00-08:00 113.657089 113.657089 -23.657089 -23.657089 356.639737 2.000549 2021-06-01 23:58:00-08:00 113.667137 113.667137 -23.667137 -23.667137 356.892129 2.000438 2021-06-01 23:59:00-08:00 113.676395 113.676395 -23.676395 -23.676395 357.144575 2.000326 1437 rows × 6 columns The solar position returns the zenith, solar elevation, azimuth angles and the equation of time. poa_global poa_direct poa_diffuse poa_sky_diffuse poa_ground_diffuse 2021-06-01 00:00:00-08:00 -0.006548 0.0 -0.006548 0.0 -0.006548 2021-06-01 00:01:00-08:00 -0.006548 0.0 -0.006548 0.0 -0.006548 2021-06-01 00:02:00-08:00 -0.006715 0.0 -0.006715 0.0 -0.006715 2021-06-01 00:03:00-08:00 -0.006933 0.0 -0.006933 0.0 -0.006933 2021-06-01 00:04:00-08:00 -0.007034 0.0 -0.007034 0.0 -0.007034 ... ... ... ... ... ... 2021-06-01 23:55:00-08:00 -0.005007 0.0 -0.005007 0.0 -0.005007 2021-06-01 23:56:00-08:00 -0.004940 0.0 -0.004940 0.0 -0.004940 2021-06-01 23:57:00-08:00 -0.005024 0.0 -0.005024 0.0 -0.005024 2021-06-01 23:58:00-08:00 -0.005007 0.0 -0.005007 0.0 -0.005007 2021-06-01 23:59:00-08:00 -0.004605 0.0 -0.004605 0.0 -0.004605 1437 rows × 5 columns The results for the plane-of-array irradiance returns the global POA irradiance and its components at the designated tilt and azimuth angle of the PV system and estimated with the method designated in ModelChain. Let’s see how to access the DC and AC power output of the PV system: i_sc v_oc i_mp v_mp p_mp i_x i_xx 2021-06-01 00:00:00-08:00 -0.000034 0.0 0.0 0.0 0.0 0.0 0.0 2021-06-01 00:01:00-08:00 -0.000034 0.0 0.0 0.0 0.0 0.0 0.0 2021-06-01 00:02:00-08:00 -0.000035 0.0 0.0 0.0 0.0 0.0 0.0 2021-06-01 00:03:00-08:00 -0.000036 0.0 0.0 0.0 0.0 0.0 0.0 2021-06-01 00:04:00-08:00 -0.000036 0.0 0.0 0.0 0.0 0.0 0.0 ... ... ... ... ... ... ... ... 2021-06-01 23:55:00-08:00 -0.000026 0.0 0.0 0.0 0.0 0.0 0.0 2021-06-01 23:56:00-08:00 -0.000026 0.0 0.0 0.0 0.0 0.0 0.0 2021-06-01 23:57:00-08:00 -0.000026 0.0 0.0 0.0 0.0 0.0 0.0 2021-06-01 23:58:00-08:00 -0.000026 0.0 0.0 0.0 0.0 0.0 0.0 2021-06-01 23:59:00-08:00 -0.000024 0.0 0.0 0.0 0.0 0.0 0.0 1437 rows × 7 columns Analyzing and visualizing the results: With all the set of results, we can analyze and visualize the results of the PV system. # Access the solar position at each timestamp mc.results.solar_position # Access Plane-of-array Irradiances mc.results.total_irrad # Access the DC power output mc.results.dc # Access the AC power output mc.results.ac 2021-06-01 00:00:00-08:00 -0.1 2021-06-01 00:01:00-08:00 -0.1 2021-06-01 00:02:00-08:00 -0.1 2021-06-01 00:03:00-08:00 -0.1 2021-06-01 00:04:00-08:00 -0.1 ... 2021-06-01 23:55:00-08:00 -0.1 2021-06-01 23:56:00-08:00 -0.1 2021-06-01 23:57:00-08:00 -0.1 2021-06-01 23:58:00-08:00 -0.1 2021-06-01 23:59:00-08:00 -0.1 Length: 1437, dtype: float64 Solar Power Modelling — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_power_modeling.html 6 of 7 9/28/22, 6:04 PM With the power output data, it is possible to assess the amount of solar energy generated in the period of time assessed: Section Summary This section has looked at the conversion from irradiance to power output in a PV system. Multiple examples have been presented illustrating: !\"how to access data of PV components such as PV modules and inverters; !\"how to estimate and visualize the I-V curve of a PV module under certain irradiance and temperature conditions; and !\"how to estimate and visualize the DC and AC power output from irradiance data. The code provided in the examples can help you as a starting point to assess other solar systems by adapting the characteristics and particularising to your case study. References Vignola, F.; Andreas, A.; (2013). University of Oregon: GPS-based Precipitable Water Vapor (Data); NREL Report No. DA-5500-64452. http://dx.doi.org/10.7799/1183467 from matplotlib.dates import DateFormatter # Define labels of variables to plot and colors irrad_labels = ['ghi', 'dni', 'dhi'] poa_labels = ['poa_global', 'poa_direct', 'poa_diffuse'] colors = ['green', 'orange', 'blue'] # Plot of Irradiance Variables fig, ax = plt.subplots(figsize=(7, 4)) for i in range(len(irrad_labels)): mc.results.weather[irrad_labels[i]].plot(label=irrad_labels[i].upper(), color=colors[i]) ax = mc.results.total_irrad[poa_labels[i]].plot(label=poa_labels[i].upper().replace('_' , ' '), color=colors[i], ls='--') ax.xaxis.set_major_formatter(DateFormatter(\"%H:%M\")) ax.set_ylabel('Irradiance [W/m$^2$]') ax.set_xlabel('UTC Time [HH:MM]') ax.set_title('Irradiance Components') plt.legend(bbox_to_anchor=(1.02,1)) plt.tight_layout() plt.show() # Plot of Power Output fig, ax = plt.subplots(figsize=(7, 3)) mc.results.dc['p_mp'].plot(label='DC power') ax = mc.results.ac.plot(label='AC power') ax.xaxis.set_major_formatter(DateFormatter(\"%H:%M\")) ax.set_ylabel('Power [W]') ax.set_xlabel('UTC Time [HH:MM]') ax.set_title('Power Output of PV System') plt.legend() plt.tight_layout() plt.show() # Estimate solar energy available and generated poa_energy = mc.results.total_irrad['poa_global'].sum()*(1/60)/1000 # Daily POA irradiation in kWh dc_energy = mc.results.dc['p_mp'].sum()*(1/60)/1000 # Daily DC energy in kWh ac_energy = mc.results.ac.sum()*(1/60)/1000 # Daily AC energy in kWh print('*'*15, ' Daily Production ','*'*15,'\\n','-'*48) print('\\tPOA irradiation: ', \"%.2f\" % poa_energy, 'kWh') print('\\tInstalled PV Capacity: ', \"%.2f\" % module_data['STC'], 'W') print('\\tDC generation:', \"%.2f\" % dc_energy, 'kWh (','%.2f'% (dc_energy*1000/module_data['STC']), 'kWh/kWp)') print('\\tAC generation:', \"%.2f\" % ac_energy, 'kWh (','%.2f'% (ac_energy*1000/module_data['STC']), 'kWh/kWp)') print('-'*50) *************** Daily Production *************** ------------------------------------------------ POA irradiation: 8.11 kWh Installed PV Capacity: 175.09 W DC generation: 1.20 kWh ( 6.88 kWh/kWp) AC generation: 1.01 kWh ( 5.79 kWh/kWp) -------------------------------------------------- By The Assessing Solar Community © Copyright 2022. Solar Power Modelling — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/solar_power_modeling.html 7 of 7 9/28/22, 6:04 PM Site Adaptation Contents !\"Quantile mapping for site adaptation !\"Example of site adaptation !\"Section summary !\"References Site adaptation is a process in which long term time series of a modeled variable (i.e., solar irradiance) is improved in accuracy by using short term of observations of the variable (for instance, one year of ground measurements in solar irradiance). One of the site adaptation methods is Quantile Mapping. In this section, an example for site adaptation using this technique is presented. Content by Jesús Polo Let’s import the required libraries for this example: Quantile mapping for site adaptation Quantile mapping (QM) is a simple technique used in climate modeling and meteorology for correcting the distribution of a modeled parameter by comparing it against the empirical distribution of observations. The methodology consists of transforming the data into the probability domain (quantiles) and reverses the transformation using the cumulative distribution function (CDF) as an operator. where and are the cumulative distribution functions of the observed and modeled data, respectively. The function for correcting data using quantile mapping is QuantileMappinBR(y_obs,y_mod), which has 2 inputs: !\"y_obs : an array with the observational data; !\"y_mod : an array with the modeled data to be corrected. The function returns an array y_cor of the same length of y_mod with the new modeled values that fits the cumulative distribution function of the observed values. To implement QM, we also use an auxiliary function ecdf to empirically compute CDF. These functions implemented in Python would look like: import numpy as np import pandas as pd import pvlib from scipy import interpolate import matplotlib.pyplot as plt yc = CDF −1 0 [CDFm(xm)], CDF0 CDFm Site Adaptation — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/site_adaptation.html 1 of 4 9/28/22, 6:04 PM Example of site adaptation In the example for the implementation of site adaptation, ground-based data for 2015 in Tamanrasset BSRN station in Algeria are used as observations and PVGIS hourly data from 2005 to 2015 are used as modeled data. Let’s query the data from those stations. First for the BSRN station: You will need to have credentials for the BSRN FTP server in order to run the query of data from a BSRN station. It is freely available under request. Check the BSRN site. Now, the PVGIS modeled data: We can now apply the QM method for site adaptation: def ecdf(x): # empirical CDF computation xs = np.sort(x) ys = np.arange(1, len(xs)+1)/float(len(xs)) return xs, ys def QuantileMappinBR(y_obs,y_mod): # Bias Removal using empirical quantile mapping y_cor = y_mod x_obs,cdf_obs = ecdf(y_obs) x_mod,cdf_mod = ecdf(y_mod) # Translate data to the quantile domain, apply the CDF operator cdf = interpolate.interp1d(x_mod,cdf_mod,kind='nearest',fill_value='extrapolate') qtile = cdf(y_mod) # Apply de CDF^-1 operator to reverse the operation to radiation domain cdfinv = interpolate.interp1d(cdf_obs,x_obs,kind='nearest',fill_value='extrapolate') y_cor = cdfinv(qtile) return y_cor BSRN credentials! # Get One year of observations of solar radiation data_obs, metadata = pvlib.iotools.get_bsrn( start = pd.Timestamp(2015,1,1), end=pd.Timestamp(2015,12,1), station ='tam', username=bsrn_username, password=bsrn_password) # Extract positive values of GHI observations ghi_obs = data_obs.ghi ghi_obs[ghi_obs<0]=0 # Resample to hourly means ghi_hr = ghi_obs.resample('60min').mean() # Get modeled data from pvgis latitude = metadata['latitude'] longitude = metadata['longitude'] # pvgis hourly data from 2005 to 2016 data_model = pvlib.iotools.get_pvgis_hourly(latitude, longitude, start=None, end=2015, raddatabase='PVGIS-SARAH', components=True, surface_tilt=0, surface_azimuth=0, outputformat='json', usehorizon=True, userhorizon=None, pvcalculation=False, peakpower=None, pvtechchoice='crystSi', mountingplace='free', loss=0, trackingtype=2, optimal_surface_tilt=False, optimalangles=False, url='https://re.jrc.ec.europa.eu/api/', map_variables=True, timeout=30) # Estimate the GHI values from the data queried dni = data_model[0].poa_direct.values diff = data_model[0].poa_sky_diffuse.values cosazen = np.cos((90-data_model[0].solar_elevation.values)*np.pi/180) ghi = dni*cosazen+diff Site Adaptation — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/site_adaptation.html 2 of 4 9/28/22, 6:04 PM We can visualize the results in a time-series: Hourly values are a great number of datapoints. Thus, we can better see the effect of site adaptation for shorter timeseries, for example: The effect of the QM technique can be observed by observing the CDF of original and adapted GHI: # Site adaptation ghi_adapted = QuantileMappinBR(ghi_hr,ghi) data_model[0]['ghi'] = ghi data_model[0]['ghi_adapted'] = ghi_adapted plt.plot(data_model[0].ghi, alpha=0.4) plt.plot(ghi_hr,color='green',linestyle='dashed', alpha=0.4) plt.plot(data_model[0].ghi_adapted, color='m', linestyle='dotted', alpha=0.4) plt.xlabel('Year') plt.ylabel('Global Horizontal Irradiance [W/m$^2$]') plt.legend(['Modeled','Observations','Adapted'], loc='lower left', framealpha=1) <matplotlib.legend.Legend at 0x7ff1aae86310> data_model[0].ghi['2015-06-22':'2015-06-27'].plot() ghi_hr['2015-06-22':'2015-06-27'].plot(color='green',linestyle='dashed') data_model[0].ghi_adapted['2015-06-22':'2015-06-27'].plot(color='m', linestyle='dotted') plt.ylabel('Global Horizontal Irradiance [W/m$^2$]') plt.xlabel('Global Horizontal Irradiance [W/m$^2$]') plt.legend(['Modeled','Observations','Adapted'], framealpha=1) <matplotlib.legend.Legend at 0x7ff1a6d49310> Site Adaptation — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/site_adaptation.html 3 of 4 9/28/22, 6:04 PM With the CDF plot we can observe that the adapted timeseries resulted from the QM site adaptation method has higher agreement with the ground-based observations than the modeled satellite-based data. Section summary This section has introduced site adaptation as a technique to adjust long-term satellite observations using short-term ground-based observations. The functions to implement site adaptation with the quantile mapping methods have been provided and an example of use has been illustrated. References Polo, J., Wilbert, S., Ruiz-Arias, J.A., Meyer, R., Gueymard, C., Súri, M., Martín, L., Mieslinger, T., Blanc, P., Grant, I., Boland, J., Ineichen, P., Remund, J., Escobar, R., Troccoli, A., Sengupta, M., Nielsen, K.P., Renne, D., Geuder, N., Cebecauer, T., 2016. Preliminary survey on site-adaptation techniques for satellite-derived and reanalysis solar radiation datasets. Solar Energy 132, 25–37. doi:10.1016/j.solener.2016.03.001 Polo, J., Fernández-Peruchena, C., Salamalikis, V., Mazorra-Aguiar, L., Turpin, M., Martín- Pomares, L., Kazantzidis, A., Blanc, P., Remund, J., 2020. Benchmarking on improvement and site-adaptation techniques for modeled solar radiation datasets. Solar Energy 201, 469–479. doi:10.1016/j.solener.2020.03.040 Fernández-Peruchena, C.M., Polo, J., Martín, L., Mazorra, L., 2020. Site-Adaptation of Modeled Solar Radiation Data : The SiteAdapt Procedure. Remote Sensing 12, 1–17. doi:10.3390/rs12132127 # Definition of variables to plot x_obs,cdf_obs = ecdf(ghi_hr) x_mod,cdf_mod = ecdf(ghi) x_adp,cdf_adp = ecdf(ghi_adapted) # Figure definition plt.figure(figsize=(8, 5)) plt.plot(x_mod,cdf_mod) plt.plot(x_obs,cdf_obs,c='g', linestyle='dashed') plt.plot(x_adp,cdf_adp,c='m', linestyle='dotted') plt.ylabel('CDF') plt.xlabel('GHI (W/m$^2$)') plt.legend(['Modeled','Observations','Adapted']) <matplotlib.legend.Legend at 0x7ff1a6b70d50> By The Assessing Solar Community © Copyright 2022. Site Adaptation — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/site_adaptation.html 4 of 4 9/28/22, 6:04 PM Glossary Contents !\"Solar radiation terms Solar radiation terms Direct Normal Irradiance (DNI) The direct or beam irradiance is the irradiance that directly from the sun, i.e., unscattered. DNI is measured with a pyrheliometer, which typically has a 5 degree opening and is mounted on a solar tracker to always point at the sun. Global horizontal irradiance (GHI) The global horizontal irradiance is the total hemispherical irradiance received on a horizontal plane. GHI is measured with a pyranometer with a 180 degree view to the sky. By The Assessing Solar Community © Copyright 2022. Glossary — Solar Resource Assessment in Python https://assessingsolar.org/notebooks/glossary.html 1 of 1 9/28/22, 6:05 PM Solar Resource for High Penetration and Large Scale Applications - IEA-PVPS The work programme of the proposed Task 16 addresses on one side scientific meteorological and climatological issues to high penetration and large scale PV in electricity networks, but also includes a strong focus on user needs and for the first time a special dissemination subTask. Dissemination and user interaction are foreseen in many different ways from workshops and webinars to paper and reports. The project requires the involvement of key players in solar resource assessment and forecasting at the scientific level (universities and research institutions) and commercial level (companies). A consortium of 53 institutions of 21 countries has been formed. This includes large science centres like DLR, NREL or Fraunhofer, universities like State Univ. of New York, Mines ParisTech or Univ. of Jaen, national weather services like DWD, BOM or DMI and data providers like Solargis, Vaisala or Meteotest. Solar Resource for High Penetration and Large Scale Applications - I... https://iea-pvps.org/research-tasks/solar-resource-for-high-penetration-a... 1 of 1 9/28/22, 6:07 PM","libVersion":"0.3.2","langs":""}