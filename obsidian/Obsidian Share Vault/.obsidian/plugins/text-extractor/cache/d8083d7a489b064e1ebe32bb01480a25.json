{"path":"lit/lit_sources.backup/Maduskar23unsuperDriftDetUDDT.pdf","text":"UDDT: An Unsupervised Drift Detection Method for Industrial Time Series Data Deepti Maduskar∗, Divyasheel Sharma∗, Chandrika KR∗, Reuben Borrison†, Gianluca Manca†, Marcel Dix† ∗Industrial Software Research, ABB Corporate Research Center, Bangalore, India †Industrial AI, ABB Corporate Research Center, Ladenburg, Germany ∗{deepti.maduskar, divya.sheel, chandrika.k-r}@in.abb.com †{reuben.borrison, gianluca.manca, marcel.dix}@de.abb.com Abstract—Industrial ML models are primarily data-driven. Therefore, one of the main focus for monitoring the model should be towards identifying the drifts in the data that might affect the performance of the model. The traditional drift detecting methods are usually based on some assumptions related to the underlying data such as no inter-dependence. However industrial sensor data typically consists of time series data, which is collected at regular intervals. Therefore, detecting drift in dependent data where the current readings depend on the previously registered readings demands a different approach. Existing solutions require either the ground truth, a fixed size, or the underlying model details. We propose an Unsupervised Drift Detection method for industrial Time series data or UDDT, a generic approach with no such pre-requisites. In our approach, we can check whether two series belong to the same model. Apart from detecting the drift in the two series, it can also provide the rationale behind the observed drift, i.e., whether the drift is due to a difference in stationarity, correlation structures, or noise distributions. We evaluate the UDDT on two datasets to demonstrate its correctness and the trust regions under various circumstances. We also establish its applicability for the real industrial setting. Keywords—Drift Detection, Distribution Shift, Time Series, Inter-dependence, Stationarity, Correlation Structure, Noise I. INTRODUCTION Machine Learning (ML) models address challenges in pro- cess industries by analyzing the process data and providing insights to the operators, enabling them to make informed decisions. Once deployed in a real plant setting, monitoring these ML models becomes crucial [19]. Situations such as changing dynamics of the data or process may lead to per- formance deterioration in these models, rendering predictions unreliable. Therefore, we need a mechanism to detect drifts and raise alerts to prevent any decisions based on them. An obvious way is to observe the model performance and flag any significant deviation as drift. However, such an approach requires ground truth in real-time, which is hardly available in the industrial setting. This calls for unsupervised approaches that are solely based on identifying the significant deviations in the underlying data. Traditional drift detecting methods are usually based on the underlying assumption of no inter-dependence in data [1], [5], [10], whereas the majority of the industrial process data is time series, i.e., time-dependent. Ignoring these underlying assumptions and directly applying the existing approaches is bound for a silent failure [3]. Therefore, detecting drift for dependent data, where the current data points depend on the previously registered data points, requires a different approach. Some drift techniques are model-specific, which restricts their generic applicability [1], [2], [11]. Hence, we propose a model-agnostic unsupervised approach, referred to as UDDT, for drift detection in industrial time series data. In the current scope of research, we focus on drift detection techniques for univariate time series data. We formulate the drift detection problem as a two-sample problem of time series, wherein we check whether the two univariate series–termed as reference and target series–come from the same data-generating models. The reference series is derived from the training data while the target series is chosen from the live data on which the model makes inferences. Additionally, our proposed approach, UDDT, provides the rationale behind the drift. Following [4], we primarily identify three reasons for differences in time series data - stationarity, correlation structures, and noise distributions. On a higher level, by performing the test for stationarity (specifically, weak stationarity [20]), we try to identify any deviations in statistical properties till the second-order moments. Further, drift can arise either due to a change in the correlation pattern in data or the noise distribution. The difference in the correlation structure might indicate that the correlations among the data points in the series have changed due to various factors such as trends, seasonality, or underlying measuring process. On the other hand, drifts due to differences in noise distribution indicate a more generic drift due to various random factors or errors. The knowledge about the reason for the drift can help choose an appropriate adaptation strategy, for example, whether a model should be retrained or fine-tuned. Our contributions follow: • We modify the two-sample testing approach from [4] and showcase its utility for detecting drift in time series. The approach is well suited for industry since it is model- agnostic and does not require real-time labels. It has a wide trust region and low execution time (Section IV). • We also utilize a collection of non-parametric and para- metric tests that support finding reasons for differences in residuals (i.e. mean, variance, outlier differences) and subsequently, for the drift (Section III).2023 IEEE 2nd Industrial Electronics Society Annual On-Line Conference (ONCON) | 979-8-3503-5797-4/23/$31.00 ©2023 IEEE | DOI: 10.1109/ONCON60463.2023.10431133 Authorized licensed use limited to: ABB - Poland. Downloaded on April 02,2024 at 11:20:09 UTC from IEEE Xplore. Restrictions apply. The rest of the paper is organized as follows: In section II, we present a literature survey on the existing drift detection techniques. Section III presents the proposed approach for drift detection. Section IV describes the datasets and the evaluation results. Section V concludes the paper while providing an outlook towards further research directions. II. RELATED WORK Data drift detection is a broad area of research with rich literature. [5], [14], [15] use supervised drift detection techniques, which are based on monitoring the deviations in the predictive error of the models. Majorly, the workflow revolves around comparing the performance of the model on the reference windows and the current window. As soon as the performance degrades beyond a certain threshold, drift is identified and the reference window is updated accordingly. [2] proposed a novel technique using the collective intelligence of Particle Swarm Optimization (PSO) for monitoring errors of several time series forecasting models generated by the swarm intelligence. However, these techniques require real- time ground truth target values, which are non-viable in the industrial context. Therefore, to overcome this challenge, we focus on the unsupervised techniques. Several unsupervised techniques have been proposed in the literature. [6] comprehensively surveys drift detection approaches for classification problems such as UDetect [18]. However, model-agnostic techniques are more generic and hence, preferable in industrial use cases. While detection is the focus, some approaches directly handle the drift situation based on the underlying model. For example, [11] proposes a drift-handling method for Global Forecasting Models (GFMs). They use the weighted average of two forecasting models, one trained on current data and the other trained on complete data, to provide the final prediction. [10] argues that the presence of concept drift implies temporal dependence. Instead of monitoring the error, they continuously update the model using bias-variance analysis and derived gradient descent approaches. Even supervised techniques such as ADWIN [5] can be ap- plied in the unsupervised context. However, a major drawback is the assumption of independent and identical distribution (i.i.d data) [5], [1]. Since the time series data is usually depen- dent data, such techniques become irrelevant. [1] formulated the problem of temporal segmentation of egocentric videos as a drift detection in a time-dependent sequence of frames. They suggested a simple heuristic of jump factor to tackle the dependence problem, wherein sub-optimal non-related windows of frames were created which have a correlation below a threshold. [9] proposed an Unsupervised Temporal Drift Detector (UTDD) to detect unknown and non-linear relations by comparing the z-scores of the residuals of a Boosted Embedding model on reference and target data while also accounting for seasonalities and cycles. A number of statistical tests such as the Kolmogorov- Smirnov test [16], and chi-squared test [3] are also commonly used for detecting distribution shift. These tests compare the Fig. 1. Sequential approach for drift detection for time series data distributions of two samples of data. Though a number of these tests are non-parametric, they are meant to compare i.i.d. data. Most of the related research has pre-requisites such as large sample size, same length of time series and assumed noise distribution. UDDT has no such pre-requisites and focuses on practical applicability in industrial setting. III. PROPOSED APPROACH This section describes our proposed approach, UDDT, to detect the drift in correlated time series data. Since time series data has complex patterns that can be difficult to capture using a single statistical test, the proposed approach uses a combination of tests to provide a more comprehensive assessment. The procedure involves only checks on data properties, statistical tests and comparisons of changes in related patterns of correlations between time series, making it widely applicable for various time series situations. Figure 1 depicts the three key steps of the approach, where each step investigates a particular reason for drift. Similar to the approach mentioned in [4], UDDT consists of sequential steps where we first check stationarity, then correlation structures, and then, at last, noise distributions. If we detect drift at any step, we stop the flow and do not proceed to subsequent steps. If all the steps are processed, we conclude there is no drift. In the step 1, we identify difference due to stationarity. For the approach to be practically viable, we consider weak stationarity [20] that checks till the second-order moments. We use the Augmented Dickey-Fuller(ADF) test which checks for the presence of unit root with test statistic as in equation 1. ˆt ˆΦ=1 = ˆΦ − 1 SE( ˆΦ) (1) where Φ = ∑p i=1 ϕi, is the least-squares estimator, ϕ are the coefficients of an AR(p) model and SE(Φ) is the standard error of the estimator. If one series is stationary and the other is non-stationary, it clearly indicates the difference in the underlying data generat- ing models and therefore, provides the basis for drift. If both are stationary, then we proceed to the next step. In case both are non-stationary, then the difference in their type of non- stationarity needs to be checked. We do this by comparing the transformations carried out to make them stationary. If these Authorized licensed use limited to: ABB - Poland. Downloaded on April 02,2024 at 11:20:09 UTC from IEEE Xplore. Restrictions apply. are not the same, we can conclude that drift is due to the difference in stationarity of the models else proceed to step 2. Note that hereafter series will imply the stationary series transformed or retrieved from step 1. The step 2 is to check the similarity in correlation structures of the time series through the approach proposed in [7], [8]. We use an AutoRegressive (AR) model [20] since it efficiently captures the correlation structure by covering the contribution of all the significant lags. The basic idea is to compare the Partial Autocorrelation Functions (PACF) signatures of the residuals, generalised by equation 2. Since residuals are i.i.d with zero mean and σ standard deviation, PACFs of the residuals will have a normal distribution with variance = 1/(n − s) and their square will have a chi-squared distribution. Hence, we can measure the goodness of fit to find out similarities in the correlation structures as in [7]. P ACF (yi, yi−k) = Cov(yi, y(i−k)|y(i−1), ..y(i−k+1)) σyi|y(i−1),...y(i−k+1)σyi−k|y(i−1),...y(i−k+1) (2) where k is the lag. The steps for comparing the correlation structures are men- tioned as follows: • Combine both the series and fit an AR(p) model on the combined data. • Then compute the PACFs of the residuals of each series, vs,v′ s separately • Calculate the χ2 statistic as per the equation 3: χ 2 (p) = ∑p s=1(vs − v′ s) 2/1/(n − s) + 1/(m − s) (3) The goal is to measure the difference in the PACFs of the two series at each lag. Therefore, an upper-tailed chi-square statistic is used as an approximate measure for quantifying the deviation of PACFs at each lag. Having chosen the significance level as 0.05, we compare the calculated χ2 (p) with the χ 2 0.05,p and if it is greater, we conclude a drift due to the difference in correlation structure, else we proceed to the step 3. After having eliminated the drift due to differences in stationarity and correlation structures, we identify differences in the noise distributions in the step 3. For this, we compare the differences in the residual signatures of the individual series as obtained from the AR model fitted in step 2. Considering the residuals to be i.i.d, rather than using the test mentioned in [4], we approached the problem from another perspective. We proposed a method, which combines the parametric and non-parametric tests based on the situation and provides an in- depth analysis of the differences. The system of tests uses a two-sample Kolmogorov-Smirnov (KS) test when at least one of the sample sizes is more than 1000. The power of the KS- test reduces when the size of the samples is small. Hence, for the sample sizes smaller than 1000, we use relevant parametric tests to compare the distributions of the data series. If the system is unsure about the comparison, then we use the KS- test along with two supportive heuristics that estimate outliers and the kurtosis of the distribution samples, respectively. The heuristics try to cover the weakness of the KS-test, which is not Fig. 2. Proposed flow of UDDT sensitive enough towards the presence of outliers and kurtosis. The complete flow of UDDT is summarized in figure 2. IV. EVALUATION For the purpose of evaluating the correctness and industrial applicability of UDDT, we have considered two datasets. One is the synthetic dataset created to showcase the correctness and trust regions of the UDDT whereas the second dataset is an industrial benchmark dataset closer to the real process scenarios. All the experiments were run on a computer with an Intel i5-1245U processor running at 1.60 GHz using 16 GB of RAM, running Windows version 10 Enterprise. A. Evaluation on synthetic dataset We generated a synthetic time series from the stationary model M of the form as in equation 4: M : Xt = aXt−1 + et (4) where, Xt and Xt−1 are data points at time t and t − 1 respectively, a is the correlation coefficient, and et is the error. Using this, we created 4 datasets, wherein each dataset consists of two time series, one being the reference series and the other being the target series. As shown in table I, datasets B and C have different correlation coefficients (i.e. different a values) whereas datasets A and D have different noise distributions (i.e. different distributions for et) in their reference and target series. Considering the industrial perspective, we chose the following three evaluation metrics: • Correctness: The result of UDDT exactly matches with the ground truth • Trust region for different sample sizes: Correctness of UDDT for different sample sizes of reference and target series. Authorized licensed use limited to: ABB - Poland. Downloaded on April 02,2024 at 11:20:09 UTC from IEEE Xplore. Restrictions apply. TABLE I ANALYSIS OF UDDT RESULTS ON SYNTHETIC DATASET IN COMPARISON WITH GROUND TRUTH Dataset name Type of Drift induced (Ground truth) UDDT Result A Noise Noise B Correlation-structure Correlation-structure C Correlation-structure Correlation-structure D Noise Noise Fig. 3. Autocorrelation plot comparison between reference and target series of synthetic dataset • Execution time: Total time taken for UDDT to run 1) Evaluation for Correctness Since all the models are stationary, no drift will be identified in the first step and hence, we proceed towards the second step. The results of UDDT on the datasets are summarized in Table I. The differences in the correlation structures in B and C Fig. 4. Visualization of datasets with drift in noise distributions (Black represents the reference series and red represents the target series) TABLE II RESULTS FOR SYSTEM OF TESTS Dataset A Dataset D Possible rea- son for drift Mean-shift Different kurtosis (4.001), difference in proportion of outliers (5%) as highlighted in figure 3 are caught in the second step, which establishes that UDDT is correctly able to catch the drift due to differences in correlation structures. As can be seen in figure 3, there is no significant difference in ACF signatures in datasets A and D. Thus, the differences in the noise distributions in A and D, as visualized in figure 4, are caught in the third step, which establishes that the UDDT is correctly able to catch the drift due to differences in noise distribution as well. Further, Table II summarizes the details of the result obtained from running the system of tests on the datasets A and D to compare their residual signatures. In addition to the possible reasons, it also quantifies the differences in case of changes in kurtosis and outliers. For example, in dataset D, there is a large difference in kurtosis as well as the proportion of outliers reference and target series, which implies the target residual distribution is heavy-tailed. 2) Evaluation for different Sample Sizes The size of the reference and the target series varies depend- ing on the use case, and the power of different statistical tests varies depending on the size. Mostly the trust region spreads across the average sample size and becomes weak for larger and/or smaller sample sizes. The larger the trust region, the better the coverage of the test enabling applicability on most of the use cases. We consider smaller sample sizes to be around 50-100 data points and larger sample sizes to be more than 1000 data points. Hence, we experiment with sample sizes varying from 55 to 10000 data points. The results of the experiment are summarized in Table III. The rows and the columns represent the sample sizes of TABLE III EVALUATION OF UDDT ON DIFFERENT SAMPLE SIZES 55 100 500 1000 5000 10000 55 2 2 2 2 2 2 100 2 4 4 4 4 4 500 2 4 4 4 4 4 1000 2 4 4 4 4 4 5000 2 4 4 3 3 3 10000 2 4 4 3 3 3 Authorized licensed use limited to: ABB - Poland. Downloaded on April 02,2024 at 11:20:09 UTC from IEEE Xplore. Restrictions apply. TABLE IV EVALUATION OF UDDT ON EXECUTION TIME (IN SECONDS) 55 100 500 1000 5000 10000 55 0.344896 0.362897 0.808149 1.119582 2.486679 5.440422 100 0.307729 0.325326 0.718811 1.154857 2.373379 4.601704 500 0.704909 0.687438 0.874905 1.064867 2.59976 4.64605 1000 0.977714 0.9771 1.085395 1.299929 2.710102 4.979103 5000 2.376864 2.408726 2.512743 2.674307 4.259046 6.872771 10000 4.737489 4.566537 4.242142 4.87535 6.598625 8.636608 reference series and target series respectively. The numeric value at ith row and jth column represent the number of correct drift identifications. In our case, this value can range between zero to four, where four represents that the drift is correctly identified in all 4 datasets. As shown, the trust region of the UDDT spreads across average sample sizes, whereas it weakens for boundary conditions like very small and large sample sizes. 3) Evaluation for Execution time Drift detection happens in real time once the live data is available and before the model gives the prediction. Hence, we consider execution time as one of the evaluation criteria for UDDT. A shorter execution time is preferred. The execution time, as shown in table IV, is measured for different combinations of sample sizes of the two series. The rows and the columns represent the sample sizes of the reference and target series respectively. The numeric value at i th row and jth column represent the execution time for a single run of UDDT. As inferred from table IV, the execution time varies between 0.3 seconds to 8.6 seconds with an average of 3-4 seconds, which is reasonable. B. Evaluation on Tennessee-Eastman Process dataset Tennessee-Eastman Process (TEP) is a simulated model of an industrial chemical process suitable for plant control prob- lems [12]. The focus is majorly on the 5 components namely a two-phase Reactor, Condenser, Separator, Compressor, and Stripper. The reactions are exothermic involving 4 gaseous reactants A, D, E and C, and 2 liquid outputs G, H along with 1 inert component B and 1 byproduct F. The normal process can be described as follows: The exothermic reaction involving A, D and E takes place in the reactor. The output stream is then passed through a condenser. The cooled stream is passed through the separator to separate the gas and liquid components. The non-condensed gas stream is passed back into the reactor through the compressor whereas condensed components move to the product stripping column to remove remaining reactants. Purge, being an essential part of the control system for managing the critical reactor pres- sure, removes the inert and the by-products from the system. This process involves 41 measurements and 12 manipulated variables. For testing and evaluation purposes, 20 process disturbances are provided. For our evaluation purpose, we chose IDV13 drift type disturbance, which is related to the change of the reaction kinetics. We simulated the TEP model using MATLAB 1, proposed 1https://depts.washington.edu/control/LARRY/TE/download.html TABLE V ANALYSIS OF UDDT RESULTS ON TEP DATASET IN COMPARISON WITH GROUND TRUTH Variable Description Ground Truth ob- servations UDDT result on Dataset 1 UDDT result on Dataset 2 XMEAS7 Reactor pressure High impact Correlation Structure Correlation Structure XMEAS4 A and C feed Indirect im- pact No drift Correlation Structure XMEAS19 Stripper steam flow No impact No drift No drift XMEAS24 Reactor feed in B Indirect im- pact Noise Noise in [17]. It provides 73 signal values (sensor readings) with sampling rate of 1 minute. Each simulation run, i.e. test was simulated for 1000 hours and contains 60,000 values per signal. For evaluation, we chose four process variables- XMEAS7, XMEAS4, XMEAS19 and XMEAS24, each impacted differ- ently by the disturbance. Dataset 1 is created with an increase in disturbance scaling from 10% to 15% and dataset 2 is created with an increase in disturbance scaling from 10% to 100%. The first 3000 data points are considered as reference series and the remaining 30000 data points are the target series. The visualization of the variables is shown in figure 5. The dataset description, ground truth and the results of UDDT are summarized in the table V. IDV13 causes changes in the reaction kinetics that further cause rapid accumulation or depletion of gas [12], [13]. Thus, one of the most directly and highly affected variables is the reactor pressure, i.e. XMEAS7. Results from UDDT also indicate the drift in correlation structures of both the series. The inlet flow is affected by the liquid level in the reactor via a control loop, i.e., the liquid level in the reactor directly affects the setpoint for the flow control that controls the valve corresponding to XMEAS4. The constantly changing reaction kinetics affect the accumulation of liquid in the reactor and thus, the reactor liquid level. However, this impact is less and indirect compared to the reactor pressure. This fact can be seen in the UDDT results, wherein drift is observed only in case of high disturbance scaling (i.e. in the case of dataset 2). Due to changes in the reaction kinetic, XMEAS24 is highly affected by inert gas B being accumulated and consumed in the reactor (this changes rapidly between the two states, i.e., the increased accumulation and the increased consumption of B in the reactor because the changes in reaction kinetics are also volatile). The reason for that is the feedback from the reactor outlet via the separator and compressor back to the reactor. We see results from UDDT also indicate drift due to noise. However, the induced disturbance does not impact the stripper steam flow, i.e. XMEAS19, since the steam valve remains zero. Thus, it remains constant throughout, irrespective of any disturbance percentage, also indicated in the UDDT results. Therefore, the results on TEP datasets demonstrate that our drift detection method successfully identifies all drifts, as shown in the ground truth in table V. This determination is Authorized licensed use limited to: ABB - Poland. Downloaded on April 02,2024 at 11:20:09 UTC from IEEE Xplore. Restrictions apply. Fig. 5. Visualization of the process variables of TEP dataset (The left and right plot corresponds to dataset 1 and dataset 2 respectively) based on a comprehensive manual analysis of the assessed disturbance scenarios and the chosen process variables, as described earlier. V. DISCUSSION AND CONCLUSION In this paper, we address the problem of detecting drift in time-dependent industrial data. We proposed a generic and viable approach, UDDT, that requires no real-time ground truth, underlying model details and/or fixed sample sizes. We demonstrated that UDDT identifies the drift correctly and provides the rationale behind it. Further, we evaluated it on two datasets, one created synthetically and the other simulated from an industrial benchmark process. The results demonstrate wide trust regions with respect to different sample sizes. Hence, UDDT is suitable for industrial use cases. In the future, we plan to extend the proposed drift detection approach for multivariate time series data. REFERENCES [1] Nagar, Pravin, Mansi Khemka, and Chetan Arora. ”Concept drift detec- tion for multivariate data streams and temporal segmentation of daylong egocentric videos.” In Proceedings of the 28th ACM International Conference on Multimedia, pp. 1065-1074. 2020. [2] Oliveira, Gustavo HFM, Rodolfo C. Cavalcante, George G. Cabral, Leandro L. Minku, and Adriano LI Oliveira. ”Time series forecasting in the presence of concept drift: A pso-based approach.” In 2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI), pp. 239-246. IEEE, 2017. [3] Rabanser, Stephan, Stephan G¨unnemann, and Zachary Lipton. ”Failing loudly: An empirical study of methods for detecting dataset shift.” Advances in Neural Information Processing Systems 32 (2019). [4] Alzahrani, Abeer. ”On Two-Sample Tests For Time Series.” PhD diss., Concordia University, 2017. [5] Bifet, Albert, and Ricard Gavalda. ”Learning from time-changing data with adaptive windowing.” In Proceedings of the 2007 SIAM interna- tional conference on data mining, pp. 443-448. Society for Industrial and Applied Mathematics, 2007. [6] Gemaque, Rosana Noronha, Albert Franc¸a Josu´a Costa, Rafael Giusti, and Eulanda Miranda Dos Santos. ”An overview of unsupervised drift detection methods.” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 10, no. 6 (2020): e1381. [7] Quenouille, M. H. ”The comparison of correlations in time-series.” Journal of the Royal Statistical Society: Series B (Methodological) 20, no. 1 (1958): 158-164. [8] Persons, Warren M. ”Correlation of time series.” Journal of the American Statistical Association 18, no. 142 (1923): 713-726. [9] Ramanan, Nandini, Rasool Tahmasbi, Marjorie Sayer, Deokwoo Jung, Shalini Hemachandran, and Claudionor Nunes Coelho Jr. ”Real-time drift detection on time-series data.” arXiv preprint arXiv:2110.06383 (2021). [10] Read, Jesse. ”Concept-drifting data streams are time series; the case for continuous adaptation.” arXiv preprint arXiv:1810.02266 (2018). [11] Liu, Ziyi, Rakshitha Godahewa, Kasun Bandara, and Christoph Bergmeir. ”Handling Concept Drift in Global Time Series Forecasting.” arXiv preprint arXiv:2304.01512 (2023). [12] Downs, J., and E. Vogel. ”A plant-wide industrial process problem control.” Comput Chem Eng 17, no. 3 (1993): 245-255. [13] Ricker, N. Lawrence. ”Decentralized control of the Tennessee Eastman challenge process.” Journal of process control 6, no. 4 (1996): 205-221. [14] Gama, Joao, Pedro Medas, Gladys Castillo, and Pedro Rodrigues. ”Learning with drift detection.” In Advances in Artificial Intelli- gence–SBIA 2004: 17th Brazilian Symposium on Artificial Intelligence, Sao Luis, Maranhao, Brazil, September 29-Ocotber 1, 2004. Proceedings 17, pp. 286-295. Springer Berlin Heidelberg, 2004. [15] Baena-Garcıa, Manuel, Jos´e del Campo- ´Avila, Raul Fidalgo, Albert Bifet, Ricard Gavalda, and Rafael Morales-Bueno. ”Early drift detection method.” In Fourth international workshop on knowledge discovery from data streams, vol. 6, pp. 77-86. 2006. [16] Massey Jr, Frank J. ”The Kolmogorov-Smirnov test for goodness of fit.” Journal of the American statistical Association 46, no. 253 (1951): 68-78. [17] Bathelt, Andreas, N. Lawrence Ricker, and Mohieddine Jelali. ”Revision of the Tennessee Eastman process model.” IFAC-PapersOnLine 48, no. 8 (2015): 309-314. [18] Bashir, Sulaimon Adebayo, Andrei Petrovski, and Daniel Doolan. ”A framework for unsupervised change detection in activity recognition.” International journal of pervasive computing and communications 13, no. 2 (2017): 157-175. [19] Dix, Marcel, Gianluca Manca, Kenneth Chigozie Okafor, Reuben Bor- rison, Konstantin Kirchheim, Divyasheel Sharma, Kr Chandrika, Deepti Maduskar, and Frank Ortmeier. ”Measuring the Robustness of ML Models Against Data Quality Issues in Industrial Time Series Data.” In 2023 IEEE 21st International Conference on Industrial Informatics (INDIN), pp. 1-8. IEEE, 2023. [20] Brockwell, Peter J., and Richard A. Davis, eds. Introduction to time series and forecasting. New York, NY: Springer New York, 2002. Authorized licensed use limited to: ABB - Poland. Downloaded on April 02,2024 at 11:20:09 UTC from IEEE Xplore. Restrictions apply.","libVersion":"0.3.2","langs":""}