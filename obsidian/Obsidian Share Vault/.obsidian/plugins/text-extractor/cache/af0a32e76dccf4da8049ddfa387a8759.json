{"path":"lit/lit_notes_OLD_PARTIAL/Huang24adaptTrajUncertDistShift.pdf","text":"Adaptive Uncertainty Quantification for Trajectory Prediction Under Distributional Shift Huiqun Huang 1âˆ— , Sihong He 1 , Fei Miao 1 1University of Connecticut {huiqun.huang, sihong.he, fei.miao}@uconn.edu Abstract Trajectory prediction models that can infer both finite future trajectories and their associated un- certainties of the target vehicles in an online set- ting (e.g., real-world application scenarios) is cru- cial for ensuring the safe and robust navigation and path planning of autonomous vehicle motion. However, the majority of existing trajectory pre- diction models have neither considered reducing the uncertainty as one objective during the training stage nor provided reliable uncertainty quantifica- tion during inference stage under potential distri- bution shift. Therefore, in this paper, we propose the Conformal Uncertainty Quantification under Distribution Shift framework, CUQDS, to quantify the uncertainty of the predicted trajectories of ex- isting trajectory prediction models under potential data distribution shift, while considering improving the prediction accuracy of the models and reducing the estimated uncertainty during the training stage. Specifically, CUQDS includes 1) a learning-based Gaussian process regression module that models the output distribution of the base model (any exist- ing trajectory prediction or time series forecasting neural networks) and reduces the estimated uncer- tainty by additional loss term, and 2) a statistical- based Conformal P control module to calibrate the estimated uncertainty from the Gaussian process regression module in an online setting under poten- tial distribution shift between training and testing data. Experimental results on various state-of-the- art methods using benchmark motion forecasting datasets demonstrate the effectiveness of our pro- posed design. 1 Introduction Accurately and efficiently predicting the future trajectories of the target vehicles is pivotal for ensuring the safety of path planning and navigation of autonomous systems in dynamic environments [Hu et al., 2023; Kedia et al., 2023]. However, âˆ—Contact Author trajectory uncertainly due to the changing external surround- ing environments (e.g., road networks, neighborhood vehi- cles, passengers, and so on) or intrinsic intention changes of drivers, can lead to both trajectory distribution shift that change over time and overconfidence in the output of tra- jectory prediction models. It remains challenging to predict the distribution of the future trajectories of the target vehicles (rather than focusing solely on point estimates), and to quan- tify the uncertainty of the output trajectories under potential distribution shift between training ans testing data. Various uncertainty quantification methods have been pro- posed for trajectory prediction. One popular approach is to estimate the distribution (e.g., Laplace distribution or Gaus- sian distribution) of future trajectories of target vehicles by di- rect modeling methods [Zhou et al., 2022; Mao et al., 2023; Zhu et al., 2023; Salzmann et al., 2020; Chen et al., 2023; Tang et al., 2021]. However, this method often overlooks the impact of model limitation (the restricted ability of mod- els to represent the real-time trajectories data) and the con- sequence overconfident uncertainty estimation in the infer- ence stage. Another popular approach is to calibrate the preliminary estimated uncertainty in the inference stage by the statistical-based methods. Specifically, methods such as split conformal prediction (CP) [Shafer and Vovk, 2008; Lindemann et al., 2023; Lekeufack et al., 2023] provide con- fidence intervals that guarantee to contain the ground truth target data with a predefined probability. However, they are not applicable to the situations when there is distribution shift between the training and testing data. In this paper, we propose CUQDS, i.e., Conformal Uncertainty Quantification under Distribution Shift frame- work, to quantify the output uncertainty of existing trajec- tory prediction models under distribution shift, while improv- ing the prediction accuracy of the models and reducing the estimated uncertainty during the training stage. The pro- posed CUQDS framework integrates a learning-based Gaus- sian process regression [Rasmussen et al., 2006] module with a statistics-based conformal P control module [Angelopoulos et al., 2023]. Specifically, in the training stage, CUQDS adopts the Gaussian process regression module to estimate the output distribution of base model. The variance of the output distri- bution quantifies the uncertainty of the predicted trajectories. We further use the output distribution to construct uncertainty interval that guarantees to cover the true target trajectory witharXiv:2406.12100v1 [cs.LG] 17 Jun 2024 Ground truth trajectory Predicted trajectory Uncertainty interval B A Figure 1: Illustration of the importance of a good uncertainty inter- val estimation for the predicted trajectories of the target vehicles. a predefined probability in the long-run. As shown in Fig. 1, a good uncertainty interval should tend to be narrow when the predicted trajectory closely aligns with the ground truth tra- jectory (e.g., vehicle A), whereas it should be widen when the output trajectory deviates (e.g., vehicle B). To achieve this, we introduce additional loss term to reduce the estimated un- certainty in the training stage, ensuring narrow uncertainty interval while covering the true target trajectory with a pre- defined probability. In the testing or inference stage, CUQDS calibrates the estimated output uncertainty from the Gaussian process regression module upon potential distribution shift by a statistics-based conformal P control module. Different from standard conformal prediction method and its variants who use fixed conformal quantile in the inference stage and violate the distribution shift assumption, we first initialize the conformal quantile using the validation data and update it af- ter every prediction step during the inference stage. The key contributions of this work are summarized as fol- lows: 1. We propose CUQDS framework that integrates both the learning-based and statistical-based modules to provide uncertainty quantification for time series trajectory pre- diction under distribution shift. The proposed learning- based module is trained alongside the base model to quantify its output uncertainty. In the training stage, the main objectives are to enhance prediction accuracy of base model and reduce the estimated uncertainty by in- corporating an additional loss term. 2. We introduce the statistical-based conformal P control module to calibrate the estimated output uncertainty from the learning-based module under potential distri- bution shift during the inference stage. To alleviate the impacts of data distribution shift on uncertainty estima- tion, the conformal quantile is first initialized using the validation data and keep updating after each prediction step in the inference stage. 3. We validate the effectiveness of our proposed framework on the Argoverse 1 motion forecasting dataset [Chang et al., 2019] and five state-of-the-art baselines. Compared to base models without our CUQDS, the experiment re- sults show that our approach improves prediction accu- racy by an average of 7.07% and reduce uncertainty of predicted trajectory by an average of 25.41% through in- corporation with our CUQDS. 2 Related Work Modeling the distribution of the trajectory of the target ve- hicles, instead of solely focusing on the point estimation of the future trajectory, proves to be an efficient approach [Chai et al., 2019; Deo and Trivedi, 2018; Phan-Minh et al., 2020; Zeng et al., 2021] to avoid missing potential behavior in trajectory prediction methods. Early works sample multi- ple potential future trajectories [Liang et al., 2020; Ngiam et al., 2021; Gupta et al., 2018; Rhinehart et al., 2018; Rhine- hart et al., 2019; Tang and Salakhutdinov, 2019] to approx- imate the predicted trajectory distribution. However, these approaches still rely on limited point estimation and suffer from overconfidence upon trajectory prediction in real-world settings. To mitigate these issues, recent works directly esti- mate the distribution of future trajectories by fitting the (mix- ture) distribution models based on the embedded features of input trajectories [Zhou et al., 2022; Varadarajan et al., 2022; Cui et al., 2019; Shi et al., 2023]. However, these works mostly train the (mixture) distribution models by the MLP- based predictor in the last layer of the model. Such designs fail to estimate an accurate enough distribution of future tra- jectories under data distribution shift. Uncertainty quantification in trajectory prediction is challenging and usually solved by two categories of meth- ods: direct modeling and statistical-based methods. Specif- ically, direct modeling assumes the target data follows spe- cific distribution, designs the learning-based neural networks for distribution estimation, and introduces the corresponding loss function to model the uncertainty directly. To achieve this, existing works usually assume the data follows Gaussian distribution [Mao et al., 2023] or Laplace distribution [Gu et al., 2024] and model the corresponding distribution by learning-based designs. However, estimating rigorous uncer- tainty by direct modeling can be challenging, as the model may easily overfit the training dataset such that invalid in the inference stage under data distribution shift. Conformal pre- diction [Shafer and Vovk, 2008; Angelopoulos et al., 2023] stands out as a method in statistical-based inference that has proven effective in constructing predictive sets, ensuring a certain probability of covering the true target values [Ivanovic et al., 2022; Xu et al., 2014]. However, the assumption of identical distribution across all datasets invalidates the stan- dard conformal prediction under distribution shift. Conse- quently, this necessitates modifications [Xu and Xie, 2023] in conformal prediction to enable timely calibration of model outputs when confronted with distribution shift. In this study, we propose the CUQDS framework to provide output distribution for the predicted trajectories of base model under distribution shift, while improving the prediction accu- racy of base model and reducing the estimated uncertainty by introducing additional loss term. In particular, CUQDS adopts Input trajectory ï¿½ğ‘¥ğ‘¥ ğ‘“ğ‘“ğœƒğœƒ ï¿½ğ‘¥ğ‘¥ Calibrated uncertainty interval ğ‘“ğ‘“ğœƒğœƒ ï¿½ğ‘¥ğ‘¥ âˆ’ ï¿½ğ‘ğ‘ğ‘¡ğ‘¡ ï¿½ğœğœ ï¿½ğ‘¥ğ‘¥ , ğ‘“ğ‘“ğœƒğœƒ ï¿½ğ‘¥ğ‘¥ + ï¿½ğ‘ğ‘ğ‘¡ğ‘¡ ï¿½ğœğœ ï¿½ğ‘¥ğ‘¥ Output trajectory ğ‘“ğ‘“ğœƒğœƒ ï¿½ğ‘¥ğ‘¥ Calibrated uncertainty intervalHistorical trajectory ï¿½ğ‘¥ğ‘¥ Base Model ğ‘“ğ‘“ğœƒğœƒ GPR Module UC Module ğ‘ğ‘ ğ‘“ğ‘“ğœƒğœƒ ï¿½ğ‘¥ğ‘¥ , ï¿½ğœğœ2 ï¿½ğ‘¥ğ‘¥ CUQDS Framework Output trajectory ğ‘“ğ‘“ğœƒğœƒ ï¿½ğ‘¥ğ‘¥ Figure 2: Our CUQDS models the conditional output distribution ËœY |Ëœx, D âˆ¼ N ( fÎ¸ (Ëœx) , ËœÏƒ2 (Ëœx)) of base model fÎ¸ by the Gaussian process regression (GPR) module, and provides the correspond calibrated uncertainty interval [fÎ¸ (Ëœx) âˆ’ Ë†qt ËœÏƒ (Ëœx) , fÎ¸ (Ëœx) + Ë†qt ËœÏƒ (Ëœx)] for the predicted trajectories by the uncertainty calibration (UC) module. a Gaussian process regression module to estimate the out- put uncertainty of base model, then utilizes a statistical-based conformal P control module to calibrate this output uncer- tainty by taking into account the model performance on recent trajectory data. Moreover, different from standard conformal prediction methods who use the fixed conformal quantile in the inference stage, we first initialize the conformal quantile using the validation data and update it after every prediction in the inference stage to alleviate the data distribution shift problem. 3 Methodology 3.1 Problem Formulation Suppose we have a training dataset D1 = {(xi, yi)} N1 i=1 = {(xt, yt)} T1 t=Lâˆ’1, a validation dataset D2 = {(xi, yi)} N2 i=1 = {(xt, yt)} T2 t=Lâˆ’1, and a testing dataset ËœD = {(Ëœxi, Ëœyi)} N3 i=1 = {(Ëœxt, Ëœyt)} T3 t=Lâˆ’1. N1, N2, and N3 are the number of data samples, and T1, T2, and T3 are the time periods of each dataset. T1 â‹‚ T2 â‹‚ T3 = âˆ…. As shown above, we use two ways to represent each dataset, where (xi, yi) (or (Ëœxi, Ëœyi)) denotes the random input-output trajectory pair within each dataset indexed by i, and (xt, yt) (or (Ëœxt, Ëœyt)) is time series data and represents the input-output trajectory pair of the cur- rent time step t. Both xi and xt denote the input historical trajectory during the past L historical time steps and are sam- pled from domain X âˆˆ RLÃ—D, and yi and yt denote the cor- responding target trajectory during the J following time steps from domain Y âˆˆ RJÃ—D. D is the dimension of target fea- tures. We will omit the index i or t when there is no conflict. We assume that we have a time series trajectory predic- tion model f with parameters Î¸. We call this model fÎ¸ a base model and it can be implemented as different struc- tures of neural network [Zhou et al., 2022; Liu et al., 2021; Zhou et al., 2023; Liang et al., 2020; Zhong et al., 2022]. The model fÎ¸ is trained using the dataset D, where the tar- get trajectory, denoted as Y , is conditioned on input x and the dataset D. We model the conditional distribution of Y given x and D as a Gaussian distribution, where Y |x, D âˆ¼ N (Âµ(x), Ïƒ2(x)). In this formulation, Âµ(x) and Ïƒ2(x) are functions that map the input x to the mean and variance of the Gaussian distribution, respectively. We treat the predicted trajectory of the base model fÎ¸ as the mean Âµ(x) directly. Our main task in this study is to estimate the variance Ïƒ2(x) to denote the output uncertainty. We propose the Conformal Uncertainty Quantification framework, CUQDS, as illustrated in Fig. 2, to quantify the uncertainty of the predicted trajectory of base model under potential distribution shift. The main objectives of this frame- work are to improve prediction accuracy of base model and reduce the output uncertainty. The framework introduces two modules, 1) In particular, in the training and validation stages ( Alg. 1), we propose a learning-based Gaussian process re- gression module to approximate the conditional output dis- tribution (Y |x, D) of base model by estimating (Y |x, Î¸ âˆ¼ N (Ë†Âµ (x) , Ë†Ïƒ2 (x))) based on fÎ¸. The details are introduced in Sec. 3.2. 2) In the testing or inference stage (Algorithm. 2), we propose a statistical-based conformal P control module to calibrate the output distribution ËœY |Ëœx, Î¸ âˆ¼ N (ËœÂµ (Ëœx) , ËœÏƒ2 (Ëœx)) by considering the potential distribution shift between the training and testing datasets and the performance limitation of fÎ¸ on current time series trajectory input. The conformal quantile of the module is first initialized using the validation data and keep updating after each prediction during the in- ference stage. We build the calibrated uncertainty interval and ensure it covers the true target trajectory with a prede- fined probability in long-run. The details are introduced in Sec. 3.3. To summarize, during training and validation stage, our goal is to find the parameters [Î¸, Ï‰] such that minimizing the loss function L on training data: [Î¸, Ï‰] = arg min Î¸,Ï‰ L (Î¸, Ï‰|D) . (1) The loss L is a weighted combination of base modelâ€™ loss L1(Î¸) and Gaussian processing regression modelâ€™s loss L2(Ï‰, Î¸). L = w1L1(Î¸) + w2L2(Ï‰, Î¸), (2) where w1 âˆˆ R and w2 âˆˆ R are the weights adjusting the influence of two loss terms, respectively. During testing or inference stage, we will calibrate the covariance and estimate the uncertainty interval of the predicted trajectory. 3.2 Gaussian Process Regression Module Existing literature of trajectory prediction models [Zhou et al., 2022; Zhou et al., 2023; Liang et al., 2020; Zhong et al., 2022] focuses on providing point estimates of future trajecto- ries. However, the uncertainty of the future trajectories due to the changing environment or the intrinsic intention changes of drivers can lead to significant distribution shift and over- confident trajectory prediction. Such distribution shift and overconfident prediction can greatly impact the subsequent decision-making processes, such as robust path planning [Hu et al., 2023; Kedia et al., 2023]. Hence, we propose to con- sider output uncertainties from both the prediction capability limitation of the model fÎ¸ upon current trajectory inputs and the noise inherent in the trajectory data. Algorithm 1: Training & validation stage Input: a base model f (Â·) with an initialized parameter Î¸ and a covariance function k(Â·) with an initialized parameter Ï‰, error rate Î± âˆˆ [0, 1], score function s(Â·), total number of training epochs epo. Data: training dataset D1 = {xi, yi}N1 i=1, validation dataset D2 = {xt, yt} T2 t=1. Output: well-trained base model fÎ¸(Â·), updated statistic Ë†q1, score set S = {s (xt, yt)} T2 t=Lâˆ’1 and error set E = {et}T2 t=Lâˆ’1 estimated from the validation data. 1 Initialization: Ë†q0 = 1. 2 for epoch in epo do 3 Training CUQDSÎ¸,Ï‰ with loss L and training dataset D1. 4 Update {Î¸, Ï‰} â† arg min Î¸,Ï‰ L (Î¸, Ï‰|D) 5 Initialize score set S = {}, error set E = {}. 6 for t = 1 : T2 do 7 fÎ¸(xt), Ë†Ïƒ(xt) â† CUQDSÎ¸,Ï‰(xt) 8 Compute score s t = s(xt, yt) by Eq. 8. 9 Compute conformal prediction set Ct by Eq. 9. 10 Compute et = 1 Ëœyt /âˆˆCt. 11 S â† s t, E â† et. 12 Î· = Î² max (S), then Ë†qt = Ë†qtâˆ’1 + Î·( Â¯E âˆ’ Î±). 13 Update Ë†q1 â† Ë†qT2 . Gaussian Process Gaussian process regression often acts as the surrogate model to estimate the output distribution of existing models [Erly- gin et al., 2023]. It introduces additional loss term to guild the learning process of existing models and reduce the output uncertainty. Gaussian process regression assumes any com- binations of data samples follows different join distribution and thus good at capturing the nonlinear relationship among time series data samples. In this study, we introduce to utilize the Gaussian process regression method to estimate the pre- liminary output distribution of existing trajectory prediction models. We view the base model fÎ¸ as a black box, whose de- sign can be an existing neural network structure in the lit- erature (examples include [Zhou et al., 2022; Liu et al., 2021; Zhou et al., 2023; Liang et al., 2020; Zhong et al., 2022]). We aim to estimate the output distribution (Y |x, Î¸ âˆ¼ N (Ë†Âµ (x) , Ë†Ïƒ2 (x))) corresponding to the time series trajec- tory inputs x by a learning-based Gaussian process regres- sion module [Rasmussen et al., 2006]. We treat the out- put of base model fÎ¸ (Â·) on x as the mean value Ë†Âµ (x) of the estimated output distribution and the correspond variance Ë†Ïƒ2 (x) as the uncertainty of fÎ¸ (x). In real-world settings of autonomous vehicles, the collected historical trajectories of the target vehicles inevitably contain noisy data due to the processing limitations during perception and object tracking steps. Such noise usually hardly captured by the trajectory prediction models such that greatly impact the output trajec- tory and the correspond uncertainty. To mitigate this problem, we model such noisy impact as Ïµ âˆˆ RD and assume it follows Gaussian distribution N (0, Ïƒ2 Ïµ ) with zero mean for simplic- ity and variance of Ïƒ2 Ïµ âˆˆ RD. ÏƒÏµ is set as trainable vector. Now the trajectory prediction process of base model is de- noted as Y |x = Ë†Âµ(x) + Ïµ, where (x, y) is any data samples from D. Then we have: Y |x âˆ¼ N ( Ë†Âµ (x) , âˆ‘N1 i=1k (x, xi) N1 + Ïƒ2 Ïµ I ) , (3) where k(Â·, Â·) is the kernel function or the covariance func- tion. For example, k (x, x â€²) quantifies the similarity between trajectory input data x and xâ€². Learnable Kernel Function In this paper, we define the covariance function as the radial basis function k (x, x â€²) = l2 1exp ( âˆ’ (x âˆ’ xâ€²) 2 2l2 2 ) , (4) where l1 âˆˆ R and l2 âˆˆ R are the parameters to be trained. The closer x and xâ€² are, the higher the value of k(x, x â€²), reaching its maximum value of l2 1. Eigenvector Inducing Variables As shown in Eq. 3, the covariance Ë†Ïƒ2(x) in standard Gaussian process regression method is typically optimized based on the whole training data. However, this can be computationally expensive when the number of training samples (N1) is large, given that the entire Gaussian process regression model re- quires O(N 3 1 ) computational complexity and O(N 2 1 ) mem- ory complexity. To alleviate such complexity while maintain- ing the effectiveness of the Gaussian process regression mod- ule, we propose a modification to approximate the covariance Ë†Ïƒ2(x) in Eq. 3 by extracting M âˆˆ R, M â‰ª N1, inducing variables {vi} M i=1, vi âˆˆ RLÃ—D by Principal Component Anal- ysis (PCA). These M inducing variables summarize the key information of training dataset. More specifically, we first standardize each input trajectory data sample xi âˆˆ RLÃ—D in training dataset D1 by its own mean and standardisation along time dimension. Then we build the N1 Ã— N1 covariance ma- trix by cov(x, x â€²) = E[(x âˆ’ E(x))(xâ€² âˆ’ E(xâ€²))]. The further steps follow the standard PCA processes. Inference under Distribution Shift Through the Gaussian process regression with a learnable kernel function, we are able to estimate the target trajectoryâ€™s distribution that in the training/validation dataset. However, under potential distribution shift between training and test- ing data in real-world settings, solely keep using the infor- mation learn from the training/validation datasets will lead to high generalization error. To take into account the po- tential distribution shift between the dataset D = {D1, D2} and the testing dataset ËœD, we instead estimate the condi- tional output distribution of base model in the testing stage by ËœY |Ëœx, D âˆ¼ N (ËœÂµ(Ëœx), ËœÏƒ(Ëœx)), where (Ëœx, Ëœy) âˆˆ ËœD. Then we compute the variance of the conditional output distribution of base model in the testing stage by ËœÏƒ2(Ëœx) = k(Ëœx, Ëœx) âˆ’ KËœxM [KM M + Ïƒ2 Ïµ I] âˆ’1(KËœxM )âŠº, (5) where KËœxM = (k (Ëœx, vi) , . . . , k (Ëœx, vM ))âŠº and [KM M ]ij = k (vi, vj). We then construct the uncertainty interval as [fÎ¸(Ëœx) âˆ’ ËœÏƒ(Ëœx), fÎ¸(Ëœx) + ËœÏƒ(Ëœx)], indicating there is a high prob- ability that it will cover the true target trajectories. To find the optimal parameters for the covariance function and the noise Ïµ, we introduce a new loss term L2: L2(Ï‰, Î¸) = 1 N1 âˆ‘N1 i=1(âˆ’ 1 2 eâŠ¤ i [ Â¯KxiM + Ïƒ2 Ïµ I]âˆ’1ei (6) âˆ’ 1 2 log âˆ£ âˆ£ Â¯KxiM + Ïƒ2 Ïµ Iâˆ£ âˆ£) + 1 2N1 log2Ï€), (7) where Ï‰ = [l1, l2, ÏƒÏµ] contains all trainable parame- ters in the Gaussian process regression module, Â¯KxiM = 1 M âˆ‘M j=1k(xi, vj), and ei = yi âˆ’ fÎ¸ (xi). 3.3 Uncertainty Quantification under Distribution Shift through Calibration The learning-based Gaussian process regression module is prone to overfit the training data and provide overconfident uncertainty estimation under distribution shift. Moreover, such uncertainty is more concerned about the aleotoric un- certainty, referring to the probabilistic nature of noise in data [Kendall and Gal, 2017], but fails to consider the perfor- mance limitation of base model on different trajectory data, namely the epistemic uncertainty. To solve these problems, we propose a conformal P control module to calibrate the out- put uncertainty from the Gaussian process regression module by considering the performance of base model under potential distribution shift. The idea of this method is based on both the conformal prediction [Shafer and Vovk, 2008] and the P con- trol in [Angelopoulos et al., 2023]. However, different from standard conformal prediction, we assume the training data and testing data follow different distributions. We initialize the conformal quantile using the validation data and keep up- dating it after every prediction step in the inference stage to provide trustworthy uncertainty quantification. Conformal Prediction for Long-run Converage We aim to design a statistical-based method to calibrate the preliminary output uncertainty from the Gaussian process re- gression module in the inference stage. Our goal is to achieve a long-run average coverage rate in time, ensuring that the calibrated uncertainty interval covers the true target trajecto- ries with a probability of 1 âˆ’ Î± [Angelopoulos et al., 2023], namely âˆ‘T t=1 errt/T â†’ Î± as T â†’ âˆ. err t = 1 (yt /âˆˆ Ct) and Î± âˆˆ (0, 1) is a predefined target error rate threshold. In particular, we seek to design a conformal score function s(x, y) (smaller scores encode better agreement between x and y), construct a conformal prediction set Ct(y|s(xt, y) â‰¤ qt), estimate the conformal quantile Ë†qt from the updated pre- diction set, and then calibrate the estimated uncertainty in- terval from the Gaussian process regression module by the updated conformal quantile. We define the score function as s(x, y) = |y âˆ’ fÎ¸(x)| Ïƒ(x) , (8) where y is the ground truth, fÎ¸(x) and Ïƒ(x) are re- spectively the mean and std of the output distribution of the base model. Then, the conformal prediction set at time t equals to an uncertainty interval {y|y âˆˆ [fÎ¸(xt) âˆ’ qtÏƒ (xt) , fÎ¸(xt) + qtÏƒ (xt)]}. Now the key of un- certainty calibration under potential distribution shift is to up- date the conformal quantile qt by considering model perfor- mance on recent inputs. Uncertainty Calibration in CUQDS Framework To update the conformal quantile qt under distribution shift, we first initialize the conformal quantile using the validation data as shown in Alg.1. In particular, during each validation iteration, we first initialize the score set S which records the conformal scores and the error set E which records the cov- erage errors of uncertainty intervals as empty. For each data sample (xt, yt) in validation data D2, we first compute the predicted trajectory fÎ¸(xt) from the base model and the stan- dard deviation Ë†Ïƒ(xt) from the Gaussian process regression module for the trajectory input xt. The conformal score for this prediction is calculated using the score function s(xt, yt), which evaluates the modelâ€™s performance for current data sample. Then, a conformal prediction set Ct is computed to determine whether the true label yt falls within the estimated uncertainty interval. The error et is set to 1 if yt is not within Ct, indicating a prediction error, and 0 otherwise. The esti- mated conformal score s(xt, yt) is added to the score set S, and the error et is added to the error set E. The conformal quantile Ë†qt is then updated based on both the existing confor- mal scores and coverage errors. The updating rule involves a learning rate Î· = Î² max(S) and adjusts Ë†qt according to the formula Ë†qt = Ë†qtâˆ’1 + Î·( Â¯E âˆ’ Î±), where Â¯E is the average coverage error in the coverage error set and Î± is the predefined error rate. This step allows the model to adapt its uncertainty estimation based on the ob- served performance during validation. During the testing stage, the conformal P control module inherits the conformal quantile, the score set S, and the error set E from the final validation iteration. The following con- formal quantile updating steps are similar as in the validation stage as shown in Alg.2. For each time step t in the testing stage, we get the predicted trajectory fÎ¸(Ëœxt) from the well trained base model and variance Ë†Ïƒ2(Ëœxt) from the well trained Gaussian process regression module. We then calibrate the output uncertainty and construct the uncertainty interval by using the current conformal quantile Ë†qt, Ct = [ fÎ¸(Ëœxt) âˆ’ Ë†qt ËœÏƒ(Ëœxt), fÎ¸(Ëœxt) + Ë†qt ËœÏƒ(Ëœxt)] . (9) Algorithm 2: Testing stage Input: the well-trained framework CUQDSÎ¸,Ï‰, the conformal quantile Ë†q1, the error set E, the conformal score set S, the error rate Î± from the training stage, score function s(Â·). Output: predicted trajectory and the correspond calibrated uncertainty interval. Data: testing data ËœD = {(Ëœxt, Ëœyt)} T3 t=Lâˆ’1 1 for t = 1 : T3 do 2 fÎ¸(Ëœxt), Ë†Ïƒ(Ëœxt) â† CUQDSÎ¸,Ï‰(Ëœxt) 3 Calibrate std ËœÏƒ(Ëœx t) by Ë†qtâˆ’1 ËœÏƒ(Ëœx t). 4 Compute score s(Ëœxt, Ëœyt) by Eq. 8. 5 Compute conformal prediction set Ct by Eq. 9. 6 Compute et = 1 Ëœyt /âˆˆCt. 7 S â† s t, E â† e t. 8 Î· = Î² max (S), then Ë†qt = Ë†qtâˆ’1 + Î·( Â¯E âˆ’ Î±). 4 Experiment 4.1 Experimental Setups Dataset & Key Setups: We use the Argoverse 1 motion fore- casting dataset [Chang et al., 2019] to verify the efficacy of our approach. This dataset collects trajectory data from Mi- ami and Pittsburgh, with a sample rate of 10 Hz. Given that the ground truth future trajectories are not provided in this official test sequences but are essential to our CUQDS in the testing stage to update the conformal quantile Ë†qt, we reparti- tion the sequences. In particular, we split the 205,942 official training sequences into 166,470 training data and 39,472 val- idation data, and use the official 39,472 validation sequences as testing data in this study. In all experiments of this study, Î± is set as 0.1. We im- plement existing base models by using their default settings, unless otherwise specified. The host machine is a server with IntelCore i9-10900X processors and four NVIDIA Quadro RTX 6000 GPUs. Prediction Accuracy Evaluation Metrics: Following the standard evaluation protocol, we utilize metrics including minimum Average Displacement Error (minADEk), mini- mum Final Displacement Error (minFDEk), and Miss Rate (MRk) to evaluate the prediction accuracy of the model. As common, k is selected as 1 and 6. Uncertainty Evaluation Metrics: To further verify the ef- ficacy of our CUQDS in reducing the predicted uncertainty to provide narrow while accurate uncertainty interval, we adopt the Negative Log-Likelihood (NLL) [Feng et al., 2021] to as- sess the level of uncertainty in the predicted distribution. For this metric, lower values connote a higher degree of precision in uncertainty estimation and narrower uncertainty interval. 4.2 Baselines In this study, we employ the following models as baselines for comparison. 1. HiVT [Zhou et al., 2022]: HiVT is a transformer-based trajectory prediction model which models the output dis- tribution as a mixture Laplace distribution. We set hid- den units as 64 and radius as 50. 2. LaneGCN [Liang et al., 2020]: LaneGCN is a graph convolutional network based model that predicts the k possible future trajectories and their confidence scores by a MLP-based prediction header. 3. LBA [Zhong et al., 2022]: LBA improves trajectory fore- casting accuracy of existing models by fusing informa- tion from observed trajectories, HD maps, and local be- havior data. 4. LBF [Zhong et al., 2022]: LBF improves trajectory forecasting accuracy of existing models by employing a local-behavior-free prediction framework which infers the impact of missing data when the local behavior his- torical data is insufficient or unavailable. 5. SPCI [Xu and Xie, 2023]: SPCI proposes a learning- based estimator to predict the conditional quantile di- rectly and bases on split conformal prediction to pro- vide conformal prediction interval for existing time se- ries forecasting models. We implement additional mod- ule whose structure is the same as the estimator to pre- dict the variance of the predicted trajectory and add the KLD [Meyer and Thakurdesai, 2020] loss term to reduce the estimated uncertainty. 4.3 Main Results We adopt HiVT, LaneGCN, LBA, and LBF as base mod- els and apply our CUQDS on them to verify the efficacy of CUQDS. To compare our CUQDS with state-of-the-art meth- ods, we also apply SPCI into the above four base models. As presented in Table. 1 and Table. 2, our CUQDS improves the prediction accuracy 7.07% on average. Compared with incorporating SPCI in the base models, our CUQDS reduces the output uncertainty which quantified by NLL by 25.41% on average, and improves the average coverage rate of the estimated uncertainty interval by 21.02%. The results indi- cate that our CUQDS is capable of providing the trust wor- thy uncertainty quantification for the output trajectory of base model under potential distribution shift. Our estimated uncer- tainty intervals are narrow and achieve high coverage rate of covering the true target trajectories. Compared with the transformer-based model HiVT, apply- ing our CUQDS in HiVT provides the output uncertainty of HiVT by considering the distribution difference between the training and testing data. Compared with the base models of LaneGCN, LBA, and LBF who provide a confidence score for Table 1: Prediction results and performance comparison on testing dataset when with and without our CUQDS. Scheme minADE6 â†“ minFDE6 â†“ MR6 â†“ minADE1 â†“ minFDE1 â†“ MR1 â†“ HiVT 0.692 1.043 0.106 1.291 2.895 0.499 HiVT+SPCI 0.694 1.047 0.107 1.302 2.921 0.501 HiVT+CUQDS 0.682 1.034 0.097 1.218 2.696 0.455 LaneGCN 0.719 1.094 0.104 1.375 3.023 0.505 LaneGCN+SPCI 0.739 1.169 0.114 1.585 3.573 0.568 LaneGCN+CUQDS 0.704 1.033 0.097 1.255 2.744 0.482 LBA 0.717 1.094 0.103 1.395 3.100 0.503 LBA+SPCI 0.719 1.098 0.104 1.402 3.100 0.523 LBA+CUQDS 0.705 1.044 0.092 1.251 2.801 0.483 LBF 0.720 1.098 0.104 1.530 3.467 0.549 LBF+SPCI 0.721 1.099 0.105 1.533 3.469 0.550 LBF+CUQDS 0.714 1.091 0.097 1.455 3.188 0.522 Table 2: Compare the NLL distribution distance between ground truth and predicted distribution, and the average cover rate (CR) of the estimated uncertainties interval under settings of 1) incorporate SPCI into base models, 2) incorporate our CUQDS into base models. Scheme +SPCI (NLL) +CUQDS (NLL) +SPCI (CR) +CUQDS (CR) HIVT 21.354 16.354 0.705 0.832 LaneGCN 25.532 18.896 0.603 0.746 LBA 23.634 17.453 0.602 0.721 LBF 23.723 17.535 0.614 0.716 Table 3: Compare the coverage rates of the uncertainty interval with and without the uncertainty calibration (UC) module. Scheme Without UC With UC HiVT+CUQDS 0.603 0.832 LaneGCN+CUQDS 0.497 0.746 LBA+CUQDS 0.570 0.721 LBF+CUQDS 0.569 0.716 each output trajectory, our CUQDS provides the output distri- bution of base model instead of point estimates and calibrates the correspond uncertainty by taking into account the model performance on recent inputs. SPCI try to predict the con- formal quantile by the learning-based estimator to provide the prediction interval. However, such estimator is prone to over- fit the training data and invalid under distribution shift. 4.4 Ablation Study â€¢ Conformal Prediction VS conformal P control module: We conduct ablation study on replacing the P control uncer- tainty calibration module with the standard split conformal prediction [Shafer and Vovk, 2008]. More specificity, the standard split conformal prediction (CP) estimates the con- formal quantile Ë†q as the (1âˆ’Î±)(N2+1) N2 smallest element in the conformal score set S = {s (xi, yi)} N2 i=1 which uses valida- tion dataset. This conformal quantile Ë†q is only calculated once and fixed in the testing stage to calibrate the uncertainty. We implement the standard split conformal prediction set- ting in base model LaneGCN. The average coverage rates of the uncertainty intervals estimated by our P control module Table 4: Results of our CUQDS and replacing the Gaussian process regression module with the self-attention based design for uncer- tainty estimation. Scheme minADE6 â†“ minFDE6 â†“ MR6 â†“ minADE1 â†“ minFDE1 â†“ MR1 â†“ HiVT+CUQDS 0.682 1.034 0.097 1.218 2.696 0.455 HiVT+DM 0.694 1.047 0.107 1.302 2.921 0.501 and the split conformal prediction are 0.746 and 0.402, re- spectively. Our P control module outperforms the standard split conformal prediction. This helps to prove the effective- ness of our uncertainty calibration module in adapting to po- tential distribution shift. â€¢ With VS without the P control uncertainty calibra- tion module: We further verify the efficacy of the P control uncertainty calibration module by removing the whole cali- bration process in the testing stage. As shown in Table. 3, by calibrating the output uncertainty of the base model by the P control uncertainty calibration module, the coverage rate of the calibrated uncertainty interval improves 35.10% on aver- age comparing with without calibration. â€¢ Gaussian process regression module VS direct model- ing: To validate the effectiveness of our Gaussian process re- gression module, we replace the Gaussian process regression module with the self-attention based design [Mao et al., 2023] to predict the variance of the output distribution and add the KLD loss term to reduce the estimated uncertainty during the training stage. We apply this setting on the base model HiVT. As shown in Table. 4, both of the methods achieves better pre- diction accuracy than without considering uncertainty in the base model. Our CUQDS slightly exceed the direct model- ing method in all prediction accuracy evaluation metrics. The results prove that our CUQDS is sufficient in providing out- put uncertainty estimation for the trajectory prediction base model and improving the prediction accuracy. 5 Conclusion & Discussion In this study, we present the framework CUQDS to estimate the output distribution for any existing trajectory prediction models under distribution shift, while improving the predic- tion accuracy and reduce the output uncertainty by introduc- ing additional loss term. CUQDS adopts the Gaussian process regression module to model the output distribution of the base model. In addition, CUQDS utilizes a statistical-based P con- trol module to calibrate the estimated uncertainty by consid- ering the performance limitation of base model upon recent inputs. The experiment results demonstrate the efficacy of CUQDS in improving the prediction accuracy and reducing the prediction uncertainty. Our findings highlight the impor- tance of quantifying the uncertainty of output trajectory in tra- jectory prediction under distribution shift. In the future work, we plan to extend our work to more state-of-the-art models, provide uncertainty of output trajectory in each time step, and further compare the performance difference of estimating un- certainty and output distribution by different designs. References [Angelopoulos et al., 2023] Anastasios N Angelopoulos, Emmanuel J Candes, and Ryan J Tibshirani. Conformal pid control for time series prediction. arXiv preprint arXiv:2307.16895, 2023. [Chai et al., 2019] Yuning Chai, Benjamin Sapp, Mayank Bansal, and Dragomir Anguelov. Multipath: Multiple probabilistic anchor trajectory hypotheses for behavior prediction. arXiv preprint arXiv:1910.05449, 2019. [Chang et al., 2019] Ming-Fang Chang, John Lambert, Pat- sorn Sangkloy, Jagjeet Singh, Slawomir Bak, Andrew Hartnett, De Wang, Peter Carr, Simon Lucey, Deva Ra- manan, et al. Argoverse: 3d tracking and forecasting with rich maps. In Pro. of IEEE/CVF, pages 8748â€“8757, 2019. [Chen et al., 2023] Guangyi Chen, Zhenhao Chen, Shunxing Fan, and Kun Zhang. Unsupervised sampling promot- ing for stochastic human trajectory prediction. In Proc. of IEEE/CVF, pages 17874â€“17884, 2023. [Cui et al., 2019] Henggang Cui, Vladan Radosavljevic, Fang-Chieh Chou, Tsung-Han Lin, Thi Nguyen, Tzu-Kuo Huang, Jeff Schneider, and Nemanja Djuric. Multimodal trajectory predictions for autonomous driving using deep convolutional networks. In 2019 ICRA, pages 2090â€“2096. IEEE, 2019. [Deo and Trivedi, 2018] Nachiket Deo and Mohan M Trivedi. Convolutional social pooling for vehicle trajec- tory prediction. In Proc. of IEEE CVPR workshops, pages 1468â€“1476, 2018. [Erlygin et al., 2023] Leonid Erlygin, Vladimir Zholobov, Valeriia Baklanova, Evgeny Sokolovskiy, and Alexey Za- ytsev. Uncertainty estimation for time series forecasting via gaussian process regression surrogates. SIGKDD 2023, 2023. [Feng et al., 2021] Di Feng, Ali Harakeh, Steven L Waslan- der, and Klaus Dietmayer. A review and comparative study on probabilistic object detection in autonomous driving. IEEE Transactions on Intelligent Transportation Systems, 23(8):9961â€“9980, 2021. [Gu et al., 2024] Xunjiang Gu, Guanyu Song, Igor Gilitschenski, Marco Pavone, and Boris Ivanovic. Producing and leveraging online map uncertainty in trajectory prediction. Proc. of the IEEE/CVF CVPR, 2024. [Gupta et al., 2018] Agrim Gupta, Justin Johnson, Li Fei- Fei, Silvio Savarese, and Alexandre Alahi. Social gan: Socially acceptable trajectories with generative adversar- ial networks. In Proc. of IEEE CVPR, pages 2255â€“2264, 2018. [Hu et al., 2023] Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tian- wei Lin, Wenhai Wang, et al. Planning-oriented au- tonomous driving. In Proc. of the IEEE/CVF, pages 17853â€“17862, 2023. [Ivanovic et al., 2022] Boris Ivanovic, Yifeng Lin, Shubham Shrivastava, Punarjay Chakravarty, and Marco Pavone. Propagating state uncertainty through trajectory forecast- ing. In 2022 ICRA, pages 2351â€“2358. IEEE, 2022. [Kedia et al., 2023] Shubham Kedia, Yu Zhou, and Sambhu H Karumanchi. Integrated perception and planning for autonomous vehicle navigation: An optimization-based approach. In Proc. of the IEEE/CVF, pages 3205â€“3214, 2023. [Kendall and Gal, 2017] Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? Advances in neural information pro- cessing systems, 30, 2017. [Lekeufack et al., 2023] Jordan Lekeufack, Anastasios N Angelopoulos, Andrea Bajcsy, Michael I. Jordan, and Jitendra Malik. Conformal decision theory: Safe au- tonomous decisions from imperfect predictions. arXiv preprint arXiv:2310.05921, 2023. [Liang et al., 2020] Ming Liang, Bin Yang, Rui Hu, Yun Chen, Renjie Liao, Song Feng, and Raquel Urtasun. Learning lane graph representations for motion forecast- ing. In Computer Visionâ€“ECCV 2020, pages 541â€“556. Springer, 2020. [Lindemann et al., 2023] Lars Lindemann, Matthew Cleave- land, Gihyun Shim, and George J Pappas. Safe planning in dynamic environments using conformal prediction. IEEE Robotics and Automation Letters, 2023. [Liu et al., 2021] Yicheng Liu, Jinghuai Zhang, Liangji Fang, Qinhong Jiang, and Bolei Zhou. Multimodal mo- tion prediction with stacked transformers. In Proc. of the IEEE/CVF Conference on CVPR, pages 7577â€“7586, 2021. [Mao et al., 2023] Weibo Mao, Chenxin Xu, Qi Zhu, Siheng Chen, and Yanfeng Wang. Leapfrog diffusion model for stochastic trajectory prediction. In Proc. of IEEE/CVF, pages 5517â€“5526, 2023. [Meyer and Thakurdesai, 2020] Gregory P Meyer and Ni- ranjan Thakurdesai. Learning an uncertainty-aware object detector for autonomous driving. In 2020 IEEE/RSJ Inter- national Conference on IROS, pages 10521â€“10527. IEEE, 2020. [Ngiam et al., 2021] Jiquan Ngiam, Benjamin Caine, Vijay Vasudevan, Zhengdong Zhang, Hao-Tien Lewis Chiang, Jeffrey Ling, Rebecca Roelofs, Alex Bewley, Chenxi Liu, Ashish Venugopal, et al. Scene transformer: A unified ar- chitecture for predicting multiple agent trajectories. arXiv preprint arXiv:2106.08417, 2021. [Phan-Minh et al., 2020] Tung Phan-Minh, Elena Corina Grigore, Freddy A Boulton, Oscar Beijbom, and Eric M Wolff. Covernet: Multimodal behavior prediction us- ing trajectory sets. In Proc. of IEEE/CVF, pages 14074â€“ 14083, 2020. [Rasmussen et al., 2006] Carl Edward Rasmussen, Christo- pher KI Williams, et al. Gaussian processes for machine learning, volume 1. Springer, 2006. [Rhinehart et al., 2018] Nicholas Rhinehart, Kris M Kitani, and Paul Vernaza. R2p2: A reparameterized pushforward policy for diverse, precise generative path forecasting. In Proc. of ECCV, pages 772â€“788, 2018. [Rhinehart et al., 2019] Nicholas Rhinehart, Rowan McAl- lister, Kris Kitani, and Sergey Levine. Precog: Predic- tion conditioned on goals in visual multi-agent settings. In Proc. of IEEE/CVF, pages 2821â€“2830, 2019. [Salzmann et al., 2020] Tim Salzmann, Boris Ivanovic, Punarjay Chakravarty, and Marco Pavone. Trajectron++: Dynamically-feasible trajectory forecasting with heteroge- neous data. In Computer Visionâ€“ECCV 2020, pages 683â€“ 700. Springer, 2020. [Shafer and Vovk, 2008] Glenn Shafer and Vladimir Vovk. A tutorial on conformal prediction. Journal of Machine Learning Research, 9(3), 2008. [Shi et al., 2023] Shaoshuai Shi, Li Jiang, Dengxin Dai, and Bernt Schiele. Mtr++: Multi-agent motion prediction with symmetric scene modeling and guided intention querying. arXiv preprint arXiv:2306.17770, 2023. [Tang and Salakhutdinov, 2019] Charlie Tang and Russ R Salakhutdinov. Multiple futures prediction. NeurIPS, 32, 2019. [Tang et al., 2021] Bohan Tang, Yiqi Zhong, Ulrich Neu- mann, Gang Wang, Siheng Chen, and Ya Zhang. Collab- orative uncertainty in multi-agent trajectory forecasting. NeurIPS, 34:6328â€“6340, 2021. [Varadarajan et al., 2022] Balakrishnan Varadarajan, Ahmed Hefny, Avikalp Srivastava, Khaled S Refaat, Nigamaa Nayakanti, Andre Cornman, Kan Chen, Bertrand Douil- lard, Chi Pang Lam, Dragomir Anguelov, et al. Multi- path++: Efficient information fusion and trajectory aggre- gation for behavior prediction. In 2022 ICRA, pages 7814â€“ 7821. IEEE, 2022. [Xu and Xie, 2023] Chen Xu and Yao Xie. Sequential pre- dictive conformal inference for time series. In Interna- tional Conference on Machine Learning, pages 38707â€“ 38727. PMLR, 2023. [Xu et al., 2014] Wenda Xu, Jia Pan, Junqing Wei, and John M Dolan. Motion planning under uncertainty for on-road autonomous driving. In 2014 IEEE ICRA, pages 2507â€“2512. IEEE, 2014. [Zeng et al., 2021] Wenyuan Zeng, Ming Liang, Renjie Liao, and Raquel Urtasun. Lanercnn: Distributed repre- sentations for graph-centric motion forecasting. In 2021 IEEE/RSJ International Conference on IROS, pages 532â€“ 539. IEEE, 2021. [Zhong et al., 2022] Yiqi Zhong, Zhenyang Ni, Siheng Chen, and Ulrich Neumann. Aware of the history: Trajec- tory forecasting with the local behavior data. In European Conference on Computer Vision, pages 393â€“409. Springer, 2022. [Zhou et al., 2022] Zikang Zhou, Luyao Ye, Jianping Wang, Kui Wu, and Kejie Lu. Hivt: Hierarchical vector trans- former for multi-agent motion prediction. In Proc. of IEEE/CVF, pages 8823â€“8833, 2022. [Zhou et al., 2023] Zikang Zhou, Jianping Wang, Yung-Hui Li, and Yu-Kai Huang. Query-centric trajectory predic- tion. In Proc. of the IEEE/CVF CVPR, pages 17863â€“ 17873, 2023. [Zhu et al., 2023] Dekai Zhu, Guangyao Zhai, Yan Di, Fabian Manhardt, Hendrik Berkemeyer, Tuan Tran, Nassir Navab, Federico Tombari, and Benjamin Busam. Ipcc- tp: Utilizing incremental pearson correlation coefficient for joint multi-agent trajectory prediction. In Proc. of IEEE/CVF, pages 5507â€“5516, 2023.","libVersion":"0.3.2","langs":""}