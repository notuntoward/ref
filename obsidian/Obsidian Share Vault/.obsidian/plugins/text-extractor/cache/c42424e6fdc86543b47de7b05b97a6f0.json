{"path":"lit/lit_sources/2406.14904v1.pdf","text":"Enhancing reliability in prediction intervals using point forecasters: Heteroscedastic Quantile Regression and Width-Adaptive Conformal Inference Carlos Sebasti´an a,b, Carlos E. Gonz´alez-Guill´en c,d, Jes´us Juane aFortia Energ´ıa, Calle de Gregorio Ben´ıtez, Madrid, 28043, Spain bUniversidad Polit´ecnica de Madrid, Madrid, Spain cDepartamento de Matem´atica Aplicada a la Ingenier´ıa Industrial, Escuela T´ecnica Superior de Ingenieros Industriales, Universidad Polit´ecnica de Madrid, Calle de Jos´e Guti´errez Abascal, Madrid, 28006, Spain dInstituto de Ciencias Matem´aticas (CSIC-UAM-UC3M-UCM), Calle Nicol´as Cabrera, Madrid, 28049, Spain eLaboratorio de Estad´ıstica, Escuela T´ecnica Superior de Ingenieros Industriales, Universidad Polit´ecnica de Madrid, Calle de Jos´e Guti´errez Abascal, Madrid, 28006, Spain Abstract Building prediction intervals for time series forecasting problems presents a complex challenge, particularly when relying solely on point predictors, a common scenario for practitioners in the industry. While research has primarily focused on achieving increasingly efficient valid intervals, we argue that, when evaluating a set of intervals, traditional measures alone are insufficient. There are additional crucial characteristics: the intervals must vary in length, with this variation directly linked to the difficulty of the prediction, and the coverage of the interval must remain independent of the difficulty of the prediction for practical utility. We propose the Heteroscedastic Quantile Regression (HQR) model and the Width-Adaptive Conformal Inference (WACI) method, providing theoretical coverage guarantees, to overcome those issues, respectively. The methodologies are evaluated in the context of Electricity Price Forecasting and Wind Power Forecasting, representing complex scenarios in time series forecasting. The results demonstrate that HQR and WACI not only improve or achieve typical measures of validity and efficiency but also successfully fulfil the commonly ignored mentioned characteristics. Keywords: Conformal Prediction, Prediction Intervals, Probabilistic Forecasting, Email address: carlos.sebastian@alumnos.upm.es (Carlos Sebasti´an) Preprint submitted to Elsevier June 24, 2024arXiv:2406.14904v1 [stat.ME] 21 Jun 2024 Time Series Forecasting, Quantile Regression Contents 1 Context of the problem 3 2 Prior work 6 2.1 Quantile regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.1.1 Quantile Regression Averaging . . . . . . . . . . . . . . . . . . 8 2.2 Conformal Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.2.1 Conformalized Quantile Regression (CQR) . . . . . . . . . . . 10 2.2.2 Adaptive Conformal Inference (ACI) . . . . . . . . . . . . . . 12 3 Our proposal 13 3.1 Heteroscedastic Quantile Regression (HQR) . . . . . . . . . . . . . . 13 3.2 Width-Adaptive Conformal Inference . . . . . . . . . . . . . . . . . . 15 4 Real data examples 21 4.1 Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 4.1.1 Electricity Price Forecasting (EPF) . . . . . . . . . . . . . . . 22 4.1.2 Wind Power Forecasting (WPF) . . . . . . . . . . . . . . . . . 24 4.2 Evaluation metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 5 Results and discussion 27 5.1 Electricity Price Forecasting (EPF) . . . . . . . . . . . . . . . . . . . 27 5.2 Wind Power Forecasting (WPF) . . . . . . . . . . . . . . . . . . . . . 41 6 Conclusions and future work 52 References 54 Appendix A Intuitive behaviour of the HQR model 57 Appendix B Results of the QRA and HQR models by hours for the EPF dataset. 61 2 1. Context of the problem Machine learning’s application in critical decision-making has expanded dramatically, reaching into domains as vital as medical diagnostics (Kourou et al., 2015; Papadopoulos, 2011) and autonomous vehicle navigation (Melotti et al., 2023). The imperative to accurately assess the risks associated with model predictions in these areas cannot be overstated. This necessity is similarly crucial in managing time series data, which plays a significant role in various industries. For example, uncertainty quantification helps optimize inventory management by minimizing costs and preventing stock shortages (B¨ose et al., 2017). Additionally, in the energy sector, the integration of fluctuating renewable energy sources into the power grid not only complicates grid maintenance but also amplifies market volatility (Zhang et al., 2014; Nowotarski and Weron, 2018). Thus, the precise quantification of uncertainty becomes essential for informed decision-making using predictive models. Additionally, it is typical, particularly in industrial settings, to not only develop in-house prediction models, if they are developed at all, but also to hire various forecasting services to provide predictions for the same process of interest. This approach allows companies to cross-validate the accuracy and reliability of different forecasts, thereby enhancing decision-making processes and optimizing operational efficiency. By comparing multiple forecasts, industries can mitigate risks associated with reliance on a single predictive model and gain a more comprehensive understanding of potential future scenarios. Let us denote by yt the value of the variable whose evolution we wish to predict, which has been observed in the past at equidistant time points, t = 1, 2, . . . , T . Suppose we have had access to predictions made by M experts who independently provide point forecasts for each time point t, namely ˆyt,1, ˆyt,2, . . . , ˆyt,M . We are interested in predicting the value of the variable at a future time point, T + 1, that is yT +1, based on the forecasts ˆyT +1,1, ˆyT +1,2, . . . , ˆyT +1,M , and in providing a prediction interval Cα,T +1 = [lα,T +1, uα,T +1] such that P (yT +1 ∈ Cα,T +1) = 1 − α where α ∈ (0, 1) represents the desired level of miscoverage, i.e., the proportion of times the band is allowed to not contain the actual value. Let the length of the interval be |Cα,T +1| = uα,T +1 − lα,T +1. If for the same level of miscoverage α and two different instants T1 and T2, |Cα,T1+1| > |Cα,T2+1| then 3 one has a higher uncertainty at the instant T1 than at T2. This way, decisions taken at different points in time will be supported by a quantification of the risk that allows for a better understanding of the situation. An interval Cα,T +1 is considered valid if its marginal coverage is greater or equal than the objective coverage level 1 − α. That is P (yT +1 ∈ Cα,T +1) ≥ 1 − α. The efficiency of the interval is associated with the length of the interval. At the same level of coverage, the smaller length of the interval will be preferred, as it will better describe the process. These two properties are the main ones when building an interval: the most efficient possible valid interval is desired (Shafer and Vovk, 2008). In practice, it is not feasible to assess the validity and efficiency of a prediction interval for a single time point. Typically, the analysis involves a comprehensive review of the intervals constructed over an extended period, which encompasses multiple prediction intervals. This broader evaluation helps to determine the overall effectiveness and reliability of the prediction intervals across different scenarios and conditions. Such an approach ensures a more solid understanding of how well the intervals perform in capturing the true values of the predicted variable under different circumstances. A good solution will give intervals of varying amplitude, where this variation should be related to the difficulty of the instance to be predicted (Angelopoulos and Bates, 2021). Thus, the variation of the length of the intervals must be measured and, in addition, it must be checked that there is an increasing relationship between the length of the interval and the error made by the point forecaster, because it would be expected to have a lower prediction accuracy in the most complicated situations. In this way, the intervals will be said to be informative. Additionally, the validity of prediction intervals should not depend on the ease of prediction and, as previously argued, the complexity of making a prediction should be directly correlated with the length of the interval. For a given prediction interval Cα,T +1 = [lα,T +1, uα,T +1] with length |Cα,T +1|, the objective is to transform this interval into a new one, C ∗ α,T +1 = [ l∗ α,T +1, u ∗ α,T +1] , such that the coverage probability remains independent of the length |Cα,T +1|. This is mathematically represented as: P ( yT +1 ∈ C ∗ α,T +1| |Cα,T +1| ) = P (yT +1 ∈ Cα,T +1) . This formulation ensures that confidence in the predictions remains constant, regardless of the length of the initial interval, thereby providing uniform certainty 4 across situations with different difficulties. These two concepts depend on the error of the point forecaster used. Thus, different point forecasters may give different error metrics. From now on, the point forecaster considered through out this work will be the mean of the M different forecasts received, which is common practice and usually yields quite decent results despite its simplicity (Wang et al., 2023). In this paper we focus on improving the results related to these properties that are key to make decisions supported by predictive models, while trying not to worsen the classical validity and efficiency measures in the context of probabilistic forecasting. All of this under the context in which only different (few) predictions of the process of interest are known, which is common in the industry. The contributions of the paper are as follows: 1. We propose a quantile regression model, inspired by the philosophy of the Quantile Regression Aveaging (QRA) model of Nowotarski and Weron (2015), but with modifications so that there is an increasing relationship between the length of the interval and the difficulty of the prediction. Due to the particular use of the standard deviation of the point predictors, we will call the model Heteroscedastic Quantile Regression (HQR). 2. To provide theoretical coverage guarantees and to achieve uniformity of coverage regardless of the difficulty of the prediction, the Width-Adaptive Conformal Inference (WACI) method is proposed, which modifies the Adaptive Conformal Inference (ACI, Gibbs and Cand`es (2021)) method by solving the problems that the rest of the models may present in this regard. To the best of our knowledge these two desired properties have not been considered before. The rest of the paper is structured in the following way. Section 2 discusses the different works related to uncertainty quantification in various forms and goes into detail on some of them, as they are the basis of the different contributions of the paper. Section 3 details our proposal, which is evaluated with the examples presented in Section 4 and whose discussion is extended in Section 5. Conclusions and future work finish the paper in Section 6. 5 2. Prior work Bayesian methods, by their very nature, are clear candidates for probabilistic regression problems. Through Bayes’ theorem, a posterior distribution can be obtained by updating beliefs as new information is obtained. Assuming a parametric model dependent on weights on the target variable, a distribution over these weights can be adopted. This is the approach followed in Bayesian neural networks (Neal, 2012). One can also consider the Bayesian approach directly on the target variable in the variant known as evidential regression (Amini et al., 2020) or with a functional approach through Gaussian processes (Rasmussen, 2003). However, Bayesian methods present problems that cannot be ignored, such as the choice of the prior distribution or the computational complexity. Assuming a specific distribution, one can try to estimate the distribution of yT +1 based on the information known at time T . This is done by methods such as NGBoost (Duan et al., 2020), GAMLSS (Stasinopoulos and Rigby, 2008) as well as distributional neural networks and mixture density networks (Bishop, 1994). But as discussed in the previous section, the constraint of selecting a particular distribution can be quite restrictive. From a non-parametric point of view, classical methods such as bootstrapping the residuals to generate prediction intervals can be applied (Efron, 1987). However, the generality of the method tends not to produce the most satisfactory results. The application of quantile regression (Koenker and Bassett Jr, 1978) is also very popular, either through a linear model or by extending the method to more complex approaches such as neural networks (Cannon, 2011). All these methods can be easily extended to time series problems (for example by considering autoregressive effects, which is common practice) but none of them can assure the marginal coverage needed to provide valid prediction intervals. The Conformal Prediction framework (Vovk et al., 2005) ensures such marginal coverage in finite samples by assuming exchangeability between observations and without any assumptions about the probability distribution. In fact, Conformalized Quantile Regression (CQR) (Romano et al., 2019) extends quantile regression by providing the property of validity under exchangeability. However, as the exchangeability property is very demanding in time series, a large branch of research has focused on maintaining the good properties of the conformal predictors without assuming it. See for example (Gibbs and Cand`es, 2021; Zaffran et al., 2022; Gibbs and Cand`es, 2022; Bhatnagar et al., 2023). 6 Regarding the context of the problem at hand, where only different predictors of the event to be forecasted are known, all these methodologies could be perfectly adapted by taking these predictors as explanatory variables. However, to our knowledge, there is only one work that has approached it in such a way: the Quantile Regression Averaging (QRA) model proposed by Nowotarski and Weron (2015), which will be explored in more depth in Section 2.1.1. 2.1. Quantile regression As the initial objective should always be to obtain valid intervals, the estimation of quantiles, by its very definition, is a logical approximation to the problem. Let α ∈ (0, 1) be the target miscoverage value, ξ ∈ (0, α) and let’s denote by qβ(yT +1) the quantile of level β of the distribution function FT +1 . If we take lα,T +1 = qξ(yT +1) and uα,T +1 = q1−α+ξ(yT +1), then P (yT +1 ∈ Cα,T +1) ≥ 1 − α. The typical choice for ξ is ξ = α 2 and this is the approach that will be followed in this paper. However, it should be noted that if the smallest intervals are desired, this option is not necessarily optimal. Let y = (y1, y2, . . . , yn) be the vector of n observations of the variable of interest and xi = (xi,1, xi,2, . . . , xi,m) be the vector of m explanatory features for the observation i for all i ∈ {1, 2, . . . , n}. Let’s consider the model1 qβ(yi) = λ0(β) + λ1(β)xi,1 + λ2(β)xi,2 + · · · + λm(β)xi,m + εi(β); E [εi(β)] = 0 where λ (β) ≡ λ = (λ0 (β) , λ1 (β) , λ2 (β) , . . . , λm (β)) are the parameters of the model and εi(β) represents noise. Let yi ∼ Y and xi ∼ X for all i = 1, 2, . . . , n. Let Y |X be distributed as F. Just as the mean squared error is the loss function that is optimised to obtain the parameters that estimate the conditional mean as a point estimator, the estimation of the conditional quantile is achieved by optimising the pinball loss: lβ(yi, ˆyi) = β|yi − ˆyi|1 {yi − ˆyi ≥ 0} + (1 − β)|yi − ˆyi|1 {yi − ˆyi ≤ 0} 1Without loss of generality, we consider the linear model. 7 The parameters λ are estimated as ˆλ = min λ { n∑ i=1 lβ(yi, λ · xi) } and inference about a new observation n + 1 is done through ˆqβ(yn+1) = ˆλ0 (β) + ˆλ1 (β) xn+1,1 + ˆλ2 (β) xn+1,2 + · · · + ˆλm (β) xn+1,m 2.1.1. Quantile Regression Averaging The problem addressed in this paper only makes use of different point predictors. Although this situation is not raised in the original paper (Nowotarski and Weron, 2015), the model presented there fits perfectly with the problem at hand. The idea is based on estimating the quantiles using individual point forecasts as independent variables. Although the model is presented in the context of Day-Ahead Electricity Price Forecasting, it is perfectly generalizable to any problem. In particular, the model proposed for the quantile β at time t is qβ(yt) = λ0(β) + λ1(β)ˆyt,1 + λ2(β)ˆyt,2 + · · · + λm(β)ˆyt,m + εt(β); E [εt(β)] = 0, (1) where ˆyt,1, ˆyt,2, . . . , ˆyt,m are the predictions of various models for the same time instant t. In particular, one-step ahead predictions would be obtained by: ˆqβ(yt) = ˆλ0(β) + ˆλ1(β)ˆyt,1 + ˆλ2(β)ˆyt,2 + · · · + ˆλm(β)ˆyt,m. (2) To fit the models for time series problems, the use of a rolling window approach is proposed. Thus, the model described in (1) and (2) would be the particular model for one window. For another window, another estimation of the model parameters would be obtained. Figure 1 describes the process of a rolling window methodology. The window size in this procedure is chosen empirically. 8 Figure 1: Rolling window mechanism with size equal to 5 time steps. To predict the next time step, only the data from the previous 5 time steps is used to estimate the model parameters. Although quantile regression procedures based on the pinball loss produce asymptotically consistent estimators (Koenker and Bassett Jr, 1978), over a finite amount of data there is no theoretical guarantee of obtaining the desired marginal coverage. This is where the Conformal Prediction framework adds value. 2.2. Conformal Prediction Conformal predictions were introduced in Vovk et al. (2005) to build prediction intervals (in the regression framework) that are valid with a finite number of data, without assumptions, except exchangeability, about any kind of distribution and for any predictive model. Although the original approach, commonly referred to as Full Conformal Prediction, is not computationally feasible on a large scale, the approach known as Split Conformal Prediction (Lei et al., 2018; Papadopoulos et al., 2002) solves such problems making its use more appealing in a multitude of situations. This paper only focuses on the second approach. Suppose we have n points (xi, yi) ∈ R m × R, i = 1, . . . , n and we are interested in providing a prediction interval for the next observation yn+1 for which xn+1 is known. Conformalization in its simplest form consists in making a correction to a predictor of the mean. Let ˆµ(·) be that predictor. The steps to perform its conformalization for an objective miscoverage of α are: 1. Randomly split the n known points into two sets: training, Tr, and calibration, Cal. Tr, Cal ⊂ {1, . . . , n}. 9 2. Train the regression algorithm ˆµ using the data from the training set. 3. Compute a set of scores that determines how well the predictions of the regression algorithm fit the observations in the calibration set. This score is known as the conformity score and the most common is the absolute error of each of the points. That is, S = SCal ∪ {+∞} 2, where SCal = {|yi − ˆµ(xi)| : i ∈ Cal} 4. Compute the ⌈(|SCal|+1)(1−α)⌉ |SCal| quantile of the conformity scores. We will denote it by Q1−α(S). 5. The final conformalized prediction interval for the observation n + 1 is given by ˆCα,n+1 = [ˆµ(xn+1) − Q1−α(S), ˆµ(xn+1) + Q1−α(S)] Theorem 1 (Lei et al. (2018)). Let (xi, yi)n+1 i=1 be exchangeable. The process of conformalizing a conditional mean predictor as described previously produces a prediction interval for the observation n + 1, ˆCα,n+1, such that P (yn+1 ∈ ˆCα,n+1) ≥ 1 − α. If, in addition, the scores SCal have a continuous joint distribution, we also have: P (yn+1 ∈ ˆCα,n+1) ≤ 1 − α + 1 #Cal + 1 . 2.2.1. Conformalized Quantile Regression (CQR) While this methodology is useful, its simplicity does not take into account the possible heteroscedasticity depending on the covariates. That is, a stronger property that would be desirable is conditional coverage: P (yn+1 ∈ Cα,n+1|xn+1 = x) ≥ 1 − α ∀ x ∈ R m. Although guaranteeing this property is not possible (Vovk, 2012; Lei and Wasserman, 2014), a variety of works have been developed to approximate it as best as possible. The most popular of these is probably the Conformalized Quantile Regression (CQR) proposed in Romano et al. (2019). CQR follows the conformal 2The +∞ is needed to take into account the n + 1 observation. 10 methodology to correct the coverage obtained by estimating the quantiles through a quantile regression procedure. Although there is no theoretical result related to conditional coverage, as the correction is performed on these estimated conditional quantiles, it is expected that heteroscedasticity is captured with much better quality than with the traditional conformal approach. The CQR methodology for an objective miscoverage rate of α could be summed up as: 1. Randomly split the n known points into two sets: training, Tr, and calibration, Cal. Tr, Cal ⊂ {1, . . . , n}. 2. Obtain a first approximation of lα,i and uα,i, ˆlα,i and ˆuα,i, i ∈ Cal ∪ {n + 1} by some quantile regression algorithm using only the training set for training. Predict over the calibration set and the observation of interest n + 1. 3. Compute the following conformity scores: S = {Si : i ∈ Cal} ∪ {+∞} where Si = max { yi − ˆuα,i, ˆlα,i − yi} ∀ i ∈ Cal 4. Compute the ⌈(|SCal|+1)(1−α)⌉ |SCal| quantile of the conformity scores. We will denote it by Q1−α(S). 5. The final conformalized prediction interval for the observation n + 1 is given by ˆCα,n+1 = [ ˆlα,n+1 − Q1−α(S), ˆuα,n+1 + Q1−α(S) ] Theorem 2 (Romano et al. (2019)). Let (xi, yi)n+1 i=1 be exchangeable. Applying CQR (xi, yi)n i=1 produces a prediction interval ˆCα,n+1 such that: P (yn+1 ∈ ˆCα,n+1) ≥ 1 − α. Moreover, if the conformity scores {Si}i∈Cal ∪ {+∞} are almost surely distinct, then the prediction interval is nearly perfectly calibrated: P (yn+1 ∈ ˆCα,n+1) ≤ 1 − α + 1 #Cal + 1 . The algorithm has shown such positive qualities that it has become the standard in Conformal Prediction for regression. For more details of the CQR algorithm we refer to Romano et al. (2019). 11 2.2.2. Adaptive Conformal Inference (ACI) CQR or any other conformal algorithm following the presented scheme depends on the condition of exchangeability between observations. In time series, which are the problems we are interested in, this condition is not fulfilled. Removing the condition of exchangeability while maintaining the validity property of the intervals has been one of the primary research objectives in the field. One such work is the Adaptive Conformal Inference (ACI) method proposed by Gibbs and Cand`es (2021). The application of ACI over the CQR procedure with α∗ as the objective miscoverage rate looks as follows. Let α1 = α∗, err1 = 0 and γ > 0.    αt+1 = αt + γ(α∗ − errt) errt = { 1 if yt ̸∈ ˆCα∗,t 0 otherwise ˆCα∗,t+1 = [ ˆlα∗,t+1 − Q1−αt+1(S), ˆuα∗,t+1 + Q1−αt+1(S)] It is a CQR procedure where the quantile used to make the correction is not necessarily that of the target coverage. It is taken adaptive depending on whether too large or too small intervals are being considered. The speed of adaptation is determined by the parameter γ. The following result can be derived: Theorem 3 (Gibbs and Cand`es (2021)). With probability one it follows that for all T ∈ N, ∣ ∣ ∣ ∣ ∣ 1 T T∑ t=1 errt − α∗∣ ∣ ∣ ∣ ∣ ≤ max {α1, 1 − α1} + γ T γ . In particular, lim T →∞ 1 T T∑ t=1 errt = α∗. In other words, there is asymptotic marginal coverage. For more details on the ACI algorithm we refer to Gibbs and Cand`es (2021) and Zaffran et al. (2022). 12 3. Our proposal Previous research has examined the issue of providing valid and efficient prediction intervals for individual values. A comprehensive analysis of the coverage of prediction bands, as well as of the interval lengths associated, based on this individual approach reveals significant issues which were described in Section 1.The first is that the length of the intervals varies depending on the difficulty of the observation to be predicted. That is, there should be an increasing relationship between the error of the point forecasting model and the length of the proposed interval. To our knowledge, the only work that uses point predictors to obtain prediction intervals, as in the context in which we are, is the QRA described in Section 2.1.1. However, its approach does not take this desired property into account. We are going to propose a model in the same spirit as the QRA, but taking into account this feature we are looking for. 3.1. Heteroscedastic Quantile Regression (HQR) The QRA model expresses the quantile of interest as a linear combination of point predictors of the mean. The effectiveness shown by this model manifests that the information given by different predictors of the event of interest provides information when quantifying the associated uncertainty. It is clear that having different predictors of the expected value can provide information on the safety of the prediction: in very common situations for the model, i.e. in areas where the space of regressor variables is highly explored, all forecasters are likely to obtain very similar predictions. However, in the more unfamiliar situations, which generally correspond to unexplored areas where models have to extrapolate, the forecasts start to differ and, in particular, the error of the models in such cases is generally larger (Figure 2). In other words, the uncertainty in unknown conditions is higher than in typical conditions. We believe that a good indicator of the level of exploration of the explanatory features space is a dispersion measure of the prediction of the different models. Thus, denoting by ˆyt = 1 M M∑ i=1 ˆyt,i and s2 ˆyt = 1 M M∑ i=1 (ˆyt,i − ˆyt)2 the following quantile 13 Figure 2: The joint distribution of two explanatory features is shown on the left. On the right, the expected error for a predictive model is plotted as a function of the two features. One would expect to have a higher error in the unexplored areas of the space, while a lower error would be expected in the very common areas. The plot is for guidance as the model could have good extrapolation properties in some situations. regression model is proposed: qt(β) = λ0(β) + λ1(β)ˆyt + λ2(β)sˆyt + εt(β), E [εt(β)] = 0, (3) where the parameters are obtained by minimizing the pinball loss (2.1) and vary over time in the same way as in (1). In particular, for the α 2 and 1 − α 2 quantiles of interest, we have: {ˆqT +1( α 2 ) = ˆλ0( α 2 ) + ˆλ1( α 2 )ˆyT +1 + ˆλ2( α 2 )sˆyT +1 ˆqT +1(1 − α 2 ) = ˆλ0(1 − α 2 ) + ˆλ1(1 − α 2 )ˆyT +1 + ˆλ2(1 − α 2 )sˆyT +1 Intuitively, we would expect high values of the λ2(β) parameter for quantiles further away from the median with a positive sign for quantiles greater than 0.5 and a negative sign for quantiles less than 0.5. Similarly, smaller values of λ2(β) would be found for quantiles close to the median. If this behaviour occurs, then we 14 would have the relationship between the length of the interval and the error that we are looking for (Appendix A). Note that (3) is actually an extension of the QRA model defined in (1). In the case of the QRA model, what is being done is to estimate the mean through a weighted average, which results in different values of the coefficients λ1, . . . , λM . That is, the QRA model is a model of the type qt(β) = λ0(β) + λ1(β)ˆyt + εt(β), E [εt(β)] = 0, where the estimation ˆyt is not done with equal weights. In that sense, we are extending the model with a further component that refers to a first assessment of the level of uncertainty that exists. Because this extension is directly related to the heteroscedasticity of the predictions, the model has been named Heteroscedastic Quantile Regression (HQR). 3.2. Width-Adaptive Conformal Inference The other property we are looking for is to have the same level of confidence regardless of the difficulty of the prediction. That is, the coverage should not depend on the complexity of the situation. It has been established that an indicator of the difficulty is the length of the interval, which in our case is constructed by a quantile regression process. We denote this interval at time T + 1 by Cα,T +1. To guarantee the desired property, this interval will be modified by constructing a second one, denoted by C c α,T +1, such that it is satisfied that P (yT +1 ∈ C c α,T +1| |Cα,T +1| ) = P (yT +1 ∈ Cα,T +1) ≥ 1 − α. Since we are trying to achieve a conditional probability, we will draw on ideas from works on conditional Conformal Prediction. In particular, one path to achieve conditional coverage is based on using weighted empirical distributions. That is, not all observations contribute the same. In Tibshirani et al. (2019) it is shown that this weighted based Conformal Prediction also maintains the marginal coverage property. In addition, in works such as Guan (2023) or Han et al. (2022) it is shown that giving weights to the observations as a function of the distance between Xi and XT +1 ∀i ∈ Cal results in asymptotic conditional coverage, i.e, if T −→ ∞, then P (yT +1 ∈ Cα,T +1|XT +1) ≥ 1 − α. Intuitively, if one focuses on certain features and considers previous samples with similar values of those features, (asymptotic) conditional coverage with 15 respect to those features is obtained. We can do the same with the length of the interval. As we are working with time series, we will modify the ACI method to apply a different α as a function of time, like the original method, and also as a function of the length of the interval. Notation 1. Let v ∈ R n be a vector of length n. The element in position i of v, i = 1, . . . , n is denoted by v [i]. The p power of v is defined as the p power of each one of the elements of v. vp = (v [1] p , v [2] p , . . . , v [n]p) . The absolute value of v is defined as the absolute values of each one of the elements of v. |v| = (|v [1] |, |v [2] |, . . . , |v [n] |) Let S be the conformity scores (Section 2.2.1). Given a step h ∈ R +, the 1-d grid long is defined as long = (longmin, longmin + h, longmin + 2h, . . . , longmax) ∈ R n. Let’s denote by |Cα,t| the lenght of the interval of the quantile regession algorithm: |Cα,t| = ˆuα∗,t − ˆlα∗,t ∀ t ∈ Cal ∪ {T + 1}. Let α∗ be the objective miscoverage rate. The application of WACI (Width-Adaptive Conformal Inference) over the CQR procedure looks as follows. Let α1 = (α∗, α∗, . . . , α∗) ∈ R n, err1 = 0, γ, σ > 0.    αt+1 = αt + γwt(α∗ − errt) errt = { 1 if yt ̸∈ ˆC c α∗,t 0 otherwise distt = |long − |Cα,t|| wt = exp ( −dist 2 t 2σ2 ) max { exp ( −dist 2 t 2σ2 )} idxt+1 = argmin {long [i] − |Cα,t+1| : i = 1, . . . , n} ˜αt+1 = αt+1 [idxt+1] C c α∗,t+1 = [ ˆlc α∗ t , ˆu c α∗ t ] = [ ˆlα∗,t+1 − Q1− ˜αt+1(S), ˆuα∗,t+1 + Q1− ˜αt+1(S) ] (4) The first difference that can be seen with the ACI method is that in this case there is not a single αt in each iteration, but a vector αt. This is done in order to be able to differentiate the real scalar ˜αt that will actually be used in that iteration, 16 which will depend on the length of the interval. That is, each element of the vector is associated with a different length of the initial interval. The possible different initial interval lengths considered are set through the 1-d grid long. Thus, αt [i] is the ˜α to be used when the length of the initial interval of the observation at time t is long[i] (or long[i] is the closest of all those considered in long). The update of αt is done in the same way as in ACI. However, as the conformal correction is being done as a function of interval length, only the positions associated with that interval length (and close to it) are updated. To do this, the weight vector wt is constructed through a Gaussian kernel, so a new parameter σ related to the amplitude of the kernel effect is introduced. The difference between the ACI and WACI methods throughout iterations is shown in Figure 3. The upper graph in Figure 3 shows the first iteration of both methods. Here the methods coincide, as both start from the target α. In the next iteration (second graph from above) the methods vary, although very slightly: the ACI method uses a slightly different α but for all possible interval lengths, while WACI only makes this modification for initial interval lengths close to those of the previous observation. The ACI method always shows a horizontal line, while WACI shows variations, to the point of using very different alphas at “close” lengths. The third and forth graph from the top correspond to subsequent iterations. In the case of the algorithm presented in (4), an exponential decay as a function of distance has been chosen. Of course, different weighting schemes can be considered. A scheme of fixed weights as a function of the position in the vector could also be considered, for example, one where the weights of each interval follow a geometric progression. That is, let long = (longmin, longmin + h, longmin + 2h, . . . , longmax) ∈ R n+13, then wt [j] = λ|i−j|, |Cα,t| ∈ int[i] ≡ [long [i] , long [i + 1]) , (5) where i = it is the index of the interval length for the sample t. Figure 4 shows the difference between the two proposed weighting schemes. 3Here, we are considering n + 1 points in the grid as we are interested in n intervals so each position of αt is associated with each interval in contrast to the previous case where αt is associated with each extreme of the interval. 17 0 20 40 60 80 100 Interval length 0.100 0.125 0.150 0.175 0.200 0.225 0.250 0.275 0.300αt Objective miscoverage WACI ACI 0 20 40 60 80 100 Interval length 0.100 0.125 0.150 0.175 0.200 0.225 0.250 0.275 0.300αt Objective miscoverage WACI ACI . . . 0 20 40 60 80 100 Interval length 0.100 0.125 0.150 0.175 0.200 0.225 0.250 0.275 0.300αt Objective miscoverage WACI ACI . . . 0 20 40 60 80 100 Interval length 0.100 0.125 0.150 0.175 0.200 0.225 0.250 0.275 0.300αt Objective miscoverage WACI ACI Figure 3: Evolution of αt in the ACI (orange line) and WACI (blue line) methods. The α used in each iteration per interval length is shown. 18 20 21 22 23 24 25 26 0 0.2 0.4 0.6 0.8 1 xy WACI Weights 1 WACI Weights 2 0 20 40 60 80 100 Interval length 0.100 0.125 0.150 0.175 0.200 0.225 0.250 0.275 0.300αt Objective miscoverage WACI WACI 2 ACI Figure 4: (Top) Comparing the different weights schemes presented for the WACI algorithm. The exponential decay weight is shown before scaling. (Bottom) The behaviour of the two schemes can be very similar in practice. Despite their differences, by selecting the parameters σ and λ in a certain way, the behaviour of both can be very similar. Indeed, if the weighting scheme (5) is considered, asymptotic conditional coverage can be proved with respect to each of the intervals considered in the grid long. Theorem 4. Let’s assume there exists δ ∈ N such that αt [i] ∈ [−δ, 1 + δ] for all i = 1, . . . , n and t ∈ N. Let i ∈ {1, ..., n} such that there is an infinite number of t ∈ int [i]. If T −→ ∞ and the weighting scheme of (5) is considered, then P (yT +1 ∈ ˆC c α∗,T +1 | |Cα,T +1| ∈ int [i]) = 1 − α∗, where α∗ is the objective miscoverage rate and |Cα,T +1| is the length of the first interval produced at time step T + 1. 19 Proof. The equation of the process is given by αT +1 = αT + γwT (α∗ − errT ). Expanding the recursion we have αT +1 = α1 + T∑ t=1 γwt (α∗ − errt) . In particular, for each position i, we have αT +1 [i] − α1 [i] = T∑ t=1 γwt [i] (α∗ − errt) . that can be decomposed based on the weight updated carried out during each iteration as αT +1 [i] − α1 [i] = n∑ j=1 ∑ t∈int[j] γλ|i−j| (α∗ − errt) Denoting by bk = αT +1[k]−α1[k] γ and ck = ∑ t∈int[k] (α∗ − errt) for k = 1, . . . , n; bi = ci + ∑ j̸=i λ |i−j|cj, for i = 1, . . . , n. By construction, we have the following system of equations:      b1 b2 ... bn      ︸ ︷︷ ︸ b =      1 λ −1 λ −2 . . . λ−(n−1) λ −1 1 λ −1 . . . λ−(n−2) ... ... ... . . . ... λ −(n−1) λ−(n−2) λ−(n−3) . . . 1      ︸ ︷︷ ︸ L      c1 c2 ... cn      ︸ ︷︷ ︸ c The matrix L is a Toeplitz matrix equivalent to the correlation matrix of a Markov-1 signal. As discussed in Britanak et al. (2007), the inverse of L exists (and it is known) and, therefore, c = L−1b. Let i ∈ {1, . . . , n} such that {t ∈ int[i] ∩ N} has an infinite number of elements and let Ti = # {t ∈ int[i] : t = 1, . . . , T }. Then, as L−1 and b are bounded, we have 20 lim T →∞ 1 Ti ∥c∥2 = lim T →∞ 1 Ti ∥L−1b∥2 = 0. This implies lim T →∞ 1 Ti c = 0 =⇒ lim T →∞ ci Ti = lim T →∞ 1 Ti ∑ t∈int[i] errt − α∗ = 0, which gives the result P (yT +1 ∈ ˆC c α∗,T +1 | |Cα,T +1| ∈ int [i]) = T −→∞ 1 − α∗ In view of Theorem 4, asymptotic coverage conditional on the difficulty of the prediction is obtained, where that difficulty is measured by the length of the interval of the first quantile regression algorithm used. As a consequence, asymptotic marginal coverage is also achieved, as in the original ACI algorithm. The only assumption made to obtain the result is that the value of α is bounded for every position. Although this is not formally proven, it seems a reasonable feature of the algorithm. Considering that every time the value of a certain position of α is greater than 1 or less than 0, if the α of that position is used in a certain iteration, it is forced to reduce or increase that value respectively, which controls the explosion of that value. The only possible way that there are no limits on the value of a certain α position is that once the value 1 (from above) or 0 (from below) is exceeded, that position is not worked on again too many times when compared to others and that distant positions continuously increase or decrease that value at a faster rate. Such behaviour is irrational, as one expects to go through the different α positions over the iterations more or less uniformly and altering the values both up and down. 4. Real data examples To test the effectiveness of the final proposed method, WACI-HQR, we will compare the different interval construction schemes presented during the paper. As quantile regression methods, the QRA model and our HQR model will be compared. Also, we will compare the different stages of conformal post-processing on the two quantile regressions considered: the conformalization of the prediction bands, CQR, and the adaptive versions of the same ACI-CQR and WACI-CQR, which will be denoted as ACI and WACI, respectively. In this way, it will be 21 possible to assess the value of each modelling step on the desired properties of the intervals: from the initial quantile regression to the final adaptive conformal model. For the application of WACI the weights shown in (4) are used. The results with the weights described in (5) are almost equivalent. 4.1. Data 4.1.1. Electricity Price Forecasting (EPF) Data for the Day-Ahead market price in Spain and four different one day-ahead point forecasters (M = 4, Figure 5) is available from 1st of January 2022 to 5th of October 2023. The period from 5th of October 2022 to 5th of October 2023 is considered as test data. This is the window where conformal methods are applied. In order for these methods to be applied, quantile regression forecasts must be available. These will be obtained from 8th of April 2022 (Figure 6). We believe that this period is ideal for testing this type of models because moments of great uncertainty can be observed at the same time as very steady phases. 2022−03−05 2022−03−06 2022−03−07 2022−03−08 2022−03−09 2022−03−10 2022−03−11 2022−03−12 Date 200 300 400 500 600 700Price(€/MWh) Spanish Day-Ahead market price forecasts Model 1 Model 2 Model 3 Model 4 Figure 5: One week example of the 4 different point forecasters for the EPF example. 22 2022−01 2022−04 2022−07 2022−10 2023−01 2023−04 2023−07 2023−10 Date 0 100 200 300 400 500 600 700Price(€/MWh) Quantile Regression predictions Conformal prediction methods Spanish Day-Ahead market price Figure 6: Time series of the Spanish Day-Ahead market between 1st of January 2022 and 5th of October 2023. The predictions of the quantile regression algorithms are obtained from 8th of April 2022 until the end. The Conformal Prediction methods are applied from 5th October 2022. When forecasting the price one day in advance, it must be predicted for the 24 hours of the next day. Thus, there are two ways of proceeding with the quantile regression: consider 24 daily series (one per hour) and a quantile regression model for each one of these series or a single hourly frequency series and therefore a single quantile regression model for all hours. In any case, a training rolling window of 180 days is considered. That is, at the time of predicting the day D, data from days D − 180 to D − 1 are considered to train the quantile regression models. For the day D + 1, the window from D − 179 to D is considered for training and so on. For those days for which the training window is shorter than 180 days due to data unavailability, all available data will be used. The size of 180 days has been selected empirically after observing the results with several windows. Conformalization is always carried out individually for each hour. For the adaptive methods we will take γ = 0.02, which seems reasonable in view of previous studies (Zaffran et al., 2022) and for the WACI approach σ = 3, which also provides an appropriate performance given the price scale. With all these distinctions, 16 possible methodologies will be compared over a test period of one year. Four possible values of α will be distinguished: 0.2, 0.1, 0.05, 0.01, which correspond to coverage values of 80, 90, 95 and 99%, respectively. 23 4.1.2. Wind Power Forecasting (WPF) Data on wind power generated in Spain and three different 24 hour-ahead point forecasters (M = 3, Figure 7) is available from 13th of March 2020 to 31st of December 2021. The period from 1st of January 2021 to 31st of December 2021 is considered as test data. Quantile regression forecasts will be obtained from 5th of July 2020 (Figure 8). 2021−03−05 2021−03−06 2021−03−07 2021−03−08 2021−03−09 2021−03−10 2021−03−11 2021−03−12 Date 2 4 6 8 10GWh Wind power forecasts Model 1 Model 2 Model 3 Figure 7: One week example of the 3 different point forecasters for the WPF example. 2020−04 2020−07 2020−10 2021−01 2021−04 2021−07 2021−10 2022−01 Date 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0GWh Quantile Regression predictions Conformal prediction methods Wind Power Figure 8: Wind power generation time series between 13th of March 2020 and 31st of December 2023. The predictions of the quantile regression algorithms are obtained from 5th of April 2020 until the end. The Conformal Prediction methods are applied from 1st January 2021. 24 Unlike the approach for pricing, in the case of wind power production such differentiation between hours is not applied. A global model that takes into account the 24 hours of the day is considered. In this case, where hours are not differentiated, we employ two quantile regression models combined with three conformal post-processing techniques, resulting in a total of eight methodologies to be evaluated. For this example, a training window of 180 days is considered, although notably effective results have also been observed with larger windows. For those days for which the training window is shorter than 180 days due to data unavailability, all available data will be used. It should be noted that the generation of the last 24 hours is not accessible. For the adaptive methods we will take γ = 0.02 and for the WACI approach σ = 0.5, again due to the scale of the data. Four possible values of α will be distinguished: 0.2, 0.1, 0.05, 0.01. 4.2. Evaluation metrics The empirical coverage is used to measure the validity property: if there are N predictions, the empirical coverage on those predictions is defined as 1 N N∑ i=1 1 { ˆlα,i ≤ yi ≤ ˆuα,i} . For an objective miscoverage rate of α, the empirical coverage is sought to be as close to 1 − α as possible. There is a consensus that overcoverage is preferred to undercoverage, so the intervals are valid. The efficiency is usually measured through the mean or median interval length. The adaptive conformal procedures are not limited in the modification of α over time. Although theoretically this makes sense, in practice getting infinite or empty intervals does not add much value. Thus, a practical modification is made to these methods. If the α value of the next iteration is greater than one or less than zero, α is not modified. Thus, the mean and median of the interval length are also used. These efficiency measures, while informative, do not allow comparison of different methodologies unless they produce the same level of empirical coverage, which is unlikely. The Winkler score (Winkler, 1972) is used to measure validity and efficiency together. For each time step t and for a miscoverage rate of α, it is defined as the length of the interval plus a penalty term proportional to how far the prediction is from being in the interval: Wα,t =    (ˆuα,t − ˆlα,t) + 2 α(ˆlα,t − yt) if yt < ˆlα,t (ˆuα,t − ˆlα,t) if ˆlα,t ≤ yt ≤ ˆuα,t (ˆuα,t − ˆlα,t) + 2 α(yt − ˆuα,t) if yt > ˆuα,t 25 Thus, better intervals will have smaller Winkler score. The Winkler score is actually a proper scoring rule (Gneiting and Raftery, 2007) and so, the mean Winkler score over every interval forecast will be also measured. The main limitation of the Winkler score is that it lacks intuitive interpretability when considered in isolation; it primarily serves as a comparative metric for assessing different prediction intervals. While the mean and median lengths of the intervals can offer some insight into their behaviour, these statistics alone do not provide a comprehensive understanding of how the intervals function. The quantile (X-axis) vs. inverse quantile of the interval length (Y-axis) plot will also be performed to observe the distribution of the interval length and to observe its variance and behaviour beyond the mean/median situation. This chart is in fact a reduced version of the inverse empirical interval length distribution function for each method that allows for a better comparison of the methods with each other. Getting intervals that vary depending on the error of the point forecasting model is an important characteristic. Thus, groups of observations of the same size will be made, having previously ordered them by interval length 4. The mean absolute error (MAE) for point predictions on each of these groups will be computed. If the error is increasing between groups, then the intervals are informative and are a first step to be able to use them correctly in decision support. Similarly, to assess if coverage is independent of the length of the interval, these groups will be made again and the coverage in each of them will be checked. The mean deviation of each of these groups from the target coverage and the maximum deviation will be calculated as metrics to measure this property. As these measures depend on the formation of the groups, different group sizes will be taken into account: groups consisting of 5% and 10% of the observations will be considered. Since in the EPF example 24 different forecasts are being evaluated at each step, the hourly empirical coverage will also be measured for this particular case. 4The quantiles of the interval length will be used to create these groups. That is, the observations with interval size 0% to the largest 5%, from 5% to 10%, from 10% to 15% and so on. 26 5. Results and discussion 5.1. Electricity Price Forecasting (EPF) The results for the EPF data are shown in Table 1. As the hourly quantile regression models performed considerably worse compared to the consideration of a single time series, only the results for the latter situation are shown. The results of the QRA and HQR models by hours are shown in Appendix B. For every α, it is seen that the HQR model performs better than the QRA model. In particular, higher coverage values are obtained with smaller intervals, as shown by the mean or median interval length. This results in noticeable differences in the Winkler score. The differences between the models are not reduced by applying conformal procedures, they remain at the same level. Thus, the HQR model is a superior option to the QRA. The standard CQR procedure contributes nothing in particular, it does not improve in any case the results of quantile regression alone. For α = 0.01 or α = 0.05 the intervals are worse. For α = 0.10 or α = 0.20 the intervals are similar. This could be due to the absence of the exchangeability condition in the series. With respect to the ACI method, there is a tendency to undercover compared to the rest of the methods. In particular, in the extreme case of α = 0.01, the coverage is well below the 99% desired and this undercoverage is not rewarded by making very efficient intervals, as the Winkler score is very large. Even so, for the rest of the cases, the Winkler score is the best or very similar to the best. The WACI method always obtains valid intervals and the Winkler score levels are always comparable to the best. The performance on the extreme case at 99% is very remarkable, where it is the only conformal method that keeps up with the HQR with respect to the Winkler score and with almost exact coverage. From now on, only the HQR and QRA models are considered, as well as the different conformalizations of the former due to its superior performance. With regard to the distribution of the length of the intervals, Figures 9, 10, 11 and 12 summarise this aspect. 27MethodObj.Coverage=99%(α=0.01)Obj.Coverage=95%(α=0.05)Emp.Cov.MeanI.L.MedianI.L.WSEmp.Cov.MeanI.L.MedianI.L.WSHQR99,11109,32110,04126,3296,1274,5975,9091,00QRA98,88114,80116,35139,3995,9878,3981,2396,34CQR-HQR99,26118,02115,45130,3896,9079,6781,8192,45CQR-QRA99,48133,39134,55143,3296,6284,1486,8197,56ACI-HQR97,7289,6388,11133,0294,9172,9272,5691,33ACI-QRA97,89100,0099,28144,9494,7977,1678,4496,42WACI-HQR99,04111,20107,29127,5796,5878,3880,5992,43WACI-QRA99,27124,38124,57137,4196,6382,7486,8897,07MethodObj.Coverage=90%(α=0.10)Obj.Coverage=80%(α=0.20)Emp.Cov.MeanI.L.MedianI.L.WSEmp.Cov.MeanI.L.MedianI.L.WSHQR92,5258,1259,1574,8784,1542,1143,3459,36QRA92,3959,5261,6777,9484,2742,9144,6660,88CQR-HQR92,3959,0561,0274,9282,9242,0343,8059,32CQR-QRA92,4561,4264,0178,2183,2743,0245,0160,73ACI-HQR89,7554,9554,2274,2379,6139,1538,2058,90ACI-QRA89,8256,8056,2277,3779,5939,6939,3960,30WACI-HQR92,0058,0660,1574,6482,1641,0142,6059,05WACI-QRA92,2561,2164,9077,6482,9242,2344,5560,03Table1:ResultsintheEPFexample. 28 0.0 0.2 0.4 0.6 0.8 1.0 Quantile 50 75 100 125 150 175 200Intervallength Interval length distribution HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 9: Distribution of the interval length for α = 0.01 in the EPF dataset. 0.0 0.2 0.4 0.6 0.8 1.0 Quantile 20 40 60 80 100 120 140 160Intervallength Interval length distribution HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 10: Distribution of the interval length for α = 0.05 in the EPF dataset. 29 0.0 0.2 0.4 0.6 0.8 1.0 Quantile 20 40 60 80 100 120Intervallength Interval length distribution HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 11: Distribution of the interval length for α = 0.10 in the EPF dataset. 0.0 0.2 0.4 0.6 0.8 1.0 Quantile 10 20 30 40 50 60 70 80Intervallength Interval length distribution HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 12: Distribution of the interval length for α = 0.20 in the EPF dataset. The first point to note is that the HQR method and QRA show relatively similar behaviour for every α, but with considerably smaller intervals across the whole distribution for the former. This explains why the observed Winkler score 30 was so much better (Table 1). A clear difference can also be observed in the upper tail of the distribution, where situations of higher uncertainty are clearly differentiated from the rest in the case of the HQR. Interestingly, the ACI method shows the smallest intervals throughout the distribution except for the upper quantiles, where the jump is noticeable and it becomes the method with the largest intervals. This happens for all α, although for α = 0.01 the ACI method does not obtain valid intervals. Take into account that this property could not be observed with just the mean or the median interval length. The comparison between the HQR method and its WACI variation is of interest: WACI prefers to use smaller intervals in the lower tail, larger intervals in the upper tail and shows similar behaviour in situations close to the median. This is one of the key methodological differences with ACI, as a different adaptation can be seen depending on the interval length. An important aspect to consider is that the intervals produced through conformal procedures are more diverse. Although the validity and efficiency metrics are similar to not applying them, we can differentiate situations more easily when conformal methods are applied. As has been explained several times in the paper, although the ranges are more varied for HQR and its conformal modifications than for QRA, this variation must be linked to the difficulty of the prediction. Figures 13, 14, 15 and 16 discuss this quality. The construction of the HQR model has focused on this characteristic. Every α show the same properties: the HQR model captures this behaviour very well and the length of the interval is correctly related to the error being made. However, the QRA model does not capture the uncertainty well, except perhaps for the case α = 0.05. Thus, it can be said that our intervals are informative, whereas the intervals produced by QRA can lead to errors in decision making by presenting inaccuracies (like saying that there is little uncertainty in situations of large error) in this regard. Furthermore, in this case also the conformal methods are slightly superior to HQR. Although all of them, except QRA, produce the desired increasing relationship, the conformal procedures manage to avoid even slight deviations. For example, look at the difference of groups (0.4, 0.5) and (0.5, 0.6) with groups (0.6, 0.7) and (0.7, 0.8) in Figures 13, 15 and 16. 31(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 6 8 10 12 14 16 18 20MAE MAE by interval length HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 13: MAE per group of observations for the EPF dataset, where the groups are formed according to the length of the intervals for α = 0.01(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 6 8 10 12 14 16 18 20MAE MAE by interval length HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 14: MAE per group of observations for the EPF dataset, where the groups are formed according to the length of the intervals for α = 0.05 32(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 6 8 10 12 14 16 18 20MAE MAE by interval length HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 15: MAE per group of observations for the EPF dataset, where the groups are formed according to the length of the intervals for α = 0.10(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 6 8 10 12 14 16 18 20MAE MAE by interval length HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 16: MAE per group of observations for the EPF dataset, where the groups are formed according to the length of the intervals for α = 0.20 Finally, it will be checked that, when considering a set of intervals, the coverage 33 does not depend on the length of the interval. That is, on the degree of difficulty of forecasting. For this purpose, the charts and the measures described in Section 4.2 are plotted/computed. For ease of comprehension, only the graphs considering 5% observations per group are shown. These are given in Figures 17, 18, 19 and 20. Table 2 shows the results of the coverage deviations for all cases. For α = 0.01 there is by itself not much scope for overcoverage and nothing particular is observed for this level in general, where all methods behave at acceptable levels even at their maximum deviation. However, for the rest of the α values the performance of the ACI method is of concern. The tendency of the method to undercoverage has been observed. However, it can be found here that this undercoverage is also related to the smaller intervals for the most part. If we look at the 5% groups of observations, the deviation from the target coverage is as high as 25%, which is unacceptable. In fact, an overconfidence bias is observed in the 10% of observations with smaller intervals. The WACI method corrects ACI by mitigating this bias. In fact, overall, it is either the best, or at similar levels compared to the best in terms of deviations by having the good properties of ACI, without the problems it presents in this regard. The quantile regression models themselves in fact appear to be well calibrated on their own in this respect, with no noticeable biases observed. One problem that all methods seem to present is that for observations with larger intervals there is underconfidence. In that case the smaller intervals would be preferred, which are associated with the QRA method (Figures 9 to 12), but this method does not provide fully informative intervals (Figures 13 to 16), so the HQR model would be the best choice for such cases. Moreover, if in Table 2 one looks at the deviations of each method for the 5% groups, the WACI method is not the best by a noticeable margin, however the few observations per group may distort the results somewhat, as only one year (365 days per hour) is being analysed and the fact that the conformalization is done by hour and by interval length makes the number of samples for each interval very small. Analizing the 10% groups where the number of samples per interval is big enough, the WACI method is clearly the one with smallest deviations except in the case α = 0.05, where it is in line with the best. Notably, improvement of maximum deviations with respect to HQR are around 20% for α = 0.10 and α = 0.20. 34(0.0,0.05)(0.05,0.1)(0.1,0.15)(0.15,0.2)(0.2,0.25)(0.25,0.3)(0.3,0.35)(0.35,0.4)(0.4,0.45)(0.45,0.5)(0.5,0.55)(0.55,0.6)(0.6,0.65)(0.65,0.7)(0.7,0.75)(0.75,0.8)(0.8,0.85)(0.85,0.9)(0.9,0.95)(0.95,1.0) Quantile (IW) 95 100EmpiricalCoverage Coverage by interval length HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 17: Empirical coverage per group of observations for the EPF dataset, where the groups are formed according to the length of the intervals for α = 0.01(0.0,0.05)(0.05,0.1)(0.1,0.15)(0.15,0.2)(0.2,0.25)(0.25,0.3)(0.3,0.35)(0.35,0.4)(0.4,0.45)(0.45,0.5)(0.5,0.55)(0.55,0.6)(0.6,0.65)(0.65,0.7)(0.7,0.75)(0.75,0.8)(0.8,0.85)(0.85,0.9)(0.9,0.95)(0.95,1.0) Quantile (IW) 80 85 90 95 100EmpiricalCoverage Coverage by interval length HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 18: Empirical coverage per group of observations for the EPF dataset, where the groups are formed according to the length of the intervals for α = 0.05 35(0.0,0.05)(0.05,0.1)(0.1,0.15)(0.15,0.2)(0.2,0.25)(0.25,0.3)(0.3,0.35)(0.35,0.4)(0.4,0.45)(0.45,0.5)(0.5,0.55)(0.55,0.6)(0.6,0.65)(0.65,0.7)(0.7,0.75)(0.75,0.8)(0.8,0.85)(0.85,0.9)(0.9,0.95)(0.95,1.0) Quantile (IW) 65 70 75 80 85 90 95 100EmpiricalCoverage Coverage by interval length HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 19: Empirical coverage per group of observations for the EPF dataset, where the groups are formed according to the length of the intervals for α = 0.10(0.0,0.05)(0.05,0.1)(0.1,0.15)(0.15,0.2)(0.2,0.25)(0.25,0.3)(0.3,0.35)(0.35,0.4)(0.4,0.45)(0.45,0.5)(0.5,0.55)(0.55,0.6)(0.6,0.65)(0.65,0.7)(0.7,0.75)(0.75,0.8)(0.8,0.85)(0.85,0.9)(0.9,0.95)(0.95,1.0) Quantile (IW) 45 50 55 60 65 70 75 80 85 90 95 100EmpiricalCoverage Coverage by interval length HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 20: Empirical coverage per group of observations for the EPF dataset, where the groups are formed according to the length of the intervals for α = 0.20 36 α 0.01 % obs. per group 5% 10% Method Mean Deviation Max Deviation Mean Deviation Max Deviation HQR 0.61 2.64 0.56 1.16 QRA 0.76 2.64 0.74 1.62 CQR-HQR 0.60 1.05 0.50 0.93 ACI-HQR 1.36 3.77 1.29 2.87 WACI-HQR 0.56 1.28 0.46 0.93 α 0.05 % obs. per group 5% 10% Method Mean Deviation Max Deviation Mean Deviation Max Deviation HQR 1.83 4.09 1.60 3.18 QRA 1.69 3.41 1.58 3.41 CQR-HQR 2.20 4.32 2.00 3.18 ACI-HQR 2.17 13.18 2.03 7.86 WACI-HQR 1.93 4.09 1.63 3.52 α 0.10 % obs. per group 5% 10% Method Mean Deviation Max Deviation Mean Deviation Max Deviation HQR 3.46 7.49 2.98 5.79 QRA 3.27 7.73 2.77 7.16 CQR-HQR 3.42 9.32 3.11 4.99 ACI-HQR 3.07 20.91 3.07 13.21 WACI-HQR 2.76 7.50 2.69 4.88 α 0.20 % obs. per group 5% 10% Method Mean Deviation Max Deviation Mean Deviation Max Deviation HQR 5.06 12.48 4.50 10.32 QRA 4.79 13.85 4.26 11.69 CQR-HQR 4.96 18.18 4.91 9.92 ACI-HQR 4.52 25.00 3.95 17.20 WACI-HQR 4.04 13.41 3.97 7.99 Table 2: Mean and maximum deviation of each model from the objective coverage by interval length for the EPF dataset. 37 As a final analysis, the effect of hourly conformalization has been studied. The empirical hourly coverage is shown in Figures 21, 22, 23 and 24. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Hour 96.0 96.5 97.0 97.5 98.0 98.5 99.0 99.5 100.0EmpiricalCoverage Coverage by hour HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 21: Coverage by hour for α = 0.01 in the EPF dataset. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Hour 90 92 94 96 98 100EmpiricalCoverage Coverage by hour HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 22: Coverage by hour for α = 0.05 in the EPF dataset. 38 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Hour 84 86 88 90 92 94 96 98 100EmpiricalCoverage Coverage by hour HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 23: Coverage by hour for α = 0.10 in the EPF dataset. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Hour 70 75 80 85 90 95 100EmpiricalCoverage Coverage by hour HQR QRA CQR-HQR ACI-HQR WACI-HQR Figure 24: Coverage by hour for α = 0.20 in the EPF dataset. In these figures, the tendency of the ACI method to undercoverage can be better appreciated, especially in the case of target coverage equal to 99%. Even so, this method presents a very good characteristic in the uniformity of the distribution of 39 coverage between hours. No other method achieves such good results in this sense. For further understading, the average deviation of each hour from the target coverage, the maximum deviation and the standard deviation of the deviations (as a measure of uniformity) have been computed. The results are shown in Tables 3 and 4. α 0.01 0.05 Method Mean deviation Max deviation Std. Mean deviation Max deviation Std. HQR 0.42 1 0.48 1.23 2.54 0.91 QRA 0.33 1.19 0.42 1.07 2.81 0.86 CQR-HQR 0.37 0.73 0.34 1.90 3.63 0.70 ACI-HQR 1.28 2 0.32 0.19 0.74 0.25 WACI-HQR 0.30 0.91 0.35 1.58 2.27 0.55 Table 3: Mean deviation, maximum deviation and standard deviation of the deviations of the coverage by hours in the EPF dataset. α = 0.01 and α = 0.05 α 0.10 0.20 Method Mean deviation Max deviation Std. Mean deviation Max deviation Std. HQR 2.61 5.08 1.65 4.15 10.16 2.45 QRA 2.39 4.26 1.36 4.31 9.34 2.73 CQR-HQR 2.39 4.26 1.05 2.94 7.70 1.95 ACI-HQR 0.29 0.66 0.24 0.48 1.04 0.39 WACI-HQR 2 3.72 0.90 2.16 4.15 1.04 Table 4: Mean deviation, maximum deviation and standard deviation of the deviations of the coverage by hours in the EPF dataset. α = 0.10 and α = 0.20 The positive comments on the ACI method are confirmed by the results. However, the WACI method shows exceptional performance in the case of the most extreme quantiles (α = 0.01) and shows more than competent results at all other levels. In fact, the conformalization step adds value in this respect, as even the CQR method improves results over the quantile regression alone. As the conformalization is being done on an hourly basis, what we are really looking at here is the marginal coverage of conformalization for each hour. Both ACI and WACI present theoretical guarantees that with infinite timesteps, this coverage has the desired level. However, it can be seen from these graphs that ACI 40 achieves these results faster than WACI. This is because ACI only makes modifications based on the last observation without discerning by interval length. In the case of WACI, you need many observations of all interval sizes considered, which is unlikely in the studied period (365 days). Thus WACI, despite showing good results, does not achieve the same level of performance as ACI in this respect. The performance should improve and be in line with the ACI method with enough observations. In conclusion, HQR has shown clear superiority to QRA in all aspects. Particularly, a big difference is observed in a correct quantification of the uncertainty by showing a relationship between the difficulty of the prediction and the length of the interval. The different conformalizations do not affect most of the characteristics and comparing the classical metrics, both ACI and WACI could be considered as the best models indistinctly. However, a clear bias can be seen in ACI by showing situations of overconfidence for the simplest predictions. WACI corrects this bias without considerably worsening any other characteristics. Everything considered, the WACI-HQR model would be the best in this example. 5.2. Wind Power Forecasting (WPF) The results associated with this example are given in detail in Table 5. This example shows a completely different behaviour from the previous one. In the case of EPF, there was a very noticeable gap between the QRA and HQR models. In this case, the two models show practically the same results for all levels of miscoverage targets. The same effect can be seen with the conformalizations. This is because for a large part of the time, the standard deviation feature is probably not significant in HQR. If that is the case, you really have two models that use only one estimator of the mean of the distribution of interest. In the HQR model all predictions are given equal weight and thus a single coefficient is used in the model. In the QRA model it is estimated as a weighted mean, resulting in M explanatory variables. This is discussed in Appendix A. However, there is a noticeable improvement in the adaptive conformal procedures, which in the previous case was not directly evident, but rather through the other characteristics studied. Between the ACI and WACI conformalizations, no major differences can be observed in this case. In the previous example ACI gave considerably smaller intervals, but penalised coverage significantly, whereas WACI aimed for efficiency within validity. In any case, the Winkler score values were similar. In this example, the Winkler score values are still comparable, but with both methods showing the same type of 41 behaviour. Only slight differences are observed for α = 0.01, where the WACI methodology shows the better results. For this same value of objective miscoverage, the HQR model shows clear superiority with respect to QRA, as was also the case in the previous example. It can also be seen again that the CQR conformalization does not bring any improvement, as expected. In view of these results, only the remaining characteristics for the ACI and WACI models are analysed. With regard to the distribution of the length of the intervals, Figures 25, 26, 27 and 28 summarise this aspect. The differences between ACI and WACI are much smaller in this case, regardless of the level of α. This was expected as it was already noted when discussing Table 5. The same behaviour is observed for every α, except for α = 0.01, where the length of the intervals is smaller for the hole distribution for the ACI methodology, but penalising the coverage. For the rest of α, WACI produces slightly larger intervals than ACI for about 40% of the smallest intervals and smaller for the top 40%, except for just the most extreme intervals, while the behaviour in the central area around the median is similar. There is no difference between QRA and HQR in this matter. 42MethodObj.Coverage=99%(α=0.01)Obj.Coverage=95%(α=0.05)Emp.Cov.MeanI.L.MedianI.L.WSEmp.Cov.MeanI.L.MedianI.L.WSHQR98,404,093,885,3194,152,972,883,95QRA98,124,033,865,4593,702,942,853,95CQR-HQR98,534,344,075,3594,733,102,923,90CQR-QRA98,424,354,065,3294,853,082,943,92ACI-HQR96,613,513,335,4693,792,802,673,54ACI-QRA96,683,503,295,5093,632,792,683,53WACI-HQR97,113,633,405,3394,092,852,713,56WACI-QRA97,073,663,405,4394,022,842,743,59MethodObj.Coverage=90%(α=0.10)Obj.Coverage=80%(α=0.20)Emp.Cov.MeanI.L.MedianI.L.WSEmp.Cov.MeanILMedianILWSHQR88,542,422,353,3778,451,811,772,75QRA88,702,392,333,3678,681,811,772,75CQR-HQR90,022,542,453,3479,931,891,842,73CQR-QRA89,832,502,433,3380,101,871,842,73ACI-HQR89,352,412,313,0779,701,881,822,58ACI-QRA89,282,382,323,0679,751,861,812,57WACI-HQR89,512,392,313,0879,921,871,792,58WACI-QRA89,512,372,303,0779,951,861,792,57Table5:ResultsintheWPFexample. 43 0.0 0.2 0.4 0.6 0.8 1.0 Quantile 2 3 4 5 6 7Intervallength Interval length distribution ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 25: Distribution of the interval length for α = 0.01 in the WPF dataset. 0.0 0.2 0.4 0.6 0.8 1.0 Quantile 1 2 3 4 5 6Intervallength Interval length distribution ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 26: Distribution of the interval length for α = 0.05 in the WPF dataset. 44 0.0 0.2 0.4 0.6 0.8 1.0 Quantile 1 2 3 4 5Intervallength Interval length distribution ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 27: Distribution of the interval length for α = 0.10 in the WPF dataset. 0.0 0.2 0.4 0.6 0.8 1.0 Quantile 1.0 1.5 2.0 2.5 3.0 3.5 4.0Intervallength Interval length distribution ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 28: Distribution of the interval length for α = 0.20 in the WPF dataset. Figures 29, 30, 31 and 32 discuss the relationship between the interval length and the difficulty of the prediction. 45(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1MAE MAE by interval length ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 29: MAE per group of observations for the WPF dataset, where the groups are formed according to the length of the intervals for α = 0.01(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.4 0.6 0.8 1.0MAE MAE by interval length ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 30: MAE per group of observations for the WPF dataset, where the groups are formed according to the length of the intervals for α = 0.05 46(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.4 0.6 0.8 1.0 1.2MAE MAE by interval length ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 31: MAE per group of observations for the WPF dataset, where the groups are formed according to the length of the intervals for α = 0.10(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.4 0.6 0.8 1.0 1.2MAE MAE by interval length ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 32: MAE per group of observations for the WPF dataset, where the groups are formed according to the length of the intervals for α = 0.20 Both QRA and HQR are able to capture well the difficulty of the prediction 47 with the length of the interval. This is consistent with the fact that the standard deviation of the models is not a significant variable. The models do not need such a variable to correctly quantify uncertainty for this example, hence QRA is able to perform this function well. We have studied this property when the coefficients associated to the estimation of the standard deviation between the predictors, λ2( α 2 ) and λ2(1 − α 2 ), are significant or not. The results are described in Appendix A. Regarding the coverage by interval length, Figures 33, 34, 35 and 36 are analysed. As in the case of the EPF, only the plots associated with the groups with 5% observations are presented, although Table 6 shows the results for the different configurations. Table 6 shows how the effect of WACI is positive. Although overall, the maximum deviation from the target coverage is not as large, WACI achieves better results for the mean and maximum deviation for every α condsidered. In particular, it should be noted that the maximum deviation of WACI when considering groups of 10% of observations is very small. Moreover, from the Figures 33 to 36, it can be seen that these improvements come mainly from correcting the overconfidence of ACI in the smallest and largest intervals, which corresponds to the effect observed in Figures 29 to 32. Furthermore, ignoring the particular behavior of the extreme case, WACI seems to achieve similar results for each group. In other words, the distribution of coverage according to the groups considered is more uniform for WACI than for ACI, as shown in Figures 34, 35 and 36. To conclude the discussion on this example, it has been observed that, overall, there are no notable differences between QRA and HQR, although they may exist in specific time periods in a favorable way for HQR (Appendix A). Standard CQR conformalization still does not provide great results on this problem. Although on classical measures, ACI and WACI obtain essentially the same results, WACI again corrects for the overconfidence biases exhibited by ACI, again making the WACI procedure more appropriate. 48(0.0,0.05)(0.05,0.1)(0.1,0.15)(0.15,0.2)(0.2,0.25)(0.25,0.3)(0.3,0.35)(0.35,0.4)(0.4,0.45)(0.45,0.5)(0.5,0.55)(0.55,0.6)(0.6,0.65)(0.65,0.7)(0.7,0.75)(0.75,0.8)(0.8,0.85)(0.85,0.9)(0.9,0.95)(0.95,1.0) Quantile (IW) 95 100EmpiricalCoverage Coverage by interval length ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 33: Empirical coverage per group of observations for the WPF dataset, where the groups are formed according to the length of the intervals for α = 0.01(0.0,0.05)(0.05,0.1)(0.1,0.15)(0.15,0.2)(0.2,0.25)(0.25,0.3)(0.3,0.35)(0.35,0.4)(0.4,0.45)(0.45,0.5)(0.5,0.55)(0.55,0.6)(0.6,0.65)(0.65,0.7)(0.7,0.75)(0.75,0.8)(0.8,0.85)(0.85,0.9)(0.9,0.95)(0.95,1.0) Quantile (IW) 90 95 100EmpiricalCoverage Coverage by interval length ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 34: Empirical coverage per group of observations for the WPF dataset, where the groups are formed according to the length of the intervals for α = 0.05 49(0.0,0.05)(0.05,0.1)(0.1,0.15)(0.15,0.2)(0.2,0.25)(0.25,0.3)(0.3,0.35)(0.35,0.4)(0.4,0.45)(0.45,0.5)(0.5,0.55)(0.55,0.6)(0.6,0.65)(0.65,0.7)(0.7,0.75)(0.75,0.8)(0.8,0.85)(0.85,0.9)(0.9,0.95)(0.95,1.0) Quantile (IW) 85 90 95 100EmpiricalCoverage Coverage by interval length ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 35: Empirical coverage per group of observations for the WPF dataset, where the groups are formed according to the length of the intervals for α = 0.10(0.0,0.05)(0.05,0.1)(0.1,0.15)(0.15,0.2)(0.2,0.25)(0.25,0.3)(0.3,0.35)(0.35,0.4)(0.4,0.45)(0.45,0.5)(0.5,0.55)(0.55,0.6)(0.6,0.65)(0.65,0.7)(0.7,0.75)(0.75,0.8)(0.8,0.85)(0.85,0.9)(0.9,0.95)(0.95,1.0) Quantile (IW) 75 80 85 90 95 100EmpiricalCoverage Coverage by interval length ACI-QRA WACI-QRA ACI-HQR WACI-HQR Figure 36: Empirical coverage per group of observations for the WPF dataset, where the groups are formed according to the length of the intervals for α = 0.20 50 α 0.01 % obs. per group 5% 10% Method Mean Deviation Max Deviation Mean Deviation Max Deviation ACI-QRA 2.34 4,71 2.32 3.91 WACI-QRA 1.99 5.85 1.93 3.45 ACI-HQR 2.42 5.39 2.39 4.37 WACI-HQR 1.91 4.94 1.89 4.71 α 0.05 % obs. per group 5% 10% Method Mean Deviation Max Deviation Mean Deviation Max Deviation ACI-QRA 1.55 4.13 1.48 3.56 WACI-QRA 1.11 3.45 0.98 1.74 ACI-HQR 1.90 5.27 1.77 3.56 WACI-HQR 1.13 2.99 0.91 1.96 α 0.10 % obs. per group 5% 10% Method Mean Deviation Max Deviation Mean Deviation Max Deviation ACI-QRA 1,55 4,13 1,48 3,56 WACI-QRA 1,11 3,45 0,98 1,74 ACI-HQR 1,90 5,27 1,77 3,56 WACI-HQR 1,13 2,99 0,91 1,96 α 0.20 % obs. per group 5% 10% Method Mean Deviation Max Deviation Mean Deviation Max Deviation ACI-QRA 2.63 6.76 2.10 5.27 WACI-QRA 2.10 5.39 1.83 5.05 ACI-HQR 2.89 7.40 2.45 6.37 WACI-HQR 2.16 4.66 1.93 3.22 Table 6: Mean and maximum deviation of each model from the objective coverage by interval length for the WPF dataset. 51 6. Conclusions and future work In this paper we have considered the problem of obtaining prediction intervals that are built with the intention of assisting in decision making correctly. It has been discussed how the classical measures of validity and efficiency of intervals are not sufficient to be able to use these intervals in an appropriate manner. It is important that the intervals are varied in a way that this variation is directly related to the difficulty of the prediction. Moreover, it is important that the coverage does not depend on this difficulty, as it is possible to make the mistake of taking decisions with a certainty that does not correspond to the real one. Thus, two innovations have been introduced: the HQR model, which focuses on the length of the intervals having the appropriate relationship with the difficulty of the prediction, and the WACI adaptive conformal process, which seeks uniformity of safety regardless of the difficulty. This is all considered in the context that only different forecasters of the event of interest are known, as we believe this is a typical situation for practitioners. The different improvements provided by these models have been evaluated with two real-life examples in the energy context, which are challenging and not simple tasks: price forecasting and wind power forecasting. The results show how each of the proposed stages produces the desired results, correcting flaws in established models in the literature. As futures lines of work, the HQR model uses only two explanatory variables, which are the first two (estimated) moments of the distribution to be predicted. However, moments such as skewness or kurtosis may be of interest and could contribute to the estimation of the quantiles, following the ideas set out in Cornish and Fisher (1938). Estimating these moments with so few predictors is not feasible, but if a considerable number of them is available, assessing the improvement by considering higher order moments is of interest. In addition, the variance estimation has not taken into account the individual quality of each of the provided models or the correlation between them. A correct use of this information could lead to better results, although something similar to what happens when combining point prediction models could occur, where the simplest combinations such as the mean perform remarkably well (Wang et al., 2023). 52 Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. CRediT authorship contribution statement Carlos Sebasti´an: Writing – original draft, Visualization, Software, Methodology, Conceptualization. Carlos E. Gonz´alez-Guill´en: Writing – review & editing, Validation, Supervision, Conceptualization, Project administration, Funding acquisition. Jes´us Juan: Writing – review & editing, Validation, Supervision, Conceptualization, Project administration, Funding acquisition. Data availability All data and code describing the algorithms presented and related to the EPF example is available to replicate the results via the link https://github.com/CCaribe9/HQR-WACI. The original data associated with the models for the WPF example cannot be shared due to commercial reasons. Funding This work has been funded by grant MIG-20211033 from Centro para el Desarrollo Tecnol´ogico Industrial, Ministerio de Universidades, and European Union-NextGenerationEU. C.E.G.G. was also funded by a Re-qualification grant of Universidad Polit´ecnica de Madrid funded by European Union-NextGenerationEU and by Ministerio de Universidades. 53 References Amini, A., Schwarting, W., Soleimany, A., Rus, D., 2020. Deep evidential regression. Advances in Neural Information Processing Systems 33, 14927–14937. Angelopoulos, A.N., Bates, S., 2021. A gentle introduction to conformal prediction and distribution-free uncertainty quantification. arXiv preprint arXiv:2107.07511 . Bhatnagar, A., Wang, H., Xiong, C., Bai, Y., 2023. Improved online conformal prediction via strongly adaptive online learning. arXiv preprint arXiv:2302.07869 . Bishop, C.M., 1994. Mixture density networks . B¨ose, J.H., Flunkert, V., Gasthaus, J., Januschowski, T., Lange, D., Salinas, D., Schelter, S., Seeger, M., Wang, Y., 2017. Probabilistic demand forecasting at scale. Proceedings of the VLDB Endowment 10, 1694–1705. Britanak, V., Yip, P.C., Rao, K., 2007. Chapter 3 - the karhunen–lo´eve transform and optimal decorrelation, in: Britanak, V., Yip, P.C., Rao, K. (Eds.), Discrete Cosine and Sine Transforms. Academic Press, Oxford, pp. 51–72. Cannon, A.J., 2011. Quantile regression neural networks: Implementation in r and application to precipitation downscaling. Computers & geosciences 37, 1277–1284. Cornish, E.A., Fisher, R.A., 1938. Moments and cumulants in the specification of distributions. Revue de l’Institut international de Statistique , 307–320. Duan, T., Anand, A., Ding, D.Y., Thai, K.K., Basu, S., Ng, A., Schuler, A., 2020. Ngboost: Natural gradient boosting for probabilistic prediction, in: International conference on machine learning, PMLR. pp. 2690–2700. Efron, B., 1987. Better bootstrap confidence intervals. Journal of the American statistical Association 82, 171–185. Gibbs, I., Cand`es, E., 2021. Adaptive conformal inference under distribution shift. Advances in Neural Information Processing Systems 34, 1660–1672. Gibbs, I., Cand`es, E., 2022. Conformal inference for online prediction with arbitrary distribution shifts. arXiv preprint arXiv:2208.08401 . 54 Gneiting, T., Raftery, A.E., 2007. Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association 102, 359–378. Guan, L., 2023. Localized conformal prediction: A generalized inference framework for conformal prediction. Biometrika 110, 33–50. Han, X., Tang, Z., Ghosh, J., Liu, Q., 2022. Split localized conformal prediction. arXiv preprint arXiv:2206.13092 . Koenker, R., Bassett Jr, G., 1978. Regression quantiles. Econometrica: journal of the Econometric Society , 33–50. Kourou, K., Exarchos, T.P., Exarchos, K.P., Karamouzis, M.V., Fotiadis, D.I., 2015. Machine learning applications in cancer prognosis and prediction. Computational and structural biotechnology journal 13, 8–17. Lei, J., G’Sell, M., Rinaldo, A., Tibshirani, R.J., Wasserman, L., 2018. Distribution- free predictive inference for regression. Journal of the American Statistical Association 113, 1094–1111. Lei, J., Wasserman, L., 2014. Distribution-free prediction bands for non- parametric regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 76, 71–96. Melotti, G., Lu, W., Conde, P., Zhao, D., Asvadi, A., Gon¸calves, N., Premebida, C., 2023. Probabilistic approach for road-users detection. IEEE Transactions on Intelligent Transportation Systems . Neal, R.M., 2012. Bayesian learning for neural networks. volume 118. Springer Science & Business Media. Nowotarski, J., Weron, R., 2015. Computing electricity spot price prediction intervals using quantile regression and forecast averaging. Computational Statistics 30, 791– 803. Nowotarski, J., Weron, R., 2018. Recent advances in electricity price forecasting: A review of probabilistic forecasting. Renewable and Sustainable Energy Reviews 81, 1548–1568. Papadopoulos, H., 2011. Reliable probabilistic prediction for medical decision support, in: International Conference on Engineering Applications of Neural Networks, Springer. pp. 265–274. 55 Papadopoulos, H., Proedrou, K., Vovk, V., Gammerman, A., 2002. Inductive confidence machines for regression, in: Machine Learning: ECML 2002: 13th European Conference on Machine Learning Helsinki, Finland, August 19–23, 2002 Proceedings 13, Springer. pp. 345–356. Rasmussen, C.E., 2003. Gaussian processes in machine learning, in: Summer school on machine learning. Springer, pp. 63–71. Romano, Y., Patterson, E., Candes, E., 2019. Conformalized quantile regression. Advances in neural information processing systems 32. Shafer, G., Vovk, V., 2008. A tutorial on conformal prediction. Journal of Machine Learning Research 9. Stasinopoulos, D.M., Rigby, R.A., 2008. Generalized additive models for location scale and shape (gamlss) in r. Journal of Statistical Software 23, 1–46. Tibshirani, R.J., Foygel Barber, R., Candes, E., Ramdas, A., 2019. Conformal prediction under covariate shift. Advances in neural information processing systems 32. Vovk, V., 2012. Conditional validity of inductive conformal predictors, in: Asian conference on machine learning, PMLR. pp. 475–490. Vovk, V., Gammerman, A., Shafer, G., 2005. Algorithmic learning in a random world. volume 29. Springer. Wang, X., Hyndman, R.J., Li, F., Kang, Y., 2023. Forecast combinations: an over 50-year review. International Journal of Forecasting 39, 1518–1547. Winkler, R.L., 1972. A decision-theoretic approach to interval estimation. Journal of the American Statistical Association , 187–191. Zaffran, M., F´eron, O., Goude, Y., Josse, J., Dieuleveut, A., 2022. Adaptive conformal predictions for time series, in: International Conference on Machine Learning, PMLR. pp. 25834–25866. Zhang, Y., Wang, J., Wang, X., 2014. Review on probabilistic forecasting of wind power generation. Renewable and Sustainable Energy Reviews 32, 255–270. 56 Appendix A. Intuitive behaviour of the HQR model The intuitive idea about the behaviour of the coefficients ˆλ2( α 2 ) and ˆλ2(1 − α 2 ) is tested. These have been analysed in the example related to EPF (Sections 4.1.1 and 5.1) and the results can be seen in Figure A.37. The results for α = 0.01 have been omited because the respective quantiles are very extreme and the behaviour may be unstable and dependent on outliers. 0 2000 4000 6000 8000 10000 12000 T+1 −2 −1 0 1 2 3Coeﬃcientvalue ˆλ2( α 2 ) and ˆλ2(1 − α 2 ) over time α = 0.05 α = 0.10 α = 0.20 Figure A.37: Value of the coefficients ˆλ2( α 2 ) (continuous line) and ˆλ2(1 − α 2 ) (discontinuous line) for different values of α for the EPF example. As expected, the coefficients associated with the upper extremes are greater than 0, while those associated with the lower extremes are less than 0. In general, the further away the value of α from 0.5, the larger the absolute value of the coefficient. In small periods of time this is not the case, which is probably related to the estimation of the other coefficients of the model. Anyway, it can be said that the intuitive idea about the expected behaviour of the model holds. The same discussion could be made for the WPF example (Sections 4.1.2 and 5.2), which is analysed in Figure A.38. 57 0 2000 4000 6000 8000 10000 12000 T+1 −1.5 −1.0 −0.5 0.0 0.5 1.0Coeﬃcientvalue ˆλ2( α 2 ) and ˆλ2(1 − α 2 ) over time α = 0.05 α = 0.10 α = 0.20 Figure A.38: Value of the coefficients ˆλ2( α 2 ) (continuous line) and ˆλ2(1 − α 2 ) (discontinuous line) for different values of α for the WPF example. However, in this case, there is a clear period where the standard deviation does not provide information, which is in line with the results obtained in Section 5.2. The design of the HQR model was focused on capturing uncertainty correctly. This means that it detects high uncertainty in situations of great unpredictability and low uncertainty in the opposite situation. This has been measured in the paper by comparing the MAE of a point model versus the length of the interval given by the quantile regression model. If we evaluate this characteristic for the QRA and the CFRQ in the first 2000 time instants (where the moment of order two is significant) and between instants 4000 and 6000 (where the moment of order two is not significant) we have the results displayed in Figures A.39, A.40, A.41 and A.42. When the variable is not significant, the two methods behave practically the same in this respect. However, in the opposite case, there are differences. In cases of higher uncertainty, the QRA model behaves strangely, capturing less uncertainty in difficult situations on a regular basis. The HQR model, except for small perturbations, does capture uncertainty well. Therefore, the inclusion of this variable is recommended, even if there are periods in which it is not significant. 58(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.30 0.35 0.40 0.45 0.50 0.55MAE λ2(α) signiﬁcant HQR QRA(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2MAE λ2(α) not signiﬁcant HQR QRA Figure A.39: MAE vs length of the interval for α = 0.01 in the WPF example.(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60MAE λ2(α) signiﬁcant HQR QRA(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.6 0.8 1.0 1.2 1.4MAE λ2(α) not signiﬁcant HQR QRA Figure A.40: MAE vs length of the interval for α = 0.05 in the WPF example. 59(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.30 0.35 0.40 0.45 0.50 0.55 0.60MAE λ2(α) signiﬁcant HQR QRA(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.6 0.8 1.0 1.2 1.4MAE λ2(α) not signiﬁcant HQR QRA Figure A.41: MAE vs length of the interval for α = 0.10 in the WPF example.(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65MAE λ2(α) signiﬁcant HQR QRA(0.0,0.1)(0.1,0.2)(0.2,0.3)(0.3,0.4)(0.4,0.5)(0.5,0.6)(0.6,0.7)(0.7,0.8)(0.8,0.9)(0.9,1.0) Quantile (IW) 0.6 0.8 1.0 1.2 1.4 1.6MAE λ2(α) not signiﬁcant HQR QRA Figure A.42: MAE vs length of the interval for α = 0.20 in the WPF example. 60 Appendix B. Results of the QRA and HQR models by hours for the EPF dataset. The results of the QRA and HQR by hours with their conformalizations are shown in Tables B.7, B.8, B.9 and B.10. Method α = 0, 01 Emp. Cov. Mean IL Median IL WS HQR 97,60 101,07 99,65 149,95 QRA 95,90 95,73 95,45 208,67 CQR-HQR 99,49 131,10 126,85 143,87 CQR-QRA 99,45 160,30 157,75 179,24 ACI-HQR 97,93 105,63 103,10 143,75 ACI-QRA 98,18 120,34 116,87 175,64 WACI-HQR 99,35 125,88 120,78 141,33 WACI-QRA 99,40 149,58 145,77 170,33 Table B.7: Results of the different methodologies on the EPF dataset for α = 0.01 considering the QRA and HQR methods by hours. Method α = 0, 05 Emp. Cov. Mean IL Median IL WS HQR 95,33 74,51 74,49 93,12 QRA 94,13 78,18 78,48 108,96 CQR-HQR 96,56 81,04 80,23 94,62 CQR-QRA 96,77 92,88 93,07 110,52 ACI-HQR 94,92 77,23 73,63 93,86 ACI-QRA 94,94 87,02 86,48 108,72 WACI-HQR 96,24 81,08 81,51 94,61 WACI-QRA 96,58 92,10 92,89 109,06 Table B.8: Results of the different methodologies on the EPF dataset for α = 0.05 considering the QRA and HQR methods by hours. 61 Method α = 0, 10 Emp. Cov. Mean IL Median IL WS HQR 91,39 59,32 59,08 77,04 QRA 90,41 60,85 61,39 83,15 CQR-HQR 92,29 62,60 61,85 77,65 CQR-QRA 92,23 67,29 67,23 84,23 ACI-HQR 89,91 59,41 56,76 77,03 ACI-QRA 89,99 62,69 61,42 82,74 WACI-HQR 92,03 61,89 61,79 77,26 WACI-QRA 92,52 67,01 67,49 83,33 Table B.9: Results of the different methodologies on the EPF dataset for α = 0.10 considering the QRA and HQR methods by hours. Method α = 0, 20 Emp. Cov. Mean IL Median IL WS HQR 82,40 41,96 41,78 60,44 QRA 82,24 43,08 43,42 62,91 CQR-HQR 82,75 43,68 43,61 60,63 CQR-QRA 83,68 45,46 45,86 63,34 ACI-HQR 79,93 41,42 40,04 60,32 ACI-QRA 79,80 41,81 41,13 62,56 WACI-HQR 82,43 43,02 43,81 60,38 WACI-QRA 83,17 44,57 45,65 62,51 Table B.10: Results of the different methodologies on the EPF dataset for α = 0.20 considering the QRA and HQR methods by hours. Although the results are clearly worse than those shown in Section 5.1, it can be seen that the HQR model still shows better performance in this case than the QRA model. 62","libVersion":"0.3.2","langs":""}