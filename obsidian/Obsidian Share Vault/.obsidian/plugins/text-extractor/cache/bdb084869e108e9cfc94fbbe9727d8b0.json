{"path":"lit/lit_notes/attachments/Khalil23predictThenOptimize-20240624171725298.webp","text":"Algorithm 1 End-to-end Gradient Descent Require: coefficient matrix A, right-hand side b, data D 1: Initialize predictor parameters @ for predictor g(;0) 2: for epochs do 3: for each batch of training data (z,c) do 4: Sample batch of the cost vectors ¢ with the corresponding features = 5: Predict cost using predictor é:= g(x; 0) 6: Forward pass to compute optimal solution w* (&) := argmin,, ¢ 7w 7 Forward pass to compute decision loss (¢, ) 8: Backward pass from loss [(¢,) to update parameters 6 with gradient 9: end for 10: end for","libVersion":"0.3.2","langs":"eng"}