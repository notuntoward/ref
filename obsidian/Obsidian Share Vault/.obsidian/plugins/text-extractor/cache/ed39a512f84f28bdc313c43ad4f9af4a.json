{"path":"lit/sources/Taillardat23extrmEventCRPS.pdf","text":"Extreme events evaluation using CRPS distributions Maxime Taillardat a,b,∗, Anne-Laure Fougèresc, Philippe Naveau d, Raphaël de Fondeville e aCNRM, Université de Toulouse, Météo-France, CNRS, Toulouse, France. bMétéo-France, Toulouse, France cUniv. Lyon, Université Claude Bernard Lyon 1, CNRS UMR 5208, Institut Camille Jordan, F-69622 Villeurbanne, France dLaboratoire des Sciences du Climat et de l’Environnement, UMR 8212, CEA-CNRS-UVSQ, IPSL & U Paris-Saclay, Gif-sur-Yvette, France eSwiss Data Science Center, ETH Zürich and EPFL, Switzerland Abstract Veriﬁcation of probabilistic forecasts for extreme events has been a very active ﬁeld of research, stirred by media and public opinions who naturally fo- cus their attention on extreme events, and easily draw biased conclusions. In this context, classical veriﬁcation methodologies tailored for extreme events, such as thresholded and weighted scoring rules, have undesirable properties that cannot be mitigated; the well-known Continuous Ranked Probability Score (CRPS) makes no exception. In this paper, we deﬁne a formal framework to assess the behavior of forecast evaluation procedures with respect to extreme events, that we use to point out that assessment based on the expectation of a proper score is not suitable for extremes. As an alternative, we propose to study the properties of the CRPS as a random variable using extreme value theory to address extreme events veriﬁcation. To compare calibrated forecasts, an index is introduced that summarizes the ability of probabilistic forecasts to predict extremes. Its strengths and limitations are discussed using both theoretical arguments and simulations. Keywords: CRPS, Extreme events, Probabilistic forecasting, Scoring rules, Calibration, Veriﬁcation. ∗Corresponding author Email address: maxime.taillardat@meteo.fr (Maxime Taillardat) Preprint submitted to International Journal of Forecasting February 2, 2022arXiv:1905.04022v3 [stat.ME] 1 Feb 2022 1. Introduction By deﬁnition, the rarity of extreme events makes diﬃcult to issue rele- vant forecasts, whose performance assessment is an even greater challenge. In particular, the scarcity of extremes imposes that veriﬁcation schemes have to be built and understood in a probabilistic sense. The general framework for probabilistic forecast evaluation compares an observation y with a proba- bilistic forecast F , represented by its cumulative distribution function (cdf). The framework also assumes that y is drawn from a random variable Y with cdf G. For a better utilization of the forecasts, it is generally convenient, and even recommended (Ferro and Stephenson, 2011), to further assume that the forecast F is calibrated (Dawid, 1984; Diebold et al., 1997), i.e., that the predictive distribution resembles the distribution of the observations given the information contained in the forecast. For a formal deﬁnition of auto- calibration (calibration in the following), we refer to the works of Tsyplakov (2011) and Strähl and Ziegel (2017) summarized in Appendix A. Calibrated forecasts can be commonly evaluated based on their sharpness, also called reﬁnement by Winkler et al. (1996), which usually refers to their spread. This leads to the paradigm of ‘maximizing sharpness subject to calibration’, introduced by Gneiting et al. (2007) and later formally justiﬁed by Tsyplakov (2011). Probabilistic forecasting has become more and more popular over the last years in various ﬁelds such as economics and ﬁnance (Galbraith and Norden, 2012), demography and social science (Raftery and Ševčíková, 2021), health (Henzi et al., 2021), energy (Hong et al., 2016), hydrology and hydraulics (Tiberi-Wadier et al., 2021). In this work, we focus on weather probabilistic forecasts (Leutbecher and Palmer, 2008). Indeed, probabilistic forecasts are nowadays issued by most National Weather Services (NWS) and F is known through a sample of ﬁnite size called “ensemble” (see, e.g., Zamo and Naveau, 2017). In this context, forecast veriﬁcation is performed by computing scoring rules such as the Continuous Ranked Probability Score (CRPS) (Epstein, 1969; Hersbach, 2000; Bröcker, 2012) CRPS(F, y) = ∫ ∞ −∞(F (x) − 1{x ≥ y})2 dx, = EF |X − y| − 1 2EF |X − X ′|, (1) where y ∈ R, and X and X ′ are independent random variables with common cdf F . The CRPS is attractive as it does not require predictive densities, is 2 inferred non-parametrically, and has simple interpretation. The right hand side of Equation (1) decomposes the CRPS into, in this order, a calibration and a sharpness term (Gneiting and Raftery, 2007). Alternative decompo- sitions are also available; see Taillardat et al. (2016); Bessac and Naveau (2021) and Appendix B. For the forecast evaluation of extreme events, proper weighted scoring rules were introduced by Gneiting and Ranjan (2011) and Diks et al. (2011). For a non-negative function w(x), the weighted CRPS wCRPS(F, y) = ∫ ∞ −∞(F (x) − 1{x ≥ y})2w(x) dx, (2) = EF |W (X) − W (y)| − 1 2 EF |W (X) − W (X ′)|, with W (x) = ∫ x −∞ w(t)dt, aims to emphasize a region of interest, for instance distributional tails. When w is continuous, an alternative expression of the weighted CRPS is available and can be found in Appendix B. The choice of the weight function w(x) is complex and depends on the diﬀerent stake- holders, such as forecast users and forecasters; see, e.g., Ehm et al. (2016); Gneiting and Ranjan (2011); Patton (2014); Smith et al. (2015); Taillardat (2021b). Even in the hypothetical case where w(x) could be objectively deﬁned, it is essential that the veriﬁcation process has to be made on the whole set of observations (Lerch et al., 2017) and one can wonder if the cor- responding weighted CRPS correctly discriminates between two competitive forecasts with respect to extreme events. In this work, we show that the expected weighted CRPS cannot discrimi- nate forecasts with diﬀerent extremal tail behaviors, a potentially redhibitory defect for extremal evaluation. To address this issue, we view the CRPS as a random variable. Its tail behavior is derived and compared to the tail regime of observations using Extreme Value Theory (EVT) (see, e.g. De Haan and Ferreira, 2007). This work is organized as follows: Section 2 provides an analysis of the weighted CRPS with respect to the notion of tail equivalence, the main back- bone of EVT. In particular, we propose a benchmark to compare the tail properties of forecast veriﬁcation tools allowing us to pinpoint the shortcom- ings of the CRPS and its weighted counterpart for scoring extreme events. In Section 3, we study the CRPS as a random variable and we make theoretical links between its tail behavior and the observational tail distribution. These mathematical connections help us to propose and study a new index to assess 3 the skill of calibrated probabilistic forecasts with respect to extreme events. The paths and pitfalls of this index and potential future works are discussed in the Section 4. 2. Limitations of the (w)CRPS as a proper scoring rule for ex- tremes 2.1. Tail modelling using EVT Thanks to the pioneering work of Gumbel (1935) and De Haan (1970), EVT provides a theoretically justiﬁed framework to model the tail of ran- dom variables, more precisely excesses above a large threshold; see, e.g., Embrechts et al. (1997); Beirlant et al. (2004). For any random variable X with cdf F , EVT models assume the existence of a domain of attraction, i.e., that there exists a positive auxiliary function b, such that F {u + xb(u)} F (u) −→ H(x) > 0, u → xF , (3) where F = 1 − F corresponds to the survival, also called tail function, and xF = sup{x : F (x) < 1} is the upper endpoint of F . Under condition (3), noted F ∈ D(H), the Pickands-Balkema-de Haan’s theorem (De Haan, 1970; Pickands, 1975) establishes that H has to belong to the family of generalized Pareto (GP) survival functions, i.e., H γ(x) = (1 + γx) − 1 γ , where x ∈ {x : 1 + γx > 0}. As a consequence, the GP tail appears to be the ideal candidate to approximate the survival function of exceedances over a large threshold u > 0, i.e., P(X − u ≥ x|X > u) ≈ H γ(x/σ) = (1 + γx σ )− 1 γ , where x ∈ {x : 1 + γx/σ > 0} and σ > 0. The GP family covers the three possible regimes of tail decay which is determined by the value of its tail index γ: when γ ̸= 0 the decay is polynomial and has an upper bound when γ < 0. For γ = 0, the GP survival function becomes exponential, i.e., H 0(z) = e −z/σ. 4 2.2. Tail equivalence and proper scoring rules The comparison of the tail behavior of two random variables, or equiva- lently their respective cdfs F and G, can be framed using the notion of tail equivalence. Deﬁnition 1. (Embrechts et al., 1997, Section 3.3) Two random variables X and Y with respective cdf F and G are tail equivalent if they have equal upper endpoint xF = xG = x∗ and if their survival functions F and G satisfy lim x→x∗ F (x) G(x) = c ∈ (0, +∞). Tail equivalence can also be simply expressed as the equality of tail in- dexes. In terms of extremal forecast, we expect that, between two forecast- ers, one should favor the one that is tail equivalent to the observations. In practice, this may be diﬃcult. For instance, consider two GP distributed random variables X1 and X2 with survival functions H 1(x) and H 1+ϵ(x/σ) with σ = (1 + ϵ)/(2 1+ϵ − 1). By construction, the medians of X1 and X2 are both equal to one. Still, their tail behavior widely diﬀer even for small ϵ: The 100 year return level for X1 is 99, while it is equal to 138 for X2 with ϵ = 0.1. In other words, if the precedent random variables were to represent water levels, a small diﬀerence of 0.1 in tail index, implied a diﬀerence of 39 meters which would most likely cause massive and destructive ﬂooding. This short example illustrates how issuing forecasts with the right tail regime, i.e., as close as possible to the observational one, is a priority for extreme events and that a veriﬁcation methodology should reward forecast with close, if not equal, tail regime. Ideally, the measure of forecast per- formance should give not only the distance but also the ‘direction’, i.e., if the forecast is more likely to over- or under-estimate the high quantiles. In- deed, let γG ∈ R be the tail index of observations. If the forecast satisﬁes γF > γG, the forecast over-estimates the risk producing a pessimistic or risk averse scenario. On the contrary, γF < γG falls on the optimistic side by under-estimating the likelihood of extreme events. Classical methods for forecast evaluation, even when designed to focus on extreme events, do not conserve tail equivalence. For instance, for any positive η and observation distribution G, it is always possible to construct a non-tail equivalent cdf F , such that |EG(wCRPS(G, Y )) − EG(wCRPS(F, Y ))| ≤ η, (4) 5 proof can be found in Appendix C. More precisely if G ∈ D(HγG), then it is possible for any arbitrary γF ∈ R to ﬁnd F ∈ D(HγF ) satisfying Equation (4). Thus the CRPS is unable to discriminate properly forecasts with diﬀerent tail regime, as non-tail equivalent forecasts can perform almost equally well as the ideal forecast G. A detailed illustration of this result for GP forecasts is given in Appendix D. We also refer to Brehmer and Strokorb (2019), who obtained a more general result, proving that proper scoring rule expectations are not suitable to distinguish tail properties, see their Theorem 5.4. 2.3. A benchmark for assessing forecasts of extremes Following Gneiting et al. (2007) and Strähl and Ziegel (2017), we propose a benchmark to assess the behavior of forecast evaluation procedures with respect to tail regimes. The design relies on a hierarchical model based on Gamma–exponential mixtures with γ > 0 { ∆ d = Γ(γ−1, γ−1) Y d = Exp(∆) d = GP(1, γ), (5) where Exp(δ) refers to an exponential random variable with scale δ > 0. The fact that Y follows a heavy tailed GP distribution, see relation (5), can be proved using Laplace transforms. For analogy with weather forecasting, we present the benchmark in a temporal setting. At each time t = 1, . . . , T > 1, an observation y is drawn independently from an exponential distribution whose scale δ is a realization of ∆. In this setting, Y has an exponential tail which is conditioned by the information brought by its scale δ, representing the a priori knowledge of the system, for instance the weather at previous time. Thus the ideal forecast for each time step is Exp(δ), and requires the knowledge of δ. Using relation (5), we see that the climatological forecaster Fclim is a GP distribution with tail index γ and unit scale. Climatology is a commonly used forecast reference in meteorology. In other ﬁelds, it can be viewed as the unconditional distribution of the truth, and an estimation of a climatological forecast can be done based on a sample of past and analogs observations. This setting is attractive as the ideal and the climatological forecasters belong to two diﬀerent regimes of tail decay. We introduce alternative competitors modelling partial knowledge of the conditional state: the λ-informed forecaster Fλ, λ ∈ [0, 1] is a mixture be- tween the climatological and ideal forecasts, where a weight, say λ ∈ [0; 1], indicates the contribution of each one, see Table 1 for the deﬁnition. 6 Finally, the extremist forecaster Fextr simply adds a multiplicative bias to the ideal forecaster: while it is not calibrated, such forecast has the same tail behavior as the ideal forecaster ; see Appendix A for detailed discussion on calibration. The benchmark is summarized in Table 1 and later referred to as the “Model GE”. Table 1: Benchmark to assess the behavior of forecast evaluation procedure with respect to diﬀerent tail regimes. All forecasts but Fextr are calibrated. Forecasts \\ Truth Y d = Exp(∆) where ∆ d = Γ(1/γ, 1/γ), 1 > γ > 0 Ideal Fideal Exp(∆) Climatological Fclim GP(1, γ) λ-Informed Fλ λExp(∆) + (1 − λ)GP(1, γ) Extremist Fextr Exp(∆/ν), ν > 1 Closed forms of the CRPS are available for each forecast of the proposed benchmark. For instance, the extremist forecast Fextr, satisﬁes CRP S(Fextr, y) = y + 2ν δ exp ( −δy ν ) − 3ν 2δ ; (6) Besides, combining (B.1) and (6) yields the following formula for the λ- informed forecast, λ ∈ [0, 1], CRP S(Fλ, y) = y + λ2 2δ + 2λ δ {exp(−δy) − 1} − 2(1 − λ) 1 − γ { 1 − (1 + γy) γ−1 γ } +2(1 − λ) 2 2 − γ + 2λ(1 − λ)γ −1 γ δ γ−1 γ {exp ( δ γ ) IΓ ( γ − 1 γ , δ γ )} , where IΓ(s, x) = ∫ +∞ x e−tt s−1 dt. Table 2 gives the relative ratio of the em- pirical means of the CRPS for the benchmark with γ = 1/4. The CRPS being a proper score, the ideal forecast cannot be beaten in average in the Table 2. Moreover, there is a clear ranking among calibrated forecasts, based on the nested information sets (Holzmann and Eulert, 2014). Following the principle of tail equivalence presented in Section 2.2, the extremist forecast should be the forecast the closest to the ideal as they both belong to the same regime of tail decay; however, we observe that the CRPS average gives 7 Table 2: Relative ratio of the mean CRPS, in percent, with respect to the ideal forecast for the model GE with γ = 1/4, based on T = 10 6 observation/forecast pairs. Truth Y d = Exp(∆) where ∆ d = Γ(4, 4) Forecasts % w.r.t. Ideal Ideal Fideal 100% Extremist ν = 1.1 100.48% 0.75-Informed F0.75 100.90% 0.5-Informed F0.5 103.58% Extremist ν = 1.4 106.68% 0.25-Informed F0.25 108.06% Climatological Fclim 114.33% Extremist ν = 1.8 122.89% a performance in between the least informed forecaster and the climatology. An alternative measure for forecast evaluation, satisfying the tail equivalence principle is thus required. A good candidate commonly used in forecast sci- ence is the ROC curve (Gneiting and Vogel, 2018). However, in the case of Model GE, all the ROC curves, except the climatological one, coincide what- ever the event, which illustrates its invariance under calibration (Kharin and Zwiers, 2003). Further alternatives should thus be investigated. 3. The CRPS as a random variable 3.1. The random CRPS and its properties Section 2 pointed out the diﬃculty of summarizing forecast performance for meaningful comparisons for extreme observations. We illustrated in par- ticular that a single number such as the mean of the CRPS, or its weighted counterpart, fails to deliver relevant comparisons. As an alternative, we propose to study the distribution of the CRPS when treated as a random variable, see also Ferro (2017); Bessac and Naveau (2021). For simplicity, we use the setting and corresponding notations of the benchmark presented in Section 2.3. From equations (B.1) and (6), the cli- matological and ideal scores can be treated as random variables whenever yt is replaced by Yt. At this stage, it is important to remind that a forecast is issue with only a partial knowledge of the system: the exact value of δt and 8 the distribution of Yt are unknown, and only the observation yt is available. Table 3 summarizes quantities that are available to forecasters. Thus, to evaluate forecasts performance, it is only possible to compute CRPS(Ft, yt) for each t. The climatological distribution, that we now note G and whose existence needs to be hypothesised in practice, is characterized by the ob- served sample (y1, . . . , yt), considered as a sample of independent realizations of the random variable Y . For any set of forecasts {Ft}t=1,...,T and sample y1, . . . , yT , two types of sets of random variables can be deﬁned: S(FT ) = {CRPS(Ft, Yt)}t=1,...,T and S ∗(FT ) = {CRPS(Ft, Yπ(t))}t=1,...,T , (7) where π is a random permutation of {1, . . . , n}. Applying π breaks the conditional dependence between yt and Ft, quantiﬁed by δt in the benchmark, creating alternative less informative forecasts. Thus for a given forecaster, represented by the set FT = {Ft}i=1,...,T and permutation π, we introduce two random variables S(FT ) and S ∗(FT ) characterized by their respective empirical cdf. The climatological forecaster is the only forecaster satisfying CRPS(G, Y ) d = S ∗(G) d = S(G) . (8) as by deﬁnition it discards any information about the system conditioning. The ﬁrst equality in (8) is a direct consequence of auto-calibration, see Ap- pendix A; the second equality follows from the permutation invariance of the data from the point of view of the climatological forecaster. The distributional properties of S(FT ), S ∗(FT ), and S(G) give relevant insights on the behavior of the forecaster. For illustration, Figure 1 gives qq-plots of the distributions of S ∗(FT ) against S(FT ) for each forecast of the benchmark with γ = 1/4. We observe that the ideal, λ-informed and extrem- ist forecasts deviate from the diagonal, illustrating the inﬂuence of the loss of information caused by the permutation: such a visual diagnostic summarizes how S(FT ) and S ∗(FT ) capture relevant information from the conditioning modelled here by the random variable ∆. The right panel of Figure 1 displays these distributions on the probability scale and highlights how the discrep- ancy of the λ-informed forecaster evolves with the parameter λ. Extremist forecasts, with multiple values of the scale parameter ν, are displayed here for the sole purpose to illustrate how such visual diagnostics behave when cali- bration is not satisﬁed. In Figure 1, we can also see that forecast dominance 9 Table 3: Availability status of the quantities of interest. It can be an a posteriori avail- ability. Object Deﬁnition Availability in practice Ft Distribution of the forecast for time t yes yt Observed realisation at time t yes δt Conditioning variable no ∆ Conditioning random variable no Yt Conditional random variable generating yt no Y Unconditional random variable of the observations yes CRPS(Ft, yt) CRPS of the couple for time t yes CRPS(Ft, Yt) Random variable associated to CRP S(Ft, yt) no CRPSS(F, Y ) Random variable generated by the (CRP S(Ft, yt))t yes CRPSS∗(F, Y ) Random variable generated by the (CRP S(Ft, yπ(t)))t yes Figure 1: Comparisons of the distributional properties between S and S ∗ for each forecast in model GE: qq-plots (left) and a pp-plots (right panel). Each forecasts are represented by a sample of size T = 10 6. 10 among forecasters could be inferred, as in Ehm et al. (2016, Fig. 1,2,4,6) for point forecasts. Under calibration, discrepancy between distributions can be appropriately interpreted as a direct measure of the forecaster skill (the λ- informed curves never cross each other), making such diagnosis particularly relevant and compliant with the recommendations on the extremal depen- dence indices established by Ferro and Stephenson (2011). 3.2. Tail properties of the random CRPS We now study the upper tail behavior of the random CRPS, using EVT to develop a meaningful forecast evaluation for extreme events. To lighten the technicality of this section, all proofs are relegated to Appendix E. In terms of notations with respect to any conditional model that depends on ∆ = δ, we want to emphasize the diﬀerence between a conditional forecast, say Fδ, and an unconditional forecast F . Note that δ depends on the time index t, but for notation simplicity, we drop this index; ∆ might also change over time but here assumed invariant. Let X and Y be two random variables with absolutely continuous cdfs F and G with common upper bound xF = xG. Suppose that there exists γ < 1 such that G ∈ D(Hγ) and that cF = 2EF (XF (X)) is ﬁnite. Then conditionally on ∆ = δ, one has P ( CRPS(Fδ, Yδ) + cFδ − uδ bδ(uδ) > x \f \f \f \f Yδ > uδ ) −→ (1 + γδx)−1/γδ , (9) as uδ tends to xGδ , with 1 + γδx > 0. So at any ﬁxed state δ (state of the atmosphere for a weather forecast, say), the CRPS upper tail behavior (conditionally on ∆ = δ) is equivalent to the observation tail behavior and formalizes what could be intuited from (B.1). Now, unconditionally, one can also get a result for the climatological forecast, thanks to its property of invariance under permutation (see Section 3.1). If there exists γ < 1 such that G ∈ D(Hγ), then P { CRPS(G, Y ) + cG − u b(u) > x \f \f \f \f Y > u} −→ (1 + γx) −1/γ, u → xG, (10) for any x such that 1 + γx > 0. In the case where γ > 0, convergence in Equation (10) also holds for cG = 0 as the latter vanishes due to the linear behavior of the auxiliary function b in Equation (3), e.g., see Embrechts et al. (1997). 11 The benchmark presented in Table 1 illustrates these results. The choice of working with a time indexed couple (Ft, Yt) or with an invariant (G, Y ) impacts signiﬁcantly the tail behavior of the CRPS random variables: ac- cording to Table 1, the former case implies that the limit in (9) exhibits an exponential tail, whereas the climatological tail given by (10) is heavy, i.e., γ > 0. 3.3. Assessing the forecaster tail behavior In this section, we propose a tail-equivalent forecast performance index inspired from equations (9), (10), and Figure 1. We aim only to provide the intuition behind the index and leave formal theoretical analysis for future work. We assume that the forecasts lie in the domain of attraction of some distribution Hγ,σ. For suﬃciently large u, the null hypothesis H0 : S(FT )|Y > u d = Hγ,σu should be rejected for any calibrated forecast with tail behaviour closer to the ideal forecast than the climatological reference. To go further, assume that the variables in S(FT ) are iid. This assump- tion may not be always satisﬁed, as for instance temperature measures of two consecutive days are likely to be dependent, but can be reasonably sat- isﬁed for measurements from suﬃciently far apart. For each forecast, we can compute a Cramér-von Mises criterion ωu2{S(FT )} = ∫ +∞ −∞ [ ˆK (m) S,u (v) − Hγ,σu(v)] 2dHγ,σu(v), where ˆK (m) S,u is the empirical distribution of the observations in S(FT ) ex- ceeding the threshold u. The empirical nature of ˆK (m) S,u allows to simplify ωu2{S(FT )} to Ω F u = m × ̂ωu2{S(FT )} = 1 12m + m∑ i=1 [2i − 1 2m − Hγ,σu(si) ]2 , where m denotes the number of observations exceeding u and s1, . . . , sm are the ordered values of S(FT ). A detailed algorithm for the computation of ΩF u is provided in Table F.4 of Appendix F. As suggested by Figure 1, we assume that Ω F u > ΩG u , for any calibrated forecasts and climatology G. Also, for two calibrated forecasts F 1 and F 2, we conjecture that Ω F 2 u ≥ ΩF 1 u if F 2 has a tail behaviour closer to the ideal 12 forecast than F 1. Under these assumptions, we can summarize simply the comparison between Ω F u and Ω G u through Tu(F, G) = 1 − Ω G u ΩF u . (11) The behaviour of the index Tu is illustrated with the help of model GE; Figure 2 displays the evolution of Tu as a function of the threshold u for T = 10 6 and γ = 1/4. The behaviour of the index is shown to be consistent with our conjecture: ﬁrst, the ideal forecast performs best, while the climatology has the lowest index. Performance ranking among calibrated forecasters is stable as the threshold increases, with the ideal forecast always obtaining the largest index. The extremist forecasters, displayed here to illustrate the behaviour of the index for non-calibrated forecast, obtain a high index, even larger than the ideal forecast, stressing the importance of calibration which must be carefully assessed before any interpretation of Tu. In practice, a threshold choice has to be made, for which numerous methodologies have been developed, see, e.g., Beirlant et al. (2004); Papas- tathopoulos and Tawn (2013); Naveau et al. (2016). 4. Discussion In this work, we have argued with the help of a carefully designed bench- mark that the mean of the CRPS, or its weighted counterparts, are unable to successfully discriminate a forecast upper tail regime, as demonstrated by Brehmer and Strokorb (2019). Ehm et al. (2016) have introduced the so- called “Murphy diagrams” for assessing dominance in point forecasts. This original approach allows to appreciate dominance among diﬀerent forecasts and anticipate their skill area; a similar visual diagnostic is presented in Figure 1 for calibrated forecasts. Inspired by Friederichs and Thorarinsdottir (2012), we apply EVT di- rectly on common veriﬁcation measures. By considering the CRPS as a ran- dom variable, see also Bessac and Naveau (2021) for non-extreme cases, one can view this contribution as a ﬁrst step in considering other functionals of the scores distributions rather than their means. The new index introduced in Section 3.3 can be considered as a probabilistic alternative to the scores introduced by Ferro (2007) and Ferro and Stephenson (2011). We make a link between the paradigm of maximizing the sharpness subject to calibration from Gneiting et al. (2007) and the paradigm of maximizing the information 13 0 10 20 30 40 0.0 0.2 0.4 0.6 0.8 1.0 Index plot for model GE (from q50 to q0.99995) ThresholdIndex 0.5 0.9 0.975 0.995 0.9995 0.99995 0.8 0.95 0.99 0.999 0.9999 ideal 0.75−informed 0.5−informed 0.25−informed climatological 1.1−extremist 1.4−extremist 1.8−extremist Figure 2: Cramér-von Mises’ criterion-based index as a function of the threshold for the diﬀerent forecasts in model GE with parameters T = 106 and γ = 1/4. Indexes are computed for thresholds ranging from the 0.5 to the 0.99995 empirical quantile. Higher index values are assumed to reﬂect a tail behaviour closer to the ideal forecaster. Validity of the index is limited to calibrated forecast and Non-calibrated extremists forecast are shown to recall that calibration must be ﬁrst carefully checked before interpreting such graphics. for extreme events subject to calibration. In a same vein, Murphy (1993) has presented the diﬀerences between forecast quality (accordance between 14 forecasts and observations) and forecast value (ability to bring information to realize a beneﬁt by choosing a forecast), the forecast value seems to be the most important for extreme events, where decision making is crucial. For de- terministic weather forecasts, such tools are well-known, see e.g. Richardson (2000); Zhu et al. (2002). Other widely-used scores based on the dependence between forecasts and observed events have been considered in Stephenson et al. (2008); Ferro and Stephenson (2011). It would be worthwhile to further study the theoretical properties of this CRPS-based tool. Another potentially interesting investigation could be to extend this procedure to other scores like the mean absolute diﬀerence, the Dawid-Sebastiani score (Dawid and Sebastiani, 1999) or the ignorance score (Smith et al., 2015; Diks et al., 2011). Classical tools in veriﬁcation re- lies on a veriﬁcation period, as a consequence evaluation is always done a posteriori. Thus, an interesting manner to pursue this work would be to con- sider sequential evaluation of rare events, in the spirit of the e-values (Vovk and Wang, 2021) introduced to assess and monitor calibration continuously (Arnold et al., 2021). Eventually, we invite scientists to work on new theory of scoring rule departing from the score’s averages. Acknowledgments Part of this work was supported by the French National Research Agency (ANR) project T-REX (ANR-20-CE40-0025) and by Energy oriented Cen- tre of Excellence-II (EoCoE-II), Grant Agreement 824158, funded within the Horizon2020 framework of the European Union. Part of this work was also supported by the ExtremesLearning grant from 80 PRIME CNRS-INSU and the ANR project Melody (ANR-19-CE46-0011). This work was partially sup- ported by the ANR LABEX MILYON (ANR-10-LABX-0070) of Université de Lyon, within the program \"Investissements d’Avenir\" (ANR-11-IDEX- 0007). Implementation details The implementation of the index relies on the extremeIndex package (Taillardat, 2021a). The R code generating simulation data and Figures is available upon request. 15 References Arnold, S., Henzi, A., Ziegel, J. F., 2021. Sequentially valid tests for forecast calibration. arXiv preprint arXiv:2109.11761. Beirlant, J., Goegebeur, Y., Segers, J., Teugels, J., Waal, D., Ferro, C., 2004. Statistics of extremes: Theory and applications. Bessac, J., Naveau, P., 2021. Forecast score distributions with imperfect ob- servations. Advances in Statistical Climatology, Meteorology and Oceanog- raphy 7 (2), 53–71. Brehmer, J. R., Strokorb, K., 2019. Why scoring functions cannot assess tail properties. Electronic Journal of Statistics 13 (2), 4015 – 4034. URL https://doi.org/10.1214/19-EJS1622 Bröcker, J., 2012. Evaluating raw ensembles with the continuous ranked probability score. Quarterly Journal of the Royal Meteorological Society 138 (667), 1611–1617. Csörgő, S., Faraway, J. J., 1996. The exact and asymptotic distributions of cramér-von mises statistics. Journal of the Royal Statistical Society: Series B (Methodological) 58 (1), 221–234. Dawid, A. P., 1984. Present position and potential developments: Some per- sonal views: Statistical theory: The prequential approach. Journal of the Royal Statistical Society. Series A (General), 278–292. Dawid, A. P., Sebastiani, P., 1999. Coherent dispersion criteria for optimal experimental design. Annals of Statistics, 65–81. De Haan, L., Ferreira, A., 2007. Extreme value theory: an introduction. Springer Science & Business Media. De Haan, L. F. M., 1970. On regular variation and its application to the weak convergence of sample extremes. Diebold, F. X., Gunther, T. A., Tay, A. S., 1997. Evaluating density forecasts. Diks, C., Panchenko, V., Van Dijk, D., 2011. Likelihood-based scoring rules for comparing density forecasts in tails. Journal of Econometrics 163 (2), 215–230. 16 Ehm, W., Gneiting, T., Jordan, A., Krüger, F., 2016. Of quantiles and ex- pectiles: consistent scoring functions, choquet representations and forecast rankings. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 78 (3), 505–562. Embrechts, P., Klüppelberg, C., Mikosch, T., 1997. Modelling extremal events, volume 33 of Applications of Mathematics. New York. Springer- Verlag, Berlin. Epstein, E. S., 1969. A scoring system for probability forecasts of ranked categories. Journal of Applied Meteorology 8 (6), 985–987. Ferro, C. A., 2007. A probability model for verifying deterministic forecasts of extreme events. Weather and Forecasting 22 (5), 1089–1100. Ferro, C. A., Stephenson, D. B., 2011. Extremal dependence indices: Im- proved veriﬁcation measures for deterministic forecasts of rare binary events. Weather and Forecasting 26 (5), 699–713. Ferro, C. A. T., 2017. Measuring forecast performance in the presence of observation error. Quarterly Journal of the Royal Meteorological Society 143 (708), 2665–2676. URL https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/ qj.3115 Friederichs, P., Thorarinsdottir, T. L., 2012. Forecast veriﬁcation for extreme value distributions with an application to probabilistic peak wind predic- tion. Environmetrics 23 (7), 579–594. Galbraith, J. W., Norden, S. v., 2012. Assessing gross domestic product and inﬂation probability forecasts derived from bank of england fan charts. Journal of the Royal Statistical Society: Series A (Statistics in Society) 175 (3), 713–727. Ghosh, S., Resnick, S., 2010. A discussion on mean excess plots. Stochastic Processes and their Applications 120 (8), 1492–1517. Gilleland, E., Hering, A. S., Fowler, T. L., Brown, B. G., 2018. Testing the tests: What are the impacts of incorrect assumptions when applying conﬁdence intervals or hypothesis tests to compare competing forecasts? Monthly Weather Review 146 (6), 1685–1703. 17 Gneiting, T., Balabdaoui, F., Raftery, A. E., 2007. Probabilistic forecasts, calibration and sharpness. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 69 (2), 243–268. Gneiting, T., Raftery, A. E., 2007. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association 102 (477), 359–378. Gneiting, T., Ranjan, R., 2011. Comparing density forecasts using threshold- and quantile-weighted scoring rules. Journal of Business & Economic Statistics 29 (3), 411–422. Gneiting, T., Ranjan, R., 2013. Combining predictive distributions. Elec- tronic Journal of Statistics 7, 1747–1782. Gneiting, T., Vogel, P., 2018. Receiver operating characteristic (roc) curves. arXiv preprint arXiv:1809.04808. Gumbel, E. J., 1935. Les valeurs extrêmes des distributions statistiques. In: Annales de l’institut Henri Poincaré. Vol. 5. pp. 115–158. Henzi, A., Kleger, G.-R., Hilty, M. P., Wendel Garcia, P. D., Ziegel, J. F., for Switzerland, R.-.-I. I., 2021. Probabilistic analysis of covid-19 patients’ individual length of stay in swiss intensive care units. PloS one 16 (2), e0247265. Hersbach, H., 2000. Decomposition of the continuous ranked probability score for ensemble prediction systems. Weather and Forecasting 15 (5), 559–570. Holzmann, H., Eulert, M., 2014. The role of the information set for fore- casting—with applications to risk management. The Annals of Applied Statistics 8 (1), 595–621. Hong, T., Pinson, P., Fan, S., Zareipour, H., Troccoli, A., Hyndman, R. J., 2016. Probabilistic energy forecasting: Global energy forecasting competi- tion 2014 and beyond. Kharin, V. V., Zwiers, F. W., 2003. On the roc score of probability forecasts. Journal of Climate 16 (24), 4145–4150. 18 Lerch, S., Thorarinsdottir, T. L., Ravazzolo, F., Gneiting, T., et al., 2017. Forecaster’s dilemma: extreme events and forecast evaluation. Statistical Science 32 (1), 106–127. Leutbecher, M., Palmer, T. N., 2008. Ensemble forecasting. Journal of com- putational physics 227 (7), 3515–3539. Murphy, A. H., 1993. What is a good forecast? an essay on the nature of goodness in weather forecasting. Weather and forecasting 8 (2), 281–293. Murphy, A. H., Winkler, R. L., 1987. A general framework for forecast veri- ﬁcation. Monthly weather review 115 (7), 1330–1338. Naveau, P., Huser, R., Ribereau, P., Hannart, A., 2016. Modeling jointly low, moderate, and heavy rainfall intensities without a threshold selection. Water Resources Research 52 (4), 2753–2769. URL http://dx.doi.org/10.1002/2015WR018552 Papastathopoulos, I., Tawn, J. A., 2013. Extended generalised pareto models for tail estimation. Journal of Statistical Planning and Inference 143 (1), 131–143. Patton, A. J., 2014. Comparing possibly misspeciﬁed forecasts. Tech. rep., Working paper, Duke University. Pickands, J., 1975. Statistical inference using extreme order statistics. the Annals of Statistics, 119–131. Prokhorov, Y. V., 1968. An extension of sn bernstein’s inequalities to multi- dimensional distributions. Theory of Probability & Its Applications 13 (2), 260–267. Raftery, A. E., Ševčíková, H., 2021. Probabilistic population forecasting: Short to very long-term. International Journal of Forecasting. URL https://www.sciencedirect.com/science/article/pii/ S0169207021001394 Richardson, D. S., 2000. Skill and relative economic value of the ecmwf en- semble prediction system. Quarterly Journal of the Royal Meteorological Society 126 (563), 649–667. 19 Smith, L. A., Suckling, E. B., Thompson, E. L., Maynard, T., Du, H., 2015. Towards improving the framework for probabilistic forecast evaluation. Climatic Change 132 (1), 31–45. Stephenson, D., Casati, B., Ferro, C., Wilson, C., 2008. The extreme depen- dency score: a non-vanishing measure for forecasts of rare events. Meteo- rological Applications 15 (1), 41–50. Strähl, C., Ziegel, J., 2017. Cross-calibration of probabilistic forecasts. Elec- tronic journal of statistics 11 (1), 608–639. Taillardat, M., 2021a. extremeIndex: Forecast Veriﬁcation for Extreme Events. R package version 0.0.3. URL https://CRAN.R-project.org/package=extremeIndex Taillardat, M., 2021b. Skewed and mixture of gaussian distributions for en- semble postprocessing. Atmosphere 12 (8), 966. Taillardat, M., Mestre, O., Zamo, M., Naveau, P., 2016. Calibrated ensem- ble forecasts using quantile regression forests and ensemble model output statistics. Monthly Weather Review 144 (6), 2375–2393. Tiberi-Wadier, A.-L., Goutal, N., Ricci, S., Sergent, P., Taillardat, M., Bout- tier, F., Monteil, C., 2021. Strategies for hydrologic ensemble generation and calibration: On the merits of using model-based predictors. Journal of Hydrology 599, 126233. Tsyplakov, A., 2011. Evaluating density forecasts: a comment. Available at SSRN 1907799. Vovk, V., Wang, R., 2021. E-values: Calibration, combination and applica- tions. The Annals of Statistics 49 (3), 1736–1754. Winkler, R. L., Munoz, J., Cervera, J. L., Bernardo, J. M., Blattenberger, G., Kadane, J. B., Lindley, D. V., Murphy, A. H., Oliver, R. M., Ríos-Insua, D., 1996. Scoring rules and the evaluation of probabilities. Test 5 (1), 1–60. Zamo, M., Naveau, P., 2017. Estimation of the continuous ranked probability score with limited information. Mathematical Geosciences. 20 Zhu, Y., Toth, Z., Wobus, R., Richardson, D., Mylne, K., 2002. The economic value of ensemble-based weather forecasts. Bulletin of the American Me- teorological Society 83 (1), 73–83. Appendix A. Prediction framework and calibration The theoretical framework considered in this paper is the now classical prediction space already introduced by Murphy and Winkler (1987); Gneiting and Ranjan (2013); Ehm et al. (2016), and generalized in a serial context by Strähl and Ziegel (2017). It starts formally with a probability space (Ω, A, Q) and a collection of sub-σ-algebras A1, . . . , Ak ⊂ A, where Ai represents the information available to forecaster i. In a meteorological context, it can be seen as the representation of the atmosphere done by each forecaster. In the benchmark considered in Section 2.3, we will consider for simplicity that the information set is generated by a random variable ∆. A real-valued outcome Y is observed and seen as a (real-valued) random variable. A probabilistic forecast i for Y is identiﬁed with its so-called “pre- dictive distribution” with cdf Fi. Rigorously speaking, Fi : Ω × B(R) → [0, 1] is a kernel1 from (Ω, Ai) to (R, B(R)), but as done by previous authors, we will identify the kernels with random cumulative cdf, see e.g. Strähl and Ziegel (2017) for more details. For each x ∈ R, we might in particular use the notation Fi(x) meaning the random element ω 7→ Fi(ω, (−∞, x]). In such a framework, a forecast Fi is termed ideal with respect to Ai if Fi = L(Y |Ai) almost surely. Tsyplakov (2011) also refers to this property saying that Fi is calibrated with respect to Ai. He additionally deﬁnes the auto-calibration as the property for Fi to satisfy Fi = L(Y |σ(Fi)) almost surely. Here, σ(Fi) denotes the σ-algebra generated by Fi, that is to say the smallest σ-algebra such that ω 7→ Fi(ω, x) is measurable for all x ∈ R. Note that if a forecast is calibrated with respect to Ai, then it is auto-calibrated, but the converse does not hold in general. As a particular case considered in Section 2.3, the climatological forecaster is ideal with respect to the trivial σ-algebra. In practice, one is not only concerned with predictions for an outcome Y at a single time point. The framework introduced above also allows to deal with independent replicates at times t = 1, 2, . . ., as is done in Section 2.3. If 1This means that for each ﬁxed ω ∈ Ω, Fi(ω, ·) is a probability measure, and for each ﬁxed x ∈ R, Fi(·, (−∞, x]) is Ai-measurable. See e.g. Kallenberg (2017). 21 such an assumption of independence sounds unrealistic in several situations, as argued by Strähl and Ziegel (2017), it can nevertheless provide a ﬁrst step and takes advantage of a lighter context. We chose therefore to keep it in this paper for simplicity. Appendix B. An alternative expression of the weighted CRPS The weighted CRPS deﬁned by (2) can be reformulated in the following way, as soon as the weight function w(.) is continuous, wCRP S(F, y) = W (y) + 2EF [{W (X) − W (y)}1X>y] − 2EF [W (X)F (X)] . (B.1) Assume that the weight function w(.) is continuous. By integrating by parts ∫ y −∞ F 2(x)w(x) dx and ∫ ∞ y F 2(x)w(x) dx and using W (x) = ∫ x −∞ w(z)dz, the weighted CRPS deﬁned by (2) can be rewritten as wCRP S(F, y) = EF |W (X) − W (y)| − 1 2EF |W (X) − W (X ′)|. The equality |a − b| = 2 max(a, b) − (a + b) gives EF |W (X) − W (y)| = 2EF max(W (X), W (y)) − EF W (X) − W (y), = W (y) − EF W (X) + 2EF (W (X) − W (y)I[W (X) > W (y)]) , and EF |W (X) − W (X ′)| = 2EF max(W (X), W (X ′)) − 2EF W (X), = 4E(W (X)FW (X)(W (X))) − 2EF W (X), = 4E(W (X)F (X)) − 2EF W (X) , where the last line follows from the fact that FW (X)(W (X)) and F (X) have the same distribution, which is uniform on (0, 1). As W (x) is non-decreasing, one has {W (X) > W (y)} = {X > y}, and it follows that wCRPS(F, y) = W (y) − EF W (X) + 2EF [ {W (X) − W (y)}1W (X)>W (y)] −2EF [W (X)F (X)] + EF W (X), = W (y) + 2EF [{W (X) − W (y)}1X>y] − 2EF [W (X)F (X)] , as announced in (B.1). 22 Appendix C. Proof of the inequality (4) Let u be a positive real. Denote Z a non-negative random variable with ﬁnite mean and cdf H. Assume that Z and Y are independent and have same right end point. We introduce the new random variable Xu = Y 1{u ≥ Y } + (Z + u)1{Y > u} , (C.1) with survival function Fu deﬁned by Fu(x) = { G(x), if x ≤ u H(x − u)G(u), otherwise. (C.2) Note that the decreasingness of Fu yields in particular that for all x, Fu(x) ≤ G(x) . (C.3) Besides, equation (C.2) and the monotonicity of W allows to write that for any x ≤ u E[W (Y )1{Y < x}] = E[W (Xu)1{Xu < x}] . (C.4) Equality (B.1) implies that 1 2 [wCRPS(Fu, x) − wCRPS(G, x)] = EFu[(W (Xu) − W (x))1{Xu > x}] − EG[(W (Y ) − W (x))1{Y > x}] +EG[W (Y )G(Y )] − EFu[W (Xu)Fu(Xu)], = EFu[W (Xu)Fu(Xu)] − EG[W (Y )G(Y )] −EFu[(W (Xu) − W (x))1{Xu ≤ x}] + EG[(W (Y ) − W (x))1{Y ≤ x}] = EFu[W (Xu)Fu(Xu)] − EG[W (Y )G(Y )] + ∆(x) , where ∆(x) = EG[(W (Y ) − W (x))1{Y ≤ x}] − EFu[(W (Xu) − W (x))1{Xu ≤ x}]. The stochastic ordering that holds between Xu and Y implies that the quan- tity EFu[W (Xu)Fu(Xu)] − EG[W (Y )G(Y )] is negative. Combined with (C.4), this leads to 1 2 |EG[wCRPS(Fu, Y )] − EG[wCRPS(G, Y )]| ≤ ∫ xG u ∆(x)dG(x). (C.5) 23 For x > u we can write that ∆(x) = EY [(W (Y ) − W (x))1{u < Y ≤ x}] − EFu[(W (Xu) − W (x))1{u < Xu ≤ x}], ≤ EFu[(W (x) − W (u))1{u < Xu ≤ x}], since W (Y ) − W (x) ≤ 0 in the ﬁrst expectation, whereas 0 ≤ W (x) − W (Xu) ≤ W (x) − W (u) in the second one. As a consequence, one gets ∆(x) ≤ (W (x) − W (u))[Fu(x) − Fu(u)], ≤ (W (x) − W (u))Fu(u), = (W (x) − W (u))G(u). This last expression combined with (C.5) leads ﬁnally to |EG[wCRPS(Fu, Y )] − EG[wCRPS(G, Y )]| ≤ 2G(u) ∫ xG u (W (x) − W (u))dG(x). Note that this inequality is true for any u and H, and its right hand side does not depend on H(x). Thus, the tail behavior of the random variables Y and Z can be completely diﬀerent, although the CRPS of G and G can be as closed as one wishes. The right hand side goes to 0 due to the ﬁnite mean of W (Y ). Appendix D. A detailed example related to Section 2.2 In this appendix, we illustrate the fact that the CRPS fails at discrim- inating forecasts with diﬀerent tails. We consider GP distributed forecasts and observations. In this case, closed form of the CRPS are available, as detailed in the following. Lemma 1. Consider X d = GP(β, ξ) and Y d = GP(σ, γ) with 0 ≤ ξ < 1 and 0 ≤ γ < 1, with respective survival functions F (x) = (1 + ξx/β)−1/ξ (for x > −β/ξ) and G(x) = (1 + γx/σ)−1/γ (for x > −σ/γ). If γ/σ = ξ/β, with γ ̸= 0, then EG [CRPS(F, Y )] = σ 1 − γ + 2β [ 1 2(2 − ξ) − γ γ + ξ − γξ ] . This gives the minimum CRPS value for ξ = γ and σ = β, EG [CRPS(G, Y )] = σ (2 − γ)(1 − γ). 24 Proof: Applying (B.1) with W (y) = y, and making use of classical prop- erties of the Pareto distribution (see e.g. (Embrechts et al., 1997, Theorem 3.4.13)), one gets CRPS(F, y) = y + 2(1 + ξy/β) −1/ξ β + ξy 1 − ξ − 2β ( 1 1 − ξ − 1 2(2 − ξ) ) . (D.1) It follows that E [CRPS(F, Y )] = σ 1 − γ + 2 β 1 − ξ m0 + 2 ξ 1 − ξ m1 − 2β ( 1 1 − ξ − 1 2(2 − ξ) ) , with m0 = E [(1 + ξ β Y )−1/ξ] , and m1 = E [ Y ( 1 + ξ β Y )−1/ξ] . Since ( 1 + ξ β y)−1/ξ = G s (cy) , with c = ξσ βγ and s = γ ξ , one can write mr = E [ Y rG s (cY ) ] for r = 0, 1. Besides, as G −1(v) = σ γ ( (1 − v) −γ − 1 ) , one can thus rewrite, denoting by U a random variable uniformly distributed on (0, 1), mr = E [ G −1(U ) rG s (cG −1(U ))] , = E [( σ γ ((1 − U ) −γ − 1 ) )r ( 1 + γ σ ( c σ γ ((1 − U ) −γ − 1 ) ))−s/γ] , = ( σ γ )r E [( U −γ − 1 )r ( (1 − c) + cU −γ)−s/γ] , = ( σ γ )r E [( B 1 − B )r ( 1 − (1 − c)B 1 − B )−s/γ] , with B = 1 − U γ = ( σ γ )r E [Br(1 − B) −r+s/γ (1 − (1 − c)B) −s/γ] , with B ∼ Beta(1, 1/γ) = ( σ γ )r E [Br(1 − B) −r+1/ξ (1 − (1 − c)B)−1/ξ] , because s/γ = 1/ξ. 25 If c = ξσ βγ = 1, then this simpliﬁes to mr = ( σ γ )r 1 γ ∫ 1 0 ur(1 − u) −r+1/ξ+1/γ−1du = ( σ γ )r 1 γ B(r + 1, −r + 1/ξ + 1/γ), = ( σ γ )r 1 γ Γ(r + 1)Γ(−r + 1/ξ + 1/γ) Γ(1 + 1/ξ + 1/γ) . In particular, m0 = 1 γ B(1, 1/ξ + 1/γ) = (1 + γ ξ )−1 and m1 = σ γ ( 1 + γ ξ )−1 ( 1 ξ + 1 γ − 1 )−1 . It follows that, if γ σ = ξ β , then we have E [CRPS(F, Y )] = σ 1 − γ + 2β [ 1 2(2 − ξ) − γ γ + ξ − γξ ] . This gives the minimum CRPS value for ξ = γ and σ = β, E [CRPS(G, Y )] = σ (2 − γ)(1 − γ), concluding the proof of Lemma 1. □ Lemma 1 allows to study the eﬀect of changing the forecast’s tail behavior captured by ξ and the spread forecast encapsulated in β, when F and G have proportional parameters, i.e., β = aσ and ξ = aγ for some a > 0. In this case, the CRPS simpliﬁes to EG [CRPS(F, Y )] = σ 1 − γ + 2aσ [ 1 2(2 − aγ) − 1 1 + a − aγ ] , (D.2) leading when a > 1 to a forecaster with heavier-tail, overestimating the true upper tail behavior, and to the opposite when a < 1. Counter examples as the previous one can thus be found, illustrating how weighted scoring rules fail to compare tail behaviors. They should therefore be handled with a particular care, especially for forecast makers, as already advocated by Gilleland et al. (2018); Lerch et al. (2017). 26 Appendix E. Proof of the convergences (9) and (10) The proof of (10) can be seen as a particular case of (9), so that we will focus on proving (9). The following lemma will help to get the result, and is presented ﬁrst with its proof. In what follows, the mean excess function of any random variable Z with ﬁnite mean and with cdf F will be denoted by M (F, z), so that F (z)M (F, z) = EF [(Z − z)1lZ>z]. Lemma : Consider a random variable Z with ﬁnite mean that belongs to domain of attraction D(Hγ) with γ < 1. There exist non negative real numbers α and β such that for each z ∈ R, 0 ≤ 2EF [(Z − z)1lZ>z] ≤ F (z)(αz + β) . (E.1) Proof of the lemma: The indicator function 1lZ>z implies that we always have 0 ≤ 2EF ((Z − z)1lZ>z). To prove that 2EF ((Z − z)1lZ>z) is smaller than F (z)(αz + β), we ﬁrst show that this inequality holds for large values of z. Note ﬁrst that if z > xF , then (E.1) is trivially true. Let then show the result when z < → xF , and for this, let decompose the proof depending on the sign of γ : 1. F belongs to D(Hγ) with 0 < γ < 1 : In this case, Embrechts et al. (1997) (Section 3.4) show that M (F, z) ∼ γz/(1 − γ) as z tends to xF , and we can conclude directly. 2. F belongs to D(Hγ) with γ < 0 : In this case, the result also follows easily from Embrechts et al. (1997) since when z tends to xF , M (F, z) ∼ γ(xF − z)/(γ − 1). This allows to ﬁx α = 0 and β = supz∈V (xF ) γ(xF − z)/(γ − 1) for an appropriate neighborhood V (xF ) of xF . 3. F belongs to D(H0) : When F is in the Gumbel domain of attraction, M (F, z)/z → 0 as z tends to xF (see e.g. Theorem 3.9 in Ghosh and Resnick (2010)). If xF is ﬁnite, then there exists a positive β such that 2M (F, z) ≤ β and α can be ﬁxed to 0, whereas if xF is inﬁnite, the fact that 2M (F, z) < z for z large enough enables to conclude. So far, we have shown that, for some large z0, there exist non negative α and β such that 2EF ((Z − z)1lZ>z) ≤ F (z)(αz + β), for all z > z0. We still need to prove that this statement also holds for z ≤ z0. Deﬁne 0 ≤ β0 = 2 max z≤z0 EF [(Z − z)1lZ>z]. 27 As γ < 1, β0 is ﬁnite and, as F (z) ≥ F (z0) for all z ≤ z0, we have 0 ≤ β0 ≤ β0 F (z) F (z0). We have now two cases: either β < β0 F (z0) or β ≥ β0 F (z0) . In the latter case, we have 2EF ((Z − z)1lZ>z) ≤ β0 ≤ F (z)(αz + β), and so, the required result is obtained. In the case of β < β0 F (z0) , it is always possible to increase β chosen when z > z0, and bring it above β0 F (z0) . We are now ready to prove (9) as announced. Proof of (9): Given the conditional forecast Fδ, the CRPS can be computed with respect to the conditional observation yδ in the following way CRPS(Fδ, yδ) = yδ − cδ + 2EFδ [(Xδ − yδ)1(Xδ > yδ)] , where cδ = 2EFδ [XδFδ(Xδ)]. To simplify notations, we drop the subscript δ in the rest of the proof, but it will be back at the end. The previous lemma allows to write Y ≤ CRPS(F, Y ) + c ≤ (1 + αF (Y ))Y + βF (Y ) a.s. Let now work conditionally on Y > u, for a large u close to xF = xY . We then get Y ≤ CRPS(F, Y ) + c ≤ (1 + αF (u))Y + βF (u) a.s. This holds when the right end point of Y is non-negative. If this was not the case, note that one can simply write Y ≤ CRPS(F, Y )+c ≤ Y +βF (u) a.s.. The main idea of the proof is to notice that F (u) goes to zero as u gets large, and consequently, the above inequalities indicate that the thresholded random variable Y [u] = [(Y − u)/b(u) | Y > u] and the thresholded CRPS C[u] = [(CRPS(F, Y ) + c − u)/b(u) | Y > u] should behave similarly for large u. The choice of positive constant b(u) depends on the domain of attraction of Y . More precisely, we assume that Y [u] converges in distribution towards a GPD with ﬁnite mean. So that 0 ≤ P ( CRPS(F, Y ) + c − u b(u) > t | Y > u) − P ( Y − u b(u) > t | Y > u) 28 ≤ P([1 + αF (Y )]Y + βF (Y ) > tb(u) + u | |Y > u) − P(Y > tb(u) + u | Y > u) ≤ P (Y > tb(u) + u − βF (u) 1 + αF (u) | Y > u) − P(Y > tb(u) + u | Y > u). We recognize the probability (conditionally on Y > u) for Y to be in an interval denoted by Iu = [tb(u) + u − βF (u) 1 + αF (u) , tb(u) + u ] . The remaining part of the proof consists in showing that this conditional probability tends to 0 as u → xF . We can write P (Y ∈ Iu | Y > u) = P (Y ∈ u + Ju | Y > u) , where Ju = [tb(u) − F (u)(α + β) 1 + αF (u) , tb(u) ] . For u large enough, the latter probability can be approximated by a GPD, so that P (Y ∈ Iu | Y > u) ∼ |Ju| sup v∈Ju gGP (v) = F (u)[α + β + αtb(u)] 1 + αF (u) sup v∈Ju gGP (v) , where gGP denotes the probability density function associated to the GPD. This implies the convergence to 0 of the latter probability. Since this is true conditionally on ∆ = δ, it can be rewritten, after reintroduction of the subscript δ, as P (CRPS(Fδ, Yδ) + cδ − uδ bδ(uδ) > x | Yδ > uδ ) −→ (1 + γδx)−1/γδ , as u tends to xGδ , with 1 + γδx > 0. 29 Appendix F. Algorithm for the computation of the Cramer-von- Mises criterion Table F.4: Computation of Cramér-von Mises’ statistic from N couples fore- cast/observation. It can be done with the R package extremeIndex (Taillardat, 2021a). 0. CRPS estimates for each forecaster: - For the N couples forecast/observation, compute their corresponding instantaneous CRPS. 1. Estimation of γ on the observations: - Find a threshold u where the Pareto approx- imation is acceptable and estimate the Pareto shape parameter γ and σ . 2. For a threshold w ≥ u: - Compute the scale parameter σw = σ + γw. 3. Computation of Xu - Order the m CRPS values where the obser- vation y ≥ w in increasing order s1, . . . , sm. For i ∈ [1, m] -Compute for each CRPS value si, Hγ,σw(si). -Compute [ 2i−1 2m − Hγ,σw(si) ]2. End 3. End 2. Note that for large u, under the null hypothesis, the statistic Ω F u follows a Cramér-von Mises distribution. The associated p-values pF u ∈ [0, 1] could have been computed, but they are actually subject to numerical instabilities (Prokhorov, 1968; Csörgő and Faraway, 1996). Furthermore, ΩF u is suﬃcient to compare the eﬀect size of the deviation. 30","libVersion":"0.3.1","langs":""}