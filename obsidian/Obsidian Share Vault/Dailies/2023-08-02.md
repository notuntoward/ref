---
created date: 2024-12-17T08:51:31-08:00
modified date: 2024-12-17T08:51:31-08:00
---

# [FCST-163](https://growingenergylabs.atlassian.net/browse/FCST-163) pv forecaster with new features

In reference to [Site Unreachable](https://bitbucket.org/gelibitbucket/gaia/pull-requests/465/fcst-163-pv-forecaster-with-new-features?link_source=email), here are some of mine.
  
Yes, the Forecaster and ForecasterConfig classes are way too deep in the weeds.  They should concern themselves only with generic pipelines – getting data, taking data, passing around configuration messages defined by the number crunching processes that communicate with each other -- not defined by the Forecaster classes themselves.  The base classes should only be about maintaining pipes, and not what’s in them.

On the other side, the number crunching processes should have to know as little as possible about the pipes.  

And each other.

The problem with data science code is that every problem is different, and there are a lot of them.  Most DS projects require different data engineering, feature extraction, modeling, visualization, and deployment.  This makes the code across different projects quite different, and the struggle to design common code across them, unprofitable.

The other thing is that DS code changes fast, as it's almost always experimental.  The problems are mostly new, so you try something, see how it goes, and adjust as fast as possible.  Every other DS project is changing, and not in sync with your DS project.   You do that to keep up with your competitors, who are moving fast too -- at least the successful ones are.

This all means that heroic effort spent hunting for commonalities across the shifting internals of every DS project is quickly obsolete.

The one thing that is somewhat common is the compute language and its libraries; QCELLS is not going to write its own TensorFlow.  Yet, different TensorFlow projects may require different TensorFlow versions, a consequence of the differing combinations of libraries used to solve each task.

DS code written with commercially relevant speed and quality is therefore *commonly* isolated.  Each step has its own module or component, so that data scientists can work efficiently, avoiding conflicts, errors, and the inconsistencies that are inevitable when trying to mix different types of code into the same common environment.

The usual isolation tools are containers and APIs,

<mark style="background: #FFB86CA6;">Need to finish this.</mark>




  
  
