---
category: literaturenote
tags: 
citekey: Liu24physSysLrnByThemslvs
status: unread
dateread: 
ZoteroTags: obsLitNote
aliases:
  - Physical systems that can learn by themselves
  - Physical systems that can learn
publisher: ""
citation key: Liu24physSysLrnByThemslvs
DOI: ""
created date: 2024-04-26T23:20:08-07:00
modified date: 2024-12-17T08:51:31-08:00
---

> [!info]- : [**Zotero**](zotero://select/library/items/6JJFZWKH)   | [**URL**](https://www.youtube.com/watch?v=7hz4cs-hGew)
>
> 
> **Abstract**
> Brains learn and perform an enormous variety of tasks on their own, using relatively little energy. Brains are able to accomplish this without an external computer because their analog constituent parts (neurons) update their connections without knowing what all the other neurons are doing using local rules. We have developed an approach to learning that shares the property that analog constituent parts update their properties via a local rule, but does not otherwise emulate the brain. Instead, we exploit physics to learn in a far simpler way. Our collaborators have implemented this approach in the lab, developing physical systems that learn and perform machine learning tasks on their own with little energy cost. These systems should open up the opportunity to study how many more is different within a new paradigm for scalable learning.
> 
> 
> **FirstDirector**:: Liu, Andrea  
~    
> **Title**:: "Physical systems that can learn by themselves"  
> **Date**:: 2024-04-24  
> **Citekey**:: Liu24physSysLrnByThemslvs  
> **ZoteroItemKey**:: 6JJFZWKH  
> **itemType**:: videoRecording  
> **DOI**::   
> **URL**:: https://www.youtube.com/watch?v=7hz4cs-hGew  
> **Journal**::   
> **Volume**::   
> **Issue**::   
> **Book**::   
> **Publisher**::   
> **Location**:: UC Berkeley   
> **Pages**::   
> **ISBN**::   
> **ZoteroTags**:: obsLitNote
> **Related**:: 

> _Physical Systems That Can Learn by Themselves_. Directed by Andrea Liu, 2024. _YouTube_, [https://www.youtube.com/watch?v=7hz4cs-hGew](https://www.youtube.com/watch?v=7hz4cs-hGew).
%% begin Obsidian Notes %%
___
Very interesting lecture on self organizing soft matter, but I saved this because of the comparison of chatGPT and human brain energy cost. Would be fun to finish watching this sometime.

# Brain vs chatGPT energy consumption

**Put in a graph?**
- could feed brain for a day with 10 (text?) chatGTP queries
- could feed brain 5 days with 1 generated image or drive an EV for 10 miles

# Raw Video Notes

- [00:39:25](https://www.youtube.com/watch?v=7hz4cs-hGew&t=2366#t=39:25.74) chatGPT query v.s. human Brain
	- human
		- ~ 2000 kJ/day (20% of calories used by body)
	- chatGPT 
		- query ~ 200 kj
		- image generation ~ 10,000 kJ
			- 5X what human brain uses in one day
			- enough to drive avg. EV for 10 miles
	- [[lit/lit_notes/attachments/41d96132f06dab9af41af9a5f7d2b7c5_MD5.jpeg|Open: Pasted image 20240426232601.png]]
- [00:38:42](https://www.youtube.com/watch?v=7hz4cs-hGew&t=2323#t=38:42.83) human neurons update their synapses by "**local rule**", don't know what everybody else is doing (must be only w/ neighboring neurons, right?)
	- **NOTE** how this is different than with the attention blocks: global: everything to everything
	- interesting that this trick is what NN's finally work like the brain, and the brain doesn't do it!
	- [ ] is that a legit point?  Do I dare say it?
![[lit/lit_notes/attachments/41d96132f06dab9af41af9a5f7d2b7c5_MD5.jpeg]]



___
%% end Obsidian Notes %%

> [!note]- Zotero Note (1)
> Liu24physSysLrnByThemslvs
> 
> Intersting lecture on self organizing soft matter, but I saved this because the energy cost comparison w/ chatGPT and human brains.
> 
> <small>ğŸ“ï¸ (modified: 2024-04-26) [link](zotero://select/library/items/WRDCPHXC) - [web](http://zotero.org/users/60638/items/WRDCPHXC)</small>
>  
> ---




%% Import Date: 2024-04-26T23:20:22.998-07:00 %%
