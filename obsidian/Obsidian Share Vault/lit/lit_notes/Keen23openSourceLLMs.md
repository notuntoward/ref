---
category: literaturenote
tags: 
citekey: Keen23openSourceLLMs
status: unread
dateread: 
ZoteroTags: obsLitNote
aliases:
  - Should You Use Open Source Large Language Models?
  - Should You Use Open Source
publisher: ""
citation key: Keen23openSourceLLMs
DOI: ""
created date: 2024-05-01T12:00:17-07:00
modified date: 2024-12-17T08:51:31-08:00
---

> [!info]- : [**Zotero**](zotero://select/library/items/3H78SQYY)   | [**URL**](https://www.youtube.com/watch?v=y9k-U9AuDeM)
>
> 
> **Abstract**
> Want to experiment with foundation models? Explore our interactive demo for watsonx.ai  → https://ibm.biz/Bdvu3f  To dive deeper get the guide to choosing the right AI foundation model → https://ibm.biz/Bdvu3H  Large Language Models (LLMs) can be proprietary to a given company, or open source and free for anyone to access and modify. While proprietary LLMs are often larger, the benefits of transparency, fine-tuning, and community contributions make open source an attractive alternative. Both proprietary and open source LLMs share risks, including inaccuracies, bias, and security concerns. In this video, Master Inventor Martin Keen covers the tradeoffs so you can make an informed decision of which option is best for you.  AI news moves fast. Sign up for a monthly newsletter for AI updates from IBM. → https://ibm.biz/Bdvu3M
> 
> 
> **FirstDirector**:: Keen, Martin  
~    
> **Title**:: "Should You Use Open Source Large Language Models?"  
> **Date**:: 2023-11-27  
> **Citekey**:: Keen23openSourceLLMs  
> **ZoteroItemKey**:: 3H78SQYY  
> **itemType**:: videoRecording  
> **DOI**::   
> **URL**:: https://www.youtube.com/watch?v=y9k-U9AuDeM  
> **Journal**::   
> **Volume**::   
> **Issue**::   
> **Book**::   
> **Publisher**::   
> **Location**::    
> **Pages**::   
> **ISBN**::   
> **ZoteroTags**:: obsLitNote
> **Related**:: 

> _Should You Use Open Source Large Language Models?_ Directed by Martin Keen, 2023. _YouTube_, [https://www.youtube.com/watch?v=y9k-U9AuDeM](https://www.youtube.com/watch?v=y9k-U9AuDeM).
%% begin Obsidian Notes %%
___

- Hugging face security risks in ([Ng, 2024](zotero://select/library/items/QUV7MR9D))
### Video Notes
There's a nice timestamped Transcript window in this video's youtube page.
```timestamp-url 
 [Should You Use Open Source Large Language Models? - YouTube](https://www.youtube.com/watch?v=y9k-U9AuDeM)
 ```

```timestamp 
 00:16
 ```
325 K LLM models on hugging face
```timestamp 
 01:20
 ```
proprietary models far larger (param size) than open.  "1000's of billions of params" but you never know
Note: best open source LLM is gigantic: 3T params, I think: [[Rodriguez24Edge386YiChnLLM|Edge 386: Inside Yi, 01's]]
```timestamp 
 02:24
 ```
open source more transparent e.g. **training data** (bias)
can be fine-tuned to your own task 
- [ ] # find technical link to a tuning method 
- Using your own data: Is he talking about [[Gen AI Talk Ideas#fine-tuning]] or [[Gen AI Talk Ideas#grounding]]?
```timestamp 
 03:22
 ```
users: NASA geospatially tuned
healthcare: diagnostic tools, optimizations
finance: finGPT
```timestamp 
 04:02
 ```
leaderboard Hugging Face: realtime ranking of their open source LLMs vs. dataset/task
```timestamp 
 04:45
 ```
LLAMA2: popular on leaderboard
- pretrained and fine-tuned
- 70B - 7B params
```timestamp 
 05:01
 ```
VICUNA:  LLAMA tuned to follow instructions
BLOOM: multi-lingual model from 1000 AI researchers
```timestamp 
 05:28
 ```
problems w/ hallucinations, bias, security (cybercrime)
```timestamp 
 06:22
 ```
IBM has its own open source models
- WatsonX.AI studio has a bunch of LLAMA2
- also has its own Granite foundation models
___
%% end Obsidian Notes %%

> [!note]- Zotero Note (1)
> Keen23openSourceLLMs
> 
> I’ve TEMPORARILY put my literature notes for this in Obsidian AI talk folder, [here](obsidian://advanced-uri?vault=Obsidian%20Share%20Vault&filepath=work%252FGenerative%2520AI%2520talk%252F%2540IBM23openSourceLLMs.md)
> 
> Remove this note when I’ve settled on how ot merge zotero and obsidian.
> 
> Hugging face security risks in ([Ng, 2024](zotero://select/library/items/QUV7MR9D))
> 
> <small>📝️ (modified: 2024-04-02) [link](zotero://select/library/items/TVG2QP4G) - [web](http://zotero.org/users/60638/items/TVG2QP4G)</small>
>  
> ---




%% Import Date: 2024-05-01T12:01:08.871-07:00 %%
