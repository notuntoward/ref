---
category: literaturenote
tags: ml/genAI
citekey: Bentsen23transformersTimeSeriesData
status: unread
dateread: 
ZoteroTags: /unread, obsLitNote
aliases:
  - Transformers for Time-Series Data
  - Transformers for Time-Series Data
publisher: ""
citation key: Bentsen23transformersTimeSeriesData
DOI: ""
created date: 2024-04-07T22:21:48-07:00
modified date: 2024-12-17T08:51:31-08:00
---

> [!info]- : [**Zotero**](zotero://select/library/items/TKZWMNCE)   | [**URL**](https://medium.com/bearingpoint-data-analytics-ai/transformers-for-time-series-data-3fadff9f07d8) | [[Bentsen23transformersTimeSeriesData.html|HTM]]
>
> 
> **Abstract**
> In this article, we aim to provide a brief overview of some interesting work that adapts the Transformer architecture to facilitate time series data (and in particular forecasting) or that aims to reduce the model complexity (<O(L^2)). Since only a brief overview of the different architectures will be provided here, we suggest that the interested reader checks out the full papers as well. Happy reading, and remember, Attention is All you Need!
> 
> 
> **FirstAuthor**:: Bentsen, Lars Ødegaard  
~    
> **Title**:: "Transformers for Time-Series Data"  
> **Date**:: 2023-12-19  
> **Citekey**:: Bentsen23transformersTimeSeriesData  
> **ZoteroItemKey**:: TKZWMNCE  
> **itemType**:: blogPost  
> **DOI**::   
> **URL**:: https://medium.com/bearingpoint-data-analytics-ai/transformers-for-time-series-data-3fadff9f07d8  
> **Journal**::   
> **Volume**::   
> **Issue**::   
> **Book**::   
> **Publisher**::   
> **Location**::    
> **Pages**::   
> **ISBN**::   
> **ZoteroTags**:: /unread, obsLitNote
>**Related**:: 

> Bentsen, Lars Ødegaard. “Transformers for Time-Series Data.” _BearingPoint Data, Analytics & AI_, 19 Dec. 2023, [https://medium.com/bearingpoint-data-analytics-ai/transformers-for-time-series-data-3fadff9f07d8](https://medium.com/bearingpoint-data-analytics-ai/transformers-for-time-series-data-3fadff9f07d8).
%% begin Obsidian Notes %%
___
==Delete this and write here.==
==Don't delete the `persist` directives above and below.==
___
%% end Obsidian Notes %%

> [!note]- Zotero Note (1)
> Bentsen23transformersTimeSeriesData
> 
> A collection of transformer structures for time series, generally different than for language and image processing.
> 
> Transformers can learn longer sequences than LSTM, but at much higher computational cost: O(L^2) vs. O(L).  
> 
> These architectures are about reducing that complexity.  Among others, one technique is to use traditional forecasting techniques -- “huge improvements” with trend, periodic, and frequency domain techniques.
> 
> <small>📝️ (modified: 2024-03-21) [link](zotero://select/library/items/BZVIIFX6) - [web](http://zotero.org/users/60638/items/BZVIIFX6)</small>
>  
> ---




%% Import Date: 2024-04-07T22:23:43.648-07:00 %%
