---
category: literaturenote
tags: ml/genAI
citekey: Hataya23genAIcorruptData
status: unread
dateread: 
ZoteroTags: /unread, obsLitNote
aliases:
  - Will Large-scale Generative Models Corrupt Future Datasets?
  - Will Large-scale Generative Models Corrupt
publisher: ""
citation key: Hataya23genAIcorruptData
DOI: 10.48550/arXiv.2211.08095
created date: 2024-04-05T12:59:16-07:00
modified date: 2024-12-17T08:51:31-08:00
---

> [!info]- : [**Zotero**](zotero://select/library/items/KS633PSR)  | [**DOI**](https://doi.org/10.48550/arXiv.2211.08095)  | [**URL**](http://arxiv.org/abs/2211.08095) | [[Hataya23genAIcorruptData.pdf|PDF]]
>
> 
> **Abstract**
> Recently proposed large-scale text-to-image generative models such as DALL$\cdot$E 2, Midjourney, and StableDiffusion can generate high-quality and realistic images from users' prompts. Not limited to the research community, ordinary Internet users enjoy these generative models, and consequently, a tremendous amount of generated images have been shared on the Internet. Meanwhile, today's success of deep learning in the computer vision field owes a lot to images collected from the Internet. These trends lead us to a research question: "\textbf{will such generated images impact the quality of future datasets and the performance of computer vision models positively or negatively?}" This paper empirically answers this question by simulating contamination. Namely, we generate ImageNet-scale and COCO-scale datasets using a state-of-the-art generative model and evaluate models trained with "contaminated" datasets on various tasks, including image classification and image generation. Throughout experiments, we conclude that generated images negatively affect downstream performance, while the significance depends on tasks and the amount of generated images. The generated datasets and the codes for experiments will be publicly released for future research. Generated datasets and source codes are available from \url{https://github.com/moskomule/dataset-contamination}.
> 
> 
> **FirstAuthor**:: Hataya, Ryuichiro  
> **Author**:: Bao, Han  
> **Author**:: Arai, Hiromi  
~    
> **Title**:: "Will Large-scale Generative Models Corrupt Future Datasets?"  
> **Date**:: 2023-08-09  
> **Citekey**:: Hataya23genAIcorruptData  
> **ZoteroItemKey**:: KS633PSR  
> **itemType**:: preprint  
> **DOI**:: 10.48550/arXiv.2211.08095  
> **URL**:: http://arxiv.org/abs/2211.08095  
> **Journal**::   
> **Volume**::   
> **Issue**::   
> **Book**::   
> **Publisher**::   
> **Location**::    
> **Pages**::   
> **ISBN**::   
> **ZoteroTags**:: /unread, obsLitNote
>**Related**:: 

> Hataya, Ryuichiro, et al. _Will Large-Scale Generative Models Corrupt Future Datasets?_ arXiv:2211.08095, arXiv, 9 Aug. 2023. _arXiv.org_, [https://doi.org/10.48550/arXiv.2211.08095](https://doi.org/10.48550/arXiv.2211.08095).
%% begin Obsidian Notes %%
___
Images fed AI generated images look more and more alike

Same thing for LLMs:

- google trying to filter AI generated stuff: ([Will Shanklin, 2024](zotero://select/library/items/8SIJDUN2))

Comment: ICCV 2023
___
%% end Obsidian Notes %%

> [!note]- Zotero Note (1)
> Hataya23genAIcorruptData
> 
> Images fed AI generated images look more and more alike
> 
> Same thing for LLMs:
> 
> - google trying to filter AI generated stuff: ([Will Shanklin, 2024](zotero://select/library/items/8SIJDUN2))
> 
> Comment: ICCV 2023
> 
> <small>📝️ (modified: 2024-03-05) [link](zotero://select/library/items/SBIMZEZ7) - [web](http://zotero.org/users/60638/items/SBIMZEZ7)</small>
>  
> ---




%% Import Date: 2024-04-05T12:59:23.197-07:00 %%
