---
category: literaturenote
tags: 
citekey: Gupta24DebiasingInSamplePolicy
status: unread
dateread: 
ZoteroTags: /unread, todo, obsLitNote
aliases:
  - Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization
  - Debiasing In-Sample Policy Performance for
publisher: Operations Research
citation key: Gupta24DebiasingInSamplePolicy
DOI: 10.1287/opre.2022.2377
created date: 2024-06-25T11:19:29-07:00
modified date: 2024-12-17T08:51:31-08:00
---

> [!info]- : [**Zotero**](zotero://select/library/items/U58KVZBQ)  | [**DOI**](https://doi.org/10.1287/opre.2022.2377)  | [**URL**](https://pubsonline.informs.org/doi/10.1287/opre.2022.2377) | [[Gupta24DebiasingInSamplePolicy.pdf|PDF]]
>
> 
> **Abstract**
> In many modern large-scale decision-making problems, data can be scarce. As a result, traditional methods such as cross-validation perform poorly in evaluating the performance of decision-making policies. In “Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization,” Gupta, Huang, and Rusmevichientong propose a novel estimator of the out-of-sample performance for a policy in data-driven optimization. Unlike cross-validation, their approach avoids sacrificing training data for evaluation. As a result, they theoretically show the estimator is asymptotically unbiased as the problem size grows. Furthermore, they show that the estimator is asymptotically optimal when applied to more specialized “weakly coupled” optimization problems. Finally, using a case study on dispatching emergency medical response services, they demonstrate their proposed method provides more accurate estimates of out-of-sample performance and selects better policies.           ,              Motivated by the poor performance of cross-validation in settings where data are scarce, we propose a novel estimator of the out-of-sample performance of a policy in data-driven optimization. Our approach exploits the optimization problem’s sensitivity analysis to estimate the gradient of the optimal objective value with respect to the amount of noise in the data and uses the estimated gradient to debias the policy’s in-sample performance. Unlike cross-validation techniques, our approach avoids sacrificing data for a test set and uses all data when training and hence is well suited to settings where data are scarce. We prove bounds on the bias and variance of our estimator for optimization problems with uncertain linear objectives but known, potentially nonconvex, feasible regions. For more specialized optimization problems where the feasible region is “weakly coupled” in a certain sense, we prove stronger results. Specifically, we provide explicit high-probability bounds on the error of our estimator that hold uniformly over a policy class and depends on the problem’s dimension and policy class’s complexity. Our bounds show that under mild conditions, the error of our estimator vanishes as the dimension of the optimization problem grows, even if the amount of available data remains small and constant. Said differently, we prove our estimator performs well in the small-data, large-scale regime. Finally, we numerically compare our proposed method to state-of-the-art approaches through a case-study on dispatching emergency medical response services using real data. Our method provides more accurate estimates of out-of-sample performance and learns better-performing policies.             Funding: This work was partially supported by the National Science Foundation, Division of Civil, Mechanical and Manufacturing Innovation [Grant 1661732].             Supplemental Material: The online appendices are available at https://doi.org/10.1287/opre.2022.2377 .
> 
> 
> **FirstAuthor**:: Gupta, Vishal  
> **Author**:: Huang, Michael  
> **Author**:: Rusmevichientong, Paat  
~    
> **Title**:: "Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization"  
> **Date**:: 2024-03-01  
> **Citekey**:: Gupta24DebiasingInSamplePolicy  
> **ZoteroItemKey**:: U58KVZBQ  
> **itemType**:: journalArticle  
> **DOI**:: 10.1287/opre.2022.2377  
> **URL**:: https://pubsonline.informs.org/doi/10.1287/opre.2022.2377  
> **Journal**:: Operations Research  
> **Volume**:: 72  
> **Issue**:: 2  
> **Book**:: Operations Research  
> **Publisher**::   
> **Location**::    
> **Pages**:: 848-870  
> **ISBN**::   
> **ZoteroTags**:: /unread, todo, obsLitNote
> **Related**:: 

> Gupta, Vishal, et al. “Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization.” _Operations Research_, vol. 72, no. 2, Mar. 2024, pp. 848–70. _DOI.org (Crossref)_, [https://doi.org/10.1287/opre.2022.2377](https://doi.org/10.1287/opre.2022.2377).
%% begin Obsidian Notes %%
___
==Delete this and write here.==
==Don't delete the `persist` directives above and below.==
___
%% end Obsidian Notes %%



%% Import Date: 2024-06-25T11:19:51.986-07:00 %%
