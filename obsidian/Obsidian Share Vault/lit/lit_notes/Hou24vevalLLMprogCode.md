---
category: literaturenote
tags: ml/genAI
citekey: Hou24vevalLLMprogCode
status: unread
dateread: 
ZoteroTags: ""
aliases:
  - A systematic evaluation of large language models for generating programming code
  - A systematic evaluation of large
publisher: ""
citation key: Hou24vevalLLMprogCode
DOI: 10.48550/arXiv.2403.00894
created date: 2024-04-07T23:05:48-07:00
modified date: 2024-12-17T08:51:31-08:00
---

> [!info]- : [**Zotero**](zotero://select/library/items/YJXUXXPH)  | [**DOI**](https://doi.org/10.48550/arXiv.2403.00894)  | [**URL**](http://arxiv.org/abs/2403.00894) | [[Hou24vevalLLMprogCode.pdf|PDF]]
>
> 
> **Abstract**
> We systematically evaluated the performance of seven large language models in generating programming code using various prompt strategies, programming languages, and task difficulties. GPT-4 substantially outperforms other large language models, including Gemini Ultra and Claude 2. The coding performance of GPT-4 varies considerably with different prompt strategies. In most LeetCode and GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the optimal prompt strategy outperforms 85 percent of human participants. Additionally, GPT-4 demonstrates strong capabilities in translating code between different programming languages and in learning from past errors. The computational efficiency of the code generated by GPT-4 is comparable to that of human programmers. These results suggest that GPT-4 has the potential to serve as a reliable assistant in programming code generation and software development.
> 
> 
> **FirstAuthor**:: Hou, Wenpin  
> **Author**:: Ji, Zhicheng  
~    
> **Title**:: "A systematic evaluation of large language models for generating programming code"  
> **Date**:: 2024-03-01  
> **Citekey**:: Hou24vevalLLMprogCode  
> **ZoteroItemKey**:: YJXUXXPH  
> **itemType**:: preprint  
> **DOI**:: 10.48550/arXiv.2403.00894  
> **URL**:: http://arxiv.org/abs/2403.00894  
> **Journal**::   
> **Volume**::   
> **Issue**::   
> **Book**::   
> **Publisher**::   
> **Location**::    
> **Pages**::   
> **ISBN**::   
> **ZoteroTags**:: 
>**Related**:: 

> Hou, Wenpin, and Zhicheng Ji. _A Systematic Evaluation of Large Language Models for Generating Programming Code_. arXiv:2403.00894, arXiv, 1 Mar. 2024. _arXiv.org_, [https://doi.org/10.48550/arXiv.2403.00894](https://doi.org/10.48550/arXiv.2403.00894).
%% begin Obsidian Notes %%
___
==Delete this and write here.==
==Don't delete the `persist` directives above and below.==
___
%% end Obsidian Notes %%



%% Import Date: 2024-04-07T23:06:00.927-07:00 %%
