---
category: literaturenote
tags: ml/genAI
citekey: Chen24areOpenSrcLLMcatchUp
status: unread
dateread: 
ZoteroTags: obsLitNote
aliases:
  - "ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?"
  - "ChatGPT's One-year Anniversary: Are Open-Source"
publisher: ""
citation key: Chen24areOpenSrcLLMcatchUp
DOI: 10.48550/arXiv.2311.16989
created date: 2024-04-03T09:08:51-07:00
modified date: 2024-12-17T08:51:31-08:00
---

> [!info]- : [**Zotero**](zotero://select/library/items/8VJN6W8W)  | [**DOI**](https://doi.org/10.48550/arXiv.2311.16989)  | [**URL**](http://arxiv.org/abs/2311.16989) | [[Chen24areOpenSrcLLMcatchUp.pdf|PDF]]
>
> 
> **Abstract**
> Upon its release in late 2022, ChatGPT has brought a seismic shift in the entire landscape of AI, both in research and commerce. Through instruction-tuning a large language model (LLM) with supervised fine-tuning and reinforcement learning from human feedback, it showed that a model could answer human questions and follow instructions on a broad panel of tasks. Following this success, interests in LLMs have intensified, with new LLMs flourishing at frequent interval across academia and industry, including many start-ups focused on LLMs. While closed-source LLMs (e.g., OpenAI's GPT, Anthropic's Claude) generally outperform their open-source counterparts, the progress on the latter has been rapid with claims of achieving parity or even better on certain tasks. This has crucial implications not only on research but also on business. In this work, on the first anniversary of ChatGPT, we provide an exhaustive overview of this success, surveying all tasks where an open-source LLM has claimed to be on par or better than ChatGPT.
> 
> 
> **FirstAuthor**:: Chen, Hailin  
> **Author**:: Jiao, Fangkai  
> **Author**:: Li, Xingxuan  
> **Author**:: Qin, Chengwei  
> **Author**:: Ravaut, Mathieu  
> **Author**:: Zhao, Ruochen  
> **Author**:: Xiong, Caiming  
> **Author**:: Joty, Shafiq  
~    
> **Title**:: "ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?"  
> **Date**:: 2024-01-15  
> **Citekey**:: Chen24areOpenSrcLLMcatchUp  
> **ZoteroItemKey**:: 8VJN6W8W  
> **itemType**:: preprint  
> **DOI**:: 10.48550/arXiv.2311.16989  
> **URL**:: http://arxiv.org/abs/2311.16989  
> **Journal**::   
> **Volume**::   
> **Issue**::   
> **Book**::   
> **Publisher**::   
> **Location**::    
> **Pages**::   
> **ISBN**::   
> **ZoteroTags**:: "obsLitNote"
>**Related**:: 

> Chen, Hailin, et al. _ChatGPT’s One-Year Anniversary: Are Open-Source Large Language Models Catching Up?_ arXiv:2311.16989, arXiv, 15 Jan. 2024. _arXiv.org_, [https://doi.org/10.48550/arXiv.2311.16989](https://doi.org/10.48550/arXiv.2311.16989).
%% begin Obsidian Notes %%
___
==Delete this and write here.==
==Don't delete the `persist` directives above and below.==
___
%% end Obsidian Notes %%

> [!note]- Zotero Note (1)
> Comment: version v4, included latest top-performing open-sourced LLMs
> 
> <small>📝️ (modified: 2024-04-03) [link](zotero://select/library/items/Q78M6N3I) - [web](http://zotero.org/users/60638/items/Q78M6N3I)</small>
>  
> ---

%% Import Date: 2024-04-03T09:09:07.374-07:00 %%
