---
created date: 2024-07-28T09:20:10-07:00
modified date: 2024-07-28T10:09:54-07:00
tags:
  - ml/grokking
  - ml/deepLrn
  - ml/hyperparamTune
---

Training an "overparameterized" neural net for so long that the overfitting is unlearned, and the net starts to generalize.  This idea was kind of discovered before; see empirical energytop.org papers that were very didn't call this grokking;

- namesake: [[Power22beyondOverfitGrokking|Power22: Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets]] 
- speed by LPFing gradients! [[Lee24accelGrokFast|Lee24: Grokfast: Accelerated Grokking by Amplifying Slow Gradients]] 
	- code: [[Lee24repoGrokfast|Lee24: ironjr/grokfast]] 
- [ ] @ find grokking related energytop.org papers and put them here


