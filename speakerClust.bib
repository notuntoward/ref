% Encoding: US-ASCII


@Article{dcheveigne02yinF0,
  Title                    = {YIN, a fundamental frequency estimator for speech and music},
  Author                   = {{de Cheveign{\' e}}, A. and {Kawahara}, H.},
  Journal                  = {Acoustical Society of America Journal},
  Year                     = {2002},
  Pages                    = {1917-1930},
  Volume                   = {111},

  Url                      = {http://pubster.aip.org/getpdf/servlet/GetPDFServlet?filetype=pdf&id=JASMAN000111000004001917000001&idtype=cvips&jsessionid=1134901088468170055}
}

@Article{emejla98spchSegAR,
  Title                    = {Speech Segmentation Using Bayesian Autoregressive Changepoint Detector},
  Author                   = {Roman ?MEJLA and Pavel SOVKA},
  Journal                  = {Radioengineering},
  Year                     = {1998},
  Number                   = {4},
  Pages                    = {14-17},
  Volume                   = {7},

  Comment                  = {421: ReadNo},
  File                     = {emejla98spchSegAR.pdf:emejla98spchSegAR.pdf:PDF},
  Url                      = {http://amber.feld.cvut.cz/user/cmejla/papers/radioeng98.pdf}
}

@Article{abdallah01sparseMusic,
  Title                    = {Sparse coding of music signals},
  Author                   = {S. A. Abdallah and M. D. Plumbley},
  Journal                  = {In Print but doesn't say where},
  Year                     = {2001},

  Comment                  = {ReadNo},
  File                     = {abdallah01sparseMusic.pdf:abdallah01sparseMusic.pdf:PDF},
  Review                   = {ICA finds pitch harmonics: Use for multi-pitch separation},
  Url                      = {http://www.elec.qmul.ac.uk/staffinfo/markp/2001/spcoding01.pdf}
}

@InProceedings{abdallah01icaedge,
  Title                    = {If edges are the independent components of natural images, what are the independent components of natural sounds?},
  Author                   = {S. A. Abdallah and M. D. Plumbley.},
  Booktitle                = {Intl. Conf. Independent Component Analysis and Blind Signal Separation},
  Year                     = {2001},

  Comment                  = {349: ReadYes},
  Review                   = {Monaural basic functions for speech and music
* mixing, W, matrix in y=Wx is basis; x= mono time series; y=projection
* W chosen so that y is independent
* trained W on normalized speech/music, displayes resulting basis (W)
* generally: increasing BW, time res. w/ increasing freq
* speech basis a little bit similar to human auditory response
* compares to Wigner-Ville time/freq dist},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/052-abdallah.pdf}
}

@Article{abedMeraim01bssCyclo,
  Title                    = {Blind source-separation using second-order cyclostationary statistics},
  Author                   = {Abed-Meraim, K. and Yong Xiang and Manton, J.H.and Yingbo Hua },
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {2001},
  Number                   = {4},
  Pages                    = {694-701},
  Volume                   = {49},

  Comment                  = {ReadNo},
  Review                   = {Overlap detection detecting pitches? Has a contrast function. Could this be a sparse basis for mono?},
  Url                      = {http://ieeexplore.ieee.org/iel5/78/19699/00912913.pdf?isNumber=19699&prod=JNL&arnumber=912913&arSt=694&ared=701&arAuthor=Abed-Meraim%2C+K.%3B+Yong+Xiang%3B+Manton%2C+J.H.%3B+Yingbo+Hua}
}

@InProceedings{abeysekera02hilbPeak,
  Title                    = {An efficient Hilbert transform interpolation algorithm for peak position estimation},
  Author                   = {Saman S. Abeysekera},
  Booktitle                = {Statistical Signal Processing, {IEEE} Signal Processing Workshop on},
  Year                     = {2001},
  Pages                    = {417-420},

  Comment                  = {328: ReadYes},
  Review                   = {Pick peaks by interpolating Hilbert coeffs
* analytic solution so don't need to iterate
* not compared to parabolic peak tricks
* would it break down for non-sinusoidal or broadband signals?
* works great for finding DFT peaks
- usual way: FFT->rough peaks -> many DFT's scanning for true peaks.
- here, FFT->rough peaks-> hilbert interpolation}
}

@InProceedings{abrard01bssUnderCanc,
  Title                    = {From blind source separation to blind source cancellation in the underdetermined case: A new approach based on time-frequency analysis},
  Author                   = {Fr?ed?eric Abrard and Yannick Deville and Paul White},
  Booktitle                = {Independent Component Analysis and Blind Signal Separation, Intl. Conf. on},
  Year                     = {2001},

  Comment                  = {364: ReadYes},
  Review                   = {Filterbank two-mic gain ratio histogram yields BSS separating coeffs
* histogram of two-microphone signal power ratio at each FFT bin
* most prominent peaks in histogram are when have single talkers
* when two talkers, gains ratios are spread all over the place
* use histo peaks to get separating matrix
* separates one speaker from two guitars w/ two mics (underdetermined)
* only works for instantaneous mixing
* rickard02wDisjoint sort-of adds delay to this idea (phase angle)},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/053-deville.pdf}
}

@InProceedings{abushikhah01harmSpch,
  Title                    = {A robust technique for harmonic analysis of speech},
  Author                   = {Abu-Shikhah, N. and Deriche, M.},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {877-880},
  Volume                   = {2 },

  Comment                  = {ReadNo}
}

@InProceedings{acero00bssVQ,
  Title                    = {Speech/Noise Separation Using Two Microphones and a {VQ} Model of Speech Signals},
  Author                   = {A. Acero and S. Altschuler and L. Wu},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2000},

  Comment                  = {593:ReadYes},
  Review                   = {Reverberant ICA using VQ speech models
* nice b/c handles reverb w/ no FFT and no whitening
=> no scaling, permutation, etc.
* infomax separated signal criteria simplifed to sum of LPC prediction errors
* LPC coeffs come from small codebook (16-256 entries)
* EM algorithm: 
E: pick best code
M: find separating filters w/ min prediction error for code
* E/M converges in 2-3 iterations
* hearing tested on longish ICA test sigs (Te-Won Lee's)},
  Url                      = {http://research.microsoft.com/copyright/accept.asp?path=http://research.microsoft.com/srg/papers/2000-alexac-icslpa.pdf&pub=ISC}
}

@InProceedings{adami02spkrChangeTwo,
  Title                    = {A New Speaker Change Detection Method for Two-Speaker Segmentation},
  Author                   = {A. Adami and S. Kajarekar and H. Hermansky},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},

  Comment                  = {414: ReadNo},
  File                     = {adami02spkrChangeTwo.pdf:adami02spkrChangeTwo.pdf:PDF},
  Url                      = {http://www.icsi.berkeley.edu/ftp/global/pub/speech/papers/icassp02-adami.pdf}
}

@Misc{adcock96mapBF,
  Title                    = {Microphone-array speech recognition via incremental {MAP} training},

  Author                   = {J. E. Adcock and Y. Gotoh and D. J. Mashao and H. F. Silverman},

  Comment                  = {255: ReadYes},
  Review                   = {MAP adaptation of beamformed data improves speech recog 
* delay and sum BF w/ brute force focus via phase match search and interp 
* 25ms frame w/ 12ms advance considered OK for speaker tracking (fs=16KHz)

* idea: train on ideal speech (headset microphone) and then retrain to adapt to BF data 
* BF recog pef better than single mic spectral subtraction 
* 16 microphones}
}

@InProceedings{afkhamie98adaptConvex,
  Title                    = {Adaptive system identification using interior point optimization},
  Author                   = {Afkhamie, K.H. and Luo, Z.-Q. and Wong, K.M.},
  Booktitle                = {Statistical Signal and Array Processing, {IEEE} workshop on},
  Year                     = {1998},
  Pages                    = {152-155},

  Comment                  = {ReadNo},
  Review                   = {relevant to the mono/ARMA/convex idea?},
  Url                      = {http://ieeexplore.ieee.org/iel4/5953/15928/00739357.pdf?isNumber=15928&prod=CNF&arnumber=739357&arSt=152&ared=155&arAuthor=Afkhamie%2C+K.H.%3B+Luo%2C+Z.-Q.%3B+Wong%2C+K.M.}
}

@InProceedings{ahn97harmVoice,
  Title                    = {Harmonic-plus-noise decomposition and its application in voiced/unvoiced classification},
  Author                   = {Ahn, R. and Holmes, W. H.},
  Booktitle                = {IEEE TENCON},
  Year                     = {1997},
  Pages                    = {587-590},
  Volume                   = {2},

  Comment                  = {ReadNo}
}

@InProceedings{ahn97imprvHarmVoice,
  Title                    = {An improved harmonic-plus-noise decomposition method and its application in pitch determination},
  Author                   = {Ahn, R. and Holmes, W. H.},
  Booktitle                = {Speech Coding For Telecommunications, {IEEE} workshop on},
  Year                     = {1997},
  Pages                    = {41-42},

  Comment                  = {ReadNo}
}

@InProceedings{airey03prodGMMasr,
  Title                    = {Product of Gaussians as a Distributed Representation for Speech Recognition},
  Author                   = {S.S. Airey and M.J.F. Gales},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {877-880},

  Comment                  = {566: ReadNo},
  Review                   = {Modelling speech w/ product of MOG: use for ICA? Two idep spkrs are prod of MOG's. Use updates in saul03statSigProcNonNega?}
}

@TechReport{ajmera-rr-02-23,
  Title                    = {Improved Unknown-Multiple Speaker clustering using {HMM}},
  Author                   = {J. Ajmera and H. Bourlard and I. Lapidot},
  Institution              = {IDIAP},
  Year                     = {2002},
  Number                   = {IDIAP-RR-02-23},

  Abstract                 = { In this report, we build up on our previous work on speaker clustering, where the number of speakers and segmentation boundaries are unknown a priori. We employ an ergodic HMM with minimum duration topology for this purpose. Starting from a large number of clusters in the beginning, we merge a pair of clusters in every iteration. A new criterion for the merging of two clusters is proposed, which ensures an increase in likelihood of the data. The merging is done in such a way that, the total number of parameters needed to model all the clusters remain same. Thus, the system finally achieves maximum likelihood (which was not the case in our last work) with the constant number of parameters. The merging process is repeated until there are no candidates available for merging. The efficiency and advantages of using only highly voiced frames was reported in our previous work, and we use the same features for this work. The system was evaluated on Hub-4 1996 evaluation set. Improvements over the previous work are reported and it is shown that, the system converges to right number of clusters in case of limited number of speakers.},
  Comment                  = {305: ReadYes},
  File                     = {ajmera-rr-02-23.ps.gz:ajmera-rr-02-23.ps.gz:PDF},
  Review                   = {Agglom clust, Viterbi reseg, BIC-like-but-avoiding stopping criteria
* improvement upon "Unknown-Multiple...", Ajmera 2002
Improvement is distance measure and stopping criteria
* As before, distance is a log likelihood difference but...
* # params in merge candidate == sum(# params) in pre-merge segs
* =exactly= the idea I had a year ago.
* stops clustering when distance says no improvement from any merge
* like BIC penalty (BIC, AIC.. explained) but not clear that it's better
* does # params increase exponentially w/ merge? 
* or # param increase done only when deciding if to merge
* initial # of GMM mixtures not given, nor is final # mixtures
Does not always get right # spkrs, even though that is claimed...},
  Url                      = {ftp://ftp.idiap.ch/pub/reports/2002/rr-02-23.ps.gz}
}

@TechReport{ajmera02hmmClustTR,
  Title                    = {Unknown-Multiple Speaker clustering using {HMM}},
  Author                   = {Jitendra Ajmera and Herve Bourlard and Itshak Lapidot and Iain McCowan},
  Institution              = {IDIAP},
  Year                     = {2002},
  Number                   = {IDIAP-RR 02-07},

  Comment                  = {ReadNo},
  Review                   = {Longer version of ICSLP paper of same title}
}

@TechReport{ajmera02hmmSpkrClust,
  Title                    = {Unknown-Multiple Speaker clustering using {HMM}},
  Author                   = {J. Ajmera and H. Bourlard and I. Lapidot and I. McCowan},
  Institution              = {Dalle Malle Institute for Perceptual Artificial Intelligence},
  Year                     = {2002},
  Number                   = {IDIAP-RR 02-07},

  Abstract                 = { An HMM-based speaker clustering framework is presented, where the number of speakers and segmentation boundaries are unknown \emph{a priori}. Ideally, the system aims to create one pure cluster for each speaker. The HMM is ergodic in nature with a minimum duration topology. The final number of clusters is determined automatically by merging closest clusters and retraining this new cluster, until a decrease in likelihood is observed. In the same framework, we also examine the effect of using only the features from highly voiced frames as a means of improving the robustness and computational complexity of the algorithm. The proposed system is assessed on the 1996 HUB-4 evaluation test set in terms of both cluster and speaker purity. It is shown that the number of clusters found often correspond to the actual number of speakers. },
  Booktitle                = {Proc. ICSLP},
  Comment                  = {304: ReadYes},
  File                     = {ajmera02hmmSpkrClust.ps.gz:ajmera02hmmSpkrClust.ps.gz:PDF},
  Review                   = {Agglom clust but HMM states = speakerID's; iterative Viterbi re-segment
Initialization:
* each segment is an HMM state (seg bndry def. not clear)
* HMM state params initialized w/ k-means
Iteration:
a.) Viterbi resegment
b.) Retrain HMM state parms
c.) Merge one cluster pair w/ log likelihood distance measure
d.) stopping if decrease in total HMM data likelihood 
* Improved sorta-BIC merge/stop in "Improved unknown...", Ajmera 2002
* More detail in "Robust HMM based speech/music...", Ajmera 2002
* Features: LPCC coeffs
* HMM min time contraints not defined, nor are trans. probs (trained?)
* evaluated on 1996 Hub-4 
* works somewhat but abstract claims more accuracy than published result
Pre voicing detect:
* claim: voiced frames have little spkr ID info (LPCC, not really clear)
* no VAD so it's not clear (voice det. removes unvoiced =and= sil)
* anyway, maybe this suggests that cluster only on voiced and assign unvoiced later
* would},
  Url                      = {ftp://ftp.idiap.ch/pub/reports/2002/rr02-07b.ps.gz}
}

@InProceedings{ajmera04spkrSegClustLoc,
  Title                    = {CLUSTERING AND SEGMENTING SPEAKERS AND THEIR LOCATIONS IN MEETINGS},
  Author                   = {Jitendra Ajmera and Guillaume Lathoud and Iain McCowan},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2004},

  Comment                  = {601:ReadYes},
  File                     = {ajmera04spkrSegClustLoc.pdf:ajmera04spkrSegClustLoc.pdf:PDF},
  Review                   = {MFCC/loc feat HMM clustering, locs from arr, MFCC's from lapels
* 8 mic circ array, 4 lapels, meeting data
* MFCCs from largest energy lapel (# spkrs != # lapels??)
* grid focus w/ SRP-PHAT localization (Brandstein, Ch. 8)
* seems to handle short segs but no explicit stats given
* 2D locs clustered w/ k-means, std sum stopping criteria
- says want only single GMM so have convex az/elev regions
- use only azimuth in calcualting stop but both for model
- # locs != # spkrs so people can move. Discrete locs assumed
* joint loc/spkr HMM state: (#locs X #segments)
- num locs est doesn't change but # spkrs does
- no pre-VAD
- no hint at initial state width, although say 50% segs<960ms
Results
* got right # spkrs w/ and w/o loc feats
* loc feats improved perf e.g. 92.6% --> 94.6%},
  Url                      = {http://ssli/proceedings/icassp04/pdfs/0100605.pdf}
}

@Article{Ajmera2Speech/MusicDiscriminationusing,
  Title                    = {Speech/Music Discrimination using Entropy and Dynamism Features in a {HMM} Classification Framework},
  Author                   = {J. Ajmera and I. McCowan and H. Bourlard},
  Journal                  = {Speech Communication},
  Year                     = {2002 },

  Abstract                 = {In this paper, we present a new approach towards high performance speech/music discrimination on realistic tasks related to the automatic transcription of broadcast news. In the approach presented here, the (local) Probability Density Function (PDF) estimators trained on clean, microphone, speech (as used in a standard large vocabulary speech recognition system) are used as a channel model at the output of which the entropy and ``dynamism'' will be measured and integrated over time through a 2-state (speech and and non-speech) hidden Markov model (HMM) with minimum duration constraints. Indeed, in the case of entropy, it is clear that, on average, the entropy at the output of the local PDF estimators will be larger for speech signals than non-speech signals presented at their input. In our case, local probabilities will be estimated from an multilayer perceptron (MLP) as used in hybrid HMM/MLP systems, thus guaranteeing the use of ``real'' probabilities in the estimation of the entropy. The 2-state speech/non-speech HMM will thus take these two dimensional features (entropy and ``dynamism'') whose distributions will be modeled through (two-dimensional) multi-Gaussian densities or an MLP, whose parameters are trained through a Viterbi algorithm.\\ Different experiments, including different speech and music styles, as well as different (a priori) distributions of the speech and music signals (real data distribution, mostly speech, or mostly music), will illustrate the robustness of the approach, always resulting in a correct segmentation performance higher than 90\%. Finally, we will show how a confidence measure can be used to further improve the segmentation results, and also discuss how this may be used to extend the technique to the case of speech/music mixtures.},
  Comment                  = {306: ReadYes},
  File                     = {ajmera02spchMusic.ps.gz:ajmera02spchMusic.ps.gz:PDF},
  Review                   = {HMM Viterbi decode, phone modelset entropy and prob dynamism features
* HMM viterbi decode like in other Ajmera papers
* (to be published)
Features:
* phone model entropy
-- many phone models pre-trained
-- low entropy (one phone model has high post. prob) => speech 
-- no phone model match better than others => high entropy => music
-- problems w/ all phones having bad match but one better than others?
-- need to normalize entropy somehow so probs sum to one?
* dynamism
-- how fast phone probs change
-- guess: music phone probs change less (doesn't turn out that way)
Neural Net v.s. GMM
* uses NN to calculate phone probs
* compares NN to GMM for fusing entropy and dynamism features
* fusion NN misses a little less speech than fusion GMM
* but not clear that they're of same complexity (# of params)
Confidence measure helps
* MPCM confidence measure for each segment
* low conf. segs assigned to neighbor segs if they're high confidence.
* assignment not clear when neighbors aren't of same type
* but whatever... this improves performance a little bit
* good idea for VAD too},
  Url                      = {ftp://ftp.idiap.ch/pub/reports/2001/rr01-26.ps.gz}
}

@InProceedings{Ajmera03spkrClust,
  Title                    = {A robust speaker clustering algorithm},
  Author                   = {Ajmera, J.; Wooters, C.},
  Year                     = {30 Nov.-3 Dec. 2003},
  Pages                    = { 411-416},

  Doi                      = {10.1109/ASRU.2003.1318476},
  File                     = {Ajmera03spkrClust.pdf:Ajmera03spkrClust.pdf:PDF},
  ISSN                     = { },
  Journal                  = {Automatic Speech Recognition and Understanding, 2003. ASRU '03. 2003 IEEE Workshop on},
  Keywords                 = { belief networks, error statistics, hidden Markov models, pattern clustering, speaker recognition, speech processing Bayesian information criterion, HMM, NIST, USA National Institute of Standards and Technology, agglomerative clustering, performance, robust speaker clustering algorithm, speaker segmentation, speaker-diarization error rate, standard speech processing},
  Owner                    = {scotto},
  Review                   = {Original HMM/BIC clustering paper, I think
* explains why merged clust has Na+Nb params, where Na,Nb are the # params for the clusters being evaluated for a merge (seems like later versions had the option of removing params from the merged cluster model)
* explains the HMM},
  Timestamp                = {2007.11.20},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1318476}
}

@InProceedings{akagi98:_spect,
  Title                    = {Spectral sequence compensation based on continuity of spectral sequence},
  Author                   = {M. Akagi and M. Iwaki and N. Sakaguchi},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1998},
  Pages                    = {1407-1410},
  Volume                   = {4},

  Comment                  = {192: ReadYes},
  Review                   = {Reconstruct corrupted speech using 2nd order peak extrapolation
* locate peaks in ceptstrum oand the refine in wavelet domain
* 4 things extrapolated per peak: freq amp, symmetry (phase?), bandwidth
* only tested w/ white noise interupting synthetic vowels
* very corny noise detection switch determiens if extrapolation is needed
* can this really work?},
  Url                      = {http://wwwhome.cs.utwente.nl/~taaltool/Icslp98/HTML/SL98S126.HTM#p0028}
}

@InProceedings{Akaike74AICdim,
  Title                    = {Information theory and an extension of the
maximum likelihood principle},
  Author                   = {Akaike, H.},
  Booktitle                = {Proc., 2nd Intern'l Symposium on Information Theory},
  Year                     = {1974},
  Editor                   = {Petrov and Caski},
  Pages                    = {267-281},

  Owner                    = {scotto},
  Timestamp                = {2008.01.28}
}

@TechReport{Albright06NNMFinitTechRep,
  Title                    = {Algorithms, Initializations, and Convergence for the Nonnegative Matrix Factorization},
  Author                   = {Russell Albright and James Cox and David Duling and Amy Langville and Carl Meyer},
  Institution              = {NC State University},
  Year                     = {2006},
  Number                   = {81706,},
  Type                     = {NCSU Technical Report Math},

  File                     = {Albright06NNMFinitTechRep.pdf:Albright06NNMFinitTechRep.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {SVD centroid is best way to inititialize Non-Negative Matrix Factorization (NNMF) There's a short version of this by Langville
* good comparison of relative merits of NNMF vs. SVD
 - SVD is theortical best reconstructor for given rank
 - SVD has unique global min
 - SVD compression is not sparse
 - NNMF is sparse
 - NNMF is "parts-based," meaning that additive pos. numbers are more indicative
 - NNMF produces positive decomp (==> input must be pos too!)
* NNMF ACLS and AHCLS algorithms require about the same time as SVD!
* They only initialize W, and then compute H by least squares.
 - all that is required for their ALS algorithms, ACLS and AHCLS
* Six initialization methods compared, SVD centroid is best
* in fact SDV centroid is much better than the centroid algorithm it's approximating (dhillon:modha:concept)
* Also recommends an NNMF stopping criteria},
  Timestamp                = {2007.03.01},
  Url                      = {http://meyer.math.ncsu.edu/Meyer/Abstracts/InitNMF.html}
}

@Article{aldroubi01nonuniform,
  Title                    = {Nonuniform Sampling and Reconstruction in Shift-Invariant Spaces},
  Author                   = {A. Aldrouibi and K. Grochenig},
  Journal                  = {SIAM Review},
  Year                     = {2001},
  Number                   = {4},
  Pages                    = {585-620},
  Volume                   = {43},

  Comment                  = {0: ReadNo},
  Review                   = {Better reconstruction when non-uniform sampling}
}

@Article{Aleksic06multiHmmFace,
  Title                    = {Automatic facial expression recognition using facial animation parameters and multistream HMMs},
  Author                   = {Aleksic, P.S.; Katsaggelos, A.K.},
  Journal                  = {Information Forensics and Security, IEEE Transactions on},
  Year                     = {March 2006},
  Number                   = {1},
  Pages                    = { 3-11},
  Volume                   = {1},

  Doi                      = {10.1109/TIFS.2005.863510},
  File                     = {:Aleksic06multiHmmFace.pdf:PDF},
  ISSN                     = {1556-6013},
  Keywords                 = { computer animation, edge detection, face recognition, hidden Markov models MPEG-4 standards, automatic facial expression recognition, facial animation parameters, hidden Markov models, multistream HMM},
  Owner                    = {scotto},
  Timestamp                = {2007.11.20}
}

@Article{algazi97depHRTF,
  Title                    = {Subject dependent transfer functions in spatial hearing},
  Author                   = {V. R. Algazi and P. L. Divenyi and V. A. Martinez and R. O. Duda},
  Journal                  = {Unknown},
  Year                     = {1997},

  Comment                  = {222: ReadYes},
  Review                   = {Plan is to make HRTF for a person based on stereoscopic measurements (not actually done here) 
* azimuth: time delay and head shadow 
* elevation pinna relfections (outer ear shape) 
* tube to ear drum poses one more resonance, which is position indep}
}

@InProceedings{abdelatty01stops,
  Title                    = {Robust classification of stop consonants using auditory-based speech processing},
  Author                   = {A. M. A. Ali and J. van der Spiegel and P. Mueller},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},

  Comment                  = {229: ReadYes},
  Review                   = {Articulatory est. for stop phonemes (hard) 
* use features from auditory-like synchrony detector 
* should be fairly easy to implement 
* referencs for sunhchrony det may be worth looking up 
* would this help VAD on the edges?}
}

@Article{alkire02convexRxx,
  Title                    = {Convex optimization problems involving finite autocorrelation sequences},
  Author                   = {B. Alkire and L. Vandenberghe },
  Journal                  = {Mathematical Programming, Series A},
  Year                     = {2002},

  Comment                  = {ReadNo},
  File                     = {alkire02convexRxx.pdf:alkire02convexRxx.pdf:PDF},
  Review                   = {Solves for ARMA coeffs w/ convex opt. reverb w/ LP model speech imposed is an ARMA. Also, it seems like some ICA things are convex opt. probs.
* has matlab and c++ software (updir for a lot of other software): http://www.ee.ucla.edu/~vandenbe/autocorr/sw.htm
* Is this a way to do all of them, particularly in the monaural case, where
LP's would add extra terms in mono-caused underdetermined case?},
  Url                      = {http://www.ee.ucla.edu/~vandenbe/reports/alv01b.pdf}
}

@Article{alkire02convOptAutocorr,
  Title                    = {Convex optimization problems involving finite autocorrelation sequences},
  Author                   = {B. Alkire and L. Vandenberghe },
  Journal                  = {Mathematical Programming, Series A},
  Year                     = {2002},
  Number                   = {3},
  Pages                    = {331-359},
  Volume                   = {93},

  Comment                  = {610:ReadNo},
  Review                   = {Efficient cone programming freq match w/ autocorr. Use for crosscorr?

Initial applications:
- forcing non-neg spectral density estimates
- freq domain IIR system ID
- FIR mag filter design
- IIR mag filter design

Somehow use these tricks for crosscorr? Note: uses FFTW and Matlab. Beg for code?},
  Url                      = {http://www.ee.ucla.edu/~vandenbe/alv01b.htm}
}

@InProceedings{alkire00posSpec,
  Title                    = {Handling Nonnegative Constraints in Spectral Estimation},
  Author                   = {B. Alkire and L. Vandenberghe },
  Booktitle                = {{IEEE} Asilomar Conf. on Signals, Systems and Computers},
  Year                     = {2000},
  Pages                    = {202-206},
  Volume                   = {1},

  Comment                  = {ReadNo},
  Review                   = {Autocorr est forcing freq mag to positive. Maybe useful for enforcing spectral correlation in ICA (like Anemuller). Much more detailed paper at:
http://www.ee.ucla.edu/~vandenbe/alv01b.htm
(several others too, like on FIR design)},
  Url                      = {http://www.ee.ucla.edu/~vandenbe/alv00.htm}
}

@Article{altincay00infoComb,
  Title                    = {An information theoretic framework for weight estimation in the combination of probabilistic classi?ers for speaker identi?cation},
  Author                   = {Hakan Altincfay and Mubeccel Demirekler},
  Journal                  = {Speech Communication},
  Year                     = {2000},
  Pages                    = {255-272},
  Volume                   = {30},

  Comment                  = {300: ReadNo}
}

@InProceedings{amari95bssRecNN,
  Title                    = {Recurrent neural networks for blind separation of sources},
  Author                   = {S. Amari and A. Cichocki and H. Yang},
  Booktitle                = {Proc. Int. Symp. {NOLTA}},
  Year                     = {1995},
  Pages                    = {37-42},

  Comment                  = {ReadNo},
  Review                   = {has an error measure for source sep used in Blaschke, "an improved...". Use for overlap detection?},
  Url                      = {citeseer.nj.nec.com/amari95recurrent.html}
}

@InProceedings{amari96infoTheoICA,
  Title                    = {A new learning algorithm for blind signal separation},
  Author                   = {S. Amari and A. Cichoki and H. H. Yang},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {1996},
  Pages                    = {757-763},
  Publisher                = {{MIT} Press},
  Volume                   = {8},

  Comment                  = {ReadNo},
  Review                   = {Ref in Haykin slides for information-theoretic ICA approach. I think the slides are wrong (it's min mut inf of unmixed _components_ not of the unmixing matrix). Covered in Ch 10 of Hyvarinen book.}
}

@Misc{andrieu00sinGauss,
  Title                    = {Default prior for robust {Bayesian} model selection of sinusoids in gaussian noise},

  Author                   = {C. Andrieu and J. M. Perez},
  Year                     = {2000},

  Comment                  = {55: ReadNo},
  Review                   = {speaker overlap resolution? number of talkers if pitch is approx a sinusoid (voiced only)}
}

@Misc{andrieuXXmcmcModelSel,
  Title                    = {Sequential {MCMC} For {Bayesian} model selection},

  Author                   = {C. Andrieua and N. de Freitas and A. Doucet},

  Comment                  = {7.0: ReadNo}
}

@PhdThesis{anemuller01cfBSS_PhD,
  Title                    = {Across-Frequency Processing in Convolutive Blind Source Separation},
  Author                   = {J\"orn Anem\"uller},
  School                   = {Vom Fachbereich Physik der Universitat Oldenburg zur Erlangung des Grades eines},
  Year                     = {2001},

  Comment                  = {334: ReadYes},
  File                     = {anemuller01cfBSS_PhD.pdf:anemuller01cfBSS_PhD.pdf:PDF},
  Review                   = {Thesis: BSS using cross-freq corr of speech (due to amplitude mod.)
* Very good thesis
* Good explanation of Gaussianess and Kurtosisnes of mixing
Three main algorithms
1.) fast adaptive BSS (for anechoic)
2.) AMDecorr (for convolutive)
3.) 2D ICA
In general his algorithms solve permutation/scaling problems
* work better if you include cross-freq upfront, rather than use them later to figure out the ambiguity
* maybe 1.) is fast enough for overlap detection?

* Student of Berger Kollmeier (BK recommended by Nelson Morgan)},
  Url                      = {http://docserver.bis.uni-oldenburg.de/publikationen/dissertation/2001/aneacr01/pdf/aneacr01.pdf}
}

@InProceedings{anemuller99corrModBSS,
  Title                    = {Correlated modulation: a criterion for blind source separation},
  Author                   = {J\"orn Anem\"uller},
  Booktitle                = {Joint meeting of the Acoustical Society of America and the European Acoustics Association},
  Year                     = {1999},

  Comment                  = {336: ReadYes},
  Review                   = {Use speech's cross-freq cov in freq domain ICA. See Anemuller's PhD Thesis},
  Url                      = {http://medi.uni-oldenburg.de/members/ane/pub/}
}

@Misc{anemullerXXbssMove,
  Title                    = {On-Line Blind Separation Of Moving Sound Sources},

  Author                   = {J\"orn Anem\"uller and Tino Gramss},

  Comment                  = {ReadNo},
  Url                      = {citeseer.nj.nec.com/315974.html}
}

@InProceedings{anemuller99moveBSS,
  Title                    = {On-line blind separation of moving sound sources},
  Author                   = {J\"orn Anem\"uller and Tino Gramss},
  Booktitle                = {Intl. workshop on independent component analysis and signal separation},
  Year                     = {1999},
  Pages                    = {331-334},

  Comment                  = {335: ReadYes},
  Review                   = {Freq domain fast adaptive ICA for delay and scale only
* very fast: 1s convergence
* assumes no reverb
* would it still work for overlap detection (not resolution)?
* Anemuller's PhD thesis has more detail}
}

@Misc{anemullerXXbssMod,
  Title                    = {Amplitude Modulation Decorrelation For Convolutive Blind Source Separation},

  Author                   = {J\"orn Anem\"uller and Birger Kollmeier},

  Comment                  = {ReadNo},
  Url                      = {citeseer.nj.nec.com/326442.html}
}

@InProceedings{anemuller00ampDecorr,
  Title                    = {Amplitude modulation decorrelation for convolutive blind source separation},
  Author                   = {J\"orn Anem\"uller and Birger Kollmeier},
  Booktitle                = {Independent component analysis and blind signal separation, Intl. Conf. on},
  Year                     = {2000},
  Pages                    = {215-220},

  Comment                  = {337: ReadYes},
  Review                   = {Cross-freq correlation cost function improves ICA
* this is covered in Anemuller's PhD thesis
* note: uses Frobenius Norm; Wu99sdif uses Hadamard instead of Frob, says it's more efficient}
}

@PhdThesis{anguera06thesis,
  Title                    = {Robust Speaker Diarization for meetings},
  Author                   = {Xavier Anguera},
  School                   = {Universitat Politecnica de Catalunya},
  Year                     = {2006},

  File                     = {anguera06thesis.pdf:anguera06thesis.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Xavi's PhD thesis on diarization with location features},
  Timestamp                = {2008.02.22}
}

@InProceedings{Anguera06HybridSpeechNonSpeech,
  Title                    = {Hybrid Speech/Non-Speech Detector Applied to Speaker Diarization of Meetings},
  Author                   = {X. Anguera and M. Aguilo and C. Wooter and C. Nadeu and J. Hernando},
  Booktitle                = {Speaker Odyssey 06},
  Year                     = {2006},

  File                     = {Anguera06HybridSpeechNonSpeech.pdf:Anguera06HybridSpeechNonSpeech.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Xavi's energy VAD: differentiator energy thresh followed by HMM retrain/resegment

* idea is to improve robustness by not pretraining

* standard energy differentiating endpoint detector for 1st stage
 - Weiner filtered input
 - time-varying max normalization
 - apparently three stages of energy differentiating and thresholding
 - iterates to adjust thresh until have 10-100 speech frames
 - finite state machine to set duration
 - duration optimized for low speech miss rate 
 - non-speech should have very low variance, 1 mixture
 - any speech leaking in will screw up

* iterative HMM train resegment for final VAD
 - same speech and non-speech duration
 - input is energy again

* three tunable params
 1.) min seg dur. in energy diff det.
 2.) number of speech mixtures (chose 2)
 3.) min seg dur in HMM seg

RESULTS
* 6.5% error pretrained VAD --> 4.9% error
 - but I'm not sure what the pretrained VAD was, or if it was energy or what
 - shouldn't MFCC's be somewhat energy indepedent?
* diarization error: 15.5% (pretrained) --> 14% (hybrid)},
  Timestamp                = {2006.08.08},
  Url                      = {http://www.icsi.berkeley.edu/cgi-bin/pubs/publication.pl?ID=002074}
}

@InProceedings{Anguera06AutomaticClusterComplexity,
  Title                    = {Automatic Cluster Complexity and Quantity Selection: Towards Robust Speaker Diarization},
  Author                   = {Xavier Anguera and Chuck Wooters and Javier Hernando},
  Booktitle                = {Speaker Odyssey 06},
  Year                     = {2006},

  Comment                  = {620:ReadYes},
  File                     = {Anguera06AutomaticClusterComplexity.pdf:Anguera06AutomaticClusterComplexity.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Initial number of clusters, cluster duration, and number of mixtures during diarization clustering

* Fixes some problems w/ Ajemera's original HMM clustering algorithm
 1.) make initial number of clusters proportional to meeting length
 2.) during HMM agglom clustering, keep number of mixtures proportional # frames in cluster
 3.) during HMM agglom clustering, remove affect of terminal transition prob (no seg len influence)

* improvement is something like 3% better DER},
  Timestamp                = {2006.08.08}
}

@Conference{Anguera06AutomaticClustercomplexitySlides,
  Title                    = {Automatic Cluster complexity and Quantity Selection: Towards Robust Speaker Diarization},
  Author                   = {Xavier Anguera and Chuck Wooters and Javier Hernando},
  Booktitle                = {MLMI},
  Year                     = {2006},

  Comment                  = {619:ReadYes},
  File                     = {Anguera06slidesAutomaticClusterComplexity.ppt:Anguera06slidesAutomaticClusterComplexity.ppt:PDF},
  Owner                    = {scotto},
  Review                   = {Slides for Anguera06AutomaticClusterComplexity},
  Timestamp                = {2006.08.08}
}

@InProceedings{Anguera06FramePurificationCluster,
  Title                    = {Frame Purification For Cluster Comparison In Speaker Diarization},
  Author                   = {Xavier Anguera and Chuck Wooters and Javier Hernando},
  Booktitle                = {MMUA '06},
  Year                     = {2006},

  Comment                  = {622: ReadYes},
  File                     = {Anguera06FramePurificationCluster.pdf:Anguera06FramePurificationCluster.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Removing short silences in long segs during BIC compare in diarization agglomerative clustering

* Says that min cluster dur for Ajmera HMM clustering is 3s
 ==> sometimes include speech from another speaker (this doesn't fix that, although it doesn't admit that)
 ==> will have short silences included
 Both will screw up the delta BIC compare during cluster merge decision

* Trick to remove silences during compare (when cluster will have >=2 mixtures)
 - train GMM on segs to consider for merging
 - eliminate frames in the upper ~ 20% th percentile (these are probably non-speech)
 - then do normal delta BIC

* Two metrics for calculating the likelihoods
 1.) use all mixtures in model (DERR improvement: 15.34% --> 14.42%)
 2.) use 50% of mixtures w/ smallest variance (15.34% --> 14.33%, so this works _slightly_ better)

* Why this works (ie. why are non-speech frames high likelihood?)
 - not many non-speech frames (because of VAD preproc)
 - non-speech has inherently less variance than speech (so better fit to a mixture component)
 - nice plots in FIg 5 showing how this works for nmix>=2

* A slightly better explanation of the frame purificiation algorithm in [Anguera06PurityalgorithmsSpeaker]},
  Timestamp                = {2006.08.08}
}

@InProceedings{Anguera06FriendsandEnemies,
  Title                    = {Friends and Enemies: A Novel Initialization for Speaker Diarization},
  Author                   = {Xavier Anguera and Chuck Wooters and Javier Hernando},
  Booktitle                = {ICSLP '06},
  Year                     = {2006},

  Comment                  = {618:ReadYes},
  File                     = {Anguera06FriendsandEnemies.pdf:Anguera06FriendsandEnemies.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Diarization clustering initialization: non-contiguous segs in same init cluster, variable width

* an improvement over "linear" cluster initialization
* used in ICSI's RT06 system
* idea is to yield initial clusters with better "purity" (single speaker)
* explanation is kind of bad
* giant minimum cluster size!
 - 3s
 - is this OK because 
 - the RT06 system also used the frame purification technique?
 - there's VAD to remove nonspeech? (not clear)
* initial # clusters defined by algorithm in Xavi's complexity paper

 - just prop. meeting length
 - (Anguera06AutomaticClusterComplexity)

Steps:
1.) speaker change point detection
2.) group segments (friends) together, creating the desired number of
initial clusters (enemies between them). 
3.) reassign frames to closest cluster (ignoring detected change points)
4.) retrain initial cluster models based on this reassignment 

RESULTS (RT05s, over linear initialization):
* 13% relative DER improvement
* 2.5% absolute improvement in initial cluster purity},
  Timestamp                = {2006.08.08}
}

@InProceedings{Anguera06PurityalgorithmsSpeaker,
  Title                    = {Purity algorithms for Speaker Diarization of Meetings Data},
  Author                   = {Xavier Anguera and Chuck Wooters and Javier Hernando},
  Booktitle                = {ICASSP},
  Year                     = {2006},

  Comment                  = {00615: ReadYes},
  File                     = {Anguera06PurityalgorithmsSpeaker.pdf:Anguera06PurityalgorithmsSpeaker.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Diarization clustering removal of bad frames and splitting improperly merged frames

* Two kinds of errors screw up agglomerative clustering
 1.) segment: falsely merged clusters
 - proposed fix (after merge)
 - remove seg most different from seg that best fits cluster model
 - if declare cluster model "pure" if all fit OK: don't touch later
 2.) frame: nonspeech segments within clusters
 - causes false alarms and missed merges
 - noticed: non-speech fits agglom cluster models best
 - proposed fix (during merge)
 - foreach pair of clusters to merge
 - calc average model fit for each frame
 - "model" is all speech mixtures in meeting or subset including non-speech
 - NOT CLEAR if using a VAD first
 - remove highest P% frames (presumably nonspeech)
 - do merge decision (train models and calc delta BIC) 

* RESULTS
 - frame based works better than seg based or seg+frame based
 - both frame or seg are better than nothing
 - not clear which kind of model in frame based is best

* Huge minimum segment length: 3s ! 
 - does this make these algorithms look better than they would have?

* Explained slightly better in [Anguera06FramePurificationCluster]},
  Timestamp                = {2006.06.05},
  Url                      = {http://www.icassp2006.org/Papers/viewpapers.asp?papernum=4229}
}

@InProceedings{Anguera05diarizationFusion,
  Title                    = {Speaker Diarization For Multi-Party Meetings Using Acoustic Fusion},
  Author                   = {Xavier Anguera and Chuck Wooters and Javier Hernando},
  Booktitle                = {ASRU},
  Year                     = {2005},

  Comment                  = {614:ReadYes},
  File                     = {anguera05diarizationFusion.pdf:anguera05diarizationFusion.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Xavi's initial delay+sum MFCC

* clustering feature is MFCC weighted delay-sum waveform (I think)
* delay calc
 - for calculating delay sum
 - use GCC-PHAT
 - works best if use reference w/ highest SNR (Table 4, not SDM chan)
 - 2006, Xavi used "most correlated chan" I think
 - was this because of SNR VAD problems? I think I remember this.
 - 500ms xcorr window worked best
 - max distance in xcorr=7meters
 - Weiner filtered before xcorr (does this hurt xcorr?)
 - delay continuity filtering
 - tries to match prev peak within +- 10 samples (no quality weight?? IDEA!)
 - search is among the 8 biggest peaks
 - IDEA: add a peak quality weight
 - IDEA: prefer peaks that are harmonically spaced
 - IDEA: anti-causal sliding window forcing best consistency over 0.5s window
 - force match of previous frame peak if xcorr coeff<=0.1
* sum 
 - must calc delay before sum,else bad results (Table 4)
 - pre-weight by corr coeff for best result (Table 4)
 wieght is smoothed by single pole LPF
* weighted-delay-sum works better than SDM
 - except on some ICSI meetings (bad mic's?)
 - better than any RT04s system

* improved in Anguera06PurityalgorithmsSpeaker},
  Timestamp                = {2006.08.08},
  Url                      = {http://www.icsi.berkeley.edu/cgi-bin/pubs/publication.pl?ID=001960}
}

@InProceedings{Anguera06RobustSpeakerDiarization,
  Title                    = {Robust Speaker Diarization for Meetings: {ICSI RT06s} evaluation system},
  Author                   = {Xavier Anguera and Chuck Wooters and Jose M. Pardo},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2006},

  Comment                  = {621:ReadYes},
  File                     = {Anguera06RobustSpeakerDiarization.pdf:Anguera06RobustSpeakerDiarization.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Xavi's RT06s diarization speaker: VAD, clustering tweaks, includes delays

* Speaker diarization based on Ajmera HMM agglomerative clustering.

* Many new tweaks and best perf. of RT06s (I think)
* Details of tweaks are in separate papers (most in my bib, I think)

Improvements over RT05 (I believe)
* adaptive energy VAD: endpoint/state machine --> HMM retrain/seg [Anguera06HybridSpeechNonSpeech]
* data-dependent initial cluster selection (not linearly selected segs) [Anguera06FriendsandEnemies]
* frame purification during BIC calc [Anguera06FramePurificationCluster]
* use delays as a feature similar to [Anguera05diarizationFusion] but merging not really explained here

Notes to self
* recommends using forced alignments instead of NIST hand labels (so get from ICSI)
* AMI benefits the most from MDM treatment
* LDC is the only one that is worse with MDM (vs. SDM)
* Says LDC is reason why SDM better than MDM in RT02s and RT04s (true for me?)

RESULTS
* pretty good!, best in RT06?


* min duration == 3s!},
  Timestamp                = {2006.08.08},
  Url                      = {http://www.icsi.berkeley.edu/cgi-bin/pubs/publication.pl?ID=002060}
}

@InProceedings{Anguera07tdoaAcoustWeights,
  Title                    = {Automatic Weighting for the Combination Of {TDOA} and Acoustic Features in Speaker Diarization for Meetings},
  Author                   = {Xavier Anguera and Chuck Wooters and Jose M. Pardo and Javier Hernando},
  Booktitle                = {ICASSP},
  Year                     = {2007},
  Pages                    = {241-244},
  Volume                   = {IV},

  File                     = {Anguera07tdoaAcoustWeights.pdf:Anguera07tdoaAcoustWeights.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Adaptive MFCC/xcorr stream weights for diarization
* same weights used for segmentation and cluster merging
* inverse entropy stream weights fail b/c TDOA entropy is always low (confident but wrong)
* So the algorithm used here is a kind of variance normalized deltaBIC

 - is the average "difference" between all class (speaker) models
 - is updated after each cluster merging operation, I think
 - is time independent, so I have an opportunity to improve},
  Timestamp                = {2007.09.10}
}

@InProceedings{anguera05spkrsegRT05,
  Title                    = {Robust Speaker Segmentation for Meetings: The {ICSI-SRI} Spring 2005 Diarization System},
  Author                   = {Xavier Anguera and Chuck Wooters and Barbara Peskin and Mateu Aguil?o},
  Booktitle                = {{IEEE ASRU} 2005},
  Year                     = {2005},

  Comment                  = {ReadNo},
  File                     = {anguera05spkrsegRT05.pdf:anguera05spkrsegRT05.pdf:PDF},
  Review                   = {Xavi's 2005 RT05 paper, I think.},
  Url                      = {http://www.icsi.berkeley.edu/ftp/global/pub/speech/papers/rt05s.pdf}
}

@InProceedings{araki01icaFreqLimit,
  Title                    = {Fundamental limitation of frequency domain blind source separation for convolved mixture of speech},
  Author                   = {Shoko Araki and Shoji Makino and Ryo Mukai and Tsuyoki Nishikawa and Hiroshi Saruwatari},
  Booktitle                = {Independent Components Analysis, Intl. Conf. on},
  Year                     = {2001},

  Comment                  = {409: ReadYes},
  Review                   = {Simple Freq domain ICA: Optimal DFT length; LSQ BF equiv => limitations
* This is all for freq domain ICA based on min KL dist (refs 3, 10)
* DFT length < room impulse length is bad
-- can'nt make an unmixing filter long enough
* DFT length >> impulse length actually is a bat
-- window too long => too few points in DFT bins => not zero mean
-- graph: DFT coeffs of truely indep srcs. are correlated for long wins
-- but, do better if increase ICA learning time (more pts in DFT bins)
* LSQ beamformer is the best case for this ICA
-- best case is when DFT's are are truely indep
-- LSQ BF => can only stick in one null (for two mics)
-- LSQ BF puts nulls in source dir => misses reverb from other dirs
-- explains why neither LSQ BF or freq domain ICA are great in reverb
-- seems like LSQ equiv could also have been shown w/ Cardoso's method
* note: Anemuller's freq domain ICA additionally has cross-freq xcorr
-- would this escape the LSQ BF limit?
-- would still have the # pts in each bin problem
* note: other methods including freq domain + extra criteria may work better (again, see Cardoso, "three easy ways...")},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/035-araki.pdf}
}

@InProceedings{Archambeau07MixRobustPCA,
  Title                    = {Mixtures of Robust Probabilistic Principal Component Analyzers},
  Author                   = {C. Archambeau and N. Delannay and M. Verleysen},
  Booktitle                = {Proc., 15th European Symposium on Artificial Neural Networks (ESANN),},
  Year                     = {2007},
  Pages                    = {229-234},

  File                     = {Archambeau07MixRobustPCA.pdf:Archambeau07MixRobustPCA.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Mixture of student-T probabalistic principle component analysers
* based on Archambeau06RobustProbProj, which does CCA, so could be extended?},
  Timestamp                = {2007.05.31},
  Url                      = {http://www.cs.ucl.ac.uk/staff/C.Archambeau/}
}

@InProceedings{Archambeau06RobustProbProj,
  Title                    = {Robust probabilistic projections},
  Author                   = {Cedric Archambeau and Nicolas Delannay and Michel Verleysen},
  Booktitle                = {ACM Intl. Conf. Proceeding Series},
  Year                     = {2006},
  Pages                    = {33-40},
  Volume                   = {148},

  File                     = {Archambeau06RobustProbProj.pdf:Archambeau06RobustProbProj.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Probabilistc PCA and CCA using Student's T noise model
* rejects outliers so might be good for xcorr lag pitch-multiple errors},
  Timestamp                = {2007.05.31},
  Url                      = {http://portal.acm.org/citation.cfm?id=1143849}
}

@Article{arslan00nnspkloc,
  Title                    = {A unified neural-network-based speaker localization technique},
  Author                   = {G. Arslan and F. A. Sakarya},
  Journal                  = {Neural Networks, IEEE Transactions on},
  Year                     = {2000},
  Number                   = {4},
  Pages                    = {97 -1002},
  Volume                   = {11},

  Comment                  = {174: ReadYes},
  Review                   = {Use NN to learn locs from linear array spect xcorr
* uses uniform linear array
* other techs fail in near field -- this one doesn't, since it memorizes
* good equations/graphs for far/near field
* better perf for lambda/2 spacing (which we won't have)
* empirically determined that d=0.2353lambda is best spacing
* est phase from K=4 largest mag spectral xcorr (adjacent mic) bins

* NN feature vect is K bins of each mics xcorr and freq loc of each bin
* diminishing returns after about 4 mics
* use N=128 pt. FFT
* angle range is about +-75 degrees}
}

@InProceedings{Asami05multiStreamLDAboost,
  Title                    = {Stream-weight optimization by LDA and adaboost for multi-stream speaker verification},
  Author                   = {Asami, Taichi and Iwano, Koji and Furui, Sadaoki},
  Booktitle                = {Interspeech},
  Year                     = {2005},
  Pages                    = {2185-2188.},

  File                     = {:Asami05multiStreamLDAboost.pdf:PDF},
  Owner                    = {scotto},
  Timestamp                = {2007.11.20}
}

@Article{asano03combinedArrICA,
  Title                    = {Combined approach of array processing and independent component analysis for blind separation of acoustic signals},
  Author                   = {F. Asano and S. Ikeda and M. Ogawa and H. Asoh and N. Kitawaki},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc. },
  Year                     = {2003},
  Number                   = {3},
  Pages                    = {204-215},
  Volume                   = {11},

  Comment                  = {590:ReadYes},
  Review                   = {PCA-like processing on FFT bins before freq domain ICA
* subspace filter (similar to PCA but better) puts reverb in different space. Opertates on each FFT bin
* infomax ICA is next
* new permutation algorithm, combined scaling algorithm
* WER is improved
* 8 microphones},
  Url                      = {http://ieeexplore.ieee.org/iel5/89/27190/01208290.pdf?tp=&arnumber=1208290&isnumber=27190}
}

@InProceedings{assman96glimpseF0,
  Title                    = {Tracking and Glimpsing Speech in Noise:^^Role of Fundamental Frequency},
  Author                   = {Peter F. Assmann},
  Booktitle                = {Acoustical Society of America and Acoustical Society of Japan Third Joint Meeting},
  Year                     = {1996},

  Comment                  = {363:ReadYes},
  Review                   = {Perceptual double vowel/sentences suggests two ways to glimpse/group

* Humans listen to overlapped vowels and overlapped sentences
* vowel/pitch perception gives clue to how humans use F0 to separate

Some time windows are better than others for separating double vowels
* good one: low freq beating at format freq (not just high mag)
* can see separated pitch pulses separated in time at high freq formants
* so I guess low and high formants would have different ID strategies?
* longer sentences provide more glimpses and better segregation by F0
High freq pitch pulse segregation:
* group ones highly correlated at same time across freq bands.
* seems most useful for deltaF0>2semitones
Low freq format detection:
* see low freq (beating) modulation in low freq filter bank outputs
* guesses that low freq cues are more important
* seems most useful for deltaF0<1semitone
When F0 segregation is most useful
* for low deltaF0 (slide 7)
* long sentences, when glimpsing is possible.
* prosody: helps track (non-native speaker have probs w/ cocktail!)
* not much evidence that correlated FM helps much w/ intelligibility
* when have long window: 50ms pitch perception weaker than 200ms.},
  Url                      = {http://www.utdallas.edu/~assmann/asa96/talk.html}
}

@InProceedings{athineos04plp2,
  Title                    = {{PLP}^2 Autoregressive modelling of @-D spectro-temporal patterns for speech recognition },
  Author                   = {Marios Athineos and Hynek Hermansky and Daniel P. W. Ellis},
  Booktitle                = {RT-04 Workshop, EARS PI Meeting},
  Year                     = {2004},
  Pages                    = {paper 3},

  Comment                  = {ReadYes},
  Review                   = {AR smoothing in both time & freq; iterative rather than joint
* better than MFCC's, worse than PLP's
* ROVER combo recog has better WER than pure PLP or MFCC recognizers
* processing is bark filtbank --> FDLP (time smooth) --> PLP (freq smooth) --> 9 frames cepstra (about 250ms?) --> LDA --> 40 dim feat vect that goes to elaborate but standard sounding ASR
* seems like a joint 2D spline would be better (some Japanese paper I remember does this?) but mabye ther PLP is too nonlinear?},
  Url                      = {http://www.ee.columbia.edu/~dpwe/pubs/sapa04-plp2.pdf (title doesn't exactly match)}
}

@InProceedings{atlas03modSpecSpkrSep,
  Title                    = {Modulation Spectral Filtering of Speech},
  Author                   = {Les Atlas},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {2577-2580},

  Comment                  = {576: ReadNo},
  Review                   = {Les's modspec spkr sep??}
}

@InProceedings{atlas03modSpecSpchSep,
  Title                    = {Modulation Spectral Transforms - Application to Speech Separation and Modification },
  Author                   = {Les ATLAS},
  Booktitle                = {DYNAMICS BY EAR, EYE, MOUTH AND MACHINE, An Interdisciplinary Workshop},
  Year                     = {2003},
  Organization             = {THE INSTITUTE OF ELECTRONICS INFORMATION AND COMMUNICATION ENGINEERS (IEICE)},

  Comment                  = {597: ReadNo},
  Review                   = {Les's speech separation w/ modspec paper},
  Url                      = {http://www.ee.washington.edu/research/isdl/papers/atlas-03-ieice.pdf}
}

@Article{attiasXXifa,
  Title                    = {Independent factor analysis},
  Author                   = {H. Attias},
  Journal                  = {Neural computation},
  Year                     = {unknown},

  Comment                  = {21: ReadNo},
  Review                   = {Seems like a good ica/ifa overview}
}

@Misc{attias00ifaTemp,
  Title                    = {Independent factor analysis with temporally structured sources},

  Author                   = {H. Attias},
  Year                     = {2000},

  Comment                  = {ReadNo},
  Review                   = {uses AR source models},
  Text                     = {Attias, H. (2000). Independent factor analysis with temporally structured sources. In Advances in Neural Information Processing Systems (NIPS), volume 12. MIT Press.},
  Url                      = {citeseer.nj.nec.com/attias00independent.html}
}

@InProceedings{attias97temporal,
  Title                    = {Temporal Low-Order Statistics of Natural Sounds},
  Author                   = {H. Attias and C. E. Schreiner},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {1997},
  Editor                   = {Michael C. Mozer and Michael I. Jordan and Thomas Petsche},
  Pages                    = {27},
  Publisher                = {The {MIT} Press},
  Volume                   = {9},

  Comment                  = {311:ReadYes},
  Review                   = {Filterbank Hilbert Envelopes are correlated across freq bands and time
* Symphony, music, speech, cats, environmental sounds have distinctive envelope amplitude histograms
* Histogram is the same across different filterbank center freqs
* Histogram is the same when amplituded processed w/ running average (=> temporal correlations)
* log-spaced filterbanks, no-overlap, square (summed FFT bins, probably)
* filterbanks from 100-11025Hz, 1/8 octave wide.
* envelope bandwidth <= filterbank filter BW (Flanagan, 1980 reference)
* maybe relevant to pitch and overlap detection},
  Url                      = {citeseer.nj.nec.com/attias97temporal.html}
}

@Article{attias97dcaDeconv,
  Title                    = {Blind source separation and deconvolution by dynamic component analysis},
  Author                   = {H. Attias and C. E. Schreiner},
  Journal                  = {Neural Networks for Signal Processing},
  Year                     = {1997},
  Pages                    = {456-465},
  Volume                   = {VII},

  Comment                  = {50: ReadYes},
  File                     = {attias97dcaDeconv.pdf:attias97dcaDeconv.pdf:PDF},
  Review                   = {ICA->DCA. finds filters to separate sources
* srcs are assumed stat. indep (not true for multi-talker)
* assumes srcs are white (not so good for speech but says this requirement can be dropped (doesn't say how))
* cant to room rever docnv.
* need # sensors = # srcs
* does it do something useful?
* maybe use for overlap resolution},
  Url                      = {http://ieeexplore.ieee.org/search/searchresult.jsp?query1=&scope1=metadata&op1=and&query2=&scope2=metadata&op2=and&query3=&scope3=metadata&queryText=%28%28blind+source+separation+and+deconvolution+by+dynamic+component+analysis%29%3Cin%3Emetadata%29&history=yes&reqloc=adv&queryblock=Blind+source+separation+and+deconvolution+by+dynamic+component+analysis&submit=Run+Search&srchlist=publist&coll1=ieeejrns&coll2=ieejrns&coll3=ieeecnfs&coll4=ieecnfs&coll5=ieeestds&coll6=preprint&coll7=books&std_status=all&currweek=16-Jul-2007&srchyr=allyr&py1=1950&py2=2007&disp=cit&maxdoc=100&ResultCount=25&SortField=Score&SortOrder=desc}
}

@Article{auckenthaler00score,
  Title                    = {Score Normalisation in a Text-independent Speaker Verification System},
  Author                   = {R. Auckenthaler and M. Carey and H. Lloyd-Thomas},
  Journal                  = {Digital Signal Processing},
  Year                     = {2000},
  Number                   = {1},
  Pages                    = {42-54},
  Volume                   = {10},

  Comment                  = {129: ReadNo},
  Publisher                = {Academic Press}
}

@Misc{ayer95mixmdl,
  Title                    = {Layered representation of motion video using robust maximum-likelihood estimation of mixture models and {MDL} encoding},

  Author                   = {S. Ayer and H. S. Sawhney},

  Comment                  = {33.5: ReadNo},
  Review                   = {Relevant to speaker segmentation and clustering? since has MDL which is like BIC}
}

@InProceedings{azimisadj04partFiltChangeDet,
  Title                    = {A Particle Filtering Approach to Change Detection for Nonlinear Systems},
  Author                   = {Azimi-Sadjadi and P.S. Krishnaprasad},
  Booktitle                = {{EURASIP} Journal on Applied Signal Processing},
  Year                     = {2004},
  Pages                    = {2295-2305},
  Volume                   = {15},

  Comment                  = {ReadNo},
  File                     = {azimisadj04partFiltChangeDet.pdf:azimisadj04partFiltChangeDet.pdf:PDF},
  Review                   = {useful for EKOS?},
  Url                      = {http://www.hindawi.co.uk/open-access/asp/volume-2004/S1110865704408051.pdf}
}

@Article{backman93hearNN,
  Title                    = {Modelling of human directional and spatial hearing using neural networks},
  Author                   = {J. Backman and M. Karjalainen},
  Journal                  = {Unknown},
  Year                     = {1993},

  Comment                  = {215: ReadYes},
  Review                   = {Neural net successfully models human spatial hearing 
* train a NN to spit out angles given features 
* NN trained on sin(theta), cos(theta) instead of theta 
* training was @ fixed range 
* features were cross correlation (across head models 'ears' of bark-band filters coeffs (think these are like MFCC's). The other feature was loudness. 
* estimates angle (says that this how humans can est dist?) 
* works as well as humans do, if not better. 
* error is 0.1 to 1 degree (depends upon if vertical angle changed -- model had no pinna for vertical dir perception) 
* worked better for impulses or noise than speech or music 
* time delay corr includes f>=1.5KHz, where dir is ambiguous [see pu nad harris `97]. There should have been a prefilter here! 
* fairly reverb robust even if training done in anechoic room }
}

@InProceedings{Bakir04LearnPreImage,
  Title                    = {Learning to Find Pre-Images},
  Author                   = {Goekhan Bakir and Jason Weston and Bernhard Sch?lkopf},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2004},

  File                     = {Bakir04LearnPreImage.pdf:Bakir04LearnPreImage.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Inverse KPCA reconstruction. Solves pre-image problem by learning a kernel ridge reqression (faster than nonlinear optimization approach)

Basic preimage idea
regress from r output KPCA basis feature space to input feature space (same kernel). Feature space MSE is minimized over the training points. It is assumed that this regression will also work for new testing points.

- it's kind of an interpolator between training points, which will be smoothed if use fewer eigenvalues
- The main idea: instead of optimizing for each point, learn some kind of regression from 
 feature space to input space. Use ridge regression because it can work with dot products 
 in feature space (which may be infinite dimensional, meaning we can't directly learn from
 feature space).
- calculates transform once, rather than once for each space (much faster than nonlinear optimization)
- transform is closed form, non-iterative (but I don't quite understand it yet)
- does not mention how to center features before the eigen analysis, but I think you have to for it to be good PCA. My kernels book, or Kwok04* explains how to do it.

Methods for preimages
1.) exact: there's an analytical equation for invertible kernels, that works if the pre-image point exists in input space (scholkopf99InVsFeatKern proves)
2.) general approximation (nonlinear optimization): Either gradient descent (scholkopf...) or select some points and use fminsearch to optimize weights
3.) Fixed point algorithm iterations (as always, no guarantee of optimality)
4.) The method here: which is to estimate the preimage map from input space to dimension-reduced input space ahead of time). Then just run the test points through this transform later.

Applications:

* KDE (kernel dependence estimation): learn a mapping from a high dim input to a high dim output. In between, are two low dim feature spaces, where a low dimensional representation is actually learned. The low dim spaces make generalization possible

* KPCA denoising (digit recognizing example). 
 -- They look clean but sometimes it ACTUALLY PICKS THE WHOLE WRONG DIGIT!

* KPCA compression
 -- video image interpolation: transmit training images and then just coeffs to interpolate between them

* String Prediction with Kernel Dependency
 --- I didn't figure out what this was

Note: this paper is highly cited

HOW TO USE for xcorr lag sampling:

1.) KPCA on training points (centering, both on test and train points?)
2.) calculate the beta vectors from the training lags using n principal comps and some kernel. Can be different than the original PCAkernel.
3.) find the range of 
 K(Pn(phi(xi),Pn(phi(xj)))
 for all i,j combinations
4.) linearly sample that range to generate the lags (the number of beta vectors equals the input dimension)},
  Timestamp                = {2007.08.15},
  Url                      = {http://eprints.pascal-network.org/archive/00000398/}
}

@InProceedings{balan99bssAR,
  Title                    = {{AR} processes and sources can be reconstructed from degenerate mixtures},
  Author                   = { Balan, R. and Jourjine, A. and Rosca, J. },
  Booktitle                = {Independent Component Analysis and Blind Source Separation, Intl. Conf. on},
  Year                     = {1999},
  Pages                    = {467-472},

  Comment                  = {ReadNo},
  Review                   = {assumes AR model and 2nd order stats. Has a demo. Subspace technique, I think.},
  Url                      = {http://www.cs.rochester.edu/u/rosca/research.html#1999}
}

@InProceedings{balan01paramDemixEcho,
  Title                    = {{ROBUSTNESS} {OF} {PARAMETRIC} {SOURCE} {DEMIXING} {IN} {ECHOIC} {ENVIRONMENTS}},
  Author                   = {Radu Balan and Justinian Rosca and Scott Rickard},
  Booktitle                = {INDEPENDENT COMPONENT ANALYSIS and BLIND SIGNAL SEPARATION, Intl. Conf. on },
  Year                     = {2001},

  Comment                  = {446: ReadNo},
  Review                   = {How many echos you need to accommodate in to your ICA algorithm},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/088-balan.pdf}
}

@InProceedings{banks93localization,
  Title                    = {Localisation and separation of simultaneous voices with two microphones},
  Author                   = {D. Banks},
  Booktitle                = {IEE Proc. I, Vol. 140, No. 4},
  Year                     = {1993},
  Pages                    = {229-34},

  Comment                  = {206: ReadYes},
  Review                   = {Localization & # spkr estimate based on delta T estimate histo
* phase diff in each xcorr freq bin => bunch of deltaT ests
* if k spkrs, get k deltaT peaks => cluster/est => # spkrs est
* (since pieces of each spkrs's spectrum will dominate in some f bin)
* eliminate high freqs since they phase wrap (also some low freqs)}
}

@Article{Bar-Hillel05LearningMahalanobisMetric,
  author    = {Aharon Bar-Hillel and Tomer Hertz and Noam Shental and Daphna Weinshall},
  title     = {Learning a Mahalanobis Metric from Equivalence Constraints},
  journal   = {Journal of Machine Learning Research},
  year      = {2005},
  volume    = {6},
  pages     = {937--965},
  file      = {Bar-Hillel05LearningMahalanobisMetric.pdf:Bar-Hillel05LearningMahalanobisMetric.pdf:PDF},
  groups    = {semisupWorkshop07},
  issn      = {1533-7928},
  owner     = {scotto},
  publisher = {MIT Press},
  review    = {Semi-supervised kernel for blind/deaf lab},
  timestamp = {2007.06.22},
  url       = {http://portal.acm.org/citation.cfm?id=1046920.1088704&coll=GUIDE&dl=GUIDE&CFID=15151515&CFTOKEN=6184618#},
}

@InProceedings{baron02punc,
  Title                    = {Automatic punctuation and disfluency detection in multi-party meetings using prosodic and lexical cues},
  Author                   = {Don Baron and Elizabeth Shriberg and Andreas Stolcke},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},

  Comment                  = {319: ReadYes},
  File                     = {baron02punc.pdf:baron02punc.pdf:PDF},
  Review                   = {Describes Don Baron's work and the data I used for the meeting VAD},
  Url                      = {http://www.icsi.berkeley.edu/ftp/global/pub/speech/papers/icslp2002-meetings.pdf}
}

@Article{barron98minDescLen,
  Title                    = {The minimum description length principle in coding and modeling},
  Author                   = {Barron, A.; Rissanen, J.; Bin Yu},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {Oct 1998},
  Number                   = {6},
  Pages                    = {2743-2760},
  Volume                   = {44},

  Abstract                 = {We review the principles of minimum description length and stochastic complexity as used in data compression and statistical modeling. Stochastic complexity is formulated as the solution to optimum universal coding problems extending Shannon's basic source coding theorem. The normalized maximized likelihood, mixture, and predictive codings are each shown to achieve the stochastic complexity to within asymptotically vanishing terms. We assess the performance of the minimum description length criterion both from the vantage point of quality of data compression and accuracy of statistical inference. Context tree modeling, density estimation, and model selection in Gaussian linear regression serve as examples},
  Doi                      = {10.1109/18.720554},
  File                     = {:C\:\\Data\\scotto_vista\\Barron98minDescLen.pdf:PDF},
  ISSN                     = {0018-9448},
  Keywords                 = {computational complexity, data compression, information theory, maximum likelihood estimation, modelling, prediction theory, reviews, source coding, statistical analysis, stochastic processesGaussian linear regression, Shannon coding, context tree modeling, data compression, density estimation, minimum description length principle, mixture coding, model selection, normalized maximized likelihood coding, optimum universal coding problem, predictive coding, review, source coding theorem, statistical inference, statistical modeling, stochastic complexity},
  Owner                    = {scotto},
  Review                   = {Base reference for minimum description length coding, used in diarization a lot. 
MDL is equivalent to BIC for parametric models but is different for non-parametric models (and can be used there, where BIC can't [[vijayasenan07diarizAgglomInfoBotneck]},
  Timestamp                = {2008.02.01},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=720554&isnumber=15554&punumber=18&k2dockey=720554@ieeejrns&query=%28%28the+minimum+description%0D%0Alength+principle+in+coding+and+modeling%29%3Cin%3Emetadata%29&pos=0}
}

@InProceedings{barros01speechreverb,
  Title                    = {Estimation of speech embedded in a reverberant environment with multiple sources of noise},
  Author                   = {Barros, A.K.and Itakura, F. and Rutkowski, T. and Mansour, A. and Ohnishi, N.},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {629-632},
  Volume                   = {1},

  Comment                  = {ReadNo},
  Review                   = {underdetermined noise/speech separation using ica and filterbanks},
  Url                      = {http://ieeexplore.ieee.org/iel5/7486/20365/00940910.pdf?isNumber=20365&prod=CNF&arnumber=940910&arSt=629&ared=632+vol.1&arAuthor=Barros%2C+A.K.%3B+Itakura%2C+F.%3B+Rutkowski%2C+T.%3B+Mansour%2C+A.%3B+Ohnishi%2C+N.}
}

@Article{bartlett02icaFaceBasis,
  Title                    = {Representations for Face Recognition by Independent Component Analysis},
  Author                   = {Marian Stewart Bartlett and Javier R. Vovellan and Terrence J. Sejnowski},
  Journal                  = {{IEEE} trans. on Neural Nets?},
  Year                     = {2002?},

  Comment                  = {Print, ReadNo},
  File                     = {bartlett02icaFaceBasis.ps:bartlett02icaFaceBasis.ps:PDF},
  Review                   = {Is this the paper Lee (mono ICA) had alternate was to choose most important basis functions? Also, I can't figure out where this was really published, although the web page it's on says IEEE Trans on NN},
  Url                      = {http://www.wisdom.weizmann.ac.il/~armin/AdvVision02/Papers/Lecture8/ICATutorial.ps}
}

@Misc{batesXXhaasCASA,
  Title                    = {Modeling the {Haas} effect: a first step for solving the {CASA} problem},

  Author                   = {J. K. Bates},

  Comment                  = {219: ReadYes},
  Review                   = {Haas effect theorized to work on attack of new wave shapes 
* claims to avoid time-frequency tradeoff by avoiding freq altogether and discretely classifiying shapes 
* no evidence that this works better than other methods
* waveshape classifier feature selection is ad-hoc
*(note: Haas is something like 'looks at first reflection')}
}

@Misc{Baxter04DomainWgtPCA,
  Title                    = {Robust Adaptive Beamforming Based on Domain Weighted PCA},

  Author                   = {Paul D. Baxter and John G. McWhirter},
  HowPublished             = {Web},
  Year                     = {2004?},

  File                     = {Baxter04DomainWgtPCA.pdf:Baxter04DomainWgtPCA.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Better SVD signal separation if have source steering angle.
* shows that may not need BSS if sig powers are different (2nd order technique is OK)
* is SVD based
* uses steering vector to artificially enhance signal power difference so extraction works
* not clear if this is reverberant or just delay sum, but it must be reverberant otherwise steering vector solved the problem, I guess
* some good refs for robustifying eigenvalue-type beamforming problems

My Use:
* overlap resolution, using combinations of lags detected during clustering?
* improvement over SRP searching w/ PCA'ed lags basis? Instead of slewing a delay-sum BF around, use them to slew around this guy's steering vector, letting BF filters adapt for max power/overlap detect.},
  Timestamp                = {2007.08.11},
  Url                      = {http://www.ee.bilkent.edu.tr/~signal/defevent/html/abstract/a1347.htm}
}

@TechReport{baxter95mdl_mml,
  Title                    = {{MDL} and {MML}: similarities and differences (Introduction to minimum encoding inference -- Part {III})},
  Author                   = {R. Baxter and J. Oliver},
  Institution              = {Computer Science Dept. {Monash} University},
  Year                     = {1995},
  Number                   = {Tech Report 207},

  Comment                  = {70: ReadNo},
  Review                   = {MDL and MML. (MDL related to BIC?) relevant to number of speakers (clusters) and model selection}
}

@InProceedings{beattie91hmmfilt,
  Title                    = {Noisy speech recognition using hidden {Markov} model state-based filtering},
  Author                   = {V. L. Beattie and S. J. Young},
  Booktitle                = {{IEEE} ?},
  Year                     = {1991},
  Pages                    = {917-920},

  Comment                  = {269: ReadYes},
  Review                   = {During viterbi decoding,for reach candidate state, the signal is convolved w/ matched filter appropriate for that state 
* observation prob is calculated from filter output 
* two kinds of filters: 1.) variable length running average 2.) fixed length (per state) weiner filter) 
* could do model-dep pole correction like this (better than yenan may 2000?)}
}

@InProceedings{bechler05tdoaReliability,
  Title                    = { Reliability Criteria Evaluation for {TDOA} Estimates in a Variety of Real Environments},
  Author                   = {Dirk Bechler and Kristian Kroschel},
  Booktitle                = {ICASSP},
  Year                     = {2005},

  Comment                  = {ReadYes},
  File                     = {bechler05tdoaReliability.pdf:bechler05tdoaReliability.pdf:PDF},
  Review                   = {Energy not good esimate of GCC reliability: peak xcorr or peak ratios better
* fullband GCC, not subband (prev 2002 paper didn't like sub-band)
* seems like xcorr peak is a little better than peak-to-next-highest-peak ratio
* no test to see if they're redundant
* pretty consistent across several levels of reverb
* previous 2002 paper by same authors found that energy not good
* 2002 paper: "RELIABILITY MEASUREMENT OF TIME DIFFERENCE OF ARRIVAL
ESTIMATIONS FOR MULTIPLE SOUND SOURCE LOCALIZATION"
* },
  Url                      = {www.sfb588.uni-karlsruhe.de/publikationen/2005/020_Bechler.pdf}
}

@InProceedings{beigi98speaker,
  Title                    = {Speaker, Channel and Environment Change Detection},
  Author                   = {H. Beigi and S. Maes},
  Booktitle                = {World Automation Congress, ISSCI, Anchorage, Alaska, May 18-22},
  Year                     = {1998},
  Pages                    = {18-22},

  Comment                  = {158: ReadYes},
  Review                   = {Broadcast News type seg/clust w/ kmeans/thresh/HMM boundaries.
* segmentation based on fixed-length sliding windows
* faults other breakpt algs for getting times wrong & splitting words
* is criticized by chen98speaker for fixed window len?
* tested on Arpa95 HUB4
Segmentation Boundary Distance
* seems to start w/ Mahalonibus but I'm not sure
* calc kmeans in each window for k=3
* then dist is normalized w/ max,min and mean global distances
Segment boundaries
* heuristics sweep attempts to autolevel adjust. Two thresholds
* won't chop unless HMM alignment indicates there's a silence
Clustering not explained
* see [9] for more explanation
Results
* 30% error in getting boundaries right.}
}

@Article{bell95infomaxBssDeconv,
  Title                    = {An Information-Maximization Approach to Blind Separation and Blind Deconvolution},
  Author                   = {Anthony J. Bell and Terrence J. Sejnowski},
  Journal                  = {Neural Computation},
  Year                     = {1995},
  Number                   = {6},
  Pages                    = {1129-1159},
  Volume                   = {7},

  Comment                  = {22.0: ReadNo},
  File                     = {:bell95infomaxBssDeconv.pdf:PDF},
  Review                   = {The original source separation paper
* matlab code: http://www.sccn.ucsd.edu/~scott/ica.html
* maybe use for overlap resolution? },
  Url                      = {citeseer.ist.psu.edu/bell95informationmaximization.html}
}

@Article{belouchrani97bss2nd,
  Title                    = {A Blind Source Separation Technique Using Second-Order Statistics},
  Author                   = {Adel Belouchrani and Karim Abed-Meraim and Jean-Francois Cardoso and Eric Moulines},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {1997},
  Number                   = {2},
  Pages                    = {434-444},
  Volume                   = {45},

  Comment                  = {ReadNo},
  Review                   = {relevant to mono/ARMA/convex idea? Has something to do with cyclostationarity. So pitch would help?},
  Url                      = {http://ieeexplore.ieee.org/iel4/78/12067/00554307.pdf?isNumber=12067&prod=JNL&arnumber=554307&arSt=434&ared=444&arAuthor=Belouchrani%2C+A.%3B+Abed-Meraim%2C+K.%3B+Cardoso%2C+J.-F.%3B+Moulines%2C+E.}
}

@Misc{benhur02maybeSVMhierClust,
  Title                    = {A Support Vector Method for Hierarchical Clustering},

  Author                   = {Asa Ben-Hur and David Horn and Hava Siegelmann and Vladimir Vapnik},

  Comment                  = {Print: Print, ReadNo},
  Url                      = {citeseer.nj.nec.com/304566.html}
}

@Article{benhur01svmClust,
  Title                    = {Support Vector Clustering},
  Author                   = {A. Ben-Hur and D. Horn and H. Siegelmann and V. Vapnik},
  Journal                  = {Journal of Machine Learning Research },
  Year                     = {2001},
  Pages                    = {125-137},
  Volume                   = {2},

  Comment                  = {1: ReadNo},
  Review                   = {Yet},
  Url                      = {citeseer.nj.nec.com/470224.html}
}

@InProceedings{benhur00support,
  Title                    = {A Support Vector Method for Clustering},
  Author                   = {Asa Ben-Hur and David Horn and Hava T. Siegelmann and Vladimir Vapnik},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2000},
  Pages                    = {367-373},

  Comment                  = {2: ReadNo},
  Url                      = {citeseer.nj.nec.com/386386.html}
}

@InProceedings{benhur00svmClust,
  Title                    = {A support vector clustering method},
  Author                   = {A. Ben-Hur and D. Horn and H. T. Siegelmann and V. Vapnik},
  Booktitle                = {International Conference on Pattern Recognition(ICPR)},
  Year                     = {2000},
  Pages                    = {724-727},
  Volume                   = {2},

  Comment                  = {3.0: ReadNo}
}

@Article{Benesty00adaptEigSrcLoc,
  author    = {Jacob Benesty},
  title     = {Adaptive eigenvalue decomposition algorithm for passive acoustic source localization},
  journal   = {JASA},
  year      = {2000},
  volume    = {107},
  number    = {1},
  pages     = {384-391},
  comment   = {644:ReadYes},
  file      = {Benesty00adaptEigSrcLoc.pdf:Benesty00adaptEigSrcLoc.pdf:PDF},
  groups    = {waspaaComment},
  owner     = {scotto},
  review    = {Microphone pair delay estimate from _smallest_ xcorr matrix eigenvalue. Has adaptive algorithm
(waspaa reject editor said this was applicable, better than GCC-PHAT)

Why min eigenvalue
* two channel impulse reponses convolved w/ the same signal==> microphone sigs
* covariance matrix is the outer product of concatenated microphones sigs
* if flip signs of the convolution matrices, then see that min eigenvalue yeilds the impulse reponses (one inverted)
* find delay by peak picking and taking the difference
* initialize w/ one of the impulses getting a 1 in the middle (zero delay); other impulse appears to be left @ 0

Adaptive algorithm
* some adaptive algorithm, UFLMS, actually does the calc, is 7 FFT's per block vs. 3 for GCC-phat
* UFLMS paper is Mansour82uconstrFreqAdaptFilt
* MATLAB is in adaptfilt.ufdaf
* parameters described so could reproduce

Results
* compares against normal cross correlation, GCC-PHAT, and FC (Fiscell-Coker)
 - these algos are given windows 64ms to 100ms while reverb is 250-750ms?
 (does that work, esp. for GCC-PHAT, which only sees one FFT window at a time) 
 - the proposed algo is give a 16ms window, must be OK since it iterates
* proposed algorithm seems to work best
* all algorithms perform badly on omni-microphones!!

Extensions
extended to case where have noise estimate and to multiple microphones in Doclo03RobAdaptTimeDel
BSS and multichannel in Cichocki02adaptBlindBook},
  timestamp = {2007.07.30},
  url       = {http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal&id=JASMAN000107000001000384000001&idtype=cvips&gifs=yes},
}

@Article{benyassine97vadG729,
  Title                    = {{ITU-T} Recommendation {G.729} {Annex B}: a silence compression scheme for use with G.729 optimized for V.70 digital simultaneous voice and data applications},
  Author                   = {Adil Benyassine and Eyal Shlomot and {Huan-Yu} Su and Dominique Massaloux and Claude Lamblin and {Jean-Pierre} Petit},
  Journal                  = {{IEEE} Communications Magazine},
  Year                     = {1997},
  Number                   = {9},
  Pages                    = {64-73},
  Volume                   = {35},

  Comment                  = {452: ReadYes},
  Review                   = {Coder w/ strawman VAD everyone beats (4 param deltas w/ heuristics)
* Params are:
- line spectral freq mags generated from 10th order LPC
- fullband energy
- low-band energy (0-1KHz)
- zero crossing rate
* Decision actually made on param differences w/ long term noise est

- is made with hypercube decision boundary
- boundaries were chosen by hand!!
* Noise estimate:
- Made from nonspeech as detected by 2nd, simplified VAD
- Simplified VAD params
-- energy
-- spectral distortion (not defined)
-- 2nd reflection coeffs
* Four step heuristic smoothing of VAD decision},
  Url                      = {http://ieeexplore.ieee.org/iel1/35/13503/00620527.pdf?isNumber=13503&prod=JNL&arnumber=620527&arSt=64&ared=73&arAuthor=Benyassine%2C+A.%3B+Shlomot%2C+E.%3B+Su%2C+H.-Y.%3B+Massaloux%2C+D.%3B+Lamblin%2C+C.%3B+Petit%2C+J.-P.}
}

@Article{berdugo02spkrDir,
  Title                    = {Speakers' direction finding using estimated time delays in the frequency domain},
  Author                   = {Baruch Berdugo and Judith Rosenhouseb and Haim Azhari},
  Journal                  = {Signal Processing},
  Year                     = {2002},
  Number                   = {1 },
  Volume                   = {82},

  Comment                  = {ReadNo},
  Url                      = {http://www.sciencedirect.com/science?_ob=MImg&_imagekey=B6V18-44B2F7X-1-47&_cdi=5668&_orig=search&_coverDate=01%2F31%2F2002&_qd=1&_sk=999179998&wchp=dGLbVzb-lSztA&_acct=C000029718&_version=1&_userid=582538&md5=9d86b4d05d3e48b4d33fbc14d290c118&ie=f.pdf}
}

@InProceedings{berenzweig01voiceInMusic,
  Title                    = {Locating singing voice segments within music signals},
  Author                   = {Adam Berenzweig and Daniel P.W. Ellis},
  Booktitle                = {WASPAA},
  Year                     = {2001},

  Comment                  = {382: ReadYes},
  Review                   = {Segment singing from music w/ posteriors; rawPPF+entropy w/ GMM is best?
* segmentation by HMM decoding
- two states: singing / not signing
- transition probs set by inverse avg. duration of state
- no min state occupancy time (why? not hard) and this hurt performance
* same NN phone posteriors (PPF) as Willians&Ellis `99
- 54-phone (subset of TIMIT) models are 2000 hidden node NN's
- inputs to NN were 12 PLP ceps + del + del^2
- says this NN is available (to public)
* Compared to PLP cepstral and condensed post features of Williams&Ellis
- raw PPF->GaussianInHMM worse than cepstral->GaussianInHMM
- but PPF->GaussVoc + PPF->GuassMusic + PPF->H -> GaussHMM is best
- suggest that should have used GMM instead of single Gaussians
- only Good condensed PPF feature from Williams&Ellis is entropy, H
* averaging features out to 81 frames (1.3secs) helps
* would just enforcing minumum HMM state accupancy work as well?
* best result is 18.8%, PPFvoc+PPFmus+PPF_H w/ 81 frame averaging},
  Url                      = {citeseer.nj.nec.com/berenzweig01locating.html}
}

@InProceedings{berg99shortID,
  Title                    = {Investigating speaker features from very short speech records },
  Author                   = {B. Berg and A. A. Beex},
  Booktitle                = {Circuits and Systems, Proc., IEEE Intl. Symposium on},
  Year                     = {1999},
  Pages                    = {102-105},
  Volume                   = {3},

  Comment                  = {14.5: ReadNo},
  Review                   = {But has glottal for short ID?}
}

@TechReport{besag01mcmc,
  Title                    = {Markov Chain Monte Carlo for Statistical Inference},
  Author                   = {Julian Besag},
  Institution              = {University of Washington},
  Year                     = {2001},
  Number                   = {Working Paper No. 9},

  Comment                  = {ReadNo},
  Review                   = {Intro for stat 593, summer 2002}
}

@Unpublished{BieEigProbsPatternRecog,
  Title                    = {Eigenproblems in Pattern Recognition},
  Author                   = {Tijl De Bie and Nello Cristianini and Roman Rosipal},
  Note                     = {Tutorial Published on website},

  File                     = {BieEigProbsPatternRecog.pdf:BieEigProbsPatternRecog.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Nice tutorial on eigenproblems in pattern recognition: PCA, CCA, PLS, spectral clustering},
  Timestamp                = {2007.06.05},
  Url                      = {http://www.tijldebie.net/}
}

@Misc{bilmes98gentleEM,
  Title                    = {A gentle tutorial of the {EM} algorithm and its application to parameter estimation for {Gaussian} mixture and hidden {Markov} models},

  Author                   = {J. Bilmes},

  Comment                  = {13.0: ReadYes},
  Review                   = {EM intro for GMMs and HMMs}
}

@InProceedings{bilmes00dynBayesMultinets,
  Title                    = {Dynamic Bayesian Multinets},
  Author                   = {Jeff Bilmes},
  Booktitle                = {UAI '00: Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence},
  Year                     = {2000},

  Address                  = {San Francisco, CA, USA},
  Pages                    = {38--45},
  Publisher                = {Morgan Kaufmann Publishers Inc.},

  File                     = {bilmes00dynBayesMultinets.pdf:bilmes00dynBayesMultinets.pdf:PDF},
  ISBN                     = {1-55860-709-9},
  Owner                    = {scotto},
  Review                   = {Has explained away residuals (EARS) method of selecting dependencies (features)},
  Timestamp                = {2008.01.29}
}

@PhdThesis{Bilmes98PhD,
  Title                    = {Natural Statistical Models for Automatic Speech Recognition},
  Author                   = {Jeff Bilmes},
  School                   = {University of Califorinia, Berkeley, EECS Department},
  Year                     = {1998},

  File                     = {Bilmes98PhD.pdf:Bilmes98PhD.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Costas thought that Jeff's thesis introduced Explained Away Redundancy (EAR) technique, but the closes thing I can find is in Chapter 4, where DBN's are connected with thresholds (see bookmark). Anyway, buried HMM's are in here, and that might be useful someday.},
  Timestamp                = {2008.01.29}
}

@Misc{bilmes01hmmDo,
  Title                    = {What {HMMs} can do},

  Author                   = {J. A. Bilmes},
  HowPublished             = { tech note?},
  Year                     = {2001},

  Comment                  = {93: ReadNo},
  Review                   = {Draft of long tutorial on HMM's. Has general properties, possibly outside of normal speech. Probably worth reading.}
}

@Article{bingham00cmplxICA,
  Title                    = {A fast fixed-point algorithm for independent component analysis of complex-valued signals},
  Author                   = {E. Bingham and A. Hyv?rinen},
  Journal                  = {Int. J. of Neural Systems},
  Year                     = {2000},
  Number                   = {1},
  Pages                    = {1-8},
  Volume                   = {10},

  Comment                  = {ReadNo},
  File                     = {bingham00cmplxICA.ps.gz:bingham00cmplxICA.ps.gz:PDF},
  Review                   = {Matlab code: http://www.cis.hut.fi/ella/publications/cfastica_public.m},
  Url                      = {http://www.cis.hut.fi/aapo/ps/gz/IJNS00.ps.gz}
}

@InProceedings{bishop99bayesPCA,
  Title                    = {Bayesian {PCA}},
  Author                   = {Christopher M. Bishop},
  Booktitle                = {Proc. Advances in neural information processing systems},
  Year                     = {1999},

  Address                  = {Cambridge, MA, USA},
  Pages                    = {382--388},
  Publisher                = {MIT Press},

  File                     = {:bishop99bayesPCA.pdf:PDF},
  ISBN                     = {0-262-11245-0},
  Owner                    = {scotto},
  Review                   = {Uses automatic relevance determination to pick PCA dimension

pdf from here: http://books.nips.cc/papers/files/nips11/0382.pdf

better of picking priors here, supposedly:
http://books.google.com/books?id=50QZqMyRuAoC&pg=PA271&lpg=PA271&dq=bayesian+pca+bishop+priors&source=web&ots=Kwq1bYN5OX&sig=hGZFT5oTTBxLLVXi4y410ArIZmY},
  Timestamp                = {2008.01.21},
  Url                      = {http://portal.acm.org/citation.cfm?id=340674#}
}

@Article{bishop98hierarchicalmix,
  Title                    = {A hierarchical latent variable model for data visualization},
  Author                   = {C. M. Bishop and M. E. Tipping},
  Journal                  = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  Year                     = {1998 },
  Number                   = {3},
  Pages                    = {281-293},
  Volume                   = {20},

  Comment                  = {Print, ReadNo},
  Review                   = {Maybe how to do EM mixtures of mixtures. Can be downloaded here: http://www.ncrg.aston.ac.uk/PhiVis/Welcome.html, and I've got it in ~/lib/matlab}
}

@InProceedings{blascheke02icaCum,
  Title                    = {An Improved Cumulant Based Method for Independent Component Analysis},
  Author                   = {Blaschke, T. and Wiskott, L.},
  Booktitle                = {Artificial Neural Networks, Intl. Conf. on},
  Year                     = {2002},

  Comment                  = {375: ReadYes},
  Review                   = {Simultaneous 3rd/4th Cumulant opt. improves ICA performance w/ skewed srcs
* independent RV's when cumulant matrices are diagonal (1st to 4th)
* assumes pre-whitening (which is an orthog rotation matrix)
- Cardoso, "Three easy..." to says pre-whitening maybe not good idea
* no ortho diag of 3rd/4th cums (not sure why must be orthog) so approx
* require ortog b/c cums are "sub-additive" (Pham, "Contrast...")
* max on-diag cum's same as minimizing off-diag cums
* Givens Rotations yield contrast functions (much algebra in appendix)
* A couple of advantages
- over Comons method: =joint= 3rd/4th opt. instead of separate
- means that it can handle skewed/nonskewed sources
- on synthesized skewed/nonskewed, works better than fastICA & others
- (but this is on 44281 pts! (Eriksson, e.g. works on ~1000pts)
* note: Hyvarinen: "New approx..." 
-- says use 4th moment for bimodality. Use this approach instead of Kurtosis, then?
--says that cumulant based approaches oversensitive to outliers in entropy approximators},
  Url                      = {http://itb.biologie.hu-berlin.de/~wiskott/Projects/ImprovedICA.html}
}

@Misc{blatt-maximal,
  Title                    = {Maximal a-posteriori multi-sensor multi-target neural data fusion},

  Author                   = {Marcelo Blatt and Tal Grossman and Eytan Domany},

  Comment                  = {Print, ReadNo},
  Url                      = {citeseer.nj.nec.com/blatt99maximal.html}
}

@InProceedings{blum98combining,
  Title                    = {Combining Labeled and Unlabeled Data with Co-training},
  Author                   = {Avrim Blum and Tom Mitchell},
  Booktitle                = {{COLT}: Proc., Workshop on Computational Learning Theory, Morgan Kaufmann Publishers},
  Year                     = {1998},
  Pages                    = {92-100},

  File                     = {blum98combining.pdf:blum98combining.pdf:PDF},
  Url                      = {citeseer.ist.psu.edu/blum98combining.html}
}

@InProceedings{Boakye08OoverlapDetMeeting,
  Title                    = {OVERLAPPED SPEECH DETECTION FOR IMPROVED SPEAKER DIARIZATION IN
MULTIPARTY MEETINGS},
  Author                   = {Kofi Boakye and Beatriz Trueba-Hornero and Oriol Vinyals and Gerald Friedland},
  Booktitle                = {ICASSP},
  Year                     = {2008},

  File                     = {Boakye08OoverlapDetMeeting.pdf:Boakye08OoverlapDetMeeting.pdf:PDF},
  Owner                    = {scotto},
  Timestamp                = {2008.01.07}
}

@Article{bofill01bssUnderSparse,
  Title                    = {Underdetermined Blind Source Separation using Sparse Representations},
  Author                   = {Bofill, P. and Zibulevsky, M},
  Journal                  = {Signal Processing},
  Year                     = {2001},
  Number                   = {11},
  Pages                    = {2353-2362},
  Volume                   = {81},

  Comment                  = {ReadNo},
  File                     = {bofill01bssUnderSparse.pdf:bofill01bssUnderSparse.pdf:PDF},
  Review                   = {on the way to mono ica},
  Url                      = {http://iew3.technion.ac.il/~mcib/undetermICA.pdf}
}

@Unpublished{Borga01CanonicalCorrelationTutorial,
  Title                    = {Canonical Correlation a Tutorial},
  Author                   = {Magnus Borga},
  Year                     = {2001},

  Comment                  = {628:ReadYes},
  File                     = {Borga01ccaTutorial.pdf:Borga01ccaTutorial.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Nice CCA overview, with accompanying Matlab

* CCA theory
 - is scale-free, unlike other techniques
 - transforms two views of a variable so that they are maximally correlated
* nice table relating CCA,PCA, PLS (partial least squares), MLR (multiple linear regression)
 - overall equation is same, the only difference is what goes in the correlation matrix you've put in the eigenvalue problem
* Relation to mutual information
* relation to SNR
* affine transforms
* Matlab is, unfortunately, numerically unstable on my ER/XC meetings data. 
 Could reimpliment 
 - w/ SVD 
 - make sure to use smallest corr matrix
 - use Cholesky decomp},
  Timestamp                = {2007.04.13},
  Url                      = {http://www.imt.liu.se/~magnus/cca/}
}

@TechReport{Borga97UnifiedApproachto,
  Title                    = {A Unified Approach to {PCA}, {PLS}, {MLR} and {CCA}},
  Author                   = {M. Borga and T. Landelius and H. Knutsson},
  Institution              = {ISY},
  Year                     = {1997},
  Number                   = {LiTH-ISY-R-1992},
  Type                     = {Report},

  Comment                  = {640:ReadNo},
  File                     = {Borga97UnifiedApproachto.pdf:Borga97UnifiedApproachto.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Unified Rayleigh Quotient treatment of PLS, PCA, CCA and MLR; extra detail about generalized eigenvalue problem},
  Timestamp                = {2007.06.14},
  Url                      = {http://www.imt.liu.se/mi/Publications/papers/blk97b.html}
}

@PhdThesis{boulis05PhD,
  Title                    = {Topic Learning in Text and
Conversational Speech},
  Author                   = {Constantinos Boulis},
  School                   = {University of Washington},
  Year                     = {2005},

  File                     = {boulis05PhD.pdf:boulis05PhD.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Costas's PhD. I'm refering to it in my thesis for the feature selection stuff in Chapter 4.},
  Timestamp                = {2008.01.29}
}

@InProceedings{bourgeois03clustBSS,
  Title                    = {A Clustering Approach to On-line Audio Source Separation},
  Author                   = {Julien Bourgeois},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {1745-1748},

  Comment                  = {574: ReadNo},
  Review                   = {source separation w/ clustering}
}

@Misc{bsalah00deconvSOMOD,
  Title                    = {A second order multi output deconvolution ({SOMOD}) technique},

  Author                   = {H. Bousbia-Salah and A. Belouchrani},
  Year                     = {2000},

  Comment                  = {56.0: ReadNo},
  Review                   = {Joint diag of spatio/temporal corr. matrix for convolutive mixture. Is this like ICA?}
}

@Book{boyd03convexOpt,
  Title                    = {{EE}364: Convex Optimization with Engineering Applications},
  Author                   = {Stephen Boyd},
  Publisher                = {Standord University},
  Year                     = {2002},

  Comment                  = {ReadNo},
  Review                   = {Classnotes, will turn into text book in 2003. Are ICA probs convex optimization?},
  Url                      = {http://www.stanford.edu/class/ee364/}
}

@Book{bradley00numtracks,
  Title                    = {Time-Recursive Number-of-Tracks Estimation for {MHT}},
  Author                   = {J. Bradley and K. Buckley and R. Perry},
  Publisher                = {The Intl. Society for Optical Engineering},
  Year                     = {2000},
  Volume                   = {4048},

  Booktitle                = {Proc. SPIE},
  Comment                  = {202: ReadYes},
  File                     = {bradley00numtracks.pdf:bradley00numtracks.pdf:PDF},
  Review                   = {Measurement to track fusion. # tracs vary, split/merge over time
* prob of detection known, as well as the # false alarms per measurement in time. Realistic?},
  Url                      = {http://citeseer.ist.psu.edu/rd/0%2C299589%2C1%2C0.25%2CDownload/http://citeseer.ist.psu.edu/cache/papers/cs/15358/http:zSzzSzwww.ee.vill.eduzSzuserzSzperryzSzresearchzSzSPIE_2000zSzpaper.pdf/bradley00timerecursive.pdf}
}

@Article{brandstein96locMicArr,
  Title                    = {A localization-error-based method for microphone-array design},
  Author                   = {B. S. Brandstein and J. E. Adcock and H. F. Silverman},
  Journal                  = {{IEEE} ?},
  Year                     = {1996},

  Comment                  = {260.0: ReadYes},
  Review                   = {Calculates covariance location estimation accuracy assuming mic pairs

* loc. est. is brute force ML 
* works pretty well @ estimating error in ideal anechoic room, where noise is considered indep. Gaurssian on TDOA (legit?) 
* has mic placement recommendations based on sims }
}

@InProceedings{brandstein99an,
  Title                    = {An event-based method for microphone array speech enhancement},
  Author                   = {M. Brandstein},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999},
  Pages                    = {953-956},

  Comment                  = {182: ReadYes},
  Review                   = {Reverberant room spch enhance using resynthesized LPC residual
* assumes known speaker location
* idea: multiple mics have destructive cancellation @ different times
-- resynth a single mean pitch pulse bigger weights in avg when 
--- aligned across channels
-- pitch pulse from LPC residual
* then resynth using new residual
* inverse and forward LPC coeffs come from multi-channel autocorr func
* 12th order LPC., 30ms analysis window
* alignment averaged over K pitch pulse periods 
* does single bulk estimate of speaker all-pole model over all mics (also pitch) 
* then nonlinearity averages the residuals for each mic into a signle residual 
* improvement isn't really demonstrated? 
* says that adaptive or optimal algs or too slow for non-stationary speech and room acoustics},
  Url                      = {citeseer.nj.nec.com/article/brandstein99eventbased.html}
}

@Misc{brandsteinXXpitchTD,
  Title                    = {A Pitch-based approach to time-delay estimation of reverberant speech},

  Author                   = {M. S. Brandstein},
  Year                     = {unknown},

  Comment                  = {236: ReadYes},
  Review                   = {GCC (generalized cross correlation) / wiener-type (ML) weighting delay est. is best in bad white noise but blows up in reverb 
* phase based delay est is more vulnerable to noise but works better than GCC in reverb 
* here, propose a GCC w/ weighting based on periodicity quality (pitch) (voiced speech model fit) 
* so, still finding max Rxx across two mics 
* prefilter before Rxx to remove non-voiced parts of speech (parts that don't fit the voiced speech model) 
* explains how to compute the voiced speech segments 
* doesnt' work better in noise than GCC but works better than either GCC or phase trans in heavy reverb. 
* problem is AOA (DOA) estimation for mic pair 
* seems to me that wideband parts of speech might work better? 
* pitch needs do be estimated to 1Hz accuracy!}
}

@Article{brandstein97locLI,
  Title                    = {A Closed-form location estimator for use with room environment microphone arrays},
  Author                   = {M. S. Brandstein and J. E. Adcock and H. F. Silverman},
  Journal                  = {{IEEE} Trans, Speech and Audio Proc.},
  Year                     = {1997},
  Number                   = {1},
  Pages                    = {45-50},
  Volume                   = {5},

  Comment                  = {238: ReadYes},
  Review                   = {Compute bearing line w/ 4-mic crosses (+ shaped) 
* works almost as well as brute force search (simulation on TDOA synthesized)

* how to estimate the required TDOA is not explained and could be a prob in spch 
* TDOA: use speech phase instead of time during voiced intervals?

* uses a prob model where it would be easy to mult. by a speaker ID prob 
* prob model for dist. weighting seems suspicious (s/b some hyperbolic something?) 
* simulations don't mention reverb but probably it's there}
}

@Article{brandstein97multiTalkerTrack,
  Title                    = {Tracking multiple talkers using microphone-array measurements},
  Author                   = {M. S. Brandstein and H. F. Silverman},
  Journal                  = {Unknown},
  Year                     = {1997},

  Comment                  = {237: ReadYes},
  Review                   = {Kalman filter smooths tracker position estimates 
* tracks spawn and die automatically 
* Kalman filter seems to late, since TDOA algs have already decided on 'arrival' (won't work for talker overlap) 
* no use of speaker ID techniques 
* speaker ID could be integrated into Kalman arrays @ some pt. in processing chain 
* I think there are pobs w/ how kalman and track mgnt is handled}
}

@Article{brandstein00ce-babe,
  Title                    = {Cell-based beamforming ({CE-BABE}) for speech acquisition with microphone arrays},
  Author                   = {M. S. Brandstein and D. B. Ward},
  Journal                  = {IEEE Trans., Speech and Audio Proc.},
  Year                     = {2000},
  Number                   = {6},
  Pages                    = {738-743},
  Volume                   = {8},

  Comment                  = {259: ReadYes},
  Review                   = {Rehash of [ward and brandstein `99] 
* not clear that this works in reverg 
* uses SNR plots instead of more important criteria (eg. PFSDM)}
}

@InProceedings{brefeld04coemSVM,
  Title                    = {Co-em support vector learning},
  Author                   = {U. Brefeld and T. Scheffer},
  Booktitle                = {Proc., Intl. Conf. on Machine Learning},
  Year                     = {2004},

  File                     = {brefeld04coemSVM.pdf:brefeld04coemSVM.pdf:PDF},
  Review                   = {Co-EM applied to SVM's. Discussed w/ Mari, Dustin and Sangyun},
  Url                      = {citeseer.ist.psu.edu/brefeld04coem.html}
}

@Book{bregman90auditoryScene,
  Title                    = {Auditory Scene Analysis },
  Author                   = {A. A. Bregman},
  Publisher                = {MIT Press},
  Year                     = {1990},

  Comment                  = {ReadNo},
  Review                   = {A book describing the "Coctail Party Effect" Referenced in Acero papers}
}

@Article{brooks00multicodec,
  Title                    = {A Multiband Excited waveform-interpolated 2.35-Kpbs speech codec for bandlimited channels},
  Author                   = {F. C. A. Brooks and L. Hanzo},
  Journal                  = {{IEEE} transactions on vehicular technology},
  Year                     = {2000},
  Number                   = {03},
  Pages                    = {766},
  Volume                   = {49},

  Comment                  = {184: ReadYes},
  Review                   = {Codec w/ voiced/unvoiced description and wavelet pitch
* voiced/unvoiced: ratio of pwr in two bands 
* further enhanced on p. 773
* wavelet pitch det narrows choices @ which to compute ACF lags
* actual pitch period est is done by ACF
* not clear if good @ tracking non-stationary pitch
* references kadambe (wavelet): odd that still uses ACF}
}

@Misc{brown92computational,
  Title                    = {{DONT} {HAVE} {THIS}: {ITS} {THE} {AUDITORY} {MAP} {PAPER} A computational model of auditory scene analysis},

  Author                   = {G. Brown and M. Cooke},
  Year                     = {1992},

  Comment                  = {Print, ReadNo},
  Text                     = {Brown, G., and Cooke, M., A computational model of auditory scene analysis, Proc. ICSLP, pp. 523-526, 1992.}
}

@InProceedings{brown95neurosc,
  Title                    = {A Neural Oscillator Model of primitive auditory grouping},
  Author                   = {G. J. Brown and M. Cooke},
  Booktitle                = {Proc., IEEE Signal Processing Society Workshop on Applications of Signal Processing to Audio and Acoustic},
  Year                     = {1995},
  Pages                    = {53-56},

  Comment                  = {176: ReadYes},
  Review                   = {Pitch analysis and audio grouping done jointly
* process is iterative lenaring rule: grouped signals are forced to oscillate in phase
* oscillator phase coupling is updated every 1ms
* 2ms autocorr on each o f32 gamatone filters (100-2KHz)
* complings:
-- increase pairwise w/ channels that have same autocorr peak heighted (similar amt. of periodicity and same pitch)
-- this enforces coupling between smaem-pitch and same ...
* initial pitch guess is the delay of overall corellation peak across all channels
* initially, all channles fully coupled; learning rule may uncouple non-pitch, non-same-offset chans
* autocorr window = 20ms}
}

@Article{brown92classbased,
  Title                    = {Class-Based n-gram Models of Natural Language},
  Author                   = {Peter F. Brown and Vincent J. Della Pietra and Peter V. {deSouza} and Jennifer C. Lai and Robert L. Mercer},
  Journal                  = {Computational Linguistics},
  Year                     = {1992},
  Number                   = {4},
  Pages                    = {467-479},
  Volume                   = {18},

  File                     = {brown92classbased.pdf:brown92classbased.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Automatic equiv. class generation as in SRILM toolkit; explanation of LM perplexity
* perplexity: inverse geomtric average of LM posteriors: small is good},
  Timestamp                = {2006.04.11},
  Url                      = {citeseer.ist.psu.edu/brown90classbased.html}
}

@InProceedings{Buchner05simulLocMIMO,
  Title                    = {Simultaneous localization of multiple sound sources using blind adaptive MIMO filtering},
  Author                   = {H. Buchner and R. Aichner and J. Stenglein and H. Teutsch and W. Kellennann},
  Booktitle                = {ICASSP},
  Year                     = {2005},
  Number                   = {18-23},
  Pages                    = {iii/97- iii100},
  Volume                   = {3},

  File                     = {Buchner05simulLocMIMO.pdf:Buchner05simulLocMIMO.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Multi-microphone, multi-speaker localization/separation; an improvement upon Benesty02adaptEigSrcLoc
* lists muliti-mic extensions to GCC-PHAT and Bensty02 in refs [8] (GCC) and [7,8] (Benesty02)},
  Timestamp                = {2007.07.31},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1415655}
}

@InProceedings{buckheit96tileTF,
  Title                    = {Time-frequency tilings which best expose the non-Gaussian behavior of a stochastic process},
  Author                   = {Buckheit, J.B. and Donoho, D.L.},
  Booktitle                = {Time-Frequency and Time-Scale Analysis},
  Year                     = {1996},
  Pages                    = {1-4},

  Comment                  = {ReadNo},
  Url                      = {http://ieeexplore.ieee.org/iel3/3977/11466/00546671.pdf?isNumber=11466&prod=CNF&arnumber=546671&arSt=1&ared=4&arAuthor=Buckheit%2C+J.B.%3B+Donoho%2C+D.L.}
}

@Misc{buckleyXXmhtprune,
  Title                    = {A new pruning/merging algorithm for {MHT} multitarget tracking},

  Author                   = {K. Buckley and A. Vaddiraju and R. Perry},

  Comment                  = {15.0: ReadNo}
}

@InProceedings{buckley00numtracks,
  Title                    = {Time-recursive number-of-tracks estimation for {MHT}},
  Author                   = {K. M. Buckley and J.Bradley and R. Perry},
  Booktitle                = {SPIE},
  Year                     = {2000},
  Volume                   = {4048},

  Comment                  = {Print, ReadNo}
}

@Article{Burden00autoRelDetSysID,
  Title                    = {Use of automatic relevance determination in QSAR studies using Bayesian neural
networks},
  Author                   = {Burden, F. R. and Ford, M. G. and Whitley, D. C. and Winkler, D. A.},
  Journal                  = {Journal of Chemical Information and Computer Sciences},
  Year                     = {2000},
  Pages                    = {1423-1430},
  Volume                   = {40},

  Owner                    = {scotto},
  Review                   = {used autoamatic relevance determination (ARD) in a system identification problem},
  Timestamp                = {2008.01.30}
}

@TechReport{cadez99probabilistic,
  Title                    = {Probabilistic clustering using hierarchical models},
  Author                   = {I. Cadez and P. Smyth},
  Institution              = {University of California at Irvine},
  Year                     = {1999},
  Number                   = {UCI-ICS 99-16},

  Comment                  = {16.0: ReadNo},
  Review                   = {YET. Model complexity tradeoff like BIC for hierarchy
Mix of static and dynamic traits in clustering},
  Url                      = {citeseer.nj.nec.com/cadez99probabilistic.html}
}

@InProceedings{cadez00general,
  Title                    = {A general probabilistic framework for clustering individuals and objects},
  Author                   = {I. V. Cadez and S. Gaffney and P. Smyth},
  Booktitle                = {Knowledge Discovery and Data Mining (KDD)},
  Year                     = {2000},
  Pages                    = {140-149},

  Comment                  = {141: ReadYes},
  Review                   = {Non-hierarchic EM clust of dynamic seqs w/ time dependence. eg. Markov
* talk about markov models but could be HMM as well
* Cadez 99-16 ref talks about model complexity tradeoff like BIC}
}

@InProceedings{cadonati03xcorrRstat,
  Title                    = {r statistics for time-domain cross correlation },
  Author                   = {Laura Cadonati},
  Booktitle                = {LSC collaboration meeting, LLO6},
  Year                     = {2003},
  Organization             = {LIGO-MIT},

  Comment                  = {Presentation Slides},
  Institution              = {LIGO-MIT},
  Review                   = {variance-based xcorr confidence, except variance window slides with lag
* also subtracted mean before comparing
* confidence estimate based on normal stats (Pearson's)
* used for assessing burst confidence
* confidence ~ (0,1)
* ACTUALLY, this is what I'm already doing, except I'm not mean subtracting.},
  Url                      = {www.ligo.caltech.edu/docs/G/G030084-00/G030084-00.pdf }
}

@MastersThesis{campbell00micArrBF,
  Title                    = {Adaptive beamforming using a microphone array for hands-free telephony},
  Author                   = {D. K. Campbell},
  School                   = {Virginia polytechnic institute and state university},
  Year                     = {1999},

  Comment                  = {209: ReadNo},
  Review                   = {Good for localization?}
}

@Article{cao97eigenspchsep,
  Title                    = {Multichannel speech separation by eigendecomposition and its application to co-talker interference removal},
  Author                   = {Y. Cao and S. Sridharan and M. Moody},
  Journal                  = {IEEE Trans. on Speech and Audio Proc.},
  Year                     = {1997},
  Number                   = {3},
  Pages                    = {209-219},
  Volume                   = {5},

  Comment                  = {29.0: ReadNo},
  Review                   = {Maybe use for overlap resolution? }
}

@Misc{cao94micArrAdapt,
  Title                    = {Post-microphone-array speech enhancement with adaptive filters for forensic application},

  Author                   = {Y. Cao and S. Sridharan and M. P. Moody},

  Comment                  = {256: ReadYes},
  Review                   = {Reference channel speech enhancement 
* subtraction is SNR based ^** locates signal and noise subspace 
* do something like this but only on speech model params? 
* no experiments to show it works}
}

@InProceedings{Cardoso01ThreeEasyRoutes,
  Title                    = {The Three Easy Routes To Independent Component Analysis; Contrasts And Geometry.},
  Author                   = {Jean-Francois Cardoso},
  Booktitle                = {Independent Components Analysis and Signal Separation},
  Year                     = {2001},

  Comment                  = {ReadYes: 377},
  Review                   = {Contrast improvements beyond non-Guassian to coherent and nonstat. srcs
Stationarity, Gaussianinity, Coherence are Simplist BSS contrasts
* ICA/BSS relies on sources being non-iid nonGaussian
Contrast function
- depends upon the source model you assume (simple is better)
- assume univariate sources
- tells you if unmixing matrix output is more/less non-iid nonGaussian
- is the neg. expected value of data likelihood, given unmixing matrix
- if minimize, then max data likelihood and max separation
- is really KL distance between src model & separated output 
Three most simple non-iid Gaussian sources models
1.) non-Gaussian iid
- uncorrelated, same correlation for all time
- likelihood: straight log sum of unmixed data in assumed src pdf
- contrast: straight KL distance
2.) Gaussian but non-stationary
- each samp is Gaussian & indep. of next, but cov. matrix is time-dep.
- cov matrix is assumed diag, because of independence
- diag of cov matrix is itself a Gaussian RV
- likelihood: sums of est. src variances and data/var quotient
- contrast: summed KL dist between source and unmixed datr cov matrices
3.) Gaussian but stationarily correlated in time
- DFT coeffs are indep Gaussian non-iid RV's since DFT is orthog xform
-- if no time corr, would be iid
-- I'm not sure how to use wavelets but they're also ortho (lookup)
- likelihood: looks like non-stationary eq.
- contrast: almost like nonstationary eq. sum KL dist, DFT coeffs
Kullback projection and Pythagorean theorem
- separates effect of src params from unmixing matrix
- unmixing matrix contrast function is simplified, is KLdist between
unmixed data and a "src dist" w/ same model params as numixed data.

Amazing!
Mutual Information
- two projection steps: 1.)unmixed data onto model (above)
- and 2.) model-matched data onto indedpendent space
- min over srcs: get contrast funcs which are mut. infos of unmixed outs
- MI minimized w/ Joint Diagonalizing algorithms (with known src)
Dependence and Correlation
- Mutual info contrast is just correlation - sum(non-properties)+const
- non props are gaussianity, stationarity, time correlation
- min this but I'm not sure if you can min all non-props @ the same time
What this means for other approaches
* maybe they are overemphasing things you don't want to:
* Pre-whitening or sphering: gives inf. weight to correlation term
* one-unit (e.g. fastiCA)
-- zero weight to correlation term
-- excludes modeling non-stationary or coherent sources},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/134-cardoso.pdf}
}

@Article{cardoso98bssStat,
  Title                    = {Blind signal separation: statistical principles},
  Author                   = {Cardoso, J.-F. },
  Journal                  = {Proc., IEEE},
  Year                     = {1998},
  Number                   = {10},
  Pages                    = {2009 -2025},
  Volume                   = {86 },

  Booktitle                = {Proc., IEEE },
  Comment                  = {ReadNo},
  Url                      = {http://ieeexplore.ieee.org/iel4/5/15548/00720250.pdf?isNumber=15548&prod=JNL&arnumber=720250&arSt=2009&ared=2025&arAuthor=Cardoso%2C+J.-F.}
}

@InProceedings{cardoso98icaMultiD,
  Title                    = {Multidimensional independent component analysis},
  Author                   = {Jean-Francois Cardoso},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1998},
  Pages                    = {1941-1944},
  Volume                   = {4},

  Comment                  = {ReadNo},
  Url                      = {http://ieeexplore.ieee.org/iel4/5518/14956/00681443.pdf?isNumber=14956&prod=CNF&arnumber=681443&arSt=1941&ared=1944+vol.4&arAuthor=Cardoso%2C+J.-F.}
}

@Article{cardoso97infomaxMaxLik,
  Title                    = {Infomax and maximum likelihood for blind source separation },
  Author                   = {J.-F. Cardoso},
  Journal                  = {{IEEE} Signal processing letters},
  Year                     = {1997},
  Number                   = {4},
  Pages                    = {112-114},
  Volume                   = {4},

  Comment                  = {ReadNo},
  File                     = {cardoso97infomaxMaxLik.pdf:cardoso97infomaxMaxLik.pdf:PDF},
  Review                   = {Ref in Haykin slides showing equiv between infomax and maximum likelihood ICA},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=566704&isnumber=12324&punumber=97&k2dockey=566704@ieeejrns&query=%28%28infomax+and+maximum+likelihood+for+blind+source+separation+%29%3Cin%3Emetadata%29&pos=0&access=no}
}

@TechReport{cardoso94diagPerturb,
  Title                    = {Perturbation of joint diagonalizers. Ref\# 94D027},
  Author                   = {Jean-Fran\ccois Cardoso},
  Institution              = {T\'el\'ecom Paris},
  Year                     = {1994},

  Comment                  = {ReadNo},
  Html                     = {ftp://tsi.enst.fr/pub/jfc/Papers/joint_diag_pert_an.ps},
  Review                   = {an analytical way of diagonalizing. Related to Anemuller's, and Blasche's ICA det stuff. Matlab code here: http://www.tsi.enst.fr/~cardoso/jointdiag.html}
}

@Article{cardoso96jacobiDiag,
  Title                    = {Jacobi angles for simultaneous diagonalization},
  Author                   = {Jean-Fran\ccois Cardoso and Antoine Souloumiac},
  Journal                  = {{SIAM} J. Mat. Anal. Appl.},
  Year                     = {1996},
  Number                   = {1},
  Pages                    = {161--164},
  Volume                   = {17},

  Comment                  = {ReadNo},
  Html                     = {ftp://tsi.enst.fr/pub/jfc/Papers/siam_note.ps.gz},
  Review                   = {an analytical way of diagonalizing. Related to Anemuller's, and Blasche's ICA det stuff. Matlab code here: http://www.tsi.enst.fr/~cardoso/jointdiag.html}
}

@InProceedings{carey96robust,
  Title                    = {Robust Prosodic Features for Speaker Identification},
  Author                   = {M. Carey and E. Parris and H. Lloyd-Thomas and S. Bennett},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1996},
  Pages                    = {1800-1803},
  Volume                   = {3},

  Comment                  = {170.0: ReadYes},
  Review                   = {HMM spkr ID is improved by fusing Pitch/Energy features 
* gender can be ID'd w/ 98% accuracy just w/ pitch
* iterative pitch est outlier throwout
* 30s train, 10s test for est (long!)
* prosodic features robust to telphone degradation, unlike ceps coeffs.
Did LDA on sort of prosodic features
-- pitch (mean, var, skew, kurtois) E, dE, d^2E, mean/var of voiced dur
-- LDA reduced to 3 dimensions
-- females more tightly clustered (better imposter reject) than men.

--- (illustrated but not quite proven)
HMM max likelihood spkr ID
* did spectral mean subtraction 1st
* built single mixt subword HMM models for each spkr (12 ceps + delta)
* segmented speech in to subword units
-- fair because segmentation was done w/ spkr independent model
-- could be made into an iterative clustering approach, like BN!
* picked highest likelihood among spkr dependent subword models
* score: fraction of times each spkr dependent model was most likely.
Fusion of Prosodic and HMM spkr ID
* for each spk: (HMM model score) - (LDA'ed prosodic feature divergence)
* not clear how they compute divergence or if they use all 3 LDA dims
* but the score of HMM and prosodic features works a little better}
}

@Misc{carreira-perpi-dimensionality,
  Title                    = {Dimensionality Reduction of Electropalatographic Data Using Latent Variable Models},

  Author                   = {M. Carreira-Perpi},

  Comment                  = {26.5: ReadNo},
  Url                      = {citeseer.nj.nec.com/56147.html}
}

@Misc{dimReduceReview,
  Title                    = {A Review of Dimension Reduction Techniques},

  Author                   = {M. ?. Carreira-Perpi??n},

  Comment                  = {25: ReadNo},
  Review                   = {But good for spkr ID? big review web page},
  Url                      = {citeseer.nj.nec.com/126333.html}
}

@InProceedings{cassidy04mtngRecogRT04s,
  Title                    = {The Macquiarie speaker diarisation system for {RT04S}},
  Author                   = {Steve Cassidy},
  Booktitle                = {{NIST} Meeting Recognition Workshop},
  Year                     = {2004},

  Comment                  = {ReadNo},
  Review                   = {CLT NIST meeting speaker seg/clust

15second read: looks standard BIC clusering. Not sure about multi-mic, looks like they didn't do much but check}
}

@InProceedings{cauwenberghs00icaMono,
  Title                    = {Monaural separation of independent acoustical components},
  Author                   = {Cauwenberghs, G.},
  Booktitle                = {ISCAS},
  Year                     = {1999},
  Pages                    = {62-65},
  Volume                   = {5},

  Comment                  = {408: ReadYes},
  Review                   = {Mono ICA w/ wavelet coeffs; good refs but I don't know if it worked
* I actually didn't understand this paper
* Gaussian wavelets (good ref) => ICA equation for incoherent sources

* Solutions in freq domain and for some kinda time domain xcorr search
* time domain works best but the sigs are simple and synthesized
* good ref on AR parameter source learning},
  Url                      = {http://ieeexplore.ieee.org/iel5/6311/16880/00777511.pdf?isNumber=16880&prod=CNF&arnumber=777511&arSt=62&ared=65+vol.5&arAuthor=Cauwenberghs%2C+G.}
}

@Misc{cetin01fisherHMM,
  Title                    = {Derivation of Fisher Score for {HMM}},

  Author                   = {O. Cetin},
  Year                     = {2001},

  Comment                  = {82: ReadYes},
  Review                   = {* Ozgur's derivation fo Fisher score for our class project}
}

@InProceedings{cetin02spineASRseg,
  Title                    = {The 2001 {GMTK}-Based {SPINE} {ASR} System},
  Author                   = {Ozgur Cetin and Harriet Nock and Katrin Kirchhoff and Jeff Bilmes and Mari Ostendorf },
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},

  Comment                  = {438: ReadYes},
  File                     = {cetin02spineASRseg.pdf:cetin02spineASRseg.pdf:PDF},
  Review                   = {SSLI Spine entry; Katrin's NN/HMM speech/nonspeech VAD; is causal
* MFCC features
* 9 frame window --> neural net for speech, one for sil
* 2nd NN takes spch/sil NN outputs and classifies spch/sil
* median filter
* remove segs < 200ms},
  Url                      = {http://ssli.ee.washington.edu/people/bilmes/mypapers/gmtk-spine-icslp2002.pdf}
}

@Misc{chabriel00blindmix,
  Title                    = {Blind identification of slightly delayed mixtures},

  Author                   = {G. Chabriel and J. Barrere},

  Comment                  = {53: ReadNo},
  Review                   = {Speaker overlap resolution?}
}

@Misc{chanXXresynth,
  Title                    = {Wideband re-synthesis of narrowband {CELP}-coded speech using multiband excitation model},

  Author                   = {C. Chan and W. Hui},

  Comment                  = {234: ReadYes},
  Review                   = {Harmonic sieve pitch est w/ brute force search 
* one indep pitch est/frame 
* voiced/unvoiced decision made in each freq band based on model fit

* voiced/unvoiced decision is extrapolated to highs, not coded 
* relevant to overlap detection and resolution? 
* also voiced/non-voiced alg may be useful}
}

@InProceedings{kwok01icaVar,
  Title                    = {{VARIATIONAL} {LEARNING} {OF} {CLUSTERS} {OF} {UNDERCOMPLETE} {NONSYMMETRIC} {INDEPENDENT} {COMPONENTS}},
  Author                   = {Kwokleung Chan and Te-Won Lee and Terrence Sejnowski},
  Booktitle                = {Independent Components Analysis, Intl. Conf. on},
  Year                     = {2001},

  Comment                  = {ReadNo}
}

@InProceedings{chandra02lpcSAPVR,
  Title                    = {Usable Speech Detection Using the Modified Spectral Autocorrelation Peak To Valley Ratio Using the {LPC} residual},
  Author                   = {Nishant Chandra and Robert E. Yantorno},
  Booktitle                = {Intl. Conf., Signal and Image Proc.},
  Year                     = {2002},

  Comment                  = {285: ReadYes},
  File                     = {chandra02lpcSAPVR.pdf:chandra02lpcSAPVR.pdf:PDF},
  Review                   = {Cochannel speech is usable for spkrID when LPC spectrum has deep notches
* like SAPVR except do autocorr of LPC residual spectrum
-- LPC residual removes vocal tract effect
-- LPC residual spectrum flatter than speech spectrum 
* different SAPVR forumla than plain SAPVR paper: sum(2*P1,P2:4)/valley1
* > %corr on male<->male plain SAPVR, less false detect on other combos.
* Average %correct = 71%, %false=37%.
-- Hard to compare with lovekin02usableAPPC because he reports % detect/missed.
* Better in reverb than plain SAPVR? Probably.
* compare w/ pitch pulses in "wavelet transform..." griebel99wavelet
-- were wavelets better than LPC for them?
-- does griebel method work better for multi-microphones?}
}

@Manual{chung01libSVMmanual,
  Title                    = {{LIBSVM}: a library for support vector machines},
  Author                   = {Chih-Chung Chang and Chih-Jen Lin},
  Year                     = {2001},

  Comment                  = {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}}
}

@InProceedings{chang98spkrloc3D,
  Title                    = {Performance of {3D} speaker localization using a small array of microphones},
  Author                   = {P. S. Chang and A. N. Willson Jr.},
  Booktitle                = {Signals, Systems \& Computers, Conf. Record},
  Year                     = {1997},
  Pages                    = {328-332},
  Volume                   = {1},

  Comment                  = {172: ReadYes},
  Review                   = {Adaptive filts work as well as cross power spectral phase for delay est.
* adaptive filter predicts middle tap of other-mic signal
* RLS or CG are good adaptive algorithms for this
* doesn't use Generalized Correlation Method (uses the adaptive filter)
* low sampling rates require delay interpolation algorithm
* filter coeffs were smoothed across time w/ 1 pole LPF
* 1 pole HPF before adaptive filter (does LPC residual work as well?)
* peak searching needs smoothing
* pitch helps w/ peak picking
* mentions Brandenstein but it's not clear that this approach is better
* dismisses MUSIC but this was before the `00 claudio ROOT-MUSIC paper
* can't handle simultaneous talking}
}

@Misc{cheesemanXXautoclass,
  Title                    = {{Bayesian} classification ({Autoclass}): {Theory} and results},

  Author                   = {P. Cheeseman and J. Stutz},

  Comment                  = {68: ReadNo},
  Publisher                = {American Association for Artificial Intelligence},
  Review                   = {some more autoclassIII clustering theory (other is hanson67bayesClass) talks about BIC? }
}

@Article{Chen03delEstMultiMic,
  author    = {Jingdong Chen and J. Benesty and Yiteng Huang},
  title     = {Robust time delay estimation exploiting redundancy among multiple microphones},
  journal   = {IEEE Trans. on Speech and Audio Proc.},
  year      = {2003},
  volume    = {11},
  number    = {6},
  pages     = {549- 557},
  comment   = {649},
  file      = {Chen03delEstMultiMic.pdf:Chen03delEstMultiMic.pdf:PDF},
  groups    = {waspaaComment},
  owner     = {scotto},
  review    = {Time delay est. using multiple microphones, requires known array geometry
(waspaa reject paper editor, sad this was better than GCC-PHAT but I CAN'T USE IT)

* for pairs, it is "similar to GCC-PHAT" & don't need geomtetry, but, since don't do freq divide, is just max xcorr
* >2 mics, has a forwards/backwards prediction algorithm, which estimates only a single delay, 
 w/ known mic delay distance offsets
* better than GCC-PHAT in reverb/noise...

* I can't use this because it requires known microphone spacing},
  timestamp = {2007.07.30},
  url       = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1255443},
}

@Article{chen06tdoaOverview,
  Title                    = {Time Delay Estimation in Room Acoustic Environments: An Overview},
  Author                   = {Chen, Jingdong and Benesty, Jacob and Huang, Yiteng (Arden)},
  Journal                  = {EURASIP Journal on Applied Signal Processing},
  Year                     = {2006},
  Note                     = {doi:10.1155/ASP/2006/26503},
  Pages                    = {Article ID 26503, 19 pages},
  Volume                   = {2006},

  File                     = {chen06tdoaOverview.pdf:chen06tdoaOverview.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Excellent overview of TDOA techniques; AED is best 1-pair method but multi-pair methods are better if aligned

* categorization of delay techniques
* ideal and multipath models
* FIR filter is a realistic multipath model
 - time delay explicityly expressed so you have to do peak picking
* onestep algorithm: calc spatial position and time delay in a single step
* twostep algorithm: calc pairwise TDE and then determine locations

-- TDE ALGORITHMS REVIEWED --------------

1. cross correlation
 - they window them: decreases freq leakage but would screw up long lags?

2. average magnitude difference (AMDF)
 - doesn't really make sense
 - statistically, minimum of the AMDF is same as finding the maximum
 of the CCF between two observation signals!

3. generalized cross correlation (GCC)
 - actually, there are several types of GCC
 1.) SCOT (smoothed coherence)
 2.) PHAT (phase transform, the standard one)
 - generally most consistent because whitening removes source signal
 variability, leaving only channel response (the delay)
 3.) ML (max lik)
 - optimal, but only if no reverb and other idealizations are true
 4.) Hassab-Boucher transform

5. LMS adaptive
 - predict one channel w/ the other; prediction FIR yields the delay
 - ideal propagation (no reverb), can solve w/ LMS algorithm

6. Sensor pair fusion
 Jointly select peaks from sensor pairs. Generally more robust than when
 using only two sensors, but computationally expensive. Three methods
 1.) synchronous adding
 - needs more than one steered array (known mic locs, so I can't use)
 2.) consistency method (he tests this one)
 - needs set of predetermined locs ==> probably can't use
 3.) steered response power (SRP, eg. Zotkin04SpchLocHierPowSrch)
 - needs known mic locs but I maybe can bend this idea w/ PCA'ed lags

7. Multi-channel xcorr (MCCC)
- argmax of the determinant of a multi-pair correlation matrix
- requires knowledge of microphone spacing == I can't use it
- anyway, pre-whitening help.
- can be considered a generalization of GCC

8. Adaptive eigenvalue decomposition (AED, Benesty00adaptEigSrcLoc)
- ID's channel impulse response from a type of correlation matrix eigenvalue
- then peak pick impulse response
- adaptive and block algorithms
- I tried this and couldn't get it to work (so far)
- tends fails for LONG IMPULSE filter (common or near common zeros) but not as bad if do multi-channel

9. Adaptive multichannel time delay estimation (AMC)
- kind of like multi-channel AED (requires more than 2 mics)
- better for long impulse responses
- Several adaptive varances:
1.) multichannel LMS (MCLMS) (
-- simple update equation but slow convergence)
2.) normalized multichannel frequency-domain LMS (NMCFLMS)
-- freq domain, adaptve,
-- faster?
-- Might be easy to implement (algorithm 5 figure)
-- filter is still not very long (256 taps)

-- INTERPOLATION -----------------

How to get better resolution than sample period

i.) parabolic interpolation
 -- creates bias is low SNR
 -- can't used w/o bandlimited cost function stat.
 -- can't use for blind function impulse responses
ii.) increasing sample rate (duh)
iii.) increasing inter-mic spacing
 -- I've got plent of that!

-- Experimental Comparison

Biggest test difference from meeting room diarization:
1.) close mics (8" spacing! common zeros for AED)
2.) no correlated noise (fans)

Results:
* all methods were fairly robust to noise
* GCC-PHAT is actually not that bad in reverb (but other authors say it is)
* AMC did the best in reverb
* AED is the best of the two sensor algorithms
* MCCC and fusion methods better than any single pair method (MCCC is best)
 -- however, they argue that they may yield no improvement if not aligned at precision < 1 sample. (do I believe that?)
* adaptive algs take a while to converge but all converge in < 1sec},
  Timestamp                = {2007.08.08},
  Url                      = {http://www.hindawi.com/GetArticle.aspx?doi=10.1155/ASP/2006/26503&e=cta}
}

@Article{Chen02SrcLocBeamform,
  Title                    = {Source Localization and Beamforming},
  Author                   = {J.C. Chen and K. Yao and R.E. Hudson},
  Journal                  = {{IEEE} Signal Processing Magazine},
  Year                     = {2002},
  Pages                    = {30-39},
  Volume                   = {19},

  File                     = {Chen02SrcLocBeamform.pdf:Chen02SrcLocBeamform.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Max power beamforming reviewed, compared to iterative ML techniques},
  Timestamp                = {2007.07.27},
  Url                      = {http://citeseer.ist.psu.edu/chen02source.html}
}

@Article{chen02MLsrcLocUnkSens,
  Title                    = {Maximum-Likelihood Source Localization and Unknown Sensor Location Estimation for Wideband Signals in the Near-Field},
  Author                   = {Joe C. Chen and Ralph E. Hudson and Kung Yao},
  Journal                  = {IEEE Trans. on Sig. Proc.},
  Year                     = {2002},
  Number                   = {8},
  Pages                    = {1843-1854},
  Volume                   = {50},

  Comment                  = {604:ReadNo},
  File                     = {chen02MLsrcLocUnkSens.pdf:chen02MLsrcLocUnkSens.pdf:PDF},
  Review                   = {must know some sensor locations; figures it out if some are unknown},
  Url                      = {http://www.ee.ucla.edu/faculty/papers/yao_TransSP_aug02.pdf}
}

@Article{chen02srcLocWideRandSens,
  Title                    = {Source Localization and Tracking of a Wideband Source Using a Randomly Distributed Beamforming Sensor Array},
  Author                   = {J. C. Chen and K. Yao and T. L. Tung and C. W. Reed and D. Chen},
  Journal                  = {Intl. Journal of High Performance Computing Applications},
  Year                     = {2002},
  Number                   = {3},
  Volume                   = {16},

  Comment                  = {635:ReadYes},
  File                     = {chen02srcLocWideRandSens.pdf:chen02srcLocWideRandSens.pdf:PDF},
  Review                   = {Max power beamformer extensions: velocity, sensor loc estimation (1 of them), straight line tracking
* weights are largest eigenvalue of big correlation matrix (much like PCA)
* For Max Power details, best go to Yao 1998
* Says a QLP approximation to SVD is more efficient},
  Url                      = {http://www.sagepub.co.uk/JournalIssueAbstract.aspx?pid=105593&jiid=517939&jiaid=28109}
}

@Article{chen96speaker,
  Title                    = {Speaker Identification Using Time-Delay {HMEs}},
  Author                   = {K. Chen and D. H. Xie and H. S. Chi},
  Journal                  = {Intl. Journal of Neural Systems},
  Year                     = {1996},
  Number                   = {1},
  Pages                    = {29-43},
  Volume                   = {7},

  Comment                  = {165: ReadYes},
  Review                   = {Not very relevant to meeting recorder: NN w/ man frames as input, closed set, text dependent ID.

* Hierarchical Mixture of Experts vote on who it is
* 'Time delay' means that across time, as in HMM state transitions
* Time window is of fixed length
* Prefer gerneralize dBernoulli density over multinomial logit density (stability)},
  Url                      = {citeseer.nj.nec.com/chen96speaker.html}
}

@Misc{chen00mixture,
  Title                    = {Mixture Kalman filters},

  Author                   = {R. Chen and J. Liu},
  Year                     = {2000},

  Comment                  = {Print, ReadNo},
  Text                     = {Chen R. and Liu J.S. (2000) Mixture Kalman filters. J. R. Statist. Soc. B, 62, 493-508.},
  Url                      = {citeseer.nj.nec.com/chen00mixture.html}
}

@Misc{hornegger95localization,
  Title                    = {Statistical learning, localization, and identification of objects},

  Author                   = {R. Chen and J. S. Liu},

  Comment                  = {37.0: ReadNo},
  Review                   = {Relevant to speaker location features?}
}

@InProceedings{chen98speaker,
  Title                    = {Speaker, environment and channel change detection and clustering via the {Bayesian} information criterion},
  Author                   = {S. Chen and P. Gopalakrishnan},
  Booktitle                = {DARPA Speech Recognition Workshop},
  Year                     = {1998},

  Comment                  = {162: ReadYes},
  Review                   = {Broadcast News style speaker cluster/adapt, uses BIC exclusively
* BIC used to both segments and stops clustering
* cepstral features, # coeffs not reported
* single mixture gaussian models, don't say if diag cov
Segmentaton:
-- likelihood ratio choice between 1 or 2 spkrs in window. BIC penalty
-- grows until finds a change point
-- later criticised by delacourt99-speakerbased for long BIC win rqt.
-- allows decision w/ max data length v.s. const. len shifting windows
-- example showing how better than log like ratio (Gish) & KL distance
Clustering:
-- bottom-up (agglomerative)
-- merge segments that increase a BIC-derived parameter
-- stops when there's no segment that will increase this param
* no tweak factors or thresholds (BIC self-scales)
* BIC like AIC and RIC
* assumes interframe independence (igonores a lot of info, doesn't it?)
* e.g. no use of common onset, continuity, etc.
* clustering/deg separate w/ no iterations or revisons
* short segment problems: misses 78% of segments < 1 s long
* interruptions not handled
Results:
-- tested Hub4 1996/97 data
-- finds 31 clusters when there were 28 speakers 
-- 20 clusters had perfect purity; worst had purity of ~0.75
-- post-clust MLLR imp.: 2.3-2.4% (good as w/ perfect spkr knowledge).},
  Url                      = {citeseer.nj.nec.com/chen98speaker.html}
}

@Article{chen98bayesclust,
  Title                    = {Clustering via the {Bayesian} information criterion with applications in speech recognition},
  Author                   = {S. Chen and P. S. Gopalakrishnan},
  Journal                  = {Acoustics, Speech and Signal Processing},
  Year                     = {1998},
  Pages                    = {645-648},
  Volume                   = {2},

  Comment                  = {119: ReadNo},
  File                     = {chen98bayesclust.pdf:chen98bayesclust.pdf:PDF},
  Review                   = {GMM number of mixtures (speakers) w/ BIC}
}

@InProceedings{chen01wavpitch,
  Title                    = {Extraction of pitch information in noisy speech using wavelet transform with aliasing compensation },
  Author                   = {S. Chen and J. Wang},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},

  Comment                  = {183: ReadYes},
  Review                   = {Wavelet aliasing corrected but importance not shown
* similar to other wavelet schemes except
-- aliasing corrected (not explained or shown to matter)
-- used Daubeches wavelet instead of spline
-- vertical (cross-decomposition, same time) prod of 2 levels, not 3
* the vertical product but could be EM clustinering and could have BIC decide if >= 1 mode.}
}

@InProceedings{chen00gaussianization,
  Title                    = {Gaussianization},
  Author                   = {Scott Shaobing Chen and Ramesh A. Gopinath},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2000},
  Pages                    = {423-429},

  Comment                  = {295: ReadNo},
  Review                   = {NOTE: also copied to energy.bib},
  Url                      = {citeseer.nj.nec.com/456021.html}
}

@Article{chen00gaussLong,
  Title                    = {Gaussianization (submitted)},
  Author                   = {S. S. Chen and R. A. Gopinath},
  Journal                  = {Neural Comp},
  Year                     = {2000},

  Comment                  = {294: ReadNo},
  Review                   = {longer version with a lot in commong with chen00gaussianization (NIPS)}
}

@Article{cheng99plotHRTF,
  Title                    = {Spatial frequency response surfaces: an alternative visualization tool for head-related transfer functions ({HRTFs})},
  Author                   = {C. I. Cheng and G. H. Wakefield},
  Journal                  = {Unknown},
  Year                     = {1999},

  Comment                  = {227: ReadYes},
  Review                   = {New ways of plotting HRTF. Good localizaton physics table. 
* some narrow band noise always sounds like it's coming froem certain dirs, regarless of source! 
* poor localization @ 5-6KHz and this shows up in HRTFs, which are multivalued @ these freqs (maybe) 
* good summary table of localizaton physics and properties v.s. freq},
  Url                      = {www.eamusic.dartmouth.edu/~corey/pre-prints/icassp99_preprint.pdf}
}

@InProceedings{Cheng99compBNclassifiersMI,
  Title                    = {Comparing Bayesian Network Classifiers},
  Author                   = {Cheng, Jie and Greiner, Russell},
  Booktitle                = {UAI},
  Year                     = {1999},
  Pages                    = {101--108},

  Abstract                 = {In this paper, we empirically evaluate algorithms for learning four types of Bayesian
network (BN) classifiers -- Na\"{i}ve-Bayes, tree augmented Na\"{i}ve-Bayes (TANs), BN augmented Na\"{i}ve-Bayes (BANs) and general BNs (GBNs), where the GBNs and BANs are learned using two variants of a conditionalindependence based BN-learning algorithm. Based on their performance, we then define a new type of classifier. Experimental results show the resulting classifiers, learned using the proposed learning...},
  Citeulike-article-id     = {1433087},
  File                     = {Cheng99compBNclassifiersMI.pdf:Cheng99compBNclassifiersMI.pdf:PDF},
  Keywords                 = {bayesian, classifiers, networks},
  Owner                    = {scotto},
  Priority                 = {2},
  Review                   = {Uses mutual information to determine dependency in Bayesian networks},
  Timestamp                = {2008.01.29}
}

@InProceedings{cheng03spkrSegSeq,
  Title                    = {A Sequential Metric-based Audio Segmentation Method via The Bayesian Information Criterion},
  Author                   = {Shi-sian Cheng and Hsin-min Wang},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {945-948},

  Comment                  = {568: ReadNo},
  Review                   = {BN spkr seg w/ odd bndry BIC heuristic: multiple widths}
}

@InProceedings{cheveigne03multiF0,
  Title                    = {F0 estimation of one or several voices},
  Author                   = {Alain de Cheveign? and Alexis Baskind},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {833-836},

  Comment                  = {565: ReadNo},
  Review                   = {multi-F0 estimation}
}

@Article{cheveigne00info,
  Title                    = {Hearnet: Info for speakers},
  Author                   = {Alain de Cheveigne},
  Journal                  = {Hearnet},
  Year                     = {2001},

  Comment                  = {359: ReadYes},
  Review                   = {Summary of what was discussed at 2001 Hearnet Conf.
* mainly CASA or auditory blind source separation stuff
* main theme is monoaural processing
* Equalization Cancellation: two ears cancel each other out to find dir.
* modified EC: like freq domain ICA
* a bunch of other references
* main web page: http://www.ircam.fr/pcm/cheveign/sh/hearnet/},
  Url                      = {http://www.ircam.fr/pcm/cheveign/sh/hearnet/talks.html}
}

@InProceedings{chickering96efficient,
  Title                    = {Efficient Approximation for the Marginal Likelihood of Incomplete Data given a {Bayesian} Network},
  Author                   = {D. Chickering and D. Heckerman},
  Booktitle                = {{UAI}'96, Revised April 1997},
  Year                     = {1996},
  Pages                    = {158-168},
  Publisher                = {Morgan Kaufmann},

  Comment                  = {197: ReadYes},
  Review                   = {Compares non-hierarchical clustering techs: BIC, CS, Laplace, Gibbs
* BIC, etc. work by approximating marginal likelihood
CS MAP 
-- approx to marginal likelihood, like BIC
-- may be better than BIC for short segs
-- computationally about the same as BIC (fig 10, p. 30,31)
-- tests on discrete dis but can work on exponential dists (p. 13)
BIC ML
-- only model not sensitive to choice of prior (p. 24). Good or bad?
-- is most accurate ML configuration (but which do we want to use?)

* good derivation of model selection criteria
* explanation of Gibbs sampling
* good criteria for cluster separability: use for feature sel? p. 20
* alternate space is better but not good for contin. dists? p. 8
* use Theisson to calc Hessian but only for disc. dists? p. 10}
}

@InProceedings{cho01smoothVAD,
  Title                    = {Improved Voice Activity Detection Based on a smoothed statistical likelihood ratio},
  Author                   = {Yong Duk Cho and Khaldoon Al-Naimi and Ahmet Kondoz},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {737 -740},
  Volume                   = {2},

  Comment                  = {102: ReadYes},
  Review                   = {VAD handles voice offset problem w/ LPF'ed likelihood est
* seems to be like sohn99statistical but markov is replaced
* is supposed to improve errors at speech offset region 
* Noise variance comes from adaptation
* Speech variance estimated in Decision Directed manner
* better than G.792B},
  Url                      = {http://ieeexplore.ieee.org/iel5/7486/20369/00941020.pdf?isNumber=20369&prod=IEEE+CNF&arnumber=941020&arSt=737&ared=740+vol.2&arAuthor=Cho%2C+Y.D.%3B+Al-Naimi%2C+K.%3B+Kondoz%2C+A.%3B}
}

@InProceedings{choi01bssCorrMatch,
  Title                    = {Correlation matching approach to source separation in the presence of spatially correlated noise},
  Author                   = {Seungjin Choi and Cichocki, A. },
  Booktitle                = {Signal Processing and its Appications, Intl. Symp.},
  Year                     = {2001},
  Pages                    = {272-275 },
  Volume                   = {1},

  Comment                  = {ReadNo},
  Review                   = {correlation blind source separation. Number of sources chosen in section 3.1},
  Url                      = {http://ieeexplore.ieee.org/iel5/7547/20554/00949830.pdf?isNumber=20554&prod=CNF&arnumber=949830&arSt=272&ared=275+vol.1&arAuthor=Seungjin+Choi%3B+Cichocki%2C+A.}
}

@Book{Cichocki02adaptBlindBook,
  Title                    = {Adaptive Blind Signal and Image Processing},
  Author                   = {Andrzej Cichocki and Shun-ichi Amari},
  Publisher                = {John Wiley \& Sons, Ltd.},
  Year                     = {2002},

  File                     = {Cichocki02adaptBlindBook.pdf:Cichocki02adaptBlindBook.pdf:PDF},
  Owner                    = {scotto},
  Timestamp                = {2007.08.01}
}

@Article{cipra93kalman,
  Title                    = {Engineers look to Kalman filtering for guidance},
  Author                   = {B. Cipra},
  Journal                  = {{SIAM} news},
  Year                     = {1993},
  Number                   = {5},
  Volume                   = {26},

  Comment                  = {65: ReadNo},
  Review                   = {Overview w/ navigation perspective}
}

@InProceedings{claudio22locMUSIC,
  Title                    = {Multi-source localization in reverberant environments by {ROOT-MUSIC} and clustering},
  Author                   = {E. D. Di Claudio and R. Parisi and G. Orlandi},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},
  Pages                    = {921-924},
  Volume                   = {2},

  Comment                  = {171: ReadYes},
  Review                   = {Speech modeled as delayed sinusoid src, MUSIC finds # srcs and delays
* FFT computes post-whitening cross-power spectrum between mic doublets
* ROOT-MUSIC finds # of source sinusoids and their freqs
* delays are extracted for each found source freq phase
* 'noise' eigenvalues are considered to be small and are approx Gaussian
* 'speaker' e.vals have unknown dist, found as outliers from noise dist
* AIC or MDL (BIC?) are model error sensitive so use median estimator
* multipath & errors cause spatial estimates to fuzz into clusters
* prewhitening before autocorr improves performance
* geometric algs restrict delay search space and combine doublet ests.
* reverb modelled as large # of virtual sources, more than # of mics
* says parametric is bad for wideband, like speech. ROOT-MUSIC too?
* ROOT-MUSIC robust to envelope fluctuation.}
}

@InProceedings{como99bssUnder,
  Title                    = {Blind Channel Identification and Extraction of more Sources than Sensors},
  Author                   = {P. COMON},
  Booktitle                = {SPIE Conf.},
  Year                     = {1998},
  Pages                    = {2--13},

  Comment                  = {ReadNo},
  File                     = {http:FichiersPs/paper3461-1.ps:PostScript;como99bssUnder.ps.gz:como99bssUnder.ps.gz:PDF},
  Review                   = {keynote address},
  Url                      = {http://wwwi3s.unice.fr/~comon/FichiersPs/paper3461-1.ps.gz}
}

@Article{comon94independent,
  Title                    = {Independent component analysis---a new concept?},
  Author                   = {P. Comon},
  Journal                  = {Signal Processing},
  Year                     = {1994},
  Number                   = {287-314},
  Volume                   = {36},

  Comment                  = {Print, ReadNo}
}

@InProceedings{comon99nonlinICAunder,
  Title                    = {Non Linear Inversion of Underdetermined Mixtures},
  Author                   = {P. COMON and O. GRELLIER},
  Booktitle                = {ICA99, IEEE Workshop on Indep. Comp. Anal. and Blind Source Separation},
  Year                     = {1999},
  Pages                    = {461--465},

  Comment                  = {ReadNo},
  File                     = {http:FichiersPs/ica99.ps:PostScript;comon99nonlinICAunder.ps:comon99nonlinICAunder.ps:PDF},
  Review                   = {makes fake sensors w/ nonlinearity when don't have enough},
  Url                      = {http://wwwi3s.unice.fr/~comon/FichiersPs/ica99.ps}
}

@Article{consortium99:_elisa_system_evaluat_speak_detec_track,
  Title                    = {The {ELISA} Systems for the {NIST'99} Evaluation in Speaker Detection and Tracking},
  Author                   = {The ELISA Consortium},
  Journal                  = {Digital Signal Processing: A Review Journal},
  Year                     = {1999},
  Number                   = {1/2/3},
  Pages                    = {143-153},
  Volume                   = {10},

  Comment                  = {126: ReadNo}
}

@InProceedings{cook95utterance,
  Title                    = {Utterance clustering for large vocabulary continuous speech recognition},
  Author                   = {G. Cook and T. Robinson},
  Booktitle                = {Eurospeech},
  Year                     = {1995},
  Pages                    = {141-144},
  Volume                   = {1},

  Comment                  = {149: ReadYes},
  Review                   = {VQ split clustering (LBG) 
* tests on ARPA Wall St. Journal
* loglikelihood (Gish?) and AHS dist 
* AHS 
* got best perf w/ only 2 clusters (turned out to be Male/Female)
Results
* cluster-specific models reduced error rate by 14.5%}
}

@TechReport{ellis98auditoryOrg,
  Title                    = {The auditory organization of speech in listeners and machines},
  Author                   = {M. P. Cooke and D. P. W. Ellis},
  Institution              = {ICSI},
  Year                     = {1998},
  Number                   = {TR-98-016},

  Comment                  = {114: ReadYes},
  Review                   = {Really good wrteup on human sound perception (too long to summarize)

* table 2, p. 6 lists grouping cues for talker segregation, spatial localization, etc. 
* p 40-41 discuss appropriate speech databases 
* SATR is excellent database (8 mics, overlapping talkers, manikin ear mics) 
* p. 16-17: localization in humans is ambiguously helpful in separating talkers}
}

@TechReport{aurealXX3daudio,
  Title                    = {3-D audio primer},
  Author                   = {Aureal Corp.},
  Institution              = {aureal corp},
  Year                     = {unknown},

  Comment                  = {214: ReadYes},
  Review                   = {Marketing type paper on head related transfer function (HRTF)}
}

@TechReport{headroomXXheadphone,
  Title                    = {Psychoacoustics of headphone listening},
  Author                   = {Headroom Corp.},
  Institution              = {Headroom (Aureal?) Corp},
  Year                     = {unknown},

  Comment                  = {216: ReadYes},
  Review                   = {Marketing type paper on headphones and head related transfer function (HRTF)}
}

@InProceedings{couvreur02icaMicArrASR,
  Title                    = {Model-Based Independent Component Analysis For Robust Multi-Microphone Automatic Speech Recognition},
  Author                   = {Laurent Couvreur and Christophe Ris},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},

  Comment                  = {589:ReadYes},
  File                     = {couvreur02icaMicArrASR.pdf:couvreur02icaMicArrASR.pdf:PDF},
  Review                   = {ICA using HMM model entropy and energy negentropy
* Noise reduction, not separation
* both energy negentropy and phone model entropy used to adjust freq domain ICA weights
* not a beamformer b/c no delays are adjusted
* 2 microphones, closely spaced so no spatial aliasing
* tested on Aurora data w/ babble background noise
* huge improvement in WER e.g. 99% WER -> 30% W -5dB SNR},
  Url                      = {http://citeseer.ist.psu.edu/rd/53754526%2C566126%2C1%2C0.25%2CDownload/http://citeseer.ist.psu.edu/cache/papers/cs/27325/http:zSzzSztcts.fpms.ac.bezSzpublicationszSzpaperszSz2002zSzicslp2002_lccr.pdf/model-based-independent-component.pdf}
}

@Misc{cox95multiTargCorresp,
  Title                    = {On finding ranked assignments with application to multi-target tracking and motion correspondence},

  Author                   = {I. J. Cox and M. L. Miller},

  Comment                  = {43.0: ReadNo},
  Review                   = {Relevant to speaker location features, esp. associating speaker id w/ location id?}
}

@TechReport{cuadra02pitch,
  Title                    = {Efficient Pitch Detection Techniques for Interactive Music},
  Author                   = {Patricio de la Cuadra and Aaron Master and Craig Sapp},
  Institution              = {Center for Computer Research in Music and Acoustics, Stanford University},
  Year                     = {2002},

  Comment                  = {293: ReadYes},
  File                     = {cuadra02pitch.pdf:cuadra02pitch.pdf:PDF},
  Review                   = {Overview of Pitch techniques and their combination for better robustness
Harmonic Product Spectrum (HPS)
* pitch = MAX(prod(|X(k*w)|)); w is a candidate pitch; k=integer
* octave errors common
* lots of zero padding required
* heuristic filter for removing pitch doubling
* tends to double but not halve pitches
Maximum Likelihood (ML)
* start w/ predefined set of pitch templates (~Gaussians @ harmonics)
* choose template w/ largest intersection
* no interpoation needed
* fixed templates => OK for pianos, flutes; bad for voice, violin
* is this a candidate for a more statistically trained pitch detector?
Frequency Indexed Cepstral (FIC)
* find ceptral peaks in pitch region
* heuristic: peack qualifies if 2nd or third peaks an subs. harmonics
* tends to pitch halving but not doubling
* "possibly the most popular"
Cepstral HPS
* combined FIC and HPS for doubling/halving cancellation
* works better than separate
* works for multi-pitch detection (masters 2000 ref: get this)
* somehow mutliply HPS and FIC but I don't get it (explained in masters 2000, probably)
* two-talker: heuristic w/ peaks not being multiples of each other
Weighted Autocorrelation Function (ACF)
* pitch @ max peak ACF
Average Magnitude Difference Function (AMDF)
* pitch at min summed maf diff at lag
* has valleyes where ACF has peaks
ACF+AMDF
* ACF and AMDF are statistically independent
* combination at the lag level is better in noise.},
  Url                      = {http://www-ccrma.stanford.edu/~pdelac/PitchDetection/icmc01-pitch.pdf}
}

@InProceedings{dapena96bssSingle,
  Title                    = {An unconstrained single stage criterion for blind source separation},
  Author                   = {Dapena, A. and Castedo, L. and Escudero, C.},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1996},
  Pages                    = {2706-2709},
  Volume                   = {5},

  Comment                  = {ReadNo},
  Review                   = {ICA/BSS contrast functions with only global minima => can use convex opt?},
  Url                      = {http://ieeexplore.ieee.org/iel3/3856/11268/00550059.pdf?isNumber=11268&prod=CNF&arnumber=550059&arSt=2706&ared=2709+vol.+5&arAuthor=Dapena%2C+A.%3B+Castedo%2C+L.%3B+Escudero%2C+C.}
}

@Article{Deerwester90LatentSymIndex,
  author    = {Scott Deerwester and Susan T. Dumais and George W. Furnas and Thomas K. Landauer and Richard Harshman},
  title     = {Indexing by latent semantic analysis},
  journal   = {Journal of the American Society for Information Science},
  year      = {1990},
  volume    = {40},
  number    = {5},
  pages     = {391-407},
  comment   = {642:ReadYes},
  file      = {Deerwester90LatentSymIndex.pdf:Deerwester90LatentSymIndex.pdf:PDF},
  groups    = {semisupWorkshop07},
  owner     = {scotto},
  review    = {Classic Latent Symantic Analysis paper. Good SVD math/geometric explanation. Good intuitive example
(see also Landauer98LatentSemAnIntro)

LSA Goals (nice illustrative example)
 - recognize synonyms automatically: a match is likely if any synonomym in the pseudo doc is present
 - ignore unimportant words (do not appear consistently in docs of a certain class (psuedo docs)
 - express complicated representations not available in hierarchical clustering
 - explicit represenation of both terms and documents
 - computationally tractable

Algorithm
* Matrix of word counts, X: t (words) x d (documents)
 - can normalize word count rows to avoid bias by document length

* Decompose X with SVD (nice figures)

 Xhat = TSD

 T: matrix of eigenvectors of X*X' (a relation to PCA)
 D: matrix of eigenvectors of X'*X
 S^2: diagonal matrix if eigenvalues

* throw away dimensions of lower magnitude eigenvalues (along diagonal of S)
 - throwing away gets rid of noise
 - retains the "latent" documents that "generates" the random words actually found

Comparing, searching

* comparing words (~synonyms): row dot: 
 Xhat*Xhat' = T*S^2*T'

* comparing documents: col dot: 
 Xhat'*Xhat = D*S^2*D'

* comparing term and a document: 
 dot ith row (word) of T*sqrt(S) with jth column (doc) of D*sqrt(s)

* representing psuedo-documents: 
 - take an unseen document, q, and convert it into the equivalent of the rows of D used above
 - Dq = Xq'*T*S^-1},
  timestamp = {2007.06.18},
  url       = {http://www3.interscience.wiley.com.offcampus.lib.washington.edu/cgi-bin/jissue/10049584?CRETRY=1&SRETRY=0},
}

@InProceedings{delacourt99speaker-based,
  Title                    = {Speaker-based Segmentation for Audio Data Indexing},
  Author                   = {P. Delacourt and D. Kryze and C. Wellekens},
  Booktitle                = {Proc. EuroSpeech },
  Year                     = {1999},
  Pages                    = {1195-1198},

  Comment                  = {152: ReadYes},
  Review                   = {Talker segmenter: GLR followed by BIC (BIC necess if had clust?)
BIC as breakpt detector has weakness
* fails for short segs (chen says 78% error for segs < 1s)
* computationally expensive
* sensitive to lambda tuning params

Authors propose two pass breakpt detection
1.) Generalized Log Likelihood (GLR)
* adjacent, non-overlapping 2s windows sliding by 0.1s
* calc GLR at each slide
* adaptive threshold determines if it's a change pt.
-- used in place of BIC model complexity penalty
-- threhold determined as fraction of global dist var after LPF
-- supposed to have few deletion errors w/ many insertion errors
2.) BIC to remove GLR insertion errors
* use delta BIC on windows determined in 1.)
* windows can still be short but decision is based on all data in win
* BIC lambda still must be tuned

* seems to have fewer deletion errors on short segs than BIC
* not clear that 2nd BIC step is better than just clustering after GLR
* failure noted on interruptions}
}

@InProceedings{delfosse94bssDeflate,
  Title                    = { Adaptive separation of independent sources: a deflation approach},
  Author                   = {Delfosse, N. and Loubaton, P. },
  Booktitle                = {Proc. ICASSP},
  Year                     = {1994},
  Pages                    = {41-44},
  Volume                   = {4},

  Comment                  = {ReadNo},
  Review                   = {signal subtraction BSS, has global min => convex?},
  Url                      = {http://ieeexplore.ieee.org/iel2/3104/8836/00389881.pdf?isNumber=8836&prod=CNF&arnumber=389881&arSt=IV%2F41&ared=IV%2F44+vol.4&arAuthor=Delfosse%2C+N.%3B+Loubaton%2C+P.}
}

@InProceedings{delignne02icaEMconv,
  Title                    = {An {EM} Algorithm for Convolutive Independent Component Analysis},
  Author                   = {Sabine Deligne and et al.},
  Booktitle                = {Proc. {IEEE} Sensor Array and Multichannel Signal Processing Workshop},
  Year                     = {2002},
  Pages                    = {254-258},

  Comment                  = {296: ReadYes},
  Review                   = {Mixing, convolving filter, GMM sources estimated in time w/ EM
* source time coherence lumped into deconvolving filter (good?)
* giant convolution matrix
* two EM inits: sequential (not simultaneous) diag; and N-D AR whitening
* AR whitening is faster/cheaper
* EM algorithm with GMM source seems to have been done in Attias ref
* filter length estimated by AIC but I don't quite understand it
Improvements I can think of:
* use Cordoso's simultaneous diag (maybe that's better?)
* don't diag, since it may be suboptimal (although init approach # 1 may not stick to decorrelation manifold)
* use Penny GAR models instead of GMM
* also, use Penny source size estimator
* use entropy of phone models as in Willians&Ellis as a driver instead
* extend for sparse code monaural ICA},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/iel5/8442/26597/01191039.pdf?tp=&arnumber=1191039&isnumber=26597}
}

@Misc{january-addressing,
  Title                    = {Addressing the Correspondence Problem: A Markov Chain Monte Carlo Approach},

  Author                   = {F. Dellaert},

  Comment                  = {Print, ReadNo},
  Url                      = {citeseer.nj.nec.com/387567.html}
}

@Article{steven-feature,
  Title                    = {Feature Correspondence: A Markov Chain Monte Carlo Approach},
  Author                   = {F. Dellaert and S. Seitz and C. Thorpe and S. Thrun},
  Journal                  = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2001},
  Volume                   = {13},

  Comment                  = {Print, ReadNo},
  Url                      = {citeseer.nj.nec.com/389246.html}
}

@Misc{dellaertXXmotionstruct,
  Title                    = {Structure from motion without correspondence},

  Author                   = {F. Dellaert and S. M. Seitz and C. Thorpe and S. Thrun},

  Comment                  = {40.0: ReadNo},
  Review                   = {Relevant to speaker location features, esp. associating speaker id w/ location id?}
}

@Misc{dellaertXXmcmcFeatCorresp,
  Title                    = {Feature correspondence: a {Markov} chain monte carlo approach},

  Author                   = {F. Dellaert and S. M. Seitz and S. Thrun and C. Thorpe},

  Comment                  = {39.0: ReadNo},
  Review                   = {Relevant to speaker location features, esp. associating speaker id w/ location id?}
}

@Misc{deville01bssNonStatEmail,
  Title                    = {more about non-stationarity in {BSS}/{ICA}},

  Author                   = {Yannick DEVILLE},
  HowPublished             = {icalistArchive},
  Year                     = {2001},

  Comment                  = {ReadNo},
  Review                   = {much info about speech nonstaionarity in convolved mixtures and references},
  Url                      = {http://tsi.enst.fr/icacentral/icalistArchive/0120.html}
}

@Article{dhillon:modha:concept,
  Title                    = { Concept decompositions for large sparse text data using clustering},
  Author                   = {I. S. Dhillon and D. S. Modha},
  Journal                  = { Machine Learning},
  Year                     = {2001},
  Number                   = { 1},
  Pages                    = { 143--175},
  Volume                   = { 42},

  File                     = {dhillon\:modha\:concept.pdf:dhillon\:modha\:concept.pdf:PDF},
  Review                   = {Describes concept decomposition used for NNMF init in Albright and Langville papers

* concept vectors: spherical k-means centroids, normalized to unit length
* spherical kmeans: uses cosine similarity instead of Euclidean dist for clustering (it's explained)
 - advantages:
 - can exploit the sparsity of the text data, 
 - it can be efficiently parallelized 
 - converges quickly (to a local maxima). 
 - generates concept vectors that serve as a model which may be used to classify future documents.
 (these things are probably why they're used for NNMF init

* "concept decomposition"
 - X=CZ
 where C is the concept matrix (matrix of concept vectors)
 X is the document word count matrix
 Z is the concept decomposition
 - compute Z with QR decomposition

* comparison of concept vectors and SVD
 - concept vectors are sparse and local
 - concept vectors "tend" toward ortonormality (SVD's are)
 - approximation power of concept decompositions is comparable to that of truncated SVDs
 - subspaces spanned by concept vectors are quite close to the subspaces spanned by the singular vectors
 - cv comp is faster and less memory intensive (but then why do Albright and Langville) do SVD 1st, claiming a computation al advantage before doing CV??},
  Url                      = {citeseer.ist.psu.edu/article/dhillon01concept.html}
}

@InProceedings{digalakis94genone,
  Title                    = {Genones: Optimizing the Degree of Mixture-Tying in a Large-Vocabulary {HMM}-Based Speech Recognizer},
  Author                   = {V. Digalakis and H. Murveit},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1994},
  Pages                    = {I-537-I-540},

  Comment                  = {301: ReadYes},
  Review                   = {Describes Mixture tying done in SRI's speech recognizer
* genone: set of mixture components (mean,sigma)
* states share entire mixture set (genone); mixture weights are adjusted
* idea: reduce params while keeping acoustic space adequately sampled
* For each group of allophones:
1.) determine which states will be tied
-- make GMM for each state of each allophone (I think: it's not clear)
-- agglom. clust. of states by "weighted-by-counts entropy" [8]
2.) split and prune
-- allocate a subset of components to each group of clustered states
-- same component can be copied to several groups
3.) Zoom (re-estimate components)
-- foreach clustered state group, reestimate components
-- foreach state, re-est mixture comps?? Not clear
* seems to work better than conventional mixture tying
* also explains conventional phonetic mixture tying}
}

@InProceedings{ding03featSelMinRedund,
  Title                    = {Minimum redundancy feature selection from microarray gene expression data},
  Author                   = {Ding, C. and Peng, H.},
  Booktitle                = {Proc., Bioinformatics Conf.},
  Year                     = {11-14 Aug. 2003},
  Pages                    = { 523-528},

  Abstract                 = { Selecting a small subset of genes out of the thousands of genes in microarray data is important for accurate classification of phenotypes. Widely used methods typically rank genes according to their differential expressions among phenotypes and pick the top-ranked genes. We observe that feature sets so obtained have certain redundancy and study methods to minimize it. Feature sets obtained through the minimum redundancy - maximum relevance framework represent broader spectrum of characteristics of phenotypes than those obtained through standard ranking methods; they are more robust, generalize well to unseen data, and lead to significantly improved classifications in extensive experiments on 5 gene expressions data sets.},
  Doi                      = {10.1109/CSB.2003.1227396},
  File                     = {ding03featSelMinRedund.pdf:ding03featSelMinRedund.pdf:PDF},
  ISSN                     = { },
  Journal                  = {Bioinformatics Conference, 2003. CSB 2003. Proceedings of the 2003 IEEE},
  Keywords                 = { arrays, feature extraction, genetics, redundancy microarray gene expression data, minimum redundancy - maximum relevance framework, minimum redundancy feature selection, phenotypes, spectrum characteristic},
  Owner                    = {scotto},
  Review                   = {Greedy feature sel: label mutual info (-/) average MI w/ already selected.
- compared to several standard F-test techniques: 
 - correlation difference, correlation quotient, distance mult, similarity quotient
 - works better than they do
- expanded in Peng05 to include classification wrappers
- good refs
- Schaffernicht09residMutInfoFeatSel: a way to avoid the redundancy subtraction, which is a bit of a hack
- Heuristics used in this paper (Ding and Peng) generalized inBrown12condLikInfoFeatSel (energy.bib)},
  Timestamp                = {2008.01.27}
}

@Article{pham01bssNonStat,
  Title                    = {Blind separation of instantaneous mixtures of nonstationary sources},
  Author                   = {Dinh-Tuan Pham; Cardoso, J.-F.},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {2001},
  Number                   = {9},
  Pages                    = {1837-1848},
  Volume                   = {49},

  Comment                  = {ReadNo},
  Review                   = {nonstationary separation but instantaneous. Maybe talks about contrast funcs?},
  Url                      = {http://ieeexplore.ieee.org/iel5/78/20403/00942614.pdf?isNumber=20403&prod=JNL&arnumber=942614&arSt=1837&ared=1848&arAuthor=Dinh-Tuan+Pham%3B+Cardoso%2C+J.-F.}
}

@Article{minh02genGauss,
  Title                    = {Wavelet-Based Texture Retrieval Using Generalized Gaussian Density and Kullback Leibler Distance},
  Author                   = {Minh N. Do and and Martin Vetterli},
  Journal                  = {IEEE TRANSACTIONS ON IMAGE PROCESSING,},
  Year                     = {2001},
  Number                   = {2},
  Pages                    = {146-158},
  Volume                   = {11},

  Comment                  = {ReadNo}
}

@Article{Doclo03RobAdaptTimeDel,
  Title                    = {Robust Adaptive Time Delay Estimation for Speaker Localization in Noisy and Reverberant Acoustic Environments},
  Author                   = {Doclo, Simon and Moonen, Marc},
  Journal                  = {EURASIP Journal on Applied Signal Processing},
  Year                     = {2003},
  Note                     = {doi:10.1155/S111086570330602X},
  Number                   = {11},
  Pages                    = {1110-1124},
  Volume                   = {2003},

  File                     = {Doclo03RobAdaptTimeDel.pdf:Doclo03RobAdaptTimeDel.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Extends Benesty00adaptEigSrcLoc to case where have a noise estimate, also has good overview of min eigenvalue technique

* GEVD of Bandenstein book, I think
* under realistic reverb/noise conditions, convergence time is about a second, too slow for diarization, I think
* and actually, the filter length is really short, only 40 samples. For the diarization, lag is +-138 or so, so need K>=276

K>L: what happens if your filter length, K, is longer than the true room reverb filter length, L?
* if K > L, then have K - L + 1 zero eigenvalues

K<L: what if you guess too short?
* no zero valued eigenvalues
* impulse response can't be ID'd correctly
* but says that can still find the main path delay using the calculated filters},
  Timestamp                = {2007.08.01},
  Url                      = {http://www.hindawi.com/GetArticle.aspx?doi=10.1155/S111086570330602X&e=cta}
}

@Article{Doclo02gsvdOptFilt,
  Title                    = {{GSVD}-based optimal filtering for single and multi-microphone speech enhancement},
  Author                   = {S. Doclo and M. Moonen},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {2002},
  Number                   = {9},
  Pages                    = {2230--2244},
  Volume                   = {50},

  File                     = {Doclo02gsvdOptFilt.pdf:Doclo02gsvdOptFilt.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Like SVD max power beamforming but use VAD to get a noise estimate},
  Timestamp                = {2007.07.27},
  Url                      = {citeseer.ist.psu.edu/doclo02gsvdbased.html}
}

@InProceedings{Doclo99svdOptFiltSpeech,
  Title                    = {SVD-based optimal filtering with applications to noise reduction in speech signals, a matrix math reference too},
  Author                   = {S. Doclo and M. Moonen},
  Booktitle                = {{IEEE} Applications of Signal Processing to Audio and Acoustics},
  Year                     = {1999},
  Pages                    = {143-146},

  File                     = {Doclo99svdOptFiltSpeech.pdf:Doclo99svdOptFiltSpeech.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Big review of SVD speech beamforming, including maximum power beamforming. Lots of info.},
  Timestamp                = {2007.07.27},
  Url                      = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=810870&isnumber=17564&punumber=6581&k2dockey=810870@ieeecnfs&query=%28%28svd-based+optimal+filtering+with+applications+to+noise+reduction+in+speech+signals%29%3Cin%3Emetadata%29&pos=0}
}

@TechReport{Doclo99svdOptFiltTechNote,
  Title                    = {{SVD}-based Optimal Filtering with Applications to Noise Reduction in Speech Signals},
  Author                   = {S. Doclo and M. Moonen},
  Institution              = {Departmement Elektrotechniek ESAT-SISTA},
  Year                     = {1999},
  Number                   = {1999-33},

  File                     = {Doclo99svdOptFiltTechNote.pdf:Doclo99svdOptFiltTechNote.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {A technote for the IEEE article of the same name and authors (Doclo99svdOptFiltSpeech)},
  Timestamp                = {2007.07.27},
  Url                      = {http://citeseer.ist.psu.edu/221185.html}
}

@Article{dong01continSVMspkrID,
  Title                    = {Speaker recognition using continuous density support vector machines},
  Author                   = {X. Dong and W. Zhaohui},
  Journal                  = {Electronics Letters},
  Year                     = {2001},
  Number                   = {17},
  Pages                    = {1099-1101},
  Volume                   = {37},

  Comment                  = {4.5: ReadYes},
  Review                   = {Weighed-average-Hybrid GMM/SVM improves speaker ID
* RBF kernel one-against-all SVM outputs train sigmoid pdfs
* SVM probs make weighted average prob classification score
* GMM probs are averaged with SVM probs to make final decision
* works: EER goes from 2.06% to 1.56% (24% reduction)
* SVM's by themselves don't work well (3.18% EER)
* 18 mixture GMM's, 12 order LPC+del (24 coeffs)}
}

@InProceedings{dorken94pitchPCA,
  Title                    = {Improved musical pitch tracking using principal decomposition analysis},
  Author                   = {Erkan Dorken and S. Hamid Nawab},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1994},
  Pages                    = {II-217-II-210},

  Comment                  = {325: ReadYes},
  Review                   = {Multi-pitch music tracking using PCA. Hard to understand...
Constant Q filter bank
* why constant Q: 
- matches music scale
- need wider BW to track higher harmonics (delta(F0) => k*delta(F0)).
NOTE: only matters if trackng; if trying to ID two independent speakers, then pitches will overlap randomly?
- no mention of beats...
* some kinda PCA predicion where freq xcorr peaks predict each other but I can't understand it...

* Referenced in Yantorno's 1998 cochannel summer report}
}

@InProceedings{doukas97bssVAD,
  Title                    = {Voice Activity Detection Using Source Separation Techniques},
  Author                   = {N. Doukas and P. Naylor and T. Stathaki},
  Booktitle                = {Eurospeech },
  Year                     = {1997},
  Pages                    = {1099--1102},

  Comment                  = {371: ReadYes},
  Review                   = {Single sensor source separator error used as a VAD; testing not great
* works better than GSM VAD in noise 
- white noise, supposed to be worst case for SSSS
- tested down to SNR-8dB
- but the test seems to be only 1600 samples
* FIR filters make synthesized "channels" so have two BSS inputs
* Basic idea: 
-- a Lagrange estimator error spikes when signal stats change
-- thresholder catches edges to find spch/nonspch transitions.
* FIR design is fixed but could be REVERB or whatever
* based on Lagrange NN
* Two stage adaptive threshold seems likely to break
* but, in fact, it works well under really heavy white noise
* seems like you'd get a lot of false transitions for non-speech 
noise changes (noise was always white).
* could this be modified to requires a speech model est?},
  Url                      = {citeseer.nj.nec.com/49153.html}
}

@InProceedings{doukas97vadStability,
  Title                    = {Stability of a voice activity detector based on source separation},
  Author                   = {Doukas, N. and Stathaki, T. and Naylor, P.},
  Booktitle                = {Digital Signal Processing Proc., {IEEE} Intl Conf. on},
  Year                     = {1997},
  Pages                    = {749-752},
  Volume                   = {2},

  Comment                  = {372:ReadYes},
  Review                   = {BSS VAD stability analysis -- it's stable but analysis seems bogus
* stability analysis for Doukas BSS VAD
* uses Lagrange NN techniques and Mathematica for the algebra
* says it's stable for small input signal variance
* huh? scale and it's stable?
* anyway paper on VAD shows it works for noisy signals
* even this simple stability analysis is complex -- adaptive BSS hard?},
  Url                      = {http://ieeexplore.ieee.org/search97/s97is.vts?Action=Search&SearchPage=VSearch.htm&sortfield=pyr&sortorder=desc&ResultTemplate=adv_crst.hts&ResultCount=25&ViewTemplate=lpdocview.hts&queryText=stability+of+a+voice+activity}
}

@InProceedings{doukas96enhanceNonlin,
  Title                    = {Speech enhancement through nonlinear adaptive source separation methods},
  Author                   = {Doukas, N. and Stathaki, T. and Naylor, P. },
  Booktitle                = {Statistical Signal and Array Processing, {IEEE} Signal Processing Workshop on },
  Year                     = {1996},
  Pages                    = {279-282},

  Comment                  = {370:ReadYes},
  Review                   = {FIRs synthesize BSS inputs from monaural, lagrange NN separates
* is the basis for Voukas VAD
* FIR's make fake "channels" for BSS
* FIR coeff design is fixed and ad-hoc
* for separation, odd crossmoments must be zero so min that
-- cost function minmized is =lower= bound on this, which seems weak
-- min is subject to constraint that NN outputs add up to src signal
* this is a job for a Lagrange Programming Neural Net
* variable gain adaptation limits oscillations but I don't understand it},
  Url                      = {http://ieeexplore.ieee.org/search97/s97is.vts?Action=FilterSearch&SearchPage=VSearch.htm&ResultTemplate=adv_crst.hts&Filter=fld_sch.hts&ViewTemplate=lpdocview.hts&queryText=speech+enhancement+through+nonlinear+adaptive&collection=jour&collection=conf&collection=stds&collection=pprint&py1=&py2=2002&SortField=pyr&SortOrder=desc&ResultCount=15}
}

@InProceedings{doval93pitchMLhmm,
  Title                    = {Fundamental frequency estimation and tracking using maximum likelihood harmonic matching and {HMM}s},
  Author                   = {Boris Doval and Xavier Rodet},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1993},
  Pages                    = {I-221-I-224},

  Comment                  = {324: ReadYes},
  Review                   = {Pitch tracking using MLE harmonic sieve and HMM
* slides harmonic sieve around => match => probability
* harmonic sieve reduces pitch divisions
* spectral envelope somehow modeled by cepstra
* HMM-trained probability distributions

*referenced by Yantorno's 1998 co-channel speech summer report}
}

@InProceedings{droppo98pitchMAP,
  Title                    = {Maximum a Posteriori Pitch Tracking},
  Author                   = {James Droppo and Alex Acero},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1998},

  Comment                  = {ReadNo},
  File                     = {droppo98pitchMAP.pdf:droppo98pitchMAP.pdf:PDF},
  Review                   = {Les Atlas's student's pitch alg. Used in Microsoft's Mandarin Chinese pitch det (according to Costas)},
  Url                      = {http://research.microsoft.com/srg/papers/1998-droppo-icslp.pdf}
}

@InProceedings{dublanchet97doa,
  Title                    = {Direction-of-arrival and frequency estimation using Poisson-Gaussian modeling},
  Author                   = {F. Dublanchet and J. Idier and P. Duwaut},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1997},
  Pages                    = {3501-3504},
  Volume                   = {5},

  Comment                  = {204: ReadYes},
  Review                   = {DOA's for unkown # of spiky sources
* spikes are glottal pulses?
* criticized BIC and AIC for unrobustness when few samples
* useful for short spans of suspected interruption?}
}

@Book{duda01pattClassBook,
  Title                    = {Pattern Classification },
  Author                   = {Richard O. Duda and Peter E. Hart and David G. Stork},
  Publisher                = {Wiley-Interscience},
  Year                     = {2001},

  Review                   = {Pattern Recognition textbook for Mari's EE596I},
  Comment                  = {See comments in energy.bib, if any},
}

@Misc{dudaXXrangeHRTF,
  Title                    = {Range-dependence of the {HRTF} for a spherical head},

  Author                   = {R. O. Duda and W. L. Martens},

  Comment                  = {213: ReadYes},
  Review                   = {Just a measurement of range dependence 
* interesting that get mag. spike from surface wave around head 
* effect of waves travelling aroun dhead is shown in plots 
* but I don't quite understand the explanation}
}

@TechReport{Dudioit00genDiscrim,
  Title                    = {Comparison of Discrimination Methods for the
Classification of Tumors Using Gene Expression Data},
  Author                   = {Sandrine Dudoit and Jane Fridlyan and Terence P. Speed},
  Institution              = {Mathematical Sciences Research Institute, Berkeley, CA.},
  Year                     = {2000},

  File                     = {Dudioit00genDiscrim.pdf:Dudioit00genDiscrim.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Uses the F-test to select genes (bookmark chapter 4)
And more: http://en.wikipedia.org/wiki/F-test},
  Timestamp                = {2008.01.29}
}

@Article{robert99:_approac_speak_detec_track_conver_speec,
  Title                    = {Approaches to Speaker Detection and Tracking in Conversational Speech},
  Author                   = {R. B. Dunn and D. A. Reynolds and T. F. Quatieri},
  Journal                  = {Digital Signal Processing: A Review Journal},
  Year                     = {1999},
  Number                   = {1/2/3},
  Pages                    = {93-112},
  Volume                   = {10},

  Comment                  = {122: ReadNo},
  Review                   = {(but should!)}
}

@Misc{dusanXXvtFromMfccs,
  Title                    = {Recovering vocal tract shapes from {MFCC} parameters},

  Author                   = {S. Dusan and L. Deng},
  HowPublished             = {unknown},

  Comment                  = {233: ReadYes},
  Review                   = {Kalman smoothing of articulatory parameter estimates 
* resolves ambiguity when many articulatory configs could have made the same sound 
* all Kalman params estimated w/ EM forward-backward alg. 
* many-to-one accoust->articulatory function approx by VQ and linearization by Taylor series 
* suboptimal since Kalman expects Gaussian and non-linear stuff => it's not 
* maybe not too relevant, except as example of tricky Kalman tracking}
}

@Article{Dvorkinda05tdoaSpeech,
  author    = {Tsvi G. Dvorkinda and Sharon Gannot},
  title     = {Time difference of arrival estimation of speech source in a noisy and reverberant environment},
  journal   = {Signal Processing},
  year      = {2005},
  volume    = {85},
  number    = {1},
  pages     = {177-204},
  file      = {Dvorkinda05tdoaSpeech.pdf:Dvorkinda05tdoaSpeech.pdf:PDF},
  groups    = {waspaaComment},
  owner     = {scotto},
  review    = {Waspaa reject editor paper},
  timestamp = {2007.07.30},
  url       = {http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6V18-4DN97S1-4&_user=582538&_coverDate=01%2F01%2F2005&_rdoc=1&_fmt=&_orig=search&_sort=d&view=c&_acct=C000029718&_version=1&_urlVersion=0&_userid=582538&md5=eb23320f1e6530c9889dc7e7d4c95122},
}

@Misc{ellis00meetingXcorr,
  Title                    = {Cross-corr. web page},

  Author                   = {D. Ellis},
  Year                     = {2000},

  Comment                  = {167: ReadYes},
  Review                   = {Meeting recorder xcorr across microphones 
* good bit on 2-mic angle corrrelation for speaker separation 
* attempt @ removing mouth mic cross-talk from other speakers 
* interesting histogram and noise floor heuristics for ID'ing each speker's taling time 
* mixing matrix inversino doesn't halep that much 
* discussion of mixing matrix maybe indicates why ICA unmixers could have a hard time 
* no attempt @ continuity estimation 
* why not use a harmonic VAD?}
}

@InProceedings{ellis04spkrSegChanDiff,
  Title                    = {Speaker turn segmentation based on between-channel differences},
  Author                   = {D. Ellis and J. Liu },
  Booktitle                = {Proc. ICASSP},
  Year                     = {2004},

  Comment                  = {602:ReadYes},
  File                     = {ellis04spkrSegChanDiff.pdf:ellis04spkrSegChanDiff.pdf:PDF},
  Review                   = {Meeting spkr seg by xcorr loc feats, spect clust, bad results
* tested on NIST RT04S eval meetings 
* desktop mics (or CMU lapel/singleOmni)
* >50% errors (tended to miss speakers (eg. missed 4 of seven))
* arbitray microphone geometry assumed
* nothing special done for overlaps & doesn't detect them
* Preproc: 
- pre-emph -> 500-6Kbpf -> LPCinverse -> xcorr
- no mention of VAD or segmentation before
Xcorr peaks for clustering: 
* 250ms analysis window, window skip
* only calculated two channel pairs
* not auditory w/ envelope xcorr (why not?)
* 250ms window (too short of ICSI meetings)
* med filt & dyn prog outlier removal didn't work
- they don't know this but the problem is spatial aliasing!
* good peak selection: threshold normalized Rxy(@ peak)
* about 1/2 are selected for clustering
Clustering of Xcorr Peaks
* 2D features (two mic pair lag times)
* affinity matrix (600us xcorr lag in gaussian sigma)
* Spectral clustering: 
- good ref relating to Markov trans. probs
- Remove bad eigen vals based on:
-- affinity eig mag ~= #pts/cluster => 1% pt count thresh
--- (ABOVE is CLEVER: USE IT)
-- concentration of eig _vector_ (note USE ENTROPY INSTEAD!)
* Classifications
- pts assigned by "eigenvalue dimension" WHAT IS THIS?
- pts > Mahahalonibus dist > 4 are called "non-speech"
* Results: 
- roughly 50-85% errors
- mostly deletions (because of bad xcorr peaks)},
  Url                      = {http://www.ee.columbia.edu/~dpwe/pubs/nist04-turnid.pdf}
}

@Misc{ellis00crosscancelweb,
  Title                    = {{ICSI} Meeting Recorder Project: Cross-cancellation of microphone channels},

  Author                   = {D. P. W. Ellis},
  HowPublished             = {Web Page: \url{http://www.icsi.berkeley.edu/~dpwe/research/mtgrcdr/xcancel.html}},
  Year                     = {2000},

  Comment                  = {Print, ReadNo},
  Review                   = {Removing other-talker voices from headset mic signals, speech/nonspeech too
Spatial ID
* plots of 2-mic angle corr for speaker spatial ID. Full of holes.
* correlation angle limits are calculated
Speech/non-speech: energy threshold
* gain diffs handled by first subtracting avg log energy from channels
* EM fit 3 Gaussians to energy histo
* ctr of middle Gaussian is threshold (with some fudging)
Talker Separation
* mult channels by inverse of estimated mixing matrix (done in energy)
* messes up voice/non-voice detection
* recommends doing full-up blind source sep, on individual waveforms instead of energy envelopes but hasn't done it yet.
* maybe use for overlap resolution? },
  Url                      = {http://www.icsi.berkeley.edu/~dpwe/research/mtgrcdr/xcancel.html}
}

@PhdThesis{ellis96pdacasaPhD,
  Title                    = {Prediction-driven computational auditory scene analysis},
  Author                   = {D. P. W. Ellis},
  School                   = {MIT},
  Year                     = {1996},

  Comment                  = {330: ReadYes},
  Review                   = {Spawns/groups harmonics tracks based on prediction (wefts)
* Mainly, I read Chapter 4 for auditory filter and Xcorr theory
- why constant Q, rectification, etc.
- has filter cutoffs center freqs etc.
* has a unique way of removing root tone (beat) (p. 91)
* also has a bunch of AI blackboard stuff}
}

@Misc{ellis95casaHard,
  Title                    = {Hard problems in computational auditory scene analysis},

  Author                   = {D. P. W. Ellis},
  HowPublished             = {web page},
  Year                     = {1995},

  Comment                  = {116: ReadYes},
  Review                   = {Mini-enthusiast problem: how many talkers are speaking when all have same F0?
* two good enthusiast problem
* one good hard problem}
}

@InProceedings{ellis93hierarchic,
  Title                    = {Hierarchic models of hearing for sound separation and reconstruction},
  Author                   = {D. P. W. Ellis},
  Booktitle                = {Proc. IEEE Workshop on Apps. of Sig. Proc. to Acous. and Audio (Mohonk), October 1993.},
  Year                     = {1993},

  Comment                  = {180: ReadYes},
  Review                   = {Speculation on how signal tracks might be segregates at higher level
* removes impulsive noise from clarinet
* maybe not too relevant to meeting recorder
* maybe use for overlap resolution? },
  Url                      = {citeseer.nj.nec.com/ellis93hierarchic.html}
}

@InProceedings{elton96aoaDeint,
  Title                    = {A state space approach to joint {AOA} and period estimation for a class of periodic discrete event processes},
  Author                   = {S. D. Elton and B. J. Slocumb},
  Booktitle                = {{IEEE} Region Ten Conf. ({TENCON}) Digital Signal Processing Applications Proc.},
  Year                     = {1996},
  Pages                    = {686-91},
  Volume                   = {2},

  Comment                  = {ReadNo},
  Review                   = {maybe good for joint pitch and location estimation. Also number of talkers and overlap detection?},
  Url                      = {citeseer.nj.nec.com/elton96state.html}
}

@Article{emilCL98timeDelayUnder,
  Title                    = {Estimation of Time Delays with fewer Sensors than Sources},
  Author                   = {B. EMILE and P. COMON and J. LEROUX},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {1998},
  Number                   = {7},
  Pages                    = {2012--2015},
  Volume                   = {46},

  Comment                  = {ReadNo},
  File                     = {http:FichiersPs/emilC98ieeesp.ps.gz:;emilCL98timeDelayUnder.ps.gz:emilCL98timeDelayUnder.ps.gz:PDF},
  Url                      = {http://wwwi3s.unice.fr/~comon/FichiersPs/emilCL98ieeesp.ps.gz}
}

@InProceedings{Engin05Multimodalspeakeridentification,
  Title                    = {Multimodal speaker identification using an adaptive classifier cascade based on modality reliability},
  Author                   = {Erzin Engin and Y. Yemez and A. M. Tekalp},
  Booktitle                = {Multimedia, {IEEE} Transactions on},
  Year                     = {2005},
  Number                   = {5},
  Pages                    = {840-852},
  Volume                   = {7},

  Comment                  = {623:ReadYes},
  File                     = {Engin05Multimodalspeakeridentification.pdf:Engin05Multimodalspeakeridentification.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Fuses Face,Lips,Acoustic for Speaker ID; feature/HMM stream confidences, reliabilities; bizzare cascade w/ math proof

* Features: lip movement, eigenface, MFCC's
* Distinguishes between mode (feature) reliability and confidence (eq for when this makes sense)
 - confidence: distance of max lik speaker model from threshold which rejects decision in favor of impostor
 - reliability: dist. between top 2 max lik speaker models, posterior of max, and/or confidence of reject
 (reliability is sigmoid-weighted in order to normalize).
* Problem w/ product of feature posteriors fusion
 1.) if features correlated, then the same thing gets extra weight in final decision
 2.) P(feature|class) may be poorly estimated
 3.) can't handle impostor rejection (a main topic in this paper)

* A combination early/late fusion
 - early: fuse features, best for when features are correlated
 - late: fuse decisions made on feautres, best for when uncorrelated
 - but actually, they do combinations of fusions and pick the best combo empirically

* They fuse based on probability of correct decision (some math, w/ assumptions in appendix)

* end up with a cascade of decisions based on fused and non-fused features (most reliable decider that is confidence makes the choice, else, there is a wieghted reliability decision, I think). Both reliability and confidence change every frame.

* intersting that one decider is fused lip/audio and another is audio alone 
 - suggests fusing w/ MFCC's not a bad idea?)
 - may want to fuse and not fuse ER/XC and ER/XC/audio

* audio/lip fusiion
 - by themselves, multistream HMM (lip/audio) works better than single stream conccat
 - multistream HMM is itself fused
 - stream weights are apparently empirical
 - later paper: audio/lip fuser done with CCA},
  Timestamp                = {2007.04.02},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/searchresult.jsp?query1=&scope1=metadata&op1=and&query2=&scope2=metadata&op2=and&query3=&scope3=metadata&queryText=%28%28multimodal+speaker+identification+using+an+adaptive+classifier%0D%0A%29%3Cin%3Emetadata%29&history=yes&reqloc=adv&queryblock=multimodal+speaker+identification+using+an+adaptive+classifier%0D%0A&submit=Run+Search&srchlist=publist&coll1=ieeejrns&coll2=ieejrns&coll3=ieeecnfs&coll4=ieecnfs&coll5=ieeestds&coll6=preprint&coll7=books&std_status=all&currweek=19-Mar-2007&srchyr=allyr&py1=1950&py2=2007&disp=cit&maxdoc=100&ResultCount=25&SortField=Score&SortOrder=desc}
}

@InProceedings{erdogmus01bssUnderMix,
  Title                    = {Nonparametric Estimation and Tracking of the Mixing Matrix for Underdetermined Blind Source Separation},
  Author                   = {D. Erdogmus and J. C. Pr?ncipe and L. Vielva},
  Booktitle                = {Independent Component Analysis and Blind Signal Separation, Intl. Conf on},
  Year                     = {2001},

  Comment                  = {ReadNo},
  Review                   = {on the way to monaural ica. Also has mention of single speaker detection (== overlap detection)
I think matlab was available for this?},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/116-derdogmus2.pdf}
}

@InProceedings{eriksson01icaCharFunc,
  Title                    = {{NOVEL} {CHARACTERISTIC} {FUNCTION} {BASED} {CRITERIA} {FOR} {ICA}},
  Author                   = {J. Eriksson and A. Kankainen and V. Koivunen},
  Booktitle                = {Independent Components Analysis and Signal Separation},
  Year                     = {2001},

  Comment                  = {378: ReadYes},
  Review                   = {Factorized CDF instead of cumulants, etc. is versatile, data-efficient
Factorized cdf
* independence if joint cdf [pdf] == prod(individual cdf [pdf])
* so, many ICA algs explicitly or implicitly rely on cdf factorization or some related statistic
* many use parametric dist models that are not robust over many signals
* sometimes cdf does not even exist
* refs for cases of failure 
Factorized characteristic functin
* this always exists
* contrast is related to emperical char func.
Orthogonal Jacobi
* requires prewhitenting (cardoso "three easy..." criticizes)
* Givens rotation
* replaces cumulants w/ characteristic functions -- a direct measure of indep
Performance of three char func methods
* mostly, they work in pathological/broad conditions where others, like fastICA, and JADE, fail in some cases
* data-efficient. They work for about 500 pts.},
  Url                      = {http://ica2001.ucsd.edu/}
}

@InProceedings{ertan99melpVocoder,
  Title                    = {Implementation of an Enhanced Fixed Point Variable Bit-Rate {MELP} Vocoder on {TMS320C549}},
  Author                   = {A. E. Ertran and E. B. Aksu and H. G. Ilk and H. Karci and ). Karpat and T. Kolcak and L. Sendur and M. Demirekler and A. E Cetin},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999},
  Pages                    = {2295-2298},
  Volume                   = {4 },

  Comment                  = {107: ReadYes},
  Review                   = {Complex voice activity detector could be turned into Bayesian Net
* adaptive noise threshold in Voice Activity Detector (VAD)
* refers to GSM VAD but not demonstrated that this is better}
}

@InProceedings{theis02bss2stepFormal,
  Title                    = {Formalization of the two-step approach to overcomplete {BSS}},
  Author                   = { F.J.Theis and E.W.Lang},
  Booktitle                = {SIP'02},
  Year                     = {2002},

  Comment                  = {ReadNo},
  Review                   = {on the way to mono ICA?},
  Url                      = {http://citeseer.nj.nec.com/update/510580}
}

@InProceedings{theis02icaGeoOverComp,
  Title                    = {Geometric Overcomplete {ICA}},
  Author                   = {F.J.Theis, E.W.Lang},
  Booktitle                = {European Symposium on Artificial Neural Networks},
  Year                     = {2002},

  Comment                  = {ReadNo},
  Review                   = {On the way to mono ICA? },
  Url                      = {http://citeseer.nj.nec.com/theis02geometric.html}
}

@Article{fang95quadDet,
  Title                    = {Quadratic detectors for energy estimation},
  Author                   = {J. Fang and L. E. Atlas},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {1995},
  Pages                    = {2582-2594},
  Volume                   = {43},

  Comment                  = {235: ReadYes},
  Review                   = {Detector output is energy in some bandwidth 
* seems to have better compromise between time and freq resolution than weiner 
* speaker ID performance improved but recog alg. isn't clear 
* could these detectors imitate MFCC filter banks for spkr ID? 
* could use w/ HRTF for localization}
}

@Misc{fasulo-an,
  Title                    = {An Analysis of Recent Work on Clustering Algorithms},

  Author                   = {D. Fasulo},

  Comment                  = {26.0: ReadNo},
  Url                      = {citeseer.nj.nec.com/fasulo99analysi.html}
}

@Article{featherstone99aoa,
  Title                    = {Mobile transmitter {AOA} estimation under multipath conditions using an {MLE} based superresolution algorithms and comparison wiht weighed spectrum methods},
  Author                   = {W. Featherstone and H. J. Strangeways},
  Journal                  = {{IEEE} ?},
  Year                     = {1999},

  Comment                  = {248: ReadNo},
  Review                   = {Relevant??}
}

@InProceedings{fernandez98multiPitch,
  Title                    = {Multi-pitch estimation for polyphonic musical signals},
  Author                   = {Fernandez-Cid, P. and Casajus-Quiros, F.J},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1998},
  Pages                    = {3565-3568},
  Volume                   = {6},

  Comment                  = {321: ReadYes},
  Review                   = {Very heuristic note harmonic grouper. Somewhat tracks three flutes.
* 4 band dyadic filter bank analysis
* generates peak list w/ "quality of fit" heuristics
- isolated peak
- adjacent peak
* peak list completion
- temporal consistency
- freq consistency for lower scales
* Ellis-like pitch track spawning and killing 
* many more heuristics before summing filterbank peaks
* then more heuristics on the sum
* more than one pitch => high freq filterband beats are garbage!
- (yet everyone I've read is using them)},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/iel4/5518/14898/00679645.pdf?tp=&arnumber=679645&isnumber=14898}
}

@TechReport{Ferrer02ProsodicFeaturesExtraction,
  Title                    = {Prosodic Features Extraction},
  Author                   = {Luciana Ferrer},
  Institution              = {Speech TEchnology and Research Lab, SRI Intl.},
  Year                     = {2002},

  File                     = {Ferrer02ProsodicFeaturesExtraction.pdf:Ferrer02ProsodicFeaturesExtraction.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Describes Dustin's prosodic "acoustic" features. 
* pitch and energy statistics and trajectories
* times, and durations
* some phone specific, some word specific, some turn specific
* Dustin reimplemented some of this stuff in C++.},
  Timestamp                = {2006.05.20}
}

@Article{fine01GMM_SVM_spkrID,
  Title                    = {A Hybrid {BMM}/{SVM} Approach To Speaker Identification},
  Author                   = {S. Fine and J. Navratil and R. A. Gopinath},
  Journal                  = {ASSP},
  Year                     = {2001},
  Pages                    = {417-420},
  Volume                   = {1},

  Comment                  = {5.0: ReadYes},
  Review                   = {SVM postprocessing of N-best GMM spkr ID improves performance
* Fisher Kernel SVM's used on 30 mixture GMM's
* all-pairs SVM's trained roughly (75-80% of optimum) so training fast
* sigmoid pdf trained for each SVM (normalizes before multiclass
-- decision)
* multiclass decision done by adding each SVM's vote
* computational saving: run SVM's only on top N of N best list from
--- a traditional GMM spkrID system (the hybrid part)
* 25% relative error reduction over GMM only
* features: 19ceps+dels(38 mfcc input vec), 30 mixture GMM}
}

@InProceedings{Fiscus2007nistEval,
  Title                    = {The Rich Transcription 2007 Meeting Recognition Evaluation},
  Author                   = {Jonathan G. Fiscus and Jerome Ajot and John S. Garofolo},
  Booktitle                = {NIST Meeting Workshop},
  Year                     = {2007},

  File                     = {Fiscus2007nistEval.pdf:Fiscus2007nistEval.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Results for 2007 NIST eval. ICSI/SRI wins again.},
  Timestamp                = {2008.01.07}
}

@TechReport{Fiscus05RichTrans05,
  Title                    = {The {Rich Transcription} 2005 Spring Meeting Recognition Evaluation},
  Author                   = {Jonathan G. Fiscus and Nicolas Radde and John S. Garofolo and Audrey Le1, Jerome Ajot and Christophe Laprun},
  Institution              = {National Institute of Standards and Technology},
  Year                     = {2005},

  File                     = {Fiscus05RichTrans05.pdf:Fiscus05RichTrans05.pdf:PDF},
  Owner                    = {scotto},
  Publisher                = {National Institute of Standards and Technology},
  Review                   = {Summary of results for NIST RT05},
  Timestamp                = {2007.06.01},
  Url                      = {http://www.nist.gov/speech/publications/index.htm}
}

@Misc{footeXXmusicAnal,
  Title                    = {Methods for automatic analysis of music and audio},

  Author                   = {J. Foote},

  Comment                  = {10.5: ReadNo}
}

@InProceedings{forster94arrayShapeLoc,
  Title                    = {Passive array shape calibration with wide band sources of unknown location},
  Author                   = {Phillippe Forster and Francis Martinerie},
  Booktitle                = {Proc. OCEANS 94. Oceans Engineering for Today's Technology and Tomorrow's Preservation. },
  Year                     = {1994},
  Pages                    = {235-240},
  Volume                   = {1},

  Comment                  = {599:ReadNo},
  Review                   = {Localization w/ somewhat unknown array. Other papers like this too. I've printed but not entered some of them},
  Url                      = {http://ieeexplore.ieee.org/iel2/2951/8342/00363933.pdf?tp=&arnumber=363933&isnumber=8342}
}

@TechReport{fraley98how,
  Title                    = {How many clusters? Which clustering method? Answers via model-based cluster analysis },
  Author                   = {C. Fraley and A. Raftery},
  Institution              = {Department of Statistics, University of Washington, Seattle, WA},
  Year                     = {1998},

  Comment                  = {198: ReadYes},
  Review                   = {Overview of agglomerative clustering w/ EM refine. S/W available.
* GMM clusters
* This software available on web (for s-plus)
Uses agglomerative clustering w/ EM tuning
-- better than nearest neighbor or K-nearest neighbor
-- k-means is a subset of this type of classifier
-- not shown how much EM tweak improves over just agglom
-- EM has conditioning probs for small clusters
-- weakness: assumes linear subspace. Could improve by:
-- - mix of mix to solve
-- - manifold clustering (p. 14, esp. [62])
* nice that EM outputs a cluster ID uncertainty for combine w/ location?
BIC for # of clusters
-- picks local maxima
-- best Cov matrix shape: run each shape and pick max BIC
-- BIC approxs 'Bayes Factor' - can compute exactly when BIC fails [9]
-- must toss out large BIC values due to ill-conditioning (small data)
Noise handling
* NNclean denoising preprocessing -- probably made EM easier
* can add noise class (p. 8). Use for room noise?}
}

@InProceedings{Fredouille07overlapInfluence,
  author    = {Corinne Fredouille and Nicholas Evans},
  title     = {The influence of speech activity detection and overlap on speaker diarization for meeting room recordings},
  booktitle = {Interspeech},
  year      = {2007},
  groups    = {ovdetasru07},
  owner     = {scotto},
  review    = {Overlaps diazization and CONFIDENCES!

NIST RT'05 and NIST RT'06 data sets. Results indicate that our system is highly sensitive to the shape of the initial segmentation and that, perhaps surprisingly, perfect references can even degrade performance. Finally we propose a direction for future research to incorporate confidence values according to acoustic attributes in order to unify what is currently a somewhat disjointed approach to speaker diarization.},
  timestamp = {2007.07.16},
  url       = {http://www.interspeech2007.org/Technical/detail.php?ses=FrC.P3},
}

@InProceedings{fredouille04mtngRecogRT04s,
  Title                    = {The {NIST} 2004 spring rich transcription evaluation: two-axis merging strategy in the context of multiple distant microphone based meeting speaker segmentation},
  Author                   = {Corinne Fredouille and Daniel Moraru and Sylvain Meignier and Laurent Besacier and Jean-Francois Bonaste},
  Booktitle                = {{NIST} Meeting Recognition Workshop},
  Year                     = {2004},

  Comment                  = {ReadNo},
  File                     = {fredouille04mtngRecogRT04s.pdf:fredouille04mtngRecogRT04s.pdf:PDF},
  Review                   = {ELISA NIST meeting speaker seg/clust

multi-mic: seems to be per-channel ASR w/ merging. Two kinds of with some CLIPS stuff. No beamforming? Didn't read carefully},
  Url                      = {http://www-clips.imag.fr/geod/User/laurent.besacier/Publis/RT04.pdf}
}

@Misc{friedmanXXbayesstructEM,
  Title                    = {The {Bayesian} structural {EM} algorithm},

  Author                   = {N. Friedman},

  Comment                  = {24.0: ReadNo}
}

@Misc{friedmanXXbayesnetstruct,
  Title                    = {Being {Bayesian} about network structure},

  Author                   = {N. Friedman and D. Koller},

  Comment                  = {24.5: ReadNo}
}

@Article{frost72linConstrAdaptArr,
  Title                    = {An algorithm for linearly constrained adaptive array processing},
  Author                   = {Frost, O.L., III},
  Journal                  = {Proc., IEEE},
  Year                     = {1972},
  Number                   = {8},
  Pages                    = {926-935},
  Volume                   = {60},

  File                     = {frost72linConstrAdaptArr.pdf:frost72linConstrAdaptArr.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {One way to solve adaptive min/max eigenvalue problem, as in Benesty00adaptEigSrcLoc (but I think they use an unconstrained method from 1982)},
  Timestamp                = {2007.08.08},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=1450747&isnumber=31159&punumber=5&k2dockey=1450747@ieeejrns&query=%28an+algorithm+for+linearly+constrained+adaptive%3Cin%3Emetadata%29&pos=0}
}

@Article{Fujikoshi79dimensionCCA,
  Title                    = {Estimation of Dimensionality in Canonical Correlation Analysis},
  Author                   = {Y. Fujikoshi and L. G. Veitch},
  Journal                  = {Biometrika},
  Year                     = {1979},
  Number                   = {2},
  Pages                    = {345-351},
  Volume                   = {66},

  Comment                  = {627:ReadSorta},
  File                     = {Fujikoshi79dimensionCCA.pdf:Fujikoshi79dimensionCCA.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {A couple simple ways to estimate Canonical Correlation Analysis Dimension (Assuming Normal distribution)},
  Timestamp                = {2007.04.11},
  Url                      = {http://links.jstor.org/sici?sici=0006-3444%28197908%2966%3A2%3C345%3AEODICC%3E2.0.CO%3B2-J}
}

@Article{gadde02spineASR,
  Title                    = {Building an {ASR} System for Noisy Environments: {SRI's} 2001 {SPINE} Evaluation System},
  Author                   = {Venkata Ramana Rao Gadde and Andreas Stolcke and Dimitra Vergyri and Jing Zheng and Kemal Sonmez and Anand Venkataraman},
  Journal                  = {Proc. ICSLP},
  Year                     = {2002},

  Comment                  = {455: ReadYes},
  File                     = {gadde02spineASR.pdf:gadde02spineASR.pdf:PDF},
  Review                   = {SRI's spine seg: preproc w/ spch/sil HMM, recog & low post prob word remove
Only read the segmentation part:
1.) spch/sil HMM
2.) recog
3.) est. posteriors in confusion matrix
4.) reseg., removing low posterior regions
On SPINE, recog was nearly as good as that from human transcriber segmentations.},
  Url                      = {http://www-speech.sri.com/people/rao/papers/spine-2001-system-icslp2002-v8.pdf}
}

@InProceedings{gales92hmmDecomp,
  Title                    = {An improved approach to the hidden {Markov} model cecomposition of speech and noise},
  Author                   = {M. J. F. Gales and S. Young},
  Booktitle                = {{IEEE} ?},
  Year                     = {1992},
  Pages                    = {233-236},
  Volume                   = {1},

  Comment                  = {270: ReadYes},
  Review                   = {Use noise model to modify model params for MFCC coeffs 
* uses same global cov. matrix for all models (helps w/ lombard effect)

* lombard effect is change in speech due to stress? 
* nice analytical expressions for noise effect on MFCCs! 
* supposed to be better than other techniques for non-stationary noise}
}

@InProceedings{ganapathiraju97echoCanc,
  Title                    = {{ECHO} {CANCELLATION} {FOR} {EVALUATING} {SPEAKER} {IDENTIFICATION} {TECHNOLOGY}},
  Author                   = {Aravind Ganapathiraju and Joseph Picone},
  Booktitle                = {Proc. {IEEE} Southeastcon},
  Year                     = {1997},
  Pages                    = {100-102},

  Comment                  = {454: ReadYes},
  File                     = {ganapathiraju97echoCanc.pdf:ganapathiraju97echoCanc.pdf:PDF},
  Review                   = {MS state echo canceller used on EARS switchboard. LMS FIR w/ heuristics

* I think this was used for EARS but I haven't confirmed that yet!

* LMS estimate of FIR given near echo & "known" reference far speech
- figure has 256 tap FIR (too short for swbdI but implies is adjusted)
* run reference speech through FIR and cancel by subtr.from near speech


Heuristics:
1.) VAD detects near talker speech: don't adapt FIR during this time
- will fail for high echo levels (I saw almsot 0dB SNR in swbdI)
- also, the usual VAD problems
2.) VAD hang time of 75ms after 1st spch det (as is common)
3.) attenuate cancelled sig when poor supression
- looks at power ratio between reference (far) and cancelled signal
- do nothing if: > -24dB (speaker overlap) or < -60dB (near silence)
- otherwise: attenuate cancelled output (equation not clear at all)
- EARS workshop: atten caused probs w/ VAD cross-chan xcorr & noise est
- WARNING! says echo is nonlinear: will be bad for ICA!
4.) adapt slowly if long delay (delay is user input)
5.) rapidly adapt over 1st few seconds of call (assumes stationarity)
- exponentially reduce adaptation rate afterwards
- I did NOT see stationarity of channel in swbdI




Note: I've also stapled to the paper few supporting slides from:
http://www.isip.msstate.edu/projects/speech/software/legacy/fir_echo_canceller/doc/overview.pdf},
  Url                      = {http://www.isip.msstate.edu/publications/conferences/ieee_secon/1997/echo_cancellation/paper_v1.pdf}
}

@Article{Gannot06spkrLocSpatioTemp,
  Title                    = {Microphone Array Speaker Localizers Using Spatial-Temporal Information},
  Author                   = {Gannot, Sharon and Dvorkind, Tsvi Gregory},
  Journal                  = {EURASIP Journal on Applied Signal Processing},
  Year                     = {2006},
  Note                     = {doi:10.1155/ASP/2006/59625},
  Pages                    = {Article ID 59625, 17 pages},
  Volume                   = {2006},

  File                     = {Gannot06spkrLocSpatioTemp.pdf:Gannot06spkrLocSpatioTemp.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Get locs, given TDOA estimates and known sensor positions, smooths over time. Can't use but a couple good refs.},
  Timestamp                = {2007.08.08},
  Url                      = {http://www.hindawi.com/GetArticle.aspx?doi=10.1155/ASP/2006/59625}
}

@InProceedings{garcia99musicSep,
  Title                    = {Separation of Musical Instruments based on Perceptual and Statistical Principles},
  Author                   = {Garcia and Casajus-Quiros},
  Booktitle                = {Digital Audio Effects, Workshop on},
  Year                     = {1999},

  Comment                  = {404: ReadYes},
  Review                   = {Discusses feasibility of auditory v.s. ICA music separation
* good, short review of ICA, up to JADE
* some review of auditory, perhaps good if want to get references
* no experiements or conclusion as to which is better},
  Url                      = {http://www.tele.ntnu.no/akustikk/meetings/DAFx99/garcia.pdf}
}

@Misc{garg00vadDBN,
  Title                    = {Audio-visual speaker detection using {Dynamic} {Bayesian} Nets},

  Author                   = {A. Garg and V. Pavlovic and J. M. Rehg},
  Year                     = {2000},

  Comment                  = {56.5: ReadYes},
  Review                   = {Audio/Video fusion VAD, DBN's temporal model improves w/ dur model.
* fuse mouth movement info w/ audio info for voice activity detection
* audio input features not described. In refs somewhere??
* Bayesisan Net (BN): expert relation between audio and video, works
* DBN: add temporal behavior, is 80% accurate (15% better than BN)
-- implied exponential duration modelling doesn't match
* DDDBN: add duration density modelling, improves to 83%
-- but is compuatationally expensive}
}

@TechReport{garofol93timitCorpus,
  Title                    = {{DARPA TIMIT} acoustic-phonetic continuous speech corpus {CD-ROM}.},
  Author                   = {J. Garofolo and L. Lamel and W. Fisher and J. Fiscus and D. Pallett and N. Dahlgren},
  Institution              = {National Institute of Standards and Technology},
  Year                     = {1993},
  Number                   = {{NISTIR} 4930},

  Comment                  = {ReadNo},
  Review                   = {The reference people seem to use when citing the TIMIT corpus }
}

@InProceedings{garofolo04mtngRecRT04s,
  Title                    = {The Rich Transcription 2004 Spring Meeting Recognition Evaluation},
  Author                   = {John S. Garofolo and Christophe D. Laprun and Jonathan G. Fiscus},
  Booktitle                = {{NIST} Meeting Recognition Workshop},
  Year                     = {2004},

  Comment                  = {ReadYes},
  Institution              = {National Institute of Standards and Technology},
  Review                   = {RT04s meeting eval results
* overlap hurts multiple distant mic diarization
- Best Diarization Error Rate (DER): 
-- 22.8% (non-overlap), 
-- 39.5% (overlapped) 
-- LIA-CLIPS0 constrast system
* about the same damage for single distant mic
* overlap is common
- 78% of word tokens occurred in overlapping spkr turns
- probably means within "silence bounded regions" (below)
* overlap decreases multi-mic WER by 11%
- 56% (overlap), 45% (non-overlap), CMU/KU system
- overlap: >1 spkr within "silence bounded region" (fig 24)
* individual headmic
- no overlap numbers given
- but did mention that some systems had problems with crosstalk-induced insertion errors.}
}

@InProceedings{gauvain92mapHMM,
  Title                    = {{MAP} estimation for continuous density {HMM}: theory and applications},
  Author                   = {J. Gauvain and C. Lee},
  Booktitle                = {Proc. {DARPA} speech and nat. lang.},
  Year                     = {1992},

  Comment                  = {92: ReadNo},
  Review                   = {MAP adaptation (param prior) on HMM's}
}

@TechReport{gelbart01reverbCMS,
  Title                    = {Evaluating Long-Term spectral subtraction for reverberant {ASR}},
  Author                   = {D. Gelbart and N. Morgan},
  Institution              = {Internation computer Siences Institute},
  Year                     = {2001},

  Comment                  = {Print, ReadNo},
  Review                   = {Actually, I think I've read this but just haven't filed it... Best cepstral mean subtraction analysis window & mean est window for ASR
- says that usual 20-30ms anal. window doesn't work for reverb
- FFT synthesis/analysis with CMS inbetween. 
- synthesis fed to ASR to check WER
- CMS doesn't work as well for real data as for synthesized reverb (noise)
- Used meeting room data
- Best FFT analysis window length (for computing one spectral est): 1-2s
- Best window over which to compute mean log spectrum: 12.3s}
}

@TechReport{genoud99spchSpkrRecog,
  Title                    = {Simultaneous speech and speaker recognition using hybrid architecture},
  Author                   = {D. Genoud and D. P. W. Ellis and N. Morgan},
  Institution              = {ICSI},
  Year                     = {1999},
  Number                   = {TR-99-012},

  Comment                  = {115: ReadNo},
  Review                   = {But seems to be partly about adaptation.
* speaker recog w/ no errors takes 8 seconds}
}

@Article{Gentile07sensorLocTriang,
  Title                    = {Distributed Sensor Location through Linear Programming with Triangle Inequality Constraints},
  Author                   = {Gentile, C.},
  Journal                  = {Wireless Communications, IEEE Transactions on},
  Year                     = {2007},
  Number                   = {7},
  Pages                    = {2572-2581},
  Volume                   = {6},

  File                     = {Gentile07sensorLocTriang.pdf:Gentile07sensorLocTriang.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Fast way to locate sensors if they can transmit pings to each other. Mine can't.},
  Timestamp                = {2007.08.08},
  Url                      = {http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=4274982&arnumber=4275010}
}

@Misc{geweke97conjprior,
  Title                    = {Applied econometrics {II} Lecture Notes. Conjugate Prior Distributions},

  Author                   = {J. Geweke},
  Year                     = {1997},

  Comment                  = {78: ReadNo},
  Review                   = {I think Laplace conjugate prior has something to do with BIC and number of speakers, clusters}
}

@Misc{ghahramaniXXskfVar,
  Title                    = {Variational learning for switching state-space models},

  Author                   = {Z. Ghahramani and G. E. Hinton},

  Comment                  = {43.5: ReadNo},
  Review                   = {Relevant to speaker motion tracking or reverb switching when head turns? is a switching state kalman filter? pitch tracking w/ multi-speakers?}
}

@InProceedings{Ghani02combiningMultiClass,
  Title                    = {Combining Labeled and Unlabeled Data for MultiClass Text Categorization},
  Author                   = {Rayid Ghani},
  Booktitle                = {ICML '02: Proc., Nineteenth Intl. Conf. on Machine Learning},
  Year                     = {2002},
  Pages                    = {187--194},
  Publisher                = {Morgan Kaufmann Publishers Inc.},

  File                     = {Ghani02combiningMultiClass.pdf:Ghani02combiningMultiClass.pdf:PDF},
  ISBN                     = {1-55860-873-7},
  Url                      = {http://portal.acm.org/citation.cfm?coll=GUIDE&dl=GUIDE&id=656160#}
}

@Book{Gibbons85nonParamStatInf,
  Title                    = {Nonparametric Statistical Inference},
  Author                   = {Gibbons, J. D.},
  Publisher                = {M. Dekker},
  Year                     = {1985},

  Owner                    = {scotto},
  Review                   = {Reference [1] for singrank() function in Matlab Statistics Toolbox},
  Timestamp                = {2008.04.30}
}

@InProceedings{gillespie01dereverb,
  Title                    = {Speech Dereverberation Via Maximum-Kurtosis Subband Adaptive Filtering},
  Author                   = {B. W. Gillespie and H. S. Malvar and D. A. F. Flor?ncio},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {3701-3704},
  Volume                   = {6},

  Comment                  = {118: ReadNo},
  File                     = {gillespie01dereverb.pdf:gillespie01dereverb.pdf:PDF},
  Review                   = {Brad's work.},
  Url                      = {http://research.microsoft.com/~malvar/papers/icassp01makurt.pdf}
}

@Article{giridhar00bss2ndCyclo,
  Title                    = {Improved system blind identification based on second-order cyclostationary statistics: A group delay approach},
  Author                   = {P V S GIRIDHAR and S V NARASIMHAN},
  Journal                  = {Sadhana},
  Year                     = {2000},
  Number                   = {2},
  Pages                    = {85-96},
  Volume                   = {25},

  Comment                  = {ReadNo},
  File                     = {giridhar00bss2ndCyclo.pdf:giridhar00bss2ndCyclo.pdf:PDF},
  Review                   = {ARMA bss w/ cyclostationarity -- good for overlap det. of pitched, voiced signals?},
  Url                      = {http://www.ias.ac.in/sadhana/Pdf2000Apr/Pe895.pdf}
}

@InProceedings{gish91segregation,
  Title                    = {Segregation of Speakers for Speech Recognition and Speaker Identification},
  Author                   = {H. Gish and M. Siu and R. Rohlicek},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1991},
  Pages                    = {873-876},

  Comment                  = {123: ReadNo},
  Review                   = {St GLR clustering distance paper?}
}

@Article{godara97doa,
  Title                    = {Application of antenna arrays to mobile communications, part {II}: beam-forming and direction-of-arrival considerations},
  Author                   = {L. C. Godara},
  Journal                  = {Proc. IEEE},
  Year                     = {1997},
  Number                   = {8},
  Pages                    = {1195-1245},
  Volume                   = {85},

  Comment                  = {75: ReadYes},
  Review                   = {Overview of array beamforming for direction of arrival (doa)
* AIC,, ESPRIT, least squre, MUSIC, MVDR
* and a bunch of other terms and variables defined. 
* only skimmed, haven't read carefully}
}

@InProceedings{godfrey92switchboard,
  Title                    = {{SWITCHBOARD}: Telephone speech corpus for research and development},
  Author                   = {J. Godfrey and E. Holliman and J. McDaniel},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1992},
  Pages                    = {517-520},

  Comment                  = {Print, ReadNo}
}

@InProceedings{golowich98svmHmm,
  Title                    = {A Support Vector/Hidden Markov Model Approach to Phoneme Recognition},
  Author                   = {S. E. Golowich and Don X. Sun},
  Booktitle                = {ASA Proc., Statistical Computing Section},
  Year                     = {1998},
  Pages                    = {125-130},

  Comment                  = {5.5: ReadYes},
  Review                   = {SVM is approx to pdf spline fit, can replace GMM in an HMM
* shows that SVM is approx to sline fit of pdf (many simplifications)
* so, for each all-against-one SVM, can back out a probability (which requires normalizations)
* 2nd order polynomical kernel SVM
* can use this prob to train/eval an HMM 
* SVM/HMM gets 54.9% acc on TIMIT phone recog, GMM/HMM gets 53.8%
* hybrid: SVM 1st, if not confident then HMM: gets 59%
* says hybrid works because SVM errors different than HMM errors
* says SVMs better than GMM's when would need a lot of GMM mixtures}
}

@InProceedings{grodriguez00reverbMicArr,
  Title                    = {Speech dereverberation and noise reduction with a combined microphone array approach},
  Author                   = {J. Gonzalez-Rodreguiz and J. L. Sanchez-Bote and J. Ortega-Garcia},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},
  Pages                    = {1037-1040},

  Comment                  = {276: ReadNo},
  Review                   = {But: combines DOA, dereverb and noise filtering}
}

@Article{gopalan99besselSpkrID,
  Title                    = {A comparision of speaker identification results using features based on cepstrum and Fourier-Bessel expansion},
  Author                   = {K. Gopalan and T. R. Anderson and E. J. Cupples},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {1999},
  Number                   = {3},
  Pages                    = {289-294},
  Volume                   = {7},

  Comment                  = {251: ReadNo},
  Review                   = {Bessel functions work as well as MFCC's for spkr ID. Is there anything about assuming a Bessel function that makes mic array processing easier -- like methods assuming Proney decaying exponentials?}
}

@Misc{gopinath00gaussSlide,
  Title                    = {Gaussianization },

  Author                   = {Ramesh A. Gopinath},
  HowPublished             = {Workshop Slides: IMA Workshop: Mathematical Foundations of Speech Processing and Recognition, University of Minn.},
  Year                     = {2000},

  Comment                  = {292.5: ReadNo},
  File                     = {gopinath00gaussSlide.ps:gopinath00gaussSlide.ps:PDF},
  Review                   = {Easy to read presentation slides on Gaussianization and dimension reduction. Probably worth reading before the other papers. },
  Url                      = {http://www.research.ibm.com/people/r/rameshg/ima-workshop-2000.ps}
}

@InProceedings{greenberg99modspect,
  Title                    = {The modulation spectrogram: in pursuit of an invariant representation of speech},
  Author                   = {S. Greenberg and B. E. D. Kingsbury},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1997},

  Comment                  = {10.0: ReadNo}
}

@InProceedings{Griebel01MicArrSrcLocRealDelVec,
  Title                    = {Microphone array source localization using realizable delay vectors},
  Author                   = {Griebel, S.M. and Brandstein, M.S.},
  Booktitle                = {Applications of Signal Processing to Audio and Acoustics, 2001 IEEE Workshop on the},
  Year                     = {2001},
  Pages                    = {71--74},

  Doi                      = {10.1109/ASPAA.2001.969545},
  File                     = {Griebel01MicArrSrcLocRealDelVec.pdf:Griebel01MicArrSrcLocRealDelVec.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Consistency method of combining pairwise localization correlations. Scans sum of pairwise only at predetermined, physically realizable locations.

* need to know the locations beforehand
* possibly could use this as a delay refinement after clustering has determined the set of locations, but I doubt it

Algorithm:

Setup before localizing:

foreach (pre-determined speaker position), loc
 foreach pair
 Rxy(loc,pair)=collect correlation waveform
 end
end

During localizaing:

foreach loc
 foreach pair
 RxySum(loc) += measuredRxy(pair,loc) ^ alpha
 end
end

loc = armgax RxySum()},
  Timestamp                = {2007.08.10},
  Url                      = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=969545&isnumber=20913&punumber=7653&k2dockey=969545@ieeecnfs&query=%28%28microphone+array+source%0D%0Alocalization+using+realizable+delay+vectors%29%3Cin%3Emetadata%29&pos=0}
}

@InProceedings{griebel99wavelet,
  Title                    = {Wavelet transform extrema clustering for multi-channel speech dereverberation},
  Author                   = {S. Griebel and M. Brandstein},
  Booktitle                = {IEEE Workshop on Acoustic Echo and Noise Control, Pocono Manor, Pennsylvania},
  Year                     = {1999},
  Pages                    = {52-55},

  Comment                  = {181: ReadYes},
  Review                   = {Speech enhancer like Brandenstein's 'An event based...' but w/ wavelets
* assumes speaker location is known
* pitch detection and voiced/unvoiced not done here
* wavelets and nonlin coherence envelope replaces them
* works better than beamforming
* supposed to be better than 'An event based ...'
Algorithm
* get LPC residual individually on each mic
* wavelet xform for each residual (quadratic spline wavelet)
* for each channel and wavelet level
-- make pitch pulses @ peaks in each wavelet level
-- lowpass each level across time w/ gaussian lpf
* average across channels
* reconstruct residual
* run residuals through LPC filter to get resynth spch},
  Url                      = {citeseer.nj.nec.com/griebel99wavelet.html}
}

@Article{gustafsson03localRevebModel,
  Title                    = {Source Localization in Reverberant Environments: Modeling and Statistical Analysis},
  Author                   = {Tony Gustafsson},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2003},
  Number                   = {6},
  Pages                    = {707-803},
  Volume                   = {11},

  Comment                  = {ReadNo},
  File                     = {gustafsson03localRevebModel.pdf:gustafsson03localRevebModel.pdf:PDF},
  Review                   = {Says GCC-PHAT is best, fancy statistical models},
  Url                      = {http://cvrr.ucsd.edu/publications/2003/IEEETransSAP2003Nov_Gustafsson.pdf}
}

@Misc{gutmannXXlocalization,
  Title                    = {An experimental comparison of localization methods},

  Author                   = {J. Gutmann and W. Burgard and D. Fox and K. Konolige},

  Comment                  = {37.0: ReadNo},
  Review                   = {Relevant to speaker location features?}
}

@InProceedings{hermansky97should,
  Title                    = {Should recognizers have ears?},
  Author                   = {Hermansky H.},
  Booktitle                = {Proc., ESCA Workshop on Robust Speech Recognition for Unknown Communication Channels},
  Year                     = {1997},
  Pages                    = {1-10},
  Publisher                = {ESCA},

  Comment                  = {170.5: ReadYes},
  Review                   = {Perceptually motivated features e.g. RASTA better than straight MFCC's
* should included about 200ms in analysis window, not 20ms
* cepstral coeffs are BPF'ed to get better results (Rasta)
* Formants seem to be too detailed 
* use lower res features (in freq) over longer time spans
* LDA and other discrim techniques help
* advocates copying human perception and then machine tweaked}
}

@Article{deHaan03micArraySubBandDesign,
  Title                    = {Filter bank design for subband adaptive microphone arrays},
  Author                   = {de Haan, J.M. and Grbic, N. and Claesson, I. and Nordholm, S.E.},
  Journal                  = {Trans., Speech and Audio Proc.},
  Year                     = {Jan 2003},
  Number                   = {1},
  Pages                    = { 14-23},
  Volume                   = {11},

  Doi                      = {10.1109/TSA.2002.807353},
  File                     = {deHaan03micArraySubBandDesign.pdf:deHaan03micArraySubBandDesign.pdf:PDF},
  ISSN                     = {1063-6676 },
  Keywords                 = { acoustic transducer arrays, adaptive filters, array signal processing, channel bank filters, delays, digital filters, discrete Fourier transforms, land mobile radio, microphones, network synthesis, radiotelephony, signal reconstruction, signal sampling aliasing components magnitude reduction, aliasing distortion minimization, array applications, beamformer, car hands-free mobile telephony, disturbing signals suppression, filter bank design, oversampled uniform DFT-filter banks, perfect reconstruction filter banks, signal degradation, signal delays, signals phase information, source positions, subband adaptive beamforming, subband adaptive microphone arrays, subband decomposition, subband reconstruction, uniform DFT-filter bank},
  Owner                    = {scotto},
  Review                   = {Has a way of undoing subband aliasing but requires calibration signal (and known mic locs?)
- has LS squared beamforming in the middle (refs [26], [27]) which needs a calibration signal ([26], I couldn't find [27]) 
- needs known mic locs too?
- referenced in kumatani07mutInfBmFrm but says there that approch won't work if jigger amplitude of indiv. bands, like in that paper.},
  Timestamp                = {2008.01.31},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1179374}
}

@TechReport{haas05ekosManufacXducer,
  Title                    = {{USC} Catheter Design Validation},
  Author                   = {Ron Haas},
  Institution              = {EKOS Corp.},
  Year                     = {2005},
  Number                   = {TR-620A},
  Type                     = {Technical Report},

  Review                   = {Shows that EKOS resistance and RDB vary widely during manufacture but are stable afterwards}
}

@InProceedings{Hain06AMIMeetingTranscription,
  Title                    = {The {AMI} Meeting Transcription System: Progress and Performance.},
  Author                   = {Thomas Hain and Lukas Burget and John Dines and Giulia Garau and Martin Karafi{\'a}t and Mike Lincoln and Jithendra Vepa and Vincent Wan},
  Booktitle                = {MLMI},
  Year                     = {2006},
  Pages                    = {419-431},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Ee                       = {http://dx.doi.org/10.1007/11965152_37},
  File                     = {Hain06AMIMeetingTranscription.pdf:Hain06AMIMeetingTranscription.pdf:PDF},
  Owner                    = {scotto},
  Timestamp                = {2007.03.26},
  Url                      = {http://www.springerlink.com/content/e281574257021g66/}
}

@InProceedings{hain05meetingTrans,
  Title                    = {The Development of the {AMI} System for the Transcription of Speech in Meetings},
  Author                   = {Thomas Hain and Lukas Burget and John Dines and Iain McCowan and Martin Karafiat and Mike Lincoln and Darren Moore and Giulia Garau and Vincent Wan and Roeland Ordelman and Steve Renals},
  Booktitle                = {MLMI},
  Year                     = {2005},
  Pages                    = {T-B-2},

  Comment                  = {611: ReadYes},
  File                     = {hain05meetingTrans.pdf:hain05meetingTrans.pdf:PDF},
  Review                   = {Superdirective delay-sum beamform on meeting speech, also headmic crosstalk VAD

Single Mic VAD+crosstalk detecton
* HMM based
* 0.5s min speech seg
* feats: PLP+vel+dvel+ddvel, energy, kurtosis, voicing
* HLD dim reduction
* classifier: MLP neural net 101 frames input, 20 hidden layers
Delay/sum:
* gain normalization
* noise estimation (also get noise cov matrix, although I'm not sure they use it)
-- estimates noise as N=20 lowest powers over time in each FFT bin (voiced speech harmonic triick, I suppose)
* Weiner filtering noise reduction
* cross correlation
* energy ratios with REFERENCE channel (not pairs)
* superdirective beamformer, may use estimated xcorr},
  Url                      = {http://groups.inf.ed.ac.uk/mlmi05/techprog/arch/T-B-2.pdf}
}

@InProceedings{hain98segment,
  Title                    = {Segment Generation and Clustering in the {HTK} Broadcast News Transcription System},
  Author                   = {T. Hain and S. Johnson and A. Tuerk and P. Woodland and S. Young},
  Booktitle                = {{DARPA} Broadcast News Transcription and Understanding Workshop},
  Year                     = {1998},
  Pages                    = {133-137},

  Comment                  = {150: ReadYes},
  Review                   = {Broadcast News style clusterer/adaptor, uses KLdist(?) + heuristics
* see Figure 1 for best alg explantion
Segmentation: on categories boundaries, 
-- type classifier -> by Male/Female ID -> contig seg merge heuristics
-- Audio type classifier:
--- says that 12 MFCC's, norm log E, 1st and 2nd order diff of these
----- is more efficient than PLP's
--- uses 1024 mixture GMM!
--- categories: music, music_spch, wide/narrowband spck
-- No spkr ID in segmentation step
-- segments are limited to 0.5-30s
-- 12 MFCC coeff features
-- M/F classifier: use sex of ML recognized phone
-- 42 rules for segmentation/segment smoothing: loops until no change
Clustering (2 kinds tried):
-- 1. top-down splitting arithmetic harmonic sphericity distance
-- 2. bottom-up merging w/ 'divergence-like' dist (K-L dist?)
-- used single gaussian model w/ diag cov
-- 1. and 2. worked about the same in terms of MLLR adapatation
-- chose bottom-up to test on 96 Broadcast News data
Results: 2-4% increase in log likelihood after MLLR}
}

@Misc{hall97introduction,
  Title                    = {An Introduction to Multisensor Data Fusion},

  Author                   = {D. Hall and J. Llinas},
  Year                     = {1997},

  Comment                  = {121: ReadNo},
  Text                     = {D. L. Hall and J. Llinas, An Introduction to Multisensor Data Fusion, Proc. from the IEEE, Volume 85, Number 1, January 1997.}
}

@InProceedings{han07diarizStopInfoChange,
  Title                    = {A robust stopping
criterion for agglomerative hierarchical clustering in
a speaker diarization system},
  Author                   = {K. J. Han and S. S. Narayanan},
  Booktitle                = {Interspeech},
  Year                     = {2007},

  File                     = {han07diarizStopInfoChange.pdf:han07diarizStopInfoChange.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Information change rate (ICR) replaces BIC for diarization stopping criteria

(use to guess @ derr v.s PCA dim?)},
  Timestamp                = {2008.01.31}
}

@InProceedings{han07diarizMergeLenGLR,
  Title                    = {Robust speaker clustering strategies to data source variation for improved speaker diarization},
  Author                   = {Han, Kyu J. Kim, Samuel and Shrikanth S. Narayanan},
  Booktitle                = {ASRU},
  Year                     = {2007},
  Pages                    = {262-267},

  File                     = {han07diarizMergeLenGLR.pdf:han07diarizMergeLenGLR.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Improves diarization merging decision by considering segment length when doing GLR

Things tried
- tries to merge long w/ short
- delays merging short segments until later
- merges in order of longest to shortest at each iteration

not sure which is best b/c methods got different perf on different data bases},
  Timestamp                = {2008.01.31}
}

@InProceedings{hansen98spchQual,
  Title                    = {An effective quality evaluation protocol for speech enhancement algorithms},
  Author                   = {John H. L. Hansen and Bryan Pellom},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1998},
  Pages                    = {2819-2822},
  Volume                   = {7},

  Comment                  = {344: ReadYes},
  Review                   = {How to measure quality of speech enhancement e.g. speech separation
* skimmed it. There are a lot of measures
* has code available, mostly matlab (I think I downloaded it to home PC)}
}

@InBook{hansen00icaMultiMedia,
  Title                    = {Multimedia Image and VideoProcessing},
  Author                   = {L. Hansen and J. Larsen and T. Kolenda},
  Chapter                  = {On Independent Component Analysis for Multimedia Signals},
  Publisher                = {CRC Press},
  Year                     = {2000},

  Comment                  = {ReadNo},
  Review                   = {the non-iterative ICA algorithm used in Hansen paper to detect IC comps},
  Url                      = {citeseer.nj.nec.com/hansen00independent.html}
}

@InProceedings{hansen01icaNum,
  Title                    = {Blind detection of independent dynamic components},
  Author                   = {Lars Kai Hansen and Jan Larsen and Thomas Kolenda},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {3197-3200},
  Volume                   = {5},

  Comment                  = {452: ReadNo},
  File                     = {hansen01icaNum.pdf:hansen01icaNum.pdf:PDF},
  Review                   = {My Overlap Idea! Number of Speakers == Number of ICA components
matlab: http://mole.imm.dtu.dk/toolbox/ica/MS/icaMS.tar.gz},
  Url                      = {http://eivind.imm.dtu.dk/publications/2001/hansen.icassp2001.pdf}
}

@Misc{hansenXXmdl,
  author  = {M. H. Hansen and B. Yu},
  title   = {Model selection and the principle of minimum descripton length},
  comment = {69: ReadNo},
  review  = {Theory behind MDL, which is equiv to BIC? and related to AIC. for picking number of speakers and other model selections 

Updated reference to this article is in energy.bib, Hansen01mdlSelMDL},
}

@TechReport{hanson67bayesClass,
  Title                    = {{Bayesian} classification theory},
  Author                   = {R. Hanson and J. Stutz and P. Cheeseman},
  Institution              = {Artificial intelligence research branch, {NASA} {Aimes} research},
  Year                     = {1990},
  Number                   = {{FIA}-90-12-7-01},

  Comment                  = {67: ReadNo},
  Review                   = {Theory behind cheeseman/stutz clustering alg. in autoclassIII. talks about BIC?}
}

@TechReport{hardoon03kcca,
  Title                    = {Canonical correlation analysis; An overview with application to learning methods},
  Author                   = {David R. Hardoon and Sandor Szedmak and John Shawe-Taylor},
  Institution              = {Royal Holloway, University of London},
  Year                     = {2003},
  Number                   = {CSD-TR-03-02},

  File                     = {hardoon03kcca.pdf:hardoon03kcca.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Kernel CCA with Cholesky and partial Grahm-Schmidt dimension reduction, simple regulation. Has matlab.
* goes part of the way to reducing computation of KCCA
* but still starts with nptsXnpts kernel matrices to start with (work in greedy PCA kernel approx approach?)
* also see paper: Hardoon04ccaLearn},
  Timestamp                = {2007.09.27},
  Url                      = {http://homepage.mac.com/davidrh/_html/code.html}
}

@Article{Hardoon04ccaLearn,
  Title                    = {Canonical Correlation Analysis: An Overview with Application to Learning Methods},
  Author                   = {David R. Hardoon and Sandor R. Szedmak and John R. Shawe-taylor},
  Journal                  = {Neural Computation},
  Year                     = {2004},
  Number                   = {12},
  Pages                    = {2639--2664},
  Volume                   = {16},

  Comment                  = {629:ReadSorta},
  Doi                      = {http://dx.doi.org/10.1162/0899766042321814},
  File                     = {Hardoon04ccaLearn.pdf:Hardoon04ccaLearn.pdf:PDF},
  ISSN                     = {0899-7667},
  Owner                    = {scotto},
  Publisher                = {MIT Press},
  Review                   = {Kernel CCA
* Pretty decent tutorial
* text description <--> image matching application
* seems to be better than GSVM
* I'm using his recommended Cholesky decomp for robustness (there are others, though, like Weenink, which may be more efficient, but which I don't understand them)
* explains incomplete Cholesky decomposition and relation to partial Graham Schmidt orthogonalization, says PGSO better since don't need to store a permuation matrix.
* perhaps more detail (and matlab) associated w/ tech note (hardoon03kcca)},
  Timestamp                = {2007.04.15},
  Url                      = {http://portal.acm.org/citation.cfm?id=1119696.1119703#}
}

@InProceedings{harris02spchEdistSFM,
  Title                    = {Energy redistribution speech intelligibility enhancement, vocalic and transitional cues},
  Author                   = {John G. Harris and Mark D. Skowronski},
  Booktitle                = {Acoustical Society of America First Pan-American/Iberian Meeting on Acoustics},
  Year                     = {2002},

  Comment                  = {ReadYes},
  File                     = {harris02spchEdistSFM.pdf:harris02spchEdistSFM.pdf:PDF},
  Review                   = {Uses Yantorno's spectral flatness measure (SFM)},
  Url                      = {http://www.cnel.ufl.edu/~markskow/papers/3aSC12.pdf}
}

@Article{hartmann99localize,
  Title                    = {How we localize sound},
  Author                   = {M. Hartmann},
  Journal                  = {Physics Today on the web},
  Year                     = {1999},

  Comment                  = {213: ReadYes},
  Review                   = {Excellent paper on how humans localize sound, HRTF 
* ILD could be used for Les's correlator (good time resp. @ low freqs)

* ear shuts off phase in reverb and uses only ILD 
* remark: brandenstein is using phase only -- bad in reverb rooms; ! Lot's of speech loc algs use phase only 
* ITD corr. s/b on freq band outputs, not a full correlation
(b/c estimating a phase, which is meaningful for sinusoid? 
why did I say this?) 
* Haas effect: heavy weight on localization ques of 1st echo 
* => brain does x-time comparison of indivdually locale 2ndary reflections

* modulation envelope detector for ITD of high freqs (another feature)

* human ILD sensitive at all freqs but cues exist only in 500-20KHz
(reliable @ > 3KHz) 
* ~2KHz localization doesn't work well 
* ITD (phase based) < 1500Hz (unless modulated @ rate<1KHz, then up to 4KHz) 
* high freqs best for ILD in reverb b/c reflection coeff drops w/ freq
(above 8KHz in high reverb)},
  Url                      = {http://www.aip.org/pt/nov99/locsound.html}
}

@Article{hastie96discriminant,
  Title                    = {Discriminant analysis by {Gaussian} mixtures},
  Author                   = {T. Hastie and R. Tibshirani},
  Journal                  = {Journal of the Royal Statistical Society series B},
  Year                     = {1996},
  Pages                    = {158-176},
  Volume                   = {58},

  Comment                  = {Print, ReadNo},
  Review                   = {LDA extended to mixture models},
  Url                      = {citeseer.nj.nec.com/article/hastie96discriminant.html}
}

@InProceedings{hateren98icfImage,
  Title                    = {Independent component filters of natural images compared with simple cells in primary visual cortex.},
  Author                   = {van Hateren, J..H. and van der Schaaf, A.},
  Booktitle                = {Proc. R. Soc. Lond.},
  Year                     = {1998},
  Pages                    = {359-366},
  Volume                   = {B 265},

  Comment                  = {ReadNo},
  File                     = {hateren98icfImage.pdf:hateren98icfImage.pdf:PDF},
  Url                      = {http://hlab.phys.rug.nl/papers/videow.pdf}
}

@Article{hazen00adapt,
  Title                    = {A comparison of novel techniques for rapid speaker adaptation},
  Author                   = {T. J. Hazen},
  Journal                  = {Speech Communication},
  Year                     = {2000},
  Number                   = {1},
  Pages                    = {15-33},
  Volume                   = {31},

  Comment                  = {179: ReadYes},
  Review                   = {Fast adaptation technique using reference speakers
* recognition models built by gender and 3 speaking rates
* BMM-like observation correlation at pon elevel (consistency meas.)
-- boils down to mutual info so does cross segment dependence
* close reference spkrs get more weight tha tfar wonds
* phones unobserved during adaptation updates w/ sort-of interpolation}
}

@InProceedings{he03locPresProjs,
  Title                    = { Locality Preserving Projections},
  Author                   = { Xiaofei He and Partha Niyogi},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2003},
  Volume                   = {12},

  File                     = {he03locPresProjs.pdf:he03locPresProjs.pdf:PDF},
  Url                      = {http://people.cs.uchicago.edu/~xiaofei/papers.html}
}

@TechReport{heckerman95bnlearnTut,
  Title                    = {A tutorial on learning with Bayesian networks},
  Author                   = {D. Heckerman},
  Institution              = {Microsoft Research},
  Year                     = {1995},
  Number                   = {MSR-TR-95-06},

  Comment                  = {18: ReadNo},
  Review                   = {describes Laplace approximation and BIC}
}

@InProceedings{heracleous03hmmSemiBSS,
  Title                    = {A SEMI-BLIND SOURCE SEPARATION METHOD FOR HANDS-FREE SPEECH RECOGNITION OF MULTIPLE TALKERS},
  Author                   = {Panikos Heracleous and Satoshi Nakamura and Kiyohiro Shikano},
  Booktitle                = {Eurospeech},
  Year                     = {2003},
  Pages                    = {509-512},

  Comment                  = {560: ReadNo},
  Review                   = {combined HMM spch recog w/ blind beamforming, like ICA}
}

@InProceedings{heracleous01arr3d,
  Title                    = {A microphone array-based {3D} N-best search algorithm for the simultaneous recognition of multiple sound sources in real environments},
  Author                   = {P. Heracleous and S. Nakamura and K. Shikano},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},

  Comment                  = {187.0: ReadYes},
  Review                   = {BF focussed in many directions; 3D Viterbi sorts each dir's stream
* 3D viterbi search gets stream of features from each direction
Basic 3D viterbi (one source only)
* search for ML path through all direction-feature sequences
Baseline 3D N-best search (multiple sources, w/ # sources pre-defined)
* pick N-best direction-feature sequences
* path dist affects probability (w/ signal power confidence weighting)
* single state, 64 mixture GMM somehow normalizes trajectory probs
* some kind of direction-clustering at the end lumps spkr streams together}
}

@InProceedings{heracleous99arr3d,
  Title                    = { Simultaneous Recognition of Multiple Sound Sources Based on 3-D N-Best Search Using Microphone Array},
  Author                   = {P. Heracleous and T. Yamada and S. Nakamura and K. Shikano},
  Booktitle                = {Eurospeech},
  Year                     = {1999},
  Pages                    = {69-72},
  Volume                   = {1},

  Comment                  = {187.5: ReadYes},
  Review                   = {BF focusses in many dirs, 3D viterbi sorts dir signals into N-best paths
* Earlier version of heracleous01arr3d
* not a great paper}
}

@Misc{hermanskyXXtemporal,
  Title                    = {Exploring temporal domain for robustness in speech recognition},

  Author                   = {H. Hermansky},

  Comment                  = {58: ReadNo},
  Review                   = {RASTA, deltas, dynamic cepstrum, etc. relvant to spkrID features?}
}

@Misc{hermansky98specBasisDiscrim,
  Title                    = {Spectral basis functions from discriminant analysis},

  Author                   = {H. Hermansky and N. Malayath},
  Year                     = {1998},

  Comment                  = {59: ReadNo},
  Review                   = {KL transform and LDA for spectral basis design. human like auditory spectrum. relvant to spkrID features?}
}

@Misc{hermansky92rastaplp,
  Title                    = {{Rasta-PLP}a speech analysis technique},

  Author                   = {H. Hermansky and N. Morgan and A. Bayya and P. Kohn},
  Year                     = {1992},

  Comment                  = {134: ReadNo},
  Text                     = {H. Hermansky, N. Morgan, A. Bayya, and P. Kohn, Rastaplp speech analysis technique, in Proc. ICASSP 1992 San Fransisco, 1992, vol. 1, pp. 121--124.}
}

@InProceedings{hermansksy99asrTRAPS,
  Title                    = {Temporal pattersn ({TRAPS}) in {ASR} of noisy speech},
  Author                   = {H. Hermansky and S. Sharma},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999},

  Comment                  = {9.0: ReadNo}
}

@Misc{hermansksyXXnonlinHMMfeatmap,
  Title                    = {Data-derived nonlinear mapping for feature extraction in {HMM}},

  Author                   = {H. Hermansky and S. Sharma and P. Jain},

  Comment                  = {9.5: ReadNo}
}

@Article{hero85genCrossCorr,
  Title                    = {A new generalized cross correlator},
  Author                   = {A. Hero and S. Schwartz},
  Journal                  = {{IEEE} trans. on acoustics, speech and signal proc.},
  Year                     = {1985},
  Number                   = {1},
  Pages                    = {38-45},
  Volume                   = {33},

  Comment                  = {585: ReadNo},
  Review                   = {One of the fundamental refs for GCC time delay est
The other is Knapp and Carter, 1976, but I couldn't find that electronically.},
  Url                      = {http://ieeexplore.ieee.org/iel6/29/26189/01164515.pdf?tp=&arnumber=1164515&isnumber=26189}
}

@InProceedings{herre96tnsAudioCode,
  Title                    = {Enhancing the Performance of Perceptual Audio Coders by Using Temporal Noise Shaping ({TNS})},
  Author                   = {Jurgen Herre and Jamdes D. Hohnston},
  Booktitle                = {Audio Engineering Society},
  Year                     = {1996},

  Comment                  = {314:ReadYes},
  Review                   = {Filterbank Hilbert Envelopes are the same shape across frequency
* purpose was to explain why filterbank predictors could work
* see fig 9. for castanet envelopes for filterbanks at 1KHz width
* this is probably neater than would be the case w/ speech
* maybe relevant to pitch and overlap detection},
  Url                      = {http://www.ee.columbia.edu/~marios/courses/e6820y02/project/papers/Enhancing%20the%20Performance%20of%20Perceptual%20Audio%20Coders%20by%20Using%20Temporal%20Noise%20Shaping%20(TNS).pdf}
}

@InProceedings{hershey02audVidHMMSep,
  Title                    = {Audio-Visual Sound Separation Via Hidden Markov Models},
  Author                   = {J. Hershey and M. Casey},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2002},
  Editor                   = {T. G. Dietterich and S. Becker and Z. Ghahramani},
  Publisher                = {MIT Press},
  Volume                   = {14},

  Comment                  = {432: ReadNo},
  File                     = {hershey02audVidHMMSep.ps.gz:hershey02audVidHMMSep.ps.gz:PDF},
  Original                 = {orig/SP09.ps},
  Review                   = {mono spkr separation, using factorial hmms (audio/video), referenced by reyes-gomez, ray and ellis},
  Url                      = {http://www-2.cs.cmu.edu/Groups/NIPS/NIPS2001/papers/psgz/SP09.ps.gz}
}

@InProceedings{Hertz06LearningKernelFunction,
  author    = {Tomer Hertz and Aharon Bar Hillel and Daphna Weinshall},
  title     = {Learning a Kernel Function for Classification with Small Training Samples},
  booktitle = {ICML},
  year      = {2006},
  file      = {Hertz06LearningKernelFunction.pdf:Hertz06LearningKernelFunction.pdf:PDF},
  groups    = {semisupWorkshop07},
  owner     = {scotto},
  review    = {Kernel learning paper for 2007 Summer Blind/Deaf workshop},
  timestamp = {2007.06.20},
  url       = {http://www.icml2006.org/icml2006/technical/accepted.html},
}

@TechReport{Hespanha04graphPart,
  Title                    = {An Efficient {Matlab} Algorithm for Graph Partitioning},
  Author                   = {Joao P. Hespanha},
  Institution              = {University of California, Santa Barbara},
  Year                     = {2004},

  File                     = {Hespanha04graphPart.pdf:Hespanha04graphPart.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Spectral partitioning alg. used for ICASSP08 paper (folding or split CCA)
matlab: http://www.ece.ucsb.edu/~hespanha/published/grPartition.m},
  Timestamp                = {2007.10.05},
  Url                      = {http://www.ece.ucsb.edu/~hespanha/techrep.html}
}

@InProceedings{hioka02arrayVAD,
  Title                    = {Voice Activity Detection with Array Signal Processing in the Wavelet Domain},
  Author                   = {Yusuke Hioka and Nozomu Hamada},
  Booktitle                = {{EUSIPCO}: European Signal Processing Conf.},
  Year                     = {2002},

  Comment                  = {586: ReadYes},
  Review                   = {{Wavelet/eigen space VAD, known spkrloc/#spkrs, close mics. Good ideas.

Ideas maybe usable for meeting location clustering
* linear low freq / octave high freq filterbank 
- mel is like this but linear until 1KHz, log afterwards
- I should think about linear/log breakpoint for myself
* # harmonics rationale for picking fixed # of low freq eigen decomps
- no good for spkr overlaps but maybe this is a pre-loc clust step?
* directional signal det (entropy of eigvals)
* DOA projection used for VAD (instead of DOA, use loc clust dirs?)
* separate voiced and unvoiced det (very good idea, I think)

Wavelet/filterbank decomp (good explanation):
* Low freqs (<2KHz)
- detect voiced speech
- linearly spaced bands spaced < minF0 so no beats
- select 5 most powerful (max # single spkr harmonics <2KHz}, pdf = {hioka02arrayVAD.pdf}, f0 = {400Hz)^^ - eigen decompose xcorr matrix ^^ - (# sources) strongest eigenvalues are "signal space"^^ - "directional speech" if low entroy eigvals^^ - confusing DOA logic for voiced-speech/non-speech decision^^ -- an unadapted threshold in there^^ -- adapt do PCA of delay profiles after meeting loc feat clust?^^* High freqs(>2KHz)^^ - unvoiced speech det^^ - don't seem to have detected envelopes^^ - confusing dot product unvoiced-speech/non-speech decisions^^* Mel-spacing: linear up to 1KHz, logarithmic above (why different?)^^^^Performance^^* works on toy problem, even in interference^^^^Requirements that aren't realistic for Meetings^^* assumes spkr is known to be @ angle zero^^* mics must be close enough to do phase based eigenstuff (2cm, here)^^* known number of possible sources^^* delay and sum beamformer already focussed on speaker^^* speaker overlaps not handled e.g. only 5 band in low freqs even though^^ can have more than that many pitches if have > 1 talker^^* DOA information is available (but use result of loc clust for this?)^^^^}},
  Url                      = {http://www.hamada.sd.keio.ac.jp/PDF/IC/2002/EUSIPCO2002_hioka.pdf}
}

@InProceedings{hochreiter01monoICAreg,
  Title                    = {Monaural separation and classification of mixed signals: a support-vector regression perspective},
  Author                   = {Sepp Hochreiter and Michael C. Mozer},
  Booktitle                = {Independent Component Analysis And Blind Signal Separation, Intl. Conf. on},
  Year                     = {2001 },

  Comment                  = {342: ReadYes},
  Review                   = {ICA is bent to be and SVM regression problem. Not clear it works
* idea is to correctly classify mixed signals
* ICA similar to epsilon-SVR support vector regression
* has sparse coding idea
* not clear if it worked or not
* really hard to read},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/131-hochreiter.pdf}
}

@Article{holland77IRLS_GLM,
  Title                    = {Robust regression using iteratively reweighted least squares},
  Author                   = {P. W. Holland and R. F. Welsch},
  Journal                  = {Comm. Statist. Theor. Methods},
  Year                     = {1977},
  Pages                    = {813-827},
  Volume                   = {A6},

  Comment                  = {Print, ReadNo},
  Review                   = {The algorithm used in BNT netlib to train the GLM softmax function
NOT READ or PRINTED.}
}

@Book{Hollander73nonParamStatMeth,
  Title                    = {Nonparametric Statistical Methods},
  Author                   = {Hollander, M. and D. A. Wolfe},
  Publisher                = {Wiley},
  Year                     = {1973},

  Owner                    = {scotto},
  Review                   = {Reference [2] for singrank() function in Matlab Statistics Toolbox},
  Timestamp                = {2008.04.30}
}

@InProceedings{hopgood99monoSep,
  Title                    = {Single channel signal separation using linear time-varying filters: Separability of non-stationary stochastic signals},
  Author                   = {J. R. Hopgood and P. J. W. Rayner},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999},
  Pages                    = {1449-1452},
  Volume                   = {3},

  Comment                  = {ReadNo},
  Review                   = {NOTE: he has some new relevant 2002 papers pending but not yet available at:
http://www-sigproc.eng.cam.ac.uk/~jrh1008/Research/Publications/Welcome.html},
  Url                      = {http://www-sigproc.eng.cam.ac.uk/~jrh1008/Components/Download/Publications/ConferencePapers/ICASSP_1999.pdf}
}

@InProceedings{hornegger95statistical,
  Title                    = {Statistical Learning, Localization, and Identification of Objects},
  Author                   = {J. Hornegger and H. Niemann},
  Booktitle                = {ICCV95},
  Year                     = {1995},
  Pages                    = {914-919},

  Comment                  = {Print, ReadNo},
  Url                      = {citeseer.nj.nec.com/hornegger95statistical.html}
}

@Article{Howes99neuralInputInfluence,
  Title                    = {Using input parameter influences to support the decisions of feedforward neural networks},
  Author                   = {Howes, P. and Crook, N.},
  Journal                  = {Neurocomputing},
  Year                     = {1999},
  Pages                    = {191-206},
  Volume                   = {24},

  Owner                    = {scotto},
  Review                   = {the General influence measure (GIM) method of determining neural network input influence. This is a sum of weights.},
  Timestamp                = {2008.01.30}
}

@Article{Hoyer04NNMFsparseConstr,
  Title                    = {Non-negative Matrix Factorization with Sparseness Constraints},
  Author                   = {Patrik O. Hoyer},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2004},
  Pages                    = {1457--1469},
  Volume                   = {5},

  File                     = {Hoyer04NNMFsparseConstr.pdf:Hoyer04NNMFsparseConstr.pdf:PDF},
  ISSN                     = {1533-7928},
  Owner                    = {scotto},
  Publisher                = {MIT Press},
  Review                   = {Covers matlab Non-negative matrix factorization functions in nmfpack
 nmfdiv.m - performs standard NMF with divergence objective
 nmfmse.m - performs standard NMF with euclidean objective
 nmfsc.m - performs NMF with sparseness constraints
 lnmf.m - performs Local NMF
 snmf.m - performs Sparse NMF},
  Timestamp                = {2007.03.03},
  Url                      = {http://portal.acm.org/citation.cfm?id=1044709}
}

@InProceedings{wu99genGauss,
  Title                    = {{GENERALIZED} {ANTI}-{HEBBIAN} {LEARNING} {FOR} {SOURCE} {SEPARATION}},
  Author                   = {Hsiao-ChunWu and Jose C. Principe},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999},

  Comment                  = {ReadNo},
  File                     = {wu99genGauss.pdf:wu99genGauss.pdf:PDF},
  Url                      = {http://www.cnel.ufl.edu/bib/pdf_papers/icassp99_p.pdf}
}

@Article{Hsieh00ccaNeuralNet,
  Title                    = {Nonlinear canonical correlation analysis by neural networks},
  Author                   = {W. W. Hsieh},
  Journal                  = {Neural Networks},
  Year                     = {2000},
  Number                   = {10},
  Pages                    = {1095-1105},
  Volume                   = {13},

  File                     = {Hsieh00ccaNeuralNet.pdf:Hsieh00ccaNeuralNet.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Most cited article for nonlinear canonical correlation analysis with neural net},
  Timestamp                = {2007.04.11},
  Url                      = {http://www.sciencedirect.com/science?_ob=PublicationURL&_cdi=4856&_pubType=J&_auth=y&_acct=C000029718&_version=1&_urlVersion=0&_userid=582538&md5=d47c2c205385412c53e44e643ffce7fd&jchunk=13#13}
}

@Misc{marktlaw02rmAcoust,
  Title                    = {Acoustics Crash Course 1 - Room Mode Acoustics Crash Course 1 - Room Modes Acoustics Crash Course 1 - Room Modes Acoustics Crash Course 1 - Room Modes},

  Author                   = {http://www.marktaw.com},
  HowPublished             = {web page},
  Year                     = {2002},

  Abstract                 = {really basic room acoustics w/ room mode calculator v.s. size, eigentones},
  Comment                  = {PrintNo},
  Url                      = {http://www.kuro5hin.org/story/2002/6/9/15027/40923}
}

@Article{hu04monoSegPitchAM,
  Title                    = {Monaural speech segregation based on pitch tracking and amplitude modulation},
  Author                   = {Guoning Hu and DeLiang Wang},
  Journal                  = {Neural Networks, IEEE Transactions on},
  Year                     = {2004},
  Number                   = {5},
  Pages                    = {1135-1150},
  Volume                   = {15},

  Comment                  = {ReadNo},
  Review                   = {Follow-on to Hu's 2002 paper:
* which -- finally -- has an explanation of what "resolved harmonic" means: lowest F0 fits within a filterbank bandwidth: as you get higher in a log space bank, you're not resolved anymore.
* uses hair cell "phase locking" might be useful?
* simple analytical equation for gammatone filtering.
* uses a dominant pitch (from summary autocorr) to segregate.},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=1333078&isnumber=29433&punumber=72&k2dockey=1333078@ieeejrns&query=%28%28monaural+speech+segregation+based+on+pitch+tracking+and+amplitude+modulation%29%3Cin%3Emetadata%29&pos=0}
}

@Article{hu02monoSegAM,
  Title                    = {On amplitude modulation for monaural speech segregation},
  Author                   = {Guoning Hu and DeLiang Wang},
  Journal                  = {International Joint Conference on Neural Networks (IJCNN)},
  Year                     = {2002},
  Pages                    = {69-74},
  Volume                   = {1},

  Comment                  = {ReadNo},
  Url                      = {http://ieeexplore.ieee.org/iel5/7877/21695/01005444.pdf?isNumber=21695&prod=CNF&arnumber=1005444&arSt=69&ared=74+vol.1&arAuthor=Guoning+Hu%3B+Deliang+Wang}
}

@Article{hu02monoSegPitchAM,
  Title                    = {Monaural speech segregation based on pitch tracking and amplitude modulation},
  Author                   = {Guoning Hu and DeLiang Wang},
  Journal                  = {Proc. ICASSP},
  Year                     = {2002},
  Pages                    = {553-556},
  Volume                   = {1},

  Comment                  = {340: ReadYes},
  Review                   = {Heuristic auditory foreground/backgrnd pitch peak segregator w/ resynth
* Why Monaural sound segregation research is stagnant
- ICA/BSS requires >= 2 microphones
- auditory fails because don't handle high freqs correctly [refs 4-7]
- this algorithm handles high freqs right (similarly to Wu&Wang 2002)
* Filterbank
- 128 gammotone filters
- hair cell simulation is a rectifier, I suppose
- LPF (1KHz cutoff) and window
- global pitch: from sum(Rxx) across freqs? (see ref [7] to be sure)
* Segregate using global pitch
- heuristics. Hard to understand... but it's temporal & Xchan corr.
- also some peak amplitude heuristics
* label time/freq cells according to which pitch the belong to
* resynthesize
* bogus test
- compare w/ data synthesized time/freq cells which are dominated by either one or the other pitch (as is assumed by this model)
- justified: human masking performance
- justified: similar binary mask system improved speech recog
* says that main improvement is from high freqs but I don't see the evidence for that.
* sys that Auditory Stream Analysis helps w/ monaural segregation.
* note: D. Wang has another paper (Wu & Wang 2002) w/ multi-pitch that compares pitch perf w/ competitors. I wonder how this one did?},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=1005799&isnumber=21701&punumber=7874&k2dockey=1005799@ieeecnfs&query=%28%28monaural+speech+segregation+based+on+pitch+tracking+and+amplitude+modulation%29%3Cin%3Emetadata%29&pos=1}
}

@Article{huang01spkrVarPCA_ICA,
  Title                    = {Analysis of Speaker Variability},
  Author                   = {C. Huang and T. Chen and S. Li and E. Chang and J. Zhou},
  Journal                  = {Eurospeech},
  Year                     = {2001},

  Comment                  = {137: ReadYes},
  Review                   = {ICA helps speaker gender/accent speaker ID
* features are MLLR matricies for 6 phones (I think)
* PCA reduces the 156-D feature to 6-D
* run ICA on PCA output
* can find two ICA components (by hand) that discrim. gender/accent
* ICA'ed features w/ orthog line thresholds separate better than w/ PCA but there's no description of in what dimension.
* Not a great paper. Not clear what they did.}
}

@Misc{huangXXspkradapt,
  Title                    = {A study of adaptation techniques on a voicemail transcription task},

  Author                   = {J. Huang and M. Padmanabhan},

  Comment                  = {19.0: ReadNo},
  Review                   = {Speaker adaptation on voicemail}
}

@Article{Huang03freqDomainBlindMultiChan,
  Title                    = {A class of frequency-domain adaptive approaches to blind multichannel identification},
  Author                   = {Yiteng Huang and Benesty, J.},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {2003},
  Number                   = {51},
  Pages                    = {11-24},
  Volume                   = {51},

  File                     = {Huang03freqDomainBlindMultiChan.pdf:Huang03freqDomainBlindMultiChan.pdf:PDF},
  Owner                    = {scotto},
  Timestamp                = {2007.08.10},
  Url                      = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=1145703&isnumber=25792&punumber=78&k2dockey=1145703@ieeejrns&query=%28%28class+of+frequency-domain%0D%0Aadaptive+approaches+to+blind+multichannel+identification%2C%94%29%3Cin%3Emetadata%29&pos=0}
}

@InProceedings{huang00endPointCar,
  Title                    = {A novel approach to robust speech endpoint detection in car environments},
  Author                   = {{Liang-Sheng} Huang and {Chung-Ho} Yang},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},
  Pages                    = {1751-1754},
  Volume                   = {3},

  Comment                  = {449: ReadYes},
  Review                   = {Spectral Entropy and Energy are complimentary; combination improves VAD
* Spectral entropy bad in babble noise and music (where energy works)
* Energy especially bad in nonstationary mechanical noise (e.g. car)
* bogus beginning of file noise level guess
* preprocessing:
- bandpassed to (250Hz,3750Hz)
- high power FFT bins zeroed (another paper does this too, I remember)
* product equation for combining energy and entropy
* heuristic state machine with unadapted thresholds does the VAD
* WER results: not as good has hand segments (91 v.s. 82%) but better than energy alone (72%)},
  Url                      = {http://ieeexplore.ieee.org/iel5/6939/18687/00862091.pdf?isNumber=18687&prod=IEEE+CNF&arnumber=862091&arSt=1751&ared=1754+vol.3&arAuthor=Liang-Sheng+Huang%3B+Chung-Ho+Yang%3B}
}

@InProceedings{hung00pcaSpkrSeg,
  Title                    = {Automatic Metric-based Speech Segmentation for Broadcast News via Principal Component Analysis----- Jeih-weih Hung, Hsin-min Wang and Lin-shan Lee},
  Author                   = {Jeih-weih Hung and Hsin-min Wang and Lin-shan Lee},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2000},

  Comment                  = {429: ReadNo},
  File                     = {hung00pcaSpkrSeg.pdf:hung00pcaSpkrSeg.pdf:PDF},
  Review                   = {Eigen is 2nd order stat. ICA is HOS and will be more sparse and better? And maybe could do overlap on? Anyway, use as example for ICA speaker ID features.},
  Url                      = {http://speech.ee.ntu.edu.tw/paper/ICSLP_2000.pdf}
}

@Article{hung00spchSegMetric,
  Title                    = {Automatic Metric-based Speech Segmentation for Broadcast News via Principal Component Analysis},
  Author                   = {Jeih-weih Hung and Hsin-min Wang and Lin-shan Lee},
  Journal                  = {Proc. ICSLP},
  Year                     = {2000},

  Comment                  = {429: ReadNo},
  File                     = {hung00spchSegMetric.pdf:hung00spchSegMetric.pdf:PDF},
  Url                      = {http://speech.ee.ntu.edu.tw/paper/ICSLP_2000.pdf}
}

@TechReport{hurd97cyclo,
  Title                    = {A brief introduction to periodically correlated (cyclostationary( random Sequences},
  Author                   = {Harry L. Hurd},
  Institution              = {University of North Carolina},
  Year                     = {1997},

  Comment                  = {ReadNo},
  File                     = {hurd97cyclo.ps:hurd97cyclo.ps:PDF},
  Review                   = {For pitch/overlap detection, for use in BSS/ICA that use cyclostationarity?},
  Url                      = {http://www.unc.edu/depts/statistics/faculty/hurd/papers/introw.ps}
}

@Misc{hyv99beyond,
  Title                    = {Beyond Independent Components},

  Author                   = {A. Hyv},
  Year                     = {1999},

  Comment                  = {ReadNo},
  Review                   = {metions sparse and subspace coding, topographic ica. Can subspace be like multi-D ICA?},
  Text                     = {A. Hyvarinen, Beyond Independent Components, Proc. Int. Conf on Articial Neural Networks, Edinburgh, UK, 1999, pp. 809-814.},
  Url                      = {citeseer.nj.nec.com/hyv99beyond.html}
}

@Article{hyvarinen01complexPurs,
  Title                    = {Complexity Pursuit: Separating interesting components from time-series},
  Author                   = {A. Hyv?rinen},
  Journal                  = {Neural Computation},
  Year                     = {2001},
  Number                   = {4},
  Pages                    = {883-898},
  Volume                   = {13},

  Comment                  = {ReadNo},
  File                     = {hyvarinen01complexPurs.ps.gz:hyvarinen01complexPurs.ps.gz:PDF},
  Review                   = {LP constraint for ICA speech? Mono? MDL (BIC) approach so useful for overlap (# talkers) or clustering?
* Introduces the concept of complexity pursuit, which means finding projections of time series (signals) that have minimum complexity. Also introduces simple approximations of complexity that take into account both nongaussianity and autocorrelations.},
  Url                      = {http://www.cis.hut.fi/aapo/ps/gz/NC01_CP.ps.gz}
}

@Article{hyvarinen99sparseShrink,
  Title                    = {Sparse Code Shrinkage: Denoising of Nongaussian Data by Maximum Likelihood Estimation},
  Author                   = {A. Hyv?rinen},
  Journal                  = {Neural Computation},
  Year                     = {1999},
  Number                   = {7},
  Pages                    = {1739-1768},
  Volume                   = {11},

  Comment                  = {ReadNo},
  File                     = {hyvarinen99sparseShrink.ps.gz:hyvarinen99sparseShrink.ps.gz:PDF},
  Review                   = {* sparse code score function which is more flexible than Laplacian
* part of sparse coding alg is an efficient approx to "noisy ICA"
* Describes sparse code shrinkage, which is a new method for denoising of images etc. It is a kind of a combination of independent component analysis and wavelet shrinkage ideas.] },
  Url                      = {http://www.cis.hut.fi/aapo/ps/gz/NC99_SCS_electr.ps.gz}
}

@InProceedings{hyvarinen98icaTimeDep,
  Title                    = {Independent Component Analysis for Time-dependent Stochastic Processes},
  Author                   = {A. Hyv?rinen},
  Booktitle                = {Artificial Neural Network, Intl. conf. on},
  Year                     = {1998},
  Pages                    = {541-546},

  Comment                  = {ReadNo},
  File                     = {hyvarinen98icaTimeDep.ps.gz:hyvarinen98icaTimeDep.ps.gz:PDF},
  Review                   = {LP constraint for ICA speech?
* This paper shows that in ICA, it is often useful to preprocess the data by computing the innovation processes.
* does this mean you should inverse filter speech before ICA?},
  Url                      = {http://www.cis.hut.fi/aapo/ps/gz/ICANN98_INNO.ps.gz}
}

@Article{hyvarinen01topoICA,
  Title                    = {Topographic Independent Component Analysis},
  Author                   = {A. Hyv?rinen and P.O. Hoyer},
  Journal                  = {Neural Computation},
  Year                     = {2001},
  Number                   = {7},
  Pages                    = {1705-1720},
  Volume                   = {12},

  Comment                  = {ReadNo},
  File                     = {hyvarinen01topoICA.pdf:hyvarinen01topoICA.pdf:PDF},
  Review                   = {ntroduces an extension of ICA. The dependencies of the estimated "independent" components are visualized as a topographic order. A new principle for
topographic organization, based on higher-order statistics. Applied on image data, both topography and complex cell properties emerge (see also above). This paper
is more concentrated on the mathematical formulation, and the preceding one on the biological application.},
  Url                      = {http://www.cis.hut.fi/aapo/ps/NC01_TICA.pdf}
}

@Article{hyvarinen00icasPhShift,
  Title                    = {Emergence of phase and shift invariant features by decomposition of natural images into independent feature subspaces},
  Author                   = {A. Hyv?rinen and P.O. Hoyer},
  Journal                  = {Neural Computation},
  Year                     = {2000},
  Number                   = {7},
  Pages                    = {1705-1720},
  Volume                   = {12},

  Comment                  = {ReadNo},
  File                     = {hyvarinen00icasPhShift.ps.gz:hyvarinen00icasPhShift.ps.gz:PDF},
  Review                   = {A simpler extension of ordinary ICA which was a precursor of topographic ICA. Here the goal of independence of scalar independent components is replaced by the
independence of the norms of projections on certain subspaces. This is applied on image data, and complex cell properties are shown to emerge. Covers multi-dim ICA},
  Url                      = {http://www.cis.hut.fi/aapo/ps/gz/NC00_complex.ps.gz}
}

@Book{hyvarinen01icaBook,
  Title                    = {Independent Component Analysis},
  Author                   = {Aapo Hyv?rinen and Juha Karhunen and Erkki Oja},
  Publisher                = {John Wiley \& Sons, Inc.},
  Year                     = {2001},

  Comment                  = {ReadYes},
  Review                   = {Good overall book. May be a bit biased towards fastICA but maybe he's right},
  Url                      = {http://www.cis.hut.fi/projects/ica/book/}
}

@Article{hyvarinen00icaAlgApp,
  Title                    = {Independent component analysis: algorithms and applications},
  Author                   = {A. Hyv?rinen and E. Oja},
  Journal                  = {Neural Networks},
  Year                     = {2000},
  Number                   = {4-5},
  Pages                    = {411-430 },
  Volume                   = {13},

  Comment                  = {351: ReadNo},
  Review                   = {Explains FastICA},
  Url                      = {http://www.sciencedirect.com/science?_ob=MImg&_imagekey=B6T08-43X2MFY-2-5T&_cdi=4856&_orig=browse&_coverDate=06%2F30%2F2000&_sk=999869995&wchp=dGLbVzz-lSzBS&_acct=C000029718&_version=1&_userid=582538&md5=f0c431b521d59d6bae0500296f7bc99e&ie=f.pdf}
}

@Article{hyvarinenXXfastICAML,
  Title                    = {The Fixed-Point Algorithm and Maximum Likelihood Estimation for Independent Component Analysis},
  Author                   = {A. Hyv?rinen.},
  Journal                  = {Neural Processing Letters},
  Year                     = {1997?},
  Number                   = {1},
  Pages                    = {1-5},
  Volume                   = {10},

  Comment                  = {ReadNo},
  File                     = {hyvarinenXXfastICAML.ps.gz:hyvarinenXXfastICAML.ps.gz:PDF},
  Review                   = {Shows how the FastICA algorithms can be interpreted as maximum likelihood estimation.},
  Url                      = {http://www.cis.hut.fi/aapo/ps/gz/NPL99.ps.gz}
}

@Article{hyvarinen99fastICA,
  Title                    = {Fast and Robust Fixed-Point Algorithms for Independent Component Analysi},
  Author                   = {A. Hyv?rinen.},
  Journal                  = {IEEE Transactions on Neural Networks},
  Year                     = {1999},
  Number                   = {3},
  Pages                    = {626-634},
  Volume                   = {10},

  Comment                  = {ReadNo},
  File                     = {hyvarinen99fastICA.ps.gz:hyvarinen99fastICA.ps.gz:PDF},
  Review                   = {The fundamental paper on the FastICA algorithm, which is a computationally very efficient method for performing ICA. This article is based on the TechRep "ICA
by Minimization of Mutual Information },
  Url                      = {http://www.cis.hut.fi/aapo/ps/gz/TNN99.ps.gz}
}

@Misc{hyvarinenXXsurveyICA,
  Title                    = {Survey on independent component analysis},

  Author                   = {A. Hyvarinen},

  Comment                  = {97: ReadNo},
  Review                   = {ICA survey paper. Looks pretty good.}
}

@Article{hyvarinen01bssVar,
  Title                    = {Blind source separation by nonstationarity of variance: a cumulant-based approach},
  Author                   = {Hyvarinen, A.},
  Journal                  = {Neural Networks, IEEE Transactions on},
  Year                     = {2001},
  Number                   = {6},
  Pages                    = {1471 -1474},
  Volume                   = {12},

  Comment                  = {ReadNo},
  Review                   = {useful for VAD or # of talkers? This is the way most people don't do ICA. Maybe add this as another constraint for monaural?
* Formulates the less-known separation criterion on variance nonstationarity using cumulants, and proposes a fast fixed-point algorithm.},
  Url                      = {http://ieeexplore.ieee.org/iel5/72/20805/00963782.pdf?isNumber=20805&prod=JNL&arnumber=963782&arSt=1471&ared=1474&arAuthor=Hyvarinen%2C+A.}
}

@Article{hyvarinen97diffEntApprox,
  Title                    = {New Approximations of Differential Entropy for Independent Component Analysis and Projection Pursui},
  Author                   = {A. Hyvarinen},
  Journal                  = {Advances in Neural Information Processing System},
  Year                     = {1998},
  Pages                    = {273-279},

  Comment                  = {374: ReadYes},
  File                     = {hyvarinen97diffEntApprox.ps.gz:hyvarinen97diffEntApprox.ps.gz:PDF},
  Review                   = {Why the fastICA contrast function
* kurotosis/cumulant estimators over sensitive to outliers (tails)
* instead, estimate the upper bound of entropy 
* minimize unmixed src entropy to separate signals
-- mutual info expressed in terms of unmixed output entropies
-- part depending unmixing matrix is sum of output entropies + const(M)
-- min mutual info by min max entrop => indep unmixed outputs
-- can minimized =individual= unmixed entropies 
-- note: Cardoso, "Three Easy..." says maybe you don't want to do that
* equiv to minimizing sum of a non-linear function of x
-- expected value of some func, Gi(x), is easy to estimate from data
-- use this as a constraint on minimization of entropy
-- (need a constraint so min problem is defined)
-- eqn. for max entropy across all dists given constraints
-- use requires sphered data and assumption of near-Guassiannes
-- Use Gram-Schmidt orthod but I kinda lost interest here
-- this imposes restrictions on the chosen function Gi(x)
* finally, an equation for his recommended contrast function
* one function measures asymmetry; the other, bimodality, sparsity

affiliated tech note has the long derivation: http://www.cis.hut.fi/~aapo/ps/gz/TR_A47_apprent.ps.gz},
  Url                      = {http://www.cis.hut.fi/~aapo/ps/gz/NIPS97.ps.gz}
}

@Misc{hyvarinenXXtutICA,
  Title                    = {Independent component analysis: A tutorial},

  Author                   = {A. Hyvarinen and E. Oja},

  Comment                  = {98: ReadNo},
  Review                   = {ICA tutorial. Specifically mentions two talker (multi-talker) separation.}
}

@TechReport{thyesXXeigenvoice,
  Title                    = {O. Thyes and R. Kuhn and P. Nguyen and J.-C. Junqua},
  Author                   = {SPEAKER IDENTIFICATION AND VERIFICATION USING EIGENVOICES},
  Institution              = {Panasonic Technologies Inc.,},
  Year                     = {2000?},

  Comment                  = {ReadNo},
  Review                   = {eigen are 2nd order stats; ICA is 3rd. Will ICA work better?
Actually, I'm not sure this was a technote},
  Url                      = {http://speech.ee.ntu.edu.tw/EigenVoices_SpkID%20Thyes%20in%20%20ICSLP00.pdf}
}

@InProceedings{hild01icaOnline,
  Title                    = {On-Line Minimum Mutual Information Method for Time-Varying Blind Source Separation},
  Author                   = {Kenneth E. Hild II and Deniz Erdogmus and Jose C. Principe},
  Booktitle                = {Independent Components Analysis and Signal Separation, Intl. Conf. on},
  Year                     = {2001},

  Comment                  = {ReadNo},
  Review                   = {compares favourably to FastICA in both data and computational efficiency},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/130-hild.pdf}
}

@InProceedings{ikeda98approach,
  Title                    = {An approach to blind source separation of speech signals},
  Author                   = {Shiro Ikeda and Noboru Murata},
  Booktitle                = {ICANN},
  Year                     = {1998},

  Comment                  = {332: ReadYes},
  Review                   = {Freq domain simultaneous diag uses 2nd order stats. Has Perm/scale fixes
* based on simultaneous freq domain diagonalization
* works in freq domain on individual FFT bin outputs
- resulting amplitude scaling solved by some kinda matrix inverse
- resulting permutation solved by ordering by max cross freq corr
- note: Anenmueller says it's better to put cross freq corr into optimization cost (better final answer)
* uses 2nd order stats only
* FFT window longer than room impulse response}
}

@InProceedings{ikeda01icaSlides,
  Title                    = {{ICA}: Blind Source Deconvolution for Speech Separation},
  Author                   = {Shiro Ikeda and Noboru Murata and Andreas Ziehe},
  Booktitle                = {Hearnet Conf. Slides},
  Year                     = {2001},

  Comment                  = {ReadNo},
  Review                   = {good ICA speech overview. He recommends these papers:
http://www.ircam.fr/pcm/cheveign/sh/hearnet/shiro

And he will also send Matlab code},
  Url                      = {http://www.mns.brain.riken.go.jp/~shiro/ikeda2001hearnet.pdf}
}

@Misc{ikram00bssReverb,
  Title                    = {Exploring permutation inconsistency in blind separation of speech signals in a reverberant environment},

  Author                   = {M. Z. Ikram and D. R. Morgan},

  Comment                  = {54: ReadNo},
  Review                   = {Speaker overlap resolution in reverb?},
  Url                      = {http://ieeexplore.ieee.org/search/searchresult.jsp?queryText=exploring+permutation+inconsistency+in+blind+separation+of+speech+signals+in+a+reverberant+environment%0D%0A&coll1=ieeejrns&coll2=ieejrns&coll3=ieeecnfs&coll4=ieecnfs&coll5=ieeestds&coll6=preprint&py1=1950&py2=2005&SortField=Score&SortOrder=desc&ResultCount=15}
}

@Article{llin04ndfaChangeDet,
  Title                    = {Nonlinear dynamical factor analysis for state change detection},
  Author                   = { Ilin, A. and Valpola, H. and Oja, E.},
  Journal                  = {Neural Networks, IEEE Transactions on},
  Year                     = {2004},
  Number                   = {3},
  Pages                    = {559- 575},
  Volume                   = {15},

  Comment                  = {ReadNo},
  Review                   = {EKOS change det?},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/iel5/72/28831/01296685.pdf?tp=&arnumber=1296685&isnumber=28831}
}

@Article{illingworth88houghTransSummary,
  Title                    = {A survey of the Hough transform},
  Author                   = {J. Illingworth and J. Kittler},
  Journal                  = {Comput. Vision Graph. Image Process.},
  Year                     = {1988},
  Number                   = {1},
  Pages                    = {87--116},
  Volume                   = {44},

  Address                  = {San Diego, CA, USA},
  Doi                      = {http://dx.doi.org/10.1016/S0734-189X(88)80033-1},
  ISSN                     = {0734-189X},
  Owner                    = {scotto},
  Publisher                = {Academic Press Professional, Inc.},
  Review                   = {Just a reference for Hough Transforms. Used in thesis.},
  Timestamp                = {2008.02.15}
}

@InProceedings{Ilonen06Gaussianmixturepdf,
  Title                    = {Gaussian mixture pdf in one-class classification: computing and utilizing confidence values},
  Author                   = {J. Ilonen and P. Paalanen and J.-K. Kamarainen and H. Kalviainen},
  Booktitle                = {International Conference on Pattern Recognition (ICPR)},
  Year                     = {2006},
  Pages                    = {577--580},
  Publisher                = {IEEE Computer Society},

  Doi                      = {http://dx.doi.org/10.1109/ICPR.2006.595},
  File                     = {Ilonen06Gaussianmixturepdf.pdf:Ilonen06Gaussianmixturepdf.pdf:PDF},
  ISBN                     = {0-7695-2521-0},
  Review                   = {Confidence (0..1) that sample is from pdf
* used for confidence in a multi-class decision when background model is too hard to compute
* (0..1) is easier to compare than posterior probs, which are arbitrarily scaled
* uses known gaussian mixture parameters
* confidence level z = contour of region containing 100*z% of pdf probability mass
* contours can't be calculated analytically so does by generating points and using a histogram
* confidence of point X is its rank in the pdf histogram divided by the number of generated points
* could also just use existing points
* application: facial feature recognititon: 
 -- individually recognize nostrils, etc. (get p(nostril) over space)
 -- best answer overall highest total prob over all face part pdf's (combinatorial search)
 -- used confidences to limit seach for each facial feature pdf, large reduction in search space},
  Url                      = {http://ieeexplore.ieee.org/search/wrapper.jsp?arnumber=1699271}
}

@InProceedings{Irino03spchSegVocoder,
  Title                    = {Speech segregation using event synchronous auditory vocoder},
  Author                   = {T. Irino and R. D. Patterson and H. Kawahara},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2003},
  Pages                    = {525-528},
  Volume                   = {5},

  Comment                  = {607:ReadNo},
  Review                   = {Related to YIN and Mellin },
  Url                      = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=1200022&isnumber=26996&punumber=8535&k2dockey=1200022@ieeecnfs&query=%28+kawahara%3Cin%3Eau+%29+%3Cand%3E+%28+patterson+%3Cin%3Eau+%29&pos=0&arSt=V&ared=525-8%20vol.5&arAuthor=Irino%2C+T.%3B+Patterson%2C+R.D.%3B+Kawahara%2C+H.%3B}
}

@InProceedings{isard96contour,
  Title                    = {Contour Tracking by Stochastic Propagation of Conditional Density},
  Author                   = {M. Isard and A. Blake},
  Booktitle                = {{ECCV} (1)},
  Year                     = {1996},
  Pages                    = {343-356},

  Comment                  = {Print, ReadNo},
  Url                      = {citeseer.nj.nec.com/isard96contour.html}
}

@InProceedings{iwano02houghF0,
  Title                    = {Noise robust speech recognition using {F0} contour extracted by {Hough} transform},
  Author                   = {Koji Iwano and Takahiro Seki and Sadaoki Furui},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {941-944},

  Comment                  = {435: ReadYes},
  File                     = {iwano02houghF0.pdf:iwano02houghF0.pdf:PDF},
  Review                   = {Hough transform enforces continuity in cepstral pitchdet; improves spch recog
* I used this as the basis for my overlap detector when I worked at FuruiLab in winter `03.},
  Url                      = {http://www.furui.cs.titech.ac.jp/publication/2002/icslp2002_941.pdf}
}

@InProceedings{lee00icaFeatures,
  Title                    = {Speech Feature Extraction Using Independent Component^^ Analysis},
  Author                   = {J-H. Lee, H-J. Jung, T-W. Lee and S-Y. Lee.},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},
  Pages                    = {1631-4},
  Volume                   = {III},

  Comment                  = {403: ReadYes},
  File                     = {lee00icaFeatures.ps.gz:lee00icaFeatures.ps.gz:PDF},
  Review                   = {ICA basis proj. replaces 1st MFCC DFT; a little better than usual MFCC's
* speech time series is time series of statistically independent sources, mixed by basis func matrix
* basis functions w/ Laplacian source prior estimated w/ Natural grdient and non-linearity
* I wonder: better if pick bases discriminatively
* this paper says bases are linearly spaced but later TW Lee paper says they're critical band.
* time span of matrix is 3.1ms (50 samples)
* speech is pre-whitened before making basis (is that a good idea?)
* strongest Euclidean norm bases (or sorce variances) selected
* speech projected by basis (replaces 1st DFT in MFCC's)
* not clear if test speech is pre-whitened like basis training speech was.
* resulting cepstral coeffs work 47% better than MFCC's on whole word models.},
  Url                      = {http://www.cnl.salk.edu/~tewon/Public/lee_icassp.ps.gz}
}

@Misc{jaakkola99maxEntDisc,
  Title                    = {Maximum entropy discrimination},

  Author                   = {T. Jaakkola},
  Year                     = {1999},

  Comment                  = {80: ReadYes},
  Review                   = {Support vector machines for use w/ generative models
* (support vectors are subsumed by this approach)
* calcs involve distributions overs tructures so maybe related to structure learning?
* a reference from Ozgur and my Fisher Kernel class project}
}

@Misc{jaakkolaXXfisher,
  Title                    = {Using the {Fisher} kernel method to detect remote protein homologies},

  Author                   = {T. Jaakkola and M. Diekhans and D. Haussler},
  Year                     = {unknown},

  Comment                  = {85: ReadYes},
  Review                   = {Using generative model (HMM) in support vector machines
* a reference from Ozgur and my Fisher Kernel class project}
}

@Misc{jaakkolaXXkernelRegression,
  Title                    = {Maximum entropy discrimination},

  Author                   = {T. Jaakkola and D. Haussler},
  Year                     = {unknown},

  Comment                  = {81: ReadYes},
  Review                   = {Support vector machines kernel functions for regression
*
* Bayesian logistic regression
* a reference from Ozgur and my Fisher Kernel class project?}
}

@Misc{jaakkolaXXMEDisc,
  Title                    = {Maximum entropy discrimination},

  Author                   = {T. Jaakkola and M. Meila and T. Jebara},

  Comment                  = {18.0: ReadNo},
  Review                   = {Slides on Max ent disc}
}

@InProceedings{jacobson01peakthresh,
  Title                    = { Auto-threshold peak detection in physiological signals},
  Author                   = {M. L. Jacobson},
  Booktitle                = {Engineering in Medicine and Biology Society, {IEEE} Intl. Conf. on},
  Year                     = {2001},
  Pages                    = {2194-2195},
  Volume                   = {3},

  Comment                  = {329: ReadYes},
  Review                   = {EKG peak threshold chosen by k-means clustering of slope derivatives
* application is selection EKG threshold defining peaks and troughs
* clusters derivatives of positive values
* peak pos deriv is EKG "peak"
* assumes, I guess, that peaks are in the minority so the bigger cluster is the non-peaks
* how the threshold is calculated from the clusters is not really explained...}
}

@Article{jami99cellLoc,
  Title                    = {Comparison of methods of locating and tracking cellular mobiles},
  Author                   = {I. Jami and M. Ali and R. R. Ormondroyd},
  Journal                  = {{IEE}?},
  Year                     = {1999},

  Comment                  = {249: ReadNo},
  Review                   = {Overview of cellular localization techniques}
}

@InProceedings{janer96wavPitch,
  Title                    = {Pitch Detection and Voiced/Unvoiced Decision Algorithm based on Wavelet Transforms},
  Author                   = {Leonard Janer and Juan Jose Bonet},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1996},

  Comment                  = {326: ReadYes},
  File                     = {janer96wavPitch.pdf:janer96wavPitch.pdf:PDF},
  Review                   = {
Auditory-style Wavelet filterbank
* Modulated Gaussian Wavelet Tranform Speech Analyser(MGWTSA)
* MGWTSA: scale spacing tighter than dyadic => better freq resolution
* (actually, not shown that this matters, though)
* HAD 17 band bark scale filter bank
* fewer scales => more big errors but fewer missed voiced periods
* SO NOW: has 5 scales
* compensated w/ voiced/unvoiced detector to filter big errors 
Peak picking/summarization
* Peak confirmation and distortion checking
* no mention of envelope in high freqs},
  Url                      = {http://www.asel.udel.edu/icslp/cdrom/vol2/883/a883.pdf}
}

@InProceedings{jang01efficientSIDfeat,
  Title                    = {Learning Statistically Efficient Features For Speaker Recognition},
  Author                   = {G. Jang and T. Lee and Y. Oh},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},

  Comment                  = {190: ReadYes},
  Review                   = {ICA fixed-len, known text time samples, then do GMM for spkrID
* each spkr has its own ICA (smart?)
* 8s learning time/spkr
* long test data set too
* works better than fourier->GMM but why not compare w/ GMM's?}
}

@InProceedings{jang02monoBSSicaBase,
  Title                    = {Blind Separation of Single Channel Mixture Using {ICA} Basis Function},
  Author                   = {Gil-Jin Jang and Te-Won Lee and Yung-Hwan Oh},
  Booktitle                = {Independent Component Analysis And Blind Signal Separation, Intl. Conf. on},
  Year                     = {2002 },
  Pages                    = {595-600},

  Comment                  = {361: ReadYes},
  Review                   = {Very similar to jang02monBSStimeIdep. Slightly different notation.
* discrete set classification from observations of RV, x
* x is a mixture fixed basis vectors},
  Url                      = {http://bulsai.kaist.ac.kr/~jangbal/research/demos/ch1bss/}
}

@Article{jang02monoBSStimeBase,
  Title                    = {Single Channel Signal Separation Using Time-Domain Basis Functions},
  Author                   = {Gil-Jin Jang and Te-Won Lee and Yung-Hwan Oh},
  Journal                  = {{IEEE} Signal Processing Letters},
  Year                     = {2002 },

  Comment                  = {341: ReadYes},
  Review                   = {Sparse code separation of single channel speech. A real CPU killer.
* advantage over subspace: 
- uses time =and= space properties of signals
- separated spaces don't have to be orthog. (works by high order stats)
* fixed for two separable signals but can be extended hierarchically
* instantaneous, not convolutive mixing
* separation not great -- good enough to count # speakers in overlap?

Signal/Source model
* x: signals to be separated are from mixed independent sources
- sources are modelled by Generalized Gaussian
- mixing matrix for each source (basis) are pre-trained by GG alg.
* y: the monaural signal: it is a linear combination of x
Separation:
* learn indep source params (same set for each signal)
* learn linear combination coeffs for combining x into y
* formulas given only for two separable signals
Experiment:
* trained basis functions for: generic male,female (TIMIT), rock, jazz
* tried to separate (different speakers and music pieces)
* best separation: jazz/male (about 5.5dB improvement for each)
* about as good as used Wiener filter w/ known target/interferer spectra
* 8 secs audio too 10min on 1.0GHz pentium!

* NOTE: IN REVISION},
  Url                      = {http://bulsai.kaist.ac.kr/~jangbal/research/demos/ch1bss/}
}

@InProceedings{jang03subspc1chanSep,
  Title                    = {A {SUBSPACE} {APPROACH} {TO} {SINGLE} {CHANNEL} {SIGNAL} {SEPARATION} {USING} {MAXIMUM} {LIKELIHOOD} {WEIGHTING} {FILTERS}},
  Author                   = {{Gil-Jin} Jang and {Te-Won} Lee and {Yung-Hwan} Oh},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2003},
  Pages                    = {45-48},
  Volume                   = {5},

  Comment                  = {448: ReadNo},
  Review                   = {overlap detector for BN? Mono.},
  Url                      = {http://bulsai.kaist.ac.kr/~jangbal/research/papers/icassp03.pdf}
}

@Misc{janinXXmultistream,
  Title                    = {Multi-stream speech recognition: ready for prime time?},

  Author                   = {A. Janin and D. Ellis and N. Morgan},

  Comment                  = {131: ReadNo}
}

@Conference{Janin07ICSI-SRISpring2006,
  Title                    = {The {ICSI-SRI} Spring 2006 Meeting Recognition System},
  Author                   = {A. Janin and A. Stolcke and X. Anguera and K. Boakye and O. Cetin and J. Frankel and J. Zheng},
  Booktitle                = {MLMI},
  Year                     = {2007},

  File                     = {Janin07ICSI-SRISpring2006.pdf:Janin07ICSI-SRISpring2006.pdf:PDF},
  Owner                    = {scotto},
  Timestamp                = {2007.03.26},
  Url                      = {http://www.icsi.berkeley.edu/cgi-bin/pubs/publication.pl?ID=002139}
}

@InProceedings{jarina01spchMusicMPEG,
  Title                    = {Speech-Music Discrimination from {MPEG}-1 Bitstream},
  Author                   = {Jarina, R. and Murphy, N. and O'Connor, N. and Marlow, S.},
  Booktitle                = {Speech, Signal and Image Processing, Intl. Conf on},
  Year                     = {2001},

  Comment                  = {406: ReadYes},
  Review                   = {MPEG scalefactors like modulation envelopes; 
* good overview of the differences between music and speech signals
- speech has 4Hz modulation
- speech envelope peaks have shorter time-widths
* scalefactors: ~avg. amplitude for each freq band, part of MPEG std.
* summed scalefactors for 700-4KHz filterbank bands
* measure time-width and repetition rate of peaks
* simple 2D if/else rule detects speech in music: 86-98% accuracy
* 4 sec analysis frame is quite long},
  Url                      = {http://www.eeng.dcu.ie/~vmpg/papers/SSIP01.pdf}
}

@Misc{jebaraXXmeFeat,
  Title                    = {Feature selection fnd dualities in maximum entropy discrimination},

  Author                   = {T. Jebara and T. Jaakkola},
  Year                     = {unknown},

  Comment                  = {87: ReadNo},
  Review                   = {A reference from Ozgur and my Fisher Kernel class project
* support vector machines}
}

@TechReport{Jenkins00pairDistKPCA,
  Title                    = {Localization from Pairwise Distance Relationships using Kernel PCA},
  Author                   = {Odest Chadwicke Jenkins},
  Institution              = {Center for Robotics and Embedded Systems, USC Viterbi School of Engineering},
  Year                     = {2003},
  Number                   = {CRES-03-010},

  File                     = {Jenkins00pairDistKPCA.pdf:Jenkins00pairDistKPCA.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {KPCA transform of pairwise distance (physical or RF atten.) produces 2-D map of object orientation

What KPCA does

Feature space PCA of makes an orthogonal coordinate system, but I'm not sure why this would necessarily remove linearity, or, in the examples given what the distance measurement nonlinearities are

jth eigenvector: jth cartesian dimension
ith eigenvector component: the ith object's location along dim j
So, need one eigenvector for each dim

Says landmarks would allow affine transformation to real world coordinates, but doesn't explain

Pairwise distances from
* human body volumetric measurement voxels (aren't these linear, so you could use MDS?)
* radio frequency strength between transmitter pairs
 -- must be normalized, 2 techniques:
 1.) correct for differences in radio gain (somehow, doesn't explain)
 2.) Ignore 1st eigenvector, use vecs 2 and 3 (w/o norm, it's the feature space mean?)

Pictures show that it kind of works (shapes match)

* Says that they've had better luck with Isomap transforms. This must be described in tech note "A Spatio-temporal Extension to Isomap Nonlinear Dimension Reduction, CRES-04-003, here:
http://cres.usc.edu/Research/files/cjenkins_stisomap.pdf},
  Timestamp                = {2007.08.18},
  Url                      = {http://cres.usc.edu/Research/publications.php}
}

@Misc{jepson93optflow,
  Title                    = {Mixture models for optical flow computation},

  Author                   = {A. Jepson and M. Black},

  Comment                  = {31.5: ReadNo},
  Review                   = {Relevant??}
}

@InProceedings{ji04multiSpkrLangModel,
  Title                    = {Multi-speaker Language Modelling},
  Author                   = {Gang Ji and Jeff Bilmes},
  Booktitle                = {Proc. {HLT-NAACL} {SIGDIAL} workshop},
  Year                     = {2004},

  Comment                  = {ReadNo},
  File                     = {ji04multiSpkrLangModel.pdf:ji04multiSpkrLangModel.pdf:PDF},
  Review                   = {Gang's multi-speaker language model: use w/ speaker tracking?},
  Url                      = {http://students.washington.edu/gji/doc/hlt04.pdf}
}

@InProceedings{jia02entropyEndpoint,
  Title                    = {{AN} {IMPROVED} {ENTROPY}-{BASED} {ENDPOINT} {DETECTION} {ALGORITHM} (poster)},
  Author                   = {Chuan JIA and Bo XU},
  Booktitle                = {ISCSLP },
  Year                     = {2002},

  Comment                  = {451: ReadYes},
  Review                   = {Adaptive bias to spectrum improves Spectral Entropy VAD
* why entropy is good VAD param
- speech H different from most noise signals (not demonstrated)
- in speech, change of entropy small compared to change of entropy

- especially, this is true for fricatives and plosives 
- (nemer didn't agree but he was using LPC residual)
- adding noise drops overall entropy but spch/noise remains the same
- good graphs of this
* add constant to all FFT bins before entropy calc
- drops everybody's neg entropy
- but decreases noise -H more
- makes various noise types (factory, office, F16 plane, (no babble))
- makes thresholds easier to adapt than with ordinary entropy calc
* constant adapted in heuristic manner
* speech is bandpassed before entropy calc
* Tests: (
- 5,10,15 dB
- better at accurately detecting start of speech than end of speech
- 13% better than energy in 5dB noise},
  Url                      = {http://neural.cs.nthu.edu.tw/jang/courses/isa5571/paper/endPointDetection/096.pdf}
}

@InProceedings{jin97automatic,
  Title                    = {Automatic speaker clustering},
  Author                   = {H. Jin and F. Kubala and R. Schwartz},
  Booktitle                = {Proc., Speech Recognition Workshop},
  Year                     = {1997},
  Pages                    = {108-111},

  Comment                  = {151: ReadYes},
  Review                   = {Broadcast News style cluster/adapt, Gish dist w/ contig. frame scale
Segmentation Chopper
-- unexplained but seems to be coarse
Clustering
-- Gish distance chooses cluster merge candidate 
-- seems to be det. of cov matrix mean (?) (dispersion?)
-- extra credit tweak for contiguous segments (interframe dep.)
-- bottom up, agglomerative
-- sqrt(# clusters) scaling penalty to avoid lots of clusters
Results:
* 10-25% relative WER reduction for clusterer
* Resulting clusters improve MLLR as much as hand-labelled case},
  Url                      = {citeseer.nj.nec.com/jin97automatic.html}
}

@InProceedings{jin04mtngRecogRT04s,
  Title                    = {Speaker Segmentation and Clustering in Meetings},
  Author                   = {Qin Jin and Kornel Laskowski and Tanja Schultz and Alex Waibel },
  Booktitle                = {{NIST} Meeting Recognition Workshop},
  Year                     = {2004},

  Comment                  = {ReadYes},
  Review                   = {NIST meeting speaker seg/clust

Multimic VAD segmentation
* VAD on each channel
* overall boundaries are union of channel VAD boundaries
* for each seg, pick single best channel (best energy/SNR)
* no beamforming, just channel selection
Multimic speaker change detection
* GLR boundaries on best channel if segment length > 5s
* overall bounaries are the union of channel boundaries
* heuristics on GLR distance measure evaluate bndry on 10ms interval
* GLR computed with TGMM (like UBM?) b/c it's more reliable
Multimic clustering
* agglomerative
* BIC stopping
* TGMM-GLR distance
* diarization: 28% error w/o overlaps; 40% error w/ overlaps!
Headset mic VAD (IHM)
* Baseline energy VAD didn't work
* Phase Closure (sort-of) overlap detection
- not well defined. better in upcoming paper by same authors?
- uses IIR pre-emph
- somehow also used as a VAD but not explained AT ALL
- fails badly (WER worse than just energy VAD)
- I can see how this failed:
o should have used inverse LP filtering instead
o mic spacing too far (phase ambiguities)
* Energy ratio overlap det (sort-of)
- uses peak Rxy
- says spkr x active if sum(max(Rxy)/Ryy)>thresh for each spkr
- works (much better WER than energy VAD)
- this is for headset mic, not distant mics

v. similar to: laskowski04crosscorrMultispeakerVAD},
  Url                      = {http://www-2.cs.cmu.edu/~tanja/MyPublications.html (not released yet)}
}

@Misc{jinachitra01convBSSrev,
  Title                    = {{BSS} of convolutive mixtures, Summary on project Literature Review},

  Author                   = {Pamornpol Jinachitra},
  HowPublished             = {Web Page Link},
  Year                     = {2001},

  Comment                  = {445: ReadYes},
  Review                   = {Nice overview of ConvBSS literature. Could look up some of the references.},
  Url                      = {http://www.stanford.edu/~pj97/SummaryConvBSS.htm}
}

@InProceedings{johnson-speaker,
  Title                    = {Speaker Clustering Using Direct Maximisation of the {MLLR}-Adapted Likelihood},
  Author                   = {S. Johnson and P. Woodland},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1998},
  Pages                    = { 1775-1779},

  Comment                  = {154: ReadYes},
  Review                   = {Broadcast News clust: Cov split/merge or MLLR-EM split/merge. MLLR best
* PLP features (bad idea according to Ellis?)
* segment breaks given
* two split/merge algorithms: Covariance and MLLR-EM
Cov Split/Merge
* AHS and Gaussian Divergence dist, quote results for AHS
* top down split into 4 nodes until no nodes can be split 
* can't split: 
-- single segment
-- child instersegment dist > parent intersegment dist
* single segments are distributed to nearest other child node 
* sequential order maintained during split
* after each split iter + single elem. merge, a recombine close children
* segs <= 0.5s are assigned after clustering (good idea)
MLLR Split (calls it two step EM)
* requires approx data transcription 1st
* For each parent node to be split
-- MLLR on each child seg (children could come from cov or time order)
-- assign each seg to best MLLR xform
-- iterate MLLR/reassign until convergence or max iter
-- min cluster occupancy is 25s, min seg length is 0.5s
MLLR Merge
* until no recombinations or only 1 child
-- MLLR for each child and likelihoods for other chldrn using this MLLR
-- merge chldrn having nearest MLLR likelihoods (if similar enough)
Results
MLLR works better than cov on 1997 hub 4}
}

@InProceedings{johnson99euro,
  Title                    = {Who Spoke When? - Automatic Segmentation and Clustering for Determining Speaker Turns},
  Author                   = {S. E. Johnson},
  Booktitle                = {Eurospeech},
  Year                     = {1999},
  Pages                    = {2211-2214},
  Volume                   = {5},

  Comment                  = {153: ReadYes},
  Review                   = {Broadcast News clust., reports cluster accuracy, advocates spkrID clust
* similar to johnson-speaker but reports cluster results, not WER
* Merit: 
-- seg based: Irand, Ibbn, Cluster Efficiency (explains how to pick Q)
-- frame based scoring: includes duration weighting (do I care?)
* segments split on silences
* GMM labeles speech category (music, telephone speech, etc)
* test on Hub94
Results
* 72.3% frame based efficiency 
* 27.7% worse than perfect, (Q choice makes makes perfect not 100%)}
}

@Misc{jordanXXbayesModSel,
  Title                    = {{Bayesian} Model Selection},

  Author                   = {D. Blei M. Jordan and J. McAuliffe},

  Comment                  = {22.6: ReadNo},
  Review                   = {Class notes web page}
}

@Misc{jordanXX_TIC_AIC,
  Title                    = {TIC/AIC},

  Author                   = {M. Jordan and F. Back and X. Ren},

  Comment                  = {23.0: ReadNo},
  Review                   = {TIC and AIC course notes. AIC something like BIC, and can be used for model selection}
}

@TechReport{jordan95logistic,
  Title                    = {Why the logistic function? A tutorial discussion nd proabilities and neural networks},
  Author                   = {M. I. Jordan},
  Institution              = {Computational cognitive science, {MIT}},
  Year                     = {1995},
  Number                   = {Tech Report. 9503},

  Comment                  = {62: ReadYes},
  Review                   = {A discriminative model yielding prob like a generative
* adv/disadv of generative v.s. discriminative models
* generic form for exponential family of pdfs
* parameter estimation^* nonlinear discriminant functions}
}

@Article{jordan94hierMix,
  Title                    = {Hierarchical mixtures of experts and the {EM} algorithm},
  Author                   = {M. I. Jordan and R. A. Jacobs},
  Journal                  = {Neural computation},
  Year                     = {1994},
  Pages                    = {181-214},
  Volume                   = {6},

  Comment                  = {61: ReadNo},
  Review                   = {EM adjustment of GLM coeffs, something like hierarchical GMM's? useful for speaker clustering and maybe VAD GLM/GMM adaptation?}
}

@InProceedings{joseph03fuseSpkrIDfeat,
  Title                    = {Fusing High- and Low-Level Features for Speaker Recognition},
  Author                   = {Joseph P. Campbell, Douglas A. Reynolds, Robert B. Dunn},
  Booktitle                = {Eurospeech},
  Year                     = {2003},
  Pages                    = {2665-2668},

  Comment                  = {579: ReadNo},
  Review                   = {multiple feature stream spkr ID (kinnunen03fuseSpkrIDclass paper had multiple classifiers)}
}

@InProceedings{jung01poleCMSimp,
  Title                    = {The implementation of {PFCMS} using cepstrum information},
  Author                   = {Hea-Kyoung Jung and Yu-Jin Kim and Jae-Ho Chung},
  Booktitle                = {ISCAS},
  Year                     = {2001},
  Pages                    = {365-368},
  Volume                   = {2 },

  Comment                  = {ReadNo}
}

@InProceedings{jutten00srcSepDusk,
  Title                    = {Source separation: From dusk till dawn},
  Author                   = {Christian Jutten and Anisse Taleb},
  Booktitle                = {Independent Components Analysis, Int. Conf. on},
  Year                     = {2000},
  Pages                    = {15-26},

  Comment                  = {ReadNo},
  Url                      = {http://citeseer.nj.nec.com/rd/18495673%2C481603%2C1%2C0.25%2CDownload/http%3AqSqqSqciteseer.nj.nec.comqSqcacheqSqpapersqSqcsqSq23443qSqhttp%3AzSzzSzwww.atri.curtin.edu.auzSzcspzSzanissezSzicainvited.pdf/source-separation-from-dusk.pdf}
}

@InProceedings{kirchoff00artic,
  Title                    = {Conversational Speech Recognition Using Acoustic and Articulatory Input},
  Author                   = {K. Kirchhoff, G.A. Fink and G. Sagerer},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},

  Comment                  = {ReadNo},
  Review                   = {Articulatory features paper? },
  Url                      = {http://www.icsi.berkeley.edu/~dpwe/research/etc/icassp2000/pdf/3367_17.PDF}
}

@InProceedings{Laskowski07VocConvType,
  Title                    = {Modeling Vocal Interaction for Text-Independent Classification of Conversation Type},
  Author                   = {K.Laskowski and M.Ostendorf and T.Schultz},
  Booktitle                = {SIGDIAL Workshop on Discourse and Dialogue},
  Year                     = {2007},

  File                     = {Laskowski07VocConvType.pdf:Laskowski07VocConvType.pdf:PDF},
  Owner                    = {scotto},
  Timestamp                = {2008.04.25}
}

@Article{kadambe92wavelPitchDet,
  Title                    = {Application of the Wavelet Transform for Pitch Detection of Speech Signals},
  Author                   = {S. Kadambe},
  Journal                  = {Information Theory, IEEE Transactions on},
  Year                     = {1992},
  Volume                   = {38 },

  Comment                  = {185: ReadYes},
  Key                      = {917-924},
  Review                   = {Seems to be earliest wavelet pitch detect paper
* generate pitch pulse when simultaneous spikes in 2 of 3 wavelet bands
* supposed to be like human algorithm
* locates each pulse in time (unlike MFCC,etc) so could separate better
* voiced/unvoiced detect: fixed threshold on max DWT coeff & same peak
on two bands.
* Brooks&Hanzo, 2000 refine this: use ACF for fine search around wavlet peaks (better?)}
}

@InProceedings{kajarekar04missFeatNERF,
  Title                    = {Modeling {NERFs }for Speaker Recognition},
  Author                   = {S. Kajarekar and L. Ferrer and K. Sonmez and J. Zheng and E. Shriberg and A. Stolcke},
  Booktitle                = {Proc. Odyssey 2004: The Speaker and Language Recognition Workshop},
  Year                     = {2004},

  Comment                  = {ReadYes},
  Review                   = {Handle missing features in GMM eg. unvoiced in GMM w/ voiced param
* different than "missing feature": can't estimate from other features, as is normally done
* has GMM equations
* has a hard-coded "undefined" bit for each element of the feature vector
* same authors, another `04 paper: NERF SVM's better than GMM's in speaker recog:
-- "SVM Modeling of ?SNERF-Grams? for Speaker Recognition"
-- find a feature's contribution to moving to classification hyper plane edge 
-- need linear kernel
-- intend to do feature selection some day},
  Url                      = {www.speech.sri.com/cgi-bin/run-distill?papers/odyssey2004-nerfs.ps.gz}
}

@InProceedings{kajarekar03spkrOvDet,
  Title                    = {Novel Approaches for One- and Two-speaker Detection},
  Author                   = {Sachin S. Kajarekar and Andr? G. Adami and Hynek Hermansky},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {2661-2664},

  Comment                  = {578: ReadNo},
  Review                   = {overlap detector}
}

@Unpublished{KakadeMulti-ViewRegressionvia,
  Title                    = {Multi-View Regression via Canonical Correlation Analysis},
  Author                   = {Sham M. Kakade and Dean P. Foster},
  Note                     = {Toyota Technological Institute at Chicago},

  Comment                  = {625:ReadYes},
  File                     = {KakadeMulti-ViewRegressionvia.pdf:KakadeMulti-ViewRegressionvia.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {How CCA and CCA dim reduction can improve a linear (or kernel-linear) regression, even if you use only 1 view

* mentions classifiers but this is really about linear regression
* probably applies to classifiers, though, since SVM's, etc. do this kind of regression
* I think it's analogous enough to provide a theoretical rationale for using unlabeled data in CCA dimension 
 reduction before classification -- a kind of weakly supervised algorithm


Basic idea:
* project a view onto its CCA basis; design a linear regression in the CCA space (eq 2)
* force linear predictor in one view to agree with the other by using CCA (if they are correlated, they will kind of agree)
* idea is that the best predictors from each view will agree with each other
* CCA eliminates hypotheses from each view where predictors don't agree
* limit of single view loss over using simultaneous views is set by the worst classifier 
 ("loss" is squared distance of predicted value from target)

Canonical Shrinkage Estimator: 
* in the linear regression, shrinks contributions from directions that are not correlated with the other view
* eq (2) is the equation for this linear estimator, operating over one view, projected onto the canonical basis
* is derviable from a cost function which minimizes prediction error and uncorrelated direction

Why using unlabeled data to compute CCA basis helps with one view:
* dimesion reduction set by thresholding CCA correlation value (remove low correlation CCA comps)
* error drops with increasing # of training samples, n, at rate of input dimensionality
* if use CCA, "regret" drops at rate of intrinsic dimensionality (sum of correlation coeffs)
 (regret: difference from best case regression using both views simultaneously)

Why dimension reduction w/ CCA can help:
* loss due to dimensionality reduction is again bound by intrinsic dimension
* something about how throwing away comps can increase bias reduce variance (I didn't understand this)},
  Timestamp                = {2007.04.05},
  Url                      = {http://gosset.wharton.upenn.edu/research/}
}

@InProceedings{karjalainen99multipitch,
  Title                    = {Multi-pitch and periodicity analysis model for sound separation and auditory scene analysis},
  Author                   = {Matti Karjalainen and Tero Tolonen},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999},
  Pages                    = {929-932},
  Volume                   = {2},

  Comment                  = {ReadNo},
  Url                      = {citeseer.nj.nec.com/karjalainen99multipitch.html}
}

@InProceedings{karneback02spchMusicE,
  Title                    = {Expanded examinations of a low frequency modulation feature for speech/music discrimination},
  Author                   = {Karneb?ck, Stefan},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},

  Comment                  = {407: ReadYes},
  File                     = {karneback02spchMusicE.pdf:karneback02spchMusicE.pdf:PDF},
  Review                   = {Low freq mods perform the same; 4Hz OK, more noise-robust than MFCC's
* more study on 4Hz modulation (see last year's paper by same author)
* low freq mod crosscorr features from 2 to 27Hz work
* but should have only one period in analysis window
* 4,5,16,20Hz features are best
* are more noise and test/train mismatch robust than MFCCs
* but otherwise are about the same
* some performance improvement LF and MFCC's combined},
  Url                      = {http://www.speech.kth.se/ctt/publications/papers/icslp02_sk.pdf}
}

@InProceedings{karneback01spchMusic,
  Title                    = {Discrimination between speech and music based on a low frequency modulation feature},
  Author                   = {Stefan Karneb?ck},
  Booktitle                = {Eurospeech},
  Year                     = {2001},
  Pages                    = {1891-1894},

  Comment                  = {405: ReadYes},
  File                     = {karneback01spchMusic.pdf:karneback01spchMusic.pdf:PDF},
  Review                   = {4Hz syllabic modulation feature across filterbanks detects speech
Low freq modulation
* modulation freq @ filt bank output has 4Hz component for speech
* explains why speech has 4Hz (max mouth speed determines syllable time)
* people are especially sensitive to 2-15Hz modulations
* other papers & 4Hz: works in Scheirer&Slaney `97; fails in philibert
* problem: music also has 4Hz e.g. 16th notes in 60 beat/sec music

Insight: music and speech 4Hz have different characteristics
* 4Hz cross-freq correlation
- speech: 4Hz comes from one mouth
- music: many instruments
* 4Hz mod amplitude/stdev varied more for speech (esp. in formant bands)
* speech time/freq crosscorr graph very different from music's
New Features
* 4Hz ASD:
- auditory-like, 20-filterbank w/ rect/lpf
- normalization and log power
--> 40 dim feature: 20 amps + 20 vars
- analysis frame is 500ms: fast compared to other papers?
* 4Hz norm amplitude
- similar to Scheirer&Slaney feature: sum of filtbank mod amps
- scalar feature
* 2-4Hz amplitude
- like 4Hz norm amplitude but summed over 1,3,4Hz
- scalar feature
Tests on Swedish FM broadcast news
* tried VQ and GMM classifiers w/ increasing # coefficients
* 4Hz ASD works best of new features
* 4Hz ASD works best with VQ-64 (but almost the same as GMM-32)
* slightly better results if combine w/ MFCC (79dim feature).
* giant MFCC features (78 coeffs) works better w/ GMM (96.6% accuracy)
* 4Hz ASD (combined or not) degrades very little w/ simpler classifiers e.g VQ-16
* my note: 4Hz ASD (combined or not) isn't diagonal; were GMM covs diag?},
  Url                      = {http://www.speech.kth.se/ctt/publications/papers/ES01_1891.pdf}
}

@Article{kass95bayesFac,
  Title                    = {Bayes factors},
  Author                   = {Kass, R. and Raftery, A.},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {1995},
  Number                   = {430},
  Pages                    = {773-795},
  Volume                   = {90},

  Comment                  = {ReadNo},
  Review                   = {Explains Laplace Approximation used in BIC. Referenced in Heckerman Tutorial (says Laplace Approx is more detailed)}
}

@InProceedings{kemp00segment,
  Title                    = {Strategies for automatic segmentation of audio data},
  Author                   = {T. Kemp and M. Schmidt and M. Westphal and A. Waibel},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},
  Pages                    = {1423 -1426},
  Volume                   = {3},

  Comment                  = {160: ReadYes},
  Review                   = {Broadcast News clust, Hybrid metric(Gish clust)/model(GMM re-seg)

* # spkrs known ahead of time
* only 4 segment classes (no spkr ID)
* equispaced segments -> coarse clust -> refined segs
* 1.5s min seg size (very coarse)
* Mel spectra better than MFCC's
* Model or Metric based seg works better than energy based silences
* Hybrid model(precision)/metric(recall) to get best of both worlds
* Gish dist best metric, slighly better than KL: ent. loss, BIC, MDL bad
* Cluster w/ Gish dist
* Then resegment, using most likely models trained on resulting clusters
* 64 mixture GMM.
* tested on German TV
* resegmentation using MLLR adapted models didn't help}
}

@InProceedings{kenny03spkrIDmap,
  Title                    = {New {MAP} Estimators for Speaker Recognition},
  Author                   = {P. Kenny and M. Mihoubi and P. Dumouchel},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {2961-1964},

  Comment                  = {582: ReadNo},
  Review                   = {eigenvoice spkrID w/ eigenchannel comp. good ICA spkr model?}
}

@InProceedings{kim88pisarSpec,
  Title                    = {The modified Pisarenko's algorithm for adaptive spectrum estimation},
  Author                   = {Kim, D. and Alexander, W. E.},
  Booktitle                = {Spectrum Estimation and Modeling, {ASSP} Workshop on},
  Year                     = {1988 },
  Pages                    = {81-84},

  Comment                  = {ReadNo}
}

@InProceedings{kim02asrCarNoise,
  Title                    = {{EVALUATION} {OF} {ROBUST} {SPEECH} {RECOGNITION} {ALGORITHMS} {FOR} {DISTRIBUTED} {SPEECH} {RECOGNITION} {IN} A {NOISY} {AUTOMOBILE} {ENVIRONMENT}},
  Author                   = {Hong Kook Kim and Richard C. Rose},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {233-237},

  Comment                  = {413:ReadYes},
  Review                   = {Cepstral cleanup / noise+model comp. / VAD & recog on synth. speech
* Cepstra cleaned up with CSM (Cepstral Subtraction Method)
- non-linear, freq dependent gain, estimated on fly the w/ MMSE-LSA
* CSM makes clean & noisy cepstra w/ freq dep gain, no explicit SNR est.
* Also does cepstral mean subtraction (CMS).
* noisy cepstra --> single mixture GMM noise model
* model compensation: noise model + Recog HMM models (mean,cov add)
* Bizarre segmentation aka VAD aka endpoints:
CSM cleaned MFCC's + pitch -> synthesized waveform 
-> attenuation of nonspeech MFCC frames (front end proc., unexplained)
-> voiced emphasis (cause probs w/ ending frics/consonants?)
-> synthesize time domain waveform!
-> pitch+autocorr VAD (2nd VAD, really)
-> segment merging so don't have too many short frags
* Additional Cepstral Mean Subtraction (CMS) after segmentation
* Cleaned & segmented MFCC's fed to regular, model-compensated ASR
* WER on noisy Aurora cut in half

* I DON'T GET IT: subtracting noise to clean MFCC's but then adding noise (model compensation) to recog HMM. Doesn't that guarantee a mismatch?

* Segmentation could be implemented causally?

* referenced by Zak's VAD paper (shafran03asrVad)},
  Url                      = {http://ssli.ee.washington.edu/proceedings/icslp02/ICSLP/PDF/AUTHOR/SL021978.PDF}
}

@Misc{kim00multiSVD,
  Title                    = {Spatial multiuser access with antenna diversity using singular value decomposition},

  Author                   = {J. Kim and J. M. Cioffi},

  Comment                  = {51.0: ReadYes},
  Review                   = {Don't focus since beam pattern looses signal power contained in multipath components
* instead, xform users to differnt spaces based on known spatial gain matrix and known # of multipaths (not available for reverb speech)
* maybe not useful for speech but provides more evidence that speech beamforming may not be a good idea
* but maybe use for overlap resolution?}
}

@InProceedings{kim03stateDblTalkEq,
  Title                    = {Accuracy Improved Double-Talk Detector Based on State Transition Diagram},
  Author                   = {SangGyun Kim and Jong Uk Kim and Chang D. Yoo},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {1421-1424},

  Comment                  = {572: ReadNo},
  Review                   = {telephone echo canceller for crosstalk, relevant to switchboard crossvad. Has state machine}
}

@InProceedings{kingsbury02spineASRseg,
  Title                    = {Robust speech recognition in noisy environments: the 2001 {IBM SPINE} evaluation system},
  Author                   = {Brian Kingsbury and George Saon and Lidia Mangu and Mukund Padmanabhan and Ruhi Sarikaya},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},
  Pages                    = {53-56},
  Volume                   = {1},

  Comment                  = {439: ReadYes},
  Review                   = {IBM's SPINE ASR, describes HMM-based VAD
* GMM's trained on spch/nonspch
* Features:
-- voicing and log energy (+-8 frames for total dim=34)
-- LDA+MLLT transformed down to 2D
-- diagonalized
* Viterbi decoded to get VAD
* Add 20 frame slop on either end 
* Note: CMU (Singh) more worried about false noise but they had no HMM},
  Url                      = {http://ieeexplore.ieee.org/iel5/7874/21701/01005673.pdf?isNumber=21701&prod=IEEE+CNF&arnumber=1005673&arSt=I-53&ared=I-56+vol.1&arAuthor=Kingsbury%2C+B.%3B+Saon%2C+G.%3B+Mangu%2C+L.%3B+Padmanabhan%2C+M.%3B+Sarikaya%2C+R.%3B}
}

@InProceedings{kinnunen02spkrIDdiscFB,
  Title                    = {{DESIGNING} A {SPEAKER}-{DISCRIMINATIVE} {ADAPTIVE} {FILTER} {BANK} {FOR} {SPEAKER} {RECOGNITION}},
  Author                   = {Tomi Kinnunen},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {2325-2328},

  Comment                  = {ReadNo},
  Url                      = {/g/ssli/html/proceedings/icslp02/ICSLP/PDF/INDEXSCR.PDF}
}

@InProceedings{kinnunen03fuseSpkrIDclass,
  Title                    = {On the Fusion of Dissimilarity-Based Classifiers for Speaker Identification},
  Author                   = {Tomi Kinnunen and Ville Hautam?aki and Pasi Fr?anti},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {2641-2644},

  Comment                  = {577: ReadNo},
  Review                   = {fusing speaker ID classifiers (eg. for me mic param classifier and acoustic param classifier). joseph03fuseSpkrIDfeat fuses features}
}

@InProceedings{kirchoff98artic,
  Title                    = {Combining Articulatory and Acoustic Information for Speech Recognition in Noisy and Reverberant Environments},
  Author                   = {K. Kirchhoff},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1998},
  Pages                    = {891-894},

  Comment                  = {ReadNo},
  Review                   = {Articulatory features},
  Url                      = {http://ssli.ee.washington.edu/proceedings/icslp98/HTML/SL98S117.HTM#p0873}
}

@Article{kirchhoff02artic,
  Title                    = {Combining acoustic and articulatory information for robust speech recognition.},
  Author                   = {Katrin Kirchhoff and Gernot A. Fink and Gerhard Sagerer},
  Journal                  = {Speech Communication},
  Year                     = {2002},
  Number                   = {3-4},
  Pages                    = {303-319},
  Volume                   = {37},

  Comment                  = {ReadNo},
  Review                   = {The long articulatory features paper },
  Url                      = {Katrin has it}
}

@Article{kittler00combo,
  Title                    = {On Combining Classifiers},
  Author                   = {Josef Kittler and Mohamad Hatef and Robert P.W. Duin and Jiri Matas},
  Journal                  = {IEEE trans. on pattern analysis and machine intelligence},
  Year                     = {2000},
  Number                   = {3},
  Pages                    = {226-239},
  Volume                   = {20},

  Comment                  = {297: ReadNo}
}

@InProceedings{kizh02cochanCyclo,
  Title                    = {Co-channel Speech Detection Approaches Using Cyclostationarity or Wavelet Transform},
  Author                   = {Arvind Raman Kizhanatham and Nishant Chandra and Robert E. Yantorno},
  Booktitle                = {Intl. Conf. on signal and image processing},
  Year                     = {2002},

  Comment                  = {284: ReadYes},
  Review                   = {SpkrID Usable when harmonics in wavelet or cyclostationary transform
* cyclostationarity: something to do w/ Hilbert Transform
* Wavelets seem like roughly same idea, and work slightly better
Wavelets
* voiced: 
-- when 90% of energy low order wavelet coeffs 
-- use both DWT and CWT for some not-really-explained reason
* usable:
-- peak picking (of what I'm not sure) plus heuristics
-- seems like it would work only for certain pitches??
* wavelets work: 94% correct, 27% false
* "correct" is not defined!}
}

@Article{knapp76generalized,
  Title                    = {The generalized correlation method for estimation of time delay},
  Author                   = {Knapp, C. H. and G. C. Carter},
  Journal                  = {Proc. ICASSP},
  Year                     = {1976},
  Pages                    = {320-327},
  Volume                   = {24},

  Comment                  = {Print, ReadNo}
}

@Book{koehler05bioChemPhys,
  Title                    = {College Physics for Students of Biology and Chemistry, 2nd ed},
  Author                   = {Ken Koehler},
  Publisher                = {EBook: http://www.rwc.uc.edu/koehler/biophys.2ed/heat.html},
  Year                     = {2005},

  Review                   = {where I got specific heat for water and tissue from. The entire book is available here: http://www.rwc.uc.edu/koehler/}
}

@InProceedings{koetter01phaseunwrap,
  Title                    = {Unwrapping phase images by propagating probabilities across graphs},
  Author                   = {R. Koetter and B. J. Frey and N. Petrovic and D. C. Munson},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {1845-1848},
  Volume                   = {3},

  Comment                  = {Print, ReadNo},
  Review                   = {Unwrapping phase w/ a Bayesian Net? NOT READ},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/iel5/7486/20374/00941302.pdf?tp=&arnumber=941302&isnumber=20374}
}

@InProceedings{kolenda01icaTopicDet,
  Title                    = {Signal Detection using {ICA}: Application to Chat Room Topic Spotting},
  Author                   = {T. Kolenda and L. K. Hansen and J. Larsen},
  Booktitle                = {Independent Components Analysis and Blind Signal Separation, Intl. Conf. on},
  Year                     = {2001},
  Pages                    = {540-545},

  Comment                  = {ReadNo},
  File                     = {kolenda01icaTopicDet.pdf:kolenda01icaTopicDet.pdf:PDF},
  Review                   = {use for overlap det?},
  Url                      = {http://www.imm.dtu.dk/pubdb/views/edoc_download.php/826/pdf/imm826.pdf}
}

@Article{johan99:_local_normal_delay_decis_makin,
  Title                    = {Local Normalization and Delayed Decision Making in Speaker Detection and Tracking},
  Author                   = {J. Koolwaaij and L. Boves},
  Journal                  = {Digital Signal Processing: A Review Journal},
  Year                     = {1999},
  Number                   = {1/2/3},
  Pages                    = {113-132},
  Volume                   = {10},

  Comment                  = {125: ReadNo}
}

@Article{vdkouwe00bssVsCasa,
  Title                    = {A comparison of auditory and blind separation techniques for speech segregaton},
  Author                   = {Andr\'e. W. van der Kouwe and DeLiang Wang and Guy J. Brown},
  Journal                  = {{IEEE} Trans. on Speech and Audio Proc.},
  Year                     = {2000},
  Pages                    = {189-195},
  Volume                   = {9},

  Comment                  = {279: ReadYes},
  File                     = {vdkouwe00bssVsCasa.pdf:vdkouwe00bssVsCasa.pdf:PDF},
  Review                   = {Ideal acoustics: BSS mostly betters CASA in speech noise/overlap removal
* however, the test is not too realistic:
-- no reverb
-- constantly mixed, known # spkrs
-- SNR is nearly 1/1
CASA: 
* good overview of CASA technique history
* picked Wang&Brown to represent them
- filterbank correlogram, oscillatory network associations
* speculates it has better reverb resistance than BSS but no test
* CASA works on mono, doesn't need to know # srcs to sep. 1st spkr
* less prob w/ moving sources than BSS (although some BSS are adaptive)
BSS:
* picked SOBI (2nd order simult. diag.) and JADE (4th order cum. min.)
* assume linear mixing, no reverb, time-aligned signals
* a few refs for BSS #sources>#sensors (not tested)
* a few BSS refs for unknown #sources
* close microphones => singular mixing matrix
TEST:
* 5 sentences by 2 males, long (6 wrd), fully voiced (looks like TIMIT)
* tests removal of 10 kinds of noise (3 are TIMIT speech)
* not really separation, since only one "signal" and one "noise"
* mixing is linear, no reverb
* noise ratio is 1:0.8, so noise is almost as strong as main speech
* apriori know it's constantly two components (speech or noise)
RESULTS
* CASA only best for 1KHz tone and siren noise; BSS better for rest

(so speech assumptions didn't seem to help CASA...).
* Joint Diag (SOBI): best when have good freq separation
* CASA has probs when time/freq overlap each other
* points out that CASA is usually "find one speaker & subtract" while

BSS tries to segregate.},
  Url                      = {http://www.dcs.shef.ac.uk/~guy/pdf/tsap2001.pdf}
}

@Article{kozick00emBF,
  Title                    = {Maximum-likelihood array processing in non-{Gaussian} noise woth {Gaussian} mixtures},
  Author                   = {R. J. Kozick and B. M. Sadler},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {2000},
  Number                   = {12},
  Volume                   = {48},

  Comment                  = {242: ReadNo},
  Review                   = {EM algorithm used in DOA/AOA 
* noise modelled as gaussian Mixture 
* not sure if this is relevant since want to see the 'noise' not null it}
}

@InProceedings{rangan00usableSAR,
  Title                    = {Spectral autocorrelation ratio as a usability measure of speech segments under co-channel conditions},
  Author                   = {K. R. Krishnamachari and R. E. Yantorno and D. S. Benincasa and S. J. Wenndt },
  Booktitle                = {ISPACS},
  Year                     = {2000},

  Comment                  = {104: ReadYes},
  Review                   = {First paper on SAPVR for usable speech in multitalker 
* 39% of 0dB talker-to-interferer ratio speech is usable for spker ID [1] 
* 70 % usable if want to ID both talkers 
* try to estimate usable w/ pitch (& harmonic power) ratio => error-prone pitch est. 
* SAR doesn't require pitch est 
* only works on voiced speech (note: location features work best on unvoiced speech so complimentary!) 
* breaks down for pure tone interference (or anything w/ harmonics like a fan?)
* [5] metions pitch detection algs for multi-talkers 
* has dropout problems 
* but finds 57 % of good frames 
* but finds at least one frame in most good segments 
* experiments done where TIR varied from -40dB to +47dB}
}

@InProceedings{krishnamachari01kurtco,
  Title                    = {Use of local kurtosis measure for spotting usable speech segments in co-channel speech},
  Author                   = {K. R. Krishnamachari and R. E. Yantorno and J. M. Lovekin and D. S. Benincasa and S. J. Wendt},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {649 -652},
  Volume                   = {1},

  Comment                  = {108: ReadYes},
  File                     = {krishnamachari01kurtco.pdf:krishnamachari01kurtco.pdf:PDF},
  Review                   = {Speech Amp. Kurtosis spikes bracket multi-talker speech
* segments w/ k>1.5 usually bracket 'usable' speech
* usable: SNR of 1 talker > 10dB than the other talker
* kurtosis calc'ed from 40ms frames
* only brackets usable speech, doesn't locate
* 83-92% of single talker speech is spotted}
}

@Article{kuhn00eigenspkradapt,
  Title                    = {Rapid speaker adaptation in eigenvoice space},
  Author                   = {R. Kuhn and J. C. Junqua and P. Nguyen and N. Niedzielski},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc. },
  Year                     = {2000},
  Number                   = {6},
  Pages                    = {695-707},
  Volume                   = {8},

  Comment                  = {178: ReadYes},
  Review                   = {Very short seg. speech adapt. Models are linear comb of PCA'ed spkrs
* adjusts phoneme HMM obs vect means
* few adjustable params means works w/ little data and computation
* PLP features (Ellis says bad)
Eigenvoices:
* PCA of 120 speaker-specific models. 
* Store K largest of the 120 eigen vectors (these are the eigenvoices)
* 1st princ comp is sex
* new spkr is linear comb of these eigenvoices
* linear comb weights adjusted w/ MLED
* reduces # adjustable params from ~500 MLLR to 1,5 or 10 degrees
Performance:
* tested on spoken letter data
* 16% relative WER improvement w/ one letter of adaptation
* 26% WER improvement w/ 4 letters
* MLLR better for long sentences

* says discriminative training might be even better
* may want to remove amplitude in 2nd princ comp

Uses for meeting recorder
* change detection, probably not clustering}
}

@InProceedings{kumatani07mutInfBmFrm,
  Title                    = {MINIMUM MUTUAL INFORMATION BEAMFORMING FOR SIMULTANEOUS ACTIVE
SPEAKERS},
  Author                   = {Kenichi Kumatani and Uwe Mayer and Tobias Gehrig and Emilian Stoimenov},
  Booktitle                = {ASRU},
  Year                     = {2007},

  File                     = {kumatani07mutInfBmFrm.pdf:kumatani07mutInfBmFrm.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Adapts to separate two speakers based on mutual information, uses super-Guassian dists.
- 2 nice circular arrays, of course
- unlike generalized sidelobe canceler (GSC) can enhance lobes, not just cancel side lobes
- enanchements capture reflections, and there's some kind of phase compensation (it'a s subband BF)
- shown to be similar to geometric source separation GSS (which enhances coherence) but only for Gaussians
-super gaussians fit speech best
- this technique tries out three different super gaussian distributions (laplace, gamma, K0), the 2nd highest kurtosis worked best for ASR, prob b/c of super gaussian noise enhance.
- 1st pass ASR is very bad (but better than delay/sum), prob b/c of noise booth, but subequent 3 ASR adaptation passes greatly improve WER (by about 30%, down to 52% in best case (close talking mics: 21.6%).

Things to note for thesis:
- diarization was crucial, even though they had a partial source separation
- most beamforming and source separation in literature is not on realistic data like this was tested on (meeting data).
- refs to spatial aliasing fix, which can't be used for this alg. (and which, it turns out, I can't use either b/c it requires a calibration signal (see de Haan...))},
  Timestamp                = {2008.01.31}
}

@Article{kurita00bssDirec,
  Title                    = {Evaluation of blind signal separation method using directivity pattern under reverberant conditions},
  Author                   = {S. Kurita and H. Saruwatari and S. Kajita and K. Takeda and F. Itakura},
  Journal                  = {Unknown},
  Year                     = {2000},

  Comment                  = {240: ReadYes},
  Review                   = {Blind signal separation in reverb using mic array beam pattern 
* I didn't read much of this article 
* but one good trick was to do mixing matrices in freq domain so they're orthogonal (I should do that too)}
}

@Article{Kwok04kernPreImage,
  Title                    = {The pre-image problem in kernel methods},
  Author                   = {Kwok, J.T.-Y. and Tsang, I.W.-H.},
  Journal                  = {Neural Networks, IEEE Transactions on},
  Year                     = {2004},
  Number                   = {6},
  Pages                    = {1517-1525},
  Volume                   = {15},

  File                     = {Kwok04kernPreImage.pdf:Kwok04kernPreImage.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {KPCA reconstructed input pts, when transformed to feat space minimize dist. to feat space train pts (like MDS)

Advantages
* result is unique, won't get stuck in local minima, or depend upon nonlin. opt. 1st guess
* is purely algebraic, and thus faster

Disadvantages
* two approximations, one in feature space and another in input space.
* besides kernel tweaking must pick n, the # of neighbors 
* BakIr04LearnPreImage might be better/simpler (but IT PICKS THE WRONG DIGIT)
* Rathi06statShapeKPCA might be better: only one approx
* I don't like the nearest neighbors picking stuff. For lags, might have enough samples with bad lag pairs that the badness will be accurately reproduced, even for low PCA dims?

Basic idea is kind of like metric MDS. For each point to be noise reduced:
1.) transform to feature space
2.) find the distances to the n-nearest training points (in feature space)
3.) in training space find the location that, when transformed back to feature space will best preserve the feature space distances. This least squared minimization is actually done in input space, using a relationship between input space distances and feature space distances

Results
* seems to remove noise from digits fairly well
* polynomial works slightly worse than exponential kernel
* k-means clustering in feature space: reconstructed cluster means look much better than averages},
  Timestamp                = {2007.08.15},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1353287}
}

@InProceedings{kwon02spkrChngWdist,
  Title                    = {{SPEAKER} {CHANGE} {DETECTION} {USING} A {NEW} {WEIGHTED} {DISTANCE} {MEASURE}},
  Author                   = {Soonil Kwon and Shrikanth Narayanan},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {2537-2540},
  Volume                   = {4},

  Comment                  = {423: ReadNo},
  File                     = {kwon02spkrChngWdist.pdf:kwon02spkrChngWdist.pdf:PDF},
  Url                      = {http://sail.usc.edu/publications/ICSLP2002_kwon.pdf}
}

@Article{lam00DCTlaplace,
  Title                    = {A Mathematical Analysis of the {DCT} Coefficient Distributions for Images},
  Author                   = {Edmund Y. Lam and Joseph W. Goodman},
  Journal                  = {{IEEE} TRANSACTIONS ON IMAGE PROCESSING},
  Year                     = {2000},
  Number                   = {10},
  Volume                   = {9},

  Comment                  = {ReadNo},
  Review                   = {Derivation showing why DCT image coeffs are laplacian. Use for sparse coding theory?},
  Url                      = {http://ieeexplore.ieee.org/iel5/83/18833/00869177.pdf?isNumber=18833&prod=JNL&arnumber=869177&arSt=1661&ared=1666&arAuthor=Lam%2C+E.Y.%3B+Goodman%2C+J.W.}
}

@Article{Landauer98LatentSemAnIntro,
  author    = {Landauer, T. K. and Foltz, P. W., and Laham, D.},
  title     = {Introduction to Latent Semantic Analysis},
  journal   = {Discourse Processes},
  year      = {1998},
  volume    = {25},
  pages     = {259-284},
  comment   = {641:ReadYes},
  file      = {Landauer98LatentSemAnIntro.pdf:Landauer98LatentSemAnIntro.pdf:PDF},
  groups    = {semisupWorkshop07},
  owner     = {scotto},
  review    = {Nice Latent Analysis Intro for document clustering using SVD, not much math, focus on relationship to human learning
(also called "latent semantic indexing")

* SVD input matrix, X
 row: word counts
 column: document (in example, just document title)

 X=W*S*P (SVD)

* toss out W and S rows/cols for which S (eigenval on diagonal) is small
* See that X reconstructed with dim reduced W and P gives high weight to words that actually did not occur in a document's tilte, also gives low weight to some words that did. Makes sense in the example
* nce example showing how the correlation of reconstructed word counts is much higher within topics (and lower outside of a topic cluster) than the original word counts were.

* Vague description of tradiitonal LSA word count pre-processing:
 - log(word frequency + 1)
 - divide by cross-row (across documements) entropy (not sure if what p is)
 - the idea is to estimate importance of a word: low entropy (possibly, a diagnostic word since it is rare) means small divisor, means that counts of this word are accentuated.

* many descriptions of neat experiements comparing LSA to human learning eg. LSA fill-in-the-blank performance of TOEFL tests.},
  timestamp = {2007.06.17},
  url       = {http://lsa.colorado.edu/},
}

@Misc{langan92meanfieldimageseg,
  Title                    = {Use of the mean-field approximation in an {EM}-based approach to unsupervised stochastic model-based image segmentation},

  Author                   = {D. A. Langan and K. J. Molnar and J. W. Modestino and J. Zhang},

  Comment                  = {32: ReadNo},
  Review                   = {Relevant to speaker segmentation and clustering?}
}

@InProceedings{Lange05FusionofSimilarityClust,
  Title                    = {Fusion of Similarity Data in Clustering},
  Author                   = {Tilman Lange and Joachim M. Buhmann},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2005},

  Comment                  = {631:ReadYes},
  File                     = {Lange05FusionofSimilarityClust.pdf:Lange05FusionofSimilarityClust.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Probabilistic interp. of non-negative matrix factorization of simarity matrix yeilds a way to fuse multiple similarity matrices for clustering

* a kind of NMF used for clustering
* can be sped up with an online algorithm which starts with a subset of the data (avoiding the nptsXnpts similarity matrix)

Single View (one simlarity matrix)
* similarity matrix (like from a kernel) is normalized, interpreted as a joint prob of two pts being in same class
* two NMF factor matrices are conditional and joint probs; Bayes' rule or something, although I didn't quite get this
* an EM-like algorithm does the factoring (the thing that looks like a mixture prob isn't a prob, though, just an intermediate variable
* use the NMF factorization to calc prob of a point being in a class

Multi-View (multiple similarity matrices)
* simlilarity matrix is considered to be a mixture of similarity matrices, one for each view
* but still have only one W and one H NMF matrix for the whole problem
* tuning parameter controls sparseness (of mixture weights)

Model Selection
* must select # classes, and sparsity
* punts on # classes, claiming that ref [9] will solve it
* select sparsity param with a kind of cross-validation

Testing (not rigorous, or compared to benchmark)
* looks great on toy cocentric ring sample frequently used for spectral clustering
* seems to have detected regions of similar image texture (eyeball determination)},
  Timestamp                = {2007.05.28}
}

@Unpublished{Langville06NNMFinit,
  Title                    = {Initializations for the Nonnegative Matrix Factorization},
  Author                   = {Amy N. Langville and Carl D. Meyer and Russell Albright},
  Year                     = {2006},

  File                     = {Langville06NNMFinit.pdf:Langville06NNMFinit.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {SVD centroid is best way to inititialize Non-Negative Matrix Factorization (NNMF. This might have been a KDD 2006 preprint. Albright has a longer tech report that describes the kinds of NNMF used)

Also, Albright has a longer tech report version of this that describes the kinds of NNMF used},
  Timestamp                = {2007.03.01},
  Url                      = {http://www.cofc.edu/~langvillea/#Publications}
}

@InProceedings{laskowski04crosscorrMultispeakerVAD,
  Title                    = {Crosscorrelation-based Multispeaker Speech Activity Detection},
  Author                   = {Kornel Laskowski and Qin Jin and Tanja Schultz},
  Booktitle                = {Interspeech},
  Year                     = {2004},
  Pages                    = {973-976},

  File                     = {laskowski04crosscorrMultispeakerVAD.pdf:laskowski04crosscorrMultispeakerVAD.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {headmic vad w/ overlap det, v. similar to jin04mtngRecogRT04s},
  Timestamp                = {2008.02.24}
}

@InProceedings{laskowski07geomCorrVAD,
  Title                    = {A Geometric Interpretation of Non-Target-Normalized Maximum Cross-channel Correlation for Vocal Activity Detection in Meetings},
  Author                   = {Kornel Laskowski and Tanja Schultz},
  Booktitle                = {HLT/NAACL},
  Year                     = {2007},

  File                     = {laskowski07geomCorrVAD.pdf:laskowski07geomCorrVAD.pdf:PDF},
  Owner                    = {scotto},
  Timestamp                = {2008.02.24},
  Url                      = {http://www.cs.cmu.edu/~tanja/MyPublications.html}
}

@InProceedings{laskowski06mtngOverlapDetMultiChan,
  Title                    = {Unsupervised Learning of Overlapped Speech Model Parameters For Multichannel Speech Activity Detection in Meetings},
  Author                   = {Laskowski, K. and Schultz, T.},
  Booktitle                = {ICASSP},
  Year                     = {2006},
  Pages                    = {I-I},
  Volume                   = {1},

  Abstract                 = {The study of meetings, and multi-party conversation in general, is currently the focus of much attention, calling for more robust and more accurate speech activity detection systems. We present a novel multichannel speech activity detection algorithm, which explicitly models the overlap incurred by participants taking turns at speaking. Parameters for overlapped speech states are estimated during decoding by using and combining knowledge from other observed states in the same meeting, in an unsupervised manner. We demonstrate on the NIST Rich Transcription Spring 2004 data set that the new system almost halves the number of frames missed by a competitive algorithm within regions of overlapped speech. The overall speech detection error on unseen data is reduced by 36% relative},
  Doi                      = {10.1109/ICASSP.2006.1660190},
  File                     = {laskowski06mtngOverlapDetMultiChan.pdf:laskowski06mtngOverlapDetMultiChan.pdf:PDF},
  ISSN                     = {1520-6149},
  Keywords                 = {Gaussian processes, decoding, speech coding, speech recognition, unsupervised learningNIST Rich Transcription Spring 2004 data set, decoding, meetings, multichannel speech activity detection, overlapped speech model parameters, unsupervised learning},
  Owner                    = {scotto},
  Review                   = {Mari suggests},
  Timestamp                = {2008.02.24}
}

@InProceedings{lathoud03locSpkrSeg,
  Title                    = {Location based speaker segmentation},
  Author                   = {G. Lathoud and I. A. McCowan},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2003},
  Pages                    = {176-179},
  Volume                   = {1},

  Comment                  = {600:ReadYes},
  Review                   = {Loc feats w/ special rapidly switching TDE HMM overlap model
* 4 element mic array in meeting
* supervised training of HMM's
* time delay est (TDE) w/ GCC-PHAT, not SRP-PHAT like ajemera04
* HMM overlap model:
- models switching TDE estimates w/ 48-160ms switching states
- HMM for each possible 2-speaker overlap (pre-trained)
* somewhat cheating b/c looks like segments are pre-defined
Works better than Ceps coeffs
* single speakers: 0.98F w/ TDE HMM, 0.77F w/ LPCC feature HMM
* segs wer 5-10s duration (long)
HMM w/ overlap model
* 0.98F for single speaker test
* 0.90 for overlaps
* overlaps 1.5-5s in duration (long)
RELATIONSHIP W/ spectral culstering and switching HMM state (maila01 speactral clust paper, transition matrix)},
  Url                      = {http://ieeexplore.ieee.org/iel5/8535/26983/01198745.pdf?tp=&arnumber=1198745&isnumber=26983}
}

@InProceedings{lathoud03multiMicSpkrSeg,
  Title                    = {Segmenting Multiple Concurrent Speakers Using Microphone Arrays},
  Author                   = {Guillaume Lathoud and Iain A. McCowan and Darren C. Moore},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {2889-2892},

  Comment                  = {580: ReadNo},
  Review                   = {multi mic spkrseg w/ overlaps!!!}
}

@Book{lauritzen96gmbook,
  Title                    = {Graphical Models},
  Author                   = {S. L. Lauritzen},
  Publisher                = {Clarendon Press, Oxford},
  Year                     = {1996},

  Comment                  = {Print, ReadNo}
}

@InProceedings{lavner99protospkID,
  Title                    = {The Prototype Model in Speaker Identification },
  Author                   = {Y. Lavner and J. Rosenhouse and I. Gath},
  Booktitle                = {Eurospeech},
  Year                     = {1999},
  Pages                    = {771-774},
  Volume                   = {2},

  Comment                  = {128: ReadNo},
  Review                   = {Empirical studies indicating glottal is good ID feature?}
}

@InProceedings{leblanc98kurtosisSep,
  Title                    = {Speech separation by kurtosis maximization},
  Author                   = {J. P. LeBlanc and P. L. de Leon},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1998},
  Pages                    = {1029-1032},

  Comment                  = {28.5: ReadYes},
  Review                   = {Why Kurtosis works to separate speech. Theory, demo and rules of thumb.
Kurtosis Min v.s. Max
* Gaussian: k=3
* Clean Speech: larger kurtosis than Gaussian
* Comm. Signals: smaller kurtosis than Gaussian
* Speech separation: maximize kurtosis
* ref [7] has good discussion of Gaussianinity
* has equation for kurtosis
Justification for speech kurtosis
* Laplace/Gaussian are common speech models: mixtures have lower K
* new speech model Spherically Invariant Random Processes (STRP)
-- this also has lower Kurtosis when mixed
* says that speech temporal corr means that sometimes this isn't true
* but in practice, one speaker always had higher K than mixture
Experiment
* modifies Comm BSS alg. (CMA) to max kurtosis instead of min
* for some reason, this paper leaves out CMA's duplication penalty
* instantaneous, not convolutive demixer
* sometimes unmixes only one channel

Maybe use for overlap resolution?}
}

@Article{lee00multiKalmanSpch,
  Title                    = {Time-domain approach using multiple kalman filters and {EM} algorithm to speech enhancement with nonstationary noise},
  Author                   = {K. Y. Lee and S. Jung},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2000},
  Number                   = {3},
  Volume                   = {8},

  Comment                  = {232: ReadYes},
  Review                   = {Jointly estimates change in noise and speech model coeffs 
* noise speech are assumed to be outputs of AR's driven w/ white noise (why does that work?) 
* state est determines weighting of parallel filters' contributions to output 
* seems to work 
* use update equs here to track pitch of multiple speakers -- but how many models to run? 
* viterbi-like model keeps track of state-sub optimal but not factorial # of models}
}

@InProceedings{lee01icaBaseMaleFem,
  Title                    = {{THE} {STATISTICAL} {STRUCTURES} {OF} {MALE} {AND} {FEMALE} {SPEECH} {SIGNALS}},
  Author                   = {Te-Won Lee and Gil-Jin Jang},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},

  Comment                  = {350: ReadYes},
  Review                   = {Comparison of ICA bases of Male and Female; also compared to PCA
ICA basis 
* are W; y=Wx in ICA equation for 8ms (64 sample) spch segs, x
* sort-of sinusoidal pulses, localized in time
* ICA bases are really a time/frequency 
* freqs change in critical bands; not octave steps like wavelets
* trained using Generalized Gaussian density prior on separated coeffs
* I wonder: is Abdallah sparse music EM a better training algorithm
PCA basis
* almost no time localization
* male and female look the same
Male v.s. Female
* females have 2 pulses, generally, and are less time-localized
* male speech more like Gabor wavelets; female more like Fourier xform
Speculation
* ICA bases are as good as MFCCs for speech recog
* might be good for speaker recog},
  Url                      = {http://bulsai.kaist.ac.kr/~jangbal/research/papers/icassp01-1.pdf}
}

@Article{lee02icaImgClass,
  Title                    = {Unsupervised image classification, segmentation and enhancement using {ICA} mixture models},
  Author                   = {T-W. Lee and M.S. Lewick},
  Journal                  = {{IEEE} Transactions on Image Processing},
  Year                     = {2002},
  Number                   = {3},
  Pages                    = {270-279},
  Volume                   = {11},

  Comment                  = {ReadNo},
  Review                   = {overlapped speaker ID?? or clustering?
builds up classes iteratively so kinda like agglomerative clustering},
  Url                      = {http://ieeexplore.ieee.org/iel5/83/21305/00988960.pdf?isNumber=21305&prod=JNL&arnumber=988960&arSt=270&ared=279&arAuthor=Te-Won+Lee%3B+Lewicki%2C+M.S.}
}

@Article{lee99bssOver,
  Title                    = {Blind source separation of more sources than mixtures using overcomplete representation},
  Author                   = {Te-Won Lee and Lewicki, M.S. and Girolami, M. and Sejnowski, T.J.},
  Journal                  = {{IEEE} Signal Processing Letters},
  Year                     = {1999},
  Number                   = {4},
  Pages                    = {87-90},
  Volume                   = {6},

  Comment                  = {ReadNo},
  Review                   = {referenced by Hockreiter},
  Url                      = {http://ieeexplore.ieee.org/iel4/97/16243/00752062.pdf?isNumber=16243&prod=JNL&arnumber=752062&arSt=87&ared=90&arAuthor=Te-Won+Lee%3B+Lewicki%2C+M.S.%3B+Girolami%2C+M.%3B+Sejnowski%2C+T.J.}
}

@Article{lee99icaMixClass,
  Title                    = {Unsupervised Classification with Non-Gaussian Mixture Models using {ICA} },
  Author                   = {Lee, T.-W. and Lewicki, M.S. and Sejnowski, T.J. },
  Journal                  = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {1999},
  Volume                   = {11},

  Comment                  = {ReadNo},
  File                     = {lee99icaMixClass.ps.gz:lee99icaMixClass.ps.gz:PDF},
  Url                      = {http://www.cnl.salk.edu/~tewon/Public/nips99.ps.gz}
}

@InProceedings{lee00ggmICA,
  Title                    = {The Generalized Gaussian Mixture Model Using {ICA}},
  Author                   = {T.-W. Lee and M. S. Lewicki},
  Booktitle                = {Intl. Workshop on Independent Component Analysis},
  Year                     = {2000},
  Pages                    = {239-244},

  Comment                  = {358: ReadYes},
  Review                   = {Sparse code blind clustering/classifier
* Generalized Gaussian also used by jang02monoBSStimeBase for monaural speech unmixing
* # classes known
* but maybe this # could be found just by ML? See penny00modelSel
* works for underdetermined (non-square, more sources than dims)

Generalized Gaussian source density model
* handles non-Gaussian dists, param q makes it more or less Gaussian
* has three params: 
-- mu,sig (as usual, directly from data) 
-- beta (sol'n is more complicated)
* univariate
Generalized Gaussian ICA
* obervations are x=As; s=independent sources
* estimates both s and A
* GG dist kurtosis is closed form: max kurtosis drive s to indep?
* details must be in Lewicki2000, "a flexible prior..." reference
Generalized Mixture model
* like a GMM but is mixture of GG's
* prob is a mixture of linear combinations of source outputs
* estimated for each class:
- source density (via beta)
- bias (where this come from? Seems to be an ICA standard)
- mixing matrix for each source (they call it the "basis function", A)
* Independent sources are =not= the classes
- there's a set for each class
- independent sources make the mixing matrix =sparse= (few coeffs)
- since they're chosen to max Kurtosis (see other talks for
- heuristic for why this makes the code sparse)
Blind Classification (clustering, really) Experiment
* four classes (fitting GG model), two dims
* no class labels
* learn GG dist params (sources, mixing matrices, bias)
* was a little better than AutoClass blind EM clustering algorithm
* nearly as good as when classification done with true GG params

* but maybe this # could be found just by ML? See penny00modelSel
* works for underdetermined (non-square, more sources than dims)}
}

@InProceedings{lee98icaCoctail,
  Title                    = {Combining Time-Delayed Decorrelation and {ICA}: Towards Solving the Cocktail Party Problem},
  Author                   = {Te-Won Lee and Andreas Ziehe and Reinhold Orglmeister and Terrence Sejnowski},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1998},
  Pages                    = {1249-1253},
  Volume                   = {2},

  Comment                  = {331: ReadYes},
  Review                   = {Separation Theory
* Feedforward (FIR) better than feedback (IIR)
- FIR can approx general inverse system 
- e.g. nonmin phase where 1st echo weaker than 2nd
* Infomax approach: max joint entropy (surprise) of separated signals
* freq domain solution: w/ overlap and save synthesis
Time Delayed Decorrelation is preprocessing step (like Anemuller?)
* this diagonalizes the covariance matrix
* doubles convergence speed (but is still very slow at 5s)
* TDD uses only 128 taps}
}

@InProceedings{Leeuwen06AMIspeakerDiariz,
  author    = {David A. van Leeuwen and Marijn Huijbregts},
  title     = {The {AMI} speaker diarization system for {NIST RT06s} meeting data},
  booktitle = {{NIST RT06} workshop},
  year      = {2006},
  file      = {Leeuwen06AMIspeakerDiariz.pdf:Leeuwen06AMIspeakerDiariz.pdf:PDF},
  groups    = {ovdetasru07},
  owner     = {scotto},
  review    = {two methods of overlap handling
 1.) average overlap: I think this meant extending?
 2.) 2 speaker GMM. I don't think this helped},
  timestamp = {2007.07.16},
}

@InProceedings{Leeuwen07ProgressinAMIDA,
  author    = {David A. van Leeuwen and Matej Konecny},
  title     = {Progress in the {AMIDA} speaker diarization system for meeting data},
  booktitle = {{NIST} RT07 Workshop},
  year      = {2007},
  file      = {Leeuwen07ProgressinAMIDA.pdf:Leeuwen07ProgressinAMIDA.pdf:PDF},
  groups    = {ovdetasru07},
  owner     = {scotto},
  review    = {Tried to handle overlaps for rt07. Not very sucessful. Used ICSI system.
* used ICSI BeamformIt, etc.
* says 3.5% DER difference with and without overlaps (RT07S)
* some trick w/ most talkative speaker
* I don't think they were successful in detecting overlap...},
  timestamp = {2007.07.16},
}

@Article{leggetter95maximum,
  Title                    = {Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models},
  Author                   = {C. J. Leggetter and P. C. Woodland},
  Journal                  = {Computer Speech and Language},
  Year                     = {1995},
  Number                   = {2},
  Pages                    = {171--185},
  Volume                   = {9},

  Comment                  = {Print, ReadNo},
  Review                   = {Or printed but this seems to be the 1st paper on this. see also leggetter94linAdapt}
}

@Misc{feder-decoupled,
  Title                    = {Decoupled Stochastic Mapping},

  Author                   = {J. J. Leonard and H. J. S. Feder},

  Comment                  = {Print, ReadNo},
  Url                      = {citeseer.nj.nec.com/leonard99decoupled.html}
}

@Misc{leonard99stochmap,
  Title                    = {Decoupled stochastic mapping},

  Author                   = {J. J. Leonard and H. J. S. Feder},

  Comment                  = {41.0: ReadNo},
  File                     = {leonard99stochmap.pdf:leonard99stochmap.pdf:PDF},
  Review                   = {Relevant to speaker location features, esp. associating speaker id w/ location id?},
  Url                      = {http://citeseer.ist.psu.edu/leonard99decoupled.html}
}

@Misc{levyXXkalman,
  Title                    = {The {Kalman} filter},

  Author                   = {L. J. Levy},

  Comment                  = {45.5: ReadNo},
  Review                   = {Kalman filter web page. breezy introduction. relevant to speaker motion tracking or reverb switching when head turns? pitch tracking w/ multi-speakers?}
}

@Article{lewis01cochanSpch,
  Title                    = {Cochannel speaker count labelling based on the use of cepstral and pitch predicton derived features},
  Author                   = {M. A. Lewis and R. P. Ramachandran},
  Journal                  = {Pattern Recognition},
  Year                     = {2001},
  Pages                    = {449-507},
  Volume                   = {34},

  Comment                  = {ReadNo},
  Review                   = {Overlap detection. Referenced in 2004 Wrigley paper & compared there}
}

@Misc{li99hmm2dseg,
  Title                    = {Image classification by a two dimensional hidden markov model},

  Author                   = {A. Najmi J. Li and R. M. Gray},

  Comment                  = {33: ReadNo},
  Review                   = {Relevant to speaker segmentation and clustering?}
}

@Article{li02endpoint,
  Title                    = {Robust Endpoint Detection and Energy Normalization for Real-Time Speech and Speaker Recognition},
  Author                   = {Qi Li and Jinsong Zheng and Augustine Tsai and Qiru Zhou},
  Journal                  = {IEEE Trans., Speech and Audio Proc.},
  Year                     = {2002},
  Number                   = {3},
  Pages                    = {146-157},
  Volume                   = {10},

  Comment                  = {415: ReadYes},
  Review                   = {Energy based VAD uses image proc. edge detection and state machine
* cepstral engery coeff in dB is only input feature
* endpoint edges modelled w/ exponential equ --> img proc opt. edge det
* log energy convolved w/ edge det filter FIR
* energy 1st normalized by max energy
* max energy updated by comparing mean energy to current max estimate
* 3 state machine
- silence, leaving speech, in speech
- transitions at fixed thresholds (compared to edge det output)
* realtime
* Testing:
- 12 telephone databases
- SNR=20 to 5dB?
- improves digit/ascii char WER on 7 of 12 databases
- 51% improve in 2; worse than 6% reduction in 2},
  Url                      = {http://ieeexplore.ieee.org/iel5/7486/20365/00940810.pdf?isNumber=20365&prod=IEEE+CNF&arnumber=940810&arSt=233&ared=236+vol.1&arAuthor=Qi+Li%3B+Jinsong+Zheng%3B+Qiru+Zhou%3B+Chin-Hui+Lee%3B}
}

@InProceedings{Li06NNMFrelationships,
  Title                    = {The Relationships Among Various Nonnegative Matrix Factorization Methods for Clustering},
  Author                   = {Tao Li and Chris Ding},
  Booktitle                = {ICDM '06: Proc., Sixth Intl. Conf. on Data Mining},
  Year                     = {2006},
  Pages                    = {362--371},
  Publisher                = {IEEE Computer Society},

  Doi                      = {http://dx.doi.org/10.1109/ICDM.2006.160},
  File                     = {Li06NNMFrelationships.pdf:Li06NNMFrelationships.pdf:PDF},
  ISBN                     = {0-7695-2701-9},
  Owner                    = {scotto},
  Review                   = {Overview of NMF formulations and their usages; clarify normalization, convergence rate, optimality issues
* also mentions co-clustering aka simultaneous clustering},
  Timestamp                = {2007.03.01},
  Url                      = {http://portal.acm.org/citation.cfm?id=1193207.1193313&coll=GUIDE&dl=GUIDE&CFID=15151515&CFTOKEN=6184618#}
}

@InProceedings{lieb00ldaRasta,
  Title                    = {{LDA} derived cepstral trajectory filters in adverse environmental conditions},
  Author                   = {M. Lieb and R. Haeb-Umbach},
  Booktitle                = {{IEEE} ?},
  Year                     = {2000},

  Comment                  = {277: ReadNo},
  Review                   = {But sorta talks about RASTA-like things in reverb}
}

@Article{lin02spchSegFuz,
  Title                    = {{NOISY} {SPEECH} {SEGMENTATION}/{ENHANCEMENT} {WITH} {MULTIBAND} {ANALYSIS} {AND} {NEURAL} {FUZZY} {NETWORKS}},
  Author                   = {{Chin-Teng} LIN and {Rui-Cheng} WU and {Gin-Der} WU},
  Journal                  = {Intl. Journal of Pattern Recognition and Artificial Intelligence},
  Year                     = {2002},
  Number                   = {7},
  Pages                    = {927-955},
  Volume                   = {16},

  Comment                  = {422: ReadYes},
  File                     = {lin02spchSegFuz.pdf:lin02spchSegFuz.pdf:PDF},
  Review                   = {Fuzzy recog VAD uses sum of power in bands estimated to be above noise
* selects Mel spectral bands by how much larger they are than noise
* # bands selected linearly upon input energy to noise ratio
* bogus noise estimate from 1st 5 frames (Noise_freq)
* Inputs to ATF-based SONFIN (fuzzy) word boundary detector:
- sum(energies of selected bands)
- zero crossing
- noise at start
* Two fuzzy outputs: speech and noise.
* Refined fuzzy: replace sum(big energies) with max(big energies)
* Further fuzzy refine (RSONFIN): past output feedback so is recursive
* speech recog then done by another fuzzy system 
* tested down to 0 dB SNR},
  Url                      = {http://www.worldscinet.com/ijprai/16/preserved-docs/1607/S0218001402002076.pdf}
}

@Article{lingjie01fusionConvex,
  Title                    = {Convex optimization approach to identify fusion for multisensor target tracking},
  Author                   = {Lingjie Li; Zhi-Quan Luo; Wong, K.M.; Bosse, E.},
  Journal                  = {Systems, Man and Cybernetics, Part A, {IEEE} Transactions on},
  Year                     = {2001},
  Number                   = {3},
  Pages                    = {172-178},
  Volume                   = {31},

  Comment                  = {ReadNo},
  Review                   = {relevant to mono/ARMA/convex idea? Looks easy to read.},
  Url                      = {http://ieeexplore.ieee.org/iel5/3468/20026/00925656.pdf?isNumber=20026&prod=JNL&arnumber=925656&arSt=172&ared=178&arAuthor=Lingjie+Li%3B+Zhi-Quan+Luo%3B+Wong%2C+K.M.%3B+Bosse%2C+E.}
}

@Article{liu01pitchEstHarm,
  Title                    = {Fundamental Frequency Estimation Based on the Joint Time-Frequency Analysis of Harmonic Spectral Structure},
  Author                   = {Der-Jenq Liu and Chin-Teng Lin},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2001},
  Number                   = {6},
  Pages                    = {609-621},
  Volume                   = {9},

  Comment                  = {456: ReadNo},
  Review                   = {F0 est, maybe relevant to Furui overlap det or maybe speech model ICA?}
}

@InProceedings{lleida98micArrASR,
  Title                    = {Robust continuous speech recognition system based on a microphone array},
  Author                   = {E. Lleida and J. Fernandez and E. Masgrau},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1998},
  Pages                    = {241-244},
  Volume                   = {1},

  Comment                  = {588:ReadYes},
  Review                   = {Microphone Array ASR w/ localization and speaker ID combined 
* special variable-spaced array avoids spatial aliasing w/o loss of resolution
* DOA result is tagged as desirable speech (or not) w/ use of GMM spkrID models (pretrained?)
* helps WER a fair amt.},
  Url                      = {http://ieeexplore.ieee.org/iel4/5518/14820/00674412.pdf?tp=&arnumber=674412&isnumber=14820}
}

@Article{lo98waveletHRTF,
  Title                    = {Wavelet Analyis of head-related transfer functions},
  Author                   = {T. F. Lo and Z. Wu and F. H. Y. Chan and F. K. Lam and J. C. K. Chan},
  Journal                  = {Proc. {IEEE} Eng. in Med. and Bio. Soc.},
  Year                     = {1998},
  Number                   = {3},
  Pages                    = {1549-1552},
  Volume                   = {20},

  Comment                  = {223: ReadYes},
  Review                   = {Just did a wavelt xform of impulse responses...}
}

@InProceedings{logan00mfccSpchMusic,
  Title                    = {Mel Frequency Cepstral Coefficients for Music Modeling},
  Author                   = {Beth Logan},
  Booktitle                = {ISMIR},
  Year                     = {2000 },

  Comment                  = {402: ReadYes},
  File                     = {logan00mfccSpchMusic.pdf:logan00mfccSpchMusic.pdf:PDF},
  Review                   = {MFCC's are reasonable speech/music discrim. features on Broadcast News
1.) Mel-spacing works for speeech/music 
- 3 hrs of BN, 14% labelled music
- GMM of linear v.s. mel-spaced cepstral coeffs (i.e. MFCCs)
- MFCC's significantly better e.g. 3.6% error v.s. 10.7%
2.) 2nd DCT works for decorrelating music cepstra
- decorrelating lets use use diag cov GMM (as in 1.))
- KL transform (PCA) will definitely diagonalize music
- DCT bases visually look like KL eigenvecs
- so that's OK too},
  Url                      = {http://ciir.cs.umass.edu/music2000/papers/logan_paper.pdf}
}

@TechReport{lopez00acdClustBN_TR,
  Title                    = {Acoustic change detection and clustering on broadcast news},
  Author                   = {J. F. Lopez and D. P. W. Ellis},
  Institution              = {ICSI},
  Year                     = {2000},
  Number                   = {TR-00-006},

  Comment                  = {120: ReadYes},
  Review                   = {Broadcast news speaker/acoustic change detector 
* Neural net acd (SVM might pick up struct better) 
* NN acd misses almost now bkpts but reduces candidates to 0.76 pct.

* assumes no overlaps 
* features are ordinary cepstral coeffs 
* PLP works worse for ACD 
* says that close to limit with this idea 
* not sure if # talkers was given 
* see also: lopez00changedet }
}

@InProceedings{lopez00changedet,
  Title                    = {Using acoustic condition clustering to improve acoustic change detection on Broadcast News},
  Author                   = {J. F. Lopez and D. P. W. Ellis},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2000},

  Comment                  = {148: ReadYes},
  Review                   = {Broacast News seg/clust: NN seg candidates, BIC-derived clust refine
* 12th order PLP for bkpt candidate, 11-15 ceps for clustering
* PLP used because bkpts are best for recognizing speech
Neural Net classifier is fed PLP frames, generates brkpt candidates
* 9 frames -> NN -> 4 spch types + nonspch -> 3 non => bkpt candidate
BIC deletes some NN bkpt candidates
* delete bkpt if BIC test is negative
* BIC lambda tweaking is necessary, depends heavily on feat. dim.
* this alg from Daben Liu `99 (look up), maybe an unusual BIC
Clustering further deletes change points
* extra clustering reduced equal error rate (EER) from 26.5% to 18%

* BIC lambda had to be tuned again
* distance measure: adaptive linear combo of BIC and interclust dist
Results
* Tested on Hub4 1997
* 18% EER
* would like to compare w/ others but they have different test data or figures of merit
* see also lopez00acdClustBN}
}

@InProceedings{lou01bssNumSource,
  Title                    = {Blind Source Separation for Changing Source Number: A Neural Network Approach with a Variable Structure},
  Author                   = {Shun-Tian Lou and Xian-Da Zhang},
  Booktitle                = {Independent Components Analysis and Signal Separation},
  Year                     = {2001},
  Pages                    = {384-379},

  Comment                  = {ReadNo},
  Review                   = {simple contrast function?},
  Url                      = {http://ica2001.ucsd.edu/}
}

@InProceedings{lovekin02usableAPPC,
  Title                    = {Adjacent pitch period comparison ({APPC}) as a usability measure of speech segments under co-channel conditions},
  Author                   = {Jereme Lovekin and Kasturi Rangan Krishnanmachari and Robert E. Yantorno},
  Booktitle                = {ISPACS},
  Year                     = {2001},

  Comment                  = {286: ReadYes},
  Review                   = {Overlapped two talker speech is "usable" when pitch pulses look the same
* "usable" declared when summed adjacent pulse diff small
-- comparison done in time
-- I think this would fail in noise or reverb (tested on TIMIT)
-- I think should compare in freq, not time (reverb'ed 0's ignorable)
* isn't this a time domain version of SAPVR??
* only works for voiced segments
* 70% co-channel TIMIT speech can be used to ID speakers 
-- usable "truth" is 20dB TIR criteria (test @ 0dB average)
-- chunks are short: are they really IDable w/ that short a sample?
* this is fused w/ APPC-residual in Smolenski02fusionIndep
-- not really "usable" if not ID'able
* "Usable" here == "heavily overlapped" rejection (easier)
-- would this work well for any overlap detection (harder)?
* got 74.5% of usable speech by this definition w/ 24.4% false detect
* pitch detection by autocorr. peaks
-- Brandnstein LPC residual pitch pulse must better in reverb & noise
-- do Brandstein mic array pitch pulse detect?
* most missed frames in voiced/unvoiced onset/offset 
-- less of a problem if "normalize" (before thresh, divide by RMS?)
* not clear if APPC is doing VAD or if it is being used to qualify some other VAD},
  Url                      = {http://www.temple.edu/speech_lab/ISPACS_2001.PDF}
}

@InProceedings{lovekin01usable,
  Title                    = {Developing usable speech criteria for speaker identification technology},
  Author                   = {J. M. Lovekin and R. E. Yantorno and K. R. Krishnamachari},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {421-424},
  Volume                   = {1},

  Comment                  = {105: ReadYes},
  Review                   = {* Speaker ID OK when >20dB main talker to interferer ratio (TIR)
* Spectral Autocorr Ratio (SAR) is reasoable proxy for TIR
* sprkID peformance about equal when selecting based on SAR or TIR
* (but cheats, since TIR is used to assign sprkID data to right spkr)
* tested on really low quality noisy phone data
* SpkrID worse when used on only voiced data (95%->75%)}
}

@InProceedings{hui-ling99vtEstConv,
  Title                    = {Joint estimation of vocal tract filter and glottal source waveform via convex optimization},
  Author                   = {Hui-Ling Lu and Smith, J.O., III},
  Booktitle                = {Applications of Signal Processing to Audio and Acoustics, {IEEE} Workshop on},
  Year                     = {1999},
  Pages                    = {79-82},

  Comment                  = {ReadNo},
  Review                   = {relevant to mono/ARMA/convex idea?},
  Url                      = {http://ieeexplore.ieee.org/search97/s97is.vts?Action=FilterSearch&SearchPage=VSearch.htm&ResultTemplate=adv_crst.hts&Filter=fld_sch.hts&ViewTemplate=lpdocview.hts&queryText=JOINT+ESTIMATION+OF+VOCAL+TRACT+FILTER+AND+GLOTTAL+SOURCE+WAVEFORM+VIA+CONVEX+OPTIMIZATION&collection=jour&collection=conf&collection=stds&collection=pprint&py1=&py2=2002&SortField=pyr&SortOrder=desc&ResultCount=15}
}

@InProceedings{lu02spkrChngRealTime,
  Title                    = {{REAL}-{TIME} {UNSUPERVISED} {SPEAKER} {CHANGE} {DETECTION}},
  Author                   = {Lie Lu and Hong-Jiang Zhang},
  Booktitle                = {Int'l Conf., Pattern Recognition (ICPR)},
  Year                     = {2002},
  Pages                    = {358-361},

  Comment                  = {424: ReadNo},
  Url                      = {http://research.microsoft.com/users/llu/Publications/ICPR02_SpkSeg.PDF}
}

@InProceedings{luo94spkrsep,
  Title                    = {A speech separation system that is robust to reverberation},
  Author                   = {H. Luo and P. Denbigh},
  Booktitle                = {Proc., Intl. Conf. on Speech, Image Processing and Neural Networks},
  Year                     = {1994},
  Pages                    = {339-42},
  Publisher                = {IEEE},

  Comment                  = {207: ReadYes},
  Review                   = {Binaural spch separator: harmonic sieve, ITD from bin avg disambiguates,
* reverb nulls ITD AOA (zeros some freq bins)
* his sol'n: average (but isn't outlier removal or power thresh better?)
Pitch Tracking
* heuristics generate simplified spectal peaks
* 3 step pitch extraction, removes weaker talker and iterates
* 2D harmonic sieve enforces freq amp continuity
* when both unvoiced, use ITD to allot bin pwr to talkers
* ignores freqs about 3K
* ITD used only to diambiguate pitch crossings and when unvoiced
* maybe use for overlap resolution? }
}

@Article{luo04SGdiff,
  Title                    = {Axial Strain Calculation Using a Low-Pass Digital Differentiator in Ultrasound Elastography},
  Author                   = {Luo, Kianwen and Bai, Jing and He, Ping and Ying, Kui},
  Journal                  = {{IEEE} trans. on ultrasonics, ferroelectrics, and freq. ctrl.},
  Year                     = {2004},
  Number                   = {9},
  Pages                    = {1119-1127},
  Volume                   = {5},

  Comment                  = {ReadNo},
  Review                   = {Reference for Savitzky-Golay differentiator. Several types compared},
  Url                      = {http://www.ieee-uffc.org/archive/uffc/trans/Toc/abs/04/t0491119.htm}
}

@Misc{macchiaXXhaas,
  Title                    = {Attain perfect feel quickly and easily by {Haas} effect quantising},

  Author                   = {C. Macchia},

  Comment                  = {220: ReadYes},
  Review                   = {If similar sounds occur 20-30ms apart, you only hear the 1st and seems about twice as loud
* he theorizes that humans echolocate mainly on transients (makes sense since periodic signals would be ambiguous every period but does this agree w/ what's in the literature -- don't they switch or something?)}
}

@InProceedings{Macho06RobustSpeechActivity,
  Title                    = {Robust Speech Activity Detection in Interactive Smart-Room Environments.},
  Author                   = {Dusan Macho and Climent Nadeu and Andrey Temko},
  Booktitle                = {MLMI},
  Year                     = {2006},
  Pages                    = {236-247},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Ee                       = {http://dx.doi.org/10.1007/11965152_21},
  Owner                    = {scotto},
  Timestamp                = {2007.03.13}
}

@InProceedings{mackay92bayesComp,
  Title                    = {Bayesian Model Comparison and Backprop Nets},
  Author                   = {David J.C. MacKay},
  Booktitle                = {Neural Information Processing Systems 4},
  Year                     = {1992},
  Pages                    = {839-846},

  Comment                  = {ReadNo},
  File                     = {mackay92bayesComp.pdf:mackay92bayesComp.pdf:PDF},
  Review                   = {The BIC paper referenced by Hansen "Independent compononent detection..."},
  Url                      = {http://www.inference.phy.cam.ac.uk/mackay/nips91.pdf}
}

@Article{MacKay192neuralAutoRelDet,
  Title                    = {A practical Bayesian framework for backpropagation
networks},
  Author                   = {MacKay, D. J. C.},
  Journal                  = {Neural Computation},
  Year                     = {1992},
  Pages                    = {448?472.},
  Volume                   = {4},

  Owner                    = {scotto},
  Review                   = {Primary ref for automatic relevance determination (ARD)},
  Timestamp                = {2008.01.30}
}

@Article{mackay94hierDircheletLM,
  Title                    = {A Hierarchical Dirichlet language model},
  Author                   = {D. J. J. MacKay},
  Journal                  = {Natural language engineering},
  Year                     = {1994},
  Number                   = {1},
  Volume                   = {1},

  Comment                  = {76: ReadNo},
  Review                   = {Hierarchical language model smoothing.
* maybe has a good explanation of Dirchlet prior
* possibly a way to do better than autoclass cheeseman-stutz clustering on classes w/ few examples. }
}

@Misc{mchagnolleau99spkrdet,
  Title                    = {Detection of target speakers in audio databases},

  Author                   = {I. Magrin-Chagnolleau and A. E. Rosenberg and S. Parthasarathy},

  Comment                  = {19.5: ReadNo},
  Review                   = {Speaker ID, broadcast news}
}

@Article{mahmoudi98wavWien,
  Title                    = {Combined {W}iener and coherence filtering in wavelet domain for microphone array speech enhancement},
  Author                   = {D. Mahmoudi and A. Drygajlo},
  Journal                  = {{IEEE} ?},
  Year                     = {1998},
  Pages                    = {385-388},

  Comment                  = {261: ReadYes},
  Review                   = {Source location assumed known 
* do noise reduction on wavelet coeffs after BF 
* sort of stomps on coeffs if not coherent w/ pre-BF coeff (BF adds speech constructively; not noise) 
* says delay & sum BF has probs w/ low freq: not clear that this doesn't => probs for pitch based BF? 
* similar to FFT approach in [slyh `93] but this sounds natural while [slyh] doesn't 
* not clear that this works in reverb 
* LAR improved by this approach (LAR is speech qual. measure) }
}

@Article{maila01randSpectSeg,
  Title                    = {A Random Walks View of Spectral Segmentation A Random Walks View of Spectral Segmentation A Random Walks View of Spectral Segmentation},
  Author                   = {Marina Maila and Jianbo Shi},
  Journal                  = {Proc. AI and Statistics},
  Year                     = {2001},

  Comment                  = {ReadNo},
  File                     = {maila01randSpectSeg.ps:maila01randSpectSeg.ps:PDF},
  Review                   = {Relates Ng Spectral clustering to Markov transition (HMM)
* use to combine w/ HMM clustering??},
  Url                      = {http://www.cis.upenn.edu/~jshi/papers/aistats.ps}
}

@InProceedings{malah99vadNonStat,
  Title                    = {Tracking speech-presence uncertainty to improve speech enhancement in non-stationary noise environments },
  Author                   = {David Malah and Richard V. Cox and Anthongy J. Accardi},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999},
  Pages                    = {789-792},
  Volume                   = {2},

  Comment                  = {412: ReadYes},
  Review                   = {Per FFT bin noise attenuation based on adaptive SNR estimate
* speech/nonspeech based simply on independent FFT bin energy ratios
* attenuation in each FFT bin based on per-bin SNR estimate
* noise spectrum estimated and tracked based on SNR-based absence of speech detection
* statistical motivation for some thresholds and smoothing (MM-LSA)
* realtime focus
* referenced by Zak's VAD paper (shafran03asrVad)},
  Url                      = {http://ieeexplore.ieee.org/iel4/6110/16374/00759789.pdf?isNumber=16374&prod=IEEE+CNF&arnumber=759789&arSt=789&ared=792+vol.2&arAuthor=Malah%2C+D.%3B+Cox%2C+R.V.%3B+Accardi%2C+A.J.%3B}
}

@Misc{maleh97comparison,
  Title                    = {Comparison of voice activity detection algorithms for wireless personal communications systems},

  Author                   = {K. Maleh and P. Kabal},
  Year                     = {1997 },

  Comment                  = {100: ReadYes},
  Review                   = {EVRC VAD better than TOS or GSM VAD
* IECM removes isolated errors
* VAD works better on LPC residual than when fed speech waveform },
  Text                     = {K. E. Maleh and P. Kabal, Comparison of voice activity detection algorithms for wireless personal communications systems, in Canadian Conf. on Electrical and Computer Engineering, vol. 2, pp. 470--473, 1997.},
  Url                      = {citeseer.nj.nec.com/152653.html}
}

@Article{Malinowski77imbedErrFun,
  Title                    = {Determination of the number of factors
and the experimental error in a data matrix},
  Author                   = {Malinowski, E. R.},
  Journal                  = {Anal. Chem.},
  Year                     = {1977},
  Number                   = {4},
  Pages                    = {612-617},
  Volume                   = {47},

  Owner                    = {scotto},
  Review                   = {first reference for IEF (imbedded error function), determining the number of parameters (ni PCA?)},
  Timestamp                = {2008.01.28}
}

@MastersThesis{malioutov03sparseLoc,
  Title                    = {A Sparse Signal Reconstruction Perspective for Source Localization with Sensor Arrays },
  Author                   = {Dmitry M. Malioutov},
  School                   = {Massachusetts Institute of Technology},
  Year                     = {2003},

  Comment                  = {592:ReadYes},
  File                     = {malioutov03sparseLoc.pdf:malioutov03sparseLoc.pdf:PDF},
  Review                   = {Focusing coeffs form overcomplete basis; localization is sparsest fit
* good localization overview
* clever conversion of localization into sparse bases proejction
* good refs on sensor location calibration
* has a couple refs for calibration with spatial aliasing 
* does not handle spatial aliasing, though
* lambda/2 spacing assumed},
  Url                      = {http://ssg.mit.edu/~mcetin/dmitry/malioutov_MS_thesis.pdf}
}

@InProceedings{mami02spkrIDanchor,
  Title                    = {{SPEAKER} {IDENTIFICATION} {BY} {LOCATION} {IN} {AN} {OPTIMAL} {SPACE} {OF} {ANCHOR} {MODELS}},
  Author                   = {Yassine Mami and Delphine Charlet},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {1333-1336},

  Comment                  = {ReadNo},
  Url                      = {/g/ssli/html/proceedings/icslp02/ICSLP/PDF/INDEXSCR.PDF}
}

@InProceedings{Mandel06EMAlgorithmLocalizing,
  Title                    = {An {EM} Algorithm for Localizing Multiple Sound
Sources in Reverberant Environments},
  Author                   = {Michael I. Mandel and Daniel P. W. Ellis and Tony Jebara},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2006},

  Comment                  = {633:ReadYes},
  File                     = {Mandel06EMAlgorithmLocalizing.pdf:Mandel06EMAlgorithmLocalizing.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Estimate time-freq speaker ID mask based on binaural phase delay
* delay noise is modeled as convolutive (like w/ reverb)
 - is modeled w/ mixture of zero mean gaussians
 - I believe that the theoretical delay is calculated for each delay bin (as a phase) and then the GMM models the difference (noise) between that and what was measured
* for each a GMM, with Nspeakers*NquantizedDelays*NmixturesPerSpeaker
* is a time-frequency mask, w/ delay estimated from phase angle between mic pair
* Gaussian models delay estimate; EM estimates ownership of delay/freq/speaker and mixture variance

Testing: 
* TIMIT speech, binaural head model, reverberant classroom setting
* mask seems to fit better than two other methods (various figures of merit)},
  Timestamp                = {2007.05.28}
}

@Article{mangold99hmmTOA,
  Title                    = {Applying pattern recognition techniques based on hidden Markov models},
  Author                   = {S. Mangold and S. Kyriazakos},
  Journal                  = {{IEEE} ?},
  Year                     = {1999},

  Comment                  = {247: ReadNo},
  Review                   = {Combined pattern recog and hmm hidden state position estimates. cell phone application}
}

@Article{manikas98linArrAmbig,
  Title                    = {Modeling and Estimation of Ambiguities in Linear Arrays},
  Author                   = {Athanassios Manikas and Christos Proukakis},
  Journal                  = {{IEEE} Trans. on Sig. Proc.},
  Year                     = {1998},
  Number                   = {8},
  Pages                    = {2166-2179},
  Volume                   = {46},

  Comment                  = {594:ReadNo},
  Review                   = {Linear array calibration with spatial aliasing?}
}

@Article{manikas01nonLinArrManifold,
  Title                    = {Manifold studies of nonlinear antenna array geometries},
  Author                   = {Athanassios Manikas and Adham Sleiman and Ioannis Dacos},
  Journal                  = {{IEEE} Trans. on Sig. Proc.},
  Year                     = {2001},
  Number                   = {3},
  Pages                    = {497-506},
  Volume                   = {49},

  Comment                  = {595:ReadNo},
  Review                   = {nonlinear array calibration with spatial aliasing?}
}

@Article{Mansour82uconstrFreqAdaptFilt,
  Title                    = {Unconstrained frequency-domain adaptive filter},
  Author                   = {D. Mansour and A. Gray Jr.},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {1982},
  Number                   = {5},
  Pages                    = {726- 734},
  Volume                   = {30},

  Comment                  = {645:ReadYes},
  File                     = {Mansour82uconstrFreqAdaptFilt.pdf:Mansour82uconstrFreqAdaptFilt.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Used to implement smalled eigenvalue TDOA in Benesty00adaptEigSrcLoc},
  Timestamp                = {2007.07.30},
  Url                      = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=1163949&isnumber=26172&punumber=29&k2dockey=1163949@ieeejrns&query=%28%28unconstrained+frequency-domain+adaptive+filter%29%3Cin%3Emetadata%29&pos=0}
}

@InProceedings{maricic01bssRestrictConv,
  Title                    = {Blind equalization of constant modulus signals via restricted convex optimization},
  Author                   = {Maricic, B. and Zhi-Quan Luo and Davidson, T.N.},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {2169-2172},
  Volume                   = {4},

  Comment                  = {ReadNo},
  Review                   = {relevant to mono/ARMA/convex idea? 
* he has a 2002 paper on nonrestricted opt.},
  Url                      = {http://ieeexplore.ieee.org/iel5/7486/20357/00940424.pdf?isNumber=20357&prod=CNF&arnumber=940424&arSt=2169&ared=2172+vol.4&arAuthor=Maricic%2C+B.%3B+Zhi-Quan+Luo%3B+Davidson%2C+T.N.}
}

@Article{maricic02bssConvex,
  Title                    = {Blind equalization of constant modulus signals via convex optimization},
  Author                   = {B. Maricic and Z.-Q. Luo and T. N. Davidson},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {2002},

  Comment                  = {ReadNo},
  Review                   = {accepted but not on IEEE web site yet. Get it. He's got a 2001 paper on =restricted= convex opt too.},
  Url                      = {http://www.ece.mcmaster.ca/~davidson/pubs/CMconvex.html (not the paper but the ref)}
}

@Article{martin99nistOv,
  Title                    = {The {NIST} 1999 Speaker Recognition Evaluation An Overview},
  Author                   = {Alvin Martin and Mark Przybocki},
  Journal                  = {Digital Signal Processing},
  Year                     = {2000},
  Pages                    = {1-18},
  Volume                   = {10},

  Comment                  = {ReadNo}
}

@Article{martin01psdEstMin,
  Title                    = {Noise power spectral density estimation based on optimal smoothing and minimum statistics},
  Author                   = {Rainer Martin},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2001},
  Number                   = {5},
  Pages                    = {504-512},
  Volume                   = {9},

  Comment                  = {411: ReadYes},
  Review                   = {Noise power for VAD comes from min PSD in each FFT bin
* estimates noise floor using min value of each FFT bin (over time win)
-- speech assumed strong, won't occupy bin forever
-- FFT bin is 1st smoothed recursively using ests. of noise variance
-- smoothing is optimal under Gaussianinity assumptions
-- bins correlated accross time => non-analytic,a empirical ctl. curves
* referenced by Zak's VAD paper (shafran03asrVad) 
-- more complicated than Zak's
* seems to work well, better on soft consonants than the competition.
* can't tell how this compares to Zak's since different test data},
  Url                      = {http://ieeexplore.ieee.org/iel5/89/20081/00928915.pdf?isNumber=20081&prod=IEEE+JNL&arnumber=928915&arSt=504&ared=512&arAuthor=Martin%2C+R.%3B}
}

@Article{martinez01PCAvsLDA,
  Title                    = {{PCA} versus {LDA}},
  Author                   = {A. M. Martinez and A. C. Kak},
  Journal                  = {IEEE Trans. on Pattern Analysis and Machine Intelligence},
  Year                     = {2001},
  Number                   = {2},
  Pages                    = {228-233},
  Volume                   = {23},

  Comment                  = {138: ReadYes},
  Review                   = {Dim. Reduction: PCA better than LDA when little training data
* done on face recognition
* decision rule is just Euclidean nearest neighbor
* Important LDA restricitons:
-- only c-1 nonzero eigen vecs (max output dim); c = # classes
-- Sw matrix nonsingularity: need c+t training samples (t=input dim)
* solution: PCA dim reduction 1st, then need fewer LDA training samples
* but, shows that PCA by itself can work better w/ few training images
* refs[10,16,5,12]: how to compute corr matrix eigenvals in high D space}
}

@Article{marzinzik02spchPause,
  Title                    = {Speech Pause Detection for Noise Spectrum Estimation by Tracking Power Envelope Dynamics},
  Author                   = {Mark Marzinzik and Birger Kollmeier},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {109-118},
  Volume                   = {10},

  Comment                  = {436: ReadYes},
  File                     = {marzinzik02spchPause.pdf:marzinzik02spchPause.pdf:PDF},
  Review                   = {Heuristic VAD based on min/max FFT bin energies in low/high bin groups
* good review of past VAD 
* lists 12 VAD categories -- not quite comprehensive
* min & max energy tracked within each of two FFT bin groups (low/high)
* noise sort of estimated and single pole smoothed
* many ugly heuristic rules 
* well tested and does better than G.729 VAD
* by of Birger Kollmeieir's students (BK recommended by Nelson Morgan)
* targeted for realtime, nonstationary, 
* looks computationally inexpensive
* criticizes "noise est at start of file" and then does it
* criticizes noise reduction algorithms that don't do a good VAD job},
  Url                      = {http://medi.uni-oldenburg.de/download/docs/paper/marz_koll_2002_speech-pause.pdf}
}

@InProceedings{matsuyama01icaConv,
  Title                    = {{CONVEX} {DIVERGENCE} {AS} A {SURROGATE} {FUNCTION} {FOR} {INDEPENDENCE}: {THE} f - {DIVERGENCE} {ICA}},
  Author                   = {Yasuo Matsuyama and Naoto Katsumata and Shuichiro Imahara},
  Booktitle                = {Independent Components Analysis, Intl. Conf. on},
  Year                     = {2001},

  Comment                  = {ReadNo},
  Review                   = {Use convex opt to do ICA? Combine w/ ARMA convex to enforce LP constraints to do mono ICA?},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/064-katsumata.pdf}
}

@InBook{maybeckXXkalmanbook,
  Title                    = {Stochastic models, estimation, and control, volume 1},
  Author                   = {P. S. Maybeck},
  Chapter                  = {UNKNOWN},
  Pages                    = {0-0},
  Publisher                = {academic pres},
  Year                     = {1979},

  Comment                  = {34.0: ReadYes},
  Review                   = {The kalman filter book chunk everybody recommends}
}

@TechReport{mccowan-rr-01-39,
  Title                    = {Microphone Array Post-filter for Diffuse Noise Field},
  Author                   = {I. McCowan and H. Bourlard},
  Institution              = {IDIAP},
  Year                     = {2001},
  Number                   = {39},
  Type                     = {IDIAP-RR},

  Abstract                 = {This paper proposes a novel technique for estimating the signal power spectral density to be used in the transfer function of a microphone array post-filter. The technique is a modification of the existing Zelinski post-filter, which uses the auto- and cross-spectral densities of the array inputs to estimate the signal and noise spectral densities. The Zelinski technique, however, assumes zero cross-correlation between noise on different sensors. This assumption is inaccurate in real conditions, particularly at low frequencies and for arrays with closely spaced sensors. In this paper we replace this with an assumption of a theoretically diffuse noise field, which is more appropriate in a variety of realistic noise environments. In experiments using noise recordings from an office of computer workstations, the modified post-filter results in significant improvement in terms of objective speech quality measures and speech recognition performance.},
  Comment                  = {307: ReadYes},
  File                     = {mccowan-rr-01-39.ps.gz:mccowan-rr-01-39.ps.gz:PDF},
  Review                   = {Post-delay/sum beamformer noise reduction filter, sorta improved Wiener
* noise reducer for after mic array time align and sum
* improvement on Zelinski post-filter, which is based on Wiener filter
Improvement of Zelinski:
* doesn't assume zero noise channel cross-correlation
* assumption bad for closely spaced mics, or off-beam background speech
* improvement assumes a diffuse noise field w/ a channel coherence func.
Results
* speech recog perf w/ new filter & 10dB SNR == perf w/ clean speech
* works much better than plain BF or BF+Zelinski
* speech model adaptation not done so don't know if there's an incremental improvement.
* helps even when there's reverb},
  Url                      = {ftp://ftp.idiap.ch/pub/reports/2001/rr01-39.ps.gz}
}

@TechReport{mccowan-rr-01-40,
  Title                    = {Generalised Microphone Array Post-filter based on Noise Field Coherence},
  Author                   = {I. McCowan and H. Bourlard},
  Institution              = {IDIAP},
  Year                     = {2001},
  Number                   = {40},
  Type                     = {IDIAP-RR},

  Abstract                 = {This article introduces a novel technique for estimating the signal power spectral density to be used in the transfer function of a microphone array post-filter. The technique is a generalisation of the existing Zelinski post-filter, which uses the auto- and cross-spectral densities of the array inputs to estimate the signal and noise spectral densities. The Zelinski technique, however, assumes zero cross-correlation between the noise on different sensors. This assumption is inaccurate, particularly at low frequencies and for arrays with closely spaced sensors, and thus the corresponding post-filter is sub-optimal in realistic noise conditions. In this article, a more general expression of the post-filter estimation is developed based on an assumed knowledge of the complex coherence of the noise field. This general expression can be used to construct a more appropriate post-filter in a variety of different noise fields. In experiments using real noise recordings from both a computer office and a car, the modified post-filter results in significant improvement in terms of objective speech quality measures and speech recognition performance.},
  Comment                  = {309: ReadNo},
  File                     = {mccowan-rr-01-40.ps.gz:mccowan-rr-01-40.ps.gz:PDF},
  Review                   = {Seems very similar to McCowan's Tech Note 01-40 but longer. Didn't read.
Submitted to IEEE Trans. on Speech and Audio Processing in 2002. Don't know if/when it was accepted},
  Url                      = {ftp://ftp.idiap.ch/pub/reports/2001/rr01-40.ps.gz}
}

@Article{mccowan06arrayShapeMDSnoise,
  Title                    = {Microphone Array Shape Calibration in Diffuse Noise Fields},
  Author                   = {Iain McCowan and Mike Lincoln and Ivan Himawan.},
  Journal                  = {Trans., Audio, Speech, and Language Proc.},
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {666-670},
  Volume                   = {16},

  File                     = {mccowan06arrayShapeMDSnoise.pdf:mccowan06arrayShapeMDSnoise.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Estimates microphone location via diffuse noise theory and multidimensional scaling

Diffuse noise microphone pair distance estimate
- diffuse noise (nondirectional) field is a good model for reverberrant office environments
- theoretical relationship between microphone pair coherence and distance
- equation looks a lot like GCC-PHAT
- can use VAD or quiet period to collect coherence (I wonder: fans, ventialtors omnidirectional?)
- use this to estimate mic distance

Multi-dimensional scaling (MDS)
- classical version reconstructs object arrangement based on pairwise estimate of similarity
- example is building a map from a list of intercity distances
- use it here to construct microphone positions

Tests
- narrowly spaced mics: 5, 10 and 8cm
- 8 microhones
- estimate converges in about 13secs
- distance erros: 0.02 to 3cm, avg. error: 1.6cm
- position errors (from MDS): 0.13cm to 3.34cm
- also good review of array calibration techniques},
  Timestamp                = {2007.08.18},
  Url                      = {www.idiap.ch/~mccowan/publications/mccowan-taslp06.pdf}
}

@InProceedings{mccowan02micArrMissDat,
  Title                    = {Improving Speech Recognition Performance of Small Microphone Arrays Using Missing Data Techniques},
  Author                   = {I. McCowan and A. Morris and H. Bourlard},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},

  Comment                  = {308: ReadYes},
  Review                   = {Noise weight freq bands in GMM sum. Better use for beamformer noise filt.
* When evaluating GMM likelihood sum, un-weight a frequency band if it is deemed noisy.
* noise estimate:
-- comes difference between pre and post-beamformer noise filter signals
-- filter is (I think) Zelinski filter discussed in other McCowan papers
* Don't actually use BF noise filter output! 
-- Only use to de-weight noisy freq bands
-- This works much, much better in high noise than using filter output
-- Surprising?: noise filter is Wiener and would distort formants
* used mel-warped spectral features (this wouldn't work for cesptral features since this cepstrum would spread this noise all over the place: wouldn't now what to weight).}
}

@InProceedings{mccowan01micarr,
  Title                    = {Microphone Array Sub-Band Speech Recognition },
  Author                   = {I. McCowan and S. Sridharan},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},

  Comment                  = {186: ReadYes},
  Review                   = {Separate mic spacing, beamform, and recog on each subband
* separate BF & microphone spacing in different freq bands
* near field super-directivicty focusses based on mag diffs too
* word recog done individually on each band w/ separate models
* this is supposed to be like humans
* multiband error suppoesed to be product of subband errors
* and it does work better
* assumes spkr location known

* does this suggest that doing separate spkrID on each microphone and then combining would be better?}
}

@Misc{mclaughlin99multiSpkrClust,
  Title                    = {Automatic clustering from multi-speaker utterances},

  Author                   = {J. McLaughlin and D. Reynolds and E. Singer and G. C. O'Leary},

  Comment                  = {156: ReadYes},
  Review                   = {Minimum unit is utterance containing multiple talkers. How to cluster these multi-talker clusters
* Doesn't seem to work
* notes that duration weighting may not be ideal
* has a metric for multiple speaker segments but I don't understand it.}
}

@InProceedings{mdlazi03pcaAutoRelDet,
  Title                    = {Principal Component Analysis and Automatic Relevance Determination in Damage Identification},
  Author                   = {L. Mdlazi and T. Marwala and C.~J. Stander and C. Scheffer and P.~S. Heyns},
  Booktitle                = {IMAC-XXI: A Conference \& Exposition on Structural Dynamics},
  Year                     = {2003},

  File                     = {:mdlazi08pcaAutoRelDet.1672:PDF},
  Owner                    = {scotto},
  Review                   = {Use to pick PCA dimension?

Conference page here, probably
http://md1.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2006076141922MT&recid=2006072524331CI&q=&uid=788451315&setcookie=yes},
  Timestamp                = {2008.01.21},
  Url                      = {http://www.citebase.org/abstract?id=oai:arXiv.org:0705.1672}
}

@Article{medan91pitchDetSuperRes,
  Title                    = {Super resolution pitch determination of speech signals},
  Author                   = {Yoav Medan and Eyal Yair and Dan Chazan},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {1991},
  Number                   = {1},
  Pages                    = {40-48},
  Volume                   = {39},

  Comment                  = {587: ReadNo},
  Review                   = {pda used in Edinburgh Speech Tools },
  Url                      = {http://ieeexplore.ieee.org/iel4/78/2655/00080763.pdf?tp=&arnumber=80763&isnumber=2655}
}

@InProceedings{meig00multihmm,
  Title                    = {Evolutive {HMM} for multi-speaker tracking system},
  Author                   = {S. Meignier and J. -F Bonastre and C. Fredouille and T. Merlin},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},
  Pages                    = {I1201 -II1204},
  Volume                   = {2},

  Comment                  = {155: ReadYes},
  Review                   = {Speaker ID in conversation modeled by HMM w/ known spkr models. 
* all speakers known beforehand, this determines subset present
* conversation turns modeled as HMM's
* no interruptions
* starts at beginning and adds speaker models as it goes
* 0.3s blocks
* Viterbi decoding of HMM}
}

@InProceedings{meila98an,
  Title                    = {An Experimental Comparison of Several Clustering and Initialization Methods},
  Author                   = {M. Meila and D. Heckerman},
  Booktitle                = {Proc., Fourteenth Conf. on Uncertainty in Artificial Intelligence},
  Year                     = {1998},
  Pages                    = {386-395},
  Publisher                = {Morgan Kaufmann Publishers, Inc., San Francisco, CA. },

  Comment                  = {196: ReadYes},
  Review                   = {Do flat EM w/ marginializaton init instead of agglom clust (disc data)
* empirical study done on discrete distributions
-- same conclusions on 2 data sets, one synthetic, one digit images
* use CS MAP to pick # of clusters (log marginal criterion, p. 3,6)
* CEM clustering: hard cluster decision: fast but bad
* Hierarchical agglomerative clustering HAC
-- 60x slower than EM
-- is best EM init when do it on a subsample of the data (p. 6,11)
- subsample HAC size comes from smallest cluster size prior (p. 14)
* EM better than agglom or CEM clustering
* most errors due to small clusters
* marginal or HAC equally good (best) for getting K* right (# clusts)
* HAC slightly (insignificantly) best for class accuracy p. 11
* init EM w/ marginal or HAC better but random gets smaller clusts p. 17
* Marginal init seems best
-- same perf as HAC but computationally cheaper p. 17
-- but does noisy marginal method work for contin data? 
-- is hundreds of times faster than HAC p. 14)
* nice table of cluster criteria on p. 8}
}

@InProceedings{meinecke01icaRelia,
  Title                    = {Estimating the Reliability of {ICA} Projections},
  Author                   = {F. Meinecke and A. Ziehe and M. Kawanabe and K.-R. M\"uller},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2002},
  Editor                   = {T. G. Dietterich and S. Becker and Z. Ghahramani},
  Publisher                = {MIT Press},
  Volume                   = {14},

  Comment                  = {434: ReadNo},
  File                     = {meinecke01icaRelia.ps.gz:meinecke01icaRelia.ps.gz:PDF},
  Review                   = {quality est. of ICA (error bars on separation params)},
  Url                      = {http://www-2.cs.cmu.edu/Groups/NIPS/NIPS2001/papers/psgz/SP08.ps.gz}
}

@InProceedings{meinicke01icaQdens,
  Title                    = {Independent Component Analysis with Quantizing Density Estimators},
  Author                   = {P. Meinicke and H. Ritter},
  Booktitle                = {Independent Component Analysis and Signal Separation, Intl. conf. on},
  Year                     = {2001},
  Pages                    = {224-229},

  Comment                  = {ReadNo},
  Review                   = {SVM-like density estimator works better when little data},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/093-meinicke.pdf}
}

@Misc{merwe00partfilt,
  Title                    = {The unscented particle filter},

  Author                   = {R. van der Merwe and A. Doucet and N. de Freitas and E. Wan},

  Comment                  = {45.0: ReadNo},
  Review                   = {Unscented kalman particle filter -- i think was recommended by kevin murphy. Have matlab code for this. relevant to speaker motion tracking or reverb switching when head turns? pitch tracking w/ multi-speakers?}
}

@InProceedings{metze04mtngRecogRT04s,
  Title                    = {The {ISL RT-04S} Meeting Transcription System},
  Author                   = {Florian Metze and Christian Fugen},
  Booktitle                = {{NIST} Meeting Recognition Workshop},
  Year                     = {2004},

  Comment                  = {ReadYes},
  Review                   = {ISL NIST meeting speaker seg/clust

Multimic VAD segmentation
* just used single most central mic and standard segmentation
Headset mic VAD (IHM)
* Energy ratio overlap det (sort-of)
- very similar to CMU system (jin04)

NOTE Fugen s/b umlauted (F\"{\u}gen) but this blows up when I try to make a DVI}
}

@Misc{michael-parameter,
  Title                    = {Parameter Reduction In A Text-Independent Speaker Verification System},

  Author                   = {R. A. Michael},

  Comment                  = {135: ReadNo},
  Url                      = {citeseer.nj.nec.com/397398.html}
}

@Article{michaelis97glottal,
  Title                    = {Glottal to noise excitation ratio - a new measure for describing pathological voices},
  Author                   = {D. Michaelis and T. Gramss and H. Strube},
  Journal                  = {ACUSTICA},
  Year                     = {1997},
  Pages                    = {700-706},
  Volume                   = {83},

  File                     = {michaelis97glottal.pdf:michaelis97glottal.pdf:PDF},
  Review                   = {Filterbank Hilbert envelopes highly correlated across freqs 
Inverse LPC filter -> filterbank -> hilbert envelope 
-> xcorr envelopes distant in freq
* envelopes are highly correlated across frequencies 
-- env noise uncorr. @ > 1/2 filter BW: use only xcorr pairs 
>= 1/2BW apart
-- not always correlated if one band falls in formant trough
so picks only the max band corr to use as figure of merit.
(I wouldn't do that for ovdet)
-- bands not exactly time aligned: foreach pair calc corr @ max
delay (searches over +-0.3ms)
* inverse filtering: window of 30 ms length and 10 ms shift
* Hilbert: window FFT bins, inverse FFT, mag
* 
Filterbank width and number of:
* filterbanks bandwidths of 1,2 and3 KHz compared (they overlap a lot)
* correspoiding # center freqs (banks): 51,31,21
* center freqs at 80-100Hz steps
* cover range of about 500-4500 (varies a little w/ bandwidth)
* BW's are quite broad: 1KHz, 2KHz, 3KHz)
* downsample to 10KHz 1st, since little energy above 5Khz
Purpose
* uses lack of correlation to ID people with vocal disease
* seems to work better but I only skimmed the disease part...
* I didn't read much of the disease ID comparison studies
* maybe relevant to pitch and overlap detection},
  Text                     = {D. Michaelis, T. Gramss, and H. W. Strube. Glottal to noise excitation ratio - a new measure for describing pathological voices. Acustica / acta acustica, 83:700--706, 1997.},
  Url                      = {http://www.physik3.gwdg.de/~micha/hd/doc/acustica97.pdf}
}

@InProceedings{Mika99kpcaDenoise,
  Title                    = {Kernel {PCA} and De--Noising in Feature Spaces},
  Author                   = {S. Mika and B. {Sch\"olkopf} and A. J. Smola and K.-R. {M\"uller} and M. Scholz and G. {R\"atsch}},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {1999},
  Editor                   = {M. S.~Kearns and S. A.~Solla and D. A.~Cohn},
  Number                   = {11},
  Pages                    = {536?542},
  Publisher                = {{MIT} Press},

  File                     = {Mika99kpcaDenoise.pdf:Mika99kpcaDenoise.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Kernel PCA denoising algorithm used in Matlab LSSVM Toolbox

KPCA: usual PCA equation (solutions of lambda*V = C*V) but..
* covariance matrix, C, is calculated with a kernel outer product

Denoising with KPCA: Can reconstruct with reduced components in feature space, just like with linear PCA but...
* nonlinear mapping means that input space point may not exist, or may be multi-valued
* Therefore, do least squares fit to find input space point
* Calls the reconstructed points "pre-images" for some reason

* Two methods for solving least squares

1.) unconstrained, multivalued least squares (What LSSVM toolbox does, using matlab's fminunc()). This works for many kernels -- toolbox uses RBF kernel

 2.) Iterative method for Gaussian kernel

Note: When I ran the LSSVM version on lags, I was limited to only 3000 points for kernel training. The inverse problem was also incredibly slow!},
  Timestamp                = {2007.08.14},
  Url                      = {citeseer.ist.psu.edu/mika99kernel.html}
}

@Misc{millerXXjumpTargTrack,
  Title                    = {Conditional-mean estimation via jump-diffusion processes in multiple target tracking/recognition},

  Author                   = {M. I. Miller and A. Srivastava and U. Grenander},

  Comment                  = {40.5: ReadNo},
  Review                   = {Relevant to speaker location features, esp. associating speaker id w/ location id?}
}

@TechReport{minka01bayesLinRegress,
  Title                    = {Bayesian linear regression},
  Author                   = {Thomas Minka},
  Institution              = {Carnigie Mellon University},
  Year                     = {2001},

  Comment                  = {401: ReadNo},
  Review                   = {Change point detection by linear regression; or by basis function change
* Relevant for speaker change det; or sparse coding speaker change det?
* says switching regression is more flexible (ref. to Chen&Liu `96)

* interesting PhD thesis on SVM-like Bayes Point Machines (w/ matlab)
* it has model selection criteria and explains Laplace and variational Bayes methods for model selection},
  Url                      = {http://www.stat.cmu.edu/~minka/papers/linear.html}
}

@InProceedings{Minka00AutoPCAdim,
  Title                    = {Automatic Choice of Dimensionality for {PCA}},
  Author                   = {Thomas P. Minka},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2000},
  Pages                    = {598-604},

  Comment                  = {400: ReadNo},
  File                     = {Minka00AutoPCAdim.pdf:Minka00AutoPCAdim.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Bayesian choice of # of PCA dimensions model order selection criteria used (more or less) by Hansen ICA detect
* I HAVE COPIED THIS TO ENERGY.BIB
* has matlab
* longer tech note: Minka00AutoPCAdimTechNote (go there for matlab too)},
  Timestamp                = {2007.06.03},
  Url                      = {http://vismod.media.mit.edu/tech-reports/TR-514-ABSTRACT.html}
}

@TechReport{Minka00AutoPCAdimTechNote,
  Title                    = {Automatic chice of dimensionality for {PCA}},
  Author                   = {Tomas P. Minka},
  Institution              = {MIT Media Laboratory, Vision and Modeling Group},
  Year                     = {2000},
  Number                   = {514},

  File                     = {Minka00AutoPCAdimTechNote.pdf:Minka00AutoPCAdimTechNote.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Bayesian choice of # of PCA dimensions model order selection criteria used (more or less) by Hansen ICA detect

* I HAVE COPIED THIS TO ENERGY.BIB

NOTE: This tech note was corrected in 2008 (see the tech note URL) but I haven't downloaded that

* published in NIPS 2000 [Minka00AutoPCAdim]
* matlab available at technote URL},
  Timestamp                = {2007.06.05},
  Url                      = {http://research.microsoft.com/~minka/papers/pca/}
}

@TechReport{minka00matrixAlg4stat,
  Title                    = {Old and New Matrix Algebra Useful for Statistics},
  Author                   = {Thomas P. Minka},
  Institution              = {Carnegie Mellon University},
  Year                     = {2000},

  Comment                  = {398: ReadNo},
  File                     = {minka00matrixAlg4stat.pdf:minka00matrixAlg4stat.pdf:PDF},
  Review                   = {Many matrix algebra and calculus tricks; has matlab code too! 

NOTE: PDF and any comments moved to energy.bib},
  Url                      = {http://www.stat.cmu.edu/~minka/papers/matrix.html}
}

@TechReport{minka98gaussInfer,
  Title                    = {Inferring a Gaussian distribution},
  Author                   = { Thomas P. Minka},
  Institution              = {MIT Media Laboratory},
  Year                     = {1998},

  Comment                  = {399: ReadYes},
  Review                   = {Bayesian method for exactly integrating data prob over all Gaussians; also has measures of Gaussianinity. Better than Kurtosis, etc.?
Sorta skimmed this but got the ghist},
  Url                      = {http://www.stat.cmu.edu/~minka/papers/gaussian.html}
}

@InProceedings{Mirghafori06NUTSANDFLAKES,
  Title                    = {{NUTS} {AND} {FLAKES}: A {STUDY} {OF} {DATA} {CHARACTERISTICS} {IN} {SPEAKER} {DIARIZATION}},
  Author                   = {Nikki Mirghafori and Chuck Wooters},
  Booktitle                = {ICASSP},
  Year                     = {2006},

  Comment                  = {617:ReadYes},
  File                     = {Mirghafori06diarizNutsFlakes.pdf:Mirghafori06diarizNutsFlakes.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Meeting characteristsics that correlated with diarization error

Nuts: meetings that are hard to crack (high average DERR across many systems)
Flakes: meetings w/ high dependence on tunable params or systems (not so useful)

Nut (high average DERR) correlates
1.) many speakers (strongest correlation)
2.) lots of speaker changes
3.) single speaker talks a lot (most surprising, the "do nothing" score)

Flakiness
* no strong correlations but...
1.) do nothing (single speaker, strongest corr)
2.) number of speakers

* used Spearmans ranking correlation (catches non-linearities)
* linear regression and regression trees uninformative (not enough data)},
  Timestamp                = {2006.08.09},
  Url                      = {http://www.icsi.berkeley.edu/cgi-bin/pubs/publication.pl?ID=001962}
}

@InProceedings{miyajima01multispaceSID,
  Title                    = {Speaker Identification Using {Gaussian} Mixture Models Based on Multi-Space Probability Distribution},
  Author                   = {C. Miyajima and Y. Hattori and K. Tokuda and T. Masuko and T. Kobayashi and T. Kitamura},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},

  Comment                  = {191: ReadYes},
  Review                   = {SpkrID w/ differnent time scale, mixed vector and symbolic streams
* adding log(pitch) improves pef over jsut MFCC GMM (is log optimal?)
* MSD-GMM allows for intermittent features e.g. voicing (EM trained)
* 32 or 64 mixtures
* 60s training (pretty big)
* have same model regardless of voicing 
-- competitive models tested have separate voiced/unvoiced 
--but they don't include pitch. 
-- Would separate spectral models have helped?
* 7.5ms window for RAPT pitch est}
}

@InProceedings{mizumachi03NonEqSpaceMicPair,
  Title                    = {Noise Reduction using Paired-microphones on Non-equally-spaced Microphone Arrangement},
  Author                   = {Mitsunori Mizumachi and Satoshi Nakamura},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {585-588},

  Comment                  = {564: ReadNo},
  Review                   = {how to selecte microphone pairs for noise reduction}
}

@Article{Moddemeijer89entInfoContinDist,
  Title                    = {On Estimation of Entropy and Mutual Information of Continuous Distributions},
  Author                   = {R. Moddemeijer},
  Journal                  = {Signal Processing},
  Year                     = {1989},
  Number                   = {3},
  Pages                    = {233--246},
  Volume                   = {16},

  Abstract                 = {Mutual information is uded in a procedure to estimate time-delays between recordings of electroencephalogram (EEG) signals originating from epileptic animals or patients. We present a simple and reliable histogram-based method to estimate mutual information. The accuracies of this mutual information estimator and of a similar entropy estimator are discussed. The bias and variance calculations presented can also be applied to discrete valued systems. Finally we present some simulation results, which are compared with earlier work.},
  Checked                  = {R. Moddemeijer, rudy at cs.rug.nl, 1 April 1999},
  Comment                  = {650},
  Entered                  = {R. Moddemeijer, rudy at cs.rug.nl, 15 March 1999},
  Keywords                 = {mutual information, entropy, bias, variance, estimator, delay-estimation},
  Owner                    = {scotto},
  Review                   = {Histogram based mutual information technique I'm using

matlab here:
http://www.cs.rug.nl/~rudy/papers/abstracts/RM8902.html},
  Timestamp                = {2008.01.23},
  Url                      = {http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6V18-48V26YR-MK&_user=582538&_rdoc=1&_fmt=high&_orig=mlkt&_sort=d&view=c&_acct=C000029718&_version=1&_urlVersion=0&_userid=582538&md5=439090302abeaea9e2ce00d74f1b99e4}
}

@Article{molgedy94bssTDcorr,
  Title                    = {Separation of independent Signals using Time-Delayed Correlations},
  Author                   = {L. Molgedey and H. Schuster},
  Journal                  = {Physical Review Letters},
  Year                     = {1994},
  Number                   = {23},
  Pages                    = {3634-3637},
  Volume                   = {72},

  Comment                  = {ReadNo},
  Review                   = {The starting point for the alg. that detects # IC comps},
  Url                      = {http://prola.aps.org/pdf/PRL/v72/i23/p3634_1}
}

@InProceedings{moraru04spkrDiariz,
  Title                    = {Speaker diariazaiont in the {ELISA} consortium over the last 4 years},
  Author                   = {D. Moraru and L. Besacier},
  Booktitle                = {RT-04 Workshop, EARS PI meeting},
  Year                     = {2004},
  Pages                    = {paper 30},

  Comment                  = {ReadYes},
  File                     = {moraru04spkrDiariz.pdf:moraru04spkrDiariz.pdf:PDF},
  Review                   = {Meeting/BN diariazaion; combines bndry detection + clust w/ pure HMM cluster segmenters
* CLIPS "two step" approach
- BIC speaker change det --> GMM clustering
- 1024 mixture UBM w/ adaptation (UBM from swbdII)
- 16 ceps w/ 56 channels (no deltas/energy)
- VAD preproc: 1 mixture silence vs. 512 mixture speech
* LIA "integrated" approach (HMM clustering)
- HMM clustering, each state is a speaker
- splitting instead of agglomerative, like IDIAP cluster
- many heuristics designed to catch long speakers 1st, matching NIST diarization criteria
- MAP adaptation of 1024 GMM
- 1/512 mixture GMM VAD
* Broadcast News results
- best performance with "pipe" combo of two-step and integrated
- two-step initializes integrated, which then iterates
* Meeting channel combination
- explained in ref [3] (fredouille04mtngRecogRT04s)
- gets 22.4% diarization error! Better than reported above??},
  Url                      = {http://www-clips.imag.fr/geod/User/laurent.besacier/Publis/RT04Fall.pdf}
}

@InProceedings{morgan01meetproj,
  Title                    = {The Meeting Project at {ICSI}},
  Author                   = {N. Morgan and D. Baron and J. Edwards and D. Ellis and D. Gelbart and A. Janin and T. Pfau and E. Shriberg and A. Stolcke},
  Booktitle                = {HLT},
  Year                     = {2001},

  Comment                  = {6: ReadNo},
  Review                   = {But referenced in Shriberg paper, as describing the meeting data.},
  Url                      = {citeseer.nj.nec.com/morgan01meeting.html}
}

@InProceedings{mori01vqchangedet,
  Title                    = {Speaker Change detection and speaker clustering using {VQ} distortion for broadcast news speech recognition},
  Author                   = {K. Mori and S. Nakagawa},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {413-416},
  Volume                   = {1},

  Comment                  = {159: ReadYes},
  Review                   = {VQ distortion for both change det. and clustering: beats BIC, GLR, etc.
* segment boundaries seem to be given
* VQ dist. is special case (approx) of G. likelihood measure
* says reliable GMM's require >= 10s of speech (don't say dim of GMM)
* VQ is better for short segs since fewer params
* backoff improves short segments
Results
* tested on Japanese broadcast news
* better than GLR, BIC, GMM,
* But: GLR, BIC, GMM clustering algorithms not described (maybe bad)
* (compared w/ full and diag cov)},
  Url                      = {http://ieeexplore.ieee.org/iel5/7486/20365/00940855.pdf?tp=&arnumber=940855&isnumber=20365}
}

@Misc{moscheniXXobjTrackSpatioTemp,
  Title                    = {Object tracking based on temporal and spatial information},

  Author                   = {F. Moscheni and F. Dufaux and M. Kunt},

  Comment                  = {41.0: ReadNo},
  Review                   = {Relevant to speaker location features, esp. associating speaker id w/ location id?}
}

@Article{moucht00loudspkrfilt,
  Title                    = {Inverse filter design for immersive audio rendering over loudspeakers},
  Author                   = {A. Mouchtaris and P. Reveliotis and C. Kyriakakis},
  Journal                  = {{IEEE} transactions on multimedia},
  Year                     = {2000},
  Number                   = {2},
  Pages                    = {77-87},
  Volume                   = {2},

  Comment                  = {228: ReadYes},
  Review                   = {How to undo effecs of headphones or loundspeakers so that synthesized HRTF will work 
* 75-100mm head movement will screwup localization unless head is tracked and coeffs adjusted on the fly 
* good paper in references on room inversion? [11]}
}

@Misc{murphy98skf,
  Title                    = {Switching {Kalman} filters},

  Author                   = {K. P. Murphy},

  Comment                  = {35.5: ReadNo},
  Review                   = {Relevant to speaker motion tracking or reverb switching when head turns?}
}

@Article{saty99grpDelInstant,
  Title                    = {Robustness of group-delay-based method for extraction of significant instants of excitation ofrom speech signals},
  Author                   = {P. S. Murthy and B. Yegnanarayana},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {1999},
  Number                   = {6},
  Volume                   = {7},

  Comment                  = {243: ReadNo},
  Review                   = {Catching glottal pulses: good for DOA?}
}

@Misc{na-frequencydomain,
  Title                    = {Frequency-Domain Implementation Of Block Adaptive Filters For Ica-Based Multichannel Blind Deconvolution},

  Author                   = {Kyungmin Na and Sang-Chul Kang and Kyung Jin Lee and Soo-Ik Chae},

  Comment                  = {333: ReadYes},
  Review                   = {Time domain block adaptive filters, realized in frequency
* covers details of how to do freq domain FIR filter update w/ overlap-save synthesis
* Two gradient algorithms:
- standard gradient 
- natural gradient
* FIR length = 1024 (8s if Fsamp=8Khz: very long)
* freq domain realization requires 20-30X less CPU than time realization}
}

@InProceedings{naik95poleCMS,
  Title                    = {Pole-filtered cepstral mean subtraction},
  Author                   = {Devang Naik},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1995},
  Pages                    = {157-160},
  Volume                   = {1 },

  Comment                  = {ReadNo}
}

@InProceedings{nakatani96localization,
  Title                    = {Localization by harmonic structure and its application to harmonic sound stream segregation},
  Author                   = {T. Nakatani and M. Goto and H. Okuno},
  Booktitle                = {Proc. {ICASSP}},
  Year                     = {1996},

  Comment                  = {175: ReadYes},
  Review                   = {Multi-talker stream segregation by harmonic struct: direction resolves ambiguity 
* => need a good pitch detector 
* not clear how # of talkers is determined 
* harmonic peaks picked based on intensity and & direction continuity w/ stream 
* separation by predicition and subtraction (probably better explained in [1] 
* harmonics and direction is better segregator than either alone 
* direction si from HRTF of IAD/ITD (10 degree increment) 
* lookup [1] -- this paper is mainly about addition of direction to algorithm 
* says later work will handle unvoiced consonants -- lookup! }
}

@Article{nakatani98ontology,
  Title                    = {Sound Ontology for Computational Auditory Scene Analysis},
  Author                   = {T. Nakatani and H. Okuno},
  Journal                  = {Something by American Associaton fo rArtifical Intelligence},
  Year                     = {1998},

  Comment                  = {177: ReadYes},
  Review                   = {Hierarchical model for sound separation for ASR front end
* low level grouping by harmonics (others mentioned but not used)
* predictive pitch tracker
* music/speech segmenter by simple heuristic rule
* music specific pitch tracker
* HTK better if unvoiced segregated by direction (since power normalized)
* HMM-LR works worse if voice segregated
* maybe use for overlap resolution? }
}

@InProceedings{nakataini03domVUV,
  Title                    = {Dominance spectrum based V/{UV} classification and F0 estimation},
  Author                   = {T. Nakatani and T. Irino P. S. Zolfaghari},
  Booktitle                = {Proc. Eurospeech},
  Year                     = {2003},
  Pages                    = {2313-2316},

  Comment                  = {609:ReadNo},
  File                     = {nakataini03domVUV.pdf:nakataini03domVUV.pdf:PDF},
  Review                   = {Related to YIN pitch detector and Mellin},
  Url                      = {http://www.kecl.ntt.co.jp/icl/signal/nakatani/papers/ES3.pdf}
}

@InProceedings{navratil02spkrIDdetac,
  Title                    = {{DETAC}: A {DISCRIMINATIVE} {CRITERION} {FOR} {SPEAKER} {VERIFICATION}},
  Author                   = {Jiri Navr?til and Ganesh N. Ramaswamy},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {1349-1352},

  Comment                  = {ReadNo},
  Url                      = {/g/ssli/html/proceedings/icslp02/ICSLP/PDF/INDEXSCR.PDF}
}

@InProceedings{necioglu00,
  Title                    = {Unsupervised Estimation of the Human vocal Tract Length over Sentence level Utterances},
  Author                   = {B. F. Necioglu and M. A. Clements and T. P. III Barnwell},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},
  Pages                    = {1319-1322},
  Volume                   = {3},

  Comment                  = {169: ReadYes},
  Review                   = {Closed form (analytical) vocal tract length estimator
* VT len est from 3 or 4 LPC spectrum peaks (curve fit of k*(1st res.))
* needs sentence length utterances
* computes avg. est over sentence
* voicing detection alg. listed in refs [3,4]
* 5% VT est error over small set of spkrs w/ measured VT len
* good TIMIT correlatin of VT est w/ spkr height (may be meaningful)
* any advantage over just using MFCC stats?}
}

@Article{nemer01hosLpcVad,
  Title                    = {Robust voice activity detection using higher-order statistics in the {LPC} residual domain},
  Author                   = {Elias Nemer and Rafik Goubran and Samy Mahmoud},
  Journal                  = {{IEEE} Trans.,Speech and Audio Proc.},
  Year                     = {2001},
  Number                   = {3},
  Pages                    = {217-231},
  Volume                   = {9},

  Comment                  = {442: ReadYes},
  Review                   = {VAD from whitened speech LPC residual kurtosis & Co, DD noise est + heuristic state mach
* analytical kurtosis/skewness expressions for speech
- possible when speech whitened
- depend upon pitch
- derived from McAulay sinusoidal model of speech
* whitened, voiced speech less gaussian than gaussian noise, hence VAD
* ideally, independent of speech amplitude (but not quite in practice)
* stationary unvoiced, white speech is white (but rarely stationary)
* whitened speech is LPC residual 
- 10 coeffs are about optimal
- special LPC algorithm to ensure flatness (almost truely flat)
- residual must be lowpass filtered so cumulant equs work out
* get soft voicing estimator as a byproduct
* analytical expression for Gaussian noise polluted, whitened speech
- results in probablistic equs for speech v.s. nonspeech
- bogus start-of-file noise estimator
- then noise is estimated based on VAD (Decision Directed (DD))
* heuristic speech/noise state machine w/ hard threshold transitions
* Tests better than G729B, even in non-gaussian car noise

* Doesn't use his `99 SNR estimator here. Is this one better?

Ideas:
* use this for ICA?
* estimate generalized Gaussians instead of Kurtosis,etc? (VAD or ICA)
* replace kurtosis VAD ests w/ robust ICA estimators
* replace state machine with trained Dynamic Bayesian Network (DBN)?

* lin02spchSegFuz says that LPC not good for nasals or fricatives
* zhang02phoneVAD says that may fail in non-gaussian noise},
  Url                      = {http://ieeexplore.ieee.org/iel5/89/19597/00905996.pdf?isNumber=19597&prod=IEEE+JNL&arnumber=905996&arSt=217&ared=231&arAuthor=Nemer%2C+E.%3B+Goubran%2C+R.%3B+Mahmoud%2C+S.%3B}
}

@Article{nemer99fourthOrderSNR,
  Title                    = {{SNR} estimation of speech signals using subbands and fourth-order statistics},
  Author                   = {Elias Nemer and Rafik Goubran and Samy Mahmoud},
  Journal                  = {{IEEE} Signal Processing Letters},
  Year                     = {1999},
  Number                   = {7},
  Pages                    = {171-174},
  Volume                   = {6},

  Comment                  = {444: ReadYes},
  Review                   = {Filterbank output kurtosis used to estimate SNR; not totally tested
* analytical expressions for kurtosis of speech (sinusoidal model)
* assumes filterbank output contains only 1 pitch harmonic 
- need to pitch det 1st, then?
- doesn't say how the bandwidth was set, 
- seems like a big issue since minF0=45Hz and maxF0=450Hz!
* Energy = noise energy + speech energy
* speech (voiced or unvoiced) kurtosis related to speech energy
* gaussian noise kurtosis = 0
* soo... can use this to estimate SNR
* SNR errors
- due to smoothing and finite length cumulant estimation
- mainly affect higher filterbank bands
- therefore affect mainly affects unvoiced speech
* qualitively tested on gaussian and street noise & seems to work
* would it work on less Gaussian noise?

* NOTE: Nemer didn't use this trick to estimate SNR in his `01 VAD paper

* Marzinzik speech pause (VAD) paper says is promising way to est. noise.
* but Marzinzik also says tests on neg SNR and different noise classes are needed.},
  Url                      = {http://ieeexplore.ieee.org/iel5/97/16666/00769361.pdf?isNumber=16666&prod=IEEE+JNL&arnumber=769361&arSt=171&ared=174&arAuthor=Nemer%2C+E.%3B+Goubran%2C+R.%3B+Mahmoud%2C+S.%3B}
}

@InProceedings{nemer98thirdOrdPitch,
  Title                    = {The third-order cumulant of speech signals with application to reliable pitch estimation},
  Author                   = {Elias Nemer and Rafik Goubran and Samy Mahmoud},
  Booktitle                = {Statistical Signal and Array Processing, {IEEE} {SP} Workshop on},
  Year                     = {1998},
  Pages                    = {427-430},

  Comment                  = {443:ReadNo},
  Review                   = {Cumulant of LPC residual improves F0 det in some kinds of noise
* analytical expressions for cumulants of flattened speech
- perhaps better done in `01 VAD paper
* just search for max in cumulant for lag corresponding to F0
* had to lowpass residual 1st (why is explained in `01 VAD paper)
* hard and fixed 3D threshold rule for voicing determination
* performance:
- tests not described really but...
- about the same as autocorr F0 det for white and babble noise
- better for street noise
- says skewness improves in all noise types
-- apparently because it helps with voicing detection

* use for voicing det for artic features ICA mixing matrix update decision/weight?

Note: also has an IEEE paper on efficient 3rd order correlation compuatation},
  Url                      = {http://ieeexplore.ieee.org/iel4/5953/15928/00739426.pdf?isNumber=15928&prod=IEEE+CNF&arnumber=739426&arSt=427&ared=430&arAuthor=Nemer%2C+E.%3B+Goubran%2C+R.%3B+Mahmoud%2C+S.%3B}
}

@InProceedings{ng01specClust,
  Title                    = {On Spectral Clustering: Analysis and an algorithm},
  Author                   = {Andrew Y. Ng and Michael I. Jordan and Yair Weiss},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2001},
  Volume                   = {14},

  Review                   = {The impressive "few lines of matlab" clustering algorithm seen at the CS colloquium

I HAVE COPIED THIS TO ENERGY.BIB (Ng02specClust) and have attached more comments and a paper there.

Xiaoyan08spectClustSelfAdapt (energy.bib) is one possible way to select # clusters.},
  Url                      = {citeseer.nj.nec.com/ng01spectral.html}
}

@InProceedings{nguyen04mtngRecogRT04s,
  Title                    = {Panasonic Real-Time Meeting Room {STT}},
  Author                   = {Patrick Nguyen},
  Booktitle                = {{NIST} Meeting Recognition Workshop},
  Year                     = {2004},

  Comment                  = {ReadYes},
  Review                   = {Panasonic NIST meeting speaker seg/clust

multi-mic: ASR on each channel w/ combined hypotheses -- no beamforming, fancy VAD, etc
Headmic: used multi-mic setup and assigned to most likely (HMM) channel. Didn't work well}
}

@InProceedings{nigam00cotrainEM,
  Title                    = {Analyzing the Effectiveness and Applicability of Co-training},
  Author                   = {Kamal Nigam and Rayid Ghani},
  Booktitle                = {CIKM},
  Year                     = {2000},
  Pages                    = {86-93},

  File                     = {nigam00cotrainEM.pdf:nigam00cotrainEM.pdf:PDF},
  Review                   = {Co-EM paper discussed w/ Mari, Dustin and Sangyun},
  Url                      = {citeseer.ist.psu.edu/nigam00analyzing.html}
}

@InProceedings{Nishiura00multiLocCSP,
  Title                    = {Localization of multiple sound sources based on a CSP analysis with a microphone array},
  Author                   = {Nishiura, T. and Yamada, T. and Nakamura, S. and Shikano, K.},
  Booktitle                = {ICASSP},
  Year                     = {2000},
  Pages                    = {II1053--II1056vol.2},
  Volume                   = {2},

  Doi                      = {10.1109/ICASSP.2000.859144},
  File                     = {Nishiura00multiLocCSP.pdf:Nishiura00multiLocCSP.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {synchronous addition method of adding pairwise correlations
* requires more than 2 microphone arrays (known positions) so can't use
* based on finding some kind of cross-point that I didn't bother trying to understand},
  Timestamp                = {2007.08.10}
}

@InProceedings{nix03smcSpkrSep,
  Title                    = {Computational Auditory Scene Analysis by using statistics of high-dimensional speech dynamics and sound source direction},
  Author                   = {Johannes Nix and Michael Kleinschmidt and Volker Hohmann},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {1441-1444},

  Comment                  = {571: ReadNo},
  Review                   = {speaker separation w/ sequential monte-carlo methods}
}

@Article{Nord98neuralInputContrib,
  Title                    = {A novel method for examination of the variable contribution to computational neural network models.},
  Author                   = {Nord, L. I. and Jacobsson, S. P.},
  Journal                  = {Chemometrics and Intelligent Laboratory Systems},
  Year                     = {1998},
  Pages                    = {153-160},
  Volume                   = {44},

  Owner                    = {scotto},
  Review                   = {SZW, which zeroes neural net inputs and measures the change in classifier error in an attempt to measure input importance},
  Timestamp                = {2008.01.30}
}

@Article{Okun06FastNonnegativeMatrix,
  Title                    = {Fast Nonnegative Matrix Factorization and Its Application for Protein Fold Recognition},
  Author                   = {Okun, Oleg and Priisalu, Helen },
  Journal                  = {EURASIP Journal on Applied Signal Processing},
  Year                     = {2006},
  Pages                    = {Article ID 71817, 8 pages},
  Volume                   = {2006},

  Doi                      = {doi:10.1155/ASP/2006/71817},
  File                     = {Okun06FastNonnegativeMatrix.pdf:Okun06FastNonnegativeMatrix.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Normalizaing NNMF inputs to (0,1) speeds up NNMF by 11x},
  Timestamp                = {2007.03.01},
  Url                      = {http://www.hindawi.com/GetArticle.aspx?doi=10.1155/ASP/2006/71817}
}

@InProceedings{okuno99combining,
  Title                    = {Combining independent component analysis and sound stream segregation},
  Author                   = {H. Okuno and S. Ikeda and T. Nakatani},
  Booktitle                = {Proc. of IJCAI Workshop on Computational Auditory Scene Analysis},
  Year                     = {1999},
  Pages                    = {92-8},

  Comment                  = {183: ReadYes},
  Review                   = {Speaker segregator using harmonics sieve and ICA
* known # speakers, breaks down during interruptions
* hybrid harmonic sieve and ICA separator
* ICA works in freq domain
* ICA permutation across freq bins handled by correlation 
-- would clustering w/ # of spkrs be better?
* binaural dir finder breaks down at <= 20 degrees
* # mics >= # spkrs required by ICA
-- gets around by using BiHBSS to generate pairs for separation
* iterative for > 2 spkrs
* maybe use for overlap resolution? },
  Url                      = {citeseer.nj.nec.com/okuno99combining.html}
}

@InProceedings{okuno97challenge3,
  Title                    = {Challenge Problem for Computational Auditory Scene Analysis: Understanding Three Simultaneous Speeches },
  Author                   = {H. G. Okuno and T. Nakatani and T. Kawabata},
  Booktitle                = {Proc. of IJCAI-97},
  Year                     = {1997},
  Pages                    = {30-35},

  Comment                  = {201: ReadYes},
  Review                   = {Three speaker separation using direction finding
* localization better w/ HRTF than w/ simple stereo
* iterative adaptive window techniques can localize simultaneous speech
* harmonic assumption allows localization during interruptions
* maybe use for overlap resolution? }
}

@TechReport{baxter95mmlBayes,
  Title                    = {{MML} and Bayesianism: similarities and differences (Introduction to minimum encoding inference -- Part {II})},
  Author                   = {J. J. Oliver and R. A. Baxter},
  Institution              = {Computer Science Dept. {Monash} University},
  Year                     = {1995},
  Number                   = {Tech Report 206},

  Comment                  = {74: ReadNo},
  Review                   = {MDL and MML. (MDL related to BIC?) relevant to number of speakers (clusters) and model selection. Mentions Jeffrey's Prior, which is what's used in Cheeseman&Stutz autoclass}
}

@Article{olshausen96sparse,
  Title                    = {Emergence of simple-cell receptive field properties by learning a sparse code for natural^^ images},
  Author                   = {B.A. Olshausen and D.J. Field},
  Journal                  = {Nature},
  Year                     = {1996},
  Pages                    = {607-609},
  Volume                   = {381},

  Comment                  = {ReadNo, Print},
  Review                   = {Sparse Code paper related to curvelets -- they derive multi-scale, increasingly directional image basis functions (OF basis)}
}

@InProceedings{omar03maxMutInfProj,
  Title                    = {Maximum Conditional Mutual Information Projection For Speech Recognition},
  Author                   = {Mohamed Kamal Omar and Mark Hasegawa-Johnson},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {505-508},

  Comment                  = {459: ReadNo},
  Review                   = {HLDA and max mutual information. Use EM iterations for spkr model ICA?}
}

@Misc{garcia94spchEnhance,
  Title                    = {Overview of speech enhancement techniques for automatic speaker recognition},

  Author                   = {J. Ortega-Garcia and J. Gonzalez-Rodriguez},
  Year                     = {1994?},

  Comment                  = {257: ReadYes},
  Review                   = {Overview of cleanup before speaker ID 
* spectral subtraction, over-subtraction, non-linear over-subtraction, LMS-adaptive w/ perfet reference chan, delay and sum 
* LMS-adaptive handles noisy reverb well but ref chan not realistic

* single chan sst-over-subtract generally best for white; NSS generally best for noise but not hugely better than SS or SSO 
* delay and sum BF also handles noisy reverb but not as well as unrealistic ref chan LMS adapt. 
* experiments done w/ SNR but this isn't well correlated w/ speech quality [slyht moses, `93]}
}

@Misc{ostendorf00em,
  Title                    = {Expectation-maximization algorithm notes.},

  Author                   = {M. Ostendorf},
  Year                     = {2000},

  Comment                  = {88: ReadYes},
  Review                   = {Mari's EM algorithm notes from EE596I}
}

@Misc{ostendorfXXambigPlane,
  Title                    = {Joint use of dynamical classifiers and abmiguity plane features},

  Author                   = {M. Ostendorf and L. Atlas and R. Fish and S. Sukittanon and G. D. Bernard},
  Year                     = {unknown},

  Comment                  = {57: ReadYes},
  Review                   = {Use ambiguity plane features instead of deltas in hmm.
* longer time frame
* toolwear is application}
}

@InProceedings{Otterson07locFeats,
  Title                    = {Improved Location Features for Meeting Speaker Diarization},
  Author                   = {Scott Otterson},
  Booktitle                = {Interspeech},
  Year                     = {2007},

  Owner                    = {scotto},
  Review                   = {My interspeech 2007 paper: Hilbert envelope correlation features, PCA, energy ratios},
  Timestamp                = {2007.07.21}
}

@TechReport{otterson05ekosPhaseIReport,
  Title                    = {{EKOS} Lysis Detection Study},
  Author                   = {Scott Otterson},
  Institution              = {{EKOS} Corp},
  Year                     = {2005},

  Comment                  = {ReadYes},
  Review                   = {Phase I final report for EKOS},
  Url                      = {K:/doc/finalReport}
}

@TechReport{otterson02vadTechRep,
  Title                    = {Meeting Voice Activity Detection From Desktop Microphones},
  Author                   = {Scott Otterson},
  Institution              = {SSLI Lab, University of Washington},
  Year                     = {2002},

  Comment                  = {ReadYes},
  Review                   = {The VAD writeup I passed out to ICSI}
}

@TechReport{otterson04ovdetTechNote,
  Title                    = {Speaker overlap detection with {Hough} transform pitch features},
  Author                   = {Scott Otterson and Sadaoki Furui and Mari Ostendorf},
  Institution              = {Univesity of Washington},
  Year                     = {2004},
  Number                   = {2004-0012},

  Review                   = {FuruiLab overlap detection stuff}
}

@InProceedings{Otterson07overlap,
  Title                    = {Efficient use orf Overlap information in Speker Diarization},
  Author                   = {Scott Otterson and Mari Ostendorf},
  Booktitle                = {ASRU},
  Year                     = {2007},

  Owner                    = {scotto},
  Review                   = {My overlap handling paper},
  Timestamp                = {2007.11.11}
}

@InProceedings{padrta03spkrIDdataAmt,
  Title                    = {On the Amount of Speech Data Necessary for Successful Speaker Identification},
  Author                   = {Ale?s Padrta and Vlasta Radov},
  Booktitle                = {Eurospeech},
  Year                     = {2003},
  Pages                    = {3021-3024},

  Comment                  = {584: ReadNo},
  Review                   = {title says it}
}

@InProceedings{jin00rmAcoustOnMfccs,
  Title                    = {The effects of the room acoustics on {MFCC} speech parameter},
  Author                   = {Yue Pan and Alex Waibel},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2000},

  Comment                  = {Print, ReadNo},
  File                     = {jin00rmAcoustOnMfccs.pdf:jin00rmAcoustOnMfccs.pdf:PDF},
  Review                   = {Clipping low energy log mel freq improves reverb/noise spkrID robustness
* Clip: DCT(MFCC) -> clip -> DCT-> new MFCC
* close talk mic train / distant mic test: 38.9% accuracy
* clipped close talk train / distant mic test: 86.9% accuracy
* not well explained but clipping helps w/ convolutional dist because:
--(log X + log H) / log X is larger for small X (additive conv dist)
* claims reverb conv dist differs from phone conv dist. (prbbly wrong)
* anyway, says CMS won't work as well for constant reverb but this

--isn't demonstrated.
* Anyway, clipping helps a lot but don't know if CMS is just as good
* Seems like this might be better because CMS assumes stationary 
--channel which we won't have in a room when someone moves.
* clipping threshold was from estimated noise

* Mapping: 
* distant cepstra are more compact than close cepstra
* Also trains a neural net to map distant talking cepstrum to close
* This improve accuracy by < 1%
* 9 frame input to NN
* I don't know about this},
  Url                      = {citeseer.ist.psu.edu/330360.html}
}

@Article{papadokonstantakis06compareVarInfluNN,
  Title                    = {Comparison of recent methods for inference of variable influence in neural networks},
  Author                   = {Stavros Papadokonstantakis and Argyrios Lygeros and Sven P. Jacobsson},
  Journal                  = {Neural Networks},
  Year                     = {2006},
  Number                   = {4},
  Pages                    = {500-513},
  Volume                   = {19},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Booktitle                = {Neural Networks},
  Ee                       = {http://dx.doi.org/10.1016/j.neunet.2005.09.002},
  File                     = {papadokonstantakis06compareVarInfluNN.pdf:papadokonstantakis06compareVarInfluNN.pdf:PDF},
  Owner                    = {scotto},
  Timestamp                = {2008.01.21},
  Url                      = {http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6T08-4HSXVWG-1&_user=582538&_rdoc=1&_fmt=&_orig=search&_sort=d&view=c&_acct=C000029718&_version=1&_urlVersion=0&_userid=582538&md5=e45394220198aa3b3d0f6656c6cd2cc4}
}

@Article{Pardo07spkrDiarizSeveralSrc,
  Title                    = {Speaker Diarization For Multiple-Distant-Microphone Meetings Using Several Sources of Information},
  Author                   = {Pardo, Jose and Anguera, Xavier and Wooters, Chuck},
  Journal                  = {IEEE Trans. on Computers},
  Year                     = {2007},
  Number                   = {9},
  Pages                    = {1189-1224},
  Volume                   = {56},

  File                     = {Pardo07spkrDiarizSeveralSrc.pdf:Pardo07spkrDiarizSeveralSrc.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Journal paper for the ICSI NIST 2006 diarization system. Lots of good detail.},
  Timestamp                = {2007.09.10},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=4288088&isnumber=4288079&punumber=12&k2dockey=4288088@ieeejrns&query=%28%28speaker+diarization+for+multiple-distant-microphone+meetings+using+several+sources+of+information%7E%7E%29%3Cin%3Emetadata%29&pos=0}
}

@InProceedings{Pardo06diarizMixTimeDiff,
  Title                    = {Speaker Diarization for Multiple Distant Microphone Meetings: Mixing Acoustic Features And Inter-Channel Time Differences},
  Author                   = {Jose M. Pardo and Xavier Anguera and Chuck Wooters},
  Booktitle                = {ICSLP},
  Year                     = {2006},

  File                     = {:Pardo06diarizMixTimeDiff.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Reports RT06 results with both official refs and forced alignments.
also explains VAD a bit},
  Timestamp                = {2008.01.04},
  Url                      = {www.icsi.berkeley.edu/pubs/speech/is06pardo.pdf}
}

@Article{parra00convBssNonStat,
  Title                    = {Convolutive blind separation of non-stationary source},
  Author                   = {Lucas Parra and Clay Spence},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2000},
  Number                   = {3},
  Pages                    = {320-327},
  Volume                   = {8},

  Comment                  = {433: ReadNo},
  Review                   = {convolutive matlab code
matlab at: http://ida.first.gmd.de/~harmeli/download/download_convbss.html},
  Url                      = {http://ieeexplore.ieee.org/iel5/89/18179/00841214.pdf?isNumber=18179&prod=IEEE+JNL&arnumber=841214&arSt=320&ared=327&arAuthor=Parra%2C+L.%3B+Spence%2C+C.%3B}
}

@InProceedings{parra98convBSSdecorr,
  Title                    = {Convolutive blind source separation based on multiple decorrelation},
  Author                   = {L. Parra and C. Spence and B. De Vries},
  Booktitle                = {Neural Networks for Signal Processing},
  Year                     = {1998},
  Pages                    = {23-32},

  Comment                  = {441: ReadNo},
  Review                   = {CoBliSS algorithm
Matlab: http://ida.first.gmd.de/~harmeli/download/download_convbss.html},
  Url                      = {http://ieeexplore.ieee.org/iel4/5736/15338/00710626.pdf?isNumber=15338&prod=IEEE+CNF&arnumber=710626&arSt=23&ared=32&arAuthor=Parra%2C+L.%3B+Spence%2C+C.%3B+De+Vries%2C+B.%3B}
}

@Misc{pavlovic99DBNfigTrack,
  Title                    = {A dynamic {Bayesian} network approach to figure tracking using learned dynamic models},

  Author                   = {V. Pavlovic and J. M. Rehg and T. Cham},

  Comment                  = {34.5: ReadNo},
  Review                   = {Relevant to pitch or overlap or speaker tracking. uses dyanamic bayesian netork}
}

@InProceedings{pearlmutter97maximum,
  Title                    = {Maximum Likelihood Blind Source Separation: A Context-Sensitive Generalization of {ICA}},
  Author                   = {Barak A. Pearlmutter and Lucas C. Parra},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {1997},
  Editor                   = {Michael C. Mozer and Michael I. Jordan and Thomas Petsche},
  Pages                    = {613},
  Publisher                = {The {MIT} Press},
  Volume                   = {9},

  Comment                  = {ReadNo},
  Review                   = {uses AR source models},
  Url                      = {citeseer.nj.nec.com/pearlmutter97maximum.html}
}

@InProceedings{pelecanos00vqgSpkrID,
  Title                    = {Vector quantization based {Gaussian} modeling for speaker verification},
  Author                   = {Pelecanos, J and Myers, S and Sridharan, S and Chandran, V},
  Booktitle                = {International Conference on Pattern Recognition (ICPR)},
  Year                     = {2000},
  Pages                    = {294-7},

  Comment                  = {ReadNo}
}

@Article{peng05featSelMutInfo,
  author   = {Hanchuan Peng and Fuhui Long and Ding, C.},
  title    = {Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy},
  journal  = {Transactions on Pattern Analysis and Machine Intelligence},
  year     = {Aug. 2005},
  volume   = {27},
  number   = {8},
  pages    = {1226-1238},
  issn     = {0162-8828},
  doi      = {10.1109/TPAMI.2005.159},
  file     = {:peng05featSelMutInfo.pdf:PDF},
  keywords = { feature extraction, pattern classification, statistical analysis arrhythmia, cancer cell lines, first-order incremental feature selection, handwritten digits, linear discriminate analysis, lymphoma tissues, maximal statistical dependency criterion, minimal-redundancy-maximal-relevance criterion, mutual information criteria, naive Bayes, pattern classification systems, support vector machine},
  review   = {NOTE: I HAVE COPIED THIS TO ENERGY.BIB

Use to select good channel pairs?, 

 Heuristics used in this paper generalized inBrown12condLikInfoFeatSel (energy.bib)

 Yang09featSelMLPrand in energy.bib might be better?

has matlab here: 
http://www.mathworks.com/matlabcentral/fileexchange/loadFile.do?objectId=14608&objectType=File, other version, including C/C++ here: http://research.janelia.org/peng/proj/mRMR/index.htm

Implemented in R in the parmigene package, mrnet function:
http://www.inside-r.org/packages/cran/parmigene/docs/mrnet

kind of like Alfonso10monMutInfoOpt but not exactly (?)


Schaffernicht09residMutInfoFeatSel: a way to avoid the redundancy subtraction, which is a bit of a hack},
  url      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1453511},
}

@InProceedings{Peng03ExploitUnlabContrast,
  Title                    = {Exploiting Unlabeled Data for Improving Accuracy of Predictive Data Mining},
  Author                   = {Kang Peng and Slobodan Vucetic and Bo Han and Hongbo Xie and Zoran Obradovick},
  Booktitle                = {ICDM},
  Year                     = {2003},
  Pages                    = {267},

  Comment                  = {ReadNo},
  File                     = {Peng03ExploitUnlabContrast.pdf:Peng03ExploitUnlabContrast.pdf:PDF},
  Keywords                 = {unsupervised, prosody,},
  Owner                    = {scotto},
  Review                   = {Possible technique to replace weakly supervised EM in break label prediction: contrast classifier},
  Timestamp                = {2006.03.27},
  Url                      = {http://csdl2.computer.org/persagen/DLAbsToc.jsp?resourcePath=/dl/proceedings/&toc=comp/proceedings/icdm/2003/1978/00/1978toc.xml&DOI=10.1109/ICDM.2003.1250929}
}

@Misc{penny00hidden,
  Title                    = {Hidden Markov Independent Components Analysis},

  Author                   = {W. Penny and R. Everson and S. Roberts},
  Year                     = {2000},

  Comment                  = {ReadNo},
  Review                   = {uses AR source models, mixtures of generalized Gaussians and HMM source switching. What else could you ask for?},
  Text                     = {Penny W.D., Everson R., Roberts S.J.: Hidden Markov Independent Components Analysis, to appear in: Independent Components Analysis, (Ed M. Girolami), Kluwer Academic Publishers, 2000.},
  Url                      = {citeseer.nj.nec.com/penny00hidden.html}
}

@InBook{penny00icaOrderDyn,
  Title                    = {{ICA}: Principles and Practice},
  Author                   = {W.D. Penny and S.J. Roberts and R. Everson},
  Chapter                  = {ICA: Model-order selection and dynamic source models },
  Pages                    = {299-314},
  Publisher                = {Cambridge University Press},
  Year                     = {2000},

  Comment                  = {385: ReadYes},
  File                     = {penny00icaOrderDyn.ps:penny00icaOrderDyn.ps:PDF},
  Review                   = {Estimate # sources when Nsources<Nsensors; several src models incl'd AR!
* Unmixing matrix constrained to decorrelating inputs
- simplified computation
- allows noise to be separately estimated by PCA
* interative ML unmixing/source estimation
Laplace approx (i.e. BIC or MDL). 
* estimates # of sources
* Works even if sources aren't Gaussian
* can also estimate the number of taps in a GAR model (below)
Source models considered:
* Gaussian
* inverse cosh
* generalized exponential (generalized Gaussian)
* Generalized Autoregressive (AR sources + noise. Like speech!)
Tests on mixed music and EEG sources
* low noise: GAR model results in order-of-mag improvement in separation
* high noise: modest benefit},
  Url                      = {http://www.fil.ion.ucl.ac.uk/~wpenny/publications/wpica.ps}
}

@Article{Penny99autoRelDetClassification,
  Title                    = {Bayesian neural networks for
classification: How useful is the evidence framework?},
  Author                   = {Penny, W. D. and Roberts, S. J.},
  Journal                  = {Neural Networks,},
  Year                     = {1999},
  Pages                    = {877-892},
  Volume                   = {12},

  Owner                    = {scotto},
  Review                   = {used neural net automatic relevance determination for classification},
  Timestamp                = {2008.01.30}
}

@Misc{perkins-pulse,
  Title                    = {Pulse Train Deinterleaving Via The Hough Transform},

  Author                   = {Jane Perkins},

  Comment                  = {ReadNo},
  Review                   = {good for # of talker est?, overlap det?},
  Url                      = {citeseer.nj.nec.com/12282.html}
}

@Misc{perkinsNumSource,
  Title                    = {Source Number Estimator In Pulse Train Data},

  Author                   = {Jane Perkins},

  Comment                  = {ReadNo},
  Review                   = {good for # of talker est?, overlap det?},
  Url                      = {citeseer.nj.nec.com/60271.html}
}

@Misc{perry00em,
  Title                    = {{EM} algorithm for sequence estimation over Gauss-Markov {ISI} channels},

  Author                   = {R. Perry and W. Berger and K. Buckley},
  Year                     = {2000},

  Comment                  = {Print, ReadNo},
  Review                   = {But LPC-like extension for MHT tracker?},
  Text                     = {R. Perry, W. Berger and K. Buckley, EM algorithm for sequence estimation over Gauss-Markov ISI channels, ICC 2000 Conf., June 2000.},
  Url                      = {citeseer.nj.nec.com/perry00em.html}
}

@InProceedings{perry00EMloc,
  Title                    = {Maximum likelihood source localization using the {EM} algorithm to incorporate prior parameter distributions},
  Author                   = {R. Perry and K. Buckley.},
  Booktitle                = {Sensor Array and Multichannel Signal Processing Workshop. Proc., {IEEE}},
  Year                     = {2000},
  Pages                    = {351-355},

  Comment                  = {203: ReadYes},
  Review                   = {EM localization algorithm that handles multiple, known # of sources
* does EM
* [10] is extension for LPC-like models
* 1st order Markov dependence between samples => EM forward-backward
* This is CML: SML may work better. See [1,3], [3] is music.
* could MUSIC be EM-ized?
* does it matter if array not linear?}
}

@InBook{grunwald04minDescLenTut,
  Title                    = {Advances in Minimum Description Length: Theory and Applications},
  Author                   = {Peter Gr??unwald, and Myung and Pitt},
  Chapter                  = {A Tutorial Introduction to the Minimum Description Length Principle},
  Publisher                = {MIT Pres},
  Year                     = {2004},

  File                     = {grunwald04minDescLenTut.pdf:grunwald04minDescLenTut.pdf:PDF},
  Review                   = {explains diff between MDL and BIC (see bookmark) pdf is 1st two chapters of the book},
  Url                      = {http://www.learningtheory.org/articles/mdlintro.pdf}
}

@InProceedings{peters03acoustClustLims,
  Title                    = {On the Limits of Cluster-Based Acoustic Modeling},
  Author                   = {S. Douglas Peters},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {1857-1860},

  Comment                  = {575: ReadNo},
  Review                   = {mutual info across utterance => poor self consistency => problems for short utterance ICA?}
}

@InProceedings{Peterson05analFastLoc,
  Title                    = {Analysis of Fast Localization Algorithms for Acoustical Environments},
  Author                   = {Peterson, J.M.and Kyriakakis, C.},
  Booktitle                = {Signals, Systems and Computers},
  Year                     = {2005},
  Pages                    = {1385- 1389},

  Comment                  = {646:ReadNo},
  File                     = {Peterson05analFastLoc.pdf:Peterson05analFastLoc.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Brute force max power beamformer search w/ sampling from spatial frequency
* This is SRP-PHAT () but instead of multiresolution cartesian search, goes along grid determined by spatial freqs
* I didn't understand the spatital freq equs. but I can't use them anyway b/c I don't know mic spacing
* Is more robust to reverb than SRP-PHAT},
  Timestamp                = {2007.08.03},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1599992}
}

@InProceedings{pfau01meetingSAD,
  Title                    = {Multispeaker speech activity detection for the {ICSI} meeting recorder},
  Author                   = {T. Pfau and D. P. W. Ellis and A. Stolcke},
  Booktitle                = {ASRU},
  Year                     = {2001},

  Comment                  = {103: ReadYes},
  File                     = {pfau01meetingSAD.pdf:pfau01meetingSAD.pdf:PDF},
  Review                   = {Speech activity detection for head mics in ICSI meeting recorder data
- focus is on SAD for only the headmic channel (not other mics)
- two main state HMM (spch/nospch) w/ intermediate states
- only two GMM's (somehow, transitions happen by prob only?)
- Features (25D):
-- normalized loundess in 20 bark bands
-- energy
-- total energy
-- total loudness
-- modified loudness
-- zero crossing

* he calls it SAD
* use the gain normalizations in section 2.2.2 for confidence features
 -- see my 2/21/06 notes in my 5/2006-6/7/2006 notebook},
  Timestamp                = {2006.10.28},
  Url                      = {www.icsi.berkeley.edu/ftp/global/pub/speech/papers/asru2001-tpfau.pdf}
}

@InProceedings{pham01bssContrast,
  Title                    = {{CONTRAST} {FUNCTIONS} {FOR} {BLIND} {SEPARATION} {AND} {DECONVOLUTION} {OF} {SOURCES}},
  Author                   = {Dinh Tuan Pham},
  Booktitle                = {Independent Components Analysis and Signal Separation},
  Year                     = {2001},
  Pages                    = {37-42},

  Comment                  = {379: ReadYes},
  Review                   = {Theoretical Contrast funcs for convolutive mixing, cumulants, gaussian sigs
* source dists assumed known; how to get there is for later papers
* I think Cardoso's "Three easy..." does this
Marginal Contrasts
* mutual info between unmixed outs = 0 if correctly unmixed
* contrast turns into sum of =individual= unmixed entropies -log(det(B))
* this avoids the curse of dimensionality
* superadditive: many classes of superadditive contrasts functions
-- including one based on Fisher Information matrix??
-- does not require orthogonal transform
Contrasts w/ orthogonality constraint
* these are subadditive 
* explains why cumulants require orthogonality(related to pre-whitening)
Joint distribution contrasts (temporal dependence)
* shows a way of interleaving samples (can I use this to get extra channels for mono ICA?)
* many joint contrast functions given
Contrasts allowing assumptiong of Gaussian signals
* different than marginal contrasts
Contrasts for filterbanks
* use this for wavelet or DFT outputs?
Contrasts for convolutive mixtures
* surprising ambiguity: you don't which signal conv'ed w/ which filt
* how do they do this, then?
Some trick at the end that lets you construct cumulant contrasts in superadditive ways (I didn't quite get it).},
  Url                      = {http://ica2001.ucsd.edu/}
}

@Article{pham97quasiScore,
  Title                    = {Blind separation of mixture of independent sources through a quasi-maximum likelihood approach},
  Author                   = {Dinh Tuan Pham and Garat, P},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {1997},
  Number                   = {7},
  Pages                    = {1712-1725},
  Volume                   = {45},

  Comment                  = {ReadNo},
  Review                   = {Original derivation of ICA score functions. Also, of source basis functions.},
  Url                      = {http://ieeexplore.ieee.org/iel4/78/13197/00599941.pdf?isNumber=13197&prod=JNL&arnumber=599941&arSt=1712&ared=1725&arAuthor=Dinh+Tuan+Pham%3B+Garat%2C+P.}
}

@InProceedings{phan88harmTrack,
  Title                    = {New method for time-varying harmonic frequency tracking},
  Author                   = {Phan, B. C.and Hu, Y. H.},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1988},
  Pages                    = {2228-2231},
  Volume                   = {4 },

  Comment                  = {ReadNo},
  Url                      = {http://ieeexplore.ieee.org/search97/s97is.vts?Action=Search&SearchPage=VSearch.htm&sortfield=pyr&sortorder=desc&ResultTemplate=adv_crst.hts&ResultCount=25&ViewTemplate=lpdocview.hts&queryText=New+method+for+time-varying+harmonic+frequency+tracking}
}

@Article{phan00spkIDnn,
  Title                    = {Speaker Identification Using Neural Nets and Wavelets},
  Author                   = {F. Phan and E. Micheli-Tzanakou and S. Sideman},
  Journal                  = {IEEE Engineering in Medicine and Biology},
  Year                     = {2000},
  Number                   = {1},
  Pages                    = {92-101},
  Volume                   = {19},

  Comment                  = {166: ReadYes},
  Review                   = {Bogus: wavelet features w/ no time warping. Really just closed set speaker ID w/ a known, single word.}
}

@TechReport{philibert99spchMusic,
  Title                    = {Speech / Music Discriminator },
  Author                   = {Arnaud Philibert},
  Institution              = {Tampere University of Technology},
  Year                     = {1999},

  Comment                  = {383: ReadYes},
  Review                   = {Speech/music features/decision algs compared; good pre-199 lit. survey
* neat table comparing 24 features v.s. authors who used them (p. 19)
* who ref'd who table on p. 20
Features experimented with:
* spectral centroid/flux, rolloff point, residual cepstrum,
zero-crossing, 4Hz modulation
* 4Hz modulation rejected
* best is centroid
Decision algorithms compared:
* K-NN, Gaussian, decision tree, VQ (didn't work)
* KNN or Gaussian are best
* best overall rate was 95% correct w/ KNN (92% w/ Gaussian)
* but Gaussian mabye not done correctly and could have been GMM instead},
  Url                      = {http://www.cs.tut.fi/sgn/arg/arno/}
}

@Article{pigeon99logistic,
  Title                    = {Applying Logistic Regression to the Fusion of the {NIST} 99 1-Speaker Submissions},
  Author                   = {St?phane Pigeon and Pascal Druyts and Patrick Verlinde},
  Journal                  = {Digital Signal Processing},
  Year                     = {2000},
  Pages                    = {237-248},
  Volume                   = {10},

  Comment                  = {ReadNo}
}

@InProceedings{pirinen05doaConf,
  Title                    = {Normalized Confidence Factors for Robust Direction of Arrival Estimation},
  Author                   = {Tuomo W. Pirinen},
  Booktitle                = {ISCAS},
  Year                     = {2005},

  Comment                  = {612: ReadYes},
  File                     = {pirinen05doaConf.pdf:pirinen05doaConf.pdf:PDF},
  Review                   = {Normalized cross-correlation Confidence using delay triangles
* relative delays of microphone triplets should sum to zero
* develops xcorr normalization over (0,1)
* of course, need at least 3 mics
* use for building location models: each xcpair gets a confidence
* PROBLEM: normalization requires knowledge of micophone positions!},
  Url                      = {http://www.cs.tut.fi/sgn/arg/tuomop/iscas2005.pdf}
}

@Article{plumbley00posICA,
  Title                    = {Algorithms for non-negative independent component analysis},
  Author                   = {M. D. Plumbley},
  Journal                  = {Submitted but didn't say where},
  Year                     = {2001},

  Comment                  = {ReadNo,Print},
  File                     = {plumbley00posICA.pdf:plumbley00posICA.pdf:PDF},
  Review                   = {Use for ICA of pos signals? e.g. evelope xcorr, freq magnitude, images},
  Url                      = {http://www.elec.qmul.ac.uk/staffinfo/markp/2002/algs4nnica02.pdf}
}

@Article{plumpe99glottal,
  Title                    = {Modeling the glottal flow derivative waveform with application to speaker identification},
  Author                   = {M. D. Plumpe and T. F. Quatieri and D. A. Reynolds},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {1999},
  Number                   = {5},
  Volume                   = {7},

  Comment                  = {136: ReadYes},
  Review                   = {Physically inspired model tries to extract the glottal pullses
* provides some additional speaker ID info over MFCC's of speech waveform.}
}

@Article{Poh05corrVarFusion,
  Title                    = {How do correlation and variance of base-experts affect fusion in biometric authentication tasks?},
  Author                   = {Poh, N and Bengio, S.},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {2005},
  Number                   = {11},
  Pages                    = {4384-4396},
  Volume                   = {53},

  Comment                  = {630:ReadYes},
  File                     = {Poh05corrVarFusion.pdf:Poh05corrVarFusion.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {How to select features to be fused for speaker ID. Positive correlation hurts, need to normalize scores 1st
* features should be either uncorrelated or negatively correlated (does this mean error)?
* features should be me/variance normalized before fusion
* could this somehow be used to figure out stream weights?
* Paper is kind of hard to under stand},
  Timestamp                = {2007.05.28},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1519704}
}

@InProceedings{pollak04snr,
  Title                    = {Efficient and Reliable Measurement and Simulation of Noisy Speech Background},
  Author                   = {Petr Pollak},
  Booktitle                = {EUSIPCO},
  Year                     = {2004},
  Pages                    = {491-494},
  Volume                   = {I},

  Comment                  = {ReadYes},
  File                     = {pollak04snr.pdf:pollak04snr.pdf:PDF},
  Review                   = {Paper describing methods used in the SNR software I'm using
The software is from:
http://noel.feld.cvut.cz/speechlab/start.php?page=download&lang=en},
  Url                      = {http://www.eurasip.org/content/Eusipco/2002/articles/paper097.pdf}
}

@InProceedings{polymenakos98transcription,
  Title                    = {Transcription of broadcast news - some recent improvements to {IBM's LVCSR} system},
  Author                   = {L. Polymenakos and P. Olsen and D. Kanvesky and R. Gopinath and P. Gopalakrishnan and S. Chen},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1998},
  Pages                    = {901-904},
  Volume                   = {2},

  Comment                  = {163: ReadYes},
  Review                   = {Broadcast news clust, gradual MLLR, clust w/ GLR dist & BIC stopping
* only segmented into 4 simple categories (clean spch, etc.)
* segmentation done w/ 
* say only diag cov Gaussians suitable for lin xform
* uniq xform/feature space dep on phone class (so diag cov works best)
* tested on 1996 Hub4
* simple acoustic models prevent splitting across word boundaries
* avoid overtrain: # MLLR params adapted incs as # data pts incs}
}

@InProceedings{potamitis03micArrayVADdenoise,
  Title                    = {{MICROPHONE} {ARRAY} {VOICE} {ACTIVITY} {DETECTION} {AND} {NOISE} {SUPPRESSION} {USING} {WIDEBAND} {GENERALIZED} {LIKELIHOOD} {RATIO}},
  Author                   = {Ilyas Potamitis and Eran Fishler},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {525-528},

  Comment                  = {562: ReadNo},
  Review                   = {compare w/ my multimic vad algorithm?}
}

@InProceedings{potamitis03multiModSpkrDOA,
  Title                    = {{MULTI}-{SPEAKER} {DOA} {TRACKING} {USING} {INTERACTIVE} {MULTIPLE} {MODELS} {AND} {PROBABILISTIC} {DATA} {ASSOCIATION}},
  Author                   = {Ilyas Potamitis and George Tremoulis and Nikos Fakotakis},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {517-520},

  Comment                  = {561: ReadNo},
  Review                   = {MUSIC w/ multiple interacting models for speaker DOA est.}
}

@InProceedings{potard04sndSrcWidth,
  Title                    = {{CONTROL} {AND} {MEASUREMENT} {OF} {APPARENT} {SOUND} {SOURCE} {WIDTH} {AND} {ITS} {APPLICATIONS} {TO} {SONIFICATION} {AND} {VIRTUAL} {AUDITORY} {DISPLAYS}},
  Author                   = {Guillaume Potard and Ian Burnett},
  Booktitle                = {Proc., {ICAD} 04-Tenth Meeting of the Intl. Conf. on Auditory Display},
  Year                     = {2004},

  Comment                  = {ReadNo},
  File                     = {potard04sndSrcWidth.pdf:potard04sndSrcWidth.pdf:PDF},
  Review                   = {Good description of auditory xcorr features, incl. spectral coherence. Good discussion of how point sources are perceived. Read!},
  Url                      = {www.icad.org/websiteV2.0/Conferences/ICAD2004/papers/potard_burnett.pdf}
}

@TechReport{potger01perfusion,
  Title                    = {Notes in Clinical Perfusion },
  Author                   = {K. C. Potger},
  Institution              = {Australasian Society of Cardio-Vascular Perfusionists, Inc.},
  Year                     = {2001},
  Type                     = {Web Report},

  Journal                  = {Australasiaon Society of Cardio-Vascular Perfusionists},
  Review                   = {Specifiic heat for blood:
http://www.perfusion.com.au/CCP/Physics&Chem/Specific%20Heat.htm},
  Url                      = {http://www.perfusion.com.au/CCP/Sentry.htm}
}

@Misc{priebe94changeptGMM,
  Title                    = {Change Point analysis with adaptive mixture models},

  Author                   = {C. E. Priebe and G. W. Rogers and D. J. Marchette and J. L. Solka},

  Comment                  = {52: ReadNo},
  Review                   = {Good for speaker change points? good for # of speakers?}
}

@Article{pu97neuromic,
  Title                    = {A neuromorphic microphone for sound localization},
  Author                   = {C. Pu and J. G. Harris and J. C. Principe},
  Journal                  = {Unknown},
  Year                     = {1997},

  Comment                  = {221: ReadYes},
  Review                   = {Make a fake ear, train an IIR filter to learn it's 'HRTF' 
* 6-tap gamma IIR to simulate monaural HRTF (gammas are easy to keep stable) 
* synthetic ear is paraboloid w/ offset mic in center (angle de. echo delay) 
* human ear has dead zone in 1.5KHz-3K (neither phase delay or spectral diff work well) 
* good equations for ITD and ILD (also explains the physics for limitations well) 
* good ILD, ITD explanation 
* fake ear is pretty giant}
}

@Article{pujol88jointloc,
  Title                    = {UNKNOWN},
  Author                   = {Pujol},
  Journal                  = {Bull. Seis. Soc. America},
  Year                     = {1988},
  Pages                    = {1179-1189},
  Volume                   = {78},

  Comment                  = {Print, ReadNo},
  Review                   = {I think this was the joint location and array calibration paper pointed out by either John Sahr or one of his geophysics colleagues}
}

@InProceedings{qi00bssMusicSep,
  Title                    = {Fast and Robust Online Music Signal Separation},
  Author                   = {Yuan Qi and P. S. Krishnaprasad and Shihab Shamma},
  Booktitle                = {Independent component analysis and blind signal separation, Intl. Conf. on},
  Year                     = {2000},

  Comment                  = {380: ReadYes},
  Review                   = {Music separation by BSS on wavelet filterbank outputs* adaptive BSS run on wavelet filterbank outputs
* nonholonomic, whatever that is.
* seems to assiciate unmixed signals w/ competitive learning clustering
* separates music types pretty well (violin/pop)
* can be slow: convergence in 18-102secs},
  Url                      = {http://www.isr.umd.edu/CAAR/pubs.html}
}

@InProceedings{Qin98pcaNcompsVRE,
  Title                    = {Determining the number of principal
components for best reconstruction.},
  Author                   = {Qin, S. J. and Dunia, R.},
  Booktitle                = {IFAC DYCOPS},
  Year                     = {1998},

  Owner                    = {scotto},
  Review                   = {primary reference for variance of reconstruction error method of selecting the # of PCA components.},
  Timestamp                = {2008.01.29}
}

@InProceedings{quast02pitchcar,
  Title                    = {Robust pitch tracking in the car environment},
  Author                   = {Holger Quast and Olaf Schreiner and Manfred R. Schroeder},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},

  Comment                  = {323: ReadYes},
  Review                   = {Four kinds of pitch tracking algorithms compared
* Outocorr: time domain autocorr
* Cepstrum: find cepstral peak
* Harmonic Product Spectrum (HPS): for each pitch guess
- multiply by harmonic sieve and sum
- compress freq by 2
- repeat
* Modulation spectrum
- calc Hilbert envelope in time (120ms window)
- FFT again to get modulation spectrum
- not like Les's stuff, which calc's mod spect at each FFT bin
- for this paper, the 2nd FFT was replaced by a wavelet transform
* For this paper, uses HPS w/ wavelet modulation spectrum

* says highest peak is not necessarily from F0 e.g. formant structure might cause 2nd or 3rd harmonic to be higher.

* HMM encodes prob of pitch change magnitude
* Viterbi decode of HMM},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/searchresult.jsp?query1=&scope1=metadata&op1=and&query2=&scope2=metadata&op2=and&query3=&scope3=metadata&queryText=%28%28robust+pitch+tracking+in+the+car+environment%29%3Cin%3Emetadata%29&history=yes&reqloc=adv&queryblock=Robust+pitch+tracking+in+the+car+environment&submit=Run+Search&srchlist=publist&coll1=ieeejrns&coll2=ieejrns&coll3=ieeecnfs&coll4=ieecnfs&coll5=ieeestds&coll6=preprint&coll7=books&currweek=08-Aug-2005&srchyr=allyr&py1=1950&py2=2005&disp=cit&maxdoc=100&ResultCount=25&SortField=Score&SortOrder=desc}
}

@Misc{quinn01LinearBayes,
  Title                    = {{Bayesian} inference for the linear model with gaussian disturbances},

  Author                   = {K. Quinn},
  Year                     = {2001},

  Comment                  = {79: ReadNo},
  Review                   = {Linear models 
* conjugate priors
* inverse gamma dist
* useful for number of spkrs/clusters, BIC, Laplace?}
}

@Article{raj02projVAD,
  Title                    = {Classifier-based non-linear projection for adaptive endpointing of continuous speech},
  Author                   = {Bhiksha Raja and Rita Singh},
  Journal                  = {Computer Speech and Language},
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {5-26},
  Volume                   = {17},

  Comment                  = {453: ReadYes},
  Review                   = {Details of CMU SPINE VAD/segmenter.
* a long paper with good explanation of dimension reduction
* tried to avoid Bayesian Classifier test/train mismatch
* says that adaptation has problems w/ high-Dim features (MLLR, MAP)
* so, project down to low-dim space where adaptation works
* #classes < #dims: likelihood dim reducing projection incurs no loss
* evaluated on SPINE 2001
* singh01spineASRseg has the results},
  Url                      = {http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6WCW-46XHFGG-1&_coverDate=01%2F31%2F2003&_alid=95190770&_rdoc=1&_fmt=&_orig=search&_qd=1&_cdi=6749&_sort=d&view=c&_acct=C000029718&_version=1&_urlVersion=0&_userid=582538&md5=796efe1c772c6fdaeee9ab32735d1763}
}

@Misc{ramoni00clustByDyn,
  Title                    = {Multivariate clustering by dynamics},

  Author                   = {M. Ramoni and P. Sebastiani and P. Cohen},

  Comment                  = {47.5: ReadYes},
  Review                   = {Agglomerative clustering by markov chain (not HMM) 
* markov chain: observations are directly observed discrete states
* merge candidates chosen by K-L dist. between transition probs
* merge if total prob increases
* stopping criteria is when prob doesn't increase
* dirichelet priors
* works only a tiny bit better than dynamic time warping
* smyth ref. clusers HMM's
* more details seem to be in sebastianis, romani, choeh: sequence learning via Bayesian Dyanamics (sebastianiXXbayesclust)}
}

@Article{rao00spchModComp,
  Title                    = {On decomposing speech into modulated components },
  Author                   = {A. Rao and R. Kumaresan},
  Journal                  = {IEEE Trans., Speech and Audio Proc.},
  Year                     = {2000},
  Pages                    = {240-254},
  Volume                   = {8},

  Comment                  = {316: ReadYes},
  Review                   = {Formants are Single Pole Filter outputs; related to Hilbert envelope. and Hilbert log spectrum. Tracks formants well. Maybe get pitch somehow?. I scanned this but did not read carefully
* maybe relevant to pitch and overlap detection}
}

@Article{rao96optHRTF,
  Title                    = {Optimal Head related transfer functions for hearing and monaural localization in elevation: a signal processing design perspective},
  Author                   = {K. R. Rao and J. Ben-arie},
  Journal                  = {IEEE trans. on biomed. eng.},
  Year                     = {1996},
  Number                   = {11},
  Pages                    = {1093-1104},
  Volume                   = {43},

  Comment                  = {217: ReadYes},
  Review                   = {HRTF computer optimized for elevational dir discrim. similar to actual human HRTF 
* hearing trades off w/ localization 
* heuristic params for what could be good or bad in hearing and localization

* only monaural, not stereo and only vertical 
* humans: < 2KHz use phase; >= 2KHz use amplitude for localization (amp resp flat below 2KHz and not above) 
* arguments are somewhat circular and accuracy is not demonstrated?}
}

@InProceedings{Rathi06statShapeKPCA,
  Title                    = {Statistical shape analysis using kernel PCA},
  Author                   = {Rathi, Y. and Dambreville, S. and Tannenbaum, A.},
  Booktitle                = {Image Processing: Algorithms and Systems, Neural Networks, and Machine Learning. Edited by Dougherty, Edward R.; Astola, Jaakko T.; Egiazarian, Karen O.; Nasrabadi, Nasser M.; Rizvi, Syed A. Proc., SPIE, Volume 6064, pp. 425-432 (2006).},
  Year                     = {2006},
  Editor                   = {{Dougherty}, E.~R. and {Astola}, J.~T. and {Egiazarian}, K.~O. and {Nasrabadi}, N.~M. and {Rizvi}, S.~A.},
  Pages                    = {425-432},
  Series                   = {Presented at the Society of Photo-Optical Instrumentation Engineers (SPIE) Conf.},
  Volume                   = {6064},

  Adsnote                  = {Provided by the Smithsonian/NASA Astrophysics Data System},
  Adsurl                   = {http://adsabs.harvard.edu/abs/2006SPIE.6064..425R},
  Doi                      = {10.1117/12.641417},
  File                     = {Rathi06statShapeKPCA.pdf:Rathi06statShapeKPCA.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Linear algebraic pre image for KPCA, inserting arbitrary input space distance functions
- Closed form approx to inverse, unique and no iteration (easy, computationaly usalbe)
- only self-cites
- only uses feature space distance. Better for me, I think, because I want to sample the manifold, and ignore outliers (other algs want to ignore outliers too?)
- reconstruction starts kind of like Kwok04kernPreImage but makes a (circular?) approx that the feature feature space PCA roughly matches the transformed input point -- might not be true for me since I want to go all the way to 1D!
- equations for exponential and polynomial kernels
- there's a way to plug in your own input space distance function (metric). The authors use it to insert a image processing derived shape match metric.
- not clear how 'n', the # of points compared was picked. Are they all of the training points or just the closest ones?
- Rathi06statShapeKernCompare compares this technique to some standard shape methods

Could I use the arbitrary matching metric?
1.) somehow insert zero closure phase?
2.) use this is clustering? the neighbors could be the lag vectors currently assigned (actually, you'd want to use probabilistic KPCA for this...)},
  Timestamp                = {2007.08.15},
  Url                      = {http://adsabs.harvard.edu/abs/2006SPIE.6064..425R}
}

@InProceedings{Rathi06statShapeKernCompare,
  Title                    = {Comparative Analysis of Kernel Methods for Statistical Shape Learning.},
  Author                   = {Yogesh Rathi and Samuel Dambreville and Allen Tannenbaum},
  Booktitle                = {CVAMIA},
  Year                     = {2006},
  Pages                    = {96-107},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Ee                       = {http://dx.doi.org/10.1007/11889762_9},
  File                     = {Rathi06statShapeKernCompare.pdf:Rathi06statShapeKernCompare.pdf:PDF},
  Review                   = {KPCA preimage solution
- closed form pre-image
- compares the KPCA reconstruction algorithm in Rathi06statShapeKPCA with some other techniques}
}

@InProceedings{Ratnaparkhi96maxentPOS,
  Title                    = {A maximum entropy part-of-speech tagger},
  Author                   = {Adwait Ratnaparkhi},
  Booktitle                = {Proc., Empirical Methods in Natural Language Processing},
  Year                     = {1996},
  Pages                    = {133-141},

  Citeseerurl              = {http://citeseer.ist.psu.edu/ratnaparkhi96maximum.html},
  File                     = {Downloading...:Downloading...:PDF},
  Owner                    = {scotto},
  Review                   = {Part of Speech (POS) tagger used by Sarah and Ivan. I'll use it for prosody break prediction.},
  Timestamp                = {2006.04.19}
}

@InProceedings{raykar03moveSpkrTrack,
  Title                    = {Tracking A Moving Speaker using Excitation Source Information},
  Author                   = {Vikas C. Raykar and Ramani Duraiswami and B. Yegnanarayana and S.R. Mahadeva Prasanna},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {69-72},

  Comment                  = {457: ReadNo},
  Review                   = {spkr loc w/ envelope of lpc residual
Xcorr localization, LPC inverse/Hilbert env, no filterbanks. Works better than GCC (of course), envelope not empirically justified (just waveform pictures)}
}

@Article{Raykar05SpeakerLocExcite,
  Title                    = {Speaker Localization Using Excitation Source Information in Speech},
  Author                   = {Vikas C. Raykar and B. Yegnanarayana and S. R. Mahadeva Prasanna and Ramani Duraiswami},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2005},
  Number                   = {5},
  Pages                    = {751-761},
  Volume                   = {13},

  File                     = {Raykar05SpeakerLocExcite.pdf:Raykar05SpeakerLocExcite.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Hilbert transform, inverse filtering better than GCC (PHAT) for speaker localization},
  Timestamp                = {2007.03.23},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1495460}
}

@Article{Regalia90adaptiveEigVals,
  Title                    = {An adaptive unit norm filter with applications to signal analysis and Karhunen-Loeve transformations},
  Author                   = {Regalia, P.A.},
  Journal                  = {Circuits and Systems, IEEE Transactions on},
  Year                     = {1990},
  Number                   = {5},
  Pages                    = {646-649},
  Volume                   = {37},

  File                     = {Regalia90adaptiveEigVals.pdf:Regalia90adaptiveEigVals.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Min or max eigenvecs of filter input correlation matrix yield coeffs for min or max filter output power. Adaptive algorithm.

 Expected squared value of filter convolution (power)
 -> Rayeigh Quotient 
 -> min this or max this will find min or max eigen vectors

* very simple recursion to find min or max eigenvectors
* also has a way to estimate all eigenvectors

* kinda cool, simple too},
  Timestamp                = {2007.08.02},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=55009&isnumber=1985&punumber=31&k2dockey=55009@ieeejrns&query=%28%28unit+norm+filter+with+applications%0D%0Ato+signal+analysis+and+karhunen-loeve+transformations%29%3Cin%3Emetadata%29&pos=0}
}

@Misc{reidXXfoveatedClustTrack,
  Title                    = {Active tracking of foveated feature clusters using affine structure},

  Author                   = {I. D. Reid and D. W. Murray},
  Year                     = {1996},

  Comment                  = {42.0: ReadNo},
  Review                   = {Relevant to speaker location feature tracking in reverb?}
}

@InProceedings{fayyad98clustinit,
  Title                    = {Initialization of iterative refinement clustering algorithms},
  Author                   = {P. S. Bradley U. M. FayyadC. A. Reina},
  Booktitle                = {Knowledge Discovery and Data Mining (KDD)},
  Year                     = {1998},
  Pages                    = {194-198},

  Comment                  = {27.0: ReadNo}
}

@InProceedings{renals03mtngSpkrTurn,
  Title                    = {{AUDIO} {INFORMATION} {ACCESS} {FROM} {MEETING} {ROOMS}},
  Author                   = {Steve Renals and Dan Ellis},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2003},

  Comment                  = {431: ReadNo},
  File                     = {renals03mtngSpkrTurn.pdf:renals03mtngSpkrTurn.pdf:PDF},
  Review                   = {Segment meeting topics based on talker turn patterns: doesn't work
* talker turn modelling and talkativity modelling
* used 32 ICSI meeting transcriptions
* says that Thilo's close talking mic VAD was poor
- 10% WER added over hand corrected segments

Talker Turn v.s. Topic
* chopped meeting into 1min chunks
* collected talker turns for each chunk
* agglom BIC clustering based on talker turn matrix
* poor relation to hand segmented topics

Talkativity
* model of speaker talkativity seemed to work
* not tested against topic segments},
  Url                      = {http://www.ee.columbia.edu/~dpwe/pubs/icassp03-mtg.pdf}
}

@InProceedings{reyes-gomez03facHMM,
  Title                    = {MULTI-CHANNEL SOURCE SEPARATION BY FACTORIAL {HMMs}},
  Author                   = {Manuel J. Reyes-Gomez and Bhiksha Raj and Daniel P. W. Ellis},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2003},
  Pages                    = {665-667},
  Volume                   = {1},

  Comment                  = {430: ReadYes},
  File                     = {reyes-gomez03facHMM.pdf:reyes-gomez03facHMM.pdf:PDF},
  Review                   = {Conv. multi-mic sep, uses MFCC's, factHMM's, & trans. Reverb too short
* test data 
- WSJ0 mixed
- synthesized room, 8 mics
- 200ms rever (too short!)
* features: 40D MFCC vectors
* Separation done by FIR's for each mic
FIR optimization:
1.) most likely state seq: filter -> MFCC -> optimal state sequence
-- really are doing alignment: state order known from transcriptions
-- HMM's are single Gaussian (signle MFCC centers allow determ target)
-- use Factorial HMM's instead of single HMM's
-- uses 
2.) generate target sequence to be used to optimize FIR's
-- conjugate gradient optimization:
-- FIR -> MFCC's -> target_error -> new FIR -> ...
3.) go to 1.) until converged

* Good equations for HMM model covariances, etc. maybe useful elsewhere
* Has EM (and variational??) equations
* Composed covariance method converges fastest, has same perf as global

Results
* 20dB interferer rejection w/ equal talkers
* lots better than best obtainable w/ simple delay and sum (no surprise)
* 38dB rejection when one talker is weak
Manuel Reyes has been working on separating voices from tabletop
mics in meeting environments. In particular, he has looked at
beamforming gradient-descent optimization to targets defined in
terms of speech recognizer features, rather than signal directly,
and where the state paths are inferred from a factorial HMM.},
  Url                      = {http://www.ee.columbia.edu/~dpwe/pubs/icassp03-fhmm.pdf}
}

@Article{reynolds94experimental,
  Title                    = {Experimental evaluation of features for robust speaker identification},
  Author                   = {D. Reynolds},
  Journal                  = {IEEE Trans., Speech and Audio Proc.},
  Year                     = {1994},
  Number                   = {4},
  Pages                    = {639--643},
  Volume                   = {2},

  Comment                  = {194: ReadYes},
  Review                   = {Spectral spkrID features & channel correction over phone lines
* cepstral mean subtraction is best chann correction
* but RASTA and quadric trend removal adapt quickly to chan changes
* MFCC's should have same # of ceps coeffs as filter banks (24)
* PLPC not as goot as MFCC or LPCC (which are about the same)
* did not use velocity or accel (mean sub would remove anyway)}
}

@Article{reynolds95gmmSpkrID,
  Title                    = {Automatics speaker recognition using {Gaussian} mixture speaker models},
  Author                   = {D. A. Reynolds},
  Journal                  = {The {Lincoln} laboratory journal},
  Year                     = {1995},
  Number                   = {2},
  Volume                   = {8},

  Comment                  = {99: ReadYes},
  Review                   = {Why GMM's work for speaker ID
* ID (only knowns) v.s. verification (1 known, infinite unknowns)

* based on formants clusters, not pitch 
* text indep => GMM model instead of HMM 
* silence (VAD), noise, channel variance removal is important 
* long speeech chunks, > 30s 
* imposter population choice is important 
* up to 830 speakers and feature space not crowded 
* multi-talker screws up recognition 
* handset variability, cross-channel echo, noise screws up results

* > 99 % accuracy is possible! 
* alg here is too slow for speaker reverb removal }
}

@Article{reynolds94spkrIDfeats,
  Title                    = {Experimental evaluation of features for robust speaker identification},
  Author                   = {Douglas A. Reynolds},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {1994},
  Number                   = {4},
  Pages                    = {639-643},
  Volume                   = {2},

  Comment                  = {ReadNo},
  Review                   = {What to use for spkr ID: PLP, MFCC, LPCC, etc. Careful analysis on telephone speech.
- only scanned MFCC stuff in this paper
- recommends ceps mean rem.
- want model order (# filterbanks, I think) >= # ceps coeffs, esp in noise
- likes 24 dim MFCC feats (his 2000 UBM references this paper & uses them)
- no deltas, although 2000UBM paper does use them...
- but abstract gives the nod to high-order LPC...
- says speaker ID benefits from using more detailed spectra than normally used in speech recog. eg. 24-MFCC for spkrID
- likes 400-3200 bandpass preproc (telephone speech, though)},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/searchresult.jsp?queryText=experimental+evaluation+of+features+for+robust+speaker+identification%2C&coll1=ieeejrns&coll2=ieejrns&coll3=ieeecnfs&coll4=ieecnfs&coll5=ieeestds&coll6=preprint&py1=1950&py2=2004&SortField=Score&SortOrder=desc&ResultCount=15}
}

@Article{reynolds00spkrNIST,
  Title                    = {The Lincoln Speaker Recognition System: {NIST} 2000},
  Author                   = {Douglas A. Reynolds and R. B. Dunn and J. J. McLaughlin},
  Journal                  = {Proc. ICSLP},
  Year                     = {2000},

  Comment                  = {417: ReadNo},
  File                     = {reynolds00spkrNIST.pdf:reynolds00spkrNIST.pdf:PDF},
  Review                   = {

Mari recommends reading.
The authors present an overview of the Lincoln Laboratory systems for the 2000 NIST speaker recognition evaluation. Among the several systems presented in the paper, they describe a speaker segmentation system that clusters the segments between the boundary candidates and models the speakers using the data from the clustering to detect where each speaker is speaking in a conversation. The boundary candidates are the regions in the conversation that have no speech, which are more likely to have a speaker change. },
  Url                      = {http://ssli.ee.washington.edu/proceedings/icslp00/pdf/00451.pdf}
}

@Article{reynolds00speaker,
  Title                    = {Speaker Verification Using Adapted {Gaussian} Mixture Models},
  Author                   = {D. Reynolds and T. Quatieri},
  Journal                  = {Digital Signal Processing: A Review Journal},
  Year                     = {2000},
  Number                   = {1-3},
  Pages                    = {19-41},
  Volume                   = {10},

  Comment                  = {164: ReadYes},
  Review                   = {Universal Background Model with HNORM (handset normalization)
UBM: build single model of many speakers instead of many single models
- adapt UBM to known spkrs;
- ID as known if one of the adapted is more likely than UBM
- UBM from collecting mix comps of individ GMM's, not concating data
- adaptation of UBM more robust than building individ models
- 1024 mix GMM, knee of perf curve @ 512 (their telephone data)
- 1 hr speech training over ? number of users
- be sure to normalize by duration
- features: mfcc's+delts (order in [22]?), 
- RASTA filter & ceps mean sub to remove linear convolution chan dist.
EM-like UBM adapatation, 
- mean only
- adapt only mix comps for which there are sufficient sufficient stats
- adapts sufficient stats, not params (unlike MLLR)
HNORM handset normalizatoin
- use big GMM to recog handset type
- bias and scale likelihood score based on hanset type
- helps but does not solve train/test condition mismatch

* specualation: adding suprasegmental features (e.g. style) will help
* HMM's shows no advantage in sprkID when text-independent
* diag cov GMM can do as well as full cov (doesn't say how, though)}
}

@Article{reynolds95robust,
  Title                    = {Robust text-independent speaker identification using gaussian mixture speaker models},
  Author                   = {D. Reynolds and R. Rose},
  Journal                  = {IEEE Trans., Speech and Audio Proc.},
  Year                     = {1995},
  Number                   = {1},
  Pages                    = {72--83},
  Volume                   = {3},

  Comment                  = {199: ReadYes},
  Review                   = {GMM spkrID better than VQ,RBF,HMM. Channel subtract. GMM training hints
* HMM phone recog phone segmenting front end doesn't help
* GMM is an 'implicit' segmenter via mixtures
* GMM EM training random init works as well as kmeans and fancy HMM init
* assign pts randomly and then use one kmeans iter to init GMM params
* robustness improved w/ min sigma limit
* 16 mixture comps good for 25D MFCC's, no accel, 5-10s test utterances
* 32 mixture comps for same w/ 1 s test utterances
* #mixtures v.s. train time: 32 mixtures is worse 16 w/ 30s train speech
* diag cov GMM best w/ nodal covariances
* GMM is better than RBF, slightly better than VQ (5s test)
Channel compensation
* frequency warping handles mismatched channel bandwidths
* cepstral mean sub fixes both channel and intra spkr variability
* RASTA works for time-varying channels
* delta cepstral features:
-- are channel invariant
-- uncorrelated w/ static coeffs
-- but don't help when use cepstral norm
* cepstral mean subtraction alone is best alg (not compareed w/ RASTA)}
}

@InProceedings{rickard01rtBSS,
  Title                    = {Real-Time Time-Frequency Based Blind Source Separation},
  Author                   = {S. Rickard and R. Balan and J. Rosca},
  Booktitle                = {Independent Components Analysis, Intl. Conf. on},
  Year                     = {2001},

  Comment                  = {ReadNo},
  File                     = {rickard01rtBSS.pdf:rickard01rtBSS.pdf:PDF},
  Review                   = {has several other good papers at:
http://www.princeton.edu/~srickard/bss.html},
  Url                      = {http://www.math.princeton.edu/~srickard/bss/RickardICA01.pdf}
}

@InProceedings{rickard02wDisjoint,
  Title                    = {On the W-Disjoint Orthogonality of Speech},
  Author                   = {S. Rickard and O. Yilmaz},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},

  Comment                  = {365: ReadYes},
  File                     = {rickard02wDisjoint.pdf:rickard02wDisjoint.pdf:PDF},
  Review                   = {Gain/delay histogram across two mics yields separating coeffs
Idea: can see when have 1 talker in 2 talker speech using histo peaks
* an improvement on abrard01bssUnderCanc 
- adds delay (phase angle, within +-pi: not much at high freqs!)
- seems to have separate histo for each time/freq
* histogram seems to be built for each time/freq
- is this a rolling histo or what? Not clear at all!
* so unique separation coeffs for each time/freq (kind of hard to read)?
- good for reverb zeros causing 2nd bounce delays to be stronger?
- not mentioned, though
- not tested in reverb
* lots of graphs showing histo peak spreading and some derivations.},
  Url                      = {http://www.math.princeton.edu/~srickard/bss/RickardICASSP02.pdf}
}

@Article{ringelstein00doa,
  Title                    = {Direction finding in random inhomogeneous media in the presenc eof multiplicative noise},
  Author                   = {J. Ringelstein and Al B. Gerhman and J. F. Bohme},
  Journal                  = {{IEEE} Signal Processing Letters},
  Year                     = {2000},
  Number                   = {10},
  Pages                    = {269-272},
  Volume                   = {7},

  Comment                  = {241: ReadNo},
  Review                   = {DOA (localization) for multiple sources}
}

@Article{Rissanen78minDescLen,
  Title                    = {Modeling by shortest data description},
  Author                   = {Rissanen, J.},
  Journal                  = {Automatica},
  Year                     = {1978},
  Pages                    = {465-471},
  Volume                   = {14},

  Owner                    = {scotto},
  Review                   = {First ref for minimum description length (MDL), for determing the # of params. I believe this is equivalent to BIC.},
  Timestamp                = {2008.01.28}
}

@InProceedings{roberts01icaMixtures,
  Title                    = {Mixtures of independent component analysers},
  Author                   = {S. J. Roberts and W. D. Penny},
  Booktitle                = {ICANN},
  Year                     = {2001},

  Comment                  = {ReadNo},
  File                     = {roberts01icaMixtures.ps:roberts01icaMixtures.ps:PDF},
  Review                   = {use for clustering?},
  Url                      = {http://www.fil.ion.ucl.ac.uk/~wpenny/publications/mix_icann01.ps}
}

@InProceedings{rodman00glotPulse,
  Title                    = {A High-Resolution Glottal Pulse Tracker},
  Author                   = {Rodman, R. and McAllister, D. and Bitzer, D. and Chappell, D.},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2000},

  Comment                  = {320: ReadYes},
  Review                   = {Gets glottal period: sum(3rd order harmonics) == 0 when DFT len == 2*pulsePeriod.
* More accurate than autocorr pulse period deteect
* many DFT's => computationally expensive
* Could use for voiced/non-voiced decision: no nice minimum curve for noise
* Use for speaker separation (pulse de-interleaving)?
* Use for localization (pick out pulse times accurately)?},
  Url                      = {http://www.csc.ncsu.edu/faculty/rodman/A%20High-Resolution%20Glottal%20Pulse%20Tracker.pdf}
}

@InProceedings{roman01spchLocSeg,
  Title                    = {Speech segregation based on sound localization},
  Author                   = {Nicoleta Roman and DeLiang Wang and Guy J. Brown},
  Booktitle                = {International Joint Conference on Neural Networks (IJCNN)},
  Year                     = {2001},

  Comment                  = {428: ReadNo},
  File                     = {roman01spchLocSeg.pdf:roman01spchLocSeg.pdf:PDF},
  Url                      = {http://www.dcs.shef.ac.uk/~guy/pdf/niki-ijcnn2001.pdf}
}

@InProceedings{wang02locseg,
  Title                    = {Location-based sound segregation},
  Author                   = {N. Roman and D. L. Wang and G. J. Brown},
  Booktitle                = {International Joint Conference on International Joint Conference on Neural Networks (IJCNN)},
  Year                     = {2002},

  Comment                  = {ReadNo}
}

@InProceedings{rosenberg02spkrSeg,
  Title                    = {Unsupervised Speaker Segmentation of Telephone Conversations},
  Author                   = {Aaron E. Rosenberg and Allen Gorin and Zhu Liu and S. Parthasarathy},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {565-568},

  Comment                  = {ReadNo},
  Url                      = {/g/ssli/html/proceedings/icslp02/ICSLP/PDF/INDEXSCR.PDF}
}

@Misc{ross99dynamical,
  Title                    = {A dynamical system model for generating fundamental frequency for speech synthesis},

  Author                   = {K. Ross and M. Ostendorf},
  Year                     = {1999},

  Comment                  = {231: ReadYes},
  Review                   = {For =generating= F0, requires knowledge of what the speech is 
* probably not relevant to speaker segmentation},
  Text                     = {Ross, K. and Ostendorf, M. 1999. A dynamical system model for generating fundamental frequency for speech synthesis. IEEE Transactions on Speech and Audio Processing. In press.}
}

@InProceedings{roth04featSelClust,
  Title                    = { Feature Selection in Clustering Problems},
  Author                   = { Volker Roth and Tilman Lange},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2004},

  Address                  = {Cambridge, MA},
  Editor                   = {Sebastian Thrun and Lawrence Saul and Bernhard {Sch\"{o}lkopf}},
  Publisher                = {MIT Press},
  Volume                   = {16},

  File                     = {:roth04featSelClust.pdf:PDF},
  Keywords                 = {feature selection, unsupervised learning, clustering, Bayesian inference, Gaussian mixtures},
  Owner                    = {scotto},
  Timestamp                = {2008.01.21},
  Url                      = {http://books.nips.cc/nips16.html}
}

@Article{rouat97pitch,
  Title                    = {A pitch determination and voiced/unvoiced decision algorithm for noisy speech},
  Author                   = {Jean Rouat and Chun Liu Yong and Daniel Morissette},
  Journal                  = {Speech Communication},
  Year                     = {1997},
  Number                   = {3},
  Pages                    = {191-207},
  Volume                   = {21},

  Comment                  = {327: ReadYes},
  File                     = {rouat97pitch.pdf:rouat97pitch.pdf:PDF},
  Review                   = {Auditory pitch w/ filter bank and heuristics
* Lots of good detail on how this algorithm works
* one of 1st high/low freq processor w/ peak sel. before summarization
* (maybe AMPEX was first (referenced))
Correlation 
* low freqs: 
- BPF
- Rxx
* high freqs: (detect beats of multiple harmonics in bank output)
- envelope det w/ Teager energy operator (AM demod)
- BPF
- Rxx
Peak Selection
* low freq peaks always selected
* high freq peaks 
- longer corr peak matches shorter corr peak
- some memory say you can compute a new estimate
-- (prev frame voiced OR energy exceeds prev frame)
Peak Summarization (channels Rxx's summed)
- a bunch of heuristics for voiced/non-voiced and removing high/low harmonic peaks.

* lots of tests, seems to work
* referenced in wu&wang 02 pitch.

* long tech report at: http://www.gel.usherb.ca/rouat/publications/SpeechComm1997V21N3.pdf},
  Url                      = {http://www.gel.usherb.ca/rouat/publications/SpeechComm1997V21N3.pdf}
}

@Article{roweis98spca,
  Title                    = {{EM} Algorithms for {PCA} and {SPCA}},
  Author                   = {Sam Roweis},
  Year                     = {1998},
  Volume                   = {10},

  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Comment                  = {639:ReadYes},
  Editor                   = {Michael I. Jordan and Michael J. Kearns and Sara A. Solla},
  File                     = {roweis98spca.pdf:roweis98spca.pdf:PDF},
  Owner                    = {scotto},
  Publisher                = {The {MIT} Press},
  Review                   = {Probabilistic PCA ("sensible PCA"), seems very close if not identical to Tipping99ProbPrincComp, has matlab
* examples with npts ~ 10*nDims.
* scales linearly with #pts, #dims, #eigenvecs
* handles missing data
* pretty fast if noise is Gaussian, very slow if not ==> better Gaussianize
* Matlab at: http://lear.inrialpes.fr/~verbeek/code/ppca_mv.m
* # free params is 1+p*k-k*(k-1)/2: can use for BIC calc
 1.) lag PCA: use to figure out best PCA dimension
 2.) max power beamformer PCA: one or two speakers (1 or 2 eigenvectors)},
  Timestamp                = {2007.05.31},
  Url                      = {citeseer.ist.psu.edu/roweis98em.html}
}

@TechReport{roweis99gaussIdentities,
  Title                    = {Gaussian Identities },
  Author                   = {Sam Roweis},
  Institution              = {University of Toronto},
  Year                     = {1999 },

  Comment                  = {397: ReadYes},
  File                     = {roweis99gaussIdentities.pdf:roweis99gaussIdentities.pdf:PDF},
  Review                   = {Cheat sheet w/ many useful matrix Gaussian distribution tricks

NOTE: pdf and any comments were moved to energytop.bib},
  Url                      = {http://www.cs.toronto.edu/~roweis/notes/gaussid.pdf}
}

@TechReport{roweis99matrixIdentities,
  Title                    = {Matrix Identities },
  Author                   = {Sam Roweis},
  Institution              = {University of Toronto},
  Year                     = {1999 },

  Comment                  = {396: ReadYes},
  File                     = {roweis99matrixIdentities.pdf:roweis99matrixIdentities.pdf:PDF},
  Review                   = {Cheat sheet w/ many useful matrix algebra and calculus tricks

NOTE: PDF and any comments moved to energy.bib},
  Url                      = {http://www.cs.toronto.edu/~roweis/notes/matrixid.pdf}
}

@InProceedings{roweis00oneMicSep,
  Title                    = {One Microphone Source Separation},
  Author                   = {Sam Roweis},
  Booktitle                = {Neural Information Processing Systems},
  Year                     = {2000},
  Pages                    = {793-799},

  Comment                  = {360: ReadYes},
  File                     = {roweis00oneMicSep.pdf:roweis00oneMicSep.pdf:PDF},
  Review                   = {Factorials trained on known speakers. Separation by binary spectral mask
* features are 2 time-adjacent columns of 513 FFT bins (pos half)
* frequency tile mask: alloted one or the other speaker 
* GMM's in factorial HMM observations have 8192 mixtures!
* and those GMM's are trained on =known= speakers. No test on unknowns
* seems to work
* says that underdetermined ICA doesn't work on mono},
  Url                      = {http://www.cs.toronto.edu/~roweis/papers/onemic.pdf}
}

@InProceedings{roweis03facModFiltSpchSep,
  Title                    = {Factorial Models and Refiltering for Speech Separation and Denoising},
  Author                   = {Sam T. Roweis},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {1009-1012},

  Comment                  = {570: ReadNo},
  Review                   = {another trick for spectral masking monaural speaker sep (enhances earlier paper)}
}

@Article{roy95speaker,
  Title                    = {Speaker Indexing Using Neural Network Clustering of Vowel Spectra},
  Author                   = {D. Roy},
  Journal                  = {Intl. Journal of Speech Technology},
  Year                     = {1995},

  Comment                  = {168: ReadYes},
  Review                   = {Broadcast news style speaker indexer (using BBC data). Pre-trained NN's
* speech/nonspeech: energy thresh @ lower 20% of histo
* MFCC-trained NN's (pre training) ID's each frame.
* NN majority vote is final ID for sentence
* Breaks a pauses > 0.2s
* Classifies vowels only}
}

@InProceedings{rutkowski00enhanceICA,
  Title                    = {Speech Enhancement Using Adaptive Filters and Independent Component Analysis Approach},
  Author                   = {T. Rutkowski and A. Cichocki and A. K. Barros},
  Booktitle                = {Intl. Conf. on Artificial Intelligence in Science and Technology},
  Year                     = {2000},
  Pages                    = {191-196},

  Comment                  = {205: ReadYes},
  Review                   = {Binarual speech enhance: perceptual pitch screen, ICA for focus
* not a very good paper
* separates out one talker from room noise or other spkrs
* pitch est -> harmonic screen at kF0 (perceptual motivation: not all k)
* ICA from binarual mic xcorr does delay calc somehom
* ICA equations given but not explained
* somehow, ICA'ed sieve outputs are segregated into spkr and noise
* some perceptual junk before reconstruction},
  Url                      = {citeseer.nj.nec.com/401843.html}
}

@Article{kemal99:_multip_speak_track_detec,
  Title                    = {Multiple Speaker Tracking and Detection: Handset Normalization and Duration Scoring},
  Author                   = {K. S?nmez and L. Heck and M. Weintraub},
  Journal                  = {Digital Signal Processing: A Review Journal},
  Year                     = {1999},
  Number                   = {1/2/3},
  Pages                    = {133-142},
  Volume                   = {10},

  Comment                  = {47.0: ReadYes},
  Review                   = {Parallel HMM's, one track for each speaker, one for noise
* min duration = 0.3s
* impossible to understand what they did from their paper 
* some attempt @ duration modelling but it's ad hoc}
}

@InProceedings{sabac02spkrIDdiscrim,
  Title                    = {Speaker Recognition Using Discriminative Features Selection},
  Author                   = {Bogdan Sabac},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {2321-2324},

  Comment                  = {ReadNo},
  Url                      = {/g/ssli/html/proceedings/icslp02/ICSLP/PDF/INDEXSCR.PDF}
}

@Article{sahr96closureCal,
  Title                    = {Application of closure phase and self-calibration to radar interferometric imaging of atmospheric and ionospheric irregularities},
  Author                   = {John D. Sahr},
  Journal                  = {Journal of Atmospheric and Terrestrial Physics},
  Year                     = {1996},
  Number                   = {8/9},
  Pages                    = {959-963},
  Volume                   = {58},

  Comment                  = {598:ReadNo},
  Review                   = {John Sahr's closure phase paper}
}

@Article{kayhan00evospect,
  Title                    = {Spatial evolutionary spectrum for {DOA} estimation and blind signal separation},
  Author                   = {A. Salim and M. G. Amin},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {2000},
  Number                   = {3},
  Volume                   = {48},

  Comment                  = {244: ReadNo},
  Review                   = {Subspace multi-source DOA }
}

@Article{Sanguinetti05nppca,
  Title                    = {Accounting for probe-level noise in principal component analysis of microarray data},
  Author                   = {Guido Sanguinetti and Marta Milo and Magnus Rattray and Neil D. Lawrence},
  Journal                  = {Bioinformatics},
  Year                     = {2005},
  Number                   = {19},
  Pages                    = {3748--3754},
  Volume                   = {21},

  Comment                  = {637:ReadYes},
  File                     = {Sanguinetti05nppca.pdf:Sanguinetti05nppca.pdf:PDF},
  ISSN                     = {1367-4803},
  Publisher                = {Oxford University Press},
  Review                   = {Probabilistic PCA which handles measurement uncertainty and picks dimension, has matlab
* "uncertainty" is a variance attached to each point
* matlab is at URL in this entry
* should not center before using because data mean is estimated, not the empirical mean from the full-d data
* auto dimension picking is based on variance measured in raw data and the user-supplied measuremeant uncertainty},
  Url                      = {http://www.dcs.shef.ac.uk/~neil/projects/pipeline/#Sanguinetti:accounting05}
}

@InProceedings{sankar00sriBN98,
  Title                    = {{SRI's} 1998 Broadcast News System -- Toward Faster, Better, Smaller Speech Recognition},
  Author                   = {A. Sankar and R. Gadde and F. Weng},
  Booktitle                = {Proc., Eighth Text Retrieval Conf..},
  Year                     = {2000},

  Comment                  = {144: ReadYes},
  Review                   = {Broadcast news seg/clust: faster than 97 but seg/clust seems same as 97
* recog model had factor of 5 fewer Gaussians than 97 version
-- fewer state clusters, more mixture comps in them
* tested on 96 and 98 H4}
}

@InProceedings{sankar96adaptPhLp,
  Title                    = {An Experimental Study of Acoustic Adaptation Algorithms},
  Author                   = {A. Sankar and L. Neumeyer and M. Weintraub},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1996},
  Pages                    = {713-716},
  Volume                   = {5},

  Comment                  = {ReadNo},
  File                     = {sankar96adaptPhLp.pdf:sankar96adaptPhLp.pdf:PDF},
  Review                   = {SRI's phone loop adaptation algorithm },
  Url                      = {http://www.speech.sri.com/people/leo/papers/icassp96.pdf}
}

@InProceedings{sankar98srtBN97,
  Title                    = {142. Development of {SRI's} 1997 Broadcast News Transcription System},
  Author                   = {A. Sankar and F. Weng and Z. Rivlin and A. Stolcke and R. R. Gadde},
  Booktitle                = {DARPA Broadcast News Transcription and Understanding Workshop},
  Year                     = {1998},
  Pages                    = {91-96},

  Comment                  = {Print, ReadNo},
  Review                   = {Broadcast News seg/clust, M/F/sil segmenter, global GMMmix, agglom clust
* gender recognizer: bkpts @ silence and m/f boundaries
* chop it into (at max?) 10s segment lengths
* agglomerative cluster:
* train one GMM for all segments: calc mixture weights only for each seg
* global GMM -> mixtures => fewer params (good)
* 39 dim MFCC's 
* distance measure is symmetric relative entropy (KL?)
* tested on 96 Hub4
* speaker model is sort of like a UBM}
}

@InProceedings{Sargin06MultimodalCCAspkrID,
  Title                    = {Multimodal Speaker Identification Using Canonical Correlation Analysis},
  Author                   = {M.E. Sargin and E. Erzin and Y. Yemez and A.M. Tekalp},
  Booktitle                = {{}ICASSP},
  Year                     = {2006},
  Pages                    = {I-1},
  Volume                   = {1},

  File                     = {Sargin06MultimodalCCAspkrID.pdf:Sargin06MultimodalCCAspkrID.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {CCA's Video and MFCC features to perform speaker ID
CCA==Canonical Correlation Analysis},
  Timestamp                = {2007.05.18},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1660095}
}

@InProceedings{Sargin06MultimodalSpeakerIdentification,
  Title                    = {Multimodal Speaker Identification Using Canonical Correlation Analysis},
  Author                   = {M. E. Sargin and E. Erzin and Y. Yemez and A. M. Tekalp},
  Booktitle                = {ICASSP},
  Year                     = {2006},
  Pages                    = {613-616},
  Volume                   = {1},

  Comment                  = {624:ReadYes},
  File                     = {Sargin06MultimodalSpeakerIdentification.pdf:Sargin06MultimodalSpeakerIdentification.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Early feature fusion helps, even if fuse decisions on same features later. CCA is a good featire fuser
* speaker ID: MFCC's and lip movement coeffs, uses HMM's
* early feature fuse acoust/lips w/ concat OR
* Canonical Correlation Analysis (CCA) works a little better than concat for feature fusion (no comparison w/ indep HMM streams)
* results in two classifiers: acoustic and acoustic+lips
* fuse decisions w/ classifier reliability weights, which are variance and sigmoid normalized (see 2005 Erzin paper)
* speculates about finding uncorrelated features in some future paper, I suppose to use these in late fusion, which is supposed to be uncorrelated
* late fusion again helps because it picks up lip features that are not correlated w/ audio, and therefore are eliminated from CCA fused audio+lips. (maybe only this uncorrelated part should be extracted numerically?)
* uses a CCA component corr threshold to decide how many comps to keep

For me, this says "fuse ER/XC", maybe fuse ER/XC and audio, and still maintain separate streams and fuse decisions w/ stream weights.},
  Timestamp                = {2007.04.02},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/selected.jsp?qry=%28multimodal+speaker+identification+using+canonical%3Cin%3Emetadata%29&srch=1&resset=1532162&imageField.x=80&imageField.y=16&imageField=View+Selected+Items&chklist=1660095%40ieeecnfs}
}

@Misc{sarikaya98robust,
  Title                    = {Robust speech activity detection in the presence of noise},

  Author                   = {R. Sarikaya and J. Hansen},
  Year                     = {1998},

  Comment                  = {109: ReadYes},
  Review                   = {Broad class phone or sil VAD detector 
* tested on TIMIT 
* works better than energy or speech enhancement techniques
* 14 broad class phone models, plus nonspeech model
* if one matches better than nonspeech, then is speech
* noncausal (Viterbi deoode) + 11p.t median filter
* bogus "start silence" noise estimator, adapts static model params once
* speculative runtime noise adaptation not implemented here (later?))
* works well in car noise, etc.
* tested down to 5dB
* zhang02phoneVAD says that this may fail in nonstationary noise},
  Text                     = {R. Sarikaya and J.H.L. Hansen. Robust speech activity detection in the presence of noise. In Proc. ICSLP, Sydney, Australia, December 1998.}
}

@InProceedings{Saul00PeriodicComponentAnalysis:,
  Title                    = {Periodic Component Analysis:
An Eigenvalue Method for Representing
Periodic Structure in Speech},
  Author                   = {Lawrence K. Saul and Jont B. Allen},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2000},

  Comment                  = {636:ReadYes},
  File                     = {Saul00PeriodicComponentAnalysis\:.pdf:Saul00PeriodicComponentAnalysis\:.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Optimal weights for correlation filterbank sum w/ PCA, kind of
* looks like this needed work, at the time (2000), may want to see if they've improved it

Basic Eigenvalue
* sum filterbank outputs, weights determined to maximize periodicity (must sample many lags)
* eigenvector solution
* problem: can't handle phase shifts across freq bands

Hilbert Enhancement
* calc analytic filterbank outputs
* calc complex weights (weight phase handles phase shift)
* super-high computational cost

Pairwise modulation
* now, multiply FB envelopes that could be harmonics of each other (consider only 1st and 2nd harmonics, can extend)
* like modulation, filter out summed freq comp and get baseband difference, which is F0
* again, try many delays, find one that has min periodicity error (but now in phase instead of time, so lower sample rate)
* still a processing pig

Hierarchical analysis
* some kinda recursion I didn't try to figure out, as the discusssion says a lot of work is still needed.},
  Timestamp                = {2007.05.28}
}

@InProceedings{saul03statSigProcNonNega,
  Title                    = {Statistical Signal Processing with Nonnegativity Constraints},
  Author                   = {Lawrence K. Saul and Fei Sha and Daniel D. Lee},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {1001-1004},

  Comment                  = {569: ReadNo},
  Review                   = {iterative multiplicative update w/ non-neg constraint, uses F0 and SVM's for examples but use for product of GMM ICA speaker model (airey03prodGMMasr)?? Maybe for doing multiple ICA traits, like independence, non-gaussianinity, model match??}
}

@Article{scholkopf98kpca,
  Title                    = {Nonlinear component analysis as a kernel eigenvalue problem},
  Author                   = {Bernhard Sch\"{o}lkopf and Alexander Smola and Klaus-Robert M\"{u}ller},
  Journal                  = {Neural Computation},
  Year                     = {1998},
  Number                   = {5},
  Pages                    = {1299--1319},
  Volume                   = {10},

  Doi                      = {http://dx.doi.org/10.1162/089976698300017467},
  File                     = {scholkopf98kpca.pdf:scholkopf98kpca.pdf:PDF},
  ISSN                     = {0899-7667},
  Owner                    = {scotto},
  Publisher                = {MIT Press},
  Review                   = {Original KPCA paper. Good theory eg. why train vecs span feat eigenspace; preimage sol'n not yet developed

Main ideas of KPCA
* transform original space into high dimensional space, then do normal PCA
* by don't actually do the transform; can do PCA w/ only dot products, so can do it using only kernels
 (this makes it computationally feasible; other nonlinear techniques can't go to as high a dim)
* dimension-reduced features are then extracted w.r.t. all the training vectors, mapped to high dim space
* must center transformed vecs before doing eig decomp, can do this with dot products!, which is perhaps explained slightly better in Williams02kpcaAndMMDS
* must also normalize the eigenvecs. How to do that is not so clear. Kwok04kernPreImage has the equation 

Useful facts
* high dim covariance matrix eigenvecs are spanned by input points (proof)
* how to do PCA is really described in Appendix B
* KPCA allows you to dimension _expand_! Getting more dims than you had originally. Might be good for meetings w/ few microphone pairs?
* Polynomial, RBF and sigmoid kernels discussed
* equation for polynomial kernel dimensionality is given (~N^3), where N is the # of training pts, d is the polynomial order.
* Normal PCA props. still hold, namely (in high dim space):
(1) the first q PCA comps, carry more variance than any other q orthogonal directions
(2) minimal reconstruction error for q projections
(3) the principal components are uncorrelated,
(4) 1st q comps have maximal mutual info. w.r.t. inputs (under gaussian assumptions,
 and thus depends on the data and the chosen kernel).
* linear PCA recovered if use dot product kernel: k(x,y)=X.y

Preimage problem:
* no guarantee that dimension-reduced feature space point exists in input space ==> must do approximately
* how to do this is much covered, by eq 4.2 is an equation you could optimize w/ gradient descent

Other nonlinear PCA methods
* Hebbian Networks (advantage where have nonstationary data)
* autoassociatev MLP (local minima, overfitting, must recompute to change # comps)
* Principal Curves (well motivated theoretically, but is a nonlin opt. probl)
* Locally Linear PCA (seems to work, no comparison made, though)},
  Timestamp                = {2007.08.19},
  Url                      = {http://www.mitpressjournals.org/doi/abs/10.1162/089976698300017467}
}

@InProceedings{scheirer97spchMusic,
  Title                    = {Construction and Evaluation of a Robust Multifeature Speech/Music Discriminator},
  Author                   = {Eric Scheirer and Malcolm Slaney},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1997 },
  Pages                    = {1331-1334},
  Volume                   = {2 },

  Comment                  = {384: ReadYes},
  Review                   = {Heuristic features and classifiers for speech/music decision
* 8 features plus variances of five of them
* feature changing in speech, const in music: variance is good feature
* Best 8: 4Hz modulation, low-energy frame pct., pulse metric, plus:
-- plus variance of: rolloff, spec centroid, spec flux, zero cross,

-- cepstral resynth residual.
* Best 3: 4Hz energy, variance of spectral flux and pulse
* Fast 5 (low latency): 4Hz energy, pct. low E., rolloff, centroid,
-- zero cross (I think)
* features are log-transformed so are more Gaussian w/ better spread
Classifiers
* GMM (diag cov, 1-50 mixtures), KDD and KNN classifiers tried
* about the same performance bug KDD is tiny bit better
* music harder to detect correctly than speech
Tests
* best frame-by-frame is 5.3%, w/ Best8
* FM radio, same as used by Willians&Ellis
* if average out to 2.4s, get 1.4% error (same as Willians&Ellis)
Speech/Music/Speech+Music detector:
* 65% accuracy},
  Url                      = {http://ieeexplore.ieee.org/iel3/4635/13030/00596192.pdf?isNumber=13030&prod=CNF&arnumber=596192&arSt=1331&ared=1334+vol.2&arAuthor=Scheirer%2C+E.%3B+Slaney%2C+M.}
}

@InProceedings{scheirer99musicComodSeg,
  Title                    = {{TOWARDS} {MUSIC} {UNDERSTANDING} {WITHOUT} {SEPARATION}: {SEGMENTING} {MUSIC} {WITH} {CORRELOGRAM} {COMODULATION}},
  Author                   = {Eric D. Scheirer},
  Booktitle                = {{IEEE} Workshop on Applications of Signal Processing to Audio and Acoustics,},
  Year                     = {1999},

  Comment                  = {ReadYes},
  File                     = {scheirer99musicComodSeg.pdf:scheirer99musicComodSeg.pdf:PDF},
  Review                   = {filterbank music segregation by time/freq sep: uses pitch/energy trajectories
groups banks both by change in periods (in-band xcorr peak) and change in
amplitude (relative change in power at a filterbank output):
- I could calculate normalized energy deltas: 
5 frame diff FIR / (avg energy in 5 frames)},
  Url                      = {http://vismod.media.mit.edu/tech-reports/TR-492.pdf}
}

@Misc{schmidtXXsvsSpkrID,
  Title                    = {Identifying speakers with support vector networks},

  Author                   = {M. S. Schmidt},

  Comment                  = {11: ReadNo}
}

@InProceedings{schobben99bssEchoCanc,
  Title                    = {A new algorithm for joint blind signal separation and acoustic echo canceling},
  Author                   = {D. W. E. Schobben and P. C. W Sommen},
  Booktitle                = {Proc. ISSPA ( Intl. Symposium on Signal Processing and its Applications)},
  Year                     = {1999,},
  Pages                    = {889-892},

  Comment                  = {440: ReadYes},
  Review                   = {Convolutive, 2nd order BSS for case when some sources are known
* better than ususal known source echo cancel: handles speaker overlap
* cancel/separation is done jointly
-- convergence faster than sequential since done @ same time
-- computationally efficient
* test is done on 21ms FIR: way too short!
* but works better simple source separation algorithm, CoBliSS
* is based on CoBliss
* reference to PhD thesis showing cross-power, filter relationship

matlab at: http://www.esp.ele.tue.nl/onderzoek/daniels/ECoBliSS.zip},
  Url                      = {http://ieeexplore.ieee.org/iel5/6605/17633/00815814.pdf?isNumber=17633&prod=IEEE+CNF&arnumber=815814&arSt=889&ared=892+vol.2&arAuthor=Schobben%2C+D.W.E.%3B+Sommen%2C+P.C.W.%3B}
}

@InProceedings{schoentgen94,
  Title                    = {Closed-Phase Glottal Inverse Filtering by Means of a Compound Auto-Regressive Model},
  Author                   = {J. Schoentgen and Z. Azimi},
  Booktitle                = {Esca Workshop on Speaker Recognition, Identification, and Verification},
  Year                     = {1994},
  Pages                    = {209-212},

  Comment                  = {Print, ReadNo},
  Html                     = { Schoentgen-94 },
  Review                   = {But good for spkr ID?}
}

@Article{scholkopf99InVsFeatKern,
  Title                    = {Input space versus feature space in kernel-based methods},
  Author                   = {Scholkopf, B. and Mika, S. and Burges, C.J.C. and Knirsch, P. and Muller, K.-R. and Ratsch, G. and Smola, A.J.},
  Journal                  = {Neural Networks, IEEE Transactions on},
  Year                     = {1999},
  Number                   = {5},
  Pages                    = {1000-1017},
  Volume                   = {10},

  File                     = {scholkopf99InVsFeatKern.pdf:scholkopf99InVsFeatKern.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Kernel input/feature space review. Explains KPCA and prefeature problem, also reduced set methods

I didn't read the whole thing but probably should (or a textbook) but here are some points:

KPCA:
* any feature space point can be expressed as a weighted sum of training points
* the kth dimension wieght of the ith training point is the kth eigenvector of the feature covariance matrix, calculated over the training points

* Also, the kth dimension of the dimension-reduced output is with weighted sum of the kernel dot products of the training points. The weights are the eigenvectors, again (eq, 37)
* on these dimension-reduced points, a linear plane classifier works as well as a nonlinear SVM

The Preimage Problem (approximating full-dim points in input space using a kernel learned from some other training points)
* for invertible kernels, there's an analytical expression for the approximation (BakIr04LearnPreImage says this doesn't work in practice)
* But some kernels eg. Gaussian, aren't invertible 
 ---- invertible kernels: polyomial, sigmoid, RBF (but you have to see ref 24 for the details of how to use them)
 ---- I thought there was something else about no guarantees for points not in the training set?

Approximate preimage algorithm
* I'm STILL not clear on whether or not there's an analytical expression for an invertible kernel
* There's a recursive one for Gaussian kernelsk},
  Timestamp                = {2007.08.16},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=788641}
}

@InProceedings{Scholz07circPCA,
  Title                    = {Analysing periodic phenomena by circular {PCA}},
  Author                   = {Matthias Scholz},
  Booktitle                = {Proc. {BIRD} Conf.},
  Year                     = {2007},
  Editor                   = {M.~Hochreiter and R.~Wagner},
  Pages                    = {38--47},
  Publisher                = {Springer-Verlag Berlin Heidelberg},
  Series                   = {LNCS/LNBI 4414},

  File                     = {Scholz07circPCA.pdf:Scholz07circPCA.pdf:PDF},
  Review                   = {Circular, nonlinear periodic PCA, implements half the MLP
* basically, this is Scholz05nlpcaMissDat, but with a circularity enforcing node
* MLP based, only implments generating side of the net
* trying to track activity of 58K genes over a 48 hour malaria bug blood infection cycle
* good overview of other circular PCA techniques},
  Url                      = {http://www.matthias-scholz.de/matlab.html}
}

@Article{Scholz05nlpcaMissDat,
  Title                    = {Non-linear PCA: a missing data approach},
  Author                   = {M.~Scholz and F.~Kaplan and C.L.~Guy and J.~Kopka and J.~Selbig},
  Journal                  = {Bioinformatics},
  Year                     = {2005},
  Number                   = {20},
  Pages                    = {3887--3895},
  Volume                   = {21},

  File                     = {Scholz05nlpcaMissDat.pdf:Scholz05nlpcaMissDat.pdf:PDF},
  Review                   = {Nonlinear MLP PCA using only half the net. Missing feats, can extract a temporal pattern. Has Matlab.
* extedned to periodic components in Scholz07circPCA

Good overview of PCA, nonlinear PCA and missing value estimation algors.

* Two basic approachines: Bayesian and Max.
 -- this paper's technique minimizes MSE by zeroring error terms of missing values (like my idea)
 -- MSE minimization ~ MAP estimation, so this is a max likelhihood technique

* Many algorithms
 1.) Bayesian linear pca (BPCA)
 2.) probablistic pca (PPCA)
 3.) KNNimpute
 4.) nonlinear est. by SOM
 5.) nonlinear regression
 6.) dynamical system, taking time information into account (but is supervised, and vulternable to overfitting)

Inverse NLPCA model

* like autoassociative PCA MLP network, w/ info bottleneck, but only train right half (generative) side of net

* is a blind inverse prob: est. both inputs (in dim-reduced space) and net params, 
 given full-Dim "outputs," the things to be compressed.
* half-net scheme is more efficient, possibly better match to physical problem of this paper

* REGULARIZATION / stabilization: 
 - number of nonlinear nodes
 - weight decay term
 - Apparently, extracting higher dims also stabilizes lower dims Something like that said in
 Scholz02nlpcaHierarch, too)

* MISSING VALUES
 - can be individual elements of a feature vector
 - just don't include the error term for the missing part (like my idea)
 - they got it to work for very high-Dim, high compression data with 33-50% missing elements, and few training samples


Compared to other techniques (synthetic and 17K gene features)
* all tecnniques work better than subsituting the mean for missing data
* better than KNNimpute
* high dim input (17K genes -> 1K feature): BPCA is best at estimating missing values (averaged over all)
* looking only at 30 most important genes, iNLPCA is tied with SOM and PPCA
* BPCA advantage: no need to pick "k", the number of used componnets, as with PPCA

Results over a time series (metabolite cooling stress response over time)
* Interesting that it managed to sort out time dependence from the data, given no time marks. It's a sort of clustering. Could use as a way to determine HMM states in an unsupervised manner.
* only 52 samples of a 388 dim feature! Yet still apparently successful in compressing it to only 3 dims.
* logratio normalize inputs to tweeze out change. Gives decrease same mag. as increase, different sign
* wasn't compared to other methods, so can't tell how they would have done
* temporal metabolite acivity ranking: found that 1st extracted comp. was "time" so: 
 time -->1st component -->x (inverse pca) --> dx/t --> rank(t)
* could also use this to find response to other changing factors, liek temperature @ fixed time...},
  Url                      = {http://www.matthias-scholz.de/matlab.html}
}

@InProceedings{Scholz02nlpcaHierarch,
  Title                    = {Nonlinear {PCA}: a new hierarchical approach},
  Author                   = {M.~Scholz and R.~{Vig\'{a}rio}},
  Booktitle                = {Proc. ESANN},
  Year                     = {2002},
  Editor                   = {M.~Verleysen},
  Pages                    = {439--444},

  File                     = {Scholz02nlpcaHierarch.pdf:Scholz02nlpcaHierarch.pdf:PDF},
  Review                   = {Nonlinear, MLP PCA decorrelates by hierarchical training, better than kPCA in some ways, not others

h-NLPCA goals:
1.) scalability: max variance explanation for a given output dim
2.) stability: lower dims of an M dim pca are the same for an M+k dim pca, k>0
(KPCA satisfies as well?)

How:
* kind of like normal MLP PCA but w/ nonlinear middle layer
 - nonlinear Input "output" layers, same # of nodes as input dim
 - middle layer (the output you use for dim reduction) is nonlinear,

 and w/ fewer nodes -- where nonlinear dim reduction occurs 
 (information bottleneck)
* hierarchical training
 - train a series of MLP's w/ increasing output dimensionality
 - backprop gradient is shared across them, is sum of their reconstruction errors

Desirable properties of h-NLPCA
* Linearized I/O relationship:
 -- Ideal for my beamforming idea: maps nonlinear input to linear output so, can scan linearly in h-NLPCA output space to map to the nonlinear lag combinations
* pickiing dimensionality?
 output not linearized if all info already captured by lower dims
* nonlinear whitening yeilds near-spherically distributed outputs (lags would better match gasssian GMM assumptions)

* classification accuracy (synthetic data, I'm not sure how meaningful the results are)
 -- better than linear, standard nonlinear PCA
 -- better than kPCA too, for small # comps
 -- however kPCA is better for large # of comps.

Possible advantage over kPCA is that "kernel" is learned from the data, while in kPCA, it's pre-determined.

MATLAB
http://www.matthias-scholz.de/matlab.html},
  Url                      = {http://www.matthias-scholz.de/matlab.html}
}

@Article{schwarz78bic,
  Title                    = {Estimating the Dimension of a Model},
  Author                   = {Gideon Schwarz},
  Journal                  = {Annals of Statistics},
  Year                     = {1978},
  Number                   = {2},
  Pages                    = {461-464},
  Volume                   = {6},

  Comment                  = {ReadNo},
  Review                   = {Original BIC ref., according to Matt, compares it w/ AIC}
}

@Book{sears78univPhyisicsBk,
  Title                    = {University Physics },
  Author                   = {Francis W. Sears and Mark W. Zemansky and Hugh D. Young},
  Publisher                = {Addison-Wesley},
  Year                     = {1976},

  Comment                  = {ReadYes},
  Review                   = {My freshman physics book.}
}

@Misc{sebastianiXXbayesclust,
  Title                    = {Sequence Learning via {Bayesian} clustering by dynamics},

  Author                   = {P. Sebastiani and M. Ramoni and P. Cohen},

  Comment                  = {48: ReadNo},
  Review                   = {Referenced by ramoni00clustByDyn}
}

@Article{mouhamadou99:_irisa_elisa_speak_detec_track,
  Title                    = {The {IRISA}/{ELISA} Speaker Detection and Tracking Systems for the {NIST}'99 Evaluation Campaign },
  Author                   = {M. Seck and R. Blouet and F. Bimbot},
  Journal                  = {Digital Signal Processing: A Review Journal},
  Year                     = {1999},
  Number                   = {1/2/3},
  Pages                    = {154-171},
  Volume                   = {10},

  Comment                  = {124: ReadNo}
}

@InProceedings{seldin07infoBottleneckNonCoOccur,
  Title                    = { Information bottleneck for non co-occurrence data},
  Author                   = {Y. Seldin and N. Slonim and N. Tishby, },
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2007},
  Publisher                = {MIT Press},
  Volume                   = {19},

  File                     = {seldin07infoBottleneckNonCoOccur.pdf:seldin07infoBottleneckNonCoOccur.pdf:PDF},
  Url                      = {books.nips.cc/papers/files/nips19/NIPS2006_0520.pdf}
}

@InProceedings{shafran03asrVad,
  Title                    = {Robust speech detection and segmentation for real-time {ASR} applications},
  Author                   = {I. Shafran and R. Rose},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2003},

  Comment                  = {410: ReadYes},
  File                     = {shafran03asrVad.pdf:shafran03asrVad.pdf:PDF},
  Review                   = {Zak's adaptive FFT energy voice activity detector

* Tries 4 frame level MFCC-type VAD's, says they're hard to train
-- best is MLP with delta+delta^2, 4.2% frame error
-- truth hand corrected word alignments
-- 3 frame slop around boundaries excluded

* FFT-based, VAD: how much of FFT is above estimated noise level
-- noise level found for each FFT bin, comes from min power over 1.4s
-- min->noise estimate: several kinds of adaptive thresholds
-- speech when 1/5 of FFT bins is above weighed noise level estimate
-- state machine and boundary padding heuristics afterwards

* FFT testing
-- tests are done on SPINE and HMIHY
-- criteria is recognizer WER
-- in terms of WER, works almost as well as hand labelling
-- is 0.7% WER better than IBM's (?) current VAD
-- no test of frame-level accuracy
-- not compared to frame level VAD's in 1st section},
  Url                      = {http://ssli.ee.washington.edu/ssli/people/zak/xstatseg.pdf}
}

@InProceedings{shen98entropyEndPt,
  Title                    = {Robust Entropy-based Endpoint Detection for Speech Recognition in Noisy Environments},
  Author                   = {{Jia-lin} Shen and {Jeih-weih} Hung and {Lin-shan} Lee},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1998},

  Comment                  = {426: ReadYes},
  File                     = {shen98entropyEndPt.pdf:shen98entropyEndPt.pdf:PDF},
  Review                   = {Spectral Entropy VAD with simple threshold; perhaps the 1st entropy VAD?
* calc entropy form spectral estimate
* before entropy clac, zero out FFT bins w/ large or small values
* some kind of trained weight also applied to each bin but not explained
* entropy smoothed w/ 20pt median, short segs rejected
* how thresholds were derived from noise not described
* says perf significantly better than energy VAD a 5,10,15dB SNR
* test noise was white, pink, and car
* In Dan Ellis's class note references so must be good (http://www.ee.columbia.edu/~dpwe/e4810/projects.html)},
  Url                      = {http://www.ee.columbia.edu/~dpwe/papers/ShenHL98-endpoint.pdf}
}

@InProceedings{Shental03gmmEquivConstraints,
  author    = {Noam Shental and Aharon Bar-Hillel and Tomer Hertz and DaphnaWeinshall},
  title     = {Computing Gaussian Mixture Models with {EM} using Equivalence Constraints},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2003},
  file      = {Shental03gmmEquivConstraints.pdf:Shental03gmmEquivConstraints.pdf:PDF},
  groups    = {semisupWorkshop07},
  owner     = {scotto},
  review    = {How to compute "weak learner" GMM for semisupervised kernel learning as in [Hertz06LearningKernelFunction]},
  timestamp = {2007.06.20},
}

@Article{shi99kalmanjump,
  Title                    = {Kalman filtering for continuous-time uncertain systems with markovian jumping parameters},
  Author                   = {P. Shi and E. Boukas and R. K. Agarwal},
  Journal                  = {{IEEE} transactions on automatic control},
  Year                     = {1999},
  Number                   = {8},
  Pages                    = {1592-1597},
  Volume                   = {44},

  Comment                  = {36.0: ReadNo},
  Review                   = {Relevant to speaker motion tracking or reverb switching when head turns? pitch tracking w/ multi-speakers?}
}

@InProceedings{shiga03spchSpecEnvEst,
  Title                    = {Estimating the Spectral Envelope of Voiced Speech Using Multi-frame Analysis},
  Author                   = {Yoshinori Shiga and Simon King},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {1737-1740},

  Comment                  = {573: ReadNo},
  Review                   = {tricky spectral envelope estimator }
}

@InProceedings{shin00endpointMultiFeat,
  Title                    = {Speech/non-speech classification using multiple features for robust endpoint detection },
  Author                   = {{Won-Ho} Shin and {Byoung-Soo} Lee and {Yun-Keun} Lee and {Jong-Seok} Lee},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},
  Pages                    = {1399-1402},
  Volume                   = {3},

  Comment                  = {450: ReadYes},
  Review                   = {Six features combined by CART classifier to make VAD decision; works
* features are:
- total energy
- audible energy (300,3700Hz)
- high energy (2-4KHz)
- peakyness
- LPC residual energy
- noise-filtered energy
* features are OK by themselves (72 to 89% accurate individually)
* Zero crossing not included b/c it's too noise sensitive
* CART tree does classification
* works better if frame-by-frame decision includes 2 adjacent neighbors
* tests: 
- 5,0,-5dB
- car, subway station, train, street noise (no babble)
- CART result is 4-10% better (frame acc.) than result w/ any 1 feature},
  Url                      = {http://ieeexplore.ieee.org/iel5/6939/18687/00861845.pdf?isNumber=18687&prod=IEEE+CNF&arnumber=861845&arSt=1399&ared=1402+vol.3&arAuthor=Won-Ho+Shin%3B+Byoung-Soo+Lee%3B+Yun-Keun+Lee%3B+Jong-Seok+Lee%3B}
}

@InProceedings{shire00multiASR,
  Title                    = {Multi-stream {ASR} trained with heterogeneous reverberant environments},
  Author                   = {M. L. Shire},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {253-256},

  Comment                  = {13.5: ReadNo},
  Review                   = {But justifies mult-stream speakerID? Although this isn't multi-bad streams, like other spkrID},
  Volumen                  = {1}
}

@InProceedings{shire00rastaReverb,
  Title                    = {Data-driven {RASTA} filters in reverberaton},
  Author                   = {M. L. Shire and B. Y. Chen},
  Booktitle                = {{IEEE} ?},
  Year                     = {2000},

  Comment                  = {272: ReadNo}
}

@InProceedings{shriberg01spkrOverlap,
  Title                    = {Observations on Overlap: Findings and Implications for Automatic Processing of Multi-Party Conversation},
  Author                   = {E. Shriberg and A. Stolcke and D. Baron},
  Booktitle                = {Eurospeech},
  Year                     = {2001},

  Comment                  = {14.0: ReadYes},
  File                     = {shriberg01spkrOverlap.pdf:shriberg01spkrOverlap.pdf:PDF},
  Url                      = {http://citeseer.ist.psu.edu/448944.html}
}

@Misc{shribergXXprosodytopicseg,
  Title                    = {Prosody-based automatic segmentation of speech into sentences and topics},

  Author                   = {E. Shriberg and A. Stolcke and D. Hakkani-Tur and G. Tur},

  Comment                  = {30.0: ReadNo}
}

@InProceedings{siegler97automatic,
  Title                    = {Automatic Segmentation, Classification and Clustering of Broadcast News Audio},
  Author                   = {M. Siegler and U. Jain and B. Raj and R. Stern},
  Booktitle                = {DARPA Speech Recognition Workshop},
  Year                     = {1997},
  Pages                    = {97-99},

  Comment                  = {143: ReadYes},
  Review                   = {Broadcast News seg/clust, KL2 seg, KL2 agglom clust. By hand is better.
* KL2 dist instead of KL dist for segmentation and clustering
* KL2 dist much better than Mahanlonibus dist
* segmentation like Gish (GLR) but use Max KL2 dist as breakp instead
* simple agglomerative clustering
* 2s sliding window for boundary detection
Results
* tested on 96 Hub4
* detected 64% of hand-labelled boundaries
* clustering failed 0.1% of the time for segments > 33s
* WER not as good as hand clustering}
}

@Misc{simon98kalman,
  Title                    = {{Kalman} filtering},

  Author                   = {D. Simon},

  Comment                  = {64: ReadNo},
  Review                   = {Kalman filter intro web page. relevant to speaker motion tracking or pitch tracking?}
}

@InProceedings{Sindhwani06Largescalesemi-supervised,
  Title                    = {Large scale semi-supervised linear {SVM}s},
  Author                   = {Vikas Sindhwani and S. Sathiya Keerthi},
  Booktitle                = {Proc., 29th annual Intl. ACM SIGIR Conf. on Research and development in information retrieval ({SIGR})},
  Year                     = {2006},
  Pages                    = {477-484},

  Abstract                 = {Large scale learning is often realistic only in a semi-supervised setting where a small set of labeled examples is available together with a large collection of unlabeled data. In many information retrieval and data mining applications, linear classifiers are strongly preferred because of their ease of implementation, interpretability and empirical performance. In this work, we present a family of semi-supervised linear support vector classifiers that are designed to handle partially-labeled sparse datasets with possibly very large number of examples and features. At their core, our algorithms employ recently developed modified finite Newton techniques. Our contributions in this paper are as follows: (a) We provide an implementation of Transductive SVM (TSVM) that is significantly more efficient and scalable than currently used dual techniques, for linear classification problems involving large, sparse datasets. (b) We propose a variant of TSVM that involves multiple switching of labels. Experimental results show that this variant provides an order of magnitude further improvement in training efficiency. (c) We present a new algorithm for semi-supervised learning based on a Deterministic Annealing (DA) approach. This algorithm alleviates the problem of local minimum in the TSVM optimization procedure while also being computationally attractive. We conduct an empirical study on several document classification tasks which confirms the value of our methods in large scale semi-supervised settings.},
  File                     = {Downloading...:Downloading...:PDF},
  Owner                    = {scotto},
  Timestamp                = {2006.08.18},
  Url                      = {http://portal.acm.org/citation.cfm?id=1148170.1148253&coll=&dl=ACM&type=series&idx=1148170&part=series&WantType=series&title=Annual%20ACM%20Conference%20on%20Research%20and%20Development%20in%20Information%20Retrieval&CFID=15151515&CFTOKEN=6184618}
}

@InProceedings{singh01spineASRseg,
  Title                    = {Speech in Noisy Environments: Robust Automatic Segmentation, Feature Extraction, and Hypothesis Combination},
  Author                   = {Rita Singh and Michael L. Seltzer and Bhiksha Raj and Richard M. Stern},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},
  Pages                    = {273-276},
  Volume                   = {1},

  Comment                  = {437: ReadYes},
  File                     = {singh01spineASRseg.pdf:singh01spineASRseg.pdf:PDF},
  Review                   = {CMU's SPINE ASR, and speech/nonspeech bimodal assumption VAD
* GMM's for speech/noise (I think, it doesn't say)
* not clear what the features are
* Calc log likelihod ratio between them
* Assume LLR will be bimodal (speech/noise)
* Put thresh at histo inflection of LLR
-- histogram calculated over 0.5s window
-- threshold then applied over that window
-- threshold offset slightly to bias towards accepting nonspeech
-- did this b/c cost of including noise worse (WER) than rejecting spch
* Spine1: lowest false alarm => lowest hallucinated words in nonspeech

* say want to focus on speech instead of learning about noise
* raj02projVAD has the algorithm details },
  Url                      = {http://www-2.cs.cmu.edu/afs/cs/user/robust/www/Papers/spineicassp.pdf}
}

@InProceedings{sivak02spkrChng,
  Title                    = {Unsupervised Speaker Segmentation of Telephone Conversations},
  Author                   = {P. Sivakumaran and A.M. Ariyaeeinia and J. Fortuna},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {569-572},

  Comment                  = {ReadNo},
  Url                      = {/g/ssli/html/proceedings/icslp02/ICSLP/PDF/INDEXSCR.PDF}
}

@InProceedings{slonim99agglomInfoBottleneck,
  Title                    = {Agglomerative Information Bottleneck},
  Author                   = {N. Slonim and N. Tishby},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {1999},
  Pages                    = {617-623},
  Volume                   = {12},

  File                     = {slonim99agglomInfoBottleneck.pdf:slonim99agglomInfoBottleneck.pdf:PDF},
  Url                      = {http://citeseer.ist.psu.edu/200942.html}
}

@Article{slyh93arrayEnhance,
  Title                    = {Microphone array speech enhancement in overdetermined signal scenarios},
  Author                   = {R. E. Slyh and R. L. Moses},
  Journal                  = {{IEEE} ?},
  Year                     = {1993},

  Comment                  = {258: ReadYes},
  Review                   = {PFSDM is better speech qual. meas. than SNR 
* frost array: uts in nulls to max SNR but doesn't change freq resp. maximizes SNR 
* GEQ: correlation determined weights determine nulls and freq resp (not optimal) 
* both require known desired angle and interference angles (don't estimate) 
* GEQ has ffreq domain BF weighting (freq domain from DCT) [Mahmoudi: `98 does something like this with wavelets] 
* GEQ sounds synthetic 
* could I do freq domain BF rever correction? }
}

@Misc{smithXXmultiTrack,
  Title                    = {Multiple target tracking with navigation uncertainty},

  Author                   = {C. M. Smith and H. J. S. Feder and J. J. Leonard},

  Comment                  = {95: ReadYes},
  Review                   = {Not detailed enough to make sense. look at his thesis (it's on line)}
}

@Article{smith02hilbertEnvPhase,
  Title                    = {Chimaeric sounds reveal dichotomies in auditory perception},
  Author                   = {Zachary M. Smith and Bertrand Delgutte and Andrew J. Oxenham},
  Journal                  = {Nature},
  Year                     = {2002},
  Pages                    = {87-90},
  Volume                   = {416},

  Comment                  = {315: ReadYes},
  Review                   = {Human Speech Recog & Hilbert Xform: Envelope = words; Phase = pitch&loc
Synthesised speech from speech and noise:
* Speech -> filterbank -> Hilbert(phase,env) -> swap w/ noise -> sum
* noise goes either in phase or envelope; speech in the other
* log frequency filterbank centers
* >= 4 freq bands: perception better if speech in envelope
* <= 2 freq bands: perception better if speech in phase
Synthesized speech from two talkers
* Speech -> filterbank -> Hilbert(phase,env) -> swap w/ talker -> sum 
* put one talker in phase; the other in pitch
* hear talker in the envelope (>= 4 bands)
Synthesized melody/melody
* correct melody heard phase for <= about 35 bands
Synthesized talkers and locaton
* Right or Left stereo delay in either pitch or phase
* mixed talkers too
* I didn't quite understand the experiment but...
* anyway, location is in phase
Other
* squared Hilbert envelope has same BW as original signal (really? won't square make harmonics?)
* envelope varies more rapidly (fine details show up there) for fewer filterbank filters (each has broader bandwidth)
* maybe relevant to pitch and overlap detection},
  Url                      = {http://www.nature.com/cgi-taf/DynaPage.taf?file=/nature/journal/v416/n6876/full/416087a_fs.html&content_filetype=pdf}
}

@InProceedings{smolenski02fusionIndep,
  Title                    = {(submitted) Fusion of Co-Channel Speech Measures Using Independent Components and Nonlinear Estimation},
  Author                   = {Brett Y. Smolenski and Robert E. Yantorno},
  Booktitle                = {IEEE Intl. symposium on intelligent signal processing and communication systems},
  Year                     = {2002},

  Comment                  = {282: ReadYes},
  Review                   = {TIR prediction = 3rd_order_regression( PCA_fusion(SAPVR-residual,APPC) )
* fusing APPC and SAPVR-residual improves errors by 28% over independent decision
* why not just compute the joint??
* results imply SAPVR-resid/APPC are slighty diff. (because of nonlins?)
Fusion:
* decorrelate 
-- SVD or PCA
-- removes cross terms in subsequent regression
-- OK since APPC and SAPVR almost Guassian (Kolmogorov-Smirnov test)
-- APPC and SAPVR-residual are somewhat redundant (2nd comp v. small)
-- say they could have used ICA but didn't, for some reason
* 3rd order regression
-- TIR not guassian, K-S test says its exponential so can't do linear
-- why not just gaussianize TIR, by log(TIR) or something?
-- 4th order regression overfits
-- could have used LDA instead, 
-- better: logistic regression (ref[14] says it's best for binary outs)
* good refs: K-S test[19], logistic v.s. LDA[14] classifier combo [10]},
  Url                      = {http://www.temple.edu/speech_lab/1stfusionpaper4.PDF}
}

@InProceedings{smolenski02spkSep,
  Title                    = {Co-channel speaker segment separation},
  Author                   = {Brett Y Smolenski and Robert E. Yantorno},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},

  Comment                  = {290: ReadYes},
  Review                   = {Which of two speakers via histogram of GMM likelihood scores
* histo -> priors -> MAP spkrID est.
* a pretty bad paper
* 90% reliable speaker separation, though it's not clear how that was measured}
}

@InProceedings{smyth95CIDclustering,
  Title                    = {Clustering Using Monte Carlo Cross-Validation},
  Author                   = {P. Smyth},
  Booktitle                = {KDD-UAI},
  Year                     = {1995},
  Pages                    = {126-133},

  Comment                  = {Print, ReadNo},
  Review                   = {YET. # of cluster/talker?},
  Url                      = {http://citeseer.nj.nec.com/smyth96clustering.html}
}

@Article{sohn99statistical,
  Title                    = {A statistical model-based voice activity detection},
  Author                   = {J. Sohn and N. Kim and W. Sung},
  Journal                  = {IEEE Signal Processing Letters},
  Year                     = {1999},
  Pages                    = {1-3},
  Volume                   = {6},

  Comment                  = {110: ReadYes},
  Review                   = {* improvement over sohn98voice VAD
-- better SNR estimator
--- DD=decision directed
--- averaged over couple of frames w/ some hard avg. decisions
-- markov hangover scheme w/ arbitrary transition probs},
  Url                      = {citeseer.nj.nec.com/sohn99statistical.html}
}

@InProceedings{sohn98voice,
  Title                    = {A voice activity detector employing soft decision based noise spectrum adaptation},
  Author                   = {J. Sohn and W. Sung},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1998 },
  Pages                    = {356-368},

  Comment                  = {112: ReadYes},
  Review                   = {VAD: If summed DFT coeffs large w.r.t. noise var est, then is speech
* noise variance is estimated from expected value and Bayes Rule
* average subband SNR is a good estimator of crossentropy between background noise and observed signal.
* basis of 'A statistical Model based...', Sohn `99. This is [2] in that paper.
* Note: this is likelihood ratio test and is almost an energy detector
* Replace FFT energy w/ speech/sil likelihood ratio
* do model updates based on decision directed noise as proposed in Sarikaya and Hansen?}
}

@InProceedings{solomonoff-clustering,
  Title                    = {Clustering Speakers by their Voices},
  Author                   = {A. Solomonoff and A. Mielke and M. Schmidt and H. Gish},
  Booktitle                = {Proc. ICASSP },
  Year                     = {1998},
  Pages                    = {757-760},
  Volume                   = {2},

  Comment                  = {157: ReadYes},
  Review                   = {Broadcast News style seg/clust, GLR w/ EM, cluster purity est of IBBN
Segmentation: given
* figures cluster ID merit: IBBN, Irand, cluster purity (chose IBBN)
* 19 ceptstra features + 19 deltas, seems to be single mixture
Clustering
* Generalized likelihood Ratio (GLR) distance between clusters
-- GLR based on EM training w/ and w/o the two segments (expensive)
-- seem to merge the closest
-- mention KL dist but don't use
* Merge all the way to the top (1 cluster) and then cut (prune)
* Prune to maximize estimated purity of cluster i w/ ni segments
-- purity = frac of segs in cluster which are in set of ni closest segs
-- stop cutting when avg. purity stops increasing
-- I don't get why it stops increasing, though)
-- seems like number of utterances (segs) should be duration-weighted.
Results
* pruning sort of works when compared to IBBN peak but that seems to assume the dendogram computed w/ GLR dist 
* i.e. not compared directly w/ perfect answer?},
  Url                      = {http://ieeexplore.ieee.org/iel4/5518/14874/00675375.pdf?isNumber=14874&prod=IEEE+CNF&arnumber=675375&arSt=757&ared=760+vol.2&arAuthor=Solomonoff%2C+A.%3B+Mielke%2C+A.%3B+Schmidt%2C+M.%3B+Gish%2C+H.%3B}
}

@InProceedings{soltau01acoustmodISL,
  Title                    = {unknown title},
  Author                   = {H. Soltau and T. Schaaf and F. Metze and A. Waibel},
  Booktitle                = {ICAASP},
  Year                     = {2001},

  Comment                  = {Print, ReadNo},
  Review                   = {I think it says don't variance normalize before LDA in speech recog}
}

@InProceedings{sonmez98modeling,
  Title                    = {Modeling dynamic prosodic variation for speaker verification},
  Author                   = {K. Sonmez and E. Shriberg and L. Heck and M. Weintraub},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1998},
  Pages                    = {3189-3192},
  Volume                   = {7},

  Comment                  = {193:ReadYes},
  Review                   = {Adding prosodic features to GMM spkrID improves perf by 0.7-10%
* prosodic features are: median f0, f0 slope, segment duration, voiced segment duration, pause duration
* pitch splitting: 
-- common error: 1/2 and x2 the true pitch
-- => so do some kind of filtering (fancy + median)
* training 2min, test 3s to 30s
* improvement @ 3s test = 4.6% (male), 0.7% (female)}
}

@InProceedings{Sonmez97LognormTiedMixPitch,
  Title                    = {A Lognormal Tied Mixture Model of Pitch for Prosody-Based Speaker Recognition},
  Author                   = {K. M. Sonmez and L. Heck and M. Weintraub and E. Shriberg},
  Booktitle                = {Eurospeech},
  Year                     = {1997},
  Pages                    = {1391--1394},

  Comment                  = {30.0: ReadYes},
  File                     = {Sonmez97LognormTiedMixPitch.pdf:Sonmez97LognormTiedMixPitch.pdf:PDF},
  Review                   = {lognormal(F0) matches Gaussian assumption better; tied mixture of lognormals models pitch splitting for speaker ID match
* clean pitch, w/o doubling or halfing, not very gaussian in the tails
* log(pitch) matches Gaussian pretty well
* halviing and doubling by multi-band xcorr model yields a 3-mode estimated pitch distribution
* model estimated distribution w/ EM: "mu" is the true F0
* speaker ID feature is pitch distribution: compare trained w/ test using relative entropy},
  Url                      = {http://www.speech.sri.com/pubs/papers/Sonm9709:Lognormal/document.ps.gz}
}

@InProceedings{spaendonck02localHilbert,
  Title                    = {Local Hilbert transformation for seismic attributes},
  Author                   = {R. L. C. Van Spaendonck and F. C. A. Fernandes and R. G. Baraniuk J. T. Fokkema},
  Booktitle                = {64th Meeting: European Association of Geoscientists and Engineers--- EAGE2002},
  Year                     = {2002},

  Comment                  = {312: ReadYes},
  Review                   = {Wavelet-based time-domain Hilbert filter can work better than FFT-based
* makes a Hilbert FIR based on maximally flat wavelet ("local Hilbert")
* doesn't have some of the artifacts seen in FFT Hilbert envelope
-- FFT is apparently a single one over whole record
-- short term FFT (STFT) has better instantaneous frequency (IF)
-- IF is phase differential
-- Why not use STFT w/ overlap and add for IF and evelope too?
* is more computationally efficient when filter is short
* maybe better than FFT's because use whole single FFT for images, which is what he's proposing.
* relevant to pitch tracking and overlap detection}
}

@InProceedings{stanford00nistSmartFlow,
  Title                    = {NIST Smart Flow System and novel speech signal to noise metrics},
  Author                   = {Vince Stanford},
  Booktitle                = {4th Harvard International Microphone Array Theory and Practice Conference},
  Year                     = {2000},

  Owner                    = {scotto},
  Review                   = {The SNR method I used in my thesis. Builds GMM's and tests for good-ness of fit with the K-S test.

code is buried in here:
http://www.nist.gov/smartspace/nsfs.html

directory:

Smartspace/Development/Audio/AudioComputing/sources/gaussianSNR/gaussianSNR},
  Timestamp                = {2008.02.12},
  Url                      = {http://www.nist.gov/smartspace/snr.html}
}

@InProceedings{stolcke02sriLM,
  Title                    = {{SRILM} -- An Extensible Language Modeling Toolkit},
  Author                   = {Andreas Stolcke},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},

  Comment                  = {303: ReadNo},
  Review                   = {Language model for the SRI recognizer given to UW}
}

@Misc{stolcke00sri,
  Title                    = {The {SRI} March 2000 Hub-5 Conversational Speech Transcription System},

  Author                   = {A. Stolcke and H. Bratt and J. Butzberger and H. Franco and V. Gadde and M. Plauche and C. Richey and E. Shriberg and K. Sonmez and J. Zheng and F. Weng},
  Year                     = {2000},

  Comment                  = {302: ReadYes},
  Review                   = {Good overview of all the tweaks in SRI's recognizer
Highlights (w/ estimates of WER improvement over 1998 Hub-5 system:
Broadband frontent: 4.4
Multiworkd dictionary: 4
cross-word triphones: 1.3
schwas and flaps added to dict: 1
duration modeling: .8
rate dependent model: .7
better adaptation: .7
trigram lattices: .7
cepstral variance norm: .6
class-based LM: .6
N-best ROVER (mulit recog sys combine): .5
Anti-LM (confusability penalty): .4
transcript cleanup: .3
variance scaling xforms: .2

total improvement: 12.5%},
  Text                     = {A. Stolcke, H. Bratt, J. Butzberger, H. Franco, V. R. Rao Gadde, M. Plauche, C. Richey, E. Shriberg, K. Sonmez, and J. Zheng F. Weng. The SRI March 2000 Hub-5 Conversational Speech Transcription System. In Proc. Speech Transcription Workshop, 2000.},
  Url                      = {citeseer.nj.nec.com/stolcke00sri.html}
}

@InProceedings{stolcke04mtnRecogRT04s,
  Title                    = {Progress in Meeting Recognition: The {ICSI-SRI-UW} Spring 2004 Evaluation System},
  Author                   = {A. Stolcke and C. Wooters and N. Mirghafori and T. Pirinen and I. Bulyko and D. Gelbart and M. Graciarena and S. Otterson and B. Peskin and M. Ostendorf},
  Booktitle                = {{NIST} 2004 Meeting Recognition Workshop},
  Year                     = {2004},

  File                     = {stolcke04mtnRecogRT04s.pdf:stolcke04mtnRecogRT04s.pdf:PDF},
  Review                   = {ICSI/SRI/UW system. My near mic features weren't in there, though},
  Url                      = {http://www.icsi.berkeley.edu/ftp/global/pub/speech/papers/nist2004-meeting-system.pdf}
}

@TechReport{stone98icaUnderDimRed,
  Title                    = {Undercomplete Independent Component Analysis for Signal Separation and Dimension Reduction},
  Author                   = { J. V. Stone and J. Porrill},
  Institution              = {Sheffield University},
  Year                     = {1998},

  Comment                  = {ReadNo},
  File                     = {stone98icaUnderDimRed.ps.gz:stone98icaUnderDimRed.ps.gz:PDF},
  Review                   = {For fewer speakers than microphones, or dim reduction},
  Url                      = {ftp://ftp.shef.ac.uk/pub/misc/personal/pc1jvs/papers/ica_dim_red_nips98_WWW.ps.gz}
}

@InProceedings{strobel99tdclass,
  Title                    = {Classification of time delay estimates for robust speaker localization},
  Author                   = {N. Strobel and R. Rabenstein},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999},
  Pages                    = {3081-3084},
  Volume                   = {6},

  Comment                  = {173: ReadYes},
  Review                   = {Angle learned from standard TDOA corr peak histograms
* standard TDOA (phase only freq corr w/ peak picking)
* phase only good? Arslan `00 uses only high pwr freqs
* phase correlation techniques fail in reverb
* train: build histograms of corr peaks w.r.t. known angle
* test: do ML classification of angle, given corr peak
* 1-2s observation time, much longer training
* one speaker only
* chi-squared dist compare better than picking angle w/ max bin count
* I wonder if KL dist would be better yet?}
}

@InProceedings{sturim01anchorspkID,
  Title                    = {Speaker Indexing In Large Audio Databases Using Anchor Models},
  Author                   = {D. Sturim and D. Reynolds and E. Singer and J. Campbell},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2001},

  Comment                  = {189: ReadYes},
  Review                   = {SpkrID feat. is vec. of probs from many GMMs. Faster&worse than UBM-GMM
* Pretrained GMM's for many speakers
* spkr ID feature vector is p(x|A), where A is the vector of spkr models
* doesn't work as well as UBM-GMM (state of art)
* proposed hierarchical, coarse/fine ID for comp. speed but GMM accuracy}
}

@InProceedings{sun93order,
  Title                    = {Order analysis of combined features in speaker recognition},
  Author                   = {Z. Sun and J. Mason},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1993},

  Comment                  = {200: ReadYes},
  Review                   = {Combine MFCC, RASTA-PLP and their deltas w/ LDA w/ no perf loss
* combinations of MFCC (order 14) and RASTA-PLP and deltas considered
* VQ spkr ID
* dividing by pooled covariance helps
* LDA reduces feature vector order from 56 to 22 w/ no perf loss},
  Url                      = {citeseer.nj.nec.com/sun93order.html}
}

@InProceedings{suyama00quadProgMicArr,
  Title                    = {A learning algorithm for adaptive microphone arrays based on mathematical programming methods},
  Author                   = {K. Suyama and R. Hirabayashi},
  Booktitle                = {{IEEE} ?},
  Year                     = {2000},

  Comment                  = {278: ReadNo},
  Review                   = {But compares RLS and LMS BF algs. Then proposes a quadratic programming method. Could this be discriminative between speakers? Could it be stuck into some kind of support vector machine clustering algorithm?}
}

@Article{lee00classSwitchICA,
  Title                    = {{ICA} Mixture Models for Unsupervised Classification of Non-Gaussian Sources and Automatic Context Switching in Blind Signal Separation},
  Author                   = {T-W. Lee, M.S. Lewicki and T.J. Sejnowski},
  Journal                  = {{IEEE} Transactions on Pattern Recognition and Machine Intelligence},
  Year                     = {2000.},
  Number                   = {10},
  Pages                    = {1-12},
  Volume                   = {22},

  Comment                  = {ReadNo}
}

@Article{tabrikian00srcloc,
  Title                    = {Robust localization of scattered sources},
  Author                   = {J. Tabrikian and H. Messer},
  Journal                  = {{IEEE} ?},
  Year                     = {2000},

  Comment                  = {245: ReadNo},
  Review                   = {Subspace multi source ML DOA estimator}
}

@Article{takiguchi01hmmSpkrMove,
  Title                    = {{HMM}-separation-based speech recongition for a distant moving speaker},
  Author                   = {T. Takiguchi and S. Nakamura and K. Shikano},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2001},
  Number                   = {2},
  Pages                    = {127-140},
  Volume                   = {9},

  Comment                  = {131: ReadNo},
  Review                   = {(should!) speaker location HMM stae -- sounds pretty familiar!}
}

@InBook{talkin95pitch_get_f0,
  Title                    = {Speech Coding and Synthesis},
  Author                   = {David Talkin},
  Chapter                  = {A Robust Algorithm for Pitch Tracking ({RAPT})},
  Publisher                = {Elsevier},
  Year                     = {1995},

  Comment                  = {ReadYes},
  Review                   = {The Xwaves get_f0 program reference. Is a correlation based pitch detector. Editors but bibtex complains if both author and editor: W. B. Kleijn and K. K. Paliwal}
}

@InProceedings{Tamura05multiHmmSteamNorm,
  Title                    = {A Stream-Weight Optimization Method for Multi-Stream HMMS Based on Likelihood Value Normalization},
  Author                   = {Tamura, S.; Iwano, K.; Furui, S.},
  Year                     = {March 18-23, 2005},
  Pages                    = { 469-472},
  Volume                   = {1},

  Doi                      = {10.1109/ICASSP.2005.1415152},
  File                     = {:Tamura05multiHmmSteamNorm.pdf:PDF},
  ISSN                     = {1520-6149},
  Journal                  = {Acoustics, Speech, and Signal Processing, 2005. Proceedings. (ICASSP '05). IEEE International Conference on},
  Owner                    = {scotto},
  Timestamp                = {2007.11.20}
}

@InProceedings{Tamura04multiHmmStreamOpt,
  Title                    = {A stream-weight optimization method for audio-visual speech recognition using multi-stream HMMs},
  Author                   = {Tamura, S.; Iwano, K.; Furui, S.},
  Year                     = {17-21 May 2004},
  Pages                    = { I-857-60 vol.1},
  Volume                   = {1},

  Doi                      = {10.1109/ICASSP.2004.1326121},
  File                     = {:Tamura04multiHmmStreamOpt.pdf:PDF},
  ISSN                     = {1520-6149 },
  Journal                  = {Acoustics, Speech, and Signal Processing, 2004. Proceedings. (ICASSP '04). IEEE International Conference on},
  Keywords                 = { error statistics, feature extraction, hidden Markov models, maximum likelihood estimation, optimisation, regression analysis, speech recognition, video signal processing Japanese connected digit speech, MLLR, acoustic features, audio-visual speech recognition, error rate reduction, likelihood-ratio maximization criterion, maximum likelihood linear regression, multi-stream HMM, stream-weight optimization, video signal capturing, visual features},
  Owner                    = {scotto},
  Review                   = {automatic method for audio/visual HMM stream weight adaptation},
  Timestamp                = {2007.11.20},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1326121}
}

@Article{tan99waveletHRTFpreproc,
  Title                    = {Wavelet packet decomposition for spatial sound conditioning},
  Author                   = {C. Tan and W. Gan},
  Journal                  = {Electronic letters},
  Year                     = {1999},
  Number                   = {21},
  Volume                   = {35},

  Comment                  = {225: ReadYes},
  Review                   = {Wavelet preprocessing to enhancement speech localizability 
* broad band signlas are most localizable 
* speech not very broadband 
* weight band pass filter outs (wavelets) to equalize speech (mostly high freq boost) 
* synthesized HRTF the works much better w/ small effect on speech quality}
}

@PhdThesis{tangwongsan03bloodHeat,
  Title                    = {Measurement of in vivo Endocardial and Hepatic Convective Heat Transfer Coefficient},
  Author                   = {Chanchana Tangwongsan},
  School                   = {University of Wisconsin-Madison},
  Year                     = {2003},

  Comment                  = {ReadYes},
  File                     = {tangwongsan03bloodHeat.pdf:tangwongsan03bloodHeat.pdf:PDF},
  Review                   = {blood heat transfer in pigs},
  Url                      = {http://rf-ablation.engr.wisc.edu/papers/Chanchana_Dissertation.pdf}
}

@Misc{thiebauxXXkalMark,
  Title                    = {Combining {Kalman} filtering and {Markov} localization in network-like environments},

  Author                   = {S. Thiebaux and P. Lamb},

  Comment                  = {94: ReadYes},
  Review                   = {Kalman pos track w/ Markov street corner changes
* apriori transition probs
* for meeting speaker segmentation: kalman could be pitch est, Markov speaker change or just dropout?
* has multiple hypothesis
* no EM optimization
* no path merging but is references [14] (would need this)}
}

@Misc{thierry-learning,
  Title                    = {Learning from an imprecise teacher: probabilistic and evidential approaches},

  Author                   = {Christophe Ambroise Thierry},

  Comment                  = {117: ReadNo},
  Review                   = {: mixtures when labels imprecise or multi-class. The author (Christophe Ambroise <ambroise@utc.fr>) sent me matlab for this one},
  Url                      = {citeseer.nj.nec.com/451690.html}
}

@TechReport{thiesson97dagMixLearn,
  Title                    = {Learning mixtures of {DAG} models},
  Author                   = {B. Thiesson and C. Meek and D. M. Chickering and D. Heckerman},
  Institution              = {Microsoft Research},
  Year                     = {1997},
  Number                   = {MSR-TR-97-30},

  Comment                  = {15.5: ReadNo}
}

@Article{thrun98probabilistic,
  Title                    = {A Probabilistic Approach to Concurrent Mapping and Localization for Mobile Robots},
  Author                   = {S. Thrun and W. Burgard and D. Fox},
  Journal                  = {Machine Learning},
  Year                     = {1998},
  Pages                    = {29},
  Volume                   = {31},

  Comment                  = {Print, ReadNo},
  Url                      = {citeseer.nj.nec.com/thrun98probabilistic.html}
}

@Misc{tim99clustering,
  Title                    = {Clustering Time Series with Hidden Markov Models and Dynamic Time Warping},

  Author                   = {O. Tim and L. Firoiu and P. Cohen},
  Year                     = {1999},

  Comment                  = {46: ReadNo},
  Text                     = {Oates, Tim, Laura Firoiu and Paul R. Cohen. 1999. Clustering Time Series with Hidden Markov Models and Dynamic Time Warping. To be presented at IJCAI-99 Workshop on Sequence Learning.},
  Url                      = {citeseer.nj.nec.com/article/tim99clustering.html}
}

@TechReport{tipping99mixPCA,
  Title                    = {Mixtures of Probabilistic Principal Component Analysers},
  Author                   = {Michael E. Tipping and Christopher M. Bishop},
  Year                     = {1999},
  Number                   = {2},

  Comment                  = {634:ReadYes},
  File                     = {tipping99mixPCA.pdf:tipping99mixPCA.pdf:PDF},
  Journal                  = {Neural Computation},
  Owner                    = {scotto},
  Pages                    = {443-482},
  Review                   = {Probalistic model of PCA allows confidences, and mixtures, which allow non-linear PCA

Probabilistic PCA (PPCA)
* PPCA compared to factor analysis; PPCA seems better?
* Is a way to convert PCA reconstruction error into a probability model (recons error ~ "noise" variance) 
* latent variable, x, is a low dimensional vector which is blown out by matrix multiplication by W to a high D space, t
 - BUT, max likelihood x and W don't yield min error reconstruction
 - PCA Lagrange constrant on w is norm==1
 - PPCA constraint on w is "sum to 1" via gaussian prior
 - STILL, you can use ML x and W to get min error reconstruction (after a transform)
 - you'd want to use ML x and W to run PPCA EM or to calculate a probability, like for mixture of PPCA's 
* prob dist of high-D is also gaussian, meaning you could insert confidences both during eval and training of PPCA
* turns out that max likelihood estimator of W comes from the principal eigennvecs of observed covariance matrix
* PPCA EM algorithm is good for high-D cases, but can doalso do PPCA w/ eigencalcs and then calc PPCA probability
 - EM algorithm would allow confidences, though

Mixtures of PPCA
* There's also on EM algorithm for a mixture of PPCA's, which allows PCA to follow non-linear paths
* mixtures of PPCA tend to be more compact than VQPCA zones
* mixtures of PPCA's may have fewer params than a diagonal GMM, for which individual mixure comps cannont camper correlations amongst variables.
* clear explanation in A.6 for solving principle axis rotational ambiguity},
  Timestamp                = {2007.05.28},
  Url                      = {citeseer.ist.psu.edu/tipping98mixtures.html},
  Volume                   = {11}
}

@Article{Tipping99ProbPrincComp,
  Title                    = {Probabilistic Principal Component Analysis},
  Author                   = {Michael E. Tipping and Christopher M. Bishop},
  Journal                  = {Journal of the Royal Statistical Society, Series B},
  Year                     = {1999},
  Number                   = {3},
  Pages                    = {611-622},
  Volume                   = {61},

  Comment                  = {638:ReadYes},
  File                     = {Tipping99ProbPrincComp.pdf:Tipping99ProbPrincComp.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Original probabilistic pca (PPCA) paper
* see tipping99mixPCA for more details
* output dimension, q, is a way of controlling degrees of freedom, gives equ. for # params 
 ==> could use BIC to pick # PCA dims?
* good discussion of cov matrix in EM computational complexity tradeoff
 - calc cov matrix @ initialization (potentially huge matrix)
 - OR est. S*W @ each iteration
* kind of explains how to deal with PPCA's inherent rotational ambiguity (Tipping99ProbPrincComp explains it well, though)},
  Timestamp                = {2007.05.30},
  Url                      = {http://citeseer.ist.psu.edu/tipping99probabilistic.html}
}

@InProceedings{tishby99infoBottleneck,
  Title                    = {The information bottleneck method},
  Author                   = {N. Tishby and F. Pereira and W. Bialek},
  Booktitle                = {Proceedings of the 37-th Annual Allerton Conference on Communication, Control and Computing},
  Year                     = {1999},
  Pages                    = {368--377},

  File                     = {tishby99infoBottleneck.pdf:tishby99infoBottleneck.pdf:PDF},
  Url                      = {citeseer.ist.psu.edu/tishby99information.html}
}

@InProceedings{tokuda99multiDhmm,
  Title                    = {Multi-Space Probability Distribution {HMM} (I'm not sure about this)},
  Author                   = {K. Tokuda and T. Masuko and N. Miyazaki and T. Kobayashi},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999 },
  Pages                    = {229-232},
  Volume                   = {1},

  Comment                  = {Print, ReadNo}
}

@Article{tolonen00multipitch,
  Title                    = {A computationally efficient multipitch analysis model},
  Author                   = {Tolonen, T. and Karjalainen, M. },
  Journal                  = {IEEE Trans., Speech and Audio Proc.},
  Year                     = {2000},
  Number                   = {6},
  Pages                    = {708-716},
  Volume                   = {8},

  Comment                  = {322: ReadYes},
  Review                   = {Two channel auditory pitch det w/ pre-whitening
* inverse warped linear prediction (WLP) filtering 
* like Rouet `97 but only two channels 
- low freq: <1KHz, BPF
- high freq: >1KHz, computes envelope (half wave rect / LPF)
* Peridicity detection in low and high channels
- FFT autocorr but mag has exponent for extra nonlinear compression
* Two bands Rxx's are summed
* Cleanup to remove harmonics and root tones (beats) w/ wierd freq compression and subtract (but it works on the musical chord experiment). Says it's similar to Ellis's but it's really different.
* tests are sort of hand-wavy


* Referenced in wu&wang multipitch. Seems to be closest competitor. Wu says his alg is better.}
}

@InProceedings{tong90bssAMUSE,
  Title                    = {tong90bss{AMUSE}},
  Author                   = {Tong, L. and Soon, V.C. and Huang, Y.F. and Liu, R.},
  Booktitle                = {Circuits and Systems, {IEEE} Intl. Symp. on},
  Year                     = {1990},
  Pages                    = {1784-1787},
  Volume                   = {3},

  Comment                  = {ReadNo},
  Review                   = {bss exploiting temporal coherence},
  Url                      = {http://ieeexplore.ieee.org/iel5/143/3356/00111981.pdf?isNumber=3356&prod=CNF&arnumber=111981&arSt=1784&ared=1787+vol.3&arAuthor=Tong%2C+L.%3B+Soon%2C+V.C.%3B+Huang%2C+Y.F.%3B+Liu%2C+R.}
}

@InProceedings{torkkola99bss,
  Title                    = {Blind separation for audio signals -- are we there yet?},
  Author                   = {K. Torkkola},
  Booktitle                = {Independent component analysis and blind signal separation, Intl. Conf. on},
  Year                     = {1999},

  Comment                  = {280: ReadYes},
  File                     = {torkkola99bss.pdf:torkkola99bss.pdf:PDF},
  Review                   = {Overview of ICA/BSS speaker separation (overlap resolution)
* prefers feedforward (FIR) to feedback (IIR) unmixers
* freq domain: convolutive (reverb) -> isolated probs in many freq bands
* - note: anemuller may have solved the resulting scale/permut probs
ICA v.s. BSCM (blind source convolutive mixture)
* ICA: traditionally assumes stationary, 2nd order spatial stats (HOS)
* BSCM: assumes temporal-spatial stats, non-stationary, 2nd order stats
* But for either:
- stationary: spatial stats and > 2nd order stats (HOS)
- nonstationary: 2nd order stats usable (2nd order est more robust)

* so they're kinda the same in their assumptions?
Separation Criteria:
* MMI: minimizing mutual information between separated channels
* InfoMax or Entropy maximization: 
- y=g(Wx), (g() is non-lin func?)
- estimates W to max entropy of y (indep src mix is less predicable)
* Latent source model or ML: 
- choose W to drive towards known distributions
- idea: could use if had already built speaker ID models
-- see my scribbling on the paper
- combine w/ clustering somehow? 
- can jointly estimate the source models and the mixture parms!!
* Bussgang: I don't get it: some derivative stuff
* Central Limit Theorem
- drive away from Gaussians, non-Guassian mix -> Gaussian
- Negentropy or Kurtosis: HOS measures of Gaussianity (Gauss: HOS=0)
-- flat pdf sources: separate by HOS -> -infinity
-- peaky pdf sources: separate by HOS -> +infinity
* Spatio-Temporal Decorrelation
- multiple linearly indep equs @ different corr lags (like anemuller diagonalization)
When/Why BSS might not work?
* true assumptions
* reverb, vibration, etc. SO many, many sources, not just speech/noise
* dynamism: headturns, movement SO big mix changes (Brandenstein)
Suggestions:
* combine non-stationarity decorr approaches w/ source densities
* use fact that speech is the signal
* maybe concentrate on artificial data 1st, like comm. probs.},
  Url                      = {http://members.cox.net/torkkola/torkkola-aussois99.pdf}
}

@Article{torres-carrasquillo04spkrDiariz,
  Title                    = {The {MIT} lincoln laboratory speaker diarization systems},
  Author                   = {P. Torres-Carrasquillo and D. A. Reynolds},
  Journal                  = {RT-04 Workshop, EARS PI Meeting},
  Year                     = {2004},
  Pages                    = {paper 42},

  Comment                  = {ReadYes},
  Review                   = {BN clustering w/ posterior probs as clustering features
* standard spkr change detect / clustering / gender+bandwidth pre-segment
* BIC in both change det and clust, notes probs w/ short segs

Two systems, different features
1.) BIC clustering
- I think it's just GMM's w/ BIC stopping but it's not really described
2.) Proxy speakers
- start 2/ 128 mixture UBM
- make a model for each segment detected by VAD by adapting UBM (lots of segs!?)
- go back and make a vector of posterior probs for these segs
- agglomerative cluster (Euclidean distance) on posteriors
-- says that Euclidean worked better than other distance metrics (did he try GMM dists??)

The proxy speaker has slightly better BN perf: 14.13% error vs. 16.77%}
}

@Article{toyama99interpHRTF,
  Title                    = {Head related transfer function representation of directional sound for spatial acoustic events modeling},
  Author                   = {M. Toyama and M. Uchiyama and H. Nomura},
  Journal                  = {Unknown},
  Year                     = {1999},

  Comment                  = {226: ReadYes},
  Review                   = {How to interpolate HRTF's between those that were measured 
* interp. minimizes mean squared error}
}

@InProceedings{tranter04spkrDiariz,
  Title                    = {The development of the cambridge university rt04 diarization system},
  Author                   = {S. E. Tranter and M. J. F. Gales and R. Sinha and S. Umesh and P. C. Woodland},
  Booktitle                = {{RT-04} Workshop, {EARS PI} Meeting},
  Year                     = {2004},

  Comment                  = {ReadYes},
  Review                   = {conventional BN system w/ lots of engineering
- VAD helps
- cepstral mean subtraction hurts diarization lot! 
eg. 16.2%error --> 23.3% error (MFCC's)
14% error --> 25.4% (PLP's)
- energy helps: 20.3% --> 15.3% (PLP's)
- c0 hurts, energy helps
- PLP's a little better than MFCC's (14% vs. 16.2%)}
}

@InProceedings{tritschler99spkrSegBIC,
  Title                    = {Improved Speaker Segmentation and Segments Clustering using the Bayesian Information Criterion},
  Author                   = {Alain Tritschler and Ramesh Gopinath},
  Booktitle                = {Eurospeech},
  Year                     = {1999},
  Pages                    = {679-682},

  Comment                  = {ReadNo},
  Review                   = {The authors present an improved version of the method for speaker segmentation and clustering using Bayesian Information Criterion introduced by S. Chen. Unlike Chen's method, the proposed algorithm performs several iterations over the conversation to search for the speaker change boundaries. This method improves the speed and accuracy over the Chen's method. 

On bibliography here:

http://www.ece.ogi.edu/~adami/references.htm

Mari has paper copy}
}

@Misc{quickBSSXXwebpage,
  Title                    = {Quickie Blind source speparaton {BSS}},

  Author                   = {Unknown},

  Comment                  = {17.5: ReadYes},
  Review                   = {A review of matrix based blind source sep techs: decorr, ICA, PCA}
}

@Misc{nist05shewhartCharts,
  Title                    = {{NIST/SEMATECH} e-Handbook of Statistical Methods, {http://www.itl.nist.gov/div898/handbook/}},

  Author                   = {UNKNOWN},
  HowPublished             = {E-book},
  Year                     = {2005},

  Review                   = {Shewart charts explained on: 

http://www.itl.nist.gov/div898/handbook/pmc/section3/pmc321.htm},
  Url                      = {http://www.itl.nist.gov/div898/handbook/pmc/pmc.htm}
}

@Book{gaussDAGbookKL,
  Title                    = {Graphical Models in Applied Multivariate Statistics},
  Author                   = {unknown author},
  Publisher                = {unknown publisher},
  Year                     = {unknown},

  Comment                  = {89: ReadNo},
  Review                   = {useful reference for K-L distance and Gaussian properties (chaps 4,5)
4. Information Divergence (Kullback-Leibler Invformation Divergence)
-- intuitive explanation
-- relation to graphical models
5. The Inverse Variance
-- least squares
-- Gaussian cov matrix props
-- partial covariance
-- Cholesky decomp
* I'm not sure where I got this}
}

@InBook{ee516bookAcoustModel,
  Title                    = {Speech Recognition Book Chapter 9 ({EE}516 text?)},
  Author                   = {unknown author},
  Chapter                  = {9},
  Pages                    = {413-471},
  Publisher                = {UNKNOWN PUBLISHER was it really 2004?},
  Year                     = {2004},

  Comment                  = {20.0: ReadNo},
  Review                   = {Discusses MLLR}
}

@Article{usagawaXXbinaural,
  Title                    = {A binaural model as a front-end for isolated word recognition},
  Author                   = {T. Usagaw and K. Boddne and M. Rateitschek},
  Journal                  = {Unknown},
  Year                     = {unknown},

  Comment                  = {208: ReadYes},
  Review                   = {Time domain correlation imitates human ITD detection
Crappy paper}
}

@InProceedings{usagawa96binaual,
  Title                    = {Modeling human sound-source localization and the cocktail-party-effect},
  Author                   = {T. Usagawa and M. Bodden and K. Rateitschek},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1996},
  Pages                    = {2352-2355},
  Volume                   = {4},

  Comment                  = {Print, ReadNo},
  Review                   = {DONT HAVE YET}
}

@Book{Vaidyanathan93MultiRateFiltBanks,
  Title                    = {Multirate Systems and Filter Banks},
  Author                   = {P. P. Vaidyanathan},
  Publisher                = {Prentice
Hall, Englewood Cliff},
  Year                     = {1993},

  Owner                    = {scotto},
  Review                   = {Talks about aliasing cancellation in chapter 5 (I think) which could be used for anti-spatial aliasing if using full spectrum, not subbands (from kumatani07... paper)},
  Timestamp                = {2008.01.31}
}

@InProceedings{vaith00heirBayesTxt,
  Title                    = {Hierarchical {Bayes} for text classification},
  Author                   = {S. Vaithyanathan and J. Mao and B. Dom},
  Booktitle                = {{PRICAI} Workshop on Text and Web Mining},
  Year                     = {2000},
  Pages                    = {36-43},

  Comment                  = {77: ReadNo},
  Review                   = {.
* Hierarchical clustering.
* Dirchlet prior for Bernoulli
* derivation of Laplace prior (I think that's a conjugate prior)
* I think Laplace has something to do with BIC
* possibly a way to do better than autoclass cheeseman-stutz clustering to get number of speakers (number of clusters)
* }
}

@Article{valaee99locLeastSq,
  Title                    = {Localization of Wideband Signals Using Least-Squares and Total Least-Squares Approaches },
  Author                   = {Shahrokh Valaee and Benoit Champagne and Peter Kabal},
  Journal                  = {Signal Processing, IEEE Transactions on},
  Year                     = {1999},
  Number                   = {5},
  Pages                    = {1213-1222},
  Volume                   = {47},

  Comment                  = {ReadNo}
}

@Article{Valle99pcaNcompsRecons,
  Title                    = {Selection of the Number of Principal Components: The Variance of the Reconstruction Error Criterion with a Comparison to Other Methods},
  Author                   = {Valle, S. and Li, W. and Qin, S.J.},
  Journal                  = {Industrial \& Engineering Chemistry Research},
  Year                     = {1999},
  Number                   = {11},
  Pages                    = {4389-4401},
  Volume                   = {38},

  Affiliation              = {Department of Chemical Engineering, The University of Texas at Austin, Austin, Texas 78712},
  Comment                  = {643},
  File                     = {Valle99pcaNcompsRecons.pdf:Valle99pcaNcompsRecons.pdf:PDF},
  ISSN                     = {0888-5885},
  Review                   = {10 PCA dim picking techniques MDL/ACI degrees of freedom: see wax85sigDetInfo},
  Url                      = {http://pubs3.acs.org/acs/journals/doilookup?in_doi=10.1021/ie990110i}
}

@InProceedings{vandecatseye03spkrSeg,
  Title                    = {A {FAST}, {ACCURATE} {AND} {STREAM}-{BASED} {SPEAKER} {SEGMENTATION} {AND} {CLUSTERING} {ALGORITHM}},
  Author                   = {An Vandecatseye and Jean-Pierre Martens},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {941-944},

  Comment                  = {567: ReadNo},
  Review                   = {BN style spkr seg/clust w/ odd clustering heuristic, prosody doesn't help}
}

@Book{vardeman98statQualMetthBk,
  Title                    = {Statistical Quality Assurance Methods for Engineers},
  Author                   = {Stephen B. Vardeman and J. Marcus Jobe},
  Publisher                = {Wiley},
  Year                     = {1998},

  Comment                  = {ReadNo},
  Review                   = {Explains CUSUM change detection algorithm},
  Url                      = {http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471159379.html}
}

@InProceedings{vaswani05changedetCUSUM,
  Title                    = {The Modified {CUSUM } Algorithm for Slow and Drastic Change Detection in General {HMMs} with Unknown Change Parameters},
  Author                   = {Namrata Vaswani},
  Booktitle                = {ICASSP},
  Year                     = {2005},

  Comment                  = {ReadNo},
  Review                   = {Change det based kinda cdf+hmm. Works w/ GLR},
  Url                      = {http://users.ece.gatech.edu/~namrata/icassp05.pdf}
}

@InProceedings{vescovi03spkrChngDetDynProg,
  Title                    = {A {DP} Algorithm for Speaker Change Detection},
  Author                   = {Michele Vescovi and Mauro Cettolo and Romeo Rizzi},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {2997-3000},

  Comment                  = {583: ReadNo},
  Review                   = {viterbi finding of spkr change points}
}

@InProceedings{veth98backoff,
  Title                    = {Acoustic Backing-Off in the Local Distance Computation for Robust Automatic Speech Recognition},
  Author                   = {J. de Veth and B. Cranen and L. Boves},
  Booktitle                = {Proc. ICSLP},
  Year                     = {1998},
  Pages                    = {1427-1430},

  Comment                  = {29.5: ReadNo},
  Review                   = {This is the backoff algorithm discussed in mori01vqchangedet. 
It's used for both VQ and GMM models.}
}

@InProceedings{vielva02bssUnderTvar,
  Title                    = {Underdetermined Blind Source Separation in a Time-Varying environment},
  Author                   = {L. Vielva and D. Erdogmus and C. Pantale?n and I. Santamar?a and J. C. Pr?ncipe},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},
  Pages                    = {3049-3052},
  Volume                   = {3},

  Comment                  = {ReadNo},
  Review                   = {On the way to monaural ica},
  Url                      = {http://ieeexplore.ieee.org/search97/s97is.vts?Action=FilterSearch&SearchPage=VSearch.htm&ResultTemplate=adv_crst.hts&Filter=fld_sch.hts&ViewTemplate=lpdocview.hts&queryText=Underdetermined+Blind+Source+Separation+in+a+Time-Varying+environment&collection=jour&collection=conf&collection=stds&collection=pprint&py1=&py2=2002&SortField=pyr&SortOrder=desc&ResultCount=15}
}

@InProceedings{vielva01bssUnderSparse,
  Title                    = {Underdetermined Blind Source Separation using a Probabilistic Source Sparsity Model},
  Author                   = {L. Vielva and D. Erdogmus and J. C. Pr?ncipe},
  Booktitle                = {Independent Component Analysis and Blind Signal Separation, Intl. Conf. on},
  Year                     = {2001},

  Comment                  = {ReadNo},
  Review                   = {on the way to monaural ica. I think matlab was available for this.},
  Url                      = {http://ica2001.ucsd.edu/index_files/pdfs/036-vielva.pdf}
}

@InProceedings{vielva02bssUnderMix,
  Title                    = {Estimation of the Mixing Matrix for Underdetermined Blind Source Separation Using Spectral^^Estimation Techniques},
  Author                   = {L. Vielva and I. Santamar?a and C. Pantale?n and J. Ib??ez and D. Erdogmus},
  Booktitle                = {EUSIPCO},
  Year                     = {2002},

  Comment                  = {ReadNo},
  Review                   = {On the way to monaural ica. Accepted but no ps or pdf available. Get eventually },
  Url                      = {http://gtas.dicom.unican.es/comp/Luis/investiga_Luis.html}
}

@InProceedings{vijayasenan07diarizAgglomInfoBotneck,
  Title                    = {Agglomerative information bottleneck for speaker diarization of meetings data},
  Author                   = {Vijayasenan, Deepu and Valente, Fabio and Bourlard, Herve},
  Booktitle                = {Automatic Speech Recognition \& Understanding, 2007. ASRU. IEEE Workshop on},
  Year                     = {9-13 Dec. 2007},
  Pages                    = {250-255},

  Abstract                 = {In this paper, we investigate the use of agglomerative Information Bottleneck (aIB) clustering for the speaker diarization task of meetings data. In contrary to the state-of-the-art diarization systems that models individual speakers with Gaussian Mixture Models, the proposed algorithm is completely non parametric . Both clustering and model selection issues of non-parametric models are addressed in this work. The proposed algorithm is evaluated on meeting data on the RT06 evaluation data set. The system is able to achieve Diarization Error Rates comparable to state-of-the-art systems at a much lower computational complexity.},
  Doi                      = {10.1109/ASRU.2007.4430119},
  File                     = {vijayasenan07diarizAgglomInfoBotneck.pdf:vijayasenan07diarizAgglomInfoBotneck.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Diarization clustering using information bottleneck. 
- "minimize the mutual information loss between
successive clusterings while preserving the mutual information to
a relevance variable"
- lower comp. cost than normal agglom.
- use to determine which PCA dim has lowest error?},
  Timestamp                = {2008.01.31},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=4430119&isnumber=4430068&punumber=4430067&k2dockey=4430119@ieeecnfs&query=%28%28agglomerative+information+bottleneck+for+speaker+diarization+of%0D%0Ameetings+data%29%3Cin%3Emetadata%29&pos=0}
}

@TechReport{vinton02modCodec,
  Title                    = {A Scalable and progressive audio codec},
  Author                   = {Mark S. Vinton and Les. E. Atlas},
  Institution              = {University of Washington},
  Year                     = {2002},

  Comment                  = {343: ReadYes},
  Review                   = {Les's modulation spectrum coder paper. Not sure where this was published or when, actually. This is a guess.},
  Url                      = {http://www.ee.washington.edu/research/isdl/papers/vinton-01-icassp.pdf}
}

@Article{vlassis99kurtosisbased,
  Title                    = {A kurtosis-based dynamic approach to {Gaussian} mixture modeling},
  Author                   = {N. Vlassis and A. Likas},
  Journal                  = {IEEE Trans. Systems, Man, and Cybernetics, Part A},
  Year                     = {1999},
  Pages                    = {393-399},
  Volume                   = {29},

  Comment                  = {133: ReadNo},
  Review                   = {How to pick # of mixtures. Use in agglomerative clustering when deciding when to increase number of mixtures?},
  Url                      = {citeseer.nj.nec.com/107308.html}
}

@TechReport{vlassis00multiGaussKurt,
  Title                    = {A multivariate kurtosis-based approach to Gaussian mixture modeling},
  Author                   = {N. Vlassis and A. Likas and B. Kr?se.},
  Institution              = {Computer Science Institute, University of Amsterdam},
  Year                     = {2000},
  Number                   = {IAS-UVA-00-04},

  Comment                  = {369: ReadNo},
  Review                   = {Derivation of kurtosis of a multi-variate Gaussian mixture model. Drives EM clustering. Use for stopping criteria or source separation?
Null hypothesis is a Gaussian w/ same # of mixtures. },
  Url                      = {ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/IAS-UVA-00-04.ps.gz}
}

@InProceedings{waheed03entropyEndPt,
  Title                    = {An Entropy based Robust Speech Boundary Detection Algorithm for Realistic Noisy Environments},
  Author                   = {Khurram Waheed and Kim Weaver and Fathi M. Salam},
  Booktitle                = {{IEEE-INNS} Joint Int'l Conf. on Neural Networks},
  Year                     = {2003},

  Comment                  = {ReadNo},
  Review                   = {Not available yet. There's an 02 paper: waheed02entropyEndPt}
}

@InProceedings{waheed02entropyEndPt,
  Title                    = {A Robust Algorithm for Detecting Speech Segments Using an Entropic Contrast},
  Author                   = {Khurram Waheed and Kim Weaver and Fathi M. Salam},
  Booktitle                = {{IEEE} Intl. Midwest Symposium on Circuits and Systems,},
  Year                     = {2002},
  Pages                    = {328-331},
  Volume                   = {3},

  Comment                  = {427: ReadYes},
  Review                   = {Time domain entropy VAD w/ noncausal thresh, const for whole file
* less sensitvie to speech energy cange than energy in "some" nosie
* works better than energy for sub-vocal (?) and fricative sounds
* premphasis filter before entropy calc, emphasizes VT over pitch
* also bandpass (cutoffs not specified)
* no justification why do in time domain, though
* spch/nonspch thresh is a little higher than mean entropy
* says min entorpy is a "measure of the remant of noise floor" (?)
* heuristic segment merging
* one merge criteria is small adjacent seg dist (dist metric undefined)
* Recog error tests
- white noise only (not the hard case, probably)
- 5,10,5dB SNR
- improved WER 9,14,16%},
  Url                      = {http://www.egr.msu.edu/~waheedkh/papers/mwscas02_entropy_endpoint_final.pdf}
}

@Misc{wallaceXXmmlMixtures,
  Title                    = {{MML} mixture modelling of multi-state, Poisson, von Mises circular and Gausssian distributions},

  Author                   = {C. S. Wallace and D. L. Dowe},

  Comment                  = {72: ReadNo},
  Review                   = {MML (related to BIC and MDL). SNOB clustering theory (another is wallaceXXmmlKolmog) Can this pick number of mixtures in GMM's?}
}

@Misc{walmsley99bayesian,
  Title                    = {Bayesian modelling of harmonic signals for polyphonic music tracking},

  Author                   = {P. Walmsley and S. Godsill and P. Rayner},
  Year                     = {1999},

  Comment                  = {318: ReadNo},
  Text                     = {P. J. Walmsley, S. J. Godsill, and P. J. W. Rayner. Bayesian modelling of harmonic signals for polyphonic music tracking. In Cambridge Music Processing Colloquium, Cambridge, UK, September 30 1999. Available on-line 8 . 4, 5},
  Url                      = {citeseer.nj.nec.com/walmsley99bayesian.html}
}

@Misc{walmsley-bayesian,
  Title                    = {Bayesian Graphical Models for Polyphonic Pitch Tracking},

  Author                   = {Paul J. Walmsley and Simon J. Godsill and Peter J.W. Rayner},

  Comment                  = {317: ReadNo},
  Url                      = {citeseer.nj.nec.com/article/walmsley99bayesian.html}
}

@Misc{wan00svmSpkrID,
  Title                    = {Support vector machines for speaker verification and identification},

  Author                   = {V. Wan and W. M. Campbell},

  Comment                  = {12.0: ReadNo}
}

@InProceedings{wang00multiCamMic,
  Title                    = {Robust automatic video-conference with multiple cameras and microphones},
  Author                   = {C. Wang and S. Griebel and M. Brandstein},
  Booktitle                = {{IEEE} ?},
  Year                     = {2000},
  Pages                    = {1585-1588},

  Comment                  = {265: ReadYes},
  Review                   = {Repeats wavelet filter discussed in prev. paper 
* audio localization points camera 
* camera finds face loc. (sometimes) and this gives audio enhancement a BF focus vector}
}

@Article{wang03spkrSegNoRecog,
  Title                    = {{SPEECH} {SEGMENTATION} {WITHOUT} {SPEECH} {RECOGNITION}},
  Author                   = {Dong Wang and Lie Lu and Hong-Jiang Zhang},
  Journal                  = {Proc. ICASSP},
  Year                     = {2003},

  Comment                  = {ReadNo},
  Review                   = {Not available yet},
  Url                      = {http://research.microsoft.com/users/llu/publications.aspx}
}

@InProceedings{wayg01eigenMLLRspkrID,
  Title                    = {Eigen-{MLLR} Coefficients as New Feature Parameters for Speaker Identi cation},
  Author                   = {Nick J.-C. Wang and Wei-Ho Tsai and Lin-Shan Lee},
  Booktitle                = {Eurospeech},
  Year                     = {2001},

  Comment                  = {ReadNo},
  Review                   = {starting point of ICA (more sparse than eigen) speaker ID features?},
  Url                      = {http://speech.ee.ntu.edu.tw/paper/eigenmllr_spid_eurospeech01%20(conference%20version)%20Nick.pdf}
}

@InProceedings{wang01basisPursuit,
  Title                    = {Basis Pursuit for Tracking},
  Author                   = {Roy Wang and Yunqiang Chen and Thomas Huang},
  Booktitle                = {Image Processing, {IEEE} Conf. on},
  Year                     = {2001},

  Comment                  = {ReadNo},
  File                     = {wang01basisPursuit.pdf:wang01basisPursuit.pdf:PDF},
  Url                      = {http://www.ifp.uiuc.edu/~chenyq/research/publications/ICIP01_BasisPursuit.pdf}
}

@InProceedings{ward99gridBF,
  Title                    = {Grid-based beamformer design for room-environment microphone arrays},
  Author                   = {D. B. Ward and M. S. Brandstein},
  Booktitle                = {Proc. {IEEE} Workshop on Applications of Signal Processing to audio and acoustics},
  Year                     = {1999},
  Pages                    = {23-26},

  Comment                  = {263: ReadYes},
  Review                   = {How to optimally sum overa microphone array 
* 'optimum' is SNR (other criteria maybe better PFSDM, LAR?) 
* assumes that you know aprior where to focus and where to null (proposes use of prior localization algs) 
* ignores mic. directivity and speech radiation pattern 
* seems also to ignore reverb (free space propagation?) 
* see als [brandstein and ward 2000]}
}

@InProceedings{ward02particleBeamForm,
  Title                    = {Particle filter beamforming for acoustic source localization in a reverberant environment},
  Author                   = {D. B. Ward and R. C. Williamson},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},
  Pages                    = {1777-1780},
  Volume                   = {2},

  Comment                  = {591: ReadYes},
  Review                   = {Maximize power of delay-and-sum beamformer w/ a particle filter
* sort of a particle HMM
* "probability" of particle (which has some angle) <--> steered power
* receive power is cubed to sharpen peaks (could do for Rxy too?)
* source location/velocity is the discrete particle state
* reference for transition probability between particle states but it's in cartesian space source position. Hard to use when unknown mic positions but adaptable? (ref [1])},
  Url                      = {http://ieeexplore.ieee.org/iel5/7874/21692/01006108.pdf?tp=&arnumber=1006108&isnumber=21692}
}

@InProceedings{Warsitz05filtSumBFpca,
  Title                    = {Acoustic filter-and-sum beamforming by adaptive principal component analysis},
  Author                   = {Warsitz, E. and Reinhold Haeb-Umbach},
  Booktitle                = {ICASSP},
  Year                     = {2005},
  Pages                    = {797-800},
  Volume                   = {4},

  Comment                  = {647:ReadNo},
  File                     = {Warsitz05filtSumBFpca.pdf:Warsitz05filtSumBFpca.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Max power beamforming in each FFT bin. Also has adaptive algorithm
* shows that max power BF can be done in each FFT bin
* related to Oja-rule for adaptive PCA (found in neural net literature)
* adaptive BF coeffs: is only 64 taps long (8ms), w/ 10cm mic spacing (0.2ms) so filter is 40X longer than max delay diff!
* adaptive algorithm convergence not clear, but maybe 50 samples @ 8KHz = 6ms (fig 3)?? Not possible, I think.},
  Timestamp                = {2007.08.03},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1416129}
}

@Misc{WarsitzPartFiltAdaptBF,
  Title                    = {Adaptive Beamforming Combined with Particle Filtering for Acoustic Source},

  Author                   = {Localization Ernst Warsitz},

  Comment                  = {648:ReadNo},
  File                     = {WarsitzPartFiltAdaptBF.pdf:WarsitzPartFiltAdaptBF.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Particle filtering dynamics, but still does some kind of adaptive beamforming, didn't quite understand
* particle filtering handles speaker movement dynamics in cartesian coordiante space (I can't do)
* uses freq domain eigen solution of Warsitz05filtSumBFpca to tune BF coeffs
* I don't understand when they apply the BF coeffs, though},
  Timestamp                = {2007.08.03},
  Url                      = {citeseer.ist.psu.edu/722784.html}
}

@Article{wasserman00bayesModSelAvg,
  Title                    = {{Bayesian} model selection and model averaging},
  Author                   = {L. Wasserman},
  Journal                  = {Journal of mathematical psychology},
  Year                     = {2000},
  Pages                    = {92-107},
  Volume                   = {44},

  Comment                  = {22.5: ReadNo}
}

@Article{wax85sigDetInfo,
  Title                    = {Detection of signals by information theoretic criteria},
  Author                   = {Wax, M.; Kailath, T.},
  Journal                  = {Acoustics, Speech, and Signal Processing [see also IEEE Transactions on Signal Processing], IEEE Transactions on},
  Year                     = {Apr 1985},
  Number                   = {2},
  Pages                    = { 387-392},
  Volume                   = {33},

  Abstract                 = { A new approach is presented to the problem of detecting the number of signals in a multichannel time-series, based on the application of the information theoretic criteria for model selection introduced by Akaike (AIC) and by Schwartz and Rissanen (MDL). Unlike the conventional hypothesis testing based approach, the new approach does not requite any subjective threshold settings; the number of signals is obtained merely by minimizing the AIC or the MDL criteria. Simulation results that illustrate the performance of the new method for the detection of the number of signals received by a sensor array are presented.},
  File                     = {wax85sigDetInfo.pdf:wax85sigDetInfo.pdf:PDF},
  ISSN                     = {0096-3518 },
  Review                   = {derives degrees freedom for MDL and AIC PCA dimension picking}
}

@Article{frederick99:_speak_recog_singl_multis_data,
  Title                    = {Speaker Recognition on Single- and Multispeaker Data},
  Author                   = {F. Weber and B. Peskin and M. Newman and A. Corrada-Emmanuel and L. Gillic},
  Journal                  = {Digital Signal Processing: A Review Journal},
  Year                     = {1999},
  Number                   = {1/2/3},
  Pages                    = {75-92},
  Volume                   = {10},

  Comment                  = {127: ReadNo},
  Review                   = {(but should!)}
}

@InProceedings{wegmann97dragon,
  Title                    = {Dragon Systems' 1997 Broadcast News Transcription System},
  Author                   = {S. Wegmann},
  Booktitle                = {DARPA Broadcast News Workshop},
  Year                     = {1998},

  Comment                  = {147: ReadYes},
  Review                   = {Broadcast News clust. silence/word breaks, KL dist clustering
* KL clustering distance metric w/ penalty for time distance
* criterion is KL dist before and after merge
* adaptation: channel, Vocal Tract norm, and spkr adaptation}
}

@InProceedings{wegmann98dragon,
  Title                    = {Dragon Systems' 1998 Broadcast News Transcription System},
  Author                   = {S. Wegmann and P. Zhan and I. Carp and M. Newman and J. Yamron and L. Gillick},
  Booktitle                = {DARPA Broadcast News Workshop},
  Year                     = {1999},

  Comment                  = {145: ReadYes},
  Review                   = {Broadcast News clust. separate gender clustering, mix results of 2 segs
* features pre-transformed to look more like diag matrix
* separate gender clustering
* criterion is KL dist before and after merge
* adaptation: channel, Vocal Tract norm, and spkr adaptation
* combined results of sytems built on two different segmentation systems}
}

@Misc{weissXXeigenseg,
  Title                    = {Segmentation using eigenvectors: A unifying view},

  Author                   = {Y. Weiss},

  Comment                  = {230: ReadYes},
  Review                   = {Segmentation based on eigen vectors of 'affinity matrix' 
* distance is Euclidean -- could replace w/ Mahalonibus or something more appropriate e.g symm. K-L dist 
* tricks w/ normalization and matrix ordering make it work better

* try these techniques on eigen speaker and eigen direction concepts (maybe) 
* rigid body movement segmentaion would also work for pitch tracking in multiple speakers (peaks move 'rigidly' as function of F0) 
* how make it really rigid 
* also says that non-eigen decomp. might work better (look up [4] and [5]) 
* is this the same as spectral clustering paper??}
}

@Misc{weiss96motionseg,
  Title                    = {A unified mixture framework for motion segmentation: incorporating spatial coherence and estimating the number of models},

  Author                   = {Y. Weiss and E. H. Adelson},

  Comment                  = {35.0: ReadNo},
  Review                   = {relevant to speaker motion or associating location features with speaker id features? Also does number of model selection (BIC replacement?)}
}

@Misc{welch95kalman,
  Title                    = {An introduction to the {Kalman} filter},

  Author                   = {G. Welch and G. Bishop},

  Comment                  = {44.0: ReadNo},
  Review                   = {Kalman filter intro relevant to speaker motion tracking or pitch tracking?}
}

@Misc{wennerstrom01intone,
  Title                    = {Keeping the floor: intonation, syntax, and pause},

  Author                   = {A. Wennerstrom and A. F. Siegel},

  Comment                  = {31.0: ReadNo},
  Review                   = {Prosody, I think. friend of leslie}
}

@Article{Weston05SemiSupClustKernel,
  author    = {Jason Weston and Christina Leslie and Eugene Ie and Dengyong Zhou and Andre Elisseeff and William Stafford Noble},
  title     = {Semi-supervised protein classification using cluster kernels},
  journal   = {Bioinformatics},
  year      = {2005},
  volume    = {21},
  number    = {15},
  pages     = {3241-3247},
  file      = {Weston05SemiSupClustKernel.pdf:Weston05SemiSupClustKernel.pdf:PDF},
  groups    = {semisupWorkshop07},
  owner     = {scotto},
  review    = {Kernel learning paper for 2007 Summer Blind/Deaf workshop

Matlab is here:
http://www.kyb.tuebingen.mpg.de/bs/people/weston/semiprot/supp.html

Extended version is here:
http://www.kyb.tuebingen.mpg.de/bs/people/weston/semiprot/semiprot-extended.ps},
  timestamp = {2007.06.20},
  url       = {http://bioinformatics.oxfordjournals.org/cgi/content/full/21/15/3241},
}

@Misc{westonXXsvmFeature,
  Title                    = {Feature selection for {SVM}s},

  Author                   = {J. Weston and S. Mukherjee and O. Chapelle and M. Pontil and T. Poggio and V. Vapnik},
  Year                     = {2001},

  Comment                  = {86: ReadNo},
  Review                   = {Feature selection for images and DNA
* leave-one-out approach w/ gradient descent}
}

@MastersThesis{westwood99eigenadapt,
  Title                    = {Speaker adaptation using eigenvoices},
  Author                   = {R. Westwood},
  School                   = {wolfson college},
  Year                     = {1999},

  Comment                  = {20.5: ReadNo}
}

@InProceedings{wilcox94spkrIDseg,
  Title                    = {Segmentation of Speech Using Speaker Identification},
  Author                   = {Lynn Wilcox and Francine Chen and Don Kimber and Vijay Balasubramanian},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1994},
  Pages                    = {161-164},
  Volume                   = {51},

  Comment                  = {418: ReadNo},
  Review                   = {The authors describe a system that performs audio segmentation based on speaker identity. The system builds a Markov model network, where each state is a speaker model, to detect which speaker is speaking in the conversation. They also present two unsupervised techniques for obtaining initial data for the speakers when no training data is available for the speakers. 
on ref page: http://www.ece.ogi.edu/~adami/references.htm},
  Url                      = {http://ieeexplore.ieee.org/iel2/3104/8833/00389330.pdf?isNumber=8833&prod=IEEE+CNF&arnumber=389330&arSt=I%2F161&ared=I%2F164+vol.1&arAuthor=Wilcox%2C+L.%3B+Chen%2C+F.%3B+Kimber%2C+D.%3B+Balasubramanian%2C+V.%3B}
}

@Article{Williams02kpcaAndMMDS,
  Title                    = {On a Connection between Kernel PCA and Metric Multidimensional Scaling},
  Author                   = {Christopher K.I. Williams},
  Journal                  = {Machine Learning},
  Year                     = {2002},
  Number                   = {1-3},
  Pages                    = {11-19},
  Volume                   = {46},

  File                     = {Williams02kpcaAndMMDS.pdf:Williams02kpcaAndMMDS.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Kernel PCA ~ metric multidimensional scaling, good general MDS, KPCA kernel, centering advice/info

Classical MDS:
* given a set of inter-object distances (or dissimilarities), arrange the objects in k-dim space such that the distances are preserved with minimal error (city map, given intercity distances is an example)
* for Euclidean distances classical MDS is the linear transform that best mimizes the summed squared distance error once the objectes are projected onto k-dims
* distance error after projection is related to sum of eigenvalues not used in the projection (but, for nonlinear kernels, you can't directly use this sum to figure out best projection (get trivial solutions, authors didn't find a good approach
* MDS can recover locations accurately, up to a a translation, rotation and reflection (since these don't affect inter-object distance)
* good description of how to center with matrix equs. I think this is frequently used in other KPCA papers
* Non-euclidean dissimilarity: MDS might give you negative eigenvalues (we will see that KPCA with pos. def. kernels (usually the case) guarantees positive eigenvalues (sec 4.1))

PCA vs. classical MDS
* PCA of distance matrix is the same thing as MDS, up to a scale by the number of objects.

Metric MDS
* metric MDS: minimize difference between projected coordinates and some analytic function of the dissimilarity (minimized cost function is called "stress")
* sometimes can do by weighted LS regression, but usually done by optimization

Non metric MDS (NMDS)
* interesting, come up with orientation based on pairwise _rankings_

Kernel PCA and MDS
* KPCA feature space features are exactly the same as doing classical MDS in feature space
* isotropic kernels (depend only upon distance): Kernel MDS is an example of metric MDS 
* Gaussian and RBF kernels are isotropic; polynomial isn't
* for pos def kernels, guaranteed pos eigenvalues (not guaranteed for metric MDS in general)
* pos def kernels, guaranteed pos eigenvalues (not guaranteed for metric MDS in general)
* KPCA has pre-computed the transform, so don't need to optimized again for a new point (unlike standard metric MDS)
* answer is unique, up to a translation, rotation and reflection (not true in general for metric MDS optimization, I think)
* non-stationary kernels: 
 -- has a relationship for polynomial kernel degree 2, but not for others
 -- similarity in feature space is a nonlinear function of input space similarity (apparently not true fo isotropic kernels but I don't quite undersand why)

Picking the kernel
* can't just look at eigenvalue sums
* no good advice},
  Timestamp                = {2007.08.18},
  Url                      = {http://www.springerlink.com.offcampus.lib.washington.edu/content/q3046748t0pw27m5/?p=51c3beb092dc478f80764590d44a568a&pi=0}
}

@InProceedings{williams99spchMusic,
  Title                    = {Speech/Music Discrimination Based On Posterior Probability Features},
  Author                   = {Gethin Williams and Daniel P.W. Ellis},
  Booktitle                = {Eurospeech },
  Year                     = {1999},

  Comment                  = {381: ReadYes},
  File                     = {williams99spchMusic.pdf:williams99spchMusic.pdf:PDF},
  Review                   = {Phone model posteriors are speech/music ID features, known segmentation
* 54 NN phone models trained on Broadcast News (see Berenzweig&Ellis)
* Phone Model posteriors crunched to features
- mean per-frame entropy (pdf peaky if matches speech)
- dynamism: how fast pdf changes (music stays stuck)
- background label: poor matching high energy frames tend to be music
- phone distrib match: Mahanonibus match of test posteriors 
w/ avg speech posterior (fails for short segs (2.5 v.s. 15secs)
* features combined w/ full covariance 1-mixture Gaussian
* Tested on radio speech/music from Scheirer & Slaney `96
- 15 second test segments: 0% error
- 2.5 second test segments: 1.3% error (same as Scheirer & Slaney)
* main use is to exclude music from a speech recognizer
* advocates picking speech/music thresh to point where all speech segs are passed to decoder and no music segs are.
* says future work will pick segment boundaries (was this Berenzweig & Ellis, "locating singing..."?},
  Url                      = {http://www.icsi.berkeley.edu/ftp/global/pub/speech/papers/euro99-mussp.pdf}
}

@InProceedings{winter04clusterBSS,
  Title                    = {Hierarchical clustering applied to overcomplete {BSS} for convolutive mixtures},
  Author                   = {Stefan Winter and Hiroshi Sawada and Shoko Araki and Shoji Makino},
  Booktitle                = {Workshop on Statistcal and Perceptual Audio Processing},
  Year                     = {2004},

  Comment                  = {ReadNo},
  Review                   = {Uses agglomerative clustering to do BSS, seem to start out by just clustering FFT bins?? The do DOA??},
  Url                      = {http://scholar.google.com/url?sa=U&q=http://www.lnt.de/lms/publications/web/lnt2004_34.pdf}
}

@InProceedings{Wokurek00spchSegEnt,
  Title                    = {{CORPUS} {BASED} {EVALUATION} {OF} {ENTROPY} {RATE} {SPEECH} {SEGMENTATION}},
  Author                   = {Wolfgang Wokurek},
  Booktitle                = {Proc., Intrn'l Conf. Phonetic Sciences, {ICPhS}},
  Year                     = {1999},

  Comment                  = {420: ReadYes},
  File                     = {Wokurek00spchSegEnt.pdf:Wokurek00spchSegEnt.pdf:PDF},
  Review                   = {Phone segmentation based on spectral entropy, not really tested at all
* entropy rate calculated across freq on one spectral estimate
- spectral estimate is Welch, averaged over several FFT's
- assumes normality in entropy eq., not sure why need to
* entropy rate is deviation from white noise
- so this will probably fail in nonwhite noise
* entropy rate is ~ same mag for vowels/fricatives (better than energy)
* phoneme change points appear near changes in entropy (changes in
stationarity)
* heuristic rules about generate labels
* evaluation is not clear at all, },
  Url                      = {http://elib.uni-stuttgart.de/opus/volltexte/2000/582/pdf/icphs99_ps.pdf}
}

@Article{Wold78pcaNcompCrossValRratio,
  Title                    = {Cross validatory estimation of the number of
components in factor and principal components analysis},
  Author                   = {Wold, S.},
  Journal                  = {Technometrics},
  Year                     = {1978},
  Pages                    = {397-406},
  Volume                   = {20},

  Owner                    = {scotto},
  Review                   = {Estimating PCA dimension by cross validation and reconstruction. 

- assumption is that you have enough PC's when reconstruction of missing values stops improving.
- Randomly delete groups of inputs and reconstruct. using missing value technique (NIPALS)
- stop adding PCA comps when ratio of reconstruction error to error present with no missing inputs stops improving
- referenced in Valle99pcaNcompsRecons (which shows that using PRESS is better/cheaper, as is VRE)},
  Timestamp                = {2008.01.29}
}

@Article{Wold87pcaNIPALS,
  Title                    = {Principal Component Analyis},
  Author                   = {Wold, S. and Esbensen, K. and Geladi, P.},
  Journal                  = {Chemom. Intell. Lab. Syst.},
  Year                     = {1987},
  Pages                    = {37-52},
  Volume                   = {2},

  Owner                    = {scotto},
  Review                   = {Primary reference for the NIPALS method of estimating PCA missing values},
  Timestamp                = {2008.01.29}
}

@Article{Wolf05CombineVarSelDimReduce,
  Title                    = {Combining variable selection with dimensionality reduction},
  Author                   = {Wolf, L.; Bileschi, S.},
  Journal                  = {Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on},
  Year                     = {20-25 June 2005},
  Pages                    = { 801-806 vol. 2},
  Volume                   = {2},

  Abstract                 = { This paper bridges the gap between variable selection methods (e.g., Pearson coefficients, KS test) and dimensionality reduction algorithms (e.g., PCA, LDA). Variable selection algorithms encounter difficulties dealing with highly correlated data, since many features are similar in quality. Dimensionality reduction algorithms tend to combine all variables and cannot select a subset of significant variables. Our approach combines both methodologies by applying variable selection followed by dimensionality reduction. This combination makes sense only when using the same utility function in both stages, which we do. The resulting algorithm benefits from complex features as variable selection algorithms do, and at the same time enjoys the benefits of dimensionality reduction.},
  Doi                      = {10.1109/CVPR.2005.103},
  File                     = {:Wolf05CombineVarSelDimReduce.pdf:PDF},
  ISSN                     = {1063-6919 },
  Keywords                 = { feature extraction, learning (artificial intelligence), statistical analysis, support vector machines KS test, LDA, PCA, Pearson coefficients, SVM, correlated data, dimensionality reduction algorithm, feature selection, utility function, variable selection algorithms},
  Owner                    = {scotto},
  Timestamp                = {2008.01.22},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=1467525&isnumber=31473&punumber=9901&k2dockey=1467525@ieeecnfs&query=%28%28combining+variable+selection+with+dimensionality+reduction%29%3Cin%3Emetadata%29&pos=0}
}

@TechReport{Wong05WeakProsody,
  Title                    = {Using Weakly Supervised Learning to Improve Prosody Labeling},
  Author                   = {Darby Wong and Mari Ostendorf and Jeremy Kahn},
  Institution              = {University of Washington},
  Year                     = {2005},
  Number                   = {UWEETR-2005-0003},
  Type                     = {Tech Report},

  File                     = {Wong05WeakProsody.pdf:Wong05WeakProsody.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {The weakly supervised breaklabel prediction pilot study. Don't trust it!},
  Timestamp                = {2006.04.04},
  Url                      = {https://www.ee.washington.edu/techsite/papers/refer/UWEETR-2005-0003.html}
}

@InProceedings{woodland_icassp98,
  Title                    = {Experiments in Broadcast News Transcription},
  Author                   = {P. C. Woodland and T. Hain and S. E. Johnson and T. R. Niesler and A.Tuerk and S. J. Young},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1998},
  Pages                    = {909--912},
  Volume                   = {II},

  Comment                  = {146: ReadYes},
  Review                   = {Broadcast News seg/clust: sil breaks w/ top-down split cov. clust
* removes simultaneous talking segments
* 1024 GMM for broad audio class
* broad classifier allows separate clustering for different audio types
* messy heuristics for pre-cluster segment merging
* MLLR adapatation on clustered data},
  Url                      = {citeseer.nj.nec.com/27918.html}
}

@Article{wooters04spkrDiariz,
  Title                    = {Towards robust speaker segmentation: the {ICSI-SRI} fall 2004 diarization system},
  Author                   = {Chuck Wooters and James Fung and Barbara Peskin and Xavier Anguera},
  Journal                  = {RT-04 Workshop, EARS PI Meeting},
  Year                     = {2004},
  Pages                    = {paper 45},

  Review                   = {HMM clustering for BN. Use Ajmera algorithm w/ a few changes
- MFCC 19 coeffs better than PLP12
- MFCC's better than PLP's (contradicts Tranter but she had different other details)
- added VAD (gets 80% improvement available from forced alignments)
- iterative HMM/viterbi loop added
- new Viterbi stopping instead of old sorta-BIC}
}

@InProceedings{Wooters07SpkrDiariz,
  author    = {Chuck Wooters and Marijn Huijbregts},
  title     = {The {ICSI RT07s} Speaker Diarization System},
  booktitle = {{NIST RT07} Workshop},
  year      = {2007},
  file      = {Wooters07SpkrDiariz.pdf:Wooters07SpkrDiariz.pdf:PDF},
  groups    = {ovdetasru07},
  owner     = {scotto},
  review    = {ISCI RT07 diarization system
rresults w/ overlaps scored, not scored. Don't seem to detect},
  timestamp = {2007.07.16},
}

@InProceedings{wrigley03closeMicCrossVAD,
  Title                    = {Feature Selection for the Classification of Crosstalk in Multi-Channel Audio},
  Author                   = {Stuart N. Wrigley and Guy J. Brown and Vincent Wan and Steve Renals},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {469-479},

  Comment                  = {458: ReadNo},
  Review                   = {VAD for closetalking microphone meeting, ID's other-talker speech, mentions SAPVR and so on}
}

@Article{wrigley05crosstalk,
  Title                    = {Speech and crosstalk detection in multi-channel audio},
  Author                   = {Stuart N. Wrigley and Guy J. Brown and Vincent Wan and Steve Renals},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {84-91},
  Volume                   = {13},

  Comment                  = {596:ReadYes},
  File                     = {wrigley05crosstalk.pdf:wrigley05crosstalk.pdf:PDF},
  Review                   = {HMM/GMM headmic meeting VAD w/ xcorr feats & others (ICSI test)
* 4 pre-trained per-chan GMM's: sil, spch, crosstalk, overlap
* HMM w/ separately trained trans probs, cross-chan combo state
* cross-corr energy features were good
* apparently fixed number of mics, same in test and train
* good VAD/crosstalk, probs w/ overlap/sil
FEATURE SELECTION
* possible features were: 
- MFCC, zerof cross, energy
- kurtosis
- fundamentalism
- SAPVR
- pitch prediction (std of pitch peak distance)
- four odd genetically derived features (none selected)
- cross-chan cross-corr's (value, not lag), these were best!
-- XC on very short segs (16ms) but OK since lags not stored?
-- feature then just "coherence" not (aliased) time delay
* different features for each GMM
* greedy, add one at a time
* features not selected (<1% EER improvement): 
- MFCC's, SAPVR, zero crossing, pitch prediction
* picked six features
* v. small frame error loss if exclude energy
RESULTS
* tested on ICSI meetings
* GMM only: about 80% frame EER on each of the four classes
* HMM: helped mostly w/ speech-only case, no bulk error rate
* HMM w/ ASR:
- threw away detected overlaps
- HTK recog w/ v. poor perf (45-64% accuracy) 
-- vs. 17.4% WER on similar ICSI w/ RT04S SRI recognizer
- only about 0.5% worse accuracy than forced alignments segs
- feature sel mtng also used in test set?
* said ICSI meetings had varying or low gain
* mentions which ICSI meetings were bad (SO USE!!)},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?tp=&arnumber=1369314}
}

@InProceedings{wu99sdif,
  Title                    = {Simultaneous diagonalization in the frequency domain {SDIF} for sources separation},
  Author                   = {H. Wu and J. C. Principe},
  Booktitle                = {Proc. Intl. Workshop on Independent Component Analysis and Signal Separation},
  Year                     = {1999},

  Comment                  = {28.0: ReadYes},
  Review                   = {Freq domain diagonalizing Blind Source Separation. No permutations.
* no IID assumption like past work so avoid source pdf matching problems
* simultaneous diag: diagonalizing mixing W's simultaneous for each freq
- Anenmueller compared this in his thesis -- his alg was better?
Two diagonalization cost functions
* Frobenius Norm (ref [12]): computationally expensive
* Hadamard inequality: cheaper and perferred.
* says eigen based diag too expensive and has worse permutation probs
* Freq domain FIR converges faster than time domain adaptive [refs 9-11]
* many non-zero elements in filter when separation failed
* Hadamard inequality combined w/ permutation/scaling constraint fixes permutaion and scaling probs simultaneously.
* works on synthetic data
* needs DFT window 10X longer than separating filter

Maybe use for overlap resolution? }
}

@PhdThesis{wu99bssTimeFreqPhD,
  Title                    = {Blind Source Separation using Information Measures in the Time and Frequency Domains},
  Author                   = {H.-C. Wu},
  School                   = {CNEL, University of Florida},
  Year                     = {1999},

  Comment                  = {ReadNo},
  File                     = {wu99bssTimeFreqPhD.pdf:wu99bssTimeFreqPhD.pdf:PDF},
  Review                   = {overlap detection? Uses eigenspread to determine when one source is active (says Erdogmus paper)},
  Url                      = {http://www.cnel.ufl.edu/bib/pdf_dissertation/wu_dissertation.pdf}
}

@InProceedings{wu97bssSimDiag,
  Title                    = {A unifying criterion for blind source separation and decorrelation: Simultaneous diagonalization of correlation matrices},
  Author                   = {H.-C. Wu and J. Principe},
  Booktitle                = {NNSP97},
  Year                     = {1997},
  Pages                    = {496-505},

  Comment                  = {ReadNo},
  Review                   = {solves positive definite problem in molgedey&Shuster and Hansen's diagonalization but it's iterative},
  Url                      = {citeseer.nj.nec.com/wu97unifying.html}
}

@InProceedings{chun98spchTimeFreq,
  Title                    = {Exploring the time-frequency microstructure of speech for blind source separation},
  Author                   = {Hsiao-Chun Wu and Principe, J.C. and Dongxin Xu },
  Booktitle                = {Proc. ICASSP},
  Year                     = {1998},
  Pages                    = {1145-1148},
  Volume                   = {2},

  Comment                  = {281: ReadYes},
  Review                   = {Clusters many sep. coeff ests. (time&freq). Picks ones w/max eigspread.
* eigen filter cancels weaker signal in each band
- not explained at all how to derive eigenfilter, though
* uses PCA to find separation coeffs (or directions of them)
* some kind of competitive learning clustering (known # srcs).
* for each cluster (source), pick the estimate with the largest eigenspread (Fig 2 shows that true coeffs are at the extremes).
* works OK
* only for instantaneous mixing, not convolutive or delayed
* paper is hard to read. Is there a better one?
* maybe useful for histo number-of-sources or overlap detection alg.},
  Url                      = {http://ieeexplore.ieee.org/iel4/5518/14874/00675472.pdf?isNumber=14874&prod=CNF&arnumber=675472&arSt=1145&ared=1148+vol.2&arAuthor=Hsiao-Chun+Wu%3B+Principe%2C+J.C.%3B+Dongxin+Xu}
}

@Article{wu98genGaussMinEnt,
  Title                    = {Minimum entropy^^ algorithms for source separation},
  Author                   = {Hsiao-Chun Wu and Jose C. Principe},
  Journal                  = {IEEE Intl. Symposium on Circuits and Systems},
  Year                     = {1998},
  Pages                    = {242-245},

  Comment                  = {ReadNo},
  File                     = {wu98genGaussMinEnt.pdf:wu98genGaussMinEnt.pdf:PDF},
  Review                   = {Has some generalized gaussian stuff},
  Url                      = {http://www.cnel.ufl.edu/bib/pdf_papers/wu98mwscas.pdf}
}

@InProceedings{wu02multipitch,
  Title                    = {A Multi-pitch tracking algorithm for noisy speech},
  Author                   = {Mingyang Wu and DeLiang Wang},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},
  Pages                    = {369-372},
  Volume                   = {1},

  Comment                  = {339: ReadYes},
  Review                   = {Filterbank pitch detector w/ statistical observation & HMM
* significantly better than Tolonen and Karjalainen (most similar alg.)
* many heuristics but some statistical modelling and training
* tech report (wu01multipitchTR)is more detailed: I'll put my comments there.}
}

@Article{wu03multipitch,
  Title                    = {A Multipitch Tracking Algorithm for Noisy Speech},
  Author                   = {Mingyang Wu and DeLiang Wang and Guy J. Brown},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2003},
  Number                   = {3},
  Pages                    = {229-241},
  Volume                   = {11},

  Comment                  = {ReadNo},
  File                     = {wu03multipitch.pdf:wu03multipitch.pdf:PDF},
  Review                   = {filterbank pitch det w/ multitalker detection 
semi-heuristic band-dependent, Laplacian-like distribution of band autocorr
lags: distribution is used to classify if one or more voices.

There's also a 2002 ICASSP paper and a tech note by this author

I've read them but have only scanned this paper. Maybe it's got signficant updates?},
  Url                      = {http://www.dcs.shef.ac.uk/~guy/pdf/wu-icassp2002.pdf}
}

@TechReport{wu01multipitchTR,
  Title                    = {A multipitch tracking algorithm for noisy speech},
  Author                   = {Mingyang Wu and DeLiang Wang and Guy J. Brown},
  Institution              = {Dept. of Comput and Info. Sci., Ohio State University},
  Year                     = {2001},
  Number                   = {OSU-CISRC-12/01-TR25},

  Comment                  = {4.0: ReadYes},
  Review                   = {Auditory multi-pitch det w/ semi-heuristic statistical model. Works.
* their 2002 paper compares against Tolonen and Kajar... This is better.
* Comments below are for 2002 paper; this tech note has some differences e.g. here don't compare Rxx at different window widths.
Four stages (2002 paper):
1.) normalized Rxx (eq 1) of 128 gamatone outputs: 
* low freqs (<800Hz): Rxx directly on low freq outputs
* high freq: Rxx on envelopes (half rect/BPF)
2.) Peak selection: detect peaks, then remove the bad ones
* low freq: remove low mag peaks (fixed thresh)
* high freqs: 
- a.) must have harmonic peak at 2*tau
- b.) remove root tone (beats): 1st peak not too much bigger than max peak
3.) Summarize peaks across frequencies
* don't just add like most do
* build heuristic "probability" of peak set supporting (0,1,2) pitches
* model based on trained Laplace distributions w/ some heuristics
4.) HMM pitch tracking
* 3 HMM states (0,1,2) pitches
* observation probs are p(heuristic peak probs | state)
* does not include pitches themselves
* wouldn't pitch values themselves also be good to know?
* e.g. to enforce pitch dynamics?
* Viterbi decoding

2003 IEEE trans paper here: http://www.cse.ohio-state.edu/~mwu/Public/TSAP2003.pdf

Results:
* they were much better than Tolonen and Karjalainen e.g. 7% gross error v.s. 28% for T&K
Also see 2003 paper}
}

@InProceedings{wu03spkrSegUBM,
  Title                    = {{UBM}-based Real-time Speaker Segmentation for Broadcasting News},
  Author                   = {TingYao Wu and Lie Lu and Hong-Jiang Zhang},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2003},

  Comment                  = {ReadNo},
  Review                   = {not available yet},
  Url                      = {http://research.microsoft.com/users/llu/publications.aspx}
}

@InProceedings{wu03spkrChngUBMrealt,
  Title                    = {{UNIVERSAL} {BACKGROUND} {MODELS} {FOR} {REAL}-{TIME} {SPEAKER} {CHANGE} {DETECTION}},
  Author                   = {Ting-Yao WU and Lie LU and Ke CHEN and Hong-Jiang ZHANG},
  Booktitle                = {Intl. Conf., Multi-Media Modeling},
  Year                     = {2003},
  Pages                    = {135-149},

  Comment                  = {425: ReadNo},
  Url                      = {http://research.microsoft.com/users/llu/Publications/MMM03_UBMforSpkSeg.PDF}
}

@Article{wu98neuralHRTF,
  Title                    = {Neural network model of binaural hearing based on spatial feature extraction of the head related transfer function},
  Author                   = {Z. Wu and T. Weng and W. Wang},
  Journal                  = {Proc. {IEEE} Eng. in Med. and Bio. Soc.},
  Year                     = {1998},
  Number                   = {3},
  Pages                    = {1109-1112},
  Volume                   = {20},

  Comment                  = {224: ReadYes},
  Review                   = {Fit NN to spatial impulses 
* preprocess before NN trainnig w/ a wavelet denoiser w/ singularity detection}
}

@InProceedings{xiang02sgmmSpkrVer,
  Title                    = {Structural Gaussian Mixture Models for Efficient Text-Independent Speaker Verication},
  Author                   = {Bing Xiang and Toby Berger},
  Booktitle                = {Proc. ICSLP},
  Year                     = {2002},
  Pages                    = {1317-1320},

  Comment                  = {ReadNo},
  Url                      = {/g/ssli/html/proceedings/icslp02/ICSLP/PDF/INDEXSCR.PDF}
}

@InProceedings{yamajo03simoConvICA,
  Title                    = {Blind Separation and Deconvolution for Convolutive Mixture of Speech Using {SIMO}-Model-Based {ICA} and Multichannel Inverse Filtering},
  Author                   = {Hiroaki Yamajo and Hiroshi Saruwatari and Tomoya Takatani and Tsuyoki Nishikawa and Kiyohiro Shikano},
  Booktitle                = {Eurospeech},
  Year                     = {2003},
  Pages                    = {537-540},

  Comment                  = {563: ReadNo},
  Review                   = {monaural ICA based on models!!! can be correlated, mixing can be conv!!!}
}

@Article{yang97blindSepmaxEntAndMinMI,
  Title                    = {Adaptive online learning algorithms for blind separation: maximum entropy and minimum mutual information},
  Author                   = {Howard Hua Yang and Shun-ichi Amari},
  Journal                  = {Neural Computation},
  Year                     = {1997},
  Number                   = {7},
  Pages                    = {1457--1482},
  Volume                   = {9},

  Address                  = {Cambridge, MA, USA},
  Doi                      = {http://dx.doi.org/10.1162/neco.1997.9.7.1457},
  ISSN                     = {0899-7667},
  Publisher                = {MIT Press}
}

@InProceedings{yanguas99glottalID,
  Title                    = {Implications of glottal source for speaker and dialect identification},
  Author                   = {L. R. Yanguas and T. F. Quatieri},
  Booktitle                = {Proc. ICASSP},
  Year                     = {1999},
  Pages                    = {813-816},
  Volume                   = {2},

  Comment                  = {140: ReadYes},
  Review                   = {Glottal pulses seem to contain speaker ID info, at least for humans
* swapping glottal pulses between soutern and norhtern speakers makes them sound more southern or northern.
* uses complicated glottal derivative estimator}
}

@TechReport{yantorno01fusion,
  Title                    = {Fusion - The next step in usable speech detection},
  Author                   = {Robert E. Yantorno},
  Institution              = {Research Laboratory AFRL/IF and Speech Processing Lab Rome Labs Rome, NY},
  Year                     = {2001},

  Comment                  = {ReadNo}
}

@TechReport{yantorno00cochanSAPVR,
  Title                    = {A study of the spectral autocorrelation peak valley ratio {(SAPVR)} as a method for identification of usable speech nad detection of co-channel speech},
  Author                   = {Robert E. Yantorno},
  Institution              = {Research Laboratory AFRL/IF and Speech Processing Lab Rome Labs Rome, NY},
  Year                     = {2000},

  Comment                  = {287: ReadYes},
  Review                   = {SAPVR heuristics explained, use of SFM, "usable" v.s. "cochannel" detect
* Best metod is V11 on p. 12 (modified method 5 on p. 4)
-- usable: (20dB TIR), works best on femals
-- cochannel: (opposite of usable, ill-defined), works best on males
* SAPVR improvement (not done): pick 1st =big= peak, not 1st peak.
* spectral flatness measure (SFM) explained, picks where SAPVR can work.
* SFM good for picking voiced or not voiced, even in cochannel speech (really?)
* claim: SAPVR better at co-chan detection than "traditional" approaches (undefined) even when pitches are very close.}
}

@TechReport{yantorno99cochan,
  Title                    = {Co-channel speech study},
  Author                   = {Robert E. Yantorno},
  Institution              = {Research Laboratory AFRL/IF and Speech Processing Lab Rome Labs Rome, NY},
  Year                     = {1999},

  Comment                  = {288: ReadYes},
  Review                   = {Usable speech detection w/ LPC and LPcep; voiced/nonvoiced w/ SFM
* good definition of LPC "residual"
* pitch halving and doubling algorithm (histo, sort of clustering)
Silence detection (VAD)
* T-netix based on energy histogram
* doesn't work as well as log-energy histogram (both are lame)
Voiced/non-voice detection
* recommend spectral flatness (SFM) -- has the definition of SFM
* I think this will fail in harmonic noise
* notes for ideas for F[F[X^2]] clustering for multi-pitch detection

(combined w/ multi-chan xcorr, p. 9 and 13)
Usable Speech Detection
* LPC residual better than LPcep
* funny that LPcep actually removed the pitch part (and they were trying 
to detect pitch!)
* does worse for females
* says fused LPC and LPcep would work better than either alone}
}

@TechReport{yantorno98cochan,
  Title                    = {Co-channel speech and speaker identification study},
  Author                   = {Robert E. Yantorno},
  Institution              = {Speech Processing Lab, Rome Labs, NY},
  Year                     = {1998},

  Comment                  = {289: ReadYes},
  Review                   = {Prelim. study: SpkrID v.s. cochannel and noise, speaker separation
* 1st study I could find in series leading to SAPVR, etc.
Cochannel SpeakerID
* noise at 0dB worse for spkr ID than 2nd talker at 0dB 
-- noise would be on every frame but would have chunks of clean speech
-- 40% 0dB speech => 15% loss in %correct
-- experiment done on open set spkrID, LPC coeff features
* Talker-to-Interferer-Ratio (TIR) of 20dB => 20% loss in %correct
-- justification seems to be from experiments w/ chunks of 0dB noise
-- BUT (I say): noise isn't like speech
-- 20dB must be some kind of instantaneous measure but it's not clear
-- overall, the TIR must be 0dB but that's not clear either
* Finding multitalker speech w/ Harmonic sampling 
-- plots and handwaving say harmonic peak picking can find multi-talker
-- comb filter not really needed: can just find peaks
-- good details on peak picking algorithm (1Hz final FFT bin res.!)
-- magnitude spectrum better than log mag or pwr. for peak picking
-- wouldn't a polyfit peak picker work as well as massive zeropad FFT? 
-- good details on harmonic sampling reconstruction algorithm
-- multi-talker pitch refs: Doval & Rodet, Dorken & Nawab
* Speculation on speaker separation w/ a bunch of refs.}
}

@InProceedings{yantorno01usable,
  Title                    = {The Spectral Autocorrelation Peak Valley Ratio {(SAPVR)} - A Usable Speech Measure Employed as a Co-channel Detection System},
  Author                   = {R. E. Yantorno and K. R. Krishnamachari and D. S. Benincasa and J. M. Lovekin and S. J. Wenndt},
  Booktitle                = {IEEE Intl. Workshop on Intelligent Signal Processing},
  Year                     = {2001},

  Comment                  = {106: ReadYes},
  Review                   = {Spectral flatness (SFM) for voiced detection explained
* SAPVR detects usable multitalker speech (see [1]}
}

@Article{yantorno00cochaneff,
  Title                    = {Effects of co-channel speech on speaker identification},
  Author                   = {Robert E. Yantornoa and Daniel S. Benincasab and Stanley J. Wenndtb},
  Journal                  = {SPIE Intl. Symposium on Technologies for Law Enforcement},
  Year                     = {2000},

  Comment                  = {292: ReadYes},
  Review                   = {How co-channel speech screws up LPC speaker ID system
* 40% overlap with TIR=0dB (both terms ill-defined) => 15% less % correct 
* male speaker ID hurt more by overlap than female
* overlap hurts less when interferer contained in the training set.
-- I can't figure out why this would be true
-- The difference is only 5% out of 40%, with 30 speakers; it's noise?}
}

@Article{yao98randBlindBeamForm,
  Title                    = {Blind beamforming on a randomly distributed sensor array system},
  Author                   = {Kung. Yao and R. E. Hudson and C. W. Reed and D. Chen and F. Lorenzelli},
  Journal                  = {Selected Areas in Communications, IEEE Journal on},
  Year                     = {1998},
  Number                   = {8},
  Pages                    = {1555-1567},
  Volume                   = {16},

  Comment                  = {ReadNo},
  File                     = {yao98randBlindBeamForm.pdf:yao98randBlindBeamForm.pdf:PDF},
  Review                   = {Eigen value, Max Rxy energy criteria for localization, seems to handle spatial aliasing},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=730461}
}

@Article{yap98spkrID,
  Title                    = {Speaker Verification Acoustic Parameters},
  Author                   = {W. Yap},
  Journal                  = {\url{http://www.iis.ee.ic.ac.uk/~frank/surp98/article2/wwy2/}},
  Year                     = {1998},

  Comment                  = {195: ReadYes},
  Review                   = {Spkr ID params overview
Segmental info more imp than suprasegmental: 
- hard to extract, hard to model dynamics, variable, under concious ctl.
- BUT (for meeting recoder) concious ctl not a prob: no need to hide
Acoustic Params
- Intensity (average energy over 0-30ms): Info is in the variations
- Pitch: avg or waveshape, robust since not affected by channel
- Formants: freq and BW hard to measure directly
- * LPC vowels: 
- -- formant structure related to vocal tract shape
- -- real axis/wideband poles are from glottal source (why?)
- * LPC nasals:
- -- complicated by zeros
- -- nasal params are among the best but vulnerable to physical changes
- * LPC strident consonants
- -- complicated by zeros too, but LPC is used
- Nasal consonant coarticulation: found to be useful
- spectral correlation across freq bins: need 30s of data
- Timing and Speaking Rate: seems like this would be text-specific},
  Url                      = {http://www.iis.ee.ic.ac.uk/~frank/surp98/article2/wwy2/}
}

@Article{yegnan00reverbLP,
  Title                    = {Enhancement of reverberant speech using {LP} residual signal},
  Author                   = {B. Yegnanarayana and P. Satyanarayana Murthy},
  Journal                  = {{IEEE} Trans., Speech and Audio Proc.},
  Year                     = {2000},
  Number                   = {3},
  Volume                   = {8},

  Comment                  = {268: ReadYes},
  Review                   = {
* LP residual is sort-of copy of glottal pulses 
* if entropy is low => this is not corrupted by reverb => no damp?

* short term (between pulses): spiky prediction error => when prediction error low, damp: this clears gap between pulses 
* filter residual w/ poles w/ time varying time constants to further clear out interpulse gaps 
* note: reverb interpulse fill-in is going to look like multitalker SAPVR fillin! So reverb will screw up that kind of multi-talker detection...}
}

@InProceedings{yli-hietanen99doarobust,
  Title                    = {Time-delay selection for robust angle of arrival estimation},
  Author                   = {JARI YLI-HIETANEN and KONSTA KOPPINEN and JAAKKO ASTOLA},
  Booktitle                = {Intl. Conf. on Signal and Image Processing){IASTED}},
  Year                     = {1999},
  Pages                    = {81-83},

  Comment                  = {613: ReadYes},
  Review                   = {Cross-Correlation Confidence using delay triangles
* Tuomo Pirinen extended this paper by normalizing
* relative delays of microphone triplets should sum to zero
* develops xcorr normalization over (0,1)
* of course, need at least 3 mics
* use for building location models: each xcpair gets a confidence},
  Url                      = {www.cs.tut.fi/sgn/arg/ypsilon/SIP99FINALPAPER.PDF}
}

@Book{young00htk_book,
  Title                    = {The {HTK} Book},
  Author                   = {Steve Young and Dan Kershaw and Julian Odell and Dave Ollason and Valtcho Valtchev and Phil Woodland},
  Publisher                = {Microsoft Corporation},
  Year                     = {2000},

  Review                   = {Documentation for the HTK recognizer}
}

@Article{yousef99wirelessTOA,
  Title                    = {A new adaptive estimation algorithm for wireless locatoin finding systems},
  Author                   = {N. R. Yousef and A. H. Sayed},
  Journal                  = {{IEEE} ?},
  Year                     = {1999},

  Comment                  = {246: ReadNo},
  Review                   = {Cellphone localization w/ sub optimal ML correlation max search. seems to make fewer subspace-type assumptions so might work}
}

@InProceedings{yu03spkrSegHMM,
  Title                    = {{AN} {IMPROVED} {MODEL}-{BASED} {SPEAKER} {SEGMENTATION} {SYSTEM}},
  Author                   = {Peng Yu and Frank Seide and Chengyuan Ma and Eric Chang},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {2025-2028},

  Comment                  = {575: ReadNo},
  Review                   = {another BN style spker segmenter but w/ a level of HMM's}
}

@InProceedings{yu04tdoaLargeArr,
  Title                    = {An Improved {TDOA}-based location estimation algorithm for large aperture microphone arrays },
  Author                   = {Ying Yu and Harvey F. Silverman},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2004},
  Pages                    = {77-80},
  Volume                   = {IV},

  Comment                  = {603:ReadYes},
  Review                   = {Mic pair subset choice tradeoffs for localization w/ large arr
* Have 128 microphones in room, select subset for localization
* 
* inter-mic distance tradeoff
- more => less quant error due to waveform samp rate
- more => worse correlation 
- optimal choice picked by lookup tables
* number of TDOA estimates 
- simplex search for best loc. fit, given set of TDOA ests
- more => less est. variance
- more => more change of one v. bad est => total simplex fail
- thinks 8 estimates is about right}
}

@Article{Yuki06RobustTalkerDirection,
  Title                    = {Robust Talker Direction Estimation Based on Weighted {CSP} Analysis and Maximum Likelihood Estimation},
  Author                   = {Yuki DENDA, Takanobu NISHIURA and Yoichi YAMASHITA},
  Journal                  = {{IEICE} Trans Inf \& Syst},
  Year                     = {2006},
  Pages                    = {1050-1057},
  Volume                   = {E89-D},

  Comment                  = {632:ReadYes},
  File                     = {Yuki06RobustTalkerDirection.pdf:Yuki06RobustTalkerDirection.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Pairwise delay est like GCC-PHAT except divide by avg. speech spectrum. Noise subtraction might be interesting
* do GCC-PHAT like thing but divide by average speech spectrum instead (averaged over a pile of read speech).
 (seems to me like inverse filtering would be better)
* the probabilistic part: fit a sequence of estimated delays to a Gaussian, and selecting the ML sample (mean!)
 - do some kinda iterative minimum variance estimation, which requires that you know mic spacing
* noise subtraction requires VAD, is actuallly subtraced off of the correlation waveform: haven't seen that before...},
  Timestamp                = {2007.05.28},
  Url                      = {http://ietisy.oxfordjournals.org/cgi/content/abstract/E89-D/3/1050}
}

@InProceedings{Zaffalon02featSelMutInf,
  Title                    = {Robust Feature Selection using Distributions of Mutual Information},
  Author                   = {Marco Zaffalon and Marcus Hutter},
  Booktitle                = {Proceedings of the 18th International Conference on Uncertainty in Artificial Intelligence (UAI-2002)},
  Year                     = {2002},

  Address                  = {San Francisco, CA.},
  Editor                   = {A. Darwiche and N. Friedman},
  Pages                    = {577--584},
  Publisher                = {Morgan Kaufmann},

  Abstract                 = {Mutual information is widely used in artificial intelligence, in a descriptive way, to measure the stochastic dependence of discrete random variables. In order to address questions such as the reliability of the empirical value, one must consider sample-to-population inferential approaches. This paper deals with the distribution of mutual information, as obtained in a Bayesian framework by a second-order Dirichlet prior distribution. The exact analytical expression for the mean and an analytical approximation of the variance are reported. Asymptotic approximations of the distribution are proposed. The results are applied to the problem of selecting features for incremental learning and classification of the naive Bayes classifier. A fast, newly defined method is shown to outperform the traditional approach based on empirical mutual information on a number of real data sets. Finally, a theoretical development is reported that allows one to efficiently extend the above methods to incomplete samples in an easy and effective way.},
  Categories               = {I.2. [Artificial Intelligence]},
  File                     = {Zaffalon02featSelMutInf.pdf:Zaffalon02featSelMutInf.pdf:PDF},
  Ftp                      = {ftp://ftp.idsia.ch/pub/techrep/IDSIA-08-02.ps.gz},
  Keywords                 = {Robust feature selection, naive Bayes classifier, Mutual Information, Cross Entropy, Dirichlet distribution, Second order distribution, expectation and variance of mutual information.},
  Owner                    = {scotto},
  Report                   = {IDSIA-08-02 and cs.AI/0206006},
  Review                   = {determines mutual info feature selection threshold by estimating the MI distribution. Does forward and backward selection algorithms.},
  Timestamp                = {2008.01.29},
  Url2                     = {http://arxiv.org/abs/cs.AI/0206006}
}

@Misc{zahorik96distPercept,
  Title                    = {Auditory distance perception: A literature review},

  Author                   = {P. Zahorik},

  Comment                  = {212: ReadYes},
  Review                   = {Human distance perception (not angle) is probably done by sound level and reverberation}
}

@InProceedings{zhang02phoneVAD,
  Title                    = {Phone Based Voice Activity Detection Using Online Bayesian Adaptation with Conjugate Normal Distributions},
  Author                   = {Jianping Zhang and Wayne Ward and Bryan Pellom},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},
  Pages                    = {321-324},
  Volume                   = {1},

  Comment                  = {419: ReadYes},
  Review                   = {online VAD from most likely phone model (online adapted)
* 50 phone models plus 12 noise phones
* single mixture Gaussian models
* pick most likely phone model 
* adapt most likely model if likelihood diff from 2nd ML is large
* state machine controls speech/nonspeech output (inserting some delay)
* HMM phone models w/ GMM obs. improves results over 1-GMM models
HMM/GMM explanation is not clear:
-- how do Viterbi decoding of HMM if this is an online algorithm
-- how many mixtured did they use?
-- HMM section seems to just show that HMM's w/ Viterbi could do better
Does better than alternatives for normal phone communication:
- energy
- G.729B
- combined method (energy/periodicity)
Complaints about other methods:
- energy: fails in noise
- LPC residual / HOS: may fail if non-Gaussian noise
- Parallel Model combination: fail in nonstationary, not online

* This is the VAD used in the communicator},
  Url                      = {http://ieeexplore.ieee.org/iel5/7874/21701/01005741.pdf?isNumber=21701&prod=IEEE+CNF&arnumber=1005741&arSt=321&ared=324&arAuthor=Jianping+Zhang%3B+Ward%2C+W.%3B+Pellom%2C+B.%3B}
}

@Article{zhang92lagrangeNN,
  Title                    = {Lagrange programming neural networks },
  Author                   = {Zhang, S. and Constantinides, A.G.},
  Journal                  = {Circuits and Systems {II}: Analog and Digital Signal Processing, {IEEE} Trans. on},
  Year                     = {1992},
  Number                   = {7},
  Pages                    = {441-452},
  Volume                   = {39},

  Comment                  = {373: ReadNo},
  Review                   = {The basis and stability analysis clue for Doukas BSS VAD},
  Url                      = {http://ieeexplore.ieee.org/iel4/82/4198/00160169.pdf?isNumber=4198&prod=JNL&arnumber=160169&arSt=441&ared=452&arAuthor=Zhang%2C+S.%3B+Constantinides%2C+A.G.}
}

@InProceedings{zhang01clustMDL,
  Title                    = {{MDL}-based cluster number decision methods for speaker clustering and {MLLR} adaptation},
  Author                   = {Zhipeng Zhang and Sadaoki Furui},
  Booktitle                = {ITR2001},
  Year                     = {2001},
  Pages                    = {41-44},

  Comment                  = {ReadNo},
  File                     = {zhang01clustMDL.pdf:zhang01clustMDL.pdf:PDF},
  Review                   = {number of clusters chosen by length sensitive MDL, one of Furui's students so better read this.},
  Url                      = {http://www.furui.cs.titech.ac.jp/publication/2001/itr2001_41.pdf}
}

@InProceedings{zhang00spkchangedet,
  Title                    = {On-line incremental speaker adaptation with automatic speaker change detection},
  Author                   = {Z. Zhang and S. Furui and K. Ohtsuki},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2000},
  Pages                    = {961-964},
  Volume                   = {2},

  Comment                  = {161: ReadYes},
  Review                   = {Broadcast News change det. MLLR compared w/ GMM hybrid on sentences
* utterance breakpoints candidates from manual sentence segmentation
* actually does better in WER than if had correct spkr ID 
* only two segs at a time, no clustering
* change det. if MLLR adapted HMM has higher likelihood than non-adapted
* doing same w/ 64 mixture GMM works almost as well -- similar to UBM
* no clustering: just do adjacent segments}
}

@InProceedings{zhao02cochanAssist,
  Title                    = {Co-channel speech separation for assistive listening},
  Author                   = {Yunxin Zhao and Kuan-Chieh Yen and S. Soli and Shawn Gao and A. Vermiglio},
  Booktitle                = {Proc. ICASSP},
  Year                     = {2002},
  Pages                    = {1945-1948},
  Volume                   = {2},

  Comment                  = {338: ReadYes},
  Review                   = {Time domain adaptive multi-mic decorrelation
* ADF (adaptive decorrelation filtering) makes "cocktail" speech more intelligble
* ADF explained in [ref 3, also by Zhao]}
}

@InProceedings{zhong03telephoneSpkrClust,
  Title                    = {Acoustic Change Detection and Segment Clustering of Two-Way Telephone Conversations},
  Author                   = {Xin Zhong and Mark Clements and Sung Lim},
  Booktitle                = {Eurospeech},
  Year                     = {2003 },
  Pages                    = {2925-2928},

  Comment                  = {581: ReadNo},
  Review                   = {switcboard crossvad segmentation!}
}

@Article{zhou00spkrSegBIC,
  Title                    = {Unsupervised Audio Stream Segmentation and Clustering Via the Bayesian Information Criterion},
  Author                   = {Bowen Zhou and John H.L. Hansen},
  Journal                  = {Proc. ICSLP},
  Year                     = {2000},

  Comment                  = {416: ReadNo},
  File                     = {zhou00spkrSegBIC.pdf:zhou00spkrSegBIC.pdf:PDF},
  Review                   = {The authors propose a new approach for audio stream segmentation and clustering that uses Hotelling's T2-statistic to improve the speed and accuracy of the Bayesian information criterion (BIC) based methods. The method uses Hotelling's T2-statistic to search for candidate boundaries. Then using the BIC method, the method validates, or discards, the boundaries. The advantages of this method are: the computation of the Hotelling's T2-statistic is faster than the BIC method and it provides more precise boundary candidates. 

On ref list at: http://www.ece.ogi.edu/~adami/references.htm},
  Url                      = {http://cslr.colorado.edu/beginweb/ngsw/publications/CP-ICSLP2000-BIC.Oct00.pdf}
}

@TechReport{Zhu04SimpleTechniqueAutomatically,
  Title                    = {A Simple Technique for Automatically Selecting the Number of Principal Components via the Use of Profle Likelihood},
  Author                   = {Mu Zhu},
  Institution              = {Department of Statistics \& Actuarial Science
University of Waterloo},
  Year                     = {2004},
  Number                   = {2004-10},
  Type                     = {Working Paper},

  Comment                  = {626:ReadYes},
  File                     = {Zhu04SimpleTechniqueAutomatically.pdf:Zhu04SimpleTechniqueAutomatically.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Automates the "scree method" for selecting the number of principal compononents
* looks for the knee in the curve (or the screen a the bottom of a cliff)

Basic Idea
* model the eigenvalue mags as two Gassian distributions, one for the significant comps and one for the insignificant ones
* finds the eigenvalue location where the two-Gaussian model fits best.

I coded this one up in Matlab},
  Timestamp                = {2007.04.06},
  Url                      = {http://www.stats.uwaterloo.ca/stats_navigation/techreports/04techreports.shtml}
}

@InProceedings{zibulevsky00bss2ndOSS,
  Title                    = {Second order blind source separation by recursive splitting of signal subspaces},
  Author                   = {Zibulevsky, M. and Pearlmutter, B.A.},
  Booktitle                = {ICA2000},
  Year                     = {2000},

  Comment                  = {ReadNo},
  File                     = {zibulevsky00bss2ndOSS.ps.gz:zibulevsky00bss2ndOSS.ps.gz:PDF},
  Review                   = {music/speech and subspace},
  Url                      = {http://iew3.technion.ac.il/~mcib/treedecor3.ps.gz}
}

@Article{zibulevsky01blind,
  Title                    = {Blind Source Separation by Sparse Decomposition in a Signal Dictionary},
  Author                   = {Michael Zibulevsky and Barak A. Pearlmutter},
  Journal                  = {Neural Computation},
  Year                     = {2001},
  Number                   = {4},
  Pages                    = {863-882},
  Volume                   = {13},

  Comment                  = {ReadNo},
  Review                   = {For fewer speakers than microphones, or dim reduction, sparse coding},
  Url                      = {citeseer.nj.nec.com/zibulevsky00blind.html}
}

@TechReport{zibulevsky01icaExtract1,
  Title                    = {Extraction of a single source from multichannel data using sparse decomposition},
  Author                   = {M. Zibulevsky and Y.Y. Zeevi},
  Institution              = {Technion},
  Year                     = {2001},

  Comment                  = {ReadNo},
  File                     = {zibulevsky01icaExtract1.ps.gz:zibulevsky01icaExtract1.ps.gz:PDF},
  Review                   = {overlap resolution after 1st pass spkr models built
has convex so maybe can combine w/ the LP/ARMA/mono idea?},
  Url                      = {http://iew3.technion.ac.il/~mcib/extr_onesrc_nc4.ps.gz}
}

@Article{Zotkin04SpchLocHierPowSrch,
  Title                    = {Accelerated speech source localization via a hierarchical search of steered response power},
  Author                   = {Zotkin, D.N. and Duraiswami, R.},
  Journal                  = {Speech and Audio Processing, IEEE Transactions on},
  Year                     = {2004},
  Number                   = {5},
  Pages                    = {499- 508},
  Volume                   = {12},

  File                     = {Zotkin04SpchLocHierPowSrch.pdf:Zotkin04SpchLocHierPowSrch.pdf:PDF},
  Owner                    = {scotto},
  Review                   = {Hierarchical Search for max receive power after GCC-PHAT weighting, resolution dependent search freqs
* enhancement of SRP-PHAT in Brandstein01MicArrays (also some grid search paper of his, I think)
* requires known microphone spacing, known room dimensions
* mics very closely spaced, 0.3m
* heirearchical, multires search of cartesian space grid, calculating corresponding mic delays
* search @ low resolultion, low freq beamforming (clip FFT bins) first, resolution/freq is res=lambda/5
* does PHAT weigthing
* in highly symmetric reverb simulations, 30% of locs not @ peak power (reverb=90ms); 55% @ reverb=210ms
 (saw some false peaks in real data too)
* says that low initial resolution helps ignore false peaks
* very short analysis windows: 25-100ms
* performs worse than brute force, high res search and others for window lenght 75 and 100ms (b/c other tech's were degraded, I think?, not because this got worse @ long windows
* computationally much more efficient than other search techniques},
  Timestamp                = {2007.08.03},
  Url                      = {http://ieeexplore.ieee.org.offcampus.lib.washington.edu/search/srchabstract.jsp?arnumber=1323086&isnumber=29292&punumber=89&k2dockey=1323086@ieeejrns&query=%28%28accelerated+speech+source+localization+via+a%0D%0Ahierarchical+search+of+steered+response+power%29%3Cin%3Emetadata%29&pos=0}
}

@Article{zotkin02jointParticleTrack,
  Title                    = {Joint audio-visual tracking using particle filters},
  Author                   = {D. Zotkin and R.Duraiswami and L.Davis},
  Journal                  = {EURASIP journal on Applied Signal Processing},
  Year                     = {2002},

  Comment                  = {310: ReadYes},
  Review                   = {Fuses/tracks video and audio position estimates w/ particle filter
* I skimmed this just to get the gist
* features are face-colored video blobs and voice location estimates
* voice location is TDOA using generalized cross-correlation
* particle filter handles missing data (video occlusion or silence)
* "particles" are sort of like GMM mixture components over time in a Kalman filter
* refs [11],[5] may be relevant for fusing spkrID and location features
* maybe relevant to pitch tracking or overlap detection, too}
}

@InProceedings{zubelli97pulseDeint,
  Title                    = {An Algorithm for Deinterleaving Pulse Trains Using the Fast Wavelet Transform},
  Author                   = {Jorge Passamani Zubelli and M.A.Grivet and R. Tavora and E.L.Pinto},
  Booktitle                = {Brazilian Symposium of Telecommunications},
  Year                     = {1997},

  Comment                  = {ReadNo},
  Review                   = {good for # of talker est?, overlap det?}
}

@Book{Brandstein01MicArrays,
  Title                    = {Microphone Arrays},
  Editor                   = {Michael Brandstein and Darren Ward},
  Publisher                = {Springer},
  Year                     = {2001},

  Owner                    = {scotto},
  Timestamp                = {2007.08.03}
}

@Book{webster98medInstBk,
  Title                    = {Medical Instrumentation },
  Editor                   = {John G. Webster},
  Publisher                = {John Wiley \& Sons, Inc},
  Year                     = {1998},

  Review                   = {Book for biomed class I TA'ed in 2005 (EE436)
The blood temp vs. velocity relation is on p. 355}
}

@Book{,
  title = {Design and operation of power systems with large amounts of wind power. Final summary report, IEA WIND Task 25, Phase three 2012?2014},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectory:papers.speakerClust;}

@Comment{jabref-meta: fileDirectory-scot:papers.speakerClust;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:semisupWorkshop07\;0\;1\;\;\;\;;
1 StaticGroup:ovdetasru07\;0\;1\;\;\;\;;
1 StaticGroup:waspaaComment\;0\;1\;\;\;\;;
}

@Comment{jabref-meta: selector_author:weakly supervised learning, prosody, conversational speech, prosodic breaks, prominence, pitch accent, EM training, decision tree, co-training, self-training, bagging;}
